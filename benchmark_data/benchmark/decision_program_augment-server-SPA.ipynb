{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db35e3d-1124-4cc4-9732-30c61afa7a26",
   "metadata": {},
   "source": [
    "# Decision program using machine learning methods\n",
    "## SparkSQL, basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42129418-1fba-457e-a372-a3a81aabed89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.0 in /usr/local/lib/python3.10/dist-packages (1.26.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn==1.5.0 in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.0) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.0) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.0) (3.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: statsmodels==0.14.2 in /usr/local/lib/python3.10/dist-packages (0.14.2)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels==0.14.2) (2.2.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels==0.14.2) (1.14.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels==0.14.2) (24.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels==0.14.2) (1.26.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels==0.14.2) (0.5.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels==0.14.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels==0.14.2) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels==0.14.2) (2.9.0.post0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels==0.14.2) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib==3.9.0 in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.0) (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.0) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.0) (24.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.0) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.0) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.0) (1.26.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.0) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.0) (3.1.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.0) (4.53.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.0) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.13.2) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.13.2) (3.9.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.13.2) (1.26.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (4.53.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (3.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.2.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn==0.13.2) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn==0.13.2) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (59.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: dhg==0.9.4 in /usr/local/lib/python3.10/dist-packages (0.9.4)\n",
      "Requirement already satisfied: torch<2.0,>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from dhg==0.9.4) (1.13.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dhg==0.9.4) (1.26.0)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from dhg==0.9.4) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from dhg==0.9.4) (1.5.0)\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from dhg==0.9.4) (3.6.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dhg==0.9.4) (2.31.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from dhg==0.9.4) (3.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.12.1->dhg==0.9.4) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.12.1->dhg==0.9.4) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.12.1->dhg==0.9.4) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.12.1->dhg==0.9.4) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.12.1->dhg==0.9.4) (11.7.99)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0,>=1.12.1->dhg==0.9.4) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0,>=1.12.1->dhg==0.9.4) (59.6.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg==0.9.4) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg==0.9.4) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg==0.9.4) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg==0.9.4) (1.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg==0.9.4) (4.53.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg==0.9.4) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg==0.9.4) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg==0.9.4) (1.4.5)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->dhg==0.9.4) (1.13.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->dhg==0.9.4) (2.0.31)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna->dhg==0.9.4) (4.66.4)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna->dhg==0.9.4) (6.0.1)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->dhg==0.9.4) (6.8.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dhg==0.9.4) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dhg==0.9.4) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dhg==0.9.4) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dhg==0.9.4) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->dhg==0.9.4) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->dhg==0.9.4) (3.5.0)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->dhg==0.9.4) (1.3.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->dhg==0.9.4) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->dhg==0.9.4) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->dhg==0.9.4) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.0\n",
    "!pip install scikit-learn==1.5.0\n",
    "!pip install statsmodels==0.14.2\n",
    "!pip install matplotlib==3.9.0\n",
    "!pip install seaborn==0.13.2\n",
    "!pip install torch==1.13.1\n",
    "!pip install tqdm==4.66.4\n",
    "!pip install dhg==0.9.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424d2e00-9146-4aa9-a3be-9731421befa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import dhg\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import export_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb24904-9f15-44f7-8909-3e069e5e46d6",
   "metadata": {},
   "source": [
    "#### Distribution of the runtimes in orders of magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab4fe1-abef-49e5-b702-d1752bd405d9",
   "metadata": {},
   "source": [
    "For the original queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b336eca-d8b8-431e-89d7-f2d31f559e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances with original runtime <= 0.01: 0\n",
      "Number of instances with original runtime (0.01, 0.1]: 35\n",
      "Number of instances with original runtime (0.1, 1]: 1638\n",
      "Number of instances with original runtime (1,10]: 598\n",
      "Number of instances with original runtime (10,100]: 241\n",
      "Number of instances with original runtime TO: 424\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('results/SPA_Scala_comparison_TO_augment_server.csv')\n",
    "\n",
    "df.loc[df['orig mean'] == 'TO', 'orig mean'] = 101\n",
    "column = df['orig mean'].astype(\"float64\")\n",
    "\n",
    "count_0_01_orig = 0\n",
    "count_0_1_orig = 0\n",
    "count_1_orig = 0\n",
    "count_10_orig = 0\n",
    "count_100_orig = 0\n",
    "count_TO_orig = 0\n",
    "\n",
    "for value in column:\n",
    "    if value <= 0.01:\n",
    "        count_0_01_orig += 1\n",
    "    elif value > 0.01 and value <= 0.1:\n",
    "        count_0_1_orig += 1\n",
    "    elif value > 0.1 and value <= 1:\n",
    "        count_1_orig += 1\n",
    "    elif value > 1 and value <= 10:\n",
    "        count_10_orig += 1\n",
    "    elif value > 10 and value <= 100:\n",
    "        count_100_orig += 1\n",
    "    else:\n",
    "        count_TO_orig += 1\n",
    "    \n",
    "\n",
    "print(\"Number of instances with original runtime <= 0.01:\", count_0_01_orig)\n",
    "print(\"Number of instances with original runtime (0.01, 0.1]:\", count_0_1_orig)\n",
    "print(\"Number of instances with original runtime (0.1, 1]:\", count_1_orig)\n",
    "print(\"Number of instances with original runtime (1,10]:\", count_10_orig)\n",
    "print(\"Number of instances with original runtime (10,100]:\", count_100_orig)\n",
    "print(\"Number of instances with original runtime TO:\", count_TO_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e943a9d8-52bf-4556-ad36-482c00972f62",
   "metadata": {},
   "source": [
    "for the rewritten queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0b2a25-5990-405c-a325-92f4f43266da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances with original runtime <= 0.01: 0\n",
      "Number of instances with original runtime (0.01, 0.1]: 12\n",
      "Number of instances with original runtime (0.1, 1]: 2179\n",
      "Number of instances with original runtime (1,10]: 461\n",
      "Number of instances with original runtime (10,100]: 282\n",
      "Number of instances with original runtime TO: 2\n"
     ]
    }
   ],
   "source": [
    "df.loc[df['rewr mean'] == 'TO', 'rewr mean'] = 101\n",
    "column = df['rewr mean'].astype(\"float64\")\n",
    "\n",
    "count_0_01_rewr = 0\n",
    "count_0_1_rewr = 0\n",
    "count_1_rewr = 0\n",
    "count_10_rewr = 0\n",
    "count_100_rewr = 0\n",
    "count_TO_rewr = 0\n",
    "\n",
    "for value in column:\n",
    "    if value <= 0.01:\n",
    "        count_0_01_rewr += 1\n",
    "    elif value > 0.01 and value <= 0.1:\n",
    "        count_0_1_rewr += 1\n",
    "    elif value > 0.1 and value <= 1:\n",
    "        count_1_rewr += 1\n",
    "    elif value > 1 and value <= 10:\n",
    "        count_10_rewr += 1\n",
    "    elif value > 10 and value <= 100:\n",
    "        count_100_rewr += 1\n",
    "    else:\n",
    "        count_TO_rewr += 1\n",
    "    \n",
    "\n",
    "print(\"Number of instances with original runtime <= 0.01:\", count_0_01_rewr)\n",
    "print(\"Number of instances with original runtime (0.01, 0.1]:\", count_0_1_rewr)\n",
    "print(\"Number of instances with original runtime (0.1, 1]:\", count_1_rewr)\n",
    "print(\"Number of instances with original runtime (1,10]:\", count_10_rewr)\n",
    "print(\"Number of instances with original runtime (10,100]:\", count_100_rewr)\n",
    "print(\"Number of instances with original runtime TO:\", count_TO_rewr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10afb32e-3e67-48af-a767-7b4dbc21ab5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_orig = [count_0_01_orig, count_0_1_orig, count_1_orig, count_10_orig, count_100_orig, count_TO_orig]\n",
    "numbers_rewr = [count_0_01_rewr, count_0_1_rewr, count_1_rewr, count_10_rewr, count_100_rewr, count_TO_rewr]\n",
    "\n",
    "# Indices for each number\n",
    "indices = [\"0.01\", \"0.1\", \"1\", \"10\", \"100\", \"TO\"]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot original numbers\n",
    "axs[0].barh(indices, numbers_orig)\n",
    "axs[0].set_xlabel('Count')\n",
    "axs[0].set_ylabel('Order of magnitude')\n",
    "axs[0].set_title('Original queries')\n",
    "axs[0].set_xlim(0, 2200)\n",
    "\n",
    "# Plot rewritten numbers\n",
    "axs[1].barh(indices, numbers_rewr)\n",
    "axs[1].set_xlabel('Count')\n",
    "axs[1].set_ylabel('Order of magnitude')\n",
    "axs[1].set_title('Rewritten queries')\n",
    "axs[1].set_xlim(0, 2200)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da2cf6-ee27-4e05-ae58-473e58cc8bd2",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77dacf66-452f-4185-ab16-d77b08bc169f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bench</th>\n",
       "      <th>query</th>\n",
       "      <th>orig/rewr(mean)</th>\n",
       "      <th>orig/rewr+rewr(mean)</th>\n",
       "      <th>orig mean</th>\n",
       "      <th>rewr mean</th>\n",
       "      <th>rewr mean+rewr</th>\n",
       "      <th>diff rewr-orig</th>\n",
       "      <th>diff rewr+rewr-orig</th>\n",
       "      <th>#relations</th>\n",
       "      <th>...</th>\n",
       "      <th>max(branching factors)</th>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <th>median(branching factors)</th>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <th>balancedness factor</th>\n",
       "      <th>container counts list</th>\n",
       "      <th>branching factors list</th>\n",
       "      <th>hypergraph</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STATS</td>\n",
       "      <td>001-014</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>0.332952</td>\n",
       "      <td>2.258359</td>\n",
       "      <td>0.117732</td>\n",
       "      <td>2.043140</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>SELECT MIN(u.Id) FROM comments as c, votes as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STATS</td>\n",
       "      <td>001-014-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.343959</td>\n",
       "      <td>0.465946</td>\n",
       "      <td>2.262779</td>\n",
       "      <td>0.121988</td>\n",
       "      <td>1.918820</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>SELECT MIN(c.id) FROM comments as c, votes as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STATS</td>\n",
       "      <td>001-014-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.241465</td>\n",
       "      <td>0.358131</td>\n",
       "      <td>2.176462</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>1.934997</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, votes as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STATS</td>\n",
       "      <td>001-014-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.223958</td>\n",
       "      <td>0.286062</td>\n",
       "      <td>2.118357</td>\n",
       "      <td>0.062104</td>\n",
       "      <td>1.894398</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>SELECT MIN(u.Id) FROM comments as c, votes as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STATS</td>\n",
       "      <td>001-014-augF1-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.258606</td>\n",
       "      <td>0.327809</td>\n",
       "      <td>2.182811</td>\n",
       "      <td>0.069203</td>\n",
       "      <td>1.924205</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>SELECT MIN(c.id) FROM comments as c, votes as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bench                query orig/rewr(mean) orig/rewr+rewr(mean)  orig mean  \\\n",
       "0  STATS              001-014            orig                 orig   0.215220   \n",
       "1  STATS        001-014-augA1            orig                 orig   0.343959   \n",
       "2  STATS        001-014-augA2            orig                 orig   0.241465   \n",
       "3  STATS        001-014-augF1            orig                 orig   0.223958   \n",
       "4  STATS  001-014-augF1-augA1            orig                 orig   0.258606   \n",
       "\n",
       "   rewr mean  rewr mean+rewr  diff rewr-orig  diff rewr+rewr-orig  #relations  \\\n",
       "0   0.332952        2.258359        0.117732             2.043140           3   \n",
       "1   0.465946        2.262779        0.121988             1.918820           3   \n",
       "2   0.358131        2.176462        0.116667             1.934997           3   \n",
       "3   0.286062        2.118357        0.062104             1.894398           3   \n",
       "4   0.327809        2.182811        0.069203             1.924205           3   \n",
       "\n",
       "   ...  max(branching factors)  mean(branching factors)  \\\n",
       "0  ...                       2                      2.0   \n",
       "1  ...                       1                      1.0   \n",
       "2  ...                       1                      1.0   \n",
       "3  ...                       2                      2.0   \n",
       "4  ...                       1                      1.0   \n",
       "\n",
       "   median(branching factors)  q25(branching factors)  q75(branching factors)  \\\n",
       "0                        2.0                     2.0                     2.0   \n",
       "1                        1.0                     1.0                     1.0   \n",
       "2                        1.0                     1.0                     1.0   \n",
       "3                        2.0                     2.0                     2.0   \n",
       "4                        1.0                     1.0                     1.0   \n",
       "\n",
       "   balancedness factor                          container counts list  \\\n",
       "0                  1.0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "1                  NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "2                  NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "3                  1.0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "4                  NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "\n",
       "   branching factors list                                         hypergraph  \\\n",
       "0                     [2]  b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "1                  [1, 1]  b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "2                  [1, 1]  b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "3                     [2]  b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "4                  [1, 1]  b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "\n",
       "                                                text  \n",
       "0  SELECT MIN(u.Id) FROM comments as c, votes as ...  \n",
       "1  SELECT MIN(c.id) FROM comments as c, votes as ...  \n",
       "2  SELECT MIN(v.id) FROM comments as c, votes as ...  \n",
       "3  SELECT MIN(u.Id) FROM comments as c, votes as ...  \n",
       "4  SELECT MIN(c.id) FROM comments as c, votes as ...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'results/features_times_SPA.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95e056c-cbfb-48fb-ad35-8b45b10e923f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bench                         object\n",
       "query                         object\n",
       "orig/rewr(mean)               object\n",
       "orig/rewr+rewr(mean)          object\n",
       "orig mean                    float64\n",
       "rewr mean                    float64\n",
       "rewr mean+rewr               float64\n",
       "diff rewr-orig               float64\n",
       "diff rewr+rewr-orig          float64\n",
       "#relations                     int64\n",
       "#conditions                    int64\n",
       "#filters                       int64\n",
       "#joins                         int64\n",
       "depth                          int64\n",
       "min(container counts)          int64\n",
       "max(container counts)          int64\n",
       "mean(container counts)       float64\n",
       "q25(container counts)        float64\n",
       "median(container counts)     float64\n",
       "q75(container counts)        float64\n",
       "min(branching factors)         int64\n",
       "max(branching factors)         int64\n",
       "mean(branching factors)      float64\n",
       "median(branching factors)    float64\n",
       "q25(branching factors)       float64\n",
       "q75(branching factors)       float64\n",
       "balancedness factor          float64\n",
       "container counts list         object\n",
       "branching factors list        object\n",
       "hypergraph                    object\n",
       "text                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1137fd08-d578-4457-b75a-39a1c0b012e8",
   "metadata": {},
   "source": [
    "Transform the hypergraph, which is saved as pickle object, back to a dhg hypergraph object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edc15423-1e19-4b2d-9351-1c022e647d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hypergraph\"] = df[\"hypergraph\"].apply(lambda x: pickle.loads(eval(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a17ac96-eb96-4a60-8776-ff6c71074256",
   "metadata": {},
   "source": [
    "#### Delete those examples, where both methods gave a timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b71ca29c-bbbc-4975-8935-fbbdb92f47fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bench</th>\n",
       "      <th>query</th>\n",
       "      <th>orig/rewr(mean)</th>\n",
       "      <th>orig/rewr+rewr(mean)</th>\n",
       "      <th>orig mean</th>\n",
       "      <th>rewr mean</th>\n",
       "      <th>rewr mean+rewr</th>\n",
       "      <th>diff rewr-orig</th>\n",
       "      <th>diff rewr+rewr-orig</th>\n",
       "      <th>#relations</th>\n",
       "      <th>...</th>\n",
       "      <th>max(branching factors)</th>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <th>median(branching factors)</th>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <th>balancedness factor</th>\n",
       "      <th>container counts list</th>\n",
       "      <th>branching factors list</th>\n",
       "      <th>hypergraph</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>wiki-path08</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 2]</td>\n",
       "      <td>Hypergraph(num_v=18, num_e=9)</td>\n",
       "      <td>select MIN(p1.toNode) from wiki p1, wiki p2, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>wiki-path08-augA1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 2]</td>\n",
       "      <td>Hypergraph(num_v=18, num_e=9)</td>\n",
       "      <td>select MIN(p2.fromnode) from wiki p1, wiki p2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bench              query orig/rewr(mean) orig/rewr+rewr(mean)  orig mean  \\\n",
       "2092  SNAP        wiki-path08               -                    -      100.0   \n",
       "2093  SNAP  wiki-path08-augA1               -                    -      100.0   \n",
       "\n",
       "      rewr mean  rewr mean+rewr  diff rewr-orig  diff rewr+rewr-orig  \\\n",
       "2092      100.0           100.0             0.0                  0.0   \n",
       "2093      100.0           100.0             0.0                  0.0   \n",
       "\n",
       "      #relations  ...  max(branching factors)  mean(branching factors)  \\\n",
       "2092           9  ...                       2                 1.142857   \n",
       "2093           9  ...                       2                 1.142857   \n",
       "\n",
       "      median(branching factors)  q25(branching factors)  \\\n",
       "2092                        1.0                     1.0   \n",
       "2093                        1.0                     1.0   \n",
       "\n",
       "      q75(branching factors)  balancedness factor  \\\n",
       "2092                     1.0                  1.0   \n",
       "2093                     1.0                  1.0   \n",
       "\n",
       "                                  container counts list  \\\n",
       "2092  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2093  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "      branching factors list                     hypergraph  \\\n",
       "2092   [1, 1, 1, 1, 1, 1, 2]  Hypergraph(num_v=18, num_e=9)   \n",
       "2093   [1, 1, 1, 1, 1, 1, 2]  Hypergraph(num_v=18, num_e=9)   \n",
       "\n",
       "                                                   text  \n",
       "2092  select MIN(p1.toNode) from wiki p1, wiki p2, w...  \n",
       "2093  select MIN(p2.fromnode) from wiki p1, wiki p2,...  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"orig/rewr(mean)\"] == \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c2c1f-0061-469e-b69e-5e75d817971a",
   "metadata": {},
   "source": [
    "For the SNAP dataset the wiki-path06, wiki-path07, wiki-path08 and wiki-tree03 (for all augmentation cases) did not finish the evaluation within our timeout (100 sec). Therefore, we cannot conclude which variante is the better one and we delete those 32 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfd9e955-6bdd-45d8-87d7-38a43f7a29f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2934, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"orig/rewr(mean)\"] != \"-\"]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e2a1a-b513-4bd9-a009-4a197c91f4e1",
   "metadata": {},
   "source": [
    "#### Get the feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051cdd4-5edf-4f3e-a0c8-06f3a5e0b275",
   "metadata": {},
   "source": [
    "Get the features matrix X and the response variables y1 and y1, where once the rewritting time and the evaluation time are taken into consideration and once only the evaluation time. Additionally the response variables have to have numbers in it and we assign 1 = rewr and 0 = orig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9705deff-9dac-4389-9793-0ca787300662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#relations</th>\n",
       "      <th>#conditions</th>\n",
       "      <th>#filters</th>\n",
       "      <th>#joins</th>\n",
       "      <th>depth</th>\n",
       "      <th>min(container counts)</th>\n",
       "      <th>max(container counts)</th>\n",
       "      <th>mean(container counts)</th>\n",
       "      <th>q25(container counts)</th>\n",
       "      <th>median(container counts)</th>\n",
       "      <th>q75(container counts)</th>\n",
       "      <th>min(branching factors)</th>\n",
       "      <th>max(branching factors)</th>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <th>median(branching factors)</th>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #relations  #conditions  #filters  #joins  depth  min(container counts)  \\\n",
       "0           3            7         5       2      1                      1   \n",
       "1           3            7         5       2      2                      1   \n",
       "2           3            7         5       2      2                      1   \n",
       "3           3            7         5       2      1                      1   \n",
       "4           3            7         5       2      2                      1   \n",
       "\n",
       "   max(container counts)  mean(container counts)  q25(container counts)  \\\n",
       "0                      3                1.133333                    1.0   \n",
       "1                      3                1.133333                    1.0   \n",
       "2                      3                1.133333                    1.0   \n",
       "3                      3                1.133333                    1.0   \n",
       "4                      3                1.133333                    1.0   \n",
       "\n",
       "   median(container counts)  q75(container counts)  min(branching factors)  \\\n",
       "0                       1.0                    1.0                       2   \n",
       "1                       1.0                    1.0                       1   \n",
       "2                       1.0                    1.0                       1   \n",
       "3                       1.0                    1.0                       2   \n",
       "4                       1.0                    1.0                       1   \n",
       "\n",
       "   max(branching factors)  mean(branching factors)  median(branching factors)  \\\n",
       "0                       2                      2.0                        2.0   \n",
       "1                       1                      1.0                        1.0   \n",
       "2                       1                      1.0                        1.0   \n",
       "3                       2                      2.0                        2.0   \n",
       "4                       1                      1.0                        1.0   \n",
       "\n",
       "   q25(branching factors)  q75(branching factors)  \n",
       "0                     2.0                     2.0  \n",
       "1                     1.0                     1.0  \n",
       "2                     1.0                     1.0  \n",
       "3                     2.0                     2.0  \n",
       "4                     1.0                     1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 9:26]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b1b77f-8f98-43c9-bba2-47a0578364f4",
   "metadata": {},
   "source": [
    "Get the feature matrix, which additionally includes the hypergraph information/representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b07433-fea3-4534-afe5-4c533884d15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#relations</th>\n",
       "      <th>#conditions</th>\n",
       "      <th>#filters</th>\n",
       "      <th>#joins</th>\n",
       "      <th>depth</th>\n",
       "      <th>min(container counts)</th>\n",
       "      <th>max(container counts)</th>\n",
       "      <th>mean(container counts)</th>\n",
       "      <th>q25(container counts)</th>\n",
       "      <th>median(container counts)</th>\n",
       "      <th>q75(container counts)</th>\n",
       "      <th>min(branching factors)</th>\n",
       "      <th>max(branching factors)</th>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <th>median(branching factors)</th>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <th>hypergraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #relations  #conditions  #filters  #joins  depth  min(container counts)  \\\n",
       "0           3            7         5       2      1                      1   \n",
       "1           3            7         5       2      2                      1   \n",
       "2           3            7         5       2      2                      1   \n",
       "3           3            7         5       2      1                      1   \n",
       "4           3            7         5       2      2                      1   \n",
       "\n",
       "   max(container counts)  mean(container counts)  q25(container counts)  \\\n",
       "0                      3                1.133333                    1.0   \n",
       "1                      3                1.133333                    1.0   \n",
       "2                      3                1.133333                    1.0   \n",
       "3                      3                1.133333                    1.0   \n",
       "4                      3                1.133333                    1.0   \n",
       "\n",
       "   median(container counts)  q75(container counts)  min(branching factors)  \\\n",
       "0                       1.0                    1.0                       2   \n",
       "1                       1.0                    1.0                       1   \n",
       "2                       1.0                    1.0                       1   \n",
       "3                       1.0                    1.0                       2   \n",
       "4                       1.0                    1.0                       1   \n",
       "\n",
       "   max(branching factors)  mean(branching factors)  median(branching factors)  \\\n",
       "0                       2                      2.0                        2.0   \n",
       "1                       1                      1.0                        1.0   \n",
       "2                       1                      1.0                        1.0   \n",
       "3                       2                      2.0                        2.0   \n",
       "4                       1                      1.0                        1.0   \n",
       "\n",
       "   q25(branching factors)  q75(branching factors)  \\\n",
       "0                     2.0                     2.0   \n",
       "1                     1.0                     1.0   \n",
       "2                     1.0                     1.0   \n",
       "3                     2.0                     2.0   \n",
       "4                     1.0                     1.0   \n",
       "\n",
       "                      hypergraph  \n",
       "0  Hypergraph(num_v=17, num_e=3)  \n",
       "1  Hypergraph(num_v=17, num_e=3)  \n",
       "2  Hypergraph(num_v=17, num_e=3)  \n",
       "3  Hypergraph(num_v=17, num_e=3)  \n",
       "4  Hypergraph(num_v=17, num_e=3)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hg = pd.concat([X, df.iloc[:,29]], axis = 1)\n",
    "X_hg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cfe523",
   "metadata": {},
   "source": [
    "#### Log-transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9181de3-7d58-4f5f-a636-993cd9410ff9",
   "metadata": {},
   "source": [
    "This basic features do not need log transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924ce8ed-0ac2-46d3-afb0-6a500537e4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#relations</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#conditions</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#filters</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#joins</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depth</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min(container counts)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max(container counts)</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean(container counts)</th>\n",
       "      <td>1.047619</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.552381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q25(container counts)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median(container counts)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q75(container counts)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Min   Max       Diff\n",
       "#relations                 2.000000  11.0   9.000000\n",
       "#conditions                2.000000  20.0  18.000000\n",
       "#filters                   0.000000  16.0  16.000000\n",
       "#joins                     1.000000  12.0  11.000000\n",
       "depth                      1.000000   7.0   6.000000\n",
       "min(container counts)      1.000000   1.0   0.000000\n",
       "max(container counts)      2.000000   5.0   3.000000\n",
       "mean(container counts)     1.047619   1.6   0.552381\n",
       "q25(container counts)      1.000000   1.0   0.000000\n",
       "median(container counts)   1.000000   1.0   0.000000\n",
       "q75(container counts)      1.000000   1.0   0.000000\n",
       "min(branching factors)     1.000000   6.0   5.000000\n",
       "max(branching factors)     1.000000   6.0   5.000000\n",
       "mean(branching factors)    1.000000   6.0   5.000000\n",
       "median(branching factors)  1.000000   6.0   5.000000\n",
       "q25(branching factors)     1.000000   6.0   5.000000\n",
       "q75(branching factors)     1.000000   6.0   5.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_values = X.min()\n",
    "max_values = X.max()\n",
    "diff = max_values-min_values\n",
    "\n",
    "pd.DataFrame({'Min': min_values, 'Max': max_values, 'Diff': diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "859f1fb1-725a-4c2e-b7ba-53a84946f954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2500 with 33 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.hist(layout=(11, 3), figsize=(20, 25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c64d7-8ae9-4958-80b0-459e6b9dc269",
   "metadata": {},
   "source": [
    "#### Boxplots of running times for both cases (either original or rewritten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "028d16a2-be30-48b4-849d-7075488c566a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_orig = df[df['orig/rewr(mean)'] == 'orig']\n",
    "df_rewr = df[df['orig/rewr(mean)'] == 'rewr']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "sns.boxplot(y='orig mean', data=df, ax=axes[0,0])\n",
    "axes[0,0].set_title(f'Boxplot for orig')\n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df, ax=axes[0,1])\n",
    "axes[0,1].set_title(f'Boxplot for rewr')\n",
    "\n",
    "sns.boxplot(y='orig mean', data=df_orig, ax=axes[1,0])\n",
    "axes[1,0].set_title(f'Boxplot for orig if \"orig\"')\n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df_rewr, ax=axes[1,1])\n",
    "axes[1,1].set_title(f'Boxplot for rewr if \"rewr\"')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d876a-cba4-444a-964d-6c8333730182",
   "metadata": {},
   "source": [
    "The runtimes are highly skewed. Therefore, we log transform them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a68388f2-759e-4d72-b5ef-a3cf151254eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_log = df.copy()\n",
    "df_log[\"orig mean\"] = np.log(df_log[\"orig mean\"])\n",
    "df_log[\"rewr mean\"] = np.log(df_log[\"rewr mean\"])\n",
    "\n",
    "df_orig = df_log[df_log['orig/rewr(mean)'] == 'orig']\n",
    "df_rewr = df_log[df_log['orig/rewr(mean)'] == 'rewr']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12,7))\n",
    "\n",
    "sns.boxplot(y='orig mean', data=df_log, ax=axes[0,0])\n",
    "axes[0,0].set_title(f'log(runtimes for original queries)')\n",
    "axes[0,0].set_ylabel(\"log(mean original runtime)\")\n",
    "axes[0,0].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df_log, ax=axes[0,1])\n",
    "axes[0,1].set_title(f'log(runtimes for rewritten queries)')\n",
    "axes[0,1].set_ylabel(\"log(mean rewritten runtime)\")\n",
    "axes[0,1].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='orig mean', data=df_orig, ax=axes[1,0])\n",
    "axes[1,0].set_title(f'log(runtimes for original queries) if \"orig\"')\n",
    "axes[1,0].set_ylabel(\"log(mean original runtime)\")\n",
    "axes[1,0].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df_rewr, ax=axes[1,1])\n",
    "axes[1,1].set_title(f'log(runtimes for rewritten queries) if \"rewr\"')\n",
    "axes[1,1].set_ylabel(\"log(mean rewritten runtime)\")\n",
    "axes[1,1].set_ylim(-8, 6) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26bb11d8-54b5-41b1-9d5c-58319eed0546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_log = df.copy()\n",
    "df_log[\"orig mean\"] = np.log(df_log[\"orig mean\"])\n",
    "df_log[\"rewr mean\"] = np.log(df_log[\"rewr mean\"])\n",
    "\n",
    "df_orig = df_log[df_log['orig/rewr(mean)'] == 'orig']\n",
    "df_rewr = df_log[df_log['orig/rewr(mean)'] == 'rewr']\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(15,4))\n",
    "\n",
    "sns.boxplot(y='orig mean', data=df_log, ax=axes[0])\n",
    "axes[0].set_title(f'log(runtimes for original queries)')\n",
    "axes[0].set_ylabel(\"log(mean original runtime)\")\n",
    "axes[0].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df_log, ax=axes[1])\n",
    "axes[1].set_title(f'log(runtimes for rewritten queries)')\n",
    "axes[1].set_ylabel(\"log(mean rewritten runtime)\")\n",
    "axes[1].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='orig mean', data=df_orig, ax=axes[2])\n",
    "axes[2].set_title(f'log(runtimes for original queries) if \"orig\"')\n",
    "axes[2].set_ylabel(\"log(mean original runtime)\")\n",
    "axes[2].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df_rewr, ax=axes[3])\n",
    "axes[3].set_title(f'log(runtimes for rewritten queries) if \"rewr\"')\n",
    "axes[3].set_ylabel(\"log(mean rewritten runtime)\")\n",
    "axes[3].set_ylim(-8, 6) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c2d0a8-40ce-491c-9c2d-ccfa025da321",
   "metadata": {},
   "source": [
    "#### Scatterplot of running times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75f9c32f-53a7-4964-b987-25d1d1bd165d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=\"orig mean\", y=\"rewr mean\", data=df)\n",
    "sns.regplot(x=\"orig mean\", y=\"rewr mean\", data=df) \n",
    "\n",
    "plt.xlabel(\"original\")\n",
    "plt.ylabel(\"rewritten\")\n",
    "plt.title(f'Running times')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9364cbe-722c-495e-b3f2-6d115eb118f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=\"orig mean\", y=\"rewr mean\", data=df_log)\n",
    "sns.regplot(x=\"orig mean\", y=\"rewr mean\", data=df_log) \n",
    "\n",
    "plt.xlabel(\"original\")\n",
    "plt.ylabel(\"rewritten\")\n",
    "plt.title(f'Running times')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab4756-1755-4f8e-b098-47eabebf67bb",
   "metadata": {},
   "source": [
    "#### Classification response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43482284-5f2c-409e-83a6-70f86c2b6c75",
   "metadata": {},
   "source": [
    "Get the column(s) where we have \"orig\" or \"rewr\", depending on which method was faster. We now want to encode this as 0 (evaluating the original query faster) and 1 (evaluating the rewritten query faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7f20f22-c2dc-4124-848a-358bd736f54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: orig/rewr(mean), dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {'orig': 0, 'rewr': 1}\n",
    "y1 = df['orig/rewr(mean)'].map(mapping)\n",
    "y1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe610bf9-f34c-48f4-8cea-0a0916f82544",
   "metadata": {},
   "source": [
    "The number of appearances of original and rewritten is very balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdeaa90b-2268-467f-85d7-d0d934f557ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orig/rewr(mean)\n",
       "1    1482\n",
       "0    1452\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0380130-a50b-449a-9f1f-89905b6d7f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orig     1452\n",
       "rewr     1482\n",
       "equal       -\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = y1.value_counts().tolist()[::-1] + [\"-\"]\n",
    "count = pd.Series(count)\n",
    "count.index = [\"orig\", \"rewr\", \"equal\"]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73f73e0e-4bf0-461b-ba44-a391422285ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orig/rewr(mean)\n",
       "rewr    1482\n",
       "orig    1452\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"orig/rewr(mean)\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9d951",
   "metadata": {},
   "source": [
    "#### Classification response with three cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcbb5f18-bed4-452b-8e04-63b3c8856c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = abs(df[\"diff rewr-orig\"]) < 0.5\n",
    "df[\"orig/rewr/equal 0.5\"] = df[\"orig/rewr(mean)\"]\n",
    "df.loc[condition, 'orig/rewr/equal 0.5'] = 'equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f016c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = abs(df[\"diff rewr-orig\"]) < 0.1\n",
    "df[\"orig/rewr/equal 0.1\"] = df[\"orig/rewr(mean)\"]\n",
    "df.loc[condition, 'orig/rewr/equal 0.1'] = 'equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12ba1cc1-840b-4e38-86dd-770cbfd8fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = abs(df[\"diff rewr-orig\"]) < 0.05\n",
    "df[\"orig/rewr/equal 0.05\"] = df[\"orig/rewr(mean)\"]\n",
    "df.loc[condition, 'orig/rewr/equal 0.05'] = 'equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27259c2b-7ed2-49d4-b7da-072ddaf6ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = abs(df[\"diff rewr-orig\"]) < 0.01\n",
    "df[\"orig/rewr/equal 0.01\"] = df[\"orig/rewr(mean)\"]\n",
    "df.loc[condition, 'orig/rewr/equal 0.01'] = 'equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fed583b-c5f2-41ee-a51f-7e2565c35531",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_05 = df[\"orig/rewr/equal 0.5\"].value_counts()\n",
    "count_01 = df[\"orig/rewr/equal 0.1\"].value_counts()\n",
    "count_005 = df[\"orig/rewr/equal 0.05\"].value_counts()\n",
    "count_001 = df[\"orig/rewr/equal 0.01\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8b56a22-ce06-421b-b91d-d757b91ef823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orig/rewr/equal 0.01\n",
       "rewr     1444\n",
       "orig     1412\n",
       "equal      78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d9916a3-cd4d-457d-80f6-92bf9beeecf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2 classes</th>\n",
       "      <th>3 classes (0.01)</th>\n",
       "      <th>3 classes (0.05)</th>\n",
       "      <th>3 classes (0.1)</th>\n",
       "      <th>3 classes (0.5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orig</th>\n",
       "      <td>1452</td>\n",
       "      <td>1412</td>\n",
       "      <td>1146</td>\n",
       "      <td>726</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rewr</th>\n",
       "      <td>1482</td>\n",
       "      <td>1444</td>\n",
       "      <td>1351</td>\n",
       "      <td>1260</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal</th>\n",
       "      <td>-</td>\n",
       "      <td>78</td>\n",
       "      <td>437</td>\n",
       "      <td>948</td>\n",
       "      <td>1802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2 classes  3 classes (0.01)  3 classes (0.05)  3 classes (0.1)  \\\n",
       "orig       1452              1412              1146              726   \n",
       "rewr       1482              1444              1351             1260   \n",
       "equal         -                78               437              948   \n",
       "\n",
       "       3 classes (0.5)  \n",
       "orig               104  \n",
       "rewr              1028  \n",
       "equal             1802  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.concat([count_001, count_005, count_01, count_05], axis = 1)\n",
    "counts.iloc[[0, 1]] = counts.iloc[[1, 0]].values\n",
    "counts.index = [\"orig\", \"rewr\", \"equal\"]\n",
    "counts = pd.concat([count, counts], axis = 1)\n",
    "counts.columns = [\"2 classes\", \"3 classes (0.01)\", \"3 classes (0.05)\", \"3 classes (0.1)\", \"3 classes (0.5)\"]\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d408dfb-744c-4d1a-87d7-17b2a1d8db97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: orig/rewr/equal 0.5, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping1 = {'orig': -1, 'rewr': 1, 'equal': 0}\n",
    "y1_equal_05 = df['orig/rewr/equal 0.5'].map(mapping1)\n",
    "y1_equal_05.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "deb2d1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1\n",
       "1   -1\n",
       "2   -1\n",
       "3    0\n",
       "4    0\n",
       "Name: orig/rewr/equal 0.1, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping1 = {'orig': -1, 'rewr': 1, 'equal': 0}\n",
    "y1_equal_01 = df['orig/rewr/equal 0.1'].map(mapping1)\n",
    "y1_equal_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f46f329-1b16-4eaf-b4ca-9de8397ebe6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1\n",
       "1   -1\n",
       "2   -1\n",
       "3   -1\n",
       "4   -1\n",
       "Name: orig/rewr/equal 0.05, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping1 = {'orig': -1, 'rewr': 1, 'equal': 0}\n",
    "y1_equal_005 = df['orig/rewr/equal 0.05'].map(mapping1)\n",
    "y1_equal_005.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83649da4-7654-401d-9ad7-531bf0131699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1\n",
       "1   -1\n",
       "2   -1\n",
       "3   -1\n",
       "4   -1\n",
       "Name: orig/rewr/equal 0.01, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping1 = {'orig': -1, 'rewr': 1, 'equal': 0}\n",
    "y1_equal_001 = df['orig/rewr/equal 0.01'].map(mapping1)\n",
    "y1_equal_001.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f36e3c7-f02a-4839-a2c1-44ef230fca30",
   "metadata": {},
   "source": [
    "#### Regression response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3500e7-c23e-4260-91de-28f12692ccce",
   "metadata": {},
   "source": [
    "We also have the time differences between the original and rewritten method and we want to use that as numerical response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67b9da20-d496-465e-8908-e33912027a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_diff = df[\"diff rewr-orig\"]\n",
    "#y1_diff = df[\"diff rewr+rewr-orig\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1956a25f-ceda-4e69-8f6e-8a237c02bb0a",
   "metadata": {},
   "source": [
    "We can see that the time difference has a wide range of values (or is skewed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea0abb17-d02c-471b-b167-4ddcc396abfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y1_diff.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d418aa-e1e5-47d6-a903-c1a83f9667d0",
   "metadata": {},
   "source": [
    "Therefore, we are going to transform it. As before with the features, we would like to apply a log transformation. Neverthless, since we have negative values this cannot be applied directly. We are going to multiple to log of the absolute values with the sign they had before. Additionally, since we have a lot of values close to zero, which leads to very low log values, we add 1 to the absolute values, which is a common method.   \n",
    "$x = sgn(x) * log(|x| + 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88002661-c5ff-4368-8bcb-d256457b72ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y1_diff_log = np.sign(y1_diff) * np.log(abs(y1_diff) +1)\n",
    "y1_diff_log.hist(bins = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc35a4c8-f8ce-49ce-bdcc-6911a920c5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axs[0].hist(y1_diff, bins=40, edgecolor='black')\n",
    "axs[0].set_title('Histogram of time differences')\n",
    "axs[0].set_ylabel(\"count\")\n",
    "axs[0].set_xlabel(\"diff = rewritten - original runtime\")\n",
    "\n",
    "# Create the second histogram\n",
    "y1_diff_log = np.sign(y1_diff) * np.log(abs(y1_diff) + 1)\n",
    "axs[1].hist(y1_diff_log, bins=40, edgecolor='black')\n",
    "axs[1].set_title('Histogram of transformed time differences')\n",
    "axs[1].set_ylabel(\"count\")\n",
    "axs[1].set_xlabel(\"sgn(diff)*log(|diff| + 1)\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c889d62-8988-4035-bc5d-e0848b0d2419",
   "metadata": {},
   "source": [
    "#### Train-validation-test split\n",
    "\n",
    "We split the dataset such that each benchmark dataset is represented in the train and in the test set (stratification). We do a 80% train, 10% validation and 10% test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b1cd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, stratify=df[\"bench\"], random_state=20)\n",
    "X_val, X_test, y1_val, y1_test = train_test_split(X_test, y1_test, test_size=0.5, stratify=df.loc[X_test.index][\"bench\"], random_state=20)\n",
    "X_train_hg = X_hg.loc[X_train.index]\n",
    "X_val_hg = X_hg.loc[X_val.index]\n",
    "X_test_hg = X_hg.loc[X_test.index]\n",
    "y1_diff_log_train = y1_diff_log.loc[y1_train.index]\n",
    "y1_diff_log_val = y1_diff_log.loc[y1_val.index]\n",
    "y1_diff_log_test = y1_diff_log.loc[y1_test.index]\n",
    "y1_equal_05_train = y1_equal_05.loc[y1_train.index]\n",
    "y1_equal_05_val = y1_equal_05.loc[y1_val.index]\n",
    "y1_equal_05_test = y1_equal_05.loc[y1_test.index]\n",
    "y1_equal_01_train = y1_equal_01.loc[y1_train.index]\n",
    "y1_equal_01_val = y1_equal_01.loc[y1_val.index]\n",
    "y1_equal_01_test = y1_equal_01.loc[y1_test.index]\n",
    "y1_equal_005_train = y1_equal_005.loc[y1_train.index]\n",
    "y1_equal_005_val = y1_equal_005.loc[y1_val.index]\n",
    "y1_equal_005_test = y1_equal_005.loc[y1_test.index]\n",
    "y1_equal_001_train = y1_equal_001.loc[y1_train.index]\n",
    "y1_equal_001_val = y1_equal_001.loc[y1_val.index]\n",
    "y1_equal_001_test = y1_equal_001.loc[y1_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c648a4-e43a-45f6-a56a-df0480393a06",
   "metadata": {},
   "source": [
    "#### Cross-validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66407e3d-f2dd-42f7-9edb-86e5df40b921",
   "metadata": {},
   "source": [
    "We take the same 10% as test set and use the rest for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1284040-9bee-418d-8553-00b841f28694",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv = pd.concat([X_train, X_val], axis = 0)\n",
    "y1_train_cv = pd.concat([y1_train, y1_val], axis = 0)\n",
    "y1_diff_log_train_cv = pd.concat([y1_diff_log_train, y1_diff_log_val], axis = 0)\n",
    "y1_equal_05_train_cv = pd.concat([y1_equal_05_train, y1_equal_05_val], axis = 0)\n",
    "y1_equal_01_train_cv = pd.concat([y1_equal_01_train, y1_equal_01_val], axis = 0)\n",
    "y1_equal_005_train_cv = pd.concat([y1_equal_005_train, y1_equal_005_val], axis = 0)\n",
    "y1_equal_001_train_cv = pd.concat([y1_equal_001_train, y1_equal_001_val], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "853188f6-6726-423c-b2e1-e77c6a0b8090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5845552127457475\n",
      "0.39209779798784195\n",
      "0.8171307829779844\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state = 20)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_dec_tree_reg = model.predict(X_val)\n",
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_dec_tree_reg)\n",
    "print(mse)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_dec_tree_reg)\n",
    "print(mae)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_dec_tree_reg)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f99b0cf-2a50-4c77-8c19-a31be418fca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7952218430034129\n",
      "0.6824324324324325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[132,  13],\n",
       "       [ 47, 101]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred_dec_tree_class = (y1_pred_dec_tree_reg < np.sign(-0.5)*np.log(abs(-0.5)+1)).astype(int)\n",
    "accuracy = accuracy_score(y1_val, y1_pred_dec_tree_class)\n",
    "print(accuracy)\n",
    "recall = recall_score(y1_val, y1_pred_dec_tree_class)\n",
    "print(recall)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_dec_tree_class)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6746696-b091-46c2-b19d-3fc2a9c05d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7952218430034129\n",
      "0.6824324324324325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[132,  13],\n",
       "       [ 47, 101]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred_dec_tree_class = (y1_pred_dec_tree_reg < np.sign(-0.5)*np.log(abs(-0.5)+1)).astype(int)\n",
    "accuracy = accuracy_score(y1_val, y1_pred_dec_tree_class)\n",
    "print(accuracy)\n",
    "recall = recall_score(y1_val, y1_pred_dec_tree_class)\n",
    "print(recall)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_dec_tree_class)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1671a922-0320-4283-b3ae-abd069f0024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8464163822525598\n",
      "0.8378378378378378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[124,  21],\n",
       "       [ 24, 124]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred_dec_tree_class = (y1_pred_dec_tree_reg < np.sign(-0.1)*np.log(abs(-0.1)+1)).astype(int)\n",
    "accuracy = accuracy_score(y1_val, y1_pred_dec_tree_class)\n",
    "print(accuracy)\n",
    "recall = recall_score(y1_val, y1_pred_dec_tree_class)\n",
    "print(recall)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_dec_tree_class)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c447d54-2e48-47da-af1c-2c578a627db8",
   "metadata": {},
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "008e826a-c25c-419c-bf68-ed3c4a85c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2_classes = pd.DataFrame(columns=['acc', 'rec', 'acc', 'rec'])\n",
    "table_3_classes = pd.DataFrame(columns=['acc', 'rec-mic', 'rec_mac', 'acc', 'rec-mic', 'rec-mac'])\n",
    "table_time_diff = pd.DataFrame(columns=['MSE', 'MAE', 'R2', 'MSE', 'MAE', 'R2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95a2a9",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors with two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f047a-d888-48e8-9a39-44e31a51892f",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "549c3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_knn = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfb81a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[121,  24],\n",
       "       [ 26, 122]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_knn)\n",
    "recall = recall_score(y1_val, y1_pred_knn)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_knn)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fe0b7-d2ec-4e4f-8af2-b95ebd54bcb3",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb8232b4-8aa7-4bb2-90b9-e45449fae536",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_knn_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b78ec316-4464-4854-9034-44543fb90508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1035,  272],\n",
       "       [ 254, 1079]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_knn_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_knn_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_knn_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3557599-f1ae-4b81-9a45-3eb34f8c7dc6",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6920f54d-d596-43e2-9d37-fc442b5458e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.800758</td>\n",
       "      <td>0.809452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc       rec       acc       rec\n",
       "5-NN  0.829352  0.824324  0.800758  0.809452"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"5-NN\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50994022",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors with three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb561e-b438-467b-b835-3e22595e39b0",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e539db7e-1f89-475d-ab27-f7a05e749182",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e525178e-dd05-40b8-9e5d-bd0f5cd795f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_knn = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d25216c6-910f-43d1-9dae-66a2f5484894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8,   3,   1],\n",
       "       [  1, 166,  14],\n",
       "       [  0,  21,  79]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_knn)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_knn, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_knn, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_knn)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd6634b-080b-43b5-9ed7-de8dd80463a1",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5e345c7-419f-4130-a3f1-2da1b90603ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_knn_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2858828-5522-499c-8575-2203842855aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  70,   19,    7],\n",
       "       [  26, 1449,  144],\n",
       "       [   8,  206,  711]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_knn_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_knn_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_knn_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_knn_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb769a-9ca3-4865-b3f0-6046a953d658",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03e253cd-99bd-4fe6-a558-85aad20cf030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5  0.863481  0.863481  0.791265  0.844697  0.844697  0.797604"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"5-NN 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a35d4-d8c3-4d19-a149-46cd16a107b4",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b7eb4d-8762-4016-a910-abc63b8d451f",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ce1349f-788d-41f5-9039-385dd7a7c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_knn = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0aecff0-c1b5-40d1-af2d-64bf9aae5b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 41,  22,   7],\n",
       "       [ 17,  70,  16],\n",
       "       [  7,  11, 102]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_knn)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_knn, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_knn, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_knn)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7feaf-bdab-44bf-a3fd-d30e2b25457d",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "873cdaf4-8c75-48fc-a0f7-3b1e44b4c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_knn_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8de27d3b-b9e9-4b04-9f0a-927bc269331e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[415, 163,  77],\n",
       "       [131, 576, 148],\n",
       "       [ 75, 133, 922]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_knn_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_knn_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_knn_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_knn_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab7287-3f3f-4b98-a173-913e5b286bf7",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36670193-8560-4def-a17e-a0f8e3bf4b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5  0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1  0.726962  0.726962  0.705109  0.724621  0.724621  0.707734"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"5-NN 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11a8dba-0c77-4f31-86ca-1093dbdd350e",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c064be4-8289-4d63-a029-399f8586d992",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f18dfad5-9d52-4bec-93ff-d450c86cd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_knn = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36ec92c7-2d00-4465-96c9-18b69e2ca7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91,  12,  16],\n",
       "       [ 21,  14,  10],\n",
       "       [ 11,   5, 113]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_knn)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_knn, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_knn, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_knn)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7374c-64de-41bf-8033-2b4fc06b8009",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8a4cb63-aeab-4740-b7da-4c99f8900831",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_knn_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59214179-d93d-4271-b7e3-2313714f78d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[799,  88, 149],\n",
       "       [159, 133, 102],\n",
       "       [171,  43, 996]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_knn_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_knn_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_knn_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_knn_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755e11e-0c73-4e24-8f0e-69d5fde1f0d5",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1e57d9c-cdd6-492f-a67e-e2112d125860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5   0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1   0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05  0.744027  0.744027  0.650595  0.730303  0.730303  0.643980"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"5-NN 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b955cd1-efd4-4df6-a887-e4672718fdc1",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15394473-e9d1-48b9-94d3-f79c01dbceb0",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef690209-d337-4d82-8ac0-7aea96ee3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_knn = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "663cdbc8-d71c-4539-99b6-160910866125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120,   0,  22],\n",
       "       [  7,   0,   2],\n",
       "       [ 20,   0, 122]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_knn)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_knn, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_knn, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_knn)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21829c-5744-4fbc-84fe-95ea6132340b",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2e6757f-946e-4612-b125-abb8859bbb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_knn_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "771d2e3c-85ce-479a-8dc1-26137d9c9d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1028,    0,  247],\n",
       "       [  35,    0,   32],\n",
       "       [ 241,    3, 1054]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_knn_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_knn_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_knn_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_knn_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a1ba4-8715-491b-a259-f40d960145ec",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1bee0255-a527-4249-b44d-fdc3a56e3cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5   0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1   0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05  0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01  0.825939  0.825939  0.568075  0.788636  0.788636  0.539431"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"5-NN 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd9f80-53b6-4095-bcbc-51530dcb4f4c",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors with time difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6bd5f-3193-46da-9ec9-6627643c6300",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "402c0739-ac3f-402a-8388-623cab859950",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_knn = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf455b8e-c6e1-4446-ae9a-7179cb7df189",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_knn)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_knn)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7148db38-5f2e-49ea-93df-ec53366bd921",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "810e4e11-28e1-408b-a794-8a8d3a75393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_knn_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b7cbd17-354c-4f13-ab49-ee9357782d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_knn_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_knn_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_knn_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787fd7b-79e8-410a-8478-dc8c70956709",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "890f3948-906c-4730-ab96-fc7c07eee05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.789418</td>\n",
       "      <td>0.730049</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN  0.673141  0.442646  0.789418  0.730049  0.478475  0.757785"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"5-NN\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69224a",
   "metadata": {},
   "source": [
    "### Decision tree with two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedbfff2",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21c7c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e8f88c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,  18],\n",
       "       [ 30, 118]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_dec_tree)\n",
    "recall = recall_score(y1_val, y1_pred_dec_tree)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1ed32",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6d11479",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_dec_tree_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "decd8e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1060,  247],\n",
       "       [ 243, 1090]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_dec_tree_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_dec_tree_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_dec_tree_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e41d8",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9895b035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.800758</td>\n",
       "      <td>0.809452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>0.817704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec       acc       rec\n",
       "5-NN           0.829352  0.824324  0.800758  0.809452\n",
       "Decision tree  0.836177  0.797297  0.814394  0.817704"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"Decision tree\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52c066f",
   "metadata": {},
   "source": [
    "### Decision tree with three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f076d0",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e96e2a0",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8da0f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67fda59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11,   0,   1],\n",
       "       [  0, 173,   8],\n",
       "       [  0,  23,  77]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a3636",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd58b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_dec_tree_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6fb22ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  74,   15,    7],\n",
       "       [  15, 1479,  125],\n",
       "       [   0,  196,  729]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_dec_tree_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_dec_tree_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_dec_tree_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_dec_tree_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5effedd",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0db9ddb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5           0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1           0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05          0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01          0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5  0.890785  0.890785  0.880823  0.864394  0.864394  0.824156"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Decision tree 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6473a751",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54970263",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce33a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "69ceb943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 47,  17,   6],\n",
       "       [ 18,  70,  15],\n",
       "       [  3,  10, 107]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b4d29f",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "261f97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_dec_tree_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bf4d3099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[426, 136,  93],\n",
       "       [145, 561, 149],\n",
       "       [ 58, 133, 939]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_dec_tree_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_dec_tree_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_dec_tree_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_dec_tree_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b291c",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f4946d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5           0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1           0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05          0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01          0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5  0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1  0.764505  0.764505  0.747569  0.729545  0.729545  0.712498"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Decision tree 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084a60a",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff152136",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "80cd9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ad05202a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99,   8,  12],\n",
       "       [ 23,  14,   8],\n",
       "       [ 11,   2, 116]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb17d3f0",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e9cf6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_dec_tree_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f3e7d46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 796,   73,  167],\n",
       "       [ 152,  129,  113],\n",
       "       [ 144,   32, 1034]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_dec_tree_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_dec_tree_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_dec_tree_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_dec_tree_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49849f3",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "af035c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Decision tree 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa462d",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c4484",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0bf5d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b72adefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125,   0,  17],\n",
       "       [  8,   0,   1],\n",
       "       [ 24,   0, 118]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58082cb",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ba9fad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_dec_tree_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "789681b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1041,    3,  231],\n",
       "       [  32,    4,   31],\n",
       "       [ 225,    3, 1070]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_dec_tree_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_dec_tree_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_dec_tree_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_dec_tree_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2608ed3",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8dd861b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Decision tree 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de38015",
   "metadata": {},
   "source": [
    "### Decision tree with time difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f05b04",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "27a24832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(random_state = 20)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_dec_tree = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6cfcd96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_dec_tree)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_dec_tree)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_dec_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f0890",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1eaa6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_dec_tree_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7fa3e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_dec_tree_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_dec_tree_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_dec_tree_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e75ea",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b05c814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.789418</td>\n",
       "      <td>0.730049</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.579022</td>\n",
       "      <td>0.390659</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>0.612816</td>\n",
       "      <td>0.433778</td>\n",
       "      <td>0.796680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN           0.673141  0.442646  0.789418  0.730049  0.478475  0.757785\n",
       "Decision tree  0.579022  0.390659  0.818862  0.612816  0.433778  0.796680"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"Decision tree\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf012823",
   "metadata": {},
   "source": [
    "### Random forest with two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e7ee1",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "43d8499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_rand_forest = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fe578b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[121,  24],\n",
       "       [ 25, 123]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_rand_forest)\n",
    "recall = recall_score(y1_val, y1_pred_rand_forest)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_rand_forest)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c685a0",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "44180d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_rand_forest_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1d82834b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1035,  272],\n",
       "       [ 222, 1111]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_rand_forest_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_rand_forest_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_rand_forest_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1878260",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "023ddc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.800758</td>\n",
       "      <td>0.809452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>0.817704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.812879</td>\n",
       "      <td>0.833458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec       acc       rec\n",
       "5-NN           0.829352  0.824324  0.800758  0.809452\n",
       "Decision tree  0.836177  0.797297  0.814394  0.817704\n",
       "Random forest  0.832765  0.831081  0.812879  0.833458"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"Random forest\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd1964",
   "metadata": {},
   "source": [
    "### Random forest with three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb244462",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f3cb44",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7747758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_rand_forest = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4772f656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11,   0,   1],\n",
       "       [  0, 172,   9],\n",
       "       [  0,  22,  78]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_rand_forest)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6d899",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b3fe8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_rand_forest_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e70993ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  73,   16,    7],\n",
       "       [  14, 1469,  136],\n",
       "       [   0,  177,  748]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_rand_forest_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_rand_forest_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_rand_forest_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_rand_forest_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9317f",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aba63737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Random forest 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bda627",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c60d4d",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "15f0f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_rand_forest = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "96bac3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 42,  22,   6],\n",
       "       [ 13,  71,  19],\n",
       "       [  3,   6, 111]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_rand_forest)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd8d848",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e392246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_rand_forest_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8053740c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[403, 157,  95],\n",
       "       [112, 578, 165],\n",
       "       [ 52, 114, 964]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_rand_forest_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_rand_forest_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_rand_forest_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_rand_forest_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695bd14c",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f2ed5d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Random forest 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40de7fa",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f22a80",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "03a894d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_rand_forest = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "33f64bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 96,   9,  14],\n",
       "       [ 19,  17,   9],\n",
       "       [ 10,   2, 117]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_rand_forest)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0257dd",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "05f0841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_rand_forest_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "93919c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 767,   84,  185],\n",
       "       [ 139,  141,  114],\n",
       "       [ 125,   31, 1054]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_rand_forest_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_rand_forest_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_rand_forest_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_rand_forest_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae7e38",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "06f21a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Random forest 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89574b2f",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1c58c",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6129267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_rand_forest = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d01209d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,   0,  23],\n",
       "       [  7,   0,   2],\n",
       "       [ 20,   0, 122]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_rand_forest)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106a24e",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "06f48990",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_rand_forest_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9050b8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1011,    5,  259],\n",
       "       [  28,    2,   37],\n",
       "       [ 206,    1, 1091]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_rand_forest_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_rand_forest_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_rand_forest_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_rand_forest_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac611a5",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3c62c35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Random forest 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa7cbd",
   "metadata": {},
   "source": [
    "### Random forest with time difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c32b59",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8f10dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=20)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_rand_forest = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "47796c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_rand_forest)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_rand_forest)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_rand_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076c87e",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "02da296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_rand_forest_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "77d813d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_rand_forest_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_rand_forest_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_rand_forest_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b18c80",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6f8f98ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.789418</td>\n",
       "      <td>0.730049</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.579022</td>\n",
       "      <td>0.390659</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>0.612816</td>\n",
       "      <td>0.433778</td>\n",
       "      <td>0.796680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.584555</td>\n",
       "      <td>0.392098</td>\n",
       "      <td>0.817131</td>\n",
       "      <td>0.613710</td>\n",
       "      <td>0.435071</td>\n",
       "      <td>0.796384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN           0.673141  0.442646  0.789418  0.730049  0.478475  0.757785\n",
       "Decision tree  0.579022  0.390659  0.818862  0.612816  0.433778  0.796680\n",
       "Random forest  0.584555  0.392098  0.817131  0.613710  0.435071  0.796384"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"Random forest\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df977162",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine) with two classes, linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae0792",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6061e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "515ee3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124,  21],\n",
       "       [ 73,  75]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_svm_linear)\n",
    "recall = recall_score(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499c898",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "73a8fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4dd37701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1066,  241],\n",
       "       [ 593,  740]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8d45b4",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5bd51ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.800758</td>\n",
       "      <td>0.809452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>0.817704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.812879</td>\n",
       "      <td>0.833458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.679181</td>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.684091</td>\n",
       "      <td>0.555139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec       acc       rec\n",
       "5-NN           0.829352  0.824324  0.800758  0.809452\n",
       "Decision tree  0.836177  0.797297  0.814394  0.817704\n",
       "Random forest  0.832765  0.831081  0.812879  0.833458\n",
       "SVM linear     0.679181  0.506757  0.684091  0.555139"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"SVM linear\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac95aca3",
   "metadata": {},
   "source": [
    "### SVM with three classes, linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec8d115",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0bb07",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "036a1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e568c9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7,   4,   1],\n",
       "       [  0, 173,   8],\n",
       "       [  0,  49,  51]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596a5660",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "af042cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d8310d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  61,   25,   10],\n",
       "       [  11, 1528,   80],\n",
       "       [   1,  491,  433]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde943a",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b5d415e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM linear 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c10d737",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c7b463",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "476b5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ca871091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 28, 14],\n",
       "       [15, 61, 27],\n",
       "       [10, 30, 80]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625e00e",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cc161cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d845f896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[241, 248, 166],\n",
       "       [ 84, 490, 281],\n",
       "       [ 97, 304, 729]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22d23c",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a582c918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.528724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439\n",
       "SVM linear 0.1      0.576792  0.576792  0.552967  0.553030  0.553030  0.528724"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM linear 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d9566",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7b781",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "51611518",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c265e101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95,  0, 24],\n",
       "       [26,  0, 19],\n",
       "       [45,  0, 84]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b1b29",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "46cdfdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d92aa701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[777,   0, 259],\n",
       "       [249,   0, 145],\n",
       "       [423,   0, 787]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af38c11",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7b0028b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.528724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439\n",
       "SVM linear 0.1      0.576792  0.576792  0.552967  0.553030  0.553030  0.528724\n",
       "SVM linear 0.05     0.610922  0.610922  0.483161  0.592424  0.592424  0.466804"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM linear 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae534cf",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d71a1b",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "52e7615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e26bab46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,   0,  23],\n",
       "       [  5,   0,   4],\n",
       "       [ 63,   0,  79]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ac34c",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d95d652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6c0f56ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1040,    0,  235],\n",
       "       [  34,    0,   33],\n",
       "       [ 547,    0,  751]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294b1f3",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "073f136d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.528724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.464756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439\n",
       "SVM linear 0.1      0.576792  0.576792  0.552967  0.553030  0.553030  0.528724\n",
       "SVM linear 0.05     0.610922  0.610922  0.483161  0.592424  0.592424  0.466804\n",
       "SVM linear 0.01     0.675768  0.675768  0.464789  0.678409  0.678409  0.464756"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM linear 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ada10",
   "metadata": {},
   "source": [
    "### SVM with time difference, linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef859e",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7a457dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR(kernel='linear')\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_svm_linear = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "63c02e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_svm_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f718d5c",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "12b7e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7f044b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_svm_linear_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676d5cf",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bb9d28d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.789418</td>\n",
       "      <td>0.730049</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.579022</td>\n",
       "      <td>0.390659</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>0.612816</td>\n",
       "      <td>0.433778</td>\n",
       "      <td>0.796680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.584555</td>\n",
       "      <td>0.392098</td>\n",
       "      <td>0.817131</td>\n",
       "      <td>0.613710</td>\n",
       "      <td>0.435071</td>\n",
       "      <td>0.796384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>2.323296</td>\n",
       "      <td>0.907326</td>\n",
       "      <td>0.273192</td>\n",
       "      <td>2.371142</td>\n",
       "      <td>0.929039</td>\n",
       "      <td>0.213305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN           0.673141  0.442646  0.789418  0.730049  0.478475  0.757785\n",
       "Decision tree  0.579022  0.390659  0.818862  0.612816  0.433778  0.796680\n",
       "Random forest  0.584555  0.392098  0.817131  0.613710  0.435071  0.796384\n",
       "SVM linear     2.323296  0.907326  0.273192  2.371142  0.929039  0.213305"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"SVM linear\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e330f9",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine) with two classes, polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee9ccdc",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cb542248",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a0072fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125,  20],\n",
       "       [ 69,  79]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_svm_linear)\n",
    "recall = recall_score(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5856416b",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fe010f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7139f422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1115,  192],\n",
       "       [ 561,  772]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08a8fc",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f84369a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.800758</td>\n",
       "      <td>0.809452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>0.817704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.812879</td>\n",
       "      <td>0.833458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.679181</td>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.684091</td>\n",
       "      <td>0.555139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.533784</td>\n",
       "      <td>0.714773</td>\n",
       "      <td>0.579145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec       acc       rec\n",
       "5-NN           0.829352  0.824324  0.800758  0.809452\n",
       "Decision tree  0.836177  0.797297  0.814394  0.817704\n",
       "Random forest  0.832765  0.831081  0.812879  0.833458\n",
       "SVM linear     0.679181  0.506757  0.684091  0.555139\n",
       "SVM poly       0.696246  0.533784  0.714773  0.579145"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"SVM poly\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49f5851",
   "metadata": {},
   "source": [
    "### SVM with three classes, polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a89846",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683caca",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6c62a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "17cee68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7,   4,   1],\n",
       "       [  0, 178,   3],\n",
       "       [  0,  52,  48]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b8e00",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "21902402",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8967d924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  54,   36,    6],\n",
       "       [   0, 1587,   32],\n",
       "       [   0,  526,  399]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae0b85",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "af6ceabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.528724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.464756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.682253</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.658029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439\n",
       "SVM linear 0.1      0.576792  0.576792  0.552967  0.553030  0.553030  0.528724\n",
       "SVM linear 0.05     0.610922  0.610922  0.483161  0.592424  0.592424  0.466804\n",
       "SVM linear 0.01     0.675768  0.675768  0.464789  0.678409  0.678409  0.464756\n",
       "SVM poly 0.5        0.795222  0.795222  0.682253  0.772727  0.772727  0.658029"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM poly 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e108394",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e5147",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8d13ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "35814096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24, 33, 13],\n",
       "       [10, 64, 29],\n",
       "       [ 1, 31, 88]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060482c8",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e12d60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "72484821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[249, 267, 139],\n",
       "       [ 75, 511, 269],\n",
       "       [ 33, 295, 802]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e8d34",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1e249e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.528724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.464756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.682253</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.658029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.565850</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.562516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439\n",
       "SVM linear 0.1      0.576792  0.576792  0.552967  0.553030  0.553030  0.528724\n",
       "SVM linear 0.05     0.610922  0.610922  0.483161  0.592424  0.592424  0.466804\n",
       "SVM linear 0.01     0.675768  0.675768  0.464789  0.678409  0.678409  0.464756\n",
       "SVM poly 0.5        0.795222  0.795222  0.682253  0.772727  0.772727  0.658029\n",
       "SVM poly 0.1        0.600683  0.600683  0.565850  0.591667  0.591667  0.562516"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM poly 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b65de",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d1381",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1a98c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f5200b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93,  0, 26],\n",
       "       [28,  0, 17],\n",
       "       [31,  0, 98]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13ac6c",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "54bc1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3cfd77ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[812,   0, 224],\n",
       "       [233,   0, 161],\n",
       "       [377,   0, 833]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004318f1",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6c449f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.528724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.464756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.682253</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.658029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.565850</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.562516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.513734</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.490738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439\n",
       "SVM linear 0.1      0.576792  0.576792  0.552967  0.553030  0.553030  0.528724\n",
       "SVM linear 0.05     0.610922  0.610922  0.483161  0.592424  0.592424  0.466804\n",
       "SVM linear 0.01     0.675768  0.675768  0.464789  0.678409  0.678409  0.464756\n",
       "SVM poly 0.5        0.795222  0.795222  0.682253  0.772727  0.772727  0.658029\n",
       "SVM poly 0.1        0.600683  0.600683  0.565850  0.591667  0.591667  0.562516\n",
       "SVM poly 0.05       0.651877  0.651877  0.513734  0.623106  0.623106  0.490738"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM poly 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a5b968",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75471ae4",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "81555e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "28f053b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[123,   0,  19],\n",
       "       [  7,   0,   2],\n",
       "       [ 62,   0,  80]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e525fc2",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "08a8b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "36cdb9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1083,    0,  192],\n",
       "       [  41,    0,   26],\n",
       "       [ 518,    0,  780]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758fa1d",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bc10466d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.528724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.464756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.682253</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.658029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.565850</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.562516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.513734</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.490738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.476526</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>0.483445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439\n",
       "SVM linear 0.1      0.576792  0.576792  0.552967  0.553030  0.553030  0.528724\n",
       "SVM linear 0.05     0.610922  0.610922  0.483161  0.592424  0.592424  0.466804\n",
       "SVM linear 0.01     0.675768  0.675768  0.464789  0.678409  0.678409  0.464756\n",
       "SVM poly 0.5        0.795222  0.795222  0.682253  0.772727  0.772727  0.658029\n",
       "SVM poly 0.1        0.600683  0.600683  0.565850  0.591667  0.591667  0.562516\n",
       "SVM poly 0.05       0.651877  0.651877  0.513734  0.623106  0.623106  0.490738\n",
       "SVM poly 0.01       0.692833  0.692833  0.476526  0.705682  0.705682  0.483445"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM poly 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2937d580",
   "metadata": {},
   "source": [
    "### SVM with time difference, polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb681d91",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "86beae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR(kernel='poly')\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_svm_linear = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c2d344dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_svm_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f206e",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7b0ad86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0462dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_svm_linear_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2786a",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4fdd9672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.789418</td>\n",
       "      <td>0.730049</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.579022</td>\n",
       "      <td>0.390659</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>0.612816</td>\n",
       "      <td>0.433778</td>\n",
       "      <td>0.796680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.584555</td>\n",
       "      <td>0.392098</td>\n",
       "      <td>0.817131</td>\n",
       "      <td>0.613710</td>\n",
       "      <td>0.435071</td>\n",
       "      <td>0.796384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>2.323296</td>\n",
       "      <td>0.907326</td>\n",
       "      <td>0.273192</td>\n",
       "      <td>2.371142</td>\n",
       "      <td>0.929039</td>\n",
       "      <td>0.213305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.778288</td>\n",
       "      <td>0.719919</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>1.815210</td>\n",
       "      <td>0.749433</td>\n",
       "      <td>0.397751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN           0.673141  0.442646  0.789418  0.730049  0.478475  0.757785\n",
       "Decision tree  0.579022  0.390659  0.818862  0.612816  0.433778  0.796680\n",
       "Random forest  0.584555  0.392098  0.817131  0.613710  0.435071  0.796384\n",
       "SVM linear     2.323296  0.907326  0.273192  2.371142  0.929039  0.213305\n",
       "SVM poly       1.778288  0.719919  0.443690  1.815210  0.749433  0.397751"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"SVM poly\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc26c83",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine) with two classes, rbf kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e2590",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4ed81170",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8a95296b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133,  12],\n",
       "       [ 72,  76]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_svm_linear)\n",
    "recall = recall_score(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd8a06b",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5503f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7ecfaec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1175,  132],\n",
       "       [ 632,  701]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84bf4a6",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8a451a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.800758</td>\n",
       "      <td>0.809452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>0.817704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.812879</td>\n",
       "      <td>0.833458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.679181</td>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.684091</td>\n",
       "      <td>0.555139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.533784</td>\n",
       "      <td>0.714773</td>\n",
       "      <td>0.579145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.710606</td>\n",
       "      <td>0.525881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec       acc       rec\n",
       "5-NN           0.829352  0.824324  0.800758  0.809452\n",
       "Decision tree  0.836177  0.797297  0.814394  0.817704\n",
       "Random forest  0.832765  0.831081  0.812879  0.833458\n",
       "SVM linear     0.679181  0.506757  0.684091  0.555139\n",
       "SVM poly       0.696246  0.533784  0.714773  0.579145\n",
       "SVM rbf        0.713311  0.513514  0.710606  0.525881"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"SVM rbf\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece3011",
   "metadata": {},
   "source": [
    "### SVM with three classes, rbf kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11581960",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb5551f",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "69d516c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e76a46dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7,   4,   1],\n",
       "       [  0, 170,  11],\n",
       "       [  0,  43,  57]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75d156",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a3a7ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6671733a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  54,   36,    6],\n",
       "       [   0, 1476,  143],\n",
       "       [   0,  422,  503]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628896f8",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e35b66f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.528724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.464756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.682253</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.658029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.565850</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.562516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.513734</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.490738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.476526</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>0.483445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.5</th>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.697520</td>\n",
       "      <td>0.770076</td>\n",
       "      <td>0.770076</td>\n",
       "      <td>0.672653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439\n",
       "SVM linear 0.1      0.576792  0.576792  0.552967  0.553030  0.553030  0.528724\n",
       "SVM linear 0.05     0.610922  0.610922  0.483161  0.592424  0.592424  0.466804\n",
       "SVM linear 0.01     0.675768  0.675768  0.464789  0.678409  0.678409  0.464756\n",
       "SVM poly 0.5        0.795222  0.795222  0.682253  0.772727  0.772727  0.658029\n",
       "SVM poly 0.1        0.600683  0.600683  0.565850  0.591667  0.591667  0.562516\n",
       "SVM poly 0.05       0.651877  0.651877  0.513734  0.623106  0.623106  0.490738\n",
       "SVM poly 0.01       0.692833  0.692833  0.476526  0.705682  0.705682  0.483445\n",
       "SVM rbf 0.5         0.798635  0.798635  0.697520  0.770076  0.770076  0.672653"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM rbf 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f081aea",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ae28c",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "113c5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a2118c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25, 34, 11],\n",
       "       [ 9, 69, 25],\n",
       "       [ 2, 27, 91]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bcb3ef",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "dbece742",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "366e57e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[258, 296, 101],\n",
       "       [ 78, 571, 206],\n",
       "       [ 41, 334, 755]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74095c",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "97fb29ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.528724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.464756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.682253</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.658029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.565850</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.562516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.513734</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.490738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.476526</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>0.483445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.5</th>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.697520</td>\n",
       "      <td>0.770076</td>\n",
       "      <td>0.770076</td>\n",
       "      <td>0.672653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.1</th>\n",
       "      <td>0.631399</td>\n",
       "      <td>0.631399</td>\n",
       "      <td>0.595126</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.576624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439\n",
       "SVM linear 0.1      0.576792  0.576792  0.552967  0.553030  0.553030  0.528724\n",
       "SVM linear 0.05     0.610922  0.610922  0.483161  0.592424  0.592424  0.466804\n",
       "SVM linear 0.01     0.675768  0.675768  0.464789  0.678409  0.678409  0.464756\n",
       "SVM poly 0.5        0.795222  0.795222  0.682253  0.772727  0.772727  0.658029\n",
       "SVM poly 0.1        0.600683  0.600683  0.565850  0.591667  0.591667  0.562516\n",
       "SVM poly 0.05       0.651877  0.651877  0.513734  0.623106  0.623106  0.490738\n",
       "SVM poly 0.01       0.692833  0.692833  0.476526  0.705682  0.705682  0.483445\n",
       "SVM rbf 0.5         0.798635  0.798635  0.697520  0.770076  0.770076  0.672653\n",
       "SVM rbf 0.1         0.631399  0.631399  0.595126  0.600000  0.600000  0.576624"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM rbf 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753595c",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb38aba",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "66ca6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f448b2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[108,   1,  10],\n",
       "       [ 31,   1,  13],\n",
       "       [ 54,   0,  75]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd550db",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cc9a335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c49d3cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[915,   2, 119],\n",
       "       [264,  16, 114],\n",
       "       [516,   1, 693]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d8bdf",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ab8b349c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.528724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.464756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.682253</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.658029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.565850</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.562516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.513734</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.490738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.476526</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>0.483445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.5</th>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.697520</td>\n",
       "      <td>0.770076</td>\n",
       "      <td>0.770076</td>\n",
       "      <td>0.672653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.1</th>\n",
       "      <td>0.631399</td>\n",
       "      <td>0.631399</td>\n",
       "      <td>0.595126</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.576624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.05</th>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.503727</td>\n",
       "      <td>0.615152</td>\n",
       "      <td>0.615152</td>\n",
       "      <td>0.498847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439\n",
       "SVM linear 0.1      0.576792  0.576792  0.552967  0.553030  0.553030  0.528724\n",
       "SVM linear 0.05     0.610922  0.610922  0.483161  0.592424  0.592424  0.466804\n",
       "SVM linear 0.01     0.675768  0.675768  0.464789  0.678409  0.678409  0.464756\n",
       "SVM poly 0.5        0.795222  0.795222  0.682253  0.772727  0.772727  0.658029\n",
       "SVM poly 0.1        0.600683  0.600683  0.565850  0.591667  0.591667  0.562516\n",
       "SVM poly 0.05       0.651877  0.651877  0.513734  0.623106  0.623106  0.490738\n",
       "SVM poly 0.01       0.692833  0.692833  0.476526  0.705682  0.705682  0.483445\n",
       "SVM rbf 0.5         0.798635  0.798635  0.697520  0.770076  0.770076  0.672653\n",
       "SVM rbf 0.1         0.631399  0.631399  0.595126  0.600000  0.600000  0.576624\n",
       "SVM rbf 0.05        0.627986  0.627986  0.503727  0.615152  0.615152  0.498847"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM rbf 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04453aa",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d94eda2",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "317cc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "581c6c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[131,   0,  11],\n",
       "       [  7,   0,   2],\n",
       "       [ 67,   0,  75]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c9ef36",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a72a400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "bca61f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1157,    0,  118],\n",
       "       [  43,    0,   24],\n",
       "       [ 602,    0,  696]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64edf7cd",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6a49411c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.863481</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.797604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.724621</td>\n",
       "      <td>0.707734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.643980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.825939</td>\n",
       "      <td>0.568075</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.539431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.880823</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.864394</td>\n",
       "      <td>0.824156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.747569</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.712498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.680756</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.650099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.566839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.882314</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.738107</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.714796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>0.697159</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.743182</td>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.565728</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>0.554439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.788396</td>\n",
       "      <td>0.683045</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.682439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.528724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.466804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.678409</td>\n",
       "      <td>0.464756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.795222</td>\n",
       "      <td>0.682253</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.658029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.600683</td>\n",
       "      <td>0.565850</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.562516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.513734</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.490738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.476526</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>0.483445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.5</th>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.697520</td>\n",
       "      <td>0.770076</td>\n",
       "      <td>0.770076</td>\n",
       "      <td>0.672653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.1</th>\n",
       "      <td>0.631399</td>\n",
       "      <td>0.631399</td>\n",
       "      <td>0.595126</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.576624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.05</th>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.627986</td>\n",
       "      <td>0.503727</td>\n",
       "      <td>0.615152</td>\n",
       "      <td>0.615152</td>\n",
       "      <td>0.498847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.01</th>\n",
       "      <td>0.703072</td>\n",
       "      <td>0.703072</td>\n",
       "      <td>0.483568</td>\n",
       "      <td>0.701894</td>\n",
       "      <td>0.701894</td>\n",
       "      <td>0.481220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.863481  0.863481  0.791265  0.844697  0.844697  0.797604\n",
       "5-NN 0.1            0.726962  0.726962  0.705109  0.724621  0.724621  0.707734\n",
       "5-NN 0.05           0.744027  0.744027  0.650595  0.730303  0.730303  0.643980\n",
       "5-NN 0.01           0.825939  0.825939  0.568075  0.788636  0.788636  0.539431\n",
       "Decision tree 0.5   0.890785  0.890785  0.880823  0.864394  0.864394  0.824156\n",
       "Decision tree 0.1   0.764505  0.764505  0.747569  0.729545  0.729545  0.712498\n",
       "Decision tree 0.05  0.781570  0.781570  0.680756  0.742045  0.742045  0.650099\n",
       "Decision tree 0.01  0.829352  0.829352  0.570423  0.801136  0.801136  0.566839\n",
       "Random forest 0.5   0.890785  0.890785  0.882314  0.867424  0.867424  0.825472\n",
       "Random forest 0.1   0.764505  0.764505  0.738107  0.736742  0.736742  0.714796\n",
       "Random forest 0.05  0.784983  0.784983  0.697159  0.743182  0.743182  0.656430\n",
       "Random forest 0.01  0.822526  0.822526  0.565728  0.796970  0.796970  0.554439\n",
       "SVM linear 0.5      0.788396  0.788396  0.683045  0.765909  0.765909  0.682439\n",
       "SVM linear 0.1      0.576792  0.576792  0.552967  0.553030  0.553030  0.528724\n",
       "SVM linear 0.05     0.610922  0.610922  0.483161  0.592424  0.592424  0.466804\n",
       "SVM linear 0.01     0.675768  0.675768  0.464789  0.678409  0.678409  0.464756\n",
       "SVM poly 0.5        0.795222  0.795222  0.682253  0.772727  0.772727  0.658029\n",
       "SVM poly 0.1        0.600683  0.600683  0.565850  0.591667  0.591667  0.562516\n",
       "SVM poly 0.05       0.651877  0.651877  0.513734  0.623106  0.623106  0.490738\n",
       "SVM poly 0.01       0.692833  0.692833  0.476526  0.705682  0.705682  0.483445\n",
       "SVM rbf 0.5         0.798635  0.798635  0.697520  0.770076  0.770076  0.672653\n",
       "SVM rbf 0.1         0.631399  0.631399  0.595126  0.600000  0.600000  0.576624\n",
       "SVM rbf 0.05        0.627986  0.627986  0.503727  0.615152  0.615152  0.498847\n",
       "SVM rbf 0.01        0.703072  0.703072  0.483568  0.701894  0.701894  0.481220"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM rbf 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d33926",
   "metadata": {},
   "source": [
    "### SVM with time difference, rbf kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08098924",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0a5f6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR(kernel='rbf')\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_svm_linear = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "29ef7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_svm_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a31d26c",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "42654a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "62801a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_svm_linear_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380bc3f3",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0e1c7b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.789418</td>\n",
       "      <td>0.730049</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.579022</td>\n",
       "      <td>0.390659</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>0.612816</td>\n",
       "      <td>0.433778</td>\n",
       "      <td>0.796680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.584555</td>\n",
       "      <td>0.392098</td>\n",
       "      <td>0.817131</td>\n",
       "      <td>0.613710</td>\n",
       "      <td>0.435071</td>\n",
       "      <td>0.796384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>2.323296</td>\n",
       "      <td>0.907326</td>\n",
       "      <td>0.273192</td>\n",
       "      <td>2.371142</td>\n",
       "      <td>0.929039</td>\n",
       "      <td>0.213305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.778288</td>\n",
       "      <td>0.719919</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>1.815210</td>\n",
       "      <td>0.749433</td>\n",
       "      <td>0.397751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.612341</td>\n",
       "      <td>0.692069</td>\n",
       "      <td>0.495604</td>\n",
       "      <td>1.666438</td>\n",
       "      <td>0.727603</td>\n",
       "      <td>0.447111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN           0.673141  0.442646  0.789418  0.730049  0.478475  0.757785\n",
       "Decision tree  0.579022  0.390659  0.818862  0.612816  0.433778  0.796680\n",
       "Random forest  0.584555  0.392098  0.817131  0.613710  0.435071  0.796384\n",
       "SVM linear     2.323296  0.907326  0.273192  2.371142  0.929039  0.213305\n",
       "SVM poly       1.778288  0.719919  0.443690  1.815210  0.749433  0.397751\n",
       "SVM rbf        1.612341  0.692069  0.495604  1.666438  0.727603  0.447111"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"SVM rbf\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923b6a7-26ef-4965-9d52-7c87cf822b61",
   "metadata": {},
   "source": [
    "### Deep MLP with two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ccff145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.values).float()  # Convert DataFrame to tensor\n",
    "        self.y = torch.from_numpy(y.values).float()  # Convert DataFrame to tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d8e1e7dd-6de4-4b65-8ffe-3be825213b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_classification(X_training, y_training, X_validation, y_validation, type, text):\n",
    "    custom_dataset = CustomDataset(X_training, y_training)\n",
    "    trainloader = DataLoader(custom_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "    mlp = MLPClassifier(random_seed=20)\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()  \n",
    "        \n",
    "    optimizer = torch.optim.Adagrad(mlp.parameters(), lr=0.1)\n",
    "\n",
    "    val_data = torch.tensor(X_validation.values, dtype=torch.float32)\n",
    "    val_targets = torch.tensor(y_validation.values, dtype=torch.float32)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(300):\n",
    "        print(f'Starting Epoch {epoch+1}')\n",
    "    \n",
    "        current_loss = 0.0\n",
    "    \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, targets = data\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = mlp(inputs)\n",
    "    \n",
    "            targets = targets.long()  # Convert target tensor to torch.long data type\n",
    "            loss = loss_function(outputs, targets)\n",
    "    \n",
    "            loss.backward()\n",
    "    \n",
    "            optimizer.step()\n",
    "    \n",
    "            current_loss += loss.item()\n",
    "    \n",
    "        print(current_loss/len(trainloader))\n",
    "    \n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = mlp(val_data).squeeze()\n",
    "            val_targets = val_targets.long()\n",
    "            val_loss = loss_function(val_outputs, val_targets).item()\n",
    "            #print(f'Validation loss: {val_loss}')\n",
    "    \n",
    "        # Check if this is the best model so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = deepcopy(mlp.state_dict())\n",
    "            print(f'New best model found at epoch {epoch+1} with validation loss {best_val_loss}')\n",
    "    \n",
    "    print(\"Training has completed\")\n",
    "\n",
    "\n",
    "    mlp2 = MLPClassifier(random_seed=20)\n",
    "    mlp2.load_state_dict(best_model_state)\n",
    "    \n",
    "    mlp2.eval() \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = mlp2(val_data).squeeze()\n",
    "        predicted_labels = torch.argmax(outputs, dim=1).numpy()\n",
    "    \n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    val_targets = np.array(val_targets)\n",
    "\n",
    "    if type == \"2_class\":\n",
    "        accuracy = accuracy_score(val_targets, predicted_labels)\n",
    "        recall = recall_score(val_targets, predicted_labels)\n",
    "        conf_matrix = confusion_matrix(val_targets, predicted_labels)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_2_classes.loc[text] = [accuracy, recall, \"-\", \"-\"]\n",
    "\n",
    "    if type == \"3_class\":\n",
    "        accuracy = accuracy_score(val_targets, predicted_labels)\n",
    "        recall_micro = recall_score(val_targets, predicted_labels, average='micro')\n",
    "        recall_macro = recall_score(val_targets, predicted_labels, average='macro')\n",
    "        conf_matrix = confusion_matrix(val_targets, predicted_labels)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_3_classes.loc[text] = [accuracy, recall_micro, recall_macro, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1e502",
   "metadata": {},
   "source": [
    "#### 3-layer MLP\n",
    "*  Loss: Cross-Entropy\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd7ff9",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 1\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 5 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c3826161-f841-4258-8583-3e8587111eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 2)\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0ea35f07-5887-40ce-9361-3eebac924761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.7442948867877325\n",
      "New best model found at epoch 1 with validation loss 0.5726732611656189\n",
      "Starting Epoch 2\n",
      "0.5795564651489258\n",
      "New best model found at epoch 2 with validation loss 0.5692018866539001\n",
      "Starting Epoch 3\n",
      "0.576042890548706\n",
      "Starting Epoch 4\n",
      "0.5746120226879915\n",
      "New best model found at epoch 4 with validation loss 0.5671882629394531\n",
      "Starting Epoch 5\n",
      "0.5736376605927944\n",
      "New best model found at epoch 5 with validation loss 0.562140166759491\n",
      "Starting Epoch 6\n",
      "0.5719288202623526\n",
      "Starting Epoch 7\n",
      "0.5709182918071747\n",
      "New best model found at epoch 7 with validation loss 0.5581754446029663\n",
      "Starting Epoch 8\n",
      "0.5688290558755398\n",
      "New best model found at epoch 8 with validation loss 0.556645929813385\n",
      "Starting Epoch 9\n",
      "0.5699893186489741\n",
      "Starting Epoch 10\n",
      "0.5686919912695885\n",
      "Starting Epoch 11\n",
      "0.5693556070327759\n",
      "New best model found at epoch 11 with validation loss 0.5561731457710266\n",
      "Starting Epoch 12\n",
      "0.5693189625938734\n",
      "Starting Epoch 13\n",
      "0.571213016907374\n",
      "New best model found at epoch 13 with validation loss 0.5554931163787842\n",
      "Starting Epoch 14\n",
      "0.5710001227756342\n",
      "Starting Epoch 15\n",
      "0.5670978327592214\n",
      "Starting Epoch 16\n",
      "0.568968404084444\n",
      "New best model found at epoch 16 with validation loss 0.553672730922699\n",
      "Starting Epoch 17\n",
      "0.5692701550821463\n",
      "Starting Epoch 18\n",
      "0.5663320397337278\n",
      "Starting Epoch 19\n",
      "0.5662833340466022\n",
      "Starting Epoch 20\n",
      "0.568528146793445\n",
      "Starting Epoch 21\n",
      "0.5654013566672802\n",
      "Starting Epoch 22\n",
      "0.5651289920012156\n",
      "New best model found at epoch 22 with validation loss 0.5524489879608154\n",
      "Starting Epoch 23\n",
      "0.5620782660941283\n",
      "Starting Epoch 24\n",
      "0.567100981871287\n",
      "New best model found at epoch 24 with validation loss 0.5522766709327698\n",
      "Starting Epoch 25\n",
      "0.5649325077732404\n",
      "Starting Epoch 26\n",
      "0.561718050390482\n",
      "Starting Epoch 27\n",
      "0.5630493834614754\n",
      "New best model found at epoch 27 with validation loss 0.5487170815467834\n",
      "Starting Epoch 28\n",
      "0.5645709559321404\n",
      "Starting Epoch 29\n",
      "0.5642627316216627\n",
      "Starting Epoch 30\n",
      "0.5638571195304394\n",
      "New best model found at epoch 30 with validation loss 0.5465101599693298\n",
      "Starting Epoch 31\n",
      "0.5640626226862272\n",
      "Starting Epoch 32\n",
      "0.5610432711740335\n",
      "Starting Epoch 33\n",
      "0.5597374513745308\n",
      "Starting Epoch 34\n",
      "0.5615407787263393\n",
      "New best model found at epoch 34 with validation loss 0.5445713996887207\n",
      "Starting Epoch 35\n",
      "0.5610176275173823\n",
      "Starting Epoch 36\n",
      "0.560651874790589\n",
      "Starting Epoch 37\n",
      "0.5614413321018219\n",
      "Starting Epoch 38\n",
      "0.5599611413975557\n",
      "Starting Epoch 39\n",
      "0.5604784352084001\n",
      "Starting Epoch 40\n",
      "0.5613811450699965\n",
      "Starting Epoch 41\n",
      "0.5607025201121966\n",
      "New best model found at epoch 41 with validation loss 0.5427390336990356\n",
      "Starting Epoch 42\n",
      "0.5603266308705012\n",
      "Starting Epoch 43\n",
      "0.560999795794487\n",
      "Starting Epoch 44\n",
      "0.5590636307994524\n",
      "Starting Epoch 45\n",
      "0.55977613478899\n",
      "Starting Epoch 46\n",
      "0.559944823384285\n",
      "Starting Epoch 47\n",
      "0.5602001125613848\n",
      "Starting Epoch 48\n",
      "0.5587720908224583\n",
      "New best model found at epoch 48 with validation loss 0.5427024364471436\n",
      "Starting Epoch 49\n",
      "0.556584137181441\n",
      "Starting Epoch 50\n",
      "0.5558937850097815\n",
      "Starting Epoch 51\n",
      "0.5556917861104012\n",
      "New best model found at epoch 51 with validation loss 0.541390061378479\n",
      "Starting Epoch 52\n",
      "0.5557367367049059\n",
      "Starting Epoch 53\n",
      "0.5585172201196352\n",
      "Starting Epoch 54\n",
      "0.5579028651118279\n",
      "Starting Epoch 55\n",
      "0.554579829176267\n",
      "Starting Epoch 56\n",
      "0.5620720659693083\n",
      "Starting Epoch 57\n",
      "0.5566182335217794\n",
      "Starting Epoch 58\n",
      "0.5569584183394909\n",
      "Starting Epoch 59\n",
      "0.5571849507590135\n",
      "Starting Epoch 60\n",
      "0.5547938955326875\n",
      "New best model found at epoch 60 with validation loss 0.5410257577896118\n",
      "Starting Epoch 61\n",
      "0.5563171034057935\n",
      "Starting Epoch 62\n",
      "0.5560374893248081\n",
      "New best model found at epoch 62 with validation loss 0.5409525036811829\n",
      "Starting Epoch 63\n",
      "0.5575543952484926\n",
      "Starting Epoch 64\n",
      "0.5568886175751686\n",
      "New best model found at epoch 64 with validation loss 0.5399630069732666\n",
      "Starting Epoch 65\n",
      "0.5542410537600517\n",
      "Starting Epoch 66\n",
      "0.5544508943955103\n",
      "Starting Epoch 67\n",
      "0.5574978751440843\n",
      "Starting Epoch 68\n",
      "0.5565319011608759\n",
      "Starting Epoch 69\n",
      "0.5588044164081415\n",
      "Starting Epoch 70\n",
      "0.552450550099214\n",
      "New best model found at epoch 70 with validation loss 0.5395070910453796\n",
      "Starting Epoch 71\n",
      "0.5543843731284142\n",
      "Starting Epoch 72\n",
      "0.5558899715542793\n",
      "Starting Epoch 73\n",
      "0.5558685710032781\n",
      "Starting Epoch 74\n",
      "0.5558529881139597\n",
      "New best model found at epoch 74 with validation loss 0.5393286943435669\n",
      "Starting Epoch 75\n",
      "0.5549885655442873\n",
      "New best model found at epoch 75 with validation loss 0.5385506749153137\n",
      "Starting Epoch 76\n",
      "0.5548138320446014\n",
      "Starting Epoch 77\n",
      "0.5524707262714704\n",
      "Starting Epoch 78\n",
      "0.5532558386524519\n",
      "New best model found at epoch 78 with validation loss 0.5377647876739502\n",
      "Starting Epoch 79\n",
      "0.552474437902371\n",
      "Starting Epoch 80\n",
      "0.5530383648971716\n",
      "Starting Epoch 81\n",
      "0.5539458816250166\n",
      "Starting Epoch 82\n",
      "0.5549248345196247\n",
      "Starting Epoch 83\n",
      "0.5576320936282476\n",
      "Starting Epoch 84\n",
      "0.554133785267671\n",
      "Starting Epoch 85\n",
      "0.5539739380280176\n",
      "Starting Epoch 86\n",
      "0.5522398538887501\n",
      "New best model found at epoch 86 with validation loss 0.5373605489730835\n",
      "Starting Epoch 87\n",
      "0.5534655873974165\n",
      "Starting Epoch 88\n",
      "0.5528757212062677\n",
      "Starting Epoch 89\n",
      "0.5548877467711767\n",
      "Starting Epoch 90\n",
      "0.5539271881182989\n",
      "Starting Epoch 91\n",
      "0.5536348968744278\n",
      "Starting Epoch 92\n",
      "0.5529635772109032\n",
      "New best model found at epoch 92 with validation loss 0.5367412567138672\n",
      "Starting Epoch 93\n",
      "0.5515948086977005\n",
      "Starting Epoch 94\n",
      "0.5540799647569656\n",
      "Starting Epoch 95\n",
      "0.5527477624515692\n",
      "Starting Epoch 96\n",
      "0.5541194950540861\n",
      "Starting Epoch 97\n",
      "0.5529297528167566\n",
      "Starting Epoch 98\n",
      "0.5524779073894024\n",
      "Starting Epoch 99\n",
      "0.5532184379796187\n",
      "Starting Epoch 100\n",
      "0.5530030603210131\n",
      "Starting Epoch 101\n",
      "0.5522894337773323\n",
      "Starting Epoch 102\n",
      "0.5523735272387663\n",
      "Starting Epoch 103\n",
      "0.5528703294694424\n",
      "Starting Epoch 104\n",
      "0.5527836295465628\n",
      "Starting Epoch 105\n",
      "0.5517997692028681\n",
      "New best model found at epoch 105 with validation loss 0.5361684560775757\n",
      "Starting Epoch 106\n",
      "0.5544317414363226\n",
      "Starting Epoch 107\n",
      "0.5517763209839662\n",
      "Starting Epoch 108\n",
      "0.5517123987277349\n",
      "Starting Epoch 109\n",
      "0.5530859778324763\n",
      "Starting Epoch 110\n",
      "0.5517702711125215\n",
      "Starting Epoch 111\n",
      "0.5542744720975558\n",
      "Starting Epoch 112\n",
      "0.5496540156503519\n",
      "Starting Epoch 113\n",
      "0.5515412117044131\n",
      "Starting Epoch 114\n",
      "0.5510102920234203\n",
      "Starting Epoch 115\n",
      "0.5496049945553144\n",
      "Starting Epoch 116\n",
      "0.5508290231227875\n",
      "New best model found at epoch 116 with validation loss 0.5359199643135071\n",
      "Starting Epoch 117\n",
      "0.550112617512544\n",
      "Starting Epoch 118\n",
      "0.5524762012064457\n",
      "Starting Epoch 119\n",
      "0.5521111016472181\n",
      "Starting Epoch 120\n",
      "0.5520402193069458\n",
      "New best model found at epoch 120 with validation loss 0.5358999967575073\n",
      "Starting Epoch 121\n",
      "0.551999881863594\n",
      "Starting Epoch 122\n",
      "0.5538435180981954\n",
      "Starting Epoch 123\n",
      "0.5488000040253004\n",
      "Starting Epoch 124\n",
      "0.5519845895469189\n",
      "New best model found at epoch 124 with validation loss 0.5355077385902405\n",
      "Starting Epoch 125\n",
      "0.5501655414700508\n",
      "Starting Epoch 126\n",
      "0.5527806306878725\n",
      "Starting Epoch 127\n",
      "0.553577333688736\n",
      "Starting Epoch 128\n",
      "0.5503667642672857\n",
      "Starting Epoch 129\n",
      "0.550541148831447\n",
      "New best model found at epoch 129 with validation loss 0.5352327823638916\n",
      "Starting Epoch 130\n",
      "0.5513393953442574\n",
      "Starting Epoch 131\n",
      "0.54997626816233\n",
      "Starting Epoch 132\n",
      "0.5509384609758854\n",
      "Starting Epoch 133\n",
      "0.5501053395370642\n",
      "Starting Epoch 134\n",
      "0.5495423537989458\n",
      "Starting Epoch 135\n",
      "0.5520426854491234\n",
      "Starting Epoch 136\n",
      "0.5504113063216209\n",
      "Starting Epoch 137\n",
      "0.5511006787419319\n",
      "Starting Epoch 138\n",
      "0.5493931360542774\n",
      "Starting Epoch 139\n",
      "0.5482673607766628\n",
      "New best model found at epoch 139 with validation loss 0.5350867509841919\n",
      "Starting Epoch 140\n",
      "0.5513051909705003\n",
      "Starting Epoch 141\n",
      "0.5496197193861008\n",
      "Starting Epoch 142\n",
      "0.5495992650588354\n",
      "Starting Epoch 143\n",
      "0.5511205792427063\n",
      "Starting Epoch 144\n",
      "0.5494805549581846\n",
      "Starting Epoch 145\n",
      "0.5492265472809473\n",
      "Starting Epoch 146\n",
      "0.5512998253107071\n",
      "Starting Epoch 147\n",
      "0.5479229862491289\n",
      "Starting Epoch 148\n",
      "0.5483929092685381\n",
      "Starting Epoch 149\n",
      "0.550800242771705\n",
      "New best model found at epoch 149 with validation loss 0.534780740737915\n",
      "Starting Epoch 150\n",
      "0.5507875631252924\n",
      "Starting Epoch 151\n",
      "0.5511761978268623\n",
      "Starting Epoch 152\n",
      "0.5505709374944369\n",
      "Starting Epoch 153\n",
      "0.5483586254219214\n",
      "Starting Epoch 154\n",
      "0.5503228815893332\n",
      "Starting Epoch 155\n",
      "0.5510497291882833\n",
      "Starting Epoch 156\n",
      "0.5505950922767321\n",
      "Starting Epoch 157\n",
      "0.5484985336661339\n",
      "Starting Epoch 158\n",
      "0.5499238794048628\n",
      "Starting Epoch 159\n",
      "0.5475870408117771\n",
      "Starting Epoch 160\n",
      "0.5508040661613146\n",
      "Starting Epoch 161\n",
      "0.5505173280835152\n",
      "Starting Epoch 162\n",
      "0.5476460059483846\n",
      "Starting Epoch 163\n",
      "0.5478948739667734\n",
      "Starting Epoch 164\n",
      "0.5474115038911501\n",
      "Starting Epoch 165\n",
      "0.5502468918760618\n",
      "Starting Epoch 166\n",
      "0.5469971733788649\n",
      "Starting Epoch 167\n",
      "0.5510699277122816\n",
      "Starting Epoch 168\n",
      "0.5513626622656981\n",
      "Starting Epoch 169\n",
      "0.5490974634885788\n",
      "Starting Epoch 170\n",
      "0.5483920263747374\n",
      "Starting Epoch 171\n",
      "0.5482791004081567\n",
      "Starting Epoch 172\n",
      "0.5505085463325182\n",
      "Starting Epoch 173\n",
      "0.5492384259899458\n",
      "Starting Epoch 174\n",
      "0.5499257010718187\n",
      "Starting Epoch 175\n",
      "0.5489486902952194\n",
      "Starting Epoch 176\n",
      "0.5505913471182188\n",
      "Starting Epoch 177\n",
      "0.5506154634058475\n",
      "Starting Epoch 178\n",
      "0.5520019444326559\n",
      "Starting Epoch 179\n",
      "0.5468895249068737\n",
      "Starting Epoch 180\n",
      "0.5474767088890076\n",
      "Starting Epoch 181\n",
      "0.5485579421122869\n",
      "Starting Epoch 182\n",
      "0.5468066049118837\n",
      "Starting Epoch 183\n",
      "0.5508373578389486\n",
      "Starting Epoch 184\n",
      "0.5485651828348637\n",
      "Starting Epoch 185\n",
      "0.5488518004616102\n",
      "New best model found at epoch 185 with validation loss 0.5342148542404175\n",
      "Starting Epoch 186\n",
      "0.5475823692977428\n",
      "Starting Epoch 187\n",
      "0.5471943144996961\n",
      "Starting Epoch 188\n",
      "0.5474955067038536\n",
      "Starting Epoch 189\n",
      "0.5498874162634214\n",
      "Starting Epoch 190\n",
      "0.5480866009990374\n",
      "Starting Epoch 191\n",
      "0.5501687377691269\n",
      "Starting Epoch 192\n",
      "0.5492033710082372\n",
      "Starting Epoch 193\n",
      "0.5478399073084196\n",
      "Starting Epoch 194\n",
      "0.5500894499321779\n",
      "Starting Epoch 195\n",
      "0.5475465320050716\n",
      "Starting Epoch 196\n",
      "0.5489703652759393\n",
      "Starting Epoch 197\n",
      "0.5482447072863579\n",
      "Starting Epoch 198\n",
      "0.549597060928742\n",
      "Starting Epoch 199\n",
      "0.5500640074412028\n",
      "Starting Epoch 200\n",
      "0.5503693632781506\n",
      "Starting Epoch 201\n",
      "0.5473441320161024\n",
      "New best model found at epoch 201 with validation loss 0.5338475704193115\n",
      "Starting Epoch 202\n",
      "0.5493809742232164\n",
      "Starting Epoch 203\n",
      "0.5500839600960413\n",
      "Starting Epoch 204\n",
      "0.5487733023862044\n",
      "Starting Epoch 205\n",
      "0.5496164932847023\n",
      "Starting Epoch 206\n",
      "0.5496741707126299\n",
      "Starting Epoch 207\n",
      "0.5484085492789745\n",
      "Starting Epoch 208\n",
      "0.5509683911999067\n",
      "Starting Epoch 209\n",
      "0.548344686627388\n",
      "Starting Epoch 210\n",
      "0.550638404985269\n",
      "Starting Epoch 211\n",
      "0.5493590782086054\n",
      "Starting Epoch 212\n",
      "0.5490863931675752\n",
      "Starting Epoch 213\n",
      "0.5477124800284704\n",
      "Starting Epoch 214\n",
      "0.5492299869656563\n",
      "Starting Epoch 215\n",
      "0.5497925740977129\n",
      "Starting Epoch 216\n",
      "0.5477550365030766\n",
      "Starting Epoch 217\n",
      "0.5462054324646791\n",
      "Starting Epoch 218\n",
      "0.5508871500690778\n",
      "Starting Epoch 219\n",
      "0.5486087451378504\n",
      "Starting Epoch 220\n",
      "0.5476767259339491\n",
      "Starting Epoch 221\n",
      "0.5463874054451784\n",
      "Starting Epoch 222\n",
      "0.5471581369638443\n",
      "Starting Epoch 223\n",
      "0.5492891669273376\n",
      "Starting Epoch 224\n",
      "0.5472315562268099\n",
      "Starting Epoch 225\n",
      "0.5465140752494335\n",
      "Starting Epoch 226\n",
      "0.5474920955797037\n",
      "Starting Epoch 227\n",
      "0.5474776588380337\n",
      "Starting Epoch 228\n",
      "0.5464912777145704\n",
      "Starting Epoch 229\n",
      "0.5497794536252817\n",
      "Starting Epoch 230\n",
      "0.5483845348159472\n",
      "Starting Epoch 231\n",
      "0.5487267971038818\n",
      "Starting Epoch 232\n",
      "0.5482156773408254\n",
      "Starting Epoch 233\n",
      "0.5487068146467209\n",
      "Starting Epoch 234\n",
      "0.5482005154093107\n",
      "Starting Epoch 235\n",
      "0.548097605506579\n",
      "Starting Epoch 236\n",
      "0.5499734406669935\n",
      "Starting Epoch 237\n",
      "0.546781109025081\n",
      "Starting Epoch 238\n",
      "0.5492601742347082\n",
      "Starting Epoch 239\n",
      "0.5465052897731463\n",
      "Starting Epoch 240\n",
      "0.5485317160685858\n",
      "Starting Epoch 241\n",
      "0.5477918187777201\n",
      "Starting Epoch 242\n",
      "0.5475686304271221\n",
      "Starting Epoch 243\n",
      "0.5484686270356178\n",
      "Starting Epoch 244\n",
      "0.5464202351868153\n",
      "Starting Epoch 245\n",
      "0.5464822513361772\n",
      "Starting Epoch 246\n",
      "0.5473281294107437\n",
      "Starting Epoch 247\n",
      "0.5483006996413072\n",
      "Starting Epoch 248\n",
      "0.5461340186496576\n",
      "Starting Epoch 249\n",
      "0.546573686103026\n",
      "Starting Epoch 250\n",
      "0.5470779004196326\n",
      "Starting Epoch 251\n",
      "0.5482586212456226\n",
      "Starting Epoch 252\n",
      "0.5469574307401975\n",
      "Starting Epoch 253\n",
      "0.5461878068745136\n",
      "Starting Epoch 254\n",
      "0.5460671856999397\n",
      "Starting Epoch 255\n",
      "0.5461997017264366\n",
      "Starting Epoch 256\n",
      "0.5464373305439949\n",
      "New best model found at epoch 256 with validation loss 0.5334351658821106\n",
      "Starting Epoch 257\n",
      "0.5474163008232912\n",
      "Starting Epoch 258\n",
      "0.5472884364426136\n",
      "New best model found at epoch 258 with validation loss 0.5333532094955444\n",
      "Starting Epoch 259\n",
      "0.5462863271435102\n",
      "New best model found at epoch 259 with validation loss 0.5330569744110107\n",
      "Starting Epoch 260\n",
      "0.5469470421473185\n",
      "Starting Epoch 261\n",
      "0.5454914085566998\n",
      "Starting Epoch 262\n",
      "0.5484268565972646\n",
      "Starting Epoch 263\n",
      "0.54764748737216\n",
      "Starting Epoch 264\n",
      "0.5453161473075548\n",
      "Starting Epoch 265\n",
      "0.5467067671318849\n",
      "Starting Epoch 266\n",
      "0.5490561785797278\n",
      "Starting Epoch 267\n",
      "0.5487656208376089\n",
      "Starting Epoch 268\n",
      "0.5467027475436529\n",
      "Starting Epoch 269\n",
      "0.5451860601703326\n",
      "Starting Epoch 270\n",
      "0.5474445869525274\n",
      "New best model found at epoch 270 with validation loss 0.5329254269599915\n",
      "Starting Epoch 271\n",
      "0.5473229562242826\n",
      "Starting Epoch 272\n",
      "0.5489039495587349\n",
      "Starting Epoch 273\n",
      "0.5464615436891714\n",
      "Starting Epoch 274\n",
      "0.5481753995021185\n",
      "New best model found at epoch 274 with validation loss 0.5328684449195862\n",
      "Starting Epoch 275\n",
      "0.5469145402312279\n",
      "Starting Epoch 276\n",
      "0.5461503602564335\n",
      "Starting Epoch 277\n",
      "0.5476261290411154\n",
      "Starting Epoch 278\n",
      "0.5466700904071331\n",
      "Starting Epoch 279\n",
      "0.5484513739744822\n",
      "Starting Epoch 280\n",
      "0.5465999394655228\n",
      "Starting Epoch 281\n",
      "0.5473170578479767\n",
      "Starting Epoch 282\n",
      "0.5454434951146444\n",
      "Starting Epoch 283\n",
      "0.5447868332266808\n",
      "Starting Epoch 284\n",
      "0.547744058072567\n",
      "Starting Epoch 285\n",
      "0.5499742279450098\n",
      "Starting Epoch 286\n",
      "0.5472577624022961\n",
      "Starting Epoch 287\n",
      "0.5474594905972481\n",
      "Starting Epoch 288\n",
      "0.5471792444586754\n",
      "Starting Epoch 289\n",
      "0.5466832568248113\n",
      "Starting Epoch 290\n",
      "0.5455569264789423\n",
      "Starting Epoch 291\n",
      "0.5467623546719551\n",
      "Starting Epoch 292\n",
      "0.545760378241539\n",
      "Starting Epoch 293\n",
      "0.5466701723635197\n",
      "Starting Epoch 294\n",
      "0.5468973219394684\n",
      "Starting Epoch 295\n",
      "0.5465606761475404\n",
      "New best model found at epoch 295 with validation loss 0.5328299403190613\n",
      "Starting Epoch 296\n",
      "0.5469734420379003\n",
      "Starting Epoch 297\n",
      "0.5467972457408905\n",
      "Starting Epoch 298\n",
      "0.547953716168801\n",
      "Starting Epoch 299\n",
      "0.5454441321392854\n",
      "Starting Epoch 300\n",
      "0.5479758481184641\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-5-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a4253",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 2\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 10 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7a2250d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cd5431a3-d32b-4fb0-9907-8adf99ca7338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.8379995475212733\n",
      "New best model found at epoch 1 with validation loss 0.5914157629013062\n",
      "Starting Epoch 2\n",
      "0.6187379484375318\n",
      "Starting Epoch 3\n",
      "0.6098581304152807\n",
      "Starting Epoch 4\n",
      "0.6064253052075704\n",
      "New best model found at epoch 4 with validation loss 0.5783376097679138\n",
      "Starting Epoch 5\n",
      "0.5934111451109251\n",
      "New best model found at epoch 5 with validation loss 0.5729165077209473\n",
      "Starting Epoch 6\n",
      "0.5937540059288343\n",
      "Starting Epoch 7\n",
      "0.5863025610645612\n",
      "New best model found at epoch 7 with validation loss 0.5636701583862305\n",
      "Starting Epoch 8\n",
      "0.5773310487469038\n",
      "Starting Epoch 9\n",
      "0.5790330295761427\n",
      "New best model found at epoch 9 with validation loss 0.5591007471084595\n",
      "Starting Epoch 10\n",
      "0.5742069880167643\n",
      "Starting Epoch 11\n",
      "0.5691543109714985\n",
      "New best model found at epoch 11 with validation loss 0.5575034618377686\n",
      "Starting Epoch 12\n",
      "0.5687786464889845\n",
      "New best model found at epoch 12 with validation loss 0.5563582181930542\n",
      "Starting Epoch 13\n",
      "0.5673764621218046\n",
      "New best model found at epoch 13 with validation loss 0.5551142692565918\n",
      "Starting Epoch 14\n",
      "0.567429901411136\n",
      "Starting Epoch 15\n",
      "0.5679388716816902\n",
      "Starting Epoch 16\n",
      "0.5687499493360519\n",
      "New best model found at epoch 16 with validation loss 0.5485538840293884\n",
      "Starting Epoch 17\n",
      "0.5646820142865181\n",
      "New best model found at epoch 17 with validation loss 0.5482429265975952\n",
      "Starting Epoch 18\n",
      "0.5621771352986494\n",
      "New best model found at epoch 18 with validation loss 0.5466647744178772\n",
      "Starting Epoch 19\n",
      "0.564013289908568\n",
      "Starting Epoch 20\n",
      "0.5582553818821907\n",
      "Starting Epoch 21\n",
      "0.5568833313882351\n",
      "Starting Epoch 22\n",
      "0.5572065711021423\n",
      "New best model found at epoch 22 with validation loss 0.5435295701026917\n",
      "Starting Epoch 23\n",
      "0.5537422423561414\n",
      "Starting Epoch 24\n",
      "0.5594229027628899\n",
      "Starting Epoch 25\n",
      "0.5534221430619558\n",
      "Starting Epoch 26\n",
      "0.5544840904573599\n",
      "Starting Epoch 27\n",
      "0.5563310049474239\n",
      "Starting Epoch 28\n",
      "0.552907487998406\n",
      "Starting Epoch 29\n",
      "0.554903378089269\n",
      "New best model found at epoch 29 with validation loss 0.539637565612793\n",
      "Starting Epoch 30\n",
      "0.5522901763518652\n",
      "Starting Epoch 31\n",
      "0.5589436081548532\n",
      "New best model found at epoch 31 with validation loss 0.5374957323074341\n",
      "Starting Epoch 32\n",
      "0.5471024488409361\n",
      "Starting Epoch 33\n",
      "0.556661161283652\n",
      "Starting Epoch 34\n",
      "0.5505532721678416\n",
      "Starting Epoch 35\n",
      "0.5481003485620022\n",
      "Starting Epoch 36\n",
      "0.5525585475067297\n",
      "Starting Epoch 37\n",
      "0.5478424057364464\n",
      "New best model found at epoch 37 with validation loss 0.5372384190559387\n",
      "Starting Epoch 38\n",
      "0.5521225817501545\n",
      "New best model found at epoch 38 with validation loss 0.5351598858833313\n",
      "Starting Epoch 39\n",
      "0.5501797671119372\n",
      "Starting Epoch 40\n",
      "0.5486453125874201\n",
      "Starting Epoch 41\n",
      "0.5501896267135938\n",
      "Starting Epoch 42\n",
      "0.552253745496273\n",
      "Starting Epoch 43\n",
      "0.548799047867457\n",
      "New best model found at epoch 43 with validation loss 0.5332298874855042\n",
      "Starting Epoch 44\n",
      "0.5477675447861353\n",
      "Starting Epoch 45\n",
      "0.5499137490987778\n",
      "Starting Epoch 46\n",
      "0.5478569554785887\n",
      "Starting Epoch 47\n",
      "0.5459013295670351\n",
      "Starting Epoch 48\n",
      "0.5484639642139276\n",
      "Starting Epoch 49\n",
      "0.5485311684509119\n",
      "Starting Epoch 50\n",
      "0.5483638197183609\n",
      "New best model found at epoch 50 with validation loss 0.530576765537262\n",
      "Starting Epoch 51\n",
      "0.5457285791635513\n",
      "Starting Epoch 52\n",
      "0.5431342211862406\n",
      "Starting Epoch 53\n",
      "0.5482126623392105\n",
      "Starting Epoch 54\n",
      "0.5443892441689968\n",
      "Starting Epoch 55\n",
      "0.5453583523631096\n",
      "Starting Epoch 56\n",
      "0.5493077921370665\n",
      "Starting Epoch 57\n",
      "0.5469474208851656\n",
      "Starting Epoch 58\n",
      "0.5509916370113691\n",
      "New best model found at epoch 58 with validation loss 0.5295431613922119\n",
      "Starting Epoch 59\n",
      "0.5431207790970802\n",
      "New best model found at epoch 59 with validation loss 0.5269514918327332\n",
      "Starting Epoch 60\n",
      "0.5437214660147826\n",
      "Starting Epoch 61\n",
      "0.5464984228213629\n",
      "Starting Epoch 62\n",
      "0.5427078281839689\n",
      "New best model found at epoch 62 with validation loss 0.525100827217102\n",
      "Starting Epoch 63\n",
      "0.543839601178964\n",
      "Starting Epoch 64\n",
      "0.5454849153757095\n",
      "Starting Epoch 65\n",
      "0.5420467257499695\n",
      "Starting Epoch 66\n",
      "0.5448760365446409\n",
      "Starting Epoch 67\n",
      "0.5423280708491802\n",
      "New best model found at epoch 67 with validation loss 0.5237292051315308\n",
      "Starting Epoch 68\n",
      "0.5409847597281138\n",
      "New best model found at epoch 68 with validation loss 0.52223801612854\n",
      "Starting Epoch 69\n",
      "0.5422214219967524\n",
      "Starting Epoch 70\n",
      "0.5427141152322292\n",
      "New best model found at epoch 70 with validation loss 0.522079586982727\n",
      "Starting Epoch 71\n",
      "0.5405337202052275\n",
      "Starting Epoch 72\n",
      "0.5406709102292856\n",
      "Starting Epoch 73\n",
      "0.5418129203220209\n",
      "New best model found at epoch 73 with validation loss 0.5215926170349121\n",
      "Starting Epoch 74\n",
      "0.5414239130914211\n",
      "Starting Epoch 75\n",
      "0.5419608888526758\n",
      "New best model found at epoch 75 with validation loss 0.5211650133132935\n",
      "Starting Epoch 76\n",
      "0.5403702594339848\n",
      "Starting Epoch 77\n",
      "0.5398167409002781\n",
      "Starting Epoch 78\n",
      "0.5420395483573278\n",
      "Starting Epoch 79\n",
      "0.5413377930720648\n",
      "New best model found at epoch 79 with validation loss 0.5182395577430725\n",
      "Starting Epoch 80\n",
      "0.5378121547400951\n",
      "New best model found at epoch 80 with validation loss 0.5176317691802979\n",
      "Starting Epoch 81\n",
      "0.5410701545576254\n",
      "Starting Epoch 82\n",
      "0.5427717107037703\n",
      "Starting Epoch 83\n",
      "0.5494880092640718\n",
      "Starting Epoch 84\n",
      "0.542391317586104\n",
      "Starting Epoch 85\n",
      "0.5419842104117075\n",
      "Starting Epoch 86\n",
      "0.5407632688681284\n",
      "Starting Epoch 87\n",
      "0.5392674046258131\n",
      "Starting Epoch 88\n",
      "0.5383418003718058\n",
      "Starting Epoch 89\n",
      "0.5401948342720667\n",
      "Starting Epoch 90\n",
      "0.5352872287233671\n",
      "Starting Epoch 91\n",
      "0.5376906593640646\n",
      "Starting Epoch 92\n",
      "0.5394707421461741\n",
      "Starting Epoch 93\n",
      "0.5392437266806761\n",
      "New best model found at epoch 93 with validation loss 0.5169386863708496\n",
      "Starting Epoch 94\n",
      "0.53786176815629\n",
      "Starting Epoch 95\n",
      "0.5399030148983002\n",
      "Starting Epoch 96\n",
      "0.5403727740049362\n",
      "Starting Epoch 97\n",
      "0.5424028399089972\n",
      "Starting Epoch 98\n",
      "0.5340654291212559\n",
      "Starting Epoch 99\n",
      "0.5391588844358921\n",
      "New best model found at epoch 99 with validation loss 0.5164401531219482\n",
      "Starting Epoch 100\n",
      "0.5368598277370135\n",
      "New best model found at epoch 100 with validation loss 0.5159448385238647\n",
      "Starting Epoch 101\n",
      "0.5404943898320198\n",
      "Starting Epoch 102\n",
      "0.5399913216630617\n",
      "Starting Epoch 103\n",
      "0.5380738067130247\n",
      "Starting Epoch 104\n",
      "0.5363324073453745\n",
      "Starting Epoch 105\n",
      "0.5395105456312498\n",
      "Starting Epoch 106\n",
      "0.5383177983264128\n",
      "Starting Epoch 107\n",
      "0.536241435756286\n",
      "Starting Epoch 108\n",
      "0.5384420193731785\n",
      "New best model found at epoch 108 with validation loss 0.5141942501068115\n",
      "Starting Epoch 109\n",
      "0.536393458644549\n",
      "Starting Epoch 110\n",
      "0.5389148717125257\n",
      "Starting Epoch 111\n",
      "0.5348059199750423\n",
      "Starting Epoch 112\n",
      "0.5370209068059921\n",
      "Starting Epoch 113\n",
      "0.5349643565714359\n",
      "Starting Epoch 114\n",
      "0.5356268261869749\n",
      "Starting Epoch 115\n",
      "0.537160862237215\n",
      "Starting Epoch 116\n",
      "0.5362295769155025\n",
      "Starting Epoch 117\n",
      "0.5352007386585077\n",
      "New best model found at epoch 117 with validation loss 0.5133615732192993\n",
      "Starting Epoch 118\n",
      "0.5384392117460569\n",
      "Starting Epoch 119\n",
      "0.5349798413614432\n",
      "Starting Epoch 120\n",
      "0.534351979692777\n",
      "Starting Epoch 121\n",
      "0.538633314271768\n",
      "Starting Epoch 122\n",
      "0.5360858738422394\n",
      "Starting Epoch 123\n",
      "0.5368126717706522\n",
      "Starting Epoch 124\n",
      "0.5364413820207119\n",
      "Starting Epoch 125\n",
      "0.5377602266768614\n",
      "New best model found at epoch 125 with validation loss 0.5127606987953186\n",
      "Starting Epoch 126\n",
      "0.5362713386615118\n",
      "Starting Epoch 127\n",
      "0.5361717157065868\n",
      "Starting Epoch 128\n",
      "0.5369932328661283\n",
      "Starting Epoch 129\n",
      "0.5342283671100935\n",
      "New best model found at epoch 129 with validation loss 0.5125471949577332\n",
      "Starting Epoch 130\n",
      "0.537217915058136\n",
      "Starting Epoch 131\n",
      "0.5367395381132761\n",
      "Starting Epoch 132\n",
      "0.5318708221117655\n",
      "Starting Epoch 133\n",
      "0.5381628957887491\n",
      "Starting Epoch 134\n",
      "0.5316460890074571\n",
      "Starting Epoch 135\n",
      "0.5357010588049889\n",
      "Starting Epoch 136\n",
      "0.5347118924061457\n",
      "Starting Epoch 137\n",
      "0.532402848203977\n",
      "Starting Epoch 138\n",
      "0.533396857480208\n",
      "New best model found at epoch 138 with validation loss 0.5120053887367249\n",
      "Starting Epoch 139\n",
      "0.5304313326875368\n",
      "Starting Epoch 140\n",
      "0.5342227307458719\n",
      "Starting Epoch 141\n",
      "0.531133438150088\n",
      "Starting Epoch 142\n",
      "0.5367234833538532\n",
      "Starting Epoch 143\n",
      "0.5358470330635706\n",
      "Starting Epoch 144\n",
      "0.5336241672436396\n",
      "Starting Epoch 145\n",
      "0.5325732852021853\n",
      "Starting Epoch 146\n",
      "0.5329432040452957\n",
      "New best model found at epoch 146 with validation loss 0.5117097496986389\n",
      "Starting Epoch 147\n",
      "0.5344420845309893\n",
      "Starting Epoch 148\n",
      "0.5366620309650898\n",
      "New best model found at epoch 148 with validation loss 0.5117058157920837\n",
      "Starting Epoch 149\n",
      "0.5340479699273905\n",
      "Starting Epoch 150\n",
      "0.5337590562800566\n",
      "Starting Epoch 151\n",
      "0.5364155396819115\n",
      "Starting Epoch 152\n",
      "0.533523345987002\n",
      "Starting Epoch 153\n",
      "0.5373050992687544\n",
      "Starting Epoch 154\n",
      "0.5298328138887882\n",
      "Starting Epoch 155\n",
      "0.5309679421285788\n",
      "Starting Epoch 156\n",
      "0.5333724791804949\n",
      "Starting Epoch 157\n",
      "0.53136782720685\n",
      "Starting Epoch 158\n",
      "0.5348344296216965\n",
      "Starting Epoch 159\n",
      "0.5361048951745033\n",
      "Starting Epoch 160\n",
      "0.5342895636955897\n",
      "Starting Epoch 161\n",
      "0.5322749502956867\n",
      "Starting Epoch 162\n",
      "0.5312232536574205\n",
      "Starting Epoch 163\n",
      "0.5350803310672442\n",
      "Starting Epoch 164\n",
      "0.5339678364495436\n",
      "Starting Epoch 165\n",
      "0.5313847648600737\n",
      "Starting Epoch 166\n",
      "0.5349145904183388\n",
      "Starting Epoch 167\n",
      "0.5333035426835219\n",
      "Starting Epoch 168\n",
      "0.5328268843392531\n",
      "Starting Epoch 169\n",
      "0.5338158694406351\n",
      "Starting Epoch 170\n",
      "0.5306185285250345\n",
      "Starting Epoch 171\n",
      "0.5330453117688497\n",
      "Starting Epoch 172\n",
      "0.5328457703193029\n",
      "Starting Epoch 173\n",
      "0.5354528501629829\n",
      "Starting Epoch 174\n",
      "0.5330289254585902\n",
      "Starting Epoch 175\n",
      "0.5354365569849809\n",
      "Starting Epoch 176\n",
      "0.5317591515680155\n",
      "New best model found at epoch 176 with validation loss 0.5109311938285828\n",
      "Starting Epoch 177\n",
      "0.5328132472932339\n",
      "Starting Epoch 178\n",
      "0.5332935253779093\n",
      "Starting Epoch 179\n",
      "0.531728790452083\n",
      "Starting Epoch 180\n",
      "0.5304967102905115\n",
      "Starting Epoch 181\n",
      "0.5337684651215872\n",
      "Starting Epoch 182\n",
      "0.5331170956293741\n",
      "Starting Epoch 183\n",
      "0.5342048729459444\n",
      "Starting Epoch 184\n",
      "0.5349461995065212\n",
      "Starting Epoch 185\n",
      "0.5363204441964626\n",
      "Starting Epoch 186\n",
      "0.5315563653906187\n",
      "Starting Epoch 187\n",
      "0.5319984741508961\n",
      "Starting Epoch 188\n",
      "0.5292247260610262\n",
      "Starting Epoch 189\n",
      "0.5316440599660078\n",
      "Starting Epoch 190\n",
      "0.5337590103348097\n",
      "Starting Epoch 191\n",
      "0.5319985623160998\n",
      "Starting Epoch 192\n",
      "0.5312411400179068\n",
      "Starting Epoch 193\n",
      "0.5318574582537016\n",
      "Starting Epoch 194\n",
      "0.5334841447571913\n",
      "Starting Epoch 195\n",
      "0.5349863146742185\n",
      "Starting Epoch 196\n",
      "0.5293766558170319\n",
      "Starting Epoch 197\n",
      "0.5313838260869185\n",
      "Starting Epoch 198\n",
      "0.5324419302244982\n",
      "Starting Epoch 199\n",
      "0.5296666684250037\n",
      "Starting Epoch 200\n",
      "0.5303743295371532\n",
      "Starting Epoch 201\n",
      "0.5308311904470125\n",
      "Starting Epoch 202\n",
      "0.5314423777163029\n",
      "Starting Epoch 203\n",
      "0.5300012876590093\n",
      "New best model found at epoch 203 with validation loss 0.5108864903450012\n",
      "Starting Epoch 204\n",
      "0.5337869773308436\n",
      "Starting Epoch 205\n",
      "0.5311833458642164\n",
      "Starting Epoch 206\n",
      "0.5333587663869063\n",
      "Starting Epoch 207\n",
      "0.5314479060471058\n",
      "Starting Epoch 208\n",
      "0.5317003453771273\n",
      "Starting Epoch 209\n",
      "0.5302475343147913\n",
      "Starting Epoch 210\n",
      "0.5307011517385641\n",
      "Starting Epoch 211\n",
      "0.5305763284365336\n",
      "Starting Epoch 212\n",
      "0.5308213320871195\n",
      "Starting Epoch 213\n",
      "0.5339575770000616\n",
      "Starting Epoch 214\n",
      "0.5307484033207098\n",
      "Starting Epoch 215\n",
      "0.5332053067783514\n",
      "Starting Epoch 216\n",
      "0.5307964930931727\n",
      "Starting Epoch 217\n",
      "0.5310808966557184\n",
      "Starting Epoch 218\n",
      "0.5309716910123825\n",
      "Starting Epoch 219\n",
      "0.5315964644153913\n",
      "Starting Epoch 220\n",
      "0.5313491821289062\n",
      "Starting Epoch 221\n",
      "0.529182189454635\n",
      "New best model found at epoch 221 with validation loss 0.5107550621032715\n",
      "Starting Epoch 222\n",
      "0.5312156230211258\n",
      "Starting Epoch 223\n",
      "0.5287733115255833\n",
      "Starting Epoch 224\n",
      "0.5303360472122828\n",
      "Starting Epoch 225\n",
      "0.5302053727209568\n",
      "Starting Epoch 226\n",
      "0.532765315224727\n",
      "Starting Epoch 227\n",
      "0.5328013474742571\n",
      "Starting Epoch 228\n",
      "0.5290714576840401\n",
      "New best model found at epoch 228 with validation loss 0.510576605796814\n",
      "Starting Epoch 229\n",
      "0.5296742382148901\n",
      "Starting Epoch 230\n",
      "0.5300359725952148\n",
      "New best model found at epoch 230 with validation loss 0.5103460550308228\n",
      "Starting Epoch 231\n",
      "0.5307626612484455\n",
      "Starting Epoch 232\n",
      "0.530374546845754\n",
      "Starting Epoch 233\n",
      "0.5336846113204956\n",
      "Starting Epoch 234\n",
      "0.5297824069857597\n",
      "Starting Epoch 235\n",
      "0.5310477887590727\n",
      "Starting Epoch 236\n",
      "0.529400609433651\n",
      "Starting Epoch 237\n",
      "0.5324728302657604\n",
      "Starting Epoch 238\n",
      "0.5324877214928468\n",
      "Starting Epoch 239\n",
      "0.5259135290980339\n",
      "Starting Epoch 240\n",
      "0.5305686506132284\n",
      "Starting Epoch 241\n",
      "0.5341980854670206\n",
      "Starting Epoch 242\n",
      "0.5330510226388773\n",
      "Starting Epoch 243\n",
      "0.5319578982889652\n",
      "Starting Epoch 244\n",
      "0.5303946547210217\n",
      "Starting Epoch 245\n",
      "0.531586109350125\n",
      "Starting Epoch 246\n",
      "0.5316681874295076\n",
      "Starting Epoch 247\n",
      "0.5341605221231779\n",
      "Starting Epoch 248\n",
      "0.5318612108627955\n",
      "New best model found at epoch 248 with validation loss 0.5102242231369019\n",
      "Starting Epoch 249\n",
      "0.5321485896905264\n",
      "Starting Epoch 250\n",
      "0.5299320109188557\n",
      "Starting Epoch 251\n",
      "0.5294683935741583\n",
      "Starting Epoch 252\n",
      "0.5317780214051405\n",
      "Starting Epoch 253\n",
      "0.5291695185005665\n",
      "Starting Epoch 254\n",
      "0.5326797341307005\n",
      "Starting Epoch 255\n",
      "0.5308272317051888\n",
      "Starting Epoch 256\n",
      "0.5333777045210203\n",
      "Starting Epoch 257\n",
      "0.530935600399971\n",
      "Starting Epoch 258\n",
      "0.5293107231458029\n",
      "Starting Epoch 259\n",
      "0.5310597755014896\n",
      "Starting Epoch 260\n",
      "0.5343724228441715\n",
      "Starting Epoch 261\n",
      "0.5302892252802849\n",
      "Starting Epoch 262\n",
      "0.5321182869374752\n",
      "Starting Epoch 263\n",
      "0.5300875802834829\n",
      "Starting Epoch 264\n",
      "0.5303990344206492\n",
      "Starting Epoch 265\n",
      "0.529703122874101\n",
      "Starting Epoch 266\n",
      "0.5312376680473486\n",
      "Starting Epoch 267\n",
      "0.5295359951754411\n",
      "Starting Epoch 268\n",
      "0.5293333021303018\n",
      "Starting Epoch 269\n",
      "0.529413491487503\n",
      "Starting Epoch 270\n",
      "0.5308213929335276\n",
      "Starting Epoch 271\n",
      "0.5309675708413124\n",
      "Starting Epoch 272\n",
      "0.5304719607035319\n",
      "Starting Epoch 273\n",
      "0.5331718487044176\n",
      "Starting Epoch 274\n",
      "0.530767735093832\n",
      "Starting Epoch 275\n",
      "0.5310872296492258\n",
      "Starting Epoch 276\n",
      "0.5293812640011311\n",
      "Starting Epoch 277\n",
      "0.5292009338736534\n",
      "Starting Epoch 278\n",
      "0.529931245992581\n",
      "Starting Epoch 279\n",
      "0.5314527278145155\n",
      "Starting Epoch 280\n",
      "0.5301581981281439\n",
      "Starting Epoch 281\n",
      "0.5315059709052244\n",
      "Starting Epoch 282\n",
      "0.5274820377429327\n",
      "New best model found at epoch 282 with validation loss 0.5102209448814392\n",
      "Starting Epoch 283\n",
      "0.5316132642328739\n",
      "New best model found at epoch 283 with validation loss 0.5101035833358765\n",
      "Starting Epoch 284\n",
      "0.5329153339068095\n",
      "Starting Epoch 285\n",
      "0.5288513327638308\n",
      "Starting Epoch 286\n",
      "0.531886987388134\n",
      "Starting Epoch 287\n",
      "0.5303179274002711\n",
      "Starting Epoch 288\n",
      "0.5315304895242056\n",
      "Starting Epoch 289\n",
      "0.5309733959535757\n",
      "Starting Epoch 290\n",
      "0.5315251238644123\n",
      "Starting Epoch 291\n",
      "0.5302457883954048\n",
      "Starting Epoch 292\n",
      "0.5302169248461723\n",
      "Starting Epoch 293\n",
      "0.5298610416551431\n",
      "Starting Epoch 294\n",
      "0.5298691131174564\n",
      "Starting Epoch 295\n",
      "0.5320424151917299\n",
      "Starting Epoch 296\n",
      "0.5300533113380274\n",
      "Starting Epoch 297\n",
      "0.5306227952241898\n",
      "Starting Epoch 298\n",
      "0.53172991797328\n",
      "Starting Epoch 299\n",
      "0.5290280605355898\n",
      "Starting Epoch 300\n",
      "0.5303139972190062\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-10-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb5bc2",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 3\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 20 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f136368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7a80c31c-648c-4d21-b93f-2d18462989a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.8416701331734657\n",
      "New best model found at epoch 1 with validation loss 0.5949550271034241\n",
      "Starting Epoch 2\n",
      "0.58680276821057\n",
      "New best model found at epoch 2 with validation loss 0.5853022933006287\n",
      "Starting Epoch 3\n",
      "0.5764506608247757\n",
      "New best model found at epoch 3 with validation loss 0.5711075663566589\n",
      "Starting Epoch 4\n",
      "0.574011966586113\n",
      "New best model found at epoch 4 with validation loss 0.5667930841445923\n",
      "Starting Epoch 5\n",
      "0.5738399041195711\n",
      "New best model found at epoch 5 with validation loss 0.5657443404197693\n",
      "Starting Epoch 6\n",
      "0.5726799157758554\n",
      "Starting Epoch 7\n",
      "0.5735275832315286\n",
      "Starting Epoch 8\n",
      "0.5768036283552647\n",
      "Starting Epoch 9\n",
      "0.5720806792378426\n",
      "New best model found at epoch 9 with validation loss 0.5620625615119934\n",
      "Starting Epoch 10\n",
      "0.5711871211727461\n",
      "Starting Epoch 11\n",
      "0.5698863801856836\n",
      "Starting Epoch 12\n",
      "0.5696451266606649\n",
      "New best model found at epoch 12 with validation loss 0.5586310625076294\n",
      "Starting Epoch 13\n",
      "0.5682104006409645\n",
      "Starting Epoch 14\n",
      "0.5694917713602384\n",
      "Starting Epoch 15\n",
      "0.5680216401815414\n",
      "New best model found at epoch 15 with validation loss 0.5543428063392639\n",
      "Starting Epoch 16\n",
      "0.5672324871023496\n",
      "Starting Epoch 17\n",
      "0.5665491546193758\n",
      "New best model found at epoch 17 with validation loss 0.554227888584137\n",
      "Starting Epoch 18\n",
      "0.5649352011581262\n",
      "New best model found at epoch 18 with validation loss 0.5534777045249939\n",
      "Starting Epoch 19\n",
      "0.5660926550626755\n",
      "New best model found at epoch 19 with validation loss 0.5530790090560913\n",
      "Starting Epoch 20\n",
      "0.5645965884129206\n",
      "Starting Epoch 21\n",
      "0.5661466519037882\n",
      "Starting Epoch 22\n",
      "0.5637402447561423\n",
      "Starting Epoch 23\n",
      "0.5629293993115425\n",
      "New best model found at epoch 23 with validation loss 0.5491002798080444\n",
      "Starting Epoch 24\n",
      "0.5635045741995176\n",
      "Starting Epoch 25\n",
      "0.5636764466762543\n",
      "Starting Epoch 26\n",
      "0.5618440980712572\n",
      "Starting Epoch 27\n",
      "0.5614851973950863\n",
      "New best model found at epoch 27 with validation loss 0.5467655062675476\n",
      "Starting Epoch 28\n",
      "0.5620586375395457\n",
      "New best model found at epoch 28 with validation loss 0.546044111251831\n",
      "Starting Epoch 29\n",
      "0.5604358837008476\n",
      "New best model found at epoch 29 with validation loss 0.542883038520813\n",
      "Starting Epoch 30\n",
      "0.5580737193425497\n",
      "Starting Epoch 31\n",
      "0.5610124530891577\n",
      "New best model found at epoch 31 with validation loss 0.5411074757575989\n",
      "Starting Epoch 32\n",
      "0.5584108854333559\n",
      "Starting Epoch 33\n",
      "0.5584425739943981\n",
      "Starting Epoch 34\n",
      "0.5589749204615752\n",
      "Starting Epoch 35\n",
      "0.5572464602688948\n",
      "Starting Epoch 36\n",
      "0.558951569100221\n",
      "New best model found at epoch 36 with validation loss 0.5401523113250732\n",
      "Starting Epoch 37\n",
      "0.5535677050550779\n",
      "Starting Epoch 38\n",
      "0.5553651787340641\n",
      "Starting Epoch 39\n",
      "0.5545305833220482\n",
      "Starting Epoch 40\n",
      "0.5534374838074049\n",
      "Starting Epoch 41\n",
      "0.553629902501901\n",
      "New best model found at epoch 41 with validation loss 0.5399810075759888\n",
      "Starting Epoch 42\n",
      "0.552582231660684\n",
      "New best model found at epoch 42 with validation loss 0.5385618209838867\n",
      "Starting Epoch 43\n",
      "0.5544437579810619\n",
      "Starting Epoch 44\n",
      "0.5530738346278667\n",
      "Starting Epoch 45\n",
      "0.5531525040666262\n",
      "Starting Epoch 46\n",
      "0.5527557159463564\n",
      "Starting Epoch 47\n",
      "0.5549359209835529\n",
      "Starting Epoch 48\n",
      "0.54886111865441\n",
      "New best model found at epoch 48 with validation loss 0.5377793312072754\n",
      "Starting Epoch 49\n",
      "0.551834678898255\n",
      "New best model found at epoch 49 with validation loss 0.534170925617218\n",
      "Starting Epoch 50\n",
      "0.5495577653249105\n",
      "Starting Epoch 51\n",
      "0.5519660400847594\n",
      "Starting Epoch 52\n",
      "0.5528438364466032\n",
      "Starting Epoch 53\n",
      "0.5486007779836655\n",
      "Starting Epoch 54\n",
      "0.5490834725399812\n",
      "Starting Epoch 55\n",
      "0.5495453948775927\n",
      "Starting Epoch 56\n",
      "0.5483920487264792\n",
      "Starting Epoch 57\n",
      "0.5486604236066341\n",
      "Starting Epoch 58\n",
      "0.5482186749577522\n",
      "Starting Epoch 59\n",
      "0.5469962184627851\n",
      "Starting Epoch 60\n",
      "0.5502956795195738\n",
      "Starting Epoch 61\n",
      "0.5486022221545378\n",
      "Starting Epoch 62\n",
      "0.5483528623978297\n",
      "Starting Epoch 63\n",
      "0.5458490736782551\n",
      "Starting Epoch 64\n",
      "0.5451292047897974\n",
      "New best model found at epoch 64 with validation loss 0.5322616100311279\n",
      "Starting Epoch 65\n",
      "0.5473074565331141\n",
      "Starting Epoch 66\n",
      "0.5463773074249426\n",
      "Starting Epoch 67\n",
      "0.5453746902445952\n",
      "Starting Epoch 68\n",
      "0.5469423892597357\n",
      "Starting Epoch 69\n",
      "0.5440925185879072\n",
      "Starting Epoch 70\n",
      "0.5439316232999166\n",
      "Starting Epoch 71\n",
      "0.5472859566410383\n",
      "Starting Epoch 72\n",
      "0.5432310725251833\n",
      "Starting Epoch 73\n",
      "0.543906919658184\n",
      "Starting Epoch 74\n",
      "0.545650627464056\n",
      "Starting Epoch 75\n",
      "0.5458043788870176\n",
      "Starting Epoch 76\n",
      "0.5454189044733843\n",
      "Starting Epoch 77\n",
      "0.5442746157447497\n",
      "Starting Epoch 78\n",
      "0.5423789049188296\n",
      "Starting Epoch 79\n",
      "0.5436601775387923\n",
      "Starting Epoch 80\n",
      "0.5443919425209364\n",
      "Starting Epoch 81\n",
      "0.5444937919576963\n",
      "Starting Epoch 82\n",
      "0.5415952913463116\n",
      "Starting Epoch 83\n",
      "0.5438767957190672\n",
      "Starting Epoch 84\n",
      "0.5404654132823149\n",
      "Starting Epoch 85\n",
      "0.5431171717743078\n",
      "Starting Epoch 86\n",
      "0.5427575546006361\n",
      "Starting Epoch 87\n",
      "0.5398406808574995\n",
      "Starting Epoch 88\n",
      "0.5414941844840845\n",
      "Starting Epoch 89\n",
      "0.5395544196168581\n",
      "Starting Epoch 90\n",
      "0.5419282192985216\n",
      "Starting Epoch 91\n",
      "0.5380771905183792\n",
      "Starting Epoch 92\n",
      "0.5427068894108137\n",
      "Starting Epoch 93\n",
      "0.5431422404944897\n",
      "Starting Epoch 94\n",
      "0.5408113052447637\n",
      "Starting Epoch 95\n",
      "0.53939305494229\n",
      "Starting Epoch 96\n",
      "0.5403010348478953\n",
      "Starting Epoch 97\n",
      "0.541250995049874\n",
      "Starting Epoch 98\n",
      "0.5396587550640106\n",
      "Starting Epoch 99\n",
      "0.5421887238820394\n",
      "Starting Epoch 100\n",
      "0.5394126921892166\n",
      "Starting Epoch 101\n",
      "0.5403730322917303\n",
      "Starting Epoch 102\n",
      "0.539553257326285\n",
      "Starting Epoch 103\n",
      "0.5420913199583689\n",
      "Starting Epoch 104\n",
      "0.5361428794761499\n",
      "Starting Epoch 105\n",
      "0.5365800919632117\n",
      "Starting Epoch 106\n",
      "0.537971576054891\n",
      "Starting Epoch 107\n",
      "0.5361301116645336\n",
      "Starting Epoch 108\n",
      "0.5399907131989797\n",
      "Starting Epoch 109\n",
      "0.5383231242497762\n",
      "Starting Epoch 110\n",
      "0.5379576347768307\n",
      "New best model found at epoch 110 with validation loss 0.5313299894332886\n",
      "Starting Epoch 111\n",
      "0.5362190492451191\n",
      "Starting Epoch 112\n",
      "0.5360656964282194\n",
      "Starting Epoch 113\n",
      "0.5367074124515057\n",
      "Starting Epoch 114\n",
      "0.5377064136167368\n",
      "Starting Epoch 115\n",
      "0.536361010124286\n",
      "Starting Epoch 116\n",
      "0.5385394680003325\n",
      "Starting Epoch 117\n",
      "0.5374651898940405\n",
      "Starting Epoch 118\n",
      "0.5360466130077839\n",
      "Starting Epoch 119\n",
      "0.5382976134618124\n",
      "Starting Epoch 120\n",
      "0.5352940956751505\n",
      "Starting Epoch 121\n",
      "0.5358389168977737\n",
      "Starting Epoch 122\n",
      "0.5357308934132258\n",
      "Starting Epoch 123\n",
      "0.5369324572384357\n",
      "Starting Epoch 124\n",
      "0.5373610394696394\n",
      "Starting Epoch 125\n",
      "0.5367419098814329\n",
      "Starting Epoch 126\n",
      "0.5353104745348295\n",
      "New best model found at epoch 126 with validation loss 0.5309878587722778\n",
      "Starting Epoch 127\n",
      "0.5367842776079973\n",
      "Starting Epoch 128\n",
      "0.536467100183169\n",
      "Starting Epoch 129\n",
      "0.5356865897774696\n",
      "Starting Epoch 130\n",
      "0.5361091494560242\n",
      "Starting Epoch 131\n",
      "0.536229650179545\n",
      "Starting Epoch 132\n",
      "0.5355327414969603\n",
      "Starting Epoch 133\n",
      "0.5373116806149483\n",
      "Starting Epoch 134\n",
      "0.5354952290654182\n",
      "Starting Epoch 135\n",
      "0.5376734559734663\n",
      "Starting Epoch 136\n",
      "0.5351217774053415\n",
      "Starting Epoch 137\n",
      "0.5354952265818914\n",
      "Starting Epoch 138\n",
      "0.5342975594103336\n",
      "Starting Epoch 139\n",
      "0.5342816698054472\n",
      "Starting Epoch 140\n",
      "0.5365330514808496\n",
      "Starting Epoch 141\n",
      "0.5342482527097067\n",
      "Starting Epoch 142\n",
      "0.5319882916907469\n",
      "Starting Epoch 143\n",
      "0.5364146729310354\n",
      "Starting Epoch 144\n",
      "0.5343848913908005\n",
      "Starting Epoch 145\n",
      "0.533728459229072\n",
      "Starting Epoch 146\n",
      "0.5326310557623705\n",
      "Starting Epoch 147\n",
      "0.5324275928239027\n",
      "Starting Epoch 148\n",
      "0.534195406983296\n",
      "Starting Epoch 149\n",
      "0.5316189887622992\n",
      "Starting Epoch 150\n",
      "0.5326021077732245\n",
      "Starting Epoch 151\n",
      "0.5320496981342634\n",
      "Starting Epoch 152\n",
      "0.5323668345808983\n",
      "Starting Epoch 153\n",
      "0.5317580675085386\n",
      "New best model found at epoch 153 with validation loss 0.5293766856193542\n",
      "Starting Epoch 154\n",
      "0.5345895004769167\n",
      "Starting Epoch 155\n",
      "0.5316629794736704\n",
      "Starting Epoch 156\n",
      "0.5335182646910349\n",
      "Starting Epoch 157\n",
      "0.5319986616571745\n",
      "Starting Epoch 158\n",
      "0.5339502717057864\n",
      "Starting Epoch 159\n",
      "0.5322840698063374\n",
      "Starting Epoch 160\n",
      "0.5315115389724573\n",
      "Starting Epoch 161\n",
      "0.5336829498410225\n",
      "Starting Epoch 162\n",
      "0.5301033395032088\n",
      "New best model found at epoch 162 with validation loss 0.5291489958763123\n",
      "Starting Epoch 163\n",
      "0.5342341686288515\n",
      "Starting Epoch 164\n",
      "0.5306824718912443\n",
      "Starting Epoch 165\n",
      "0.5322552161912123\n",
      "Starting Epoch 166\n",
      "0.5321360963086287\n",
      "New best model found at epoch 166 with validation loss 0.5279856324195862\n",
      "Starting Epoch 167\n",
      "0.5312696086863676\n",
      "Starting Epoch 168\n",
      "0.5316476052006086\n",
      "Starting Epoch 169\n",
      "0.5302284856637319\n",
      "Starting Epoch 170\n",
      "0.529693695406119\n",
      "Starting Epoch 171\n",
      "0.5301054492592812\n",
      "Starting Epoch 172\n",
      "0.5321831417580446\n",
      "Starting Epoch 173\n",
      "0.5297527437408766\n",
      "New best model found at epoch 173 with validation loss 0.5269696712493896\n",
      "Starting Epoch 174\n",
      "0.5293650863071283\n",
      "Starting Epoch 175\n",
      "0.5302065387368202\n",
      "Starting Epoch 176\n",
      "0.5319290831685066\n",
      "Starting Epoch 177\n",
      "0.5314512687424818\n",
      "Starting Epoch 178\n",
      "0.5296939772864183\n",
      "Starting Epoch 179\n",
      "0.5290512305994829\n",
      "Starting Epoch 180\n",
      "0.5288540124893188\n",
      "New best model found at epoch 180 with validation loss 0.5267704725265503\n",
      "Starting Epoch 181\n",
      "0.5298594683408737\n",
      "Starting Epoch 182\n",
      "0.5305869728326797\n",
      "Starting Epoch 183\n",
      "0.530523040642341\n",
      "Starting Epoch 184\n",
      "0.5291574274500211\n",
      "Starting Epoch 185\n",
      "0.5298177562654018\n",
      "Starting Epoch 186\n",
      "0.5288267210125923\n",
      "Starting Epoch 187\n",
      "0.5315978700915972\n",
      "Starting Epoch 188\n",
      "0.5321799851953983\n",
      "Starting Epoch 189\n",
      "0.5264148563146591\n",
      "Starting Epoch 190\n",
      "0.5291661111017069\n",
      "Starting Epoch 191\n",
      "0.5312087188164393\n",
      "Starting Epoch 192\n",
      "0.5316319825748602\n",
      "Starting Epoch 193\n",
      "0.5295772242049376\n",
      "Starting Epoch 194\n",
      "0.5286586532990137\n",
      "New best model found at epoch 194 with validation loss 0.5249333381652832\n",
      "Starting Epoch 195\n",
      "0.529657577474912\n",
      "New best model found at epoch 195 with validation loss 0.524648904800415\n",
      "Starting Epoch 196\n",
      "0.5300165203710397\n",
      "Starting Epoch 197\n",
      "0.5309344666699568\n",
      "Starting Epoch 198\n",
      "0.5284101851284504\n",
      "Starting Epoch 199\n",
      "0.5296747895578543\n",
      "New best model found at epoch 199 with validation loss 0.5233268737792969\n",
      "Starting Epoch 200\n",
      "0.5293442669014136\n",
      "Starting Epoch 201\n",
      "0.5273562843600909\n",
      "Starting Epoch 202\n",
      "0.5278577754894892\n",
      "Starting Epoch 203\n",
      "0.5281369835138321\n",
      "Starting Epoch 204\n",
      "0.5298593056698641\n",
      "Starting Epoch 205\n",
      "0.5285008996725082\n",
      "Starting Epoch 206\n",
      "0.5287545720736185\n",
      "Starting Epoch 207\n",
      "0.5261052337785562\n",
      "Starting Epoch 208\n",
      "0.5264915761848291\n",
      "Starting Epoch 209\n",
      "0.5296695878108343\n",
      "Starting Epoch 210\n",
      "0.5303427713612715\n",
      "Starting Epoch 211\n",
      "0.5277905911207199\n",
      "Starting Epoch 212\n",
      "0.5289958690603574\n",
      "New best model found at epoch 212 with validation loss 0.5219372510910034\n",
      "Starting Epoch 213\n",
      "0.5272598415613174\n",
      "Starting Epoch 214\n",
      "0.5276017052431902\n",
      "Starting Epoch 215\n",
      "0.5264386894802252\n",
      "New best model found at epoch 215 with validation loss 0.5217127203941345\n",
      "Starting Epoch 216\n",
      "0.5274964657922586\n",
      "Starting Epoch 217\n",
      "0.5257647633552551\n",
      "Starting Epoch 218\n",
      "0.5272213766972224\n",
      "Starting Epoch 219\n",
      "0.5268085263669491\n",
      "New best model found at epoch 219 with validation loss 0.5213882327079773\n",
      "Starting Epoch 220\n",
      "0.5269389760990938\n",
      "New best model found at epoch 220 with validation loss 0.5196951627731323\n",
      "Starting Epoch 221\n",
      "0.5279045576850573\n",
      "Starting Epoch 222\n",
      "0.5270487579206625\n",
      "Starting Epoch 223\n",
      "0.5276618724068006\n",
      "Starting Epoch 224\n",
      "0.5255535803735256\n",
      "Starting Epoch 225\n",
      "0.5288460279504458\n",
      "New best model found at epoch 225 with validation loss 0.5179707407951355\n",
      "Starting Epoch 226\n",
      "0.5252590750654539\n",
      "Starting Epoch 227\n",
      "0.5264023654162884\n",
      "Starting Epoch 228\n",
      "0.5256869321068128\n",
      "Starting Epoch 229\n",
      "0.525636742512385\n",
      "Starting Epoch 230\n",
      "0.5276186702152094\n",
      "Starting Epoch 231\n",
      "0.5285788091520468\n",
      "Starting Epoch 232\n",
      "0.5234112851321697\n",
      "New best model found at epoch 232 with validation loss 0.5168856978416443\n",
      "Starting Epoch 233\n",
      "0.5266534574329853\n",
      "Starting Epoch 234\n",
      "0.529179610311985\n",
      "Starting Epoch 235\n",
      "0.5243941160539786\n",
      "Starting Epoch 236\n",
      "0.526195116341114\n",
      "Starting Epoch 237\n",
      "0.5249789468944073\n",
      "Starting Epoch 238\n",
      "0.5255536809563637\n",
      "New best model found at epoch 238 with validation loss 0.5146801471710205\n",
      "Starting Epoch 239\n",
      "0.5246851829191049\n",
      "Starting Epoch 240\n",
      "0.5237465860942999\n",
      "Starting Epoch 241\n",
      "0.5198229899009069\n",
      "Starting Epoch 242\n",
      "0.520766926308473\n",
      "Starting Epoch 243\n",
      "0.5195163351794084\n",
      "New best model found at epoch 243 with validation loss 0.5118170976638794\n",
      "Starting Epoch 244\n",
      "0.5181662750740846\n",
      "Starting Epoch 245\n",
      "0.520097229629755\n",
      "New best model found at epoch 245 with validation loss 0.5093808770179749\n",
      "Starting Epoch 246\n",
      "0.5198043460647265\n",
      "Starting Epoch 247\n",
      "0.5160648909707864\n",
      "New best model found at epoch 247 with validation loss 0.5090384483337402\n",
      "Starting Epoch 248\n",
      "0.516411792486906\n",
      "New best model found at epoch 248 with validation loss 0.5080346465110779\n",
      "Starting Epoch 249\n",
      "0.5161164067685604\n",
      "Starting Epoch 250\n",
      "0.5173368627826372\n",
      "Starting Epoch 251\n",
      "0.516426062832276\n",
      "Starting Epoch 252\n",
      "0.518878078709046\n",
      "Starting Epoch 253\n",
      "0.5171804999311765\n",
      "Starting Epoch 254\n",
      "0.5167320606609186\n",
      "New best model found at epoch 254 with validation loss 0.506169319152832\n",
      "Starting Epoch 255\n",
      "0.5160468568404516\n",
      "Starting Epoch 256\n",
      "0.5151415591438612\n",
      "Starting Epoch 257\n",
      "0.5156318061053753\n",
      "New best model found at epoch 257 with validation loss 0.5053660869598389\n",
      "Starting Epoch 258\n",
      "0.5168574924270312\n",
      "Starting Epoch 259\n",
      "0.51602274676164\n",
      "Starting Epoch 260\n",
      "0.5160940599938234\n",
      "Starting Epoch 261\n",
      "0.5150242609282335\n",
      "Starting Epoch 262\n",
      "0.5134371047218641\n",
      "Starting Epoch 263\n",
      "0.5143552124500275\n",
      "New best model found at epoch 263 with validation loss 0.5046169757843018\n",
      "Starting Epoch 264\n",
      "0.5120260119438171\n",
      "Starting Epoch 265\n",
      "0.5127888942758242\n",
      "New best model found at epoch 265 with validation loss 0.5031808018684387\n",
      "Starting Epoch 266\n",
      "0.5120296701788902\n",
      "Starting Epoch 267\n",
      "0.5102794282138348\n",
      "Starting Epoch 268\n",
      "0.5134268403053284\n",
      "Starting Epoch 269\n",
      "0.5125393010675907\n",
      "New best model found at epoch 269 with validation loss 0.5021181106567383\n",
      "Starting Epoch 270\n",
      "0.5156624590357145\n",
      "Starting Epoch 271\n",
      "0.5143059579034647\n",
      "Starting Epoch 272\n",
      "0.5124582536518574\n",
      "Starting Epoch 273\n",
      "0.5142237929006418\n",
      "Starting Epoch 274\n",
      "0.5133363368610541\n",
      "Starting Epoch 275\n",
      "0.5104540561636289\n",
      "Starting Epoch 276\n",
      "0.5118387627104918\n",
      "Starting Epoch 277\n",
      "0.5114792908231417\n",
      "Starting Epoch 278\n",
      "0.514317919810613\n",
      "Starting Epoch 279\n",
      "0.512547659377257\n",
      "New best model found at epoch 279 with validation loss 0.5010619163513184\n",
      "Starting Epoch 280\n",
      "0.5115993445118269\n",
      "Starting Epoch 281\n",
      "0.5125111229717731\n",
      "Starting Epoch 282\n",
      "0.5124402965108553\n",
      "New best model found at epoch 282 with validation loss 0.5009511113166809\n",
      "Starting Epoch 283\n",
      "0.5112527857224146\n",
      "Starting Epoch 284\n",
      "0.5133870554467043\n",
      "Starting Epoch 285\n",
      "0.5121170518298944\n",
      "Starting Epoch 286\n",
      "0.5125038884580135\n",
      "Starting Epoch 287\n",
      "0.5103544096151987\n",
      "Starting Epoch 288\n",
      "0.5140633607904116\n",
      "Starting Epoch 289\n",
      "0.5117733081181844\n",
      "Starting Epoch 290\n",
      "0.5117984091242155\n",
      "Starting Epoch 291\n",
      "0.5113980968793234\n",
      "Starting Epoch 292\n",
      "0.5119632209340731\n",
      "Starting Epoch 293\n",
      "0.5108215597768625\n",
      "Starting Epoch 294\n",
      "0.5119257730742296\n",
      "Starting Epoch 295\n",
      "0.5112089576820532\n",
      "New best model found at epoch 295 with validation loss 0.5007359385490417\n",
      "Starting Epoch 296\n",
      "0.510955948382616\n",
      "Starting Epoch 297\n",
      "0.512622207403183\n",
      "Starting Epoch 298\n",
      "0.512033066401879\n",
      "Starting Epoch 299\n",
      "0.5126951647301515\n",
      "Starting Epoch 300\n",
      "0.5113852682212988\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-20-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a92759",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 4\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 25 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "927d5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a8765711-27a0-44fb-9644-1157f2252731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.9861047118902206\n",
      "New best model found at epoch 1 with validation loss 0.5878664255142212\n",
      "Starting Epoch 2\n",
      "0.6029275804758072\n",
      "New best model found at epoch 2 with validation loss 0.578240156173706\n",
      "Starting Epoch 3\n",
      "0.6018370091915131\n",
      "Starting Epoch 4\n",
      "0.5901985242962837\n",
      "New best model found at epoch 4 with validation loss 0.5651363134384155\n",
      "Starting Epoch 5\n",
      "0.5807055458426476\n",
      "New best model found at epoch 5 with validation loss 0.5611612796783447\n",
      "Starting Epoch 6\n",
      "0.5781910518805186\n",
      "Starting Epoch 7\n",
      "0.5798015718658766\n",
      "New best model found at epoch 7 with validation loss 0.5595408082008362\n",
      "Starting Epoch 8\n",
      "0.583001563946406\n",
      "Starting Epoch 9\n",
      "0.5744314876695474\n",
      "Starting Epoch 10\n",
      "0.5700258711973826\n",
      "New best model found at epoch 10 with validation loss 0.5566468834877014\n",
      "Starting Epoch 11\n",
      "0.5681091174483299\n",
      "Starting Epoch 12\n",
      "0.5659641089538733\n",
      "Starting Epoch 13\n",
      "0.5643705253799757\n",
      "New best model found at epoch 13 with validation loss 0.5524047017097473\n",
      "Starting Epoch 14\n",
      "0.5636328409115473\n",
      "Starting Epoch 15\n",
      "0.5600492196778456\n",
      "Starting Epoch 16\n",
      "0.5615382691224416\n",
      "New best model found at epoch 16 with validation loss 0.5510480403900146\n",
      "Starting Epoch 17\n",
      "0.562678744395574\n",
      "Starting Epoch 18\n",
      "0.5606504715979099\n",
      "New best model found at epoch 18 with validation loss 0.5461059808731079\n",
      "Starting Epoch 19\n",
      "0.5591327771544456\n",
      "Starting Epoch 20\n",
      "0.5610238860050837\n",
      "Starting Epoch 21\n",
      "0.5579721766213576\n",
      "Starting Epoch 22\n",
      "0.5613859531780084\n",
      "Starting Epoch 23\n",
      "0.5515931832293669\n",
      "New best model found at epoch 23 with validation loss 0.5423796772956848\n",
      "Starting Epoch 24\n",
      "0.5550682557125887\n",
      "New best model found at epoch 24 with validation loss 0.541736900806427\n",
      "Starting Epoch 25\n",
      "0.5543970180054506\n",
      "New best model found at epoch 25 with validation loss 0.5394428968429565\n",
      "Starting Epoch 26\n",
      "0.5566642892857393\n",
      "Starting Epoch 27\n",
      "0.5554922856390476\n",
      "Starting Epoch 28\n",
      "0.5521102448304495\n",
      "New best model found at epoch 28 with validation loss 0.5391265153884888\n",
      "Starting Epoch 29\n",
      "0.5495091316600641\n",
      "New best model found at epoch 29 with validation loss 0.5351095795631409\n",
      "Starting Epoch 30\n",
      "0.5521514701346556\n",
      "Starting Epoch 31\n",
      "0.5498707592487335\n",
      "Starting Epoch 32\n",
      "0.5483298612137636\n",
      "New best model found at epoch 32 with validation loss 0.5333507061004639\n",
      "Starting Epoch 33\n",
      "0.5493159927427769\n",
      "New best model found at epoch 33 with validation loss 0.5325442552566528\n",
      "Starting Epoch 34\n",
      "0.5485517804821333\n",
      "Starting Epoch 35\n",
      "0.5477970764040947\n",
      "Starting Epoch 36\n",
      "0.5440213419497013\n",
      "New best model found at epoch 36 with validation loss 0.5300567150115967\n",
      "Starting Epoch 37\n",
      "0.546865064650774\n",
      "Starting Epoch 38\n",
      "0.5428740965823332\n",
      "Starting Epoch 39\n",
      "0.5434051093955835\n",
      "New best model found at epoch 39 with validation loss 0.5269909501075745\n",
      "Starting Epoch 40\n",
      "0.5432349120577177\n",
      "Starting Epoch 41\n",
      "0.5437191799283028\n",
      "Starting Epoch 42\n",
      "0.5417454168200493\n",
      "Starting Epoch 43\n",
      "0.5453335419297218\n",
      "Starting Epoch 44\n",
      "0.5421031440297762\n",
      "New best model found at epoch 44 with validation loss 0.5267579555511475\n",
      "Starting Epoch 45\n",
      "0.5397928369541963\n",
      "New best model found at epoch 45 with validation loss 0.5255696773529053\n",
      "Starting Epoch 46\n",
      "0.5445431210100651\n",
      "Starting Epoch 47\n",
      "0.5416589081287384\n",
      "Starting Epoch 48\n",
      "0.5414184406399727\n",
      "Starting Epoch 49\n",
      "0.5414858621855577\n",
      "Starting Epoch 50\n",
      "0.5421715502937635\n",
      "New best model found at epoch 50 with validation loss 0.5244998335838318\n",
      "Starting Epoch 51\n",
      "0.5408940613269806\n",
      "Starting Epoch 52\n",
      "0.5404567644000053\n",
      "New best model found at epoch 52 with validation loss 0.5240042805671692\n",
      "Starting Epoch 53\n",
      "0.5417219723264376\n",
      "Starting Epoch 54\n",
      "0.5397550848623117\n",
      "New best model found at epoch 54 with validation loss 0.5234853029251099\n",
      "Starting Epoch 55\n",
      "0.5414708914856116\n",
      "Starting Epoch 56\n",
      "0.5405797846615314\n",
      "Starting Epoch 57\n",
      "0.5355029044051965\n",
      "Starting Epoch 58\n",
      "0.5423600996534029\n",
      "Starting Epoch 59\n",
      "0.5347422411044439\n",
      "Starting Epoch 60\n",
      "0.539615107079347\n",
      "Starting Epoch 61\n",
      "0.5381376085182031\n",
      "Starting Epoch 62\n",
      "0.5360548297564188\n",
      "New best model found at epoch 62 with validation loss 0.5212342739105225\n",
      "Starting Epoch 63\n",
      "0.537872721751531\n",
      "New best model found at epoch 63 with validation loss 0.519029438495636\n",
      "Starting Epoch 64\n",
      "0.534224059432745\n",
      "Starting Epoch 65\n",
      "0.5377446984251341\n",
      "Starting Epoch 66\n",
      "0.5333869854609171\n",
      "Starting Epoch 67\n",
      "0.5399276030560335\n",
      "Starting Epoch 68\n",
      "0.5381841858228048\n",
      "Starting Epoch 69\n",
      "0.5372873321175575\n",
      "Starting Epoch 70\n",
      "0.5353776874641577\n",
      "Starting Epoch 71\n",
      "0.5375249696274599\n",
      "Starting Epoch 72\n",
      "0.5369905096789201\n",
      "Starting Epoch 73\n",
      "0.5393904062608877\n",
      "Starting Epoch 74\n",
      "0.5365922674536705\n",
      "Starting Epoch 75\n",
      "0.5360173135995865\n",
      "Starting Epoch 76\n",
      "0.5395850775142511\n",
      "Starting Epoch 77\n",
      "0.5353037590781847\n",
      "Starting Epoch 78\n",
      "0.540013158073028\n",
      "Starting Epoch 79\n",
      "0.532146525879701\n",
      "Starting Epoch 80\n",
      "0.5329789357880751\n",
      "Starting Epoch 81\n",
      "0.5355163986484209\n",
      "Starting Epoch 82\n",
      "0.5333322795728842\n",
      "Starting Epoch 83\n",
      "0.5369028709828854\n",
      "Starting Epoch 84\n",
      "0.5376121948162714\n",
      "Starting Epoch 85\n",
      "0.5370396288732687\n",
      "Starting Epoch 86\n",
      "0.5341683377822241\n",
      "Starting Epoch 87\n",
      "0.533050370713075\n",
      "Starting Epoch 88\n",
      "0.537087960789601\n",
      "Starting Epoch 89\n",
      "0.53556681300203\n",
      "New best model found at epoch 89 with validation loss 0.5188090801239014\n",
      "Starting Epoch 90\n",
      "0.533670712262392\n",
      "Starting Epoch 91\n",
      "0.5360773193339506\n",
      "Starting Epoch 92\n",
      "0.5362499741216501\n",
      "Starting Epoch 93\n",
      "0.535490095615387\n",
      "Starting Epoch 94\n",
      "0.535133911917607\n",
      "Starting Epoch 95\n",
      "0.5324741154909134\n",
      "Starting Epoch 96\n",
      "0.5345195047557354\n",
      "Starting Epoch 97\n",
      "0.5346212560931841\n",
      "New best model found at epoch 97 with validation loss 0.5171655416488647\n",
      "Starting Epoch 98\n",
      "0.5367119970420996\n",
      "Starting Epoch 99\n",
      "0.5351842194795609\n",
      "Starting Epoch 100\n",
      "0.5371588468551636\n",
      "Starting Epoch 101\n",
      "0.5331847580770651\n",
      "New best model found at epoch 101 with validation loss 0.5152214765548706\n",
      "Starting Epoch 102\n",
      "0.5350399799644947\n",
      "Starting Epoch 103\n",
      "0.5346465110778809\n",
      "Starting Epoch 104\n",
      "0.5333868811527888\n",
      "Starting Epoch 105\n",
      "0.5320492684841156\n",
      "Starting Epoch 106\n",
      "0.5348336398601532\n",
      "Starting Epoch 107\n",
      "0.5344351331392924\n",
      "Starting Epoch 108\n",
      "0.5352533906698227\n",
      "Starting Epoch 109\n",
      "0.5356438606977463\n",
      "Starting Epoch 110\n",
      "0.5364001592000326\n",
      "Starting Epoch 111\n",
      "0.5330957807600498\n",
      "Starting Epoch 112\n",
      "0.5328563215831915\n",
      "Starting Epoch 113\n",
      "0.530060812830925\n",
      "Starting Epoch 114\n",
      "0.5328108444809914\n",
      "Starting Epoch 115\n",
      "0.5344268530607224\n",
      "Starting Epoch 116\n",
      "0.5322511394818624\n",
      "Starting Epoch 117\n",
      "0.5320721380412579\n",
      "Starting Epoch 118\n",
      "0.5328210294246674\n",
      "Starting Epoch 119\n",
      "0.5342605598270893\n",
      "Starting Epoch 120\n",
      "0.5357355910042921\n",
      "Starting Epoch 121\n",
      "0.5297860180338224\n",
      "Starting Epoch 122\n",
      "0.5313987794021765\n",
      "Starting Epoch 123\n",
      "0.5333239746590456\n",
      "Starting Epoch 124\n",
      "0.5307554764052232\n",
      "Starting Epoch 125\n",
      "0.5307976293067137\n",
      "Starting Epoch 126\n",
      "0.5311582585175832\n",
      "Starting Epoch 127\n",
      "0.5318470833202203\n",
      "Starting Epoch 128\n",
      "0.5310566003123919\n",
      "Starting Epoch 129\n",
      "0.5342556598285834\n",
      "Starting Epoch 130\n",
      "0.5312781929969788\n",
      "Starting Epoch 131\n",
      "0.5334101455907027\n",
      "Starting Epoch 132\n",
      "0.5316133623321851\n",
      "Starting Epoch 133\n",
      "0.5324614072839419\n",
      "Starting Epoch 134\n",
      "0.5302537505825361\n",
      "Starting Epoch 135\n",
      "0.5312030340234438\n",
      "Starting Epoch 136\n",
      "0.5307828436295191\n",
      "Starting Epoch 137\n",
      "0.5305887224773566\n",
      "New best model found at epoch 137 with validation loss 0.5146454572677612\n",
      "Starting Epoch 138\n",
      "0.5339564730723699\n",
      "Starting Epoch 139\n",
      "0.5308957571784655\n",
      "Starting Epoch 140\n",
      "0.5323773672183355\n",
      "Starting Epoch 141\n",
      "0.5317326088746389\n",
      "Starting Epoch 142\n",
      "0.5312280605236689\n",
      "Starting Epoch 143\n",
      "0.5313689348598322\n",
      "Starting Epoch 144\n",
      "0.5314804924031099\n",
      "Starting Epoch 145\n",
      "0.5305992712577184\n",
      "Starting Epoch 146\n",
      "0.529449749737978\n",
      "Starting Epoch 147\n",
      "0.531303291519483\n",
      "Starting Epoch 148\n",
      "0.528821550309658\n",
      "New best model found at epoch 148 with validation loss 0.5141499638557434\n",
      "Starting Epoch 149\n",
      "0.5298927165567875\n",
      "Starting Epoch 150\n",
      "0.5304231258730093\n",
      "Starting Epoch 151\n",
      "0.532658401876688\n",
      "Starting Epoch 152\n",
      "0.5326712292929491\n",
      "Starting Epoch 153\n",
      "0.5288040650387605\n",
      "Starting Epoch 154\n",
      "0.5293137058615685\n",
      "Starting Epoch 155\n",
      "0.5296306783954302\n",
      "New best model found at epoch 155 with validation loss 0.5125443339347839\n",
      "Starting Epoch 156\n",
      "0.5310943735142549\n",
      "Starting Epoch 157\n",
      "0.5298757789035639\n",
      "Starting Epoch 158\n",
      "0.5330461338162422\n",
      "Starting Epoch 159\n",
      "0.5298109402259191\n",
      "Starting Epoch 160\n",
      "0.5305206254124641\n",
      "Starting Epoch 161\n",
      "0.5287545112272104\n",
      "Starting Epoch 162\n",
      "0.532533078143994\n",
      "Starting Epoch 163\n",
      "0.5317434445023537\n",
      "Starting Epoch 164\n",
      "0.5262012109160423\n",
      "Starting Epoch 165\n",
      "0.5302332130571207\n",
      "Starting Epoch 166\n",
      "0.5327824242413044\n",
      "Starting Epoch 167\n",
      "0.5323128439486027\n",
      "Starting Epoch 168\n",
      "0.5304908603429794\n",
      "Starting Epoch 169\n",
      "0.5296859356264273\n",
      "Starting Epoch 170\n",
      "0.5307303679486116\n",
      "Starting Epoch 171\n",
      "0.5319719513257345\n",
      "Starting Epoch 172\n",
      "0.532570435355107\n",
      "Starting Epoch 173\n",
      "0.5306179871161779\n",
      "New best model found at epoch 173 with validation loss 0.5119265913963318\n",
      "Starting Epoch 174\n",
      "0.5311890356242657\n",
      "Starting Epoch 175\n",
      "0.5287457828720411\n",
      "Starting Epoch 176\n",
      "0.5277018422881762\n",
      "Starting Epoch 177\n",
      "0.5312350305418173\n",
      "Starting Epoch 178\n",
      "0.5277653560042381\n",
      "Starting Epoch 179\n",
      "0.5317233502864838\n",
      "Starting Epoch 180\n",
      "0.5293483920395374\n",
      "Starting Epoch 181\n",
      "0.5318630536397299\n",
      "Starting Epoch 182\n",
      "0.528791985164086\n",
      "Starting Epoch 183\n",
      "0.5271167221168677\n",
      "Starting Epoch 184\n",
      "0.5292466518779596\n",
      "Starting Epoch 185\n",
      "0.5325489876170953\n",
      "Starting Epoch 186\n",
      "0.5277659843365351\n",
      "Starting Epoch 187\n",
      "0.529777372876803\n",
      "Starting Epoch 188\n",
      "0.5285166849692663\n",
      "Starting Epoch 189\n",
      "0.5278771718343099\n",
      "Starting Epoch 190\n",
      "0.5269201099872589\n",
      "Starting Epoch 191\n",
      "0.5285364252825578\n",
      "Starting Epoch 192\n",
      "0.5265427144865195\n",
      "Starting Epoch 193\n",
      "0.5263708494603634\n",
      "Starting Epoch 194\n",
      "0.5275530628859997\n",
      "Starting Epoch 195\n",
      "0.5283828154206276\n",
      "Starting Epoch 196\n",
      "0.5278547070920467\n",
      "Starting Epoch 197\n",
      "0.5273966950674852\n",
      "Starting Epoch 198\n",
      "0.5291405941049258\n",
      "Starting Epoch 199\n",
      "0.5272610659400622\n",
      "Starting Epoch 200\n",
      "0.5273928691943487\n",
      "Starting Epoch 201\n",
      "0.5259706142048041\n",
      "Starting Epoch 202\n",
      "0.5256894392271837\n",
      "Starting Epoch 203\n",
      "0.5260420702397823\n",
      "Starting Epoch 204\n",
      "0.5276299826800823\n",
      "Starting Epoch 205\n",
      "0.526442140340805\n",
      "Starting Epoch 206\n",
      "0.5279820536573728\n",
      "Starting Epoch 207\n",
      "0.5234756010274092\n",
      "New best model found at epoch 207 with validation loss 0.5102232694625854\n",
      "Starting Epoch 208\n",
      "0.5277141506473223\n",
      "Starting Epoch 209\n",
      "0.5296660823126634\n",
      "Starting Epoch 210\n",
      "0.5252237319946289\n",
      "Starting Epoch 211\n",
      "0.5278688160081705\n",
      "Starting Epoch 212\n",
      "0.5264645218849182\n",
      "Starting Epoch 213\n",
      "0.5275962998469671\n",
      "New best model found at epoch 213 with validation loss 0.5100018978118896\n",
      "Starting Epoch 214\n",
      "0.5258140477041403\n",
      "Starting Epoch 215\n",
      "0.5267936574916045\n",
      "Starting Epoch 216\n",
      "0.525737593571345\n",
      "Starting Epoch 217\n",
      "0.5262375175952911\n",
      "Starting Epoch 218\n",
      "0.5247496391336123\n",
      "Starting Epoch 219\n",
      "0.5253847166895866\n",
      "Starting Epoch 220\n",
      "0.5277165534595648\n",
      "Starting Epoch 221\n",
      "0.5251998417079449\n",
      "Starting Epoch 222\n",
      "0.5257920883595943\n",
      "Starting Epoch 223\n",
      "0.5271948191026846\n",
      "Starting Epoch 224\n",
      "0.524110708385706\n",
      "Starting Epoch 225\n",
      "0.5260183364152908\n",
      "Starting Epoch 226\n",
      "0.5254265405237675\n",
      "Starting Epoch 227\n",
      "0.5284603014588356\n",
      "Starting Epoch 228\n",
      "0.5276236174007257\n",
      "Starting Epoch 229\n",
      "0.5267567150294781\n",
      "Starting Epoch 230\n",
      "0.5256623178720474\n",
      "Starting Epoch 231\n",
      "0.5255536151429018\n",
      "Starting Epoch 232\n",
      "0.5253482659657797\n",
      "Starting Epoch 233\n",
      "0.5269526578485966\n",
      "Starting Epoch 234\n",
      "0.5268223869303862\n",
      "Starting Epoch 235\n",
      "0.5248489677906036\n",
      "Starting Epoch 236\n",
      "0.5250288024544716\n",
      "Starting Epoch 237\n",
      "0.5242483528951803\n",
      "Starting Epoch 238\n",
      "0.5257182978093624\n",
      "Starting Epoch 239\n",
      "0.5247588393588861\n",
      "Starting Epoch 240\n",
      "0.5239251827200254\n",
      "Starting Epoch 241\n",
      "0.5235406421124935\n",
      "Starting Epoch 242\n",
      "0.5204069490234057\n",
      "Starting Epoch 243\n",
      "0.5257599813242754\n",
      "Starting Epoch 244\n",
      "0.5230336785316467\n",
      "Starting Epoch 245\n",
      "0.5265427082777023\n",
      "Starting Epoch 246\n",
      "0.5257941099504629\n",
      "Starting Epoch 247\n",
      "0.5244696736335754\n",
      "Starting Epoch 248\n",
      "0.5246965835491816\n",
      "Starting Epoch 249\n",
      "0.5236520816882452\n",
      "Starting Epoch 250\n",
      "0.5231743405262629\n",
      "Starting Epoch 251\n",
      "0.5217018115023772\n",
      "Starting Epoch 252\n",
      "0.5217578336596489\n",
      "Starting Epoch 253\n",
      "0.5252069967488447\n",
      "Starting Epoch 254\n",
      "0.5212570913136005\n",
      "Starting Epoch 255\n",
      "0.5243672740956148\n",
      "Starting Epoch 256\n",
      "0.5257570197184881\n",
      "New best model found at epoch 256 with validation loss 0.5086648464202881\n",
      "Starting Epoch 257\n",
      "0.5239216387271881\n",
      "Starting Epoch 258\n",
      "0.5219648505250613\n",
      "Starting Epoch 259\n",
      "0.5263329657415549\n",
      "Starting Epoch 260\n",
      "0.5236301744977633\n",
      "Starting Epoch 261\n",
      "0.5257999586562315\n",
      "Starting Epoch 262\n",
      "0.5209912570814291\n",
      "Starting Epoch 263\n",
      "0.5248099491000175\n",
      "Starting Epoch 264\n",
      "0.5245950805644194\n",
      "Starting Epoch 265\n",
      "0.5223487131297588\n",
      "Starting Epoch 266\n",
      "0.5249250506361326\n",
      "Starting Epoch 267\n",
      "0.5235793764392535\n",
      "Starting Epoch 268\n",
      "0.521035602937142\n",
      "Starting Epoch 269\n",
      "0.5238696833451589\n",
      "Starting Epoch 270\n",
      "0.5223631163438162\n",
      "Starting Epoch 271\n",
      "0.5232421656449636\n",
      "Starting Epoch 272\n",
      "0.5257310767968496\n",
      "Starting Epoch 273\n",
      "0.5221102821330229\n",
      "Starting Epoch 274\n",
      "0.5242914805809656\n",
      "Starting Epoch 275\n",
      "0.5226018155614535\n",
      "Starting Epoch 276\n",
      "0.5223885190983614\n",
      "Starting Epoch 277\n",
      "0.5235069046417872\n",
      "Starting Epoch 278\n",
      "0.5225646408895651\n",
      "Starting Epoch 279\n",
      "0.5213915506998698\n",
      "Starting Epoch 280\n",
      "0.5210959861675898\n",
      "Starting Epoch 281\n",
      "0.5233382893105348\n",
      "Starting Epoch 282\n",
      "0.5239760503172874\n",
      "Starting Epoch 283\n",
      "0.5227721060315768\n",
      "Starting Epoch 284\n",
      "0.5208890674014887\n",
      "Starting Epoch 285\n",
      "0.52581183736523\n",
      "Starting Epoch 286\n",
      "0.5233160890638828\n",
      "Starting Epoch 287\n",
      "0.5233323983848095\n",
      "Starting Epoch 288\n",
      "0.5237453108032545\n",
      "Starting Epoch 289\n",
      "0.5213311935464541\n",
      "Starting Epoch 290\n",
      "0.5220856542388598\n",
      "Starting Epoch 291\n",
      "0.5221052827934424\n",
      "Starting Epoch 292\n",
      "0.5218735734621683\n",
      "Starting Epoch 293\n",
      "0.5258150560160478\n",
      "Starting Epoch 294\n",
      "0.5219196751713753\n",
      "Starting Epoch 295\n",
      "0.5217394158244133\n",
      "Starting Epoch 296\n",
      "0.5205140188336372\n",
      "Starting Epoch 297\n",
      "0.5199115164577961\n",
      "Starting Epoch 298\n",
      "0.5207031046350797\n",
      "New best model found at epoch 298 with validation loss 0.5084053874015808\n",
      "Starting Epoch 299\n",
      "0.5210636258125305\n",
      "Starting Epoch 300\n",
      "0.5200951620936394\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-25-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc213ca",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 5\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 40 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9349cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "983da5a7-0ce7-4477-b50a-d0549e013c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.485403761267662\n",
      "New best model found at epoch 1 with validation loss 0.6645243763923645\n",
      "Starting Epoch 2\n",
      "0.6223328510920206\n",
      "New best model found at epoch 2 with validation loss 0.5846708416938782\n",
      "Starting Epoch 3\n",
      "0.6115364183982214\n",
      "Starting Epoch 4\n",
      "0.6007194047172865\n",
      "New best model found at epoch 4 with validation loss 0.5759806632995605\n",
      "Starting Epoch 5\n",
      "0.5913672174016634\n",
      "Starting Epoch 6\n",
      "0.5977613230546316\n",
      "New best model found at epoch 6 with validation loss 0.5735726356506348\n",
      "Starting Epoch 7\n",
      "0.5858812009294828\n",
      "Starting Epoch 8\n",
      "0.588665978362163\n",
      "Starting Epoch 9\n",
      "0.5885333592693011\n",
      "New best model found at epoch 9 with validation loss 0.5712106227874756\n",
      "Starting Epoch 10\n",
      "0.5823734849691391\n",
      "New best model found at epoch 10 with validation loss 0.5645089149475098\n",
      "Starting Epoch 11\n",
      "0.5794079775611559\n",
      "Starting Epoch 12\n",
      "0.572603822996219\n",
      "Starting Epoch 13\n",
      "0.5770689360797405\n",
      "Starting Epoch 14\n",
      "0.5711359803875288\n",
      "New best model found at epoch 14 with validation loss 0.5581913590431213\n",
      "Starting Epoch 15\n",
      "0.5682248324155807\n",
      "New best model found at epoch 15 with validation loss 0.5571621060371399\n",
      "Starting Epoch 16\n",
      "0.5650635485847791\n",
      "Starting Epoch 17\n",
      "0.5680747504035631\n",
      "Starting Epoch 18\n",
      "0.5630509480834007\n",
      "New best model found at epoch 18 with validation loss 0.556520938873291\n",
      "Starting Epoch 19\n",
      "0.5621075195570787\n",
      "New best model found at epoch 19 with validation loss 0.5550108551979065\n",
      "Starting Epoch 20\n",
      "0.5587876451512178\n",
      "Starting Epoch 21\n",
      "0.5605176438887914\n",
      "New best model found at epoch 21 with validation loss 0.5546998977661133\n",
      "Starting Epoch 22\n",
      "0.5574091300368309\n",
      "New best model found at epoch 22 with validation loss 0.5541926026344299\n",
      "Starting Epoch 23\n",
      "0.561368907491366\n",
      "Starting Epoch 24\n",
      "0.5580029574533304\n",
      "Starting Epoch 25\n",
      "0.5615078856547674\n",
      "New best model found at epoch 25 with validation loss 0.5534509420394897\n",
      "Starting Epoch 26\n",
      "0.5541629269719124\n",
      "New best model found at epoch 26 with validation loss 0.5500326156616211\n",
      "Starting Epoch 27\n",
      "0.5554297429819902\n",
      "Starting Epoch 28\n",
      "0.5541164974371592\n",
      "Starting Epoch 29\n",
      "0.5531296456853548\n",
      "Starting Epoch 30\n",
      "0.5496197938919067\n",
      "Starting Epoch 31\n",
      "0.5528446659445763\n",
      "Starting Epoch 32\n",
      "0.5506522158781687\n",
      "Starting Epoch 33\n",
      "0.5516412270565828\n",
      "New best model found at epoch 33 with validation loss 0.5478692054748535\n",
      "Starting Epoch 34\n",
      "0.5520953983068466\n",
      "Starting Epoch 35\n",
      "0.5543436259031296\n",
      "Starting Epoch 36\n",
      "0.5486709276835123\n",
      "New best model found at epoch 36 with validation loss 0.5464797019958496\n",
      "Starting Epoch 37\n",
      "0.5466814835866293\n",
      "Starting Epoch 38\n",
      "0.5424469908078512\n",
      "Starting Epoch 39\n",
      "0.5441522262990475\n",
      "Starting Epoch 40\n",
      "0.5473580919206142\n",
      "Starting Epoch 41\n",
      "0.5453570646544298\n",
      "Starting Epoch 42\n",
      "0.5458863663176695\n",
      "Starting Epoch 43\n",
      "0.5445648469030857\n",
      "Starting Epoch 44\n",
      "0.5456885620951653\n",
      "Starting Epoch 45\n",
      "0.5493644438683987\n",
      "Starting Epoch 46\n",
      "0.5403226626416048\n",
      "Starting Epoch 47\n",
      "0.5436908987661203\n",
      "New best model found at epoch 47 with validation loss 0.545717179775238\n",
      "Starting Epoch 48\n",
      "0.5415501222014427\n",
      "Starting Epoch 49\n",
      "0.5403341402610143\n",
      "Starting Epoch 50\n",
      "0.5442915844420592\n",
      "Starting Epoch 51\n",
      "0.5410089107851187\n",
      "Starting Epoch 52\n",
      "0.5395680256187916\n",
      "Starting Epoch 53\n",
      "0.5379790303607782\n",
      "Starting Epoch 54\n",
      "0.54398670916756\n",
      "New best model found at epoch 54 with validation loss 0.5455266237258911\n",
      "Starting Epoch 55\n",
      "0.5390774334470431\n",
      "Starting Epoch 56\n",
      "0.541647057980299\n",
      "New best model found at epoch 56 with validation loss 0.5447208881378174\n",
      "Starting Epoch 57\n",
      "0.5391051868597666\n",
      "New best model found at epoch 57 with validation loss 0.5447074770927429\n",
      "Starting Epoch 58\n",
      "0.5402265985806783\n",
      "Starting Epoch 59\n",
      "0.5389212829371294\n",
      "Starting Epoch 60\n",
      "0.5377860143780708\n",
      "Starting Epoch 61\n",
      "0.538411288211743\n",
      "Starting Epoch 62\n",
      "0.5390693495670954\n",
      "New best model found at epoch 62 with validation loss 0.5446322560310364\n",
      "Starting Epoch 63\n",
      "0.5420001136759917\n",
      "Starting Epoch 64\n",
      "0.538807878891627\n",
      "Starting Epoch 65\n",
      "0.5406278210381666\n",
      "Starting Epoch 66\n",
      "0.5399941342572371\n",
      "Starting Epoch 67\n",
      "0.5398907077809175\n",
      "Starting Epoch 68\n",
      "0.5375330572326978\n",
      "Starting Epoch 69\n",
      "0.5393836349248886\n",
      "Starting Epoch 70\n",
      "0.5367625442643961\n",
      "Starting Epoch 71\n",
      "0.5358294894297918\n",
      "Starting Epoch 72\n",
      "0.5386221408843994\n",
      "Starting Epoch 73\n",
      "0.5363475394745668\n",
      "Starting Epoch 74\n",
      "0.5366326421499252\n",
      "Starting Epoch 75\n",
      "0.5382550122837225\n",
      "Starting Epoch 76\n",
      "0.539923674116532\n",
      "Starting Epoch 77\n",
      "0.5400524400174618\n",
      "Starting Epoch 78\n",
      "0.5348342880606651\n",
      "New best model found at epoch 78 with validation loss 0.543258547782898\n",
      "Starting Epoch 79\n",
      "0.5366226894160112\n",
      "Starting Epoch 80\n",
      "0.5345875310401121\n",
      "Starting Epoch 81\n",
      "0.5377753178278605\n",
      "Starting Epoch 82\n",
      "0.5353449036677679\n",
      "Starting Epoch 83\n",
      "0.5412247131268183\n",
      "Starting Epoch 84\n",
      "0.5368585214018822\n",
      "Starting Epoch 85\n",
      "0.5359658760329088\n",
      "Starting Epoch 86\n",
      "0.534179205695788\n",
      "Starting Epoch 87\n",
      "0.5400545733670393\n",
      "Starting Epoch 88\n",
      "0.5374226073424021\n",
      "New best model found at epoch 88 with validation loss 0.5429231524467468\n",
      "Starting Epoch 89\n",
      "0.5321631406744322\n",
      "Starting Epoch 90\n",
      "0.5363486036658287\n",
      "Starting Epoch 91\n",
      "0.5378411660591761\n",
      "New best model found at epoch 91 with validation loss 0.5424583554267883\n",
      "Starting Epoch 92\n",
      "0.5366798142592112\n",
      "New best model found at epoch 92 with validation loss 0.5423281192779541\n",
      "Starting Epoch 93\n",
      "0.5350784212350845\n",
      "Starting Epoch 94\n",
      "0.5342948623001575\n",
      "New best model found at epoch 94 with validation loss 0.540391743183136\n",
      "Starting Epoch 95\n",
      "0.5343701156477133\n",
      "Starting Epoch 96\n",
      "0.5369593414167563\n",
      "Starting Epoch 97\n",
      "0.5379417054355145\n",
      "Starting Epoch 98\n",
      "0.5343051490684351\n",
      "New best model found at epoch 98 with validation loss 0.5393567085266113\n",
      "Starting Epoch 99\n",
      "0.536005233724912\n",
      "Starting Epoch 100\n",
      "0.5344848024348418\n",
      "Starting Epoch 101\n",
      "0.5329506310323874\n",
      "Starting Epoch 102\n",
      "0.5355973901847998\n",
      "Starting Epoch 103\n",
      "0.5322308527926604\n",
      "Starting Epoch 104\n",
      "0.5349235907196999\n",
      "Starting Epoch 105\n",
      "0.5329223535954952\n",
      "New best model found at epoch 105 with validation loss 0.5391252040863037\n",
      "Starting Epoch 106\n",
      "0.5367168734471003\n",
      "Starting Epoch 107\n",
      "0.5324328939119974\n",
      "Starting Epoch 108\n",
      "0.5324913039803505\n",
      "New best model found at epoch 108 with validation loss 0.53877854347229\n",
      "Starting Epoch 109\n",
      "0.5350512936711311\n",
      "Starting Epoch 110\n",
      "0.5372901459534963\n",
      "Starting Epoch 111\n",
      "0.5311874759693941\n",
      "Starting Epoch 112\n",
      "0.5348151115079721\n",
      "New best model found at epoch 112 with validation loss 0.5380638837814331\n",
      "Starting Epoch 113\n",
      "0.532873143752416\n",
      "Starting Epoch 114\n",
      "0.5328756471474966\n",
      "Starting Epoch 115\n",
      "0.5312924037377039\n",
      "Starting Epoch 116\n",
      "0.533879179507494\n",
      "Starting Epoch 117\n",
      "0.5305300342539946\n",
      "Starting Epoch 118\n",
      "0.5316278686126074\n",
      "Starting Epoch 119\n",
      "0.53171123812596\n",
      "Starting Epoch 120\n",
      "0.5332807985444864\n",
      "New best model found at epoch 120 with validation loss 0.5378072261810303\n",
      "Starting Epoch 121\n",
      "0.5322638601064682\n",
      "Starting Epoch 122\n",
      "0.5329491955538591\n",
      "Starting Epoch 123\n",
      "0.5334137169023355\n",
      "New best model found at epoch 123 with validation loss 0.5377939343452454\n",
      "Starting Epoch 124\n",
      "0.531197669605414\n",
      "New best model found at epoch 124 with validation loss 0.5377074480056763\n",
      "Starting Epoch 125\n",
      "0.5315319548050562\n",
      "Starting Epoch 126\n",
      "0.5296882763504982\n",
      "Starting Epoch 127\n",
      "0.5308903952439626\n",
      "Starting Epoch 128\n",
      "0.5332816590865453\n",
      "Starting Epoch 129\n",
      "0.53128573919336\n",
      "New best model found at epoch 129 with validation loss 0.5373008251190186\n",
      "Starting Epoch 130\n",
      "0.5312990546226501\n",
      "Starting Epoch 131\n",
      "0.5329714231193066\n",
      "Starting Epoch 132\n",
      "0.5296337207158407\n",
      "Starting Epoch 133\n",
      "0.5327178264657656\n",
      "New best model found at epoch 133 with validation loss 0.5366925597190857\n",
      "Starting Epoch 134\n",
      "0.5352332592010498\n",
      "Starting Epoch 135\n",
      "0.5306009190777937\n",
      "Starting Epoch 136\n",
      "0.5311571409304937\n",
      "Starting Epoch 137\n",
      "0.5305621375640234\n",
      "New best model found at epoch 137 with validation loss 0.5366239547729492\n",
      "Starting Epoch 138\n",
      "0.5318395954867204\n",
      "New best model found at epoch 138 with validation loss 0.536002516746521\n",
      "Starting Epoch 139\n",
      "0.5313874346514543\n",
      "Starting Epoch 140\n",
      "0.5321820589403311\n",
      "Starting Epoch 141\n",
      "0.5304977533717951\n",
      "Starting Epoch 142\n",
      "0.5309039428830147\n",
      "Starting Epoch 143\n",
      "0.530676414569219\n",
      "Starting Epoch 144\n",
      "0.5310940543810526\n",
      "Starting Epoch 145\n",
      "0.5335870310664177\n",
      "Starting Epoch 146\n",
      "0.5303969768186411\n",
      "Starting Epoch 147\n",
      "0.5297820369402567\n",
      "New best model found at epoch 147 with validation loss 0.5356946587562561\n",
      "Starting Epoch 148\n",
      "0.532386552542448\n",
      "Starting Epoch 149\n",
      "0.5287517284353574\n",
      "Starting Epoch 150\n",
      "0.530478335916996\n",
      "Starting Epoch 151\n",
      "0.5309765661756197\n",
      "Starting Epoch 152\n",
      "0.5335337941845258\n",
      "Starting Epoch 153\n",
      "0.5325583356122175\n",
      "Starting Epoch 154\n",
      "0.5316737455626329\n",
      "New best model found at epoch 154 with validation loss 0.5349763631820679\n",
      "Starting Epoch 155\n",
      "0.5303213695685068\n",
      "Starting Epoch 156\n",
      "0.5305936709046364\n",
      "New best model found at epoch 156 with validation loss 0.5348832011222839\n",
      "Starting Epoch 157\n",
      "0.5310381303230921\n",
      "New best model found at epoch 157 with validation loss 0.5344128608703613\n",
      "Starting Epoch 158\n",
      "0.5328732008735338\n",
      "Starting Epoch 159\n",
      "0.5321354096134504\n",
      "Starting Epoch 160\n",
      "0.5305145444969336\n",
      "Starting Epoch 161\n",
      "0.5295961797237396\n",
      "Starting Epoch 162\n",
      "0.5297977663576603\n",
      "Starting Epoch 163\n",
      "0.5318130068480968\n",
      "Starting Epoch 164\n",
      "0.5298845581710339\n",
      "Starting Epoch 165\n",
      "0.5289170369505882\n",
      "Starting Epoch 166\n",
      "0.5287115263442198\n",
      "Starting Epoch 167\n",
      "0.5264091305434704\n",
      "New best model found at epoch 167 with validation loss 0.5334306955337524\n",
      "Starting Epoch 168\n",
      "0.5300717428326607\n",
      "Starting Epoch 169\n",
      "0.5292780920863152\n",
      "Starting Epoch 170\n",
      "0.532822405298551\n",
      "Starting Epoch 171\n",
      "0.5295416004955769\n",
      "Starting Epoch 172\n",
      "0.5290010571479797\n",
      "Starting Epoch 173\n",
      "0.530467726290226\n",
      "Starting Epoch 174\n",
      "0.5295424001912276\n",
      "Starting Epoch 175\n",
      "0.528213140865167\n",
      "Starting Epoch 176\n",
      "0.5269944928586483\n",
      "Starting Epoch 177\n",
      "0.5263862982392311\n",
      "Starting Epoch 178\n",
      "0.5314530606071154\n",
      "New best model found at epoch 178 with validation loss 0.5333265662193298\n",
      "Starting Epoch 179\n",
      "0.5273023458818594\n",
      "Starting Epoch 180\n",
      "0.5294666898747286\n",
      "Starting Epoch 181\n",
      "0.5311915638546149\n",
      "New best model found at epoch 181 with validation loss 0.532693088054657\n",
      "Starting Epoch 182\n",
      "0.5287608491877714\n",
      "Starting Epoch 183\n",
      "0.5272713166972002\n",
      "Starting Epoch 184\n",
      "0.5303879727919897\n",
      "Starting Epoch 185\n",
      "0.5271660660703977\n",
      "Starting Epoch 186\n",
      "0.530493825674057\n",
      "Starting Epoch 187\n",
      "0.5268927191694578\n",
      "New best model found at epoch 187 with validation loss 0.5324687361717224\n",
      "Starting Epoch 188\n",
      "0.5302993518610796\n",
      "Starting Epoch 189\n",
      "0.529756256689628\n",
      "Starting Epoch 190\n",
      "0.528480434169372\n",
      "Starting Epoch 191\n",
      "0.5310248223443826\n",
      "Starting Epoch 192\n",
      "0.5295540454487005\n",
      "New best model found at epoch 192 with validation loss 0.5321528315544128\n",
      "Starting Epoch 193\n",
      "0.5259263664484024\n",
      "Starting Epoch 194\n",
      "0.5285394887129465\n",
      "Starting Epoch 195\n",
      "0.5275675977269808\n",
      "Starting Epoch 196\n",
      "0.5286009646952152\n",
      "Starting Epoch 197\n",
      "0.529953179260095\n",
      "Starting Epoch 198\n",
      "0.5288439045349757\n",
      "Starting Epoch 199\n",
      "0.529954214890798\n",
      "Starting Epoch 200\n",
      "0.5278250885506471\n",
      "Starting Epoch 201\n",
      "0.5263215340673923\n",
      "Starting Epoch 202\n",
      "0.5283247753977776\n",
      "New best model found at epoch 202 with validation loss 0.5314509272575378\n",
      "Starting Epoch 203\n",
      "0.5283812011281649\n",
      "Starting Epoch 204\n",
      "0.5267171437541643\n",
      "Starting Epoch 205\n",
      "0.5259634802738825\n",
      "Starting Epoch 206\n",
      "0.5279122491677603\n",
      "Starting Epoch 207\n",
      "0.5289008282124996\n",
      "Starting Epoch 208\n",
      "0.5287678750852743\n",
      "Starting Epoch 209\n",
      "0.5269161139925321\n",
      "Starting Epoch 210\n",
      "0.530462771654129\n",
      "Starting Epoch 211\n",
      "0.5284783144791921\n",
      "Starting Epoch 212\n",
      "0.5284181572496891\n",
      "New best model found at epoch 212 with validation loss 0.5313999056816101\n",
      "Starting Epoch 213\n",
      "0.5286023616790771\n",
      "Starting Epoch 214\n",
      "0.5262541038294634\n",
      "New best model found at epoch 214 with validation loss 0.5304542779922485\n",
      "Starting Epoch 215\n",
      "0.5265458524227142\n",
      "Starting Epoch 216\n",
      "0.5271059920390447\n",
      "New best model found at epoch 216 with validation loss 0.5295635461807251\n",
      "Starting Epoch 217\n",
      "0.5260384815434614\n",
      "Starting Epoch 218\n",
      "0.5299943586190542\n",
      "Starting Epoch 219\n",
      "0.5278637210528055\n",
      "Starting Epoch 220\n",
      "0.5272096494833628\n",
      "Starting Epoch 221\n",
      "0.5263000962634882\n",
      "Starting Epoch 222\n",
      "0.5274541030327479\n",
      "Starting Epoch 223\n",
      "0.5259604975581169\n",
      "Starting Epoch 224\n",
      "0.5257078657547632\n",
      "Starting Epoch 225\n",
      "0.5249969574312369\n",
      "Starting Epoch 226\n",
      "0.5236129636565844\n",
      "Starting Epoch 227\n",
      "0.5285081615050634\n",
      "Starting Epoch 228\n",
      "0.5273291555543741\n",
      "Starting Epoch 229\n",
      "0.5278391428291798\n",
      "Starting Epoch 230\n",
      "0.5265594261387984\n",
      "New best model found at epoch 230 with validation loss 0.5288712978363037\n",
      "Starting Epoch 231\n",
      "0.5260696423550447\n",
      "Starting Epoch 232\n",
      "0.5262416402498881\n",
      "Starting Epoch 233\n",
      "0.5239314970870813\n",
      "Starting Epoch 234\n",
      "0.5279968207081159\n",
      "Starting Epoch 235\n",
      "0.52416334922115\n",
      "Starting Epoch 236\n",
      "0.525104803343614\n",
      "Starting Epoch 237\n",
      "0.5264826379716396\n",
      "Starting Epoch 238\n",
      "0.5276082418859005\n",
      "Starting Epoch 239\n",
      "0.5255410894751549\n",
      "Starting Epoch 240\n",
      "0.525749376664559\n",
      "Starting Epoch 241\n",
      "0.525196430583795\n",
      "New best model found at epoch 241 with validation loss 0.5283324718475342\n",
      "Starting Epoch 242\n",
      "0.5261666340132555\n",
      "Starting Epoch 243\n",
      "0.5249176832536856\n",
      "Starting Epoch 244\n",
      "0.5269258047143618\n",
      "Starting Epoch 245\n",
      "0.5267375645538172\n",
      "Starting Epoch 246\n",
      "0.5274770346780618\n",
      "Starting Epoch 247\n",
      "0.5243385856350263\n",
      "Starting Epoch 248\n",
      "0.5287082741657892\n",
      "Starting Epoch 249\n",
      "0.5246689394116402\n",
      "Starting Epoch 250\n",
      "0.5235073951383432\n",
      "Starting Epoch 251\n",
      "0.5272008267541727\n",
      "New best model found at epoch 251 with validation loss 0.527917206287384\n",
      "Starting Epoch 252\n",
      "0.5251411075393358\n",
      "Starting Epoch 253\n",
      "0.5268283610542616\n",
      "Starting Epoch 254\n",
      "0.5250183455646038\n",
      "Starting Epoch 255\n",
      "0.5236721436182658\n",
      "Starting Epoch 256\n",
      "0.5257072026530901\n",
      "Starting Epoch 257\n",
      "0.5257541512449583\n",
      "Starting Epoch 258\n",
      "0.5236933367947737\n",
      "Starting Epoch 259\n",
      "0.5255581364035606\n",
      "Starting Epoch 260\n",
      "0.5237278280158838\n",
      "Starting Epoch 261\n",
      "0.5231754394869009\n",
      "Starting Epoch 262\n",
      "0.5269320569932461\n",
      "New best model found at epoch 262 with validation loss 0.5274308323860168\n",
      "Starting Epoch 263\n",
      "0.5244398315747579\n",
      "Starting Epoch 264\n",
      "0.5220084624985853\n",
      "Starting Epoch 265\n",
      "0.5285145031909148\n",
      "Starting Epoch 266\n",
      "0.5249625990788142\n",
      "Starting Epoch 267\n",
      "0.5231012913088003\n",
      "Starting Epoch 268\n",
      "0.5247634624441465\n",
      "Starting Epoch 269\n",
      "0.5232208395997683\n",
      "Starting Epoch 270\n",
      "0.5228733246525129\n",
      "New best model found at epoch 270 with validation loss 0.5271933674812317\n",
      "Starting Epoch 271\n",
      "0.5236800350248814\n",
      "Starting Epoch 272\n",
      "0.5242962700625261\n",
      "Starting Epoch 273\n",
      "0.5246436831851801\n",
      "Starting Epoch 274\n",
      "0.5226041289667288\n",
      "Starting Epoch 275\n",
      "0.5263584740459919\n",
      "Starting Epoch 276\n",
      "0.522650039444367\n",
      "New best model found at epoch 276 with validation loss 0.5267001390457153\n",
      "Starting Epoch 277\n",
      "0.5266798113783201\n",
      "New best model found at epoch 277 with validation loss 0.5266768932342529\n",
      "Starting Epoch 278\n",
      "0.5235190577805042\n",
      "Starting Epoch 279\n",
      "0.5283659795920054\n",
      "Starting Epoch 280\n",
      "0.5275503297646841\n",
      "New best model found at epoch 280 with validation loss 0.5260708928108215\n",
      "Starting Epoch 281\n",
      "0.5248612885673841\n",
      "Starting Epoch 282\n",
      "0.5234493501484394\n",
      "Starting Epoch 283\n",
      "0.5246147848665714\n",
      "Starting Epoch 284\n",
      "0.5241052073736986\n",
      "Starting Epoch 285\n",
      "0.5247617475688457\n",
      "New best model found at epoch 285 with validation loss 0.5260288119316101\n",
      "Starting Epoch 286\n",
      "0.5213561778267225\n",
      "New best model found at epoch 286 with validation loss 0.525689959526062\n",
      "Starting Epoch 287\n",
      "0.5237756210068861\n",
      "New best model found at epoch 287 with validation loss 0.5253646969795227\n",
      "Starting Epoch 288\n",
      "0.5237646115322908\n",
      "Starting Epoch 289\n",
      "0.5252373901506265\n",
      "Starting Epoch 290\n",
      "0.5256155468523502\n",
      "New best model found at epoch 290 with validation loss 0.525159478187561\n",
      "Starting Epoch 291\n",
      "0.5212770638366541\n",
      "Starting Epoch 292\n",
      "0.5229787727197012\n",
      "Starting Epoch 293\n",
      "0.5225430602828661\n",
      "Starting Epoch 294\n",
      "0.5212883527080218\n",
      "Starting Epoch 295\n",
      "0.5204070520897707\n",
      "Starting Epoch 296\n",
      "0.5234417046109835\n",
      "Starting Epoch 297\n",
      "0.5251160462697347\n",
      "Starting Epoch 298\n",
      "0.5217216772337755\n",
      "New best model found at epoch 298 with validation loss 0.5245513916015625\n",
      "Starting Epoch 299\n",
      "0.5223913093407949\n",
      "Starting Epoch 300\n",
      "0.5226220513383547\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-40-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b03b14",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 6\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 60 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9461fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "320c063b-7853-4a9d-8b8a-64c6135b2d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.2934865007797878\n",
      "New best model found at epoch 1 with validation loss 0.6840505003929138\n",
      "Starting Epoch 2\n",
      "0.6151171699166298\n",
      "New best model found at epoch 2 with validation loss 0.5741039514541626\n",
      "Starting Epoch 3\n",
      "0.5950388585527738\n",
      "New best model found at epoch 3 with validation loss 0.5675252676010132\n",
      "Starting Epoch 4\n",
      "0.5883699854214987\n",
      "New best model found at epoch 4 with validation loss 0.5637314319610596\n",
      "Starting Epoch 5\n",
      "0.5825260877609253\n",
      "New best model found at epoch 5 with validation loss 0.563510000705719\n",
      "Starting Epoch 6\n",
      "0.5875357165932655\n",
      "Starting Epoch 7\n",
      "0.5747323061029116\n",
      "New best model found at epoch 7 with validation loss 0.5534159541130066\n",
      "Starting Epoch 8\n",
      "0.5689612105488777\n",
      "Starting Epoch 9\n",
      "0.5680359850327173\n",
      "New best model found at epoch 9 with validation loss 0.5510074496269226\n",
      "Starting Epoch 10\n",
      "0.5717062875628471\n",
      "Starting Epoch 11\n",
      "0.5603689427177111\n",
      "Starting Epoch 12\n",
      "0.5623901511232058\n",
      "New best model found at epoch 12 with validation loss 0.5438950061798096\n",
      "Starting Epoch 13\n",
      "0.5624216832220554\n",
      "Starting Epoch 14\n",
      "0.5591662550965945\n",
      "Starting Epoch 15\n",
      "0.5572410648067793\n",
      "Starting Epoch 16\n",
      "0.5578283245364825\n",
      "Starting Epoch 17\n",
      "0.553789866467317\n",
      "New best model found at epoch 17 with validation loss 0.5390133261680603\n",
      "Starting Epoch 18\n",
      "0.5544075220823288\n",
      "Starting Epoch 19\n",
      "0.549584491799275\n",
      "Starting Epoch 20\n",
      "0.5562366160253683\n",
      "New best model found at epoch 20 with validation loss 0.536039412021637\n",
      "Starting Epoch 21\n",
      "0.5470953024923801\n",
      "Starting Epoch 22\n",
      "0.5479901507496834\n",
      "New best model found at epoch 22 with validation loss 0.5342438220977783\n",
      "Starting Epoch 23\n",
      "0.5522237730522951\n",
      "Starting Epoch 24\n",
      "0.5534847403566042\n",
      "Starting Epoch 25\n",
      "0.5428852861126264\n",
      "Starting Epoch 26\n",
      "0.5421826566259066\n",
      "New best model found at epoch 26 with validation loss 0.531393826007843\n",
      "Starting Epoch 27\n",
      "0.5415188322464625\n",
      "Starting Epoch 28\n",
      "0.5450036823749542\n",
      "Starting Epoch 29\n",
      "0.5451070206860701\n",
      "New best model found at epoch 29 with validation loss 0.530966579914093\n",
      "Starting Epoch 30\n",
      "0.5400691330432892\n",
      "Starting Epoch 31\n",
      "0.5420574583113194\n",
      "New best model found at epoch 31 with validation loss 0.529063880443573\n",
      "Starting Epoch 32\n",
      "0.5379187514384588\n",
      "New best model found at epoch 32 with validation loss 0.5277343392372131\n",
      "Starting Epoch 33\n",
      "0.543045228968064\n",
      "New best model found at epoch 33 with validation loss 0.5258432030677795\n",
      "Starting Epoch 34\n",
      "0.5427190760771433\n",
      "Starting Epoch 35\n",
      "0.5345225383838018\n",
      "Starting Epoch 36\n",
      "0.5371451290945212\n",
      "Starting Epoch 37\n",
      "0.5353916597863039\n",
      "Starting Epoch 38\n",
      "0.5364050902426243\n",
      "New best model found at epoch 38 with validation loss 0.5235884189605713\n",
      "Starting Epoch 39\n",
      "0.5347371399402618\n",
      "Starting Epoch 40\n",
      "0.5365816839039326\n",
      "Starting Epoch 41\n",
      "0.5346959978342056\n",
      "Starting Epoch 42\n",
      "0.5358495997885863\n",
      "Starting Epoch 43\n",
      "0.533860749254624\n",
      "New best model found at epoch 43 with validation loss 0.5228434205055237\n",
      "Starting Epoch 44\n",
      "0.5336485008398691\n",
      "Starting Epoch 45\n",
      "0.535456166913112\n",
      "Starting Epoch 46\n",
      "0.5299101124207178\n",
      "Starting Epoch 47\n",
      "0.5326352082192898\n",
      "Starting Epoch 48\n",
      "0.5340074636042118\n",
      "Starting Epoch 49\n",
      "0.5295787913103899\n",
      "Starting Epoch 50\n",
      "0.53256223599116\n",
      "Starting Epoch 51\n",
      "0.5307361694673697\n",
      "Starting Epoch 52\n",
      "0.5325418983896574\n",
      "Starting Epoch 53\n",
      "0.5311396097143491\n",
      "New best model found at epoch 53 with validation loss 0.5161526799201965\n",
      "Starting Epoch 54\n",
      "0.5300728815297285\n",
      "Starting Epoch 55\n",
      "0.5276764792700609\n",
      "Starting Epoch 56\n",
      "0.5296979211270809\n",
      "Starting Epoch 57\n",
      "0.5265325680375099\n",
      "Starting Epoch 58\n",
      "0.5305549092590809\n",
      "Starting Epoch 59\n",
      "0.5305803194642067\n",
      "Starting Epoch 60\n",
      "0.5253024895985922\n",
      "Starting Epoch 61\n",
      "0.5240466346343359\n",
      "Starting Epoch 62\n",
      "0.5249575016399225\n",
      "Starting Epoch 63\n",
      "0.5251946697632471\n",
      "Starting Epoch 64\n",
      "0.5259787775576115\n",
      "Starting Epoch 65\n",
      "0.5234513444205126\n",
      "New best model found at epoch 65 with validation loss 0.5139755606651306\n",
      "Starting Epoch 66\n",
      "0.5229281360904375\n",
      "New best model found at epoch 66 with validation loss 0.5135550498962402\n",
      "Starting Epoch 67\n",
      "0.5188663676381111\n",
      "Starting Epoch 68\n",
      "0.5247239942351977\n",
      "Starting Epoch 69\n",
      "0.5217498727142811\n",
      "New best model found at epoch 69 with validation loss 0.5135083794593811\n",
      "Starting Epoch 70\n",
      "0.526317602644364\n",
      "Starting Epoch 71\n",
      "0.5228585513929526\n",
      "Starting Epoch 72\n",
      "0.520591831455628\n",
      "Starting Epoch 73\n",
      "0.5209568912784258\n",
      "Starting Epoch 74\n",
      "0.520655787239472\n",
      "New best model found at epoch 74 with validation loss 0.5119147300720215\n",
      "Starting Epoch 75\n",
      "0.5204075078169504\n",
      "Starting Epoch 76\n",
      "0.5179405411084493\n",
      "New best model found at epoch 76 with validation loss 0.5108758807182312\n",
      "Starting Epoch 77\n",
      "0.5176067898670832\n",
      "Starting Epoch 78\n",
      "0.5218719666202863\n",
      "Starting Epoch 79\n",
      "0.5176723438004652\n",
      "Starting Epoch 80\n",
      "0.5198207534849644\n",
      "Starting Epoch 81\n",
      "0.5219670335451762\n",
      "New best model found at epoch 81 with validation loss 0.5079969763755798\n",
      "Starting Epoch 82\n",
      "0.5191982400914034\n",
      "Starting Epoch 83\n",
      "0.5168961783250173\n",
      "Starting Epoch 84\n",
      "0.5205386454860369\n",
      "Starting Epoch 85\n",
      "0.5168424236277739\n",
      "Starting Epoch 86\n",
      "0.5199770318965117\n",
      "Starting Epoch 87\n",
      "0.5163257941603661\n",
      "Starting Epoch 88\n",
      "0.5195805840194225\n",
      "Starting Epoch 89\n",
      "0.5185487953325113\n",
      "Starting Epoch 90\n",
      "0.5159329026937485\n",
      "Starting Epoch 91\n",
      "0.5193637112776438\n",
      "Starting Epoch 92\n",
      "0.5181993494431177\n",
      "Starting Epoch 93\n",
      "0.5139940070609251\n",
      "Starting Epoch 94\n",
      "0.516606609026591\n",
      "Starting Epoch 95\n",
      "0.5142450382312139\n",
      "Starting Epoch 96\n",
      "0.5153690415124098\n",
      "Starting Epoch 97\n",
      "0.5201772215465704\n",
      "Starting Epoch 98\n",
      "0.5154067575931549\n",
      "Starting Epoch 99\n",
      "0.5163889452815056\n",
      "Starting Epoch 100\n",
      "0.5142286357780298\n",
      "Starting Epoch 101\n",
      "0.5137420644362768\n",
      "Starting Epoch 102\n",
      "0.5160805943111578\n",
      "New best model found at epoch 102 with validation loss 0.5053794384002686\n",
      "Starting Epoch 103\n",
      "0.514034998913606\n",
      "Starting Epoch 104\n",
      "0.5119854981700579\n",
      "Starting Epoch 105\n",
      "0.5121365611751875\n",
      "Starting Epoch 106\n",
      "0.5144218516846498\n",
      "Starting Epoch 107\n",
      "0.5151088237762451\n",
      "Starting Epoch 108\n",
      "0.5134464874863625\n",
      "Starting Epoch 109\n",
      "0.5112291127443314\n",
      "Starting Epoch 110\n",
      "0.5155988782644272\n",
      "Starting Epoch 111\n",
      "0.51441823442777\n",
      "Starting Epoch 112\n",
      "0.5132398592929045\n",
      "Starting Epoch 113\n",
      "0.5132731248935064\n",
      "Starting Epoch 114\n",
      "0.5115174390375614\n",
      "New best model found at epoch 114 with validation loss 0.503435492515564\n",
      "Starting Epoch 115\n",
      "0.5108851951857408\n",
      "Starting Epoch 116\n",
      "0.5115894315143427\n",
      "Starting Epoch 117\n",
      "0.5125748353699843\n",
      "Starting Epoch 118\n",
      "0.5138483295838038\n",
      "Starting Epoch 119\n",
      "0.5119424896935622\n",
      "Starting Epoch 120\n",
      "0.5100965835154057\n",
      "Starting Epoch 121\n",
      "0.5093595633904139\n",
      "Starting Epoch 122\n",
      "0.5104284857710203\n",
      "Starting Epoch 123\n",
      "0.5101498179137707\n",
      "New best model found at epoch 123 with validation loss 0.5024473071098328\n",
      "Starting Epoch 124\n",
      "0.5088617478807768\n",
      "Starting Epoch 125\n",
      "0.507189441472292\n",
      "Starting Epoch 126\n",
      "0.5076261224846045\n",
      "Starting Epoch 127\n",
      "0.5126991420984268\n",
      "Starting Epoch 128\n",
      "0.5104473009705544\n",
      "Starting Epoch 129\n",
      "0.5123686703542868\n",
      "Starting Epoch 130\n",
      "0.509383749216795\n",
      "New best model found at epoch 130 with validation loss 0.4993726313114166\n",
      "Starting Epoch 131\n",
      "0.5084992423653603\n",
      "Starting Epoch 132\n",
      "0.5094986719389757\n",
      "Starting Epoch 133\n",
      "0.5058043338358402\n",
      "Starting Epoch 134\n",
      "0.5133402893940607\n",
      "Starting Epoch 135\n",
      "0.507868462552627\n",
      "Starting Epoch 136\n",
      "0.5079815785090128\n",
      "Starting Epoch 137\n",
      "0.5074201971292496\n",
      "Starting Epoch 138\n",
      "0.510285505404075\n",
      "Starting Epoch 139\n",
      "0.5065549748639265\n",
      "Starting Epoch 140\n",
      "0.5088164235154787\n",
      "Starting Epoch 141\n",
      "0.5081039195259412\n",
      "Starting Epoch 142\n",
      "0.5066633534928163\n",
      "Starting Epoch 143\n",
      "0.5064395740628242\n",
      "Starting Epoch 144\n",
      "0.5087864535550276\n",
      "Starting Epoch 145\n",
      "0.5089898258447647\n",
      "Starting Epoch 146\n",
      "0.5076509192585945\n",
      "Starting Epoch 147\n",
      "0.5064523965120316\n",
      "Starting Epoch 148\n",
      "0.5107801606257757\n",
      "Starting Epoch 149\n",
      "0.5073173108200232\n",
      "Starting Epoch 150\n",
      "0.5039613991975784\n",
      "Starting Epoch 151\n",
      "0.5090220049023628\n",
      "Starting Epoch 152\n",
      "0.5050781158109506\n",
      "Starting Epoch 153\n",
      "0.5059400623043379\n",
      "Starting Epoch 154\n",
      "0.5071259165803591\n",
      "Starting Epoch 155\n",
      "0.5044759946564833\n",
      "Starting Epoch 156\n",
      "0.5063211756447951\n",
      "Starting Epoch 157\n",
      "0.5062208684782187\n",
      "Starting Epoch 158\n",
      "0.5038932201762995\n",
      "Starting Epoch 159\n",
      "0.5041154076655706\n",
      "Starting Epoch 160\n",
      "0.5042706752816836\n",
      "Starting Epoch 161\n",
      "0.5021011146406332\n",
      "Starting Epoch 162\n",
      "0.5066588098804156\n",
      "Starting Epoch 163\n",
      "0.503767671684424\n",
      "Starting Epoch 164\n",
      "0.5030919114748637\n",
      "Starting Epoch 165\n",
      "0.5068206538756689\n",
      "Starting Epoch 166\n",
      "0.504793411741654\n",
      "Starting Epoch 167\n",
      "0.5049328605333964\n",
      "Starting Epoch 168\n",
      "0.5029441130657991\n",
      "Starting Epoch 169\n",
      "0.5019915749629339\n",
      "New best model found at epoch 169 with validation loss 0.4980296492576599\n",
      "Starting Epoch 170\n",
      "0.5027048364281654\n",
      "Starting Epoch 171\n",
      "0.5058013573288918\n",
      "Starting Epoch 172\n",
      "0.5030213805536429\n",
      "Starting Epoch 173\n",
      "0.5031626683970293\n",
      "Starting Epoch 174\n",
      "0.500172117104133\n",
      "Starting Epoch 175\n",
      "0.5051730101307234\n",
      "Starting Epoch 176\n",
      "0.502048605432113\n",
      "New best model found at epoch 176 with validation loss 0.4974314272403717\n",
      "Starting Epoch 177\n",
      "0.5049557512005171\n",
      "Starting Epoch 178\n",
      "0.5018647300700346\n",
      "Starting Epoch 179\n",
      "0.5073479264974594\n",
      "Starting Epoch 180\n",
      "0.5080192262927691\n",
      "New best model found at epoch 180 with validation loss 0.4964786171913147\n",
      "Starting Epoch 181\n",
      "0.5031151361763477\n",
      "Starting Epoch 182\n",
      "0.501574169844389\n",
      "Starting Epoch 183\n",
      "0.5049629211425781\n",
      "Starting Epoch 184\n",
      "0.5018260354797045\n",
      "Starting Epoch 185\n",
      "0.5030777504046758\n",
      "Starting Epoch 186\n",
      "0.5000808301071326\n",
      "Starting Epoch 187\n",
      "0.5025573720534643\n",
      "Starting Epoch 188\n",
      "0.5015529741843542\n",
      "Starting Epoch 189\n",
      "0.5021443987886111\n",
      "Starting Epoch 190\n",
      "0.5021346857150396\n",
      "New best model found at epoch 190 with validation loss 0.4963361322879791\n",
      "Starting Epoch 191\n",
      "0.5001658499240875\n",
      "New best model found at epoch 191 with validation loss 0.4945370852947235\n",
      "Starting Epoch 192\n",
      "0.5004165408511957\n",
      "Starting Epoch 193\n",
      "0.5002979872127374\n",
      "Starting Epoch 194\n",
      "0.4996277006963889\n",
      "Starting Epoch 195\n",
      "0.4976364274819692\n",
      "New best model found at epoch 195 with validation loss 0.49341264367103577\n",
      "Starting Epoch 196\n",
      "0.501556321978569\n",
      "Starting Epoch 197\n",
      "0.5012977235019207\n",
      "Starting Epoch 198\n",
      "0.4998149089515209\n",
      "Starting Epoch 199\n",
      "0.5006565973162651\n",
      "Starting Epoch 200\n",
      "0.5007143740852674\n",
      "Starting Epoch 201\n",
      "0.504693099608024\n",
      "Starting Epoch 202\n",
      "0.5012161545455456\n",
      "Starting Epoch 203\n",
      "0.4994987833003203\n",
      "Starting Epoch 204\n",
      "0.5007070178786913\n",
      "New best model found at epoch 204 with validation loss 0.49220967292785645\n",
      "Starting Epoch 205\n",
      "0.5020245524744192\n",
      "Starting Epoch 206\n",
      "0.501646858950456\n",
      "Starting Epoch 207\n",
      "0.49960768843690556\n",
      "Starting Epoch 208\n",
      "0.5008224075039228\n",
      "Starting Epoch 209\n",
      "0.5007094331085682\n",
      "Starting Epoch 210\n",
      "0.4985160517195861\n",
      "Starting Epoch 211\n",
      "0.5005217169721922\n",
      "Starting Epoch 212\n",
      "0.4979797974228859\n",
      "Starting Epoch 213\n",
      "0.49798086658120155\n",
      "Starting Epoch 214\n",
      "0.4984152043859164\n",
      "Starting Epoch 215\n",
      "0.4979788586497307\n",
      "Starting Epoch 216\n",
      "0.4980887522300084\n",
      "Starting Epoch 217\n",
      "0.499667152762413\n",
      "Starting Epoch 218\n",
      "0.499151053527991\n",
      "New best model found at epoch 218 with validation loss 0.48851341009140015\n",
      "Starting Epoch 219\n",
      "0.4980570897459984\n",
      "Starting Epoch 220\n",
      "0.4979356415569782\n",
      "Starting Epoch 221\n",
      "0.4976108483970165\n",
      "Starting Epoch 222\n",
      "0.4976460821926594\n",
      "Starting Epoch 223\n",
      "0.4968944912155469\n",
      "Starting Epoch 224\n",
      "0.4979240484535694\n",
      "Starting Epoch 225\n",
      "0.496661522736152\n",
      "Starting Epoch 226\n",
      "0.49769887203971547\n",
      "Starting Epoch 227\n",
      "0.4965762508412202\n",
      "Starting Epoch 228\n",
      "0.4971618776520093\n",
      "Starting Epoch 229\n",
      "0.4970016727844874\n",
      "Starting Epoch 230\n",
      "0.49726320058107376\n",
      "Starting Epoch 231\n",
      "0.4988014002641042\n",
      "Starting Epoch 232\n",
      "0.5013252335290114\n",
      "Starting Epoch 233\n",
      "0.49684494237105054\n",
      "Starting Epoch 234\n",
      "0.49534781525532406\n",
      "Starting Epoch 235\n",
      "0.4984782710671425\n",
      "Starting Epoch 236\n",
      "0.4947652729849021\n",
      "Starting Epoch 237\n",
      "0.49699849759538967\n",
      "Starting Epoch 238\n",
      "0.4979681211213271\n",
      "Starting Epoch 239\n",
      "0.5037143155932426\n",
      "Starting Epoch 240\n",
      "0.4971306932469209\n",
      "Starting Epoch 241\n",
      "0.4934326559305191\n",
      "Starting Epoch 242\n",
      "0.49477842077612877\n",
      "New best model found at epoch 242 with validation loss 0.487911194562912\n",
      "Starting Epoch 243\n",
      "0.49683890119194984\n",
      "Starting Epoch 244\n",
      "0.49986369411150616\n",
      "Starting Epoch 245\n",
      "0.49571332708001137\n",
      "Starting Epoch 246\n",
      "0.49907540902495384\n",
      "Starting Epoch 247\n",
      "0.4977884528537591\n",
      "Starting Epoch 248\n",
      "0.49569446096817654\n",
      "Starting Epoch 249\n",
      "0.4964739258090655\n",
      "Starting Epoch 250\n",
      "0.4968413971364498\n",
      "Starting Epoch 251\n",
      "0.4979647087554137\n",
      "Starting Epoch 252\n",
      "0.49624331668019295\n",
      "New best model found at epoch 252 with validation loss 0.4858718812465668\n",
      "Starting Epoch 253\n",
      "0.49378206580877304\n",
      "Starting Epoch 254\n",
      "0.4940684214234352\n",
      "Starting Epoch 255\n",
      "0.4968881780902545\n",
      "New best model found at epoch 255 with validation loss 0.4841177761554718\n",
      "Starting Epoch 256\n",
      "0.4962218999862671\n",
      "Starting Epoch 257\n",
      "0.49714036534229916\n",
      "Starting Epoch 258\n",
      "0.49253873030344647\n",
      "Starting Epoch 259\n",
      "0.500245563685894\n",
      "Starting Epoch 260\n",
      "0.4965735338628292\n",
      "Starting Epoch 261\n",
      "0.4943828446169694\n",
      "Starting Epoch 262\n",
      "0.494531078884999\n",
      "Starting Epoch 263\n",
      "0.49707788104812306\n",
      "Starting Epoch 264\n",
      "0.4944775539139907\n",
      "Starting Epoch 265\n",
      "0.49289944271246594\n",
      "Starting Epoch 266\n",
      "0.4949706147114436\n",
      "Starting Epoch 267\n",
      "0.49347983797391254\n",
      "Starting Epoch 268\n",
      "0.4924582118789355\n",
      "Starting Epoch 269\n",
      "0.4931536515553792\n",
      "Starting Epoch 270\n",
      "0.4952156754831473\n",
      "Starting Epoch 271\n",
      "0.4949071208635966\n",
      "Starting Epoch 272\n",
      "0.4954161134858926\n",
      "Starting Epoch 273\n",
      "0.4957009938855966\n",
      "Starting Epoch 274\n",
      "0.49606773629784584\n",
      "Starting Epoch 275\n",
      "0.4937107103566329\n",
      "Starting Epoch 276\n",
      "0.49786131580670673\n",
      "Starting Epoch 277\n",
      "0.4960780180990696\n",
      "New best model found at epoch 277 with validation loss 0.48370227217674255\n",
      "Starting Epoch 278\n",
      "0.49493740623195964\n",
      "Starting Epoch 279\n",
      "0.49732381477952003\n",
      "Starting Epoch 280\n",
      "0.4934092089533806\n",
      "Starting Epoch 281\n",
      "0.49459050968289375\n",
      "Starting Epoch 282\n",
      "0.49379981060822803\n",
      "New best model found at epoch 282 with validation loss 0.48333704471588135\n",
      "Starting Epoch 283\n",
      "0.4935704829792182\n",
      "Starting Epoch 284\n",
      "0.4963242250184218\n",
      "Starting Epoch 285\n",
      "0.49329158167044324\n",
      "Starting Epoch 286\n",
      "0.4934663288295269\n",
      "Starting Epoch 287\n",
      "0.4955421909689903\n",
      "New best model found at epoch 287 with validation loss 0.481745183467865\n",
      "Starting Epoch 288\n",
      "0.49453216046094894\n",
      "Starting Epoch 289\n",
      "0.4925781898200512\n",
      "Starting Epoch 290\n",
      "0.49520130455493927\n",
      "Starting Epoch 291\n",
      "0.4951080729564031\n",
      "Starting Epoch 292\n",
      "0.49520084882775944\n",
      "Starting Epoch 293\n",
      "0.49519847457607585\n",
      "Starting Epoch 294\n",
      "0.4924153337876002\n",
      "Starting Epoch 295\n",
      "0.4922540287176768\n",
      "Starting Epoch 296\n",
      "0.493190901974837\n",
      "Starting Epoch 297\n",
      "0.49773117030660313\n",
      "Starting Epoch 298\n",
      "0.49210794021685916\n",
      "Starting Epoch 299\n",
      "0.4916817123691241\n",
      "Starting Epoch 300\n",
      "0.49638329073786736\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-60-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22521a0c",
   "metadata": {},
   "source": [
    "#### 4-layer MLP\n",
    "*  Loss: Cross-entropy\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0db3a",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 10 - 5 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8d4f8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "28015467-5c7a-495d-af6c-cdc18d31e3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.7509863078594208\n",
      "New best model found at epoch 1 with validation loss 0.585844099521637\n",
      "Starting Epoch 2\n",
      "0.594898983836174\n",
      "New best model found at epoch 2 with validation loss 0.5722861289978027\n",
      "Starting Epoch 3\n",
      "0.5906402617692947\n",
      "Starting Epoch 4\n",
      "0.5811571379502615\n",
      "New best model found at epoch 4 with validation loss 0.5702766180038452\n",
      "Starting Epoch 5\n",
      "0.5792363807559013\n",
      "New best model found at epoch 5 with validation loss 0.5701988935470581\n",
      "Starting Epoch 6\n",
      "0.5784717450539271\n",
      "Starting Epoch 7\n",
      "0.5754518012205759\n",
      "New best model found at epoch 7 with validation loss 0.569673478603363\n",
      "Starting Epoch 8\n",
      "0.5778265620271364\n",
      "Starting Epoch 9\n",
      "0.5761745820442835\n",
      "New best model found at epoch 9 with validation loss 0.5676354169845581\n",
      "Starting Epoch 10\n",
      "0.5763514141241709\n",
      "Starting Epoch 11\n",
      "0.5752653715511163\n",
      "New best model found at epoch 11 with validation loss 0.566676914691925\n",
      "Starting Epoch 12\n",
      "0.5742872431874275\n",
      "Starting Epoch 13\n",
      "0.5775385076800982\n",
      "Starting Epoch 14\n",
      "0.5759384768704573\n",
      "Starting Epoch 15\n",
      "0.5754978880286217\n",
      "New best model found at epoch 15 with validation loss 0.5661764740943909\n",
      "Starting Epoch 16\n",
      "0.5728375936547915\n",
      "Starting Epoch 17\n",
      "0.5741163392861685\n",
      "New best model found at epoch 17 with validation loss 0.565681517124176\n",
      "Starting Epoch 18\n",
      "0.5732231413324674\n",
      "Starting Epoch 19\n",
      "0.5748621548215548\n",
      "Starting Epoch 20\n",
      "0.5744707075258096\n",
      "Starting Epoch 21\n",
      "0.5752140482266744\n",
      "Starting Epoch 22\n",
      "0.5743289304276308\n",
      "Starting Epoch 23\n",
      "0.5736999387542406\n",
      "New best model found at epoch 23 with validation loss 0.5645108222961426\n",
      "Starting Epoch 24\n",
      "0.5750138883789381\n",
      "Starting Epoch 25\n",
      "0.5710419416427612\n",
      "Starting Epoch 26\n",
      "0.5730393293003241\n",
      "New best model found at epoch 26 with validation loss 0.5635732412338257\n",
      "Starting Epoch 27\n",
      "0.5709216942389806\n",
      "Starting Epoch 28\n",
      "0.570455846687158\n",
      "New best model found at epoch 28 with validation loss 0.5632201433181763\n",
      "Starting Epoch 29\n",
      "0.5689505971968174\n",
      "Starting Epoch 30\n",
      "0.5704108302791914\n",
      "Starting Epoch 31\n",
      "0.5733760794003805\n",
      "Starting Epoch 32\n",
      "0.5711795538663864\n",
      "New best model found at epoch 32 with validation loss 0.5625521540641785\n",
      "Starting Epoch 33\n",
      "0.5692368211845557\n",
      "Starting Epoch 34\n",
      "0.5684860857824484\n",
      "New best model found at epoch 34 with validation loss 0.561859130859375\n",
      "Starting Epoch 35\n",
      "0.5716046914458275\n",
      "Starting Epoch 36\n",
      "0.5692302758495013\n",
      "Starting Epoch 37\n",
      "0.570055560519298\n",
      "New best model found at epoch 37 with validation loss 0.5609254837036133\n",
      "Starting Epoch 38\n",
      "0.5683255990346273\n",
      "Starting Epoch 39\n",
      "0.5680517728130022\n",
      "Starting Epoch 40\n",
      "0.5669165427486101\n",
      "New best model found at epoch 40 with validation loss 0.5607477426528931\n",
      "Starting Epoch 41\n",
      "0.5670893006026745\n",
      "Starting Epoch 42\n",
      "0.5679309206704298\n",
      "New best model found at epoch 42 with validation loss 0.5592983365058899\n",
      "Starting Epoch 43\n",
      "0.5674076825380325\n",
      "Starting Epoch 44\n",
      "0.568745327492555\n",
      "New best model found at epoch 44 with validation loss 0.5576046109199524\n",
      "Starting Epoch 45\n",
      "0.5630401683350404\n",
      "New best model found at epoch 45 with validation loss 0.5575392246246338\n",
      "Starting Epoch 46\n",
      "0.5631221979856491\n",
      "Starting Epoch 47\n",
      "0.5671545105675856\n",
      "New best model found at epoch 47 with validation loss 0.556883692741394\n",
      "Starting Epoch 48\n",
      "0.5637822796901067\n",
      "Starting Epoch 49\n",
      "0.5648014818628629\n",
      "New best model found at epoch 49 with validation loss 0.5561115741729736\n",
      "Starting Epoch 50\n",
      "0.5641120125850042\n",
      "Starting Epoch 51\n",
      "0.5597966201603413\n",
      "New best model found at epoch 51 with validation loss 0.5544571876525879\n",
      "Starting Epoch 52\n",
      "0.5608171795805296\n",
      "New best model found at epoch 52 with validation loss 0.5536653399467468\n",
      "Starting Epoch 53\n",
      "0.5617288971940676\n",
      "Starting Epoch 54\n",
      "0.5613584741950035\n",
      "Starting Epoch 55\n",
      "0.5640119450787703\n",
      "Starting Epoch 56\n",
      "0.558039960761865\n",
      "New best model found at epoch 56 with validation loss 0.5511986613273621\n",
      "Starting Epoch 57\n",
      "0.5579176110525926\n",
      "New best model found at epoch 57 with validation loss 0.5502358675003052\n",
      "Starting Epoch 58\n",
      "0.5603661288817724\n",
      "New best model found at epoch 58 with validation loss 0.5483279824256897\n",
      "Starting Epoch 59\n",
      "0.5568829849362373\n",
      "Starting Epoch 60\n",
      "0.5551383569836617\n",
      "New best model found at epoch 60 with validation loss 0.5481109619140625\n",
      "Starting Epoch 61\n",
      "0.5583216572801272\n",
      "Starting Epoch 62\n",
      "0.550529420375824\n",
      "Starting Epoch 63\n",
      "0.5530138115088145\n",
      "New best model found at epoch 63 with validation loss 0.5465101599693298\n",
      "Starting Epoch 64\n",
      "0.5511208586394787\n",
      "New best model found at epoch 64 with validation loss 0.5438758134841919\n",
      "Starting Epoch 65\n",
      "0.5543762644131979\n",
      "New best model found at epoch 65 with validation loss 0.5435295104980469\n",
      "Starting Epoch 66\n",
      "0.5536851696670055\n",
      "Starting Epoch 67\n",
      "0.5466818635662397\n",
      "Starting Epoch 68\n",
      "0.5514086931943893\n",
      "New best model found at epoch 68 with validation loss 0.5426592230796814\n",
      "Starting Epoch 69\n",
      "0.5468517566720644\n",
      "New best model found at epoch 69 with validation loss 0.5383985042572021\n",
      "Starting Epoch 70\n",
      "0.5445222606261572\n",
      "Starting Epoch 71\n",
      "0.5516979917883873\n",
      "Starting Epoch 72\n",
      "0.5495619289577007\n",
      "New best model found at epoch 72 with validation loss 0.5373693108558655\n",
      "Starting Epoch 73\n",
      "0.5440947599709034\n",
      "New best model found at epoch 73 with validation loss 0.535764753818512\n",
      "Starting Epoch 74\n",
      "0.5435070370634397\n",
      "Starting Epoch 75\n",
      "0.5428830273449421\n",
      "Starting Epoch 76\n",
      "0.5433048332730929\n",
      "Starting Epoch 77\n",
      "0.541611244281133\n",
      "New best model found at epoch 77 with validation loss 0.5346626043319702\n",
      "Starting Epoch 78\n",
      "0.5474469996988773\n",
      "Starting Epoch 79\n",
      "0.5427160871525606\n",
      "New best model found at epoch 79 with validation loss 0.5339205861091614\n",
      "Starting Epoch 80\n",
      "0.5424037004510561\n",
      "Starting Epoch 81\n",
      "0.5407137957712015\n",
      "New best model found at epoch 81 with validation loss 0.5300970077514648\n",
      "Starting Epoch 82\n",
      "0.5471979628006617\n",
      "Starting Epoch 83\n",
      "0.5423038490116596\n",
      "Starting Epoch 84\n",
      "0.5373538459340731\n",
      "Starting Epoch 85\n",
      "0.54036537433664\n",
      "Starting Epoch 86\n",
      "0.5422730818390846\n",
      "Starting Epoch 87\n",
      "0.5384273243447145\n",
      "New best model found at epoch 87 with validation loss 0.5276623368263245\n",
      "Starting Epoch 88\n",
      "0.5364137204984823\n",
      "Starting Epoch 89\n",
      "0.5396739865342776\n",
      "Starting Epoch 90\n",
      "0.5370547051231066\n",
      "Starting Epoch 91\n",
      "0.5385177669425806\n",
      "Starting Epoch 92\n",
      "0.5354117304086685\n",
      "Starting Epoch 93\n",
      "0.5311662616829077\n",
      "Starting Epoch 94\n",
      "0.5383352215091387\n",
      "Starting Epoch 95\n",
      "0.5358376652002335\n",
      "Starting Epoch 96\n",
      "0.5351861082017422\n",
      "Starting Epoch 97\n",
      "0.534047099451224\n",
      "Starting Epoch 98\n",
      "0.5320665364464124\n",
      "Starting Epoch 99\n",
      "0.530789547910293\n",
      "Starting Epoch 100\n",
      "0.5308649304012457\n",
      "Starting Epoch 101\n",
      "0.5312909285227457\n",
      "Starting Epoch 102\n",
      "0.5293305851519108\n",
      "New best model found at epoch 102 with validation loss 0.5273517966270447\n",
      "Starting Epoch 103\n",
      "0.5313101435701052\n",
      "Starting Epoch 104\n",
      "0.5296419883767763\n",
      "New best model found at epoch 104 with validation loss 0.5266623497009277\n",
      "Starting Epoch 105\n",
      "0.5261937926212946\n",
      "Starting Epoch 106\n",
      "0.5283253043889999\n",
      "Starting Epoch 107\n",
      "0.5297288956741492\n",
      "Starting Epoch 108\n",
      "0.5290656772752603\n",
      "New best model found at epoch 108 with validation loss 0.5231422781944275\n",
      "Starting Epoch 109\n",
      "0.5257072908182939\n",
      "Starting Epoch 110\n",
      "0.5252861082553864\n",
      "Starting Epoch 111\n",
      "0.5263945485154787\n",
      "Starting Epoch 112\n",
      "0.5238847012321154\n",
      "Starting Epoch 113\n",
      "0.5264961396654447\n",
      "Starting Epoch 114\n",
      "0.5254796830316385\n",
      "Starting Epoch 115\n",
      "0.52380229656895\n",
      "Starting Epoch 116\n",
      "0.5241308485468229\n",
      "Starting Epoch 117\n",
      "0.5248450102905432\n",
      "Starting Epoch 118\n",
      "0.5229786485433578\n",
      "Starting Epoch 119\n",
      "0.5215134558578333\n",
      "New best model found at epoch 119 with validation loss 0.5190407633781433\n",
      "Starting Epoch 120\n",
      "0.5221193420390288\n",
      "Starting Epoch 121\n",
      "0.5211254296203455\n",
      "Starting Epoch 122\n",
      "0.5201054116090139\n",
      "Starting Epoch 123\n",
      "0.5232142719129721\n",
      "Starting Epoch 124\n",
      "0.5202095806598663\n",
      "Starting Epoch 125\n",
      "0.5234410290916761\n",
      "Starting Epoch 126\n",
      "0.5190623886883259\n",
      "Starting Epoch 127\n",
      "0.5264316213627657\n",
      "Starting Epoch 128\n",
      "0.5204477484027544\n",
      "New best model found at epoch 128 with validation loss 0.5181998014450073\n",
      "Starting Epoch 129\n",
      "0.5185529279212157\n",
      "Starting Epoch 130\n",
      "0.5189703851938248\n",
      "New best model found at epoch 130 with validation loss 0.5174723267555237\n",
      "Starting Epoch 131\n",
      "0.5177005082368851\n",
      "Starting Epoch 132\n",
      "0.5169127533833185\n",
      "New best model found at epoch 132 with validation loss 0.5138670206069946\n",
      "Starting Epoch 133\n",
      "0.5212399289011955\n",
      "Starting Epoch 134\n",
      "0.5177491729458173\n",
      "Starting Epoch 135\n",
      "0.5182274828354517\n",
      "New best model found at epoch 135 with validation loss 0.5136664509773254\n",
      "Starting Epoch 136\n",
      "0.5202149612208208\n",
      "Starting Epoch 137\n",
      "0.5198384163280328\n",
      "Starting Epoch 138\n",
      "0.5173286435504755\n",
      "Starting Epoch 139\n",
      "0.5139898943404356\n",
      "New best model found at epoch 139 with validation loss 0.512238621711731\n",
      "Starting Epoch 140\n",
      "0.5132473297417164\n",
      "New best model found at epoch 140 with validation loss 0.5119888782501221\n",
      "Starting Epoch 141\n",
      "0.5143479071557522\n",
      "Starting Epoch 142\n",
      "0.5165750322242578\n",
      "Starting Epoch 143\n",
      "0.5203962189455827\n",
      "Starting Epoch 144\n",
      "0.5151134232680002\n",
      "Starting Epoch 145\n",
      "0.5140422806143761\n",
      "Starting Epoch 146\n",
      "0.5147269243995348\n",
      "New best model found at epoch 146 with validation loss 0.5117643475532532\n",
      "Starting Epoch 147\n",
      "0.5160968552033106\n",
      "Starting Epoch 148\n",
      "0.5139582579334577\n",
      "New best model found at epoch 148 with validation loss 0.5114356279373169\n",
      "Starting Epoch 149\n",
      "0.5129986839989821\n",
      "Starting Epoch 150\n",
      "0.5129611641168594\n",
      "New best model found at epoch 150 with validation loss 0.5093855857849121\n",
      "Starting Epoch 151\n",
      "0.5154665025571982\n",
      "Starting Epoch 152\n",
      "0.5142972134053707\n",
      "Starting Epoch 153\n",
      "0.5189799865086874\n",
      "Starting Epoch 154\n",
      "0.5153940034409364\n",
      "Starting Epoch 155\n",
      "0.5139586304624876\n",
      "Starting Epoch 156\n",
      "0.512727715075016\n",
      "New best model found at epoch 156 with validation loss 0.5090911388397217\n",
      "Starting Epoch 157\n",
      "0.5122566297650337\n",
      "Starting Epoch 158\n",
      "0.5077563698093096\n",
      "Starting Epoch 159\n",
      "0.5134101212024689\n",
      "Starting Epoch 160\n",
      "0.5128416406611601\n",
      "Starting Epoch 161\n",
      "0.5122624449431896\n",
      "Starting Epoch 162\n",
      "0.5142713723083338\n",
      "Starting Epoch 163\n",
      "0.5103761566181978\n",
      "Starting Epoch 164\n",
      "0.5100588848193487\n",
      "Starting Epoch 165\n",
      "0.5114609661201636\n",
      "Starting Epoch 166\n",
      "0.5091752310593923\n",
      "Starting Epoch 167\n",
      "0.5122300274670124\n",
      "Starting Epoch 168\n",
      "0.5117861119409403\n",
      "Starting Epoch 169\n",
      "0.5095615784327189\n",
      "Starting Epoch 170\n",
      "0.5088994068404039\n",
      "Starting Epoch 171\n",
      "0.5111913420259953\n",
      "Starting Epoch 172\n",
      "0.5121411196887493\n",
      "Starting Epoch 173\n",
      "0.5110280513763428\n",
      "Starting Epoch 174\n",
      "0.509149082005024\n",
      "Starting Epoch 175\n",
      "0.5134848554929098\n",
      "Starting Epoch 176\n",
      "0.5080203699568907\n",
      "Starting Epoch 177\n",
      "0.5086956309775511\n",
      "Starting Epoch 178\n",
      "0.5094523926575979\n",
      "Starting Epoch 179\n",
      "0.5061601425210634\n",
      "Starting Epoch 180\n",
      "0.5068668300906817\n",
      "Starting Epoch 181\n",
      "0.5098136787613233\n",
      "Starting Epoch 182\n",
      "0.5041173622012138\n",
      "Starting Epoch 183\n",
      "0.5063142677148184\n",
      "Starting Epoch 184\n",
      "0.5065426578124365\n",
      "Starting Epoch 185\n",
      "0.508118192354838\n",
      "Starting Epoch 186\n",
      "0.5086587270100912\n",
      "Starting Epoch 187\n",
      "0.507878897090753\n",
      "Starting Epoch 188\n",
      "0.5066206057866415\n",
      "Starting Epoch 189\n",
      "0.503421638160944\n",
      "Starting Epoch 190\n",
      "0.5079406301180521\n",
      "Starting Epoch 191\n",
      "0.5062029796342055\n",
      "New best model found at epoch 191 with validation loss 0.5081514716148376\n",
      "Starting Epoch 192\n",
      "0.5059505179524422\n",
      "Starting Epoch 193\n",
      "0.5075003827611605\n",
      "Starting Epoch 194\n",
      "0.5080969619254271\n",
      "Starting Epoch 195\n",
      "0.5085900823275248\n",
      "Starting Epoch 196\n",
      "0.5045189931988716\n",
      "New best model found at epoch 196 with validation loss 0.5069476962089539\n",
      "Starting Epoch 197\n",
      "0.5049509940048059\n",
      "Starting Epoch 198\n",
      "0.5053573610881964\n",
      "Starting Epoch 199\n",
      "0.5077803283929825\n",
      "Starting Epoch 200\n",
      "0.5048438298205534\n",
      "Starting Epoch 201\n",
      "0.5059547436734041\n",
      "Starting Epoch 202\n",
      "0.5066768489778042\n",
      "Starting Epoch 203\n",
      "0.5025283234814802\n",
      "Starting Epoch 204\n",
      "0.5071659858028094\n",
      "Starting Epoch 205\n",
      "0.5042218950887521\n",
      "Starting Epoch 206\n",
      "0.5047162882983685\n",
      "Starting Epoch 207\n",
      "0.5070311067004999\n",
      "Starting Epoch 208\n",
      "0.5027632912000021\n",
      "Starting Epoch 209\n",
      "0.50343785683314\n",
      "Starting Epoch 210\n",
      "0.5081108162800471\n",
      "Starting Epoch 211\n",
      "0.504176277667284\n",
      "Starting Epoch 212\n",
      "0.5054464526474476\n",
      "Starting Epoch 213\n",
      "0.5035963418583075\n",
      "New best model found at epoch 213 with validation loss 0.5065878629684448\n",
      "Starting Epoch 214\n",
      "0.5054354555904865\n",
      "Starting Epoch 215\n",
      "0.5053450328608354\n",
      "Starting Epoch 216\n",
      "0.5020802803337574\n",
      "Starting Epoch 217\n",
      "0.5038655114670595\n",
      "New best model found at epoch 217 with validation loss 0.5046051144599915\n",
      "Starting Epoch 218\n",
      "0.5057807862758636\n",
      "Starting Epoch 219\n",
      "0.5050788968801498\n",
      "Starting Epoch 220\n",
      "0.5029917682210604\n",
      "Starting Epoch 221\n",
      "0.5047386499742667\n",
      "Starting Epoch 222\n",
      "0.5008319579064846\n",
      "Starting Epoch 223\n",
      "0.49983102828264236\n",
      "Starting Epoch 224\n",
      "0.5012826261421045\n",
      "Starting Epoch 225\n",
      "0.5030526469151179\n",
      "Starting Epoch 226\n",
      "0.5025777705013752\n",
      "Starting Epoch 227\n",
      "0.5035226667920748\n",
      "Starting Epoch 228\n",
      "0.5010497321685156\n",
      "Starting Epoch 229\n",
      "0.5026812665164471\n",
      "Starting Epoch 230\n",
      "0.49890293677647907\n",
      "Starting Epoch 231\n",
      "0.5012345140178999\n",
      "Starting Epoch 232\n",
      "0.500884917875131\n",
      "Starting Epoch 233\n",
      "0.5036193703611692\n",
      "Starting Epoch 234\n",
      "0.49926186973849934\n",
      "Starting Epoch 235\n",
      "0.5028284750878811\n",
      "Starting Epoch 236\n",
      "0.5004982861379782\n",
      "Starting Epoch 237\n",
      "0.4976692820588748\n",
      "Starting Epoch 238\n",
      "0.5022848509252071\n",
      "New best model found at epoch 238 with validation loss 0.5040470957756042\n",
      "Starting Epoch 239\n",
      "0.5003657477597395\n",
      "Starting Epoch 240\n",
      "0.5049286981423696\n",
      "Starting Epoch 241\n",
      "0.5038341383139292\n",
      "Starting Epoch 242\n",
      "0.5024239631990591\n",
      "Starting Epoch 243\n",
      "0.49852688362201053\n",
      "Starting Epoch 244\n",
      "0.5026961093147596\n",
      "Starting Epoch 245\n",
      "0.49903705219427746\n",
      "Starting Epoch 246\n",
      "0.4977411776781082\n",
      "Starting Epoch 247\n",
      "0.5016447864472866\n",
      "Starting Epoch 248\n",
      "0.4994082438449065\n",
      "Starting Epoch 249\n",
      "0.49859613304336864\n",
      "Starting Epoch 250\n",
      "0.5026286852856477\n",
      "Starting Epoch 251\n",
      "0.4996754949291547\n",
      "Starting Epoch 252\n",
      "0.5042079848547777\n",
      "Starting Epoch 253\n",
      "0.4993647274871667\n",
      "Starting Epoch 254\n",
      "0.49834102019667625\n",
      "Starting Epoch 255\n",
      "0.501478181531032\n",
      "Starting Epoch 256\n",
      "0.49963468809922534\n",
      "Starting Epoch 257\n",
      "0.501968347777923\n",
      "Starting Epoch 258\n",
      "0.5006551158924898\n",
      "Starting Epoch 259\n",
      "0.5017633636792501\n",
      "Starting Epoch 260\n",
      "0.5007190965116024\n",
      "Starting Epoch 261\n",
      "0.49849287917216617\n",
      "Starting Epoch 262\n",
      "0.49937257915735245\n",
      "Starting Epoch 263\n",
      "0.49901406715313595\n",
      "Starting Epoch 264\n",
      "0.5025937917331854\n",
      "Starting Epoch 265\n",
      "0.5012622115512689\n",
      "Starting Epoch 266\n",
      "0.5002493510643641\n",
      "Starting Epoch 267\n",
      "0.5023509996632735\n",
      "Starting Epoch 268\n",
      "0.5006209847827753\n",
      "Starting Epoch 269\n",
      "0.5003658334414164\n",
      "Starting Epoch 270\n",
      "0.49867548296848935\n",
      "New best model found at epoch 270 with validation loss 0.5034734010696411\n",
      "Starting Epoch 271\n",
      "0.5001833885908127\n",
      "Starting Epoch 272\n",
      "0.500225767493248\n",
      "Starting Epoch 273\n",
      "0.4988352321088314\n",
      "Starting Epoch 274\n",
      "0.49736957003672916\n",
      "Starting Epoch 275\n",
      "0.4994169423977534\n",
      "Starting Epoch 276\n",
      "0.4985290393233299\n",
      "Starting Epoch 277\n",
      "0.5006903149187565\n",
      "Starting Epoch 278\n",
      "0.4992431389788787\n",
      "New best model found at epoch 278 with validation loss 0.5033819079399109\n",
      "Starting Epoch 279\n",
      "0.5018094157179197\n",
      "Starting Epoch 280\n",
      "0.5022443123161793\n",
      "Starting Epoch 281\n",
      "0.49969689299662906\n",
      "Starting Epoch 282\n",
      "0.49769408628344536\n",
      "Starting Epoch 283\n",
      "0.4973684810101986\n",
      "Starting Epoch 284\n",
      "0.5008816396196684\n",
      "Starting Epoch 285\n",
      "0.5001620352268219\n",
      "Starting Epoch 286\n",
      "0.5013752418259779\n",
      "New best model found at epoch 286 with validation loss 0.5031449794769287\n",
      "Starting Epoch 287\n",
      "0.5014213547110558\n",
      "Starting Epoch 288\n",
      "0.4983699557681878\n",
      "Starting Epoch 289\n",
      "0.5012002525230249\n",
      "New best model found at epoch 289 with validation loss 0.5031117796897888\n",
      "Starting Epoch 290\n",
      "0.49805886546770733\n",
      "Starting Epoch 291\n",
      "0.5043156569202741\n",
      "Starting Epoch 292\n",
      "0.49688219154874486\n",
      "New best model found at epoch 292 with validation loss 0.502997875213623\n",
      "Starting Epoch 293\n",
      "0.4975960354010264\n",
      "Starting Epoch 294\n",
      "0.49952124680082005\n",
      "Starting Epoch 295\n",
      "0.4994589102764924\n",
      "Starting Epoch 296\n",
      "0.4980732190112273\n",
      "Starting Epoch 297\n",
      "0.4966290680070718\n",
      "Starting Epoch 298\n",
      "0.497297207514445\n",
      "Starting Epoch 299\n",
      "0.4972657648225625\n",
      "Starting Epoch 300\n",
      "0.49819785356521606\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-10-5-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ebe52e",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 20 - 10 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "da03fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "fbf53daa-38f2-4741-8496-30425a43ef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.7637677093346914\n",
      "New best model found at epoch 1 with validation loss 0.6074227690696716\n",
      "Starting Epoch 2\n",
      "0.5842183157801628\n",
      "New best model found at epoch 2 with validation loss 0.5692379474639893\n",
      "Starting Epoch 3\n",
      "0.5747722710172335\n",
      "Starting Epoch 4\n",
      "0.582257580012083\n",
      "New best model found at epoch 4 with validation loss 0.5676413178443909\n",
      "Starting Epoch 5\n",
      "0.577489343782266\n",
      "Starting Epoch 6\n",
      "0.5740671580036482\n",
      "New best model found at epoch 6 with validation loss 0.5636148452758789\n",
      "Starting Epoch 7\n",
      "0.5740656753381094\n",
      "Starting Epoch 8\n",
      "0.5726649289329847\n",
      "New best model found at epoch 8 with validation loss 0.5561926364898682\n",
      "Starting Epoch 9\n",
      "0.5660343108077844\n",
      "New best model found at epoch 9 with validation loss 0.5530290603637695\n",
      "Starting Epoch 10\n",
      "0.5664738317330679\n",
      "New best model found at epoch 10 with validation loss 0.5517794489860535\n",
      "Starting Epoch 11\n",
      "0.5635304152965546\n",
      "Starting Epoch 12\n",
      "0.5623356935878595\n",
      "Starting Epoch 13\n",
      "0.5640945409735044\n",
      "New best model found at epoch 13 with validation loss 0.5505067110061646\n",
      "Starting Epoch 14\n",
      "0.5602033461133639\n",
      "New best model found at epoch 14 with validation loss 0.5480174422264099\n",
      "Starting Epoch 15\n",
      "0.5561345418294271\n",
      "Starting Epoch 16\n",
      "0.553910798082749\n",
      "New best model found at epoch 16 with validation loss 0.5418371558189392\n",
      "Starting Epoch 17\n",
      "0.5541203742225965\n",
      "Starting Epoch 18\n",
      "0.5495025540391604\n",
      "Starting Epoch 19\n",
      "0.5505214035511017\n",
      "Starting Epoch 20\n",
      "0.5457185270885626\n",
      "New best model found at epoch 20 with validation loss 0.5378808975219727\n",
      "Starting Epoch 21\n",
      "0.5467726017038027\n",
      "Starting Epoch 22\n",
      "0.540784848233064\n",
      "Starting Epoch 23\n",
      "0.5431272126734257\n",
      "Starting Epoch 24\n",
      "0.539860911667347\n",
      "New best model found at epoch 24 with validation loss 0.5366940498352051\n",
      "Starting Epoch 25\n",
      "0.5386194847524166\n",
      "Starting Epoch 26\n",
      "0.5383128250638644\n",
      "Starting Epoch 27\n",
      "0.5375632978975773\n",
      "New best model found at epoch 27 with validation loss 0.5284903645515442\n",
      "Starting Epoch 28\n",
      "0.5361755142609278\n",
      "New best model found at epoch 28 with validation loss 0.5275456309318542\n",
      "Starting Epoch 29\n",
      "0.5364794184764227\n",
      "Starting Epoch 30\n",
      "0.5370247935255369\n",
      "New best model found at epoch 30 with validation loss 0.5262170433998108\n",
      "Starting Epoch 31\n",
      "0.5377964340150356\n",
      "Starting Epoch 32\n",
      "0.5362395544846853\n",
      "Starting Epoch 33\n",
      "0.5342844873666763\n",
      "Starting Epoch 34\n",
      "0.5288981311023235\n",
      "New best model found at epoch 34 with validation loss 0.5225666761398315\n",
      "Starting Epoch 35\n",
      "0.535199761390686\n",
      "Starting Epoch 36\n",
      "0.5323225570221742\n",
      "Starting Epoch 37\n",
      "0.5302034094929695\n",
      "Starting Epoch 38\n",
      "0.5270284054179987\n",
      "Starting Epoch 39\n",
      "0.5318921816845735\n",
      "New best model found at epoch 39 with validation loss 0.5220454335212708\n",
      "Starting Epoch 40\n",
      "0.5293274720509847\n",
      "Starting Epoch 41\n",
      "0.5277498463789622\n",
      "Starting Epoch 42\n",
      "0.5258083045482635\n",
      "Starting Epoch 43\n",
      "0.5288170178731283\n",
      "Starting Epoch 44\n",
      "0.5253368007640044\n",
      "Starting Epoch 45\n",
      "0.528433833271265\n",
      "Starting Epoch 46\n",
      "0.5261660839120547\n",
      "Starting Epoch 47\n",
      "0.5214400812983513\n",
      "Starting Epoch 48\n",
      "0.5242019382615885\n",
      "Starting Epoch 49\n",
      "0.5224092192947865\n",
      "Starting Epoch 50\n",
      "0.522324005762736\n",
      "New best model found at epoch 50 with validation loss 0.5200659036636353\n",
      "Starting Epoch 51\n",
      "0.5207279647390047\n",
      "Starting Epoch 52\n",
      "0.5229505610962709\n",
      "Starting Epoch 53\n",
      "0.5224746440847715\n",
      "Starting Epoch 54\n",
      "0.5220207497477531\n",
      "New best model found at epoch 54 with validation loss 0.5185753703117371\n",
      "Starting Epoch 55\n",
      "0.519844808926185\n",
      "Starting Epoch 56\n",
      "0.5176009684801102\n",
      "Starting Epoch 57\n",
      "0.5239347616831461\n",
      "Starting Epoch 58\n",
      "0.5178023055195808\n",
      "New best model found at epoch 58 with validation loss 0.5179979801177979\n",
      "Starting Epoch 59\n",
      "0.5186165285607179\n",
      "Starting Epoch 60\n",
      "0.5158568161229292\n",
      "Starting Epoch 61\n",
      "0.5209080589314302\n",
      "Starting Epoch 62\n",
      "0.5183409042656422\n",
      "Starting Epoch 63\n",
      "0.5144585445523262\n",
      "Starting Epoch 64\n",
      "0.5178174835940202\n",
      "Starting Epoch 65\n",
      "0.5136552390952905\n",
      "Starting Epoch 66\n",
      "0.516280721873045\n",
      "New best model found at epoch 66 with validation loss 0.5108118057250977\n",
      "Starting Epoch 67\n",
      "0.5128231098254522\n",
      "Starting Epoch 68\n",
      "0.5133920684456825\n",
      "Starting Epoch 69\n",
      "0.5153956040740013\n",
      "New best model found at epoch 69 with validation loss 0.5105291604995728\n",
      "Starting Epoch 70\n",
      "0.5140028993288676\n",
      "Starting Epoch 71\n",
      "0.5093651575346788\n",
      "New best model found at epoch 71 with validation loss 0.5100146532058716\n",
      "Starting Epoch 72\n",
      "0.5108626472453276\n",
      "Starting Epoch 73\n",
      "0.5102717156211535\n",
      "Starting Epoch 74\n",
      "0.5088506179551283\n",
      "New best model found at epoch 74 with validation loss 0.5092402100563049\n",
      "Starting Epoch 75\n",
      "0.5106356466809908\n",
      "New best model found at epoch 75 with validation loss 0.507200300693512\n",
      "Starting Epoch 76\n",
      "0.506872379531463\n",
      "Starting Epoch 77\n",
      "0.5108594782650471\n",
      "New best model found at epoch 77 with validation loss 0.5054303407669067\n",
      "Starting Epoch 78\n",
      "0.5108704417943954\n",
      "New best model found at epoch 78 with validation loss 0.5050312876701355\n",
      "Starting Epoch 79\n",
      "0.5090247939030329\n",
      "Starting Epoch 80\n",
      "0.5082484570642313\n",
      "Starting Epoch 81\n",
      "0.5102386636038622\n",
      "Starting Epoch 82\n",
      "0.5094472952187061\n",
      "Starting Epoch 83\n",
      "0.5109671925505003\n",
      "Starting Epoch 84\n",
      "0.5068838968873024\n",
      "Starting Epoch 85\n",
      "0.5086153000593185\n",
      "Starting Epoch 86\n",
      "0.5056374929845333\n",
      "Starting Epoch 87\n",
      "0.5080414985617002\n",
      "Starting Epoch 88\n",
      "0.5038805777827898\n",
      "Starting Epoch 89\n",
      "0.5070409265657266\n",
      "New best model found at epoch 89 with validation loss 0.5045725107192993\n",
      "Starting Epoch 90\n",
      "0.5068358580271403\n",
      "Starting Epoch 91\n",
      "0.5048208745817343\n",
      "Starting Epoch 92\n",
      "0.5077070072293282\n",
      "Starting Epoch 93\n",
      "0.5023544679085413\n",
      "Starting Epoch 94\n",
      "0.5036336270471414\n",
      "Starting Epoch 95\n",
      "0.5054136179387569\n",
      "New best model found at epoch 95 with validation loss 0.5044219493865967\n",
      "Starting Epoch 96\n",
      "0.5038732637961706\n",
      "New best model found at epoch 96 with validation loss 0.4986386299133301\n",
      "Starting Epoch 97\n",
      "0.5063234294454256\n",
      "Starting Epoch 98\n",
      "0.5069737434387207\n",
      "Starting Epoch 99\n",
      "0.504503782838583\n",
      "Starting Epoch 100\n",
      "0.5045799538493156\n",
      "Starting Epoch 101\n",
      "0.5003452387948831\n",
      "New best model found at epoch 101 with validation loss 0.49628931283950806\n",
      "Starting Epoch 102\n",
      "0.502732245872418\n",
      "Starting Epoch 103\n",
      "0.503888993213574\n",
      "Starting Epoch 104\n",
      "0.5067340632279714\n",
      "Starting Epoch 105\n",
      "0.5029294602572918\n",
      "Starting Epoch 106\n",
      "0.5014099751909574\n",
      "Starting Epoch 107\n",
      "0.50150599082311\n",
      "Starting Epoch 108\n",
      "0.4998719369371732\n",
      "Starting Epoch 109\n",
      "0.5043960486849149\n",
      "Starting Epoch 110\n",
      "0.5056250269214312\n",
      "Starting Epoch 111\n",
      "0.5015573787192503\n",
      "Starting Epoch 112\n",
      "0.5026145490507284\n",
      "Starting Epoch 113\n",
      "0.5010952850182852\n",
      "New best model found at epoch 113 with validation loss 0.4951823353767395\n",
      "Starting Epoch 114\n",
      "0.5024558293322722\n",
      "Starting Epoch 115\n",
      "0.5026479500035445\n",
      "Starting Epoch 116\n",
      "0.5013862028717995\n",
      "New best model found at epoch 116 with validation loss 0.494559109210968\n",
      "Starting Epoch 117\n",
      "0.499315785864989\n",
      "New best model found at epoch 117 with validation loss 0.4918611943721771\n",
      "Starting Epoch 118\n",
      "0.4993279042343299\n",
      "Starting Epoch 119\n",
      "0.4977228343486786\n",
      "Starting Epoch 120\n",
      "0.4990048718949159\n",
      "Starting Epoch 121\n",
      "0.4981817975640297\n",
      "Starting Epoch 122\n",
      "0.5021080821752548\n",
      "Starting Epoch 123\n",
      "0.49882500246167183\n",
      "Starting Epoch 124\n",
      "0.49884362891316414\n",
      "Starting Epoch 125\n",
      "0.4995120478173097\n",
      "Starting Epoch 126\n",
      "0.5044260757664839\n",
      "New best model found at epoch 126 with validation loss 0.4912291169166565\n",
      "Starting Epoch 127\n",
      "0.49622522418697673\n",
      "Starting Epoch 128\n",
      "0.5003879169623057\n",
      "Starting Epoch 129\n",
      "0.5008917724092802\n",
      "Starting Epoch 130\n",
      "0.5009024428824583\n",
      "Starting Epoch 131\n",
      "0.4970548910399278\n",
      "Starting Epoch 132\n",
      "0.5007956251502037\n",
      "Starting Epoch 133\n",
      "0.49758967757225037\n",
      "Starting Epoch 134\n",
      "0.49884245668848354\n",
      "Starting Epoch 135\n",
      "0.5002640063563982\n",
      "New best model found at epoch 135 with validation loss 0.4884539544582367\n",
      "Starting Epoch 136\n",
      "0.49502462645371753\n",
      "Starting Epoch 137\n",
      "0.5000206617017587\n",
      "Starting Epoch 138\n",
      "0.5011391577621301\n",
      "Starting Epoch 139\n",
      "0.4960690774023533\n",
      "Starting Epoch 140\n",
      "0.4958863730231921\n",
      "New best model found at epoch 140 with validation loss 0.4863789677619934\n",
      "Starting Epoch 141\n",
      "0.49923529475927353\n",
      "Starting Epoch 142\n",
      "0.49442509934306145\n",
      "New best model found at epoch 142 with validation loss 0.4858223497867584\n",
      "Starting Epoch 143\n",
      "0.4994879439473152\n",
      "Starting Epoch 144\n",
      "0.49843016515175503\n",
      "Starting Epoch 145\n",
      "0.49922435233990353\n",
      "Starting Epoch 146\n",
      "0.495401697854201\n",
      "Starting Epoch 147\n",
      "0.49694177880883217\n",
      "Starting Epoch 148\n",
      "0.495034109801054\n",
      "Starting Epoch 149\n",
      "0.4968702805538972\n",
      "Starting Epoch 150\n",
      "0.4963832423090935\n",
      "Starting Epoch 151\n",
      "0.49604569127162296\n",
      "Starting Epoch 152\n",
      "0.4971962347626686\n",
      "New best model found at epoch 152 with validation loss 0.4847809076309204\n",
      "Starting Epoch 153\n",
      "0.4952089252571265\n",
      "Starting Epoch 154\n",
      "0.4964664652943611\n",
      "Starting Epoch 155\n",
      "0.4959886570771535\n",
      "Starting Epoch 156\n",
      "0.4969814320405324\n",
      "Starting Epoch 157\n",
      "0.4959869037071864\n",
      "Starting Epoch 158\n",
      "0.4949326068162918\n",
      "Starting Epoch 159\n",
      "0.4932336248457432\n",
      "Starting Epoch 160\n",
      "0.49559155230720836\n",
      "New best model found at epoch 160 with validation loss 0.48373857140541077\n",
      "Starting Epoch 161\n",
      "0.5009644143283367\n",
      "Starting Epoch 162\n",
      "0.498541172593832\n",
      "Starting Epoch 163\n",
      "0.4935908118883769\n",
      "Starting Epoch 164\n",
      "0.4931080328921477\n",
      "New best model found at epoch 164 with validation loss 0.4830659329891205\n",
      "Starting Epoch 165\n",
      "0.4966870533923308\n",
      "Starting Epoch 166\n",
      "0.4905250283579032\n",
      "Starting Epoch 167\n",
      "0.4956295055647691\n",
      "Starting Epoch 168\n",
      "0.495857593913873\n",
      "Starting Epoch 169\n",
      "0.49492239703734714\n",
      "Starting Epoch 170\n",
      "0.4944680755337079\n",
      "Starting Epoch 171\n",
      "0.49550331259767216\n",
      "Starting Epoch 172\n",
      "0.49313971027731895\n",
      "Starting Epoch 173\n",
      "0.49150064463416737\n",
      "Starting Epoch 174\n",
      "0.49433748920758563\n",
      "Starting Epoch 175\n",
      "0.49594903116424877\n",
      "Starting Epoch 176\n",
      "0.4937227815389633\n",
      "Starting Epoch 177\n",
      "0.4954306135574977\n",
      "Starting Epoch 178\n",
      "0.49474578599135083\n",
      "Starting Epoch 179\n",
      "0.49337467923760414\n",
      "Starting Epoch 180\n",
      "0.4980447168151538\n",
      "Starting Epoch 181\n",
      "0.4935249562064807\n",
      "Starting Epoch 182\n",
      "0.49294937153657276\n",
      "Starting Epoch 183\n",
      "0.4947816456357638\n",
      "Starting Epoch 184\n",
      "0.49009615431229275\n",
      "Starting Epoch 185\n",
      "0.49181363607446354\n",
      "New best model found at epoch 185 with validation loss 0.4811719059944153\n",
      "Starting Epoch 186\n",
      "0.4907445125281811\n",
      "Starting Epoch 187\n",
      "0.4931449020902316\n",
      "Starting Epoch 188\n",
      "0.49322209879755974\n",
      "Starting Epoch 189\n",
      "0.49532843256990117\n",
      "Starting Epoch 190\n",
      "0.4918167156477769\n",
      "Starting Epoch 191\n",
      "0.49696604907512665\n",
      "New best model found at epoch 191 with validation loss 0.48082929849624634\n",
      "Starting Epoch 192\n",
      "0.4942791499197483\n",
      "Starting Epoch 193\n",
      "0.49452584981918335\n",
      "Starting Epoch 194\n",
      "0.49328291167815524\n",
      "New best model found at epoch 194 with validation loss 0.4784986972808838\n",
      "Starting Epoch 195\n",
      "0.4925229363143444\n",
      "Starting Epoch 196\n",
      "0.49378258859117824\n",
      "Starting Epoch 197\n",
      "0.4910617197553317\n",
      "Starting Epoch 198\n",
      "0.49335281550884247\n",
      "Starting Epoch 199\n",
      "0.4913062850634257\n",
      "Starting Epoch 200\n",
      "0.4908415414392948\n",
      "Starting Epoch 201\n",
      "0.48990531886617344\n",
      "Starting Epoch 202\n",
      "0.49102868884801865\n",
      "Starting Epoch 203\n",
      "0.49353256821632385\n",
      "New best model found at epoch 203 with validation loss 0.47839173674583435\n",
      "Starting Epoch 204\n",
      "0.49148476496338844\n",
      "Starting Epoch 205\n",
      "0.49231404066085815\n",
      "Starting Epoch 206\n",
      "0.4929838577906291\n",
      "Starting Epoch 207\n",
      "0.48952026416858035\n",
      "Starting Epoch 208\n",
      "0.4920879118144512\n",
      "Starting Epoch 209\n",
      "0.49015600110093754\n",
      "Starting Epoch 210\n",
      "0.4891072151561578\n",
      "Starting Epoch 211\n",
      "0.49195267880956334\n",
      "New best model found at epoch 211 with validation loss 0.47557532787323\n",
      "Starting Epoch 212\n",
      "0.49340364212791127\n",
      "Starting Epoch 213\n",
      "0.4908927318950494\n",
      "Starting Epoch 214\n",
      "0.4903452756504218\n",
      "Starting Epoch 215\n",
      "0.4905998061100642\n",
      "Starting Epoch 216\n",
      "0.4912563847998778\n",
      "Starting Epoch 217\n",
      "0.4907406394680341\n",
      "Starting Epoch 218\n",
      "0.4925803169608116\n",
      "Starting Epoch 219\n",
      "0.49506725122531253\n",
      "Starting Epoch 220\n",
      "0.49118459845582646\n",
      "New best model found at epoch 220 with validation loss 0.4737739861011505\n",
      "Starting Epoch 221\n",
      "0.4946153225998084\n",
      "Starting Epoch 222\n",
      "0.4912903159856796\n",
      "Starting Epoch 223\n",
      "0.4893788620829582\n",
      "Starting Epoch 224\n",
      "0.4900675726433595\n",
      "Starting Epoch 225\n",
      "0.48997186372677487\n",
      "Starting Epoch 226\n",
      "0.4894077467421691\n",
      "Starting Epoch 227\n",
      "0.4912726506590843\n",
      "Starting Epoch 228\n",
      "0.4902651111284892\n",
      "Starting Epoch 229\n",
      "0.4881901393334071\n",
      "Starting Epoch 230\n",
      "0.4891633242368698\n",
      "Starting Epoch 231\n",
      "0.48995279396573704\n",
      "Starting Epoch 232\n",
      "0.49000082165002823\n",
      "Starting Epoch 233\n",
      "0.4910791603227456\n",
      "Starting Epoch 234\n",
      "0.48996221895019215\n",
      "Starting Epoch 235\n",
      "0.491184023519357\n",
      "Starting Epoch 236\n",
      "0.49199114988247555\n",
      "Starting Epoch 237\n",
      "0.48822295914093655\n",
      "Starting Epoch 238\n",
      "0.4892048252125581\n",
      "Starting Epoch 239\n",
      "0.4888249896466732\n",
      "Starting Epoch 240\n",
      "0.4900059911111991\n",
      "New best model found at epoch 240 with validation loss 0.4728511869907379\n",
      "Starting Epoch 241\n",
      "0.4924487831691901\n",
      "Starting Epoch 242\n",
      "0.48889169842004776\n",
      "Starting Epoch 243\n",
      "0.48546136543154716\n",
      "Starting Epoch 244\n",
      "0.49323588112990063\n",
      "Starting Epoch 245\n",
      "0.49020907034476596\n",
      "Starting Epoch 246\n",
      "0.4897332576413949\n",
      "Starting Epoch 247\n",
      "0.48952118307352066\n",
      "Starting Epoch 248\n",
      "0.4898768986264865\n",
      "New best model found at epoch 248 with validation loss 0.47277310490608215\n",
      "Starting Epoch 249\n",
      "0.48922761157155037\n",
      "Starting Epoch 250\n",
      "0.4876831943790118\n",
      "Starting Epoch 251\n",
      "0.4910747557878494\n",
      "Starting Epoch 252\n",
      "0.48936905215183896\n",
      "Starting Epoch 253\n",
      "0.48871950308481854\n",
      "Starting Epoch 254\n",
      "0.4872655048966408\n",
      "Starting Epoch 255\n",
      "0.48702691371242207\n",
      "New best model found at epoch 255 with validation loss 0.4713016152381897\n",
      "Starting Epoch 256\n",
      "0.48818176488081616\n",
      "Starting Epoch 257\n",
      "0.48653296505411464\n",
      "Starting Epoch 258\n",
      "0.4887446040908496\n",
      "New best model found at epoch 258 with validation loss 0.4698539972305298\n",
      "Starting Epoch 259\n",
      "0.490275834997495\n",
      "Starting Epoch 260\n",
      "0.48890166978041333\n",
      "Starting Epoch 261\n",
      "0.48805637781818706\n",
      "Starting Epoch 262\n",
      "0.48734748487671214\n",
      "Starting Epoch 263\n",
      "0.48995815465847653\n",
      "Starting Epoch 264\n",
      "0.48821693037947017\n",
      "Starting Epoch 265\n",
      "0.4914811700582504\n",
      "Starting Epoch 266\n",
      "0.4899798023204009\n",
      "Starting Epoch 267\n",
      "0.48668427144487697\n",
      "Starting Epoch 268\n",
      "0.48733578622341156\n",
      "Starting Epoch 269\n",
      "0.4871961697936058\n",
      "Starting Epoch 270\n",
      "0.48621316875020665\n",
      "Starting Epoch 271\n",
      "0.48591096078356105\n",
      "Starting Epoch 272\n",
      "0.48724029834071797\n",
      "Starting Epoch 273\n",
      "0.4876469212273757\n",
      "Starting Epoch 274\n",
      "0.4856252421935399\n",
      "Starting Epoch 275\n",
      "0.4883115850389004\n",
      "Starting Epoch 276\n",
      "0.4876997483273347\n",
      "Starting Epoch 277\n",
      "0.48893243819475174\n",
      "Starting Epoch 278\n",
      "0.4910803685585658\n",
      "Starting Epoch 279\n",
      "0.48848052074511844\n",
      "Starting Epoch 280\n",
      "0.4855537563562393\n",
      "Starting Epoch 281\n",
      "0.4855305813252926\n",
      "Starting Epoch 282\n",
      "0.48759814103444415\n",
      "Starting Epoch 283\n",
      "0.4908611091474692\n",
      "Starting Epoch 284\n",
      "0.48588526993989944\n",
      "Starting Epoch 285\n",
      "0.48641465976834297\n",
      "New best model found at epoch 285 with validation loss 0.4687804579734802\n",
      "Starting Epoch 286\n",
      "0.4876190808912118\n",
      "Starting Epoch 287\n",
      "0.4859380970398585\n",
      "Starting Epoch 288\n",
      "0.4851348325610161\n",
      "Starting Epoch 289\n",
      "0.4880160962541898\n",
      "Starting Epoch 290\n",
      "0.4852270459135373\n",
      "Starting Epoch 291\n",
      "0.4868830678363641\n",
      "Starting Epoch 292\n",
      "0.4869080086549123\n",
      "Starting Epoch 293\n",
      "0.4864654156068961\n",
      "Starting Epoch 294\n",
      "0.48624680439631146\n",
      "Starting Epoch 295\n",
      "0.4858872964978218\n",
      "Starting Epoch 296\n",
      "0.486861286063989\n",
      "Starting Epoch 297\n",
      "0.48556584243973094\n",
      "Starting Epoch 298\n",
      "0.48532236988345784\n",
      "Starting Epoch 299\n",
      "0.4850987146298091\n",
      "Starting Epoch 300\n",
      "0.48839884251356125\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-20-10-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a290800",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 3\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 20 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "76869e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "fca0f798-2d8e-4036-ac9c-f5ce03a02a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.9840214525659879\n",
      "New best model found at epoch 1 with validation loss 0.590629518032074\n",
      "Starting Epoch 2\n",
      "0.5996841316421827\n",
      "New best model found at epoch 2 with validation loss 0.5677183270454407\n",
      "Starting Epoch 3\n",
      "0.5814636747042338\n",
      "Starting Epoch 4\n",
      "0.5823670489092668\n",
      "Starting Epoch 5\n",
      "0.5779256286720434\n",
      "Starting Epoch 6\n",
      "0.5759276896715164\n",
      "Starting Epoch 7\n",
      "0.5743923584620158\n",
      "Starting Epoch 8\n",
      "0.574910561243693\n",
      "New best model found at epoch 8 with validation loss 0.5667933225631714\n",
      "Starting Epoch 9\n",
      "0.5721495350201925\n",
      "Starting Epoch 10\n",
      "0.5694425043960413\n",
      "Starting Epoch 11\n",
      "0.5738466108838717\n",
      "New best model found at epoch 11 with validation loss 0.5661737322807312\n",
      "Starting Epoch 12\n",
      "0.5692396486798922\n",
      "Starting Epoch 13\n",
      "0.5699529126286507\n",
      "New best model found at epoch 13 with validation loss 0.5620254874229431\n",
      "Starting Epoch 14\n",
      "0.5658598902324835\n",
      "Starting Epoch 15\n",
      "0.5690953222413858\n",
      "New best model found at epoch 15 with validation loss 0.5614312291145325\n",
      "Starting Epoch 16\n",
      "0.56483955681324\n",
      "New best model found at epoch 16 with validation loss 0.554994523525238\n",
      "Starting Epoch 17\n",
      "0.5691796702643236\n",
      "Starting Epoch 18\n",
      "0.5650294894973437\n",
      "Starting Epoch 19\n",
      "0.5633406614263853\n",
      "New best model found at epoch 19 with validation loss 0.549426257610321\n",
      "Starting Epoch 20\n",
      "0.5593792709211508\n",
      "Starting Epoch 21\n",
      "0.5584268184999625\n",
      "Starting Epoch 22\n",
      "0.5597372837364674\n",
      "New best model found at epoch 22 with validation loss 0.5474843382835388\n",
      "Starting Epoch 23\n",
      "0.5559589204688867\n",
      "Starting Epoch 24\n",
      "0.555774404356877\n",
      "New best model found at epoch 24 with validation loss 0.5413095951080322\n",
      "Starting Epoch 25\n",
      "0.5507471077144146\n",
      "Starting Epoch 26\n",
      "0.5495106788973013\n",
      "Starting Epoch 27\n",
      "0.5498577430844307\n",
      "New best model found at epoch 27 with validation loss 0.5378523468971252\n",
      "Starting Epoch 28\n",
      "0.5470158370832602\n",
      "New best model found at epoch 28 with validation loss 0.5342728495597839\n",
      "Starting Epoch 29\n",
      "0.546989668160677\n",
      "Starting Epoch 30\n",
      "0.5430869422852993\n",
      "New best model found at epoch 30 with validation loss 0.5336591005325317\n",
      "Starting Epoch 31\n",
      "0.544752299785614\n",
      "Starting Epoch 32\n",
      "0.5529063207407793\n",
      "Starting Epoch 33\n",
      "0.5454763111968836\n",
      "New best model found at epoch 33 with validation loss 0.5300520658493042\n",
      "Starting Epoch 34\n",
      "0.5464294192691644\n",
      "Starting Epoch 35\n",
      "0.5406278086205324\n",
      "Starting Epoch 36\n",
      "0.5412206500768661\n",
      "New best model found at epoch 36 with validation loss 0.52635657787323\n",
      "Starting Epoch 37\n",
      "0.5412122085690498\n",
      "Starting Epoch 38\n",
      "0.538992972423633\n",
      "Starting Epoch 39\n",
      "0.5439283363521099\n",
      "Starting Epoch 40\n",
      "0.5374367001156012\n",
      "New best model found at epoch 40 with validation loss 0.5243988633155823\n",
      "Starting Epoch 41\n",
      "0.5380237226684889\n",
      "New best model found at epoch 41 with validation loss 0.5220869779586792\n",
      "Starting Epoch 42\n",
      "0.5381116407612959\n",
      "New best model found at epoch 42 with validation loss 0.5207018256187439\n",
      "Starting Epoch 43\n",
      "0.5405417966345946\n",
      "Starting Epoch 44\n",
      "0.5335717486838499\n",
      "Starting Epoch 45\n",
      "0.5351322690645853\n",
      "Starting Epoch 46\n",
      "0.5383492161830267\n",
      "Starting Epoch 47\n",
      "0.533579483628273\n",
      "Starting Epoch 48\n",
      "0.5355383393665155\n",
      "New best model found at epoch 48 with validation loss 0.5199852585792542\n",
      "Starting Epoch 49\n",
      "0.5354110822081566\n",
      "Starting Epoch 50\n",
      "0.5367404681940874\n",
      "Starting Epoch 51\n",
      "0.5365934061507384\n",
      "Starting Epoch 52\n",
      "0.5322567435602347\n",
      "Starting Epoch 53\n",
      "0.5382483912010988\n",
      "Starting Epoch 54\n",
      "0.5344363761444887\n",
      "Starting Epoch 55\n",
      "0.5310353164871534\n",
      "New best model found at epoch 55 with validation loss 0.5194823741912842\n",
      "Starting Epoch 56\n",
      "0.5370082172254721\n",
      "New best model found at epoch 56 with validation loss 0.5190407037734985\n",
      "Starting Epoch 57\n",
      "0.5314939779539903\n",
      "Starting Epoch 58\n",
      "0.5329200774431229\n",
      "Starting Epoch 59\n",
      "0.5334667017062505\n",
      "Starting Epoch 60\n",
      "0.5295163653790951\n",
      "Starting Epoch 61\n",
      "0.5318245254456997\n",
      "Starting Epoch 62\n",
      "0.5332526974380016\n",
      "Starting Epoch 63\n",
      "0.529874129841725\n",
      "Starting Epoch 64\n",
      "0.530552115291357\n",
      "Starting Epoch 65\n",
      "0.5304573786755403\n",
      "Starting Epoch 66\n",
      "0.5277153998613358\n",
      "New best model found at epoch 66 with validation loss 0.5190020203590393\n",
      "Starting Epoch 67\n",
      "0.5335728960732619\n",
      "Starting Epoch 68\n",
      "0.5288905041913191\n",
      "Starting Epoch 69\n",
      "0.5282466771701971\n",
      "Starting Epoch 70\n",
      "0.5322756779690584\n",
      "Starting Epoch 71\n",
      "0.5312347722550234\n",
      "Starting Epoch 72\n",
      "0.531009870270888\n",
      "Starting Epoch 73\n",
      "0.5287763563295206\n",
      "Starting Epoch 74\n",
      "0.5261848034958044\n",
      "Starting Epoch 75\n",
      "0.5263578283290068\n",
      "Starting Epoch 76\n",
      "0.530271208534638\n",
      "New best model found at epoch 76 with validation loss 0.5175220966339111\n",
      "Starting Epoch 77\n",
      "0.5301785618066788\n",
      "Starting Epoch 78\n",
      "0.528945571432511\n",
      "Starting Epoch 79\n",
      "0.5247044687469801\n",
      "Starting Epoch 80\n",
      "0.5298534122606119\n",
      "Starting Epoch 81\n",
      "0.5254282181461652\n",
      "New best model found at epoch 81 with validation loss 0.5163830518722534\n",
      "Starting Epoch 82\n",
      "0.5300251990556717\n",
      "Starting Epoch 83\n",
      "0.5260572532812754\n",
      "Starting Epoch 84\n",
      "0.5319538426895937\n",
      "Starting Epoch 85\n",
      "0.5319965456922849\n",
      "New best model found at epoch 85 with validation loss 0.5153458118438721\n",
      "Starting Epoch 86\n",
      "0.5249453186988831\n",
      "Starting Epoch 87\n",
      "0.5233911362787088\n",
      "Starting Epoch 88\n",
      "0.5269526367386183\n",
      "Starting Epoch 89\n",
      "0.5251188526550928\n",
      "Starting Epoch 90\n",
      "0.5260355373223623\n",
      "Starting Epoch 91\n",
      "0.5233197162548701\n",
      "Starting Epoch 92\n",
      "0.5252619261542956\n",
      "Starting Epoch 93\n",
      "0.5247688107192516\n",
      "Starting Epoch 94\n",
      "0.522692778458198\n",
      "Starting Epoch 95\n",
      "0.522148766865333\n",
      "New best model found at epoch 95 with validation loss 0.5151817798614502\n",
      "Starting Epoch 96\n",
      "0.5221561814347903\n",
      "Starting Epoch 97\n",
      "0.5237149161597093\n",
      "Starting Epoch 98\n",
      "0.5232217709223429\n",
      "Starting Epoch 99\n",
      "0.5225750766694546\n",
      "Starting Epoch 100\n",
      "0.5207730183998743\n",
      "New best model found at epoch 100 with validation loss 0.51358962059021\n",
      "Starting Epoch 101\n",
      "0.5225917734205723\n",
      "New best model found at epoch 101 with validation loss 0.5102912187576294\n",
      "Starting Epoch 102\n",
      "0.5240042743583521\n",
      "Starting Epoch 103\n",
      "0.5213826075196266\n",
      "Starting Epoch 104\n",
      "0.5233771738906702\n",
      "Starting Epoch 105\n",
      "0.5225102665523688\n",
      "Starting Epoch 106\n",
      "0.5276889763772488\n",
      "Starting Epoch 107\n",
      "0.5240516190727552\n",
      "Starting Epoch 108\n",
      "0.5214256805678209\n",
      "Starting Epoch 109\n",
      "0.5225183380146822\n",
      "Starting Epoch 110\n",
      "0.5241302077968916\n",
      "Starting Epoch 111\n",
      "0.5221140856544176\n",
      "Starting Epoch 112\n",
      "0.5212688532968363\n",
      "Starting Epoch 113\n",
      "0.5234856928388277\n",
      "Starting Epoch 114\n",
      "0.5232286266982555\n",
      "Starting Epoch 115\n",
      "0.5196196114023527\n",
      "Starting Epoch 116\n",
      "0.5220688370366892\n",
      "Starting Epoch 117\n",
      "0.5198906349639097\n",
      "Starting Epoch 118\n",
      "0.5182452375690142\n",
      "Starting Epoch 119\n",
      "0.519835943977038\n",
      "Starting Epoch 120\n",
      "0.5214031636714935\n",
      "Starting Epoch 121\n",
      "0.5185036572317282\n",
      "Starting Epoch 122\n",
      "0.520483810454607\n",
      "Starting Epoch 123\n",
      "0.5216329532365004\n",
      "Starting Epoch 124\n",
      "0.5196151013175646\n",
      "Starting Epoch 125\n",
      "0.5177157757182916\n",
      "Starting Epoch 126\n",
      "0.5193527067701021\n",
      "Starting Epoch 127\n",
      "0.5195333150525888\n",
      "Starting Epoch 128\n",
      "0.5192885783811411\n",
      "Starting Epoch 129\n",
      "0.5181767878433069\n",
      "Starting Epoch 130\n",
      "0.5175530215104421\n",
      "Starting Epoch 131\n",
      "0.518532062570254\n",
      "Starting Epoch 132\n",
      "0.5170759422083696\n",
      "Starting Epoch 133\n",
      "0.5186611153185368\n",
      "Starting Epoch 134\n",
      "0.5169142733017603\n",
      "Starting Epoch 135\n",
      "0.5173929358522097\n",
      "Starting Epoch 136\n",
      "0.520778783907493\n",
      "Starting Epoch 137\n",
      "0.5231740102171898\n",
      "Starting Epoch 138\n",
      "0.5192482694983482\n",
      "Starting Epoch 139\n",
      "0.5165122461815675\n",
      "Starting Epoch 140\n",
      "0.5211041507621607\n",
      "Starting Epoch 141\n",
      "0.5163743185500304\n",
      "Starting Epoch 142\n",
      "0.5185918472707272\n",
      "Starting Epoch 143\n",
      "0.5185967373351256\n",
      "Starting Epoch 144\n",
      "0.5234560507039229\n",
      "Starting Epoch 145\n",
      "0.5173173608879248\n",
      "Starting Epoch 146\n",
      "0.513906559596459\n",
      "Starting Epoch 147\n",
      "0.5158735699951649\n",
      "Starting Epoch 148\n",
      "0.5175219165782133\n",
      "Starting Epoch 149\n",
      "0.5203636984030405\n",
      "Starting Epoch 150\n",
      "0.5161226987838745\n",
      "Starting Epoch 151\n",
      "0.5190355814993382\n",
      "Starting Epoch 152\n",
      "0.5190509296953678\n",
      "Starting Epoch 153\n",
      "0.5162089603642622\n",
      "Starting Epoch 154\n",
      "0.5177096575498581\n",
      "Starting Epoch 155\n",
      "0.5166877644757429\n",
      "Starting Epoch 156\n",
      "0.5165569285551707\n",
      "Starting Epoch 157\n",
      "0.5153093462189039\n",
      "Starting Epoch 158\n",
      "0.5133538270990053\n",
      "Starting Epoch 159\n",
      "0.5155307278037071\n",
      "Starting Epoch 160\n",
      "0.5182042072216669\n",
      "Starting Epoch 161\n",
      "0.5172111342350642\n",
      "Starting Epoch 162\n",
      "0.5164342845479647\n",
      "Starting Epoch 163\n",
      "0.5119826594988505\n",
      "Starting Epoch 164\n",
      "0.5193127207458019\n",
      "Starting Epoch 165\n",
      "0.5184405446052551\n",
      "Starting Epoch 166\n",
      "0.515323224167029\n",
      "Starting Epoch 167\n",
      "0.5153100999693075\n",
      "Starting Epoch 168\n",
      "0.5157712996006012\n",
      "Starting Epoch 169\n",
      "0.5149484649300575\n",
      "Starting Epoch 170\n",
      "0.5128338734308878\n",
      "Starting Epoch 171\n",
      "0.5154012714823087\n",
      "Starting Epoch 172\n",
      "0.5130471338828405\n",
      "Starting Epoch 173\n",
      "0.5132481356461843\n",
      "Starting Epoch 174\n",
      "0.5130966827273369\n",
      "Starting Epoch 175\n",
      "0.5150267332792282\n",
      "Starting Epoch 176\n",
      "0.5147954796751341\n",
      "Starting Epoch 177\n",
      "0.5147398263216019\n",
      "Starting Epoch 178\n",
      "0.513563676426808\n",
      "New best model found at epoch 178 with validation loss 0.5100829005241394\n",
      "Starting Epoch 179\n",
      "0.514594583461682\n",
      "Starting Epoch 180\n",
      "0.5114360364774863\n",
      "Starting Epoch 181\n",
      "0.5161007009446621\n",
      "Starting Epoch 182\n",
      "0.5171342367927233\n",
      "Starting Epoch 183\n",
      "0.5154461239775022\n",
      "Starting Epoch 184\n",
      "0.5165075622498989\n",
      "Starting Epoch 185\n",
      "0.5125181724627813\n",
      "Starting Epoch 186\n",
      "0.5133268820742766\n",
      "Starting Epoch 187\n",
      "0.5123482570052147\n",
      "Starting Epoch 188\n",
      "0.5120283116896948\n",
      "Starting Epoch 189\n",
      "0.515665507564942\n",
      "Starting Epoch 190\n",
      "0.5130591578781605\n",
      "Starting Epoch 191\n",
      "0.5137400565048059\n",
      "Starting Epoch 192\n",
      "0.5144799016416073\n",
      "Starting Epoch 193\n",
      "0.5130919876197974\n",
      "Starting Epoch 194\n",
      "0.5104897481699785\n",
      "Starting Epoch 195\n",
      "0.5140073709189892\n",
      "Starting Epoch 196\n",
      "0.5122718599935373\n",
      "Starting Epoch 197\n",
      "0.5128541129330794\n",
      "Starting Epoch 198\n",
      "0.514136099567016\n",
      "Starting Epoch 199\n",
      "0.5098718417187532\n",
      "Starting Epoch 200\n",
      "0.5096858118971189\n",
      "Starting Epoch 201\n",
      "0.5119098871946335\n",
      "Starting Epoch 202\n",
      "0.5157720955709616\n",
      "Starting Epoch 203\n",
      "0.5097817766169707\n",
      "Starting Epoch 204\n",
      "0.5091728419065475\n",
      "Starting Epoch 205\n",
      "0.5164857991039753\n",
      "Starting Epoch 206\n",
      "0.5134983075161775\n",
      "Starting Epoch 207\n",
      "0.5139714106917381\n",
      "Starting Epoch 208\n",
      "0.5106377427776655\n",
      "Starting Epoch 209\n",
      "0.5103061323364576\n",
      "Starting Epoch 210\n",
      "0.5094294734299183\n",
      "Starting Epoch 211\n",
      "0.5075264995296797\n",
      "Starting Epoch 212\n",
      "0.5086748798688253\n",
      "Starting Epoch 213\n",
      "0.5102794443567594\n",
      "Starting Epoch 214\n",
      "0.5119811097780863\n",
      "New best model found at epoch 214 with validation loss 0.5096567869186401\n",
      "Starting Epoch 215\n",
      "0.5114168326059977\n",
      "New best model found at epoch 215 with validation loss 0.5081928372383118\n",
      "Starting Epoch 216\n",
      "0.5071676870187124\n",
      "Starting Epoch 217\n",
      "0.5119005739688873\n",
      "Starting Epoch 218\n",
      "0.5093177879850069\n",
      "Starting Epoch 219\n",
      "0.5094112629691759\n",
      "Starting Epoch 220\n",
      "0.5083471797406673\n",
      "New best model found at epoch 220 with validation loss 0.5074386596679688\n",
      "Starting Epoch 221\n",
      "0.509699517240127\n",
      "Starting Epoch 222\n",
      "0.5067489271362623\n",
      "Starting Epoch 223\n",
      "0.5044211323062578\n",
      "Starting Epoch 224\n",
      "0.5103752948343754\n",
      "Starting Epoch 225\n",
      "0.507192961871624\n",
      "Starting Epoch 226\n",
      "0.5086668394505978\n",
      "Starting Epoch 227\n",
      "0.5100786785284678\n",
      "Starting Epoch 228\n",
      "0.5080467090010643\n",
      "Starting Epoch 229\n",
      "0.5068097598850727\n",
      "Starting Epoch 230\n",
      "0.5119195853670439\n",
      "Starting Epoch 231\n",
      "0.5089170249799887\n",
      "New best model found at epoch 231 with validation loss 0.5061792135238647\n",
      "Starting Epoch 232\n",
      "0.5060981512069702\n",
      "Starting Epoch 233\n",
      "0.5085763446986675\n",
      "New best model found at epoch 233 with validation loss 0.5060754418373108\n",
      "Starting Epoch 234\n",
      "0.5087339803576469\n",
      "Starting Epoch 235\n",
      "0.506866741925478\n",
      "New best model found at epoch 235 with validation loss 0.5036860108375549\n",
      "Starting Epoch 236\n",
      "0.5076451761027178\n",
      "Starting Epoch 237\n",
      "0.5083109227319559\n",
      "Starting Epoch 238\n",
      "0.5079344150920709\n",
      "Starting Epoch 239\n",
      "0.5070710505048434\n",
      "Starting Epoch 240\n",
      "0.5065729382137457\n",
      "Starting Epoch 241\n",
      "0.5068479391435782\n",
      "Starting Epoch 242\n",
      "0.5038012104729811\n",
      "Starting Epoch 243\n",
      "0.5124655117591222\n",
      "Starting Epoch 244\n",
      "0.5060882717370987\n",
      "Starting Epoch 245\n",
      "0.5034287708501021\n",
      "Starting Epoch 246\n",
      "0.5072911481062571\n",
      "Starting Epoch 247\n",
      "0.5051436622937521\n",
      "Starting Epoch 248\n",
      "0.5070165122548739\n",
      "Starting Epoch 249\n",
      "0.5033758717278639\n",
      "Starting Epoch 250\n",
      "0.5069225629170736\n",
      "Starting Epoch 251\n",
      "0.5054521063963572\n",
      "Starting Epoch 252\n",
      "0.5068426318466663\n",
      "Starting Epoch 253\n",
      "0.5030665310720602\n",
      "Starting Epoch 254\n",
      "0.5052633831898371\n",
      "Starting Epoch 255\n",
      "0.5041399498780569\n",
      "Starting Epoch 256\n",
      "0.5052257776260376\n",
      "Starting Epoch 257\n",
      "0.5024853808184465\n",
      "Starting Epoch 258\n",
      "0.5063572525978088\n",
      "Starting Epoch 259\n",
      "0.5041221293310324\n",
      "Starting Epoch 260\n",
      "0.506522083034118\n",
      "New best model found at epoch 260 with validation loss 0.50284743309021\n",
      "Starting Epoch 261\n",
      "0.5052611442903677\n",
      "Starting Epoch 262\n",
      "0.5049737095832825\n",
      "Starting Epoch 263\n",
      "0.5059057325124741\n",
      "Starting Epoch 264\n",
      "0.5020487991472086\n",
      "Starting Epoch 265\n",
      "0.5044185829659303\n",
      "Starting Epoch 266\n",
      "0.5009719245135784\n",
      "Starting Epoch 267\n",
      "0.5017467538515726\n",
      "Starting Epoch 268\n",
      "0.5054463657240073\n",
      "Starting Epoch 269\n",
      "0.5054922439157963\n",
      "Starting Epoch 270\n",
      "0.5038048649827639\n",
      "Starting Epoch 271\n",
      "0.504666325946649\n",
      "Starting Epoch 272\n",
      "0.5025502853095531\n",
      "Starting Epoch 273\n",
      "0.5038907676935196\n",
      "Starting Epoch 274\n",
      "0.5040123164653778\n",
      "New best model found at epoch 274 with validation loss 0.49894067645072937\n",
      "Starting Epoch 275\n",
      "0.503095289071401\n",
      "Starting Epoch 276\n",
      "0.505202499528726\n",
      "Starting Epoch 277\n",
      "0.5046751039723555\n",
      "Starting Epoch 278\n",
      "0.5005334752301375\n",
      "Starting Epoch 279\n",
      "0.5016849388678869\n",
      "Starting Epoch 280\n",
      "0.502104613929987\n",
      "New best model found at epoch 280 with validation loss 0.49817946553230286\n",
      "Starting Epoch 281\n",
      "0.5011137636999289\n",
      "Starting Epoch 282\n",
      "0.4994189143180847\n",
      "Starting Epoch 283\n",
      "0.5026602645715078\n",
      "Starting Epoch 284\n",
      "0.5029527979592482\n",
      "Starting Epoch 285\n",
      "0.49811773250500363\n",
      "Starting Epoch 286\n",
      "0.5014237302045027\n",
      "Starting Epoch 287\n",
      "0.4998328424990177\n",
      "Starting Epoch 288\n",
      "0.4993761864801248\n",
      "Starting Epoch 289\n",
      "0.4990278209249179\n",
      "Starting Epoch 290\n",
      "0.49905949210127193\n",
      "Starting Epoch 291\n",
      "0.499410018324852\n",
      "Starting Epoch 292\n",
      "0.499469564606746\n",
      "Starting Epoch 293\n",
      "0.4974972866475582\n",
      "Starting Epoch 294\n",
      "0.49664652595917386\n",
      "Starting Epoch 295\n",
      "0.4991590119898319\n",
      "Starting Epoch 296\n",
      "0.5020875471333662\n",
      "Starting Epoch 297\n",
      "0.5013629496097565\n",
      "Starting Epoch 298\n",
      "0.4974353536963463\n",
      "New best model found at epoch 298 with validation loss 0.4962601363658905\n",
      "Starting Epoch 299\n",
      "0.49883198986450833\n",
      "Starting Epoch 300\n",
      "0.4994104454914729\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-40-20-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6abdb9",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 10 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "65d3ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "630846d5-8374-4f68-886b-e26d71862b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.8191209261616071\n",
      "New best model found at epoch 1 with validation loss 0.5813604593276978\n",
      "Starting Epoch 2\n",
      "0.5842991744478544\n",
      "New best model found at epoch 2 with validation loss 0.5677634477615356\n",
      "Starting Epoch 3\n",
      "0.579484760761261\n",
      "New best model found at epoch 3 with validation loss 0.5650525689125061\n",
      "Starting Epoch 4\n",
      "0.571612456192573\n",
      "New best model found at epoch 4 with validation loss 0.5591917634010315\n",
      "Starting Epoch 5\n",
      "0.5705312291781107\n",
      "Starting Epoch 6\n",
      "0.5659071914851665\n",
      "New best model found at epoch 6 with validation loss 0.558246374130249\n",
      "Starting Epoch 7\n",
      "0.5657314906517664\n",
      "New best model found at epoch 7 with validation loss 0.5573199987411499\n",
      "Starting Epoch 8\n",
      "0.562456930677096\n",
      "New best model found at epoch 8 with validation loss 0.5524157881736755\n",
      "Starting Epoch 9\n",
      "0.5581733671327432\n",
      "Starting Epoch 10\n",
      "0.5565174805621306\n",
      "New best model found at epoch 10 with validation loss 0.5429893732070923\n",
      "Starting Epoch 11\n",
      "0.5542006542285284\n",
      "Starting Epoch 12\n",
      "0.5557158403098583\n",
      "Starting Epoch 13\n",
      "0.549102017035087\n",
      "New best model found at epoch 13 with validation loss 0.5360485315322876\n",
      "Starting Epoch 14\n",
      "0.5503674633800983\n",
      "Starting Epoch 15\n",
      "0.546915822972854\n",
      "Starting Epoch 16\n",
      "0.545239694416523\n",
      "Starting Epoch 17\n",
      "0.5463466507693132\n",
      "Starting Epoch 18\n",
      "0.5413735012213389\n",
      "New best model found at epoch 18 with validation loss 0.5346037149429321\n",
      "Starting Epoch 19\n",
      "0.5372087806463242\n",
      "New best model found at epoch 19 with validation loss 0.5299773216247559\n",
      "Starting Epoch 20\n",
      "0.5430846735835075\n",
      "Starting Epoch 21\n",
      "0.5503414968649546\n",
      "Starting Epoch 22\n",
      "0.5421575158834457\n",
      "Starting Epoch 23\n",
      "0.5331663116812706\n",
      "Starting Epoch 24\n",
      "0.5341094347337881\n",
      "New best model found at epoch 24 with validation loss 0.5274337530136108\n",
      "Starting Epoch 25\n",
      "0.5351088903844357\n",
      "New best model found at epoch 25 with validation loss 0.5238752365112305\n",
      "Starting Epoch 26\n",
      "0.5294205422202746\n",
      "Starting Epoch 27\n",
      "0.5348965339362621\n",
      "Starting Epoch 28\n",
      "0.5351213999092579\n",
      "Starting Epoch 29\n",
      "0.5311443855365118\n",
      "Starting Epoch 30\n",
      "0.5277801702419916\n",
      "Starting Epoch 31\n",
      "0.5289110640684763\n",
      "New best model found at epoch 31 with validation loss 0.5225093364715576\n",
      "Starting Epoch 32\n",
      "0.5250519377489885\n",
      "New best model found at epoch 32 with validation loss 0.5191560387611389\n",
      "Starting Epoch 33\n",
      "0.5267468330760797\n",
      "Starting Epoch 34\n",
      "0.5314288126925627\n",
      "Starting Epoch 35\n",
      "0.5281529476245245\n",
      "Starting Epoch 36\n",
      "0.5270700318117937\n",
      "Starting Epoch 37\n",
      "0.5283249045411745\n",
      "New best model found at epoch 37 with validation loss 0.5190869569778442\n",
      "Starting Epoch 38\n",
      "0.524301982174317\n",
      "Starting Epoch 39\n",
      "0.5253893757859865\n",
      "Starting Epoch 40\n",
      "0.5317735659579436\n",
      "Starting Epoch 41\n",
      "0.5247104888161024\n",
      "Starting Epoch 42\n",
      "0.5235504967470964\n",
      "Starting Epoch 43\n",
      "0.5256462804973125\n",
      "New best model found at epoch 43 with validation loss 0.5185521245002747\n",
      "Starting Epoch 44\n",
      "0.5189008377492428\n",
      "Starting Epoch 45\n",
      "0.5236598588526249\n",
      "Starting Epoch 46\n",
      "0.5224115314582983\n",
      "Starting Epoch 47\n",
      "0.5255771490434805\n",
      "Starting Epoch 48\n",
      "0.5247600128253301\n",
      "Starting Epoch 49\n",
      "0.5257860608398914\n",
      "Starting Epoch 50\n",
      "0.5242794466515383\n",
      "New best model found at epoch 50 with validation loss 0.5169855356216431\n",
      "Starting Epoch 51\n",
      "0.5230360726515452\n",
      "Starting Epoch 52\n",
      "0.5268517409761747\n",
      "Starting Epoch 53\n",
      "0.5232137031853199\n",
      "Starting Epoch 54\n",
      "0.5247031065324942\n",
      "New best model found at epoch 54 with validation loss 0.5134056806564331\n",
      "Starting Epoch 55\n",
      "0.5193358411391577\n",
      "Starting Epoch 56\n",
      "0.520194503168265\n",
      "New best model found at epoch 56 with validation loss 0.5115013122558594\n",
      "Starting Epoch 57\n",
      "0.5219624315698942\n",
      "Starting Epoch 58\n",
      "0.5219111454983553\n",
      "Starting Epoch 59\n",
      "0.5205081750949224\n",
      "Starting Epoch 60\n",
      "0.5187517777085304\n",
      "Starting Epoch 61\n",
      "0.517798475921154\n",
      "Starting Epoch 62\n",
      "0.5200503927965959\n",
      "Starting Epoch 63\n",
      "0.5191300834218661\n",
      "Starting Epoch 64\n",
      "0.5190009698271751\n",
      "Starting Epoch 65\n",
      "0.5213140547275543\n",
      "Starting Epoch 66\n",
      "0.5202230798701445\n",
      "Starting Epoch 67\n",
      "0.5176946682234606\n",
      "Starting Epoch 68\n",
      "0.5196836118896803\n",
      "Starting Epoch 69\n",
      "0.5182068049907684\n",
      "New best model found at epoch 69 with validation loss 0.510590136051178\n",
      "Starting Epoch 70\n",
      "0.5177513634165128\n",
      "Starting Epoch 71\n",
      "0.518463550756375\n",
      "Starting Epoch 72\n",
      "0.5205539229015509\n",
      "Starting Epoch 73\n",
      "0.5160559924940268\n",
      "New best model found at epoch 73 with validation loss 0.5104966759681702\n",
      "Starting Epoch 74\n",
      "0.515801110615333\n",
      "Starting Epoch 75\n",
      "0.5162200555205345\n",
      "Starting Epoch 76\n",
      "0.5190433065096537\n",
      "Starting Epoch 77\n",
      "0.5180265133579572\n",
      "Starting Epoch 78\n",
      "0.5190829634666443\n",
      "New best model found at epoch 78 with validation loss 0.5086790919303894\n",
      "Starting Epoch 79\n",
      "0.5191797912120819\n",
      "Starting Epoch 80\n",
      "0.5174720175564289\n",
      "Starting Epoch 81\n",
      "0.5186981831987699\n",
      "Starting Epoch 82\n",
      "0.5176212613781294\n",
      "Starting Epoch 83\n",
      "0.514036264270544\n",
      "Starting Epoch 84\n",
      "0.5169724908967813\n",
      "Starting Epoch 85\n",
      "0.5151510126888752\n",
      "Starting Epoch 86\n",
      "0.5145169521371523\n",
      "Starting Epoch 87\n",
      "0.5149212641020616\n",
      "Starting Epoch 88\n",
      "0.5146575768788656\n",
      "Starting Epoch 89\n",
      "0.5128721309204897\n",
      "Starting Epoch 90\n",
      "0.5149573112527529\n",
      "Starting Epoch 91\n",
      "0.5148488779862722\n",
      "Starting Epoch 92\n",
      "0.5144481485088667\n",
      "Starting Epoch 93\n",
      "0.5177529901266098\n",
      "Starting Epoch 94\n",
      "0.5135314712921778\n",
      "Starting Epoch 95\n",
      "0.515867910037438\n",
      "Starting Epoch 96\n",
      "0.5175302736461163\n",
      "Starting Epoch 97\n",
      "0.5101888962090015\n",
      "Starting Epoch 98\n",
      "0.5144373774528503\n",
      "Starting Epoch 99\n",
      "0.5121869531770548\n",
      "Starting Epoch 100\n",
      "0.5132005997002125\n",
      "Starting Epoch 101\n",
      "0.5142453263203303\n",
      "Starting Epoch 102\n",
      "0.5143349294861158\n",
      "New best model found at epoch 102 with validation loss 0.5080427527427673\n",
      "Starting Epoch 103\n",
      "0.5113026462495327\n",
      "Starting Epoch 104\n",
      "0.515760563313961\n",
      "Starting Epoch 105\n",
      "0.5130848375459512\n",
      "Starting Epoch 106\n",
      "0.5120687683423361\n",
      "Starting Epoch 107\n",
      "0.5108156402905782\n",
      "Starting Epoch 108\n",
      "0.5148008900384108\n",
      "New best model found at epoch 108 with validation loss 0.5071505308151245\n",
      "Starting Epoch 109\n",
      "0.5112343418101469\n",
      "Starting Epoch 110\n",
      "0.5108557765682539\n",
      "Starting Epoch 111\n",
      "0.5134568611780802\n",
      "Starting Epoch 112\n",
      "0.512887604534626\n",
      "Starting Epoch 113\n",
      "0.5127003801365694\n",
      "Starting Epoch 114\n",
      "0.5112562229235967\n",
      "Starting Epoch 115\n",
      "0.5105306804180145\n",
      "Starting Epoch 116\n",
      "0.5110519900918007\n",
      "Starting Epoch 117\n",
      "0.5106270102163156\n",
      "Starting Epoch 118\n",
      "0.5114580417672793\n",
      "Starting Epoch 119\n",
      "0.5096293625732263\n",
      "Starting Epoch 120\n",
      "0.5105265801151594\n",
      "Starting Epoch 121\n",
      "0.5116906935969988\n",
      "Starting Epoch 122\n",
      "0.5087942530711492\n",
      "Starting Epoch 123\n",
      "0.5162109310428301\n",
      "Starting Epoch 124\n",
      "0.5099723972380161\n",
      "Starting Epoch 125\n",
      "0.5117173194885254\n",
      "Starting Epoch 126\n",
      "0.5136186604698499\n",
      "Starting Epoch 127\n",
      "0.5093106205264727\n",
      "New best model found at epoch 127 with validation loss 0.5068237781524658\n",
      "Starting Epoch 128\n",
      "0.5090741080542406\n",
      "New best model found at epoch 128 with validation loss 0.506147027015686\n",
      "Starting Epoch 129\n",
      "0.509938350568215\n",
      "Starting Epoch 130\n",
      "0.5098400885860125\n",
      "Starting Epoch 131\n",
      "0.5099834526578585\n",
      "Starting Epoch 132\n",
      "0.5088682932158312\n",
      "Starting Epoch 133\n",
      "0.5112444286545118\n",
      "Starting Epoch 134\n",
      "0.5074566043913364\n",
      "Starting Epoch 135\n",
      "0.5108386253317198\n",
      "Starting Epoch 136\n",
      "0.5110201065738996\n",
      "Starting Epoch 137\n",
      "0.5140111508468787\n",
      "Starting Epoch 138\n",
      "0.5148824614783128\n",
      "Starting Epoch 139\n",
      "0.5102713443338871\n",
      "Starting Epoch 140\n",
      "0.5090645290911198\n",
      "Starting Epoch 141\n",
      "0.5070127695798874\n",
      "Starting Epoch 142\n",
      "0.5120030778149763\n",
      "Starting Epoch 143\n",
      "0.5109600101908048\n",
      "Starting Epoch 144\n",
      "0.5065534934401512\n",
      "Starting Epoch 145\n",
      "0.5072946523626646\n",
      "Starting Epoch 146\n",
      "0.5091124648849169\n",
      "Starting Epoch 147\n",
      "0.5088303349912167\n",
      "Starting Epoch 148\n",
      "0.5082757075627645\n",
      "Starting Epoch 149\n",
      "0.5117166278262933\n",
      "Starting Epoch 150\n",
      "0.5084545128047466\n",
      "Starting Epoch 151\n",
      "0.5088652409613132\n",
      "Starting Epoch 152\n",
      "0.5094513197739919\n",
      "Starting Epoch 153\n",
      "0.5099849551916122\n",
      "New best model found at epoch 153 with validation loss 0.5047984719276428\n",
      "Starting Epoch 154\n",
      "0.5094594359397888\n",
      "Starting Epoch 155\n",
      "0.5084219475587209\n",
      "Starting Epoch 156\n",
      "0.5091669137279192\n",
      "Starting Epoch 157\n",
      "0.5093888727327188\n",
      "Starting Epoch 158\n",
      "0.5088871332506338\n",
      "Starting Epoch 159\n",
      "0.5089966543018818\n",
      "Starting Epoch 160\n",
      "0.5095659357806047\n",
      "Starting Epoch 161\n",
      "0.5102819303671519\n",
      "Starting Epoch 162\n",
      "0.5110033725698789\n",
      "Starting Epoch 163\n",
      "0.5073198117315769\n",
      "Starting Epoch 164\n",
      "0.508275688936313\n",
      "Starting Epoch 165\n",
      "0.507693895449241\n",
      "Starting Epoch 166\n",
      "0.5078804865479469\n",
      "Starting Epoch 167\n",
      "0.5065888079504172\n",
      "Starting Epoch 168\n",
      "0.5069246962666512\n",
      "Starting Epoch 169\n",
      "0.508218931655089\n",
      "Starting Epoch 170\n",
      "0.5104116822282473\n",
      "Starting Epoch 171\n",
      "0.5062597046295801\n",
      "Starting Epoch 172\n",
      "0.5099847589929899\n",
      "New best model found at epoch 172 with validation loss 0.5046943426132202\n",
      "Starting Epoch 173\n",
      "0.5100485819081465\n",
      "Starting Epoch 174\n",
      "0.5091969395677248\n",
      "Starting Epoch 175\n",
      "0.5074761187036833\n",
      "Starting Epoch 176\n",
      "0.5077727697789669\n",
      "Starting Epoch 177\n",
      "0.507780659943819\n",
      "Starting Epoch 178\n",
      "0.5084180335203806\n",
      "Starting Epoch 179\n",
      "0.5070677101612091\n",
      "New best model found at epoch 179 with validation loss 0.50412917137146\n",
      "Starting Epoch 180\n",
      "0.507949431737264\n",
      "Starting Epoch 181\n",
      "0.5070271181563536\n",
      "Starting Epoch 182\n",
      "0.5069067863126596\n",
      "Starting Epoch 183\n",
      "0.506179099281629\n",
      "Starting Epoch 184\n",
      "0.506946824491024\n",
      "Starting Epoch 185\n",
      "0.5077266295750936\n",
      "Starting Epoch 186\n",
      "0.509223914394776\n",
      "Starting Epoch 187\n",
      "0.5064451980094115\n",
      "Starting Epoch 188\n",
      "0.5082278326153755\n",
      "Starting Epoch 189\n",
      "0.5080547084410986\n",
      "Starting Epoch 190\n",
      "0.5080284588038921\n",
      "Starting Epoch 191\n",
      "0.5068082151313623\n",
      "Starting Epoch 192\n",
      "0.5115877216060957\n",
      "Starting Epoch 193\n",
      "0.5073148508866628\n",
      "Starting Epoch 194\n",
      "0.5076650008559227\n",
      "Starting Epoch 195\n",
      "0.5085818022489548\n",
      "Starting Epoch 196\n",
      "0.507944023857514\n",
      "Starting Epoch 197\n",
      "0.5075701326131821\n",
      "Starting Epoch 198\n",
      "0.509504488358895\n",
      "Starting Epoch 199\n",
      "0.511606503278017\n",
      "Starting Epoch 200\n",
      "0.5089791541298231\n",
      "Starting Epoch 201\n",
      "0.5103224851191044\n",
      "Starting Epoch 202\n",
      "0.5053794321914514\n",
      "Starting Epoch 203\n",
      "0.5082004107534885\n",
      "Starting Epoch 204\n",
      "0.5063651738067468\n",
      "Starting Epoch 205\n",
      "0.507343432555596\n",
      "Starting Epoch 206\n",
      "0.5063458047807217\n",
      "Starting Epoch 207\n",
      "0.5068342499434948\n",
      "Starting Epoch 208\n",
      "0.508082278072834\n",
      "Starting Epoch 209\n",
      "0.50718350832661\n",
      "Starting Epoch 210\n",
      "0.5082133325437704\n",
      "Starting Epoch 211\n",
      "0.5065091686944166\n",
      "Starting Epoch 212\n",
      "0.5079774533708891\n",
      "Starting Epoch 213\n",
      "0.5066484063863754\n",
      "Starting Epoch 214\n",
      "0.5070696448286375\n",
      "Starting Epoch 215\n",
      "0.5058930578331152\n",
      "Starting Epoch 216\n",
      "0.5083014269669851\n",
      "Starting Epoch 217\n",
      "0.5090524877111117\n",
      "Starting Epoch 218\n",
      "0.5095676171282927\n",
      "Starting Epoch 219\n",
      "0.5089117847383022\n",
      "Starting Epoch 220\n",
      "0.5066160509983698\n",
      "Starting Epoch 221\n",
      "0.5072745271027088\n",
      "Starting Epoch 222\n",
      "0.505183968693018\n",
      "Starting Epoch 223\n",
      "0.5097086951136589\n",
      "Starting Epoch 224\n",
      "0.5101131635407606\n",
      "Starting Epoch 225\n",
      "0.5066635111967722\n",
      "Starting Epoch 226\n",
      "0.5070278632144133\n",
      "Starting Epoch 227\n",
      "0.5079957793156306\n",
      "Starting Epoch 228\n",
      "0.5082157626748085\n",
      "Starting Epoch 229\n",
      "0.5064228114982446\n",
      "Starting Epoch 230\n",
      "0.5063317144910494\n",
      "Starting Epoch 231\n",
      "0.5078699973722299\n",
      "Starting Epoch 232\n",
      "0.5064180294672648\n",
      "Starting Epoch 233\n",
      "0.5047853775322437\n",
      "Starting Epoch 234\n",
      "0.5107004928092161\n",
      "Starting Epoch 235\n",
      "0.5044345532854398\n",
      "Starting Epoch 236\n",
      "0.5077741531034311\n",
      "Starting Epoch 237\n",
      "0.5052920803427696\n",
      "Starting Epoch 238\n",
      "0.5055775108436743\n",
      "Starting Epoch 239\n",
      "0.5079186943670114\n",
      "Starting Epoch 240\n",
      "0.5081017489234606\n",
      "Starting Epoch 241\n",
      "0.508811013152202\n",
      "Starting Epoch 242\n",
      "0.5075470494727293\n",
      "Starting Epoch 243\n",
      "0.5061445074776808\n",
      "Starting Epoch 244\n",
      "0.5052213097612063\n",
      "Starting Epoch 245\n",
      "0.504947072515885\n",
      "Starting Epoch 246\n",
      "0.5070899811883768\n",
      "Starting Epoch 247\n",
      "0.5084210733572642\n",
      "Starting Epoch 248\n",
      "0.5060577181478342\n",
      "Starting Epoch 249\n",
      "0.5049105746050676\n",
      "Starting Epoch 250\n",
      "0.5036961498359839\n",
      "Starting Epoch 251\n",
      "0.5081051327288151\n",
      "Starting Epoch 252\n",
      "0.5069112181663513\n",
      "Starting Epoch 253\n",
      "0.5055576202770075\n",
      "Starting Epoch 254\n",
      "0.5082713651160399\n",
      "Starting Epoch 255\n",
      "0.5071493834257126\n",
      "New best model found at epoch 255 with validation loss 0.5038536787033081\n",
      "Starting Epoch 256\n",
      "0.5062521832684675\n",
      "Starting Epoch 257\n",
      "0.5047391727566719\n",
      "Starting Epoch 258\n",
      "0.5077601025501887\n",
      "Starting Epoch 259\n",
      "0.5081510096788406\n",
      "Starting Epoch 260\n",
      "0.506016289194425\n",
      "Starting Epoch 261\n",
      "0.5064413597186407\n",
      "Starting Epoch 262\n",
      "0.5063425314923128\n",
      "Starting Epoch 263\n",
      "0.5096144216756026\n",
      "Starting Epoch 264\n",
      "0.506624078998963\n",
      "Starting Epoch 265\n",
      "0.5086688896020254\n",
      "Starting Epoch 266\n",
      "0.5058992120126883\n",
      "Starting Epoch 267\n",
      "0.5042287471393744\n",
      "Starting Epoch 268\n",
      "0.5057444622119268\n",
      "Starting Epoch 269\n",
      "0.504742082208395\n",
      "Starting Epoch 270\n",
      "0.5072498979667822\n",
      "Starting Epoch 271\n",
      "0.5072712004184723\n",
      "Starting Epoch 272\n",
      "0.5032550171017647\n",
      "Starting Epoch 273\n",
      "0.5074024982750416\n",
      "Starting Epoch 274\n",
      "0.5038776422540346\n",
      "Starting Epoch 275\n",
      "0.505566036949555\n",
      "Starting Epoch 276\n",
      "0.5051308212180933\n",
      "Starting Epoch 277\n",
      "0.5058183943231901\n",
      "Starting Epoch 278\n",
      "0.5051629307369391\n",
      "Starting Epoch 279\n",
      "0.502875205129385\n",
      "Starting Epoch 280\n",
      "0.5049094433585802\n",
      "Starting Epoch 281\n",
      "0.5055087680617968\n",
      "Starting Epoch 282\n",
      "0.5054008898635706\n",
      "Starting Epoch 283\n",
      "0.5071301981806755\n",
      "Starting Epoch 284\n",
      "0.5032764387627443\n",
      "Starting Epoch 285\n",
      "0.5036086911956469\n",
      "Starting Epoch 286\n",
      "0.5073028976718584\n",
      "Starting Epoch 287\n",
      "0.5066069501141707\n",
      "Starting Epoch 288\n",
      "0.5073917570213476\n",
      "Starting Epoch 289\n",
      "0.5047351655860742\n",
      "Starting Epoch 290\n",
      "0.5094071626663208\n",
      "Starting Epoch 291\n",
      "0.5070823803544044\n",
      "Starting Epoch 292\n",
      "0.5055951302250227\n",
      "Starting Epoch 293\n",
      "0.5061678762237231\n",
      "Starting Epoch 294\n",
      "0.5049613503118356\n",
      "Starting Epoch 295\n",
      "0.5062189251184464\n",
      "Starting Epoch 296\n",
      "0.5040520988404751\n",
      "Starting Epoch 297\n",
      "0.5050353693465391\n",
      "Starting Epoch 298\n",
      "0.5043223574757576\n",
      "Starting Epoch 299\n",
      "0.5045307725667953\n",
      "Starting Epoch 300\n",
      "0.5093795321881771\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-40-10-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00186d",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 40 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "85d99099-71db-4b80-86df-1d1916222bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "48953fd3-3b82-4cbe-82e8-947531e6169b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.7189568753043811\n",
      "New best model found at epoch 1 with validation loss 0.5931351780891418\n",
      "Starting Epoch 2\n",
      "0.5880860562125841\n",
      "New best model found at epoch 2 with validation loss 0.5914270281791687\n",
      "Starting Epoch 3\n",
      "0.5828460703293482\n",
      "New best model found at epoch 3 with validation loss 0.5865311622619629\n",
      "Starting Epoch 4\n",
      "0.5794476320346197\n",
      "New best model found at epoch 4 with validation loss 0.5726064443588257\n",
      "Starting Epoch 5\n",
      "0.5727733646829923\n",
      "Starting Epoch 6\n",
      "0.5782913143436114\n",
      "New best model found at epoch 6 with validation loss 0.5701979398727417\n",
      "Starting Epoch 7\n",
      "0.5738566244641939\n",
      "New best model found at epoch 7 with validation loss 0.561957061290741\n",
      "Starting Epoch 8\n",
      "0.5721455439925194\n",
      "Starting Epoch 9\n",
      "0.5702908212939898\n",
      "New best model found at epoch 9 with validation loss 0.5614489912986755\n",
      "Starting Epoch 10\n",
      "0.5700380603472391\n",
      "New best model found at epoch 10 with validation loss 0.5613908767700195\n",
      "Starting Epoch 11\n",
      "0.5667164698243141\n",
      "New best model found at epoch 11 with validation loss 0.5599339604377747\n",
      "Starting Epoch 12\n",
      "0.5633014068007469\n",
      "New best model found at epoch 12 with validation loss 0.5575699806213379\n",
      "Starting Epoch 13\n",
      "0.5659636681278547\n",
      "New best model found at epoch 13 with validation loss 0.5562854409217834\n",
      "Starting Epoch 14\n",
      "0.5660341630379359\n",
      "Starting Epoch 15\n",
      "0.5681490389009317\n",
      "New best model found at epoch 15 with validation loss 0.5542688369750977\n",
      "Starting Epoch 16\n",
      "0.5609434172511101\n",
      "New best model found at epoch 16 with validation loss 0.5540893077850342\n",
      "Starting Epoch 17\n",
      "0.5608434478441874\n",
      "New best model found at epoch 17 with validation loss 0.5516250729560852\n",
      "Starting Epoch 18\n",
      "0.5562465488910675\n",
      "New best model found at epoch 18 with validation loss 0.5435447692871094\n",
      "Starting Epoch 19\n",
      "0.5572255551815033\n",
      "Starting Epoch 20\n",
      "0.5566362428168455\n",
      "Starting Epoch 21\n",
      "0.5570896292726198\n",
      "New best model found at epoch 21 with validation loss 0.5378844738006592\n",
      "Starting Epoch 22\n",
      "0.555831133077542\n",
      "Starting Epoch 23\n",
      "0.5515090910096964\n",
      "Starting Epoch 24\n",
      "0.5500170066952705\n",
      "Starting Epoch 25\n",
      "0.5543759874999523\n",
      "Starting Epoch 26\n",
      "0.5538433988889059\n",
      "Starting Epoch 27\n",
      "0.5459209891657034\n",
      "Starting Epoch 28\n",
      "0.5483537676433722\n",
      "Starting Epoch 29\n",
      "0.5478903278708458\n",
      "Starting Epoch 30\n",
      "0.5474463912347952\n",
      "New best model found at epoch 30 with validation loss 0.5317709445953369\n",
      "Starting Epoch 31\n",
      "0.5480260203282038\n",
      "Starting Epoch 32\n",
      "0.5460823513567448\n",
      "Starting Epoch 33\n",
      "0.5449717218677202\n",
      "Starting Epoch 34\n",
      "0.543419849127531\n",
      "New best model found at epoch 34 with validation loss 0.5200746059417725\n",
      "Starting Epoch 35\n",
      "0.537326148400704\n",
      "Starting Epoch 36\n",
      "0.5384203779200712\n",
      "New best model found at epoch 36 with validation loss 0.5159691572189331\n",
      "Starting Epoch 37\n",
      "0.5383839892844359\n",
      "Starting Epoch 38\n",
      "0.538885124027729\n",
      "Starting Epoch 39\n",
      "0.5365271158516407\n",
      "Starting Epoch 40\n",
      "0.5343042202293873\n",
      "New best model found at epoch 40 with validation loss 0.5157551169395447\n",
      "Starting Epoch 41\n",
      "0.537755104402701\n",
      "Starting Epoch 42\n",
      "0.535786305864652\n",
      "New best model found at epoch 42 with validation loss 0.5142088532447815\n",
      "Starting Epoch 43\n",
      "0.5393857421974341\n",
      "Starting Epoch 44\n",
      "0.5330941677093506\n",
      "Starting Epoch 45\n",
      "0.532460859666268\n",
      "Starting Epoch 46\n",
      "0.5314524173736572\n",
      "Starting Epoch 47\n",
      "0.5284537076950073\n",
      "Starting Epoch 48\n",
      "0.5295088129738966\n",
      "Starting Epoch 49\n",
      "0.5294198778768381\n",
      "New best model found at epoch 49 with validation loss 0.5110644698143005\n",
      "Starting Epoch 50\n",
      "0.5262010718385378\n",
      "New best model found at epoch 50 with validation loss 0.5081017017364502\n",
      "Starting Epoch 51\n",
      "0.5248945641020933\n",
      "Starting Epoch 52\n",
      "0.5251998466749986\n",
      "Starting Epoch 53\n",
      "0.5240301887194315\n",
      "New best model found at epoch 53 with validation loss 0.5076733231544495\n",
      "Starting Epoch 54\n",
      "0.528926589836677\n",
      "Starting Epoch 55\n",
      "0.5222870322565237\n",
      "Starting Epoch 56\n",
      "0.52555301040411\n",
      "Starting Epoch 57\n",
      "0.5224934617678324\n",
      "Starting Epoch 58\n",
      "0.5238442023595175\n",
      "New best model found at epoch 58 with validation loss 0.5061492323875427\n",
      "Starting Epoch 59\n",
      "0.5197521224617958\n",
      "New best model found at epoch 59 with validation loss 0.5053629279136658\n",
      "Starting Epoch 60\n",
      "0.5194096354146799\n",
      "Starting Epoch 61\n",
      "0.5213275241355101\n",
      "Starting Epoch 62\n",
      "0.520434899876515\n",
      "Starting Epoch 63\n",
      "0.5190266917149226\n",
      "New best model found at epoch 63 with validation loss 0.5042338371276855\n",
      "Starting Epoch 64\n",
      "0.5187520955999693\n",
      "Starting Epoch 65\n",
      "0.518022091438373\n",
      "Starting Epoch 66\n",
      "0.5152889390786489\n",
      "Starting Epoch 67\n",
      "0.515232847382625\n",
      "Starting Epoch 68\n",
      "0.5171293628712496\n",
      "Starting Epoch 69\n",
      "0.5195781290531158\n",
      "Starting Epoch 70\n",
      "0.5145860587557157\n",
      "Starting Epoch 71\n",
      "0.5149935719867548\n",
      "Starting Epoch 72\n",
      "0.5193648537000021\n",
      "Starting Epoch 73\n",
      "0.5132290696104368\n",
      "New best model found at epoch 73 with validation loss 0.5014103055000305\n",
      "Starting Epoch 74\n",
      "0.5101651971538862\n",
      "New best model found at epoch 74 with validation loss 0.49416667222976685\n",
      "Starting Epoch 75\n",
      "0.5139871860543886\n",
      "Starting Epoch 76\n",
      "0.5092746056616306\n",
      "Starting Epoch 77\n",
      "0.5116672106087208\n",
      "Starting Epoch 78\n",
      "0.5111422389745712\n",
      "Starting Epoch 79\n",
      "0.5100561728080114\n",
      "Starting Epoch 80\n",
      "0.5111380169788996\n",
      "Starting Epoch 81\n",
      "0.5064625429610411\n",
      "Starting Epoch 82\n",
      "0.5098939115802447\n",
      "Starting Epoch 83\n",
      "0.5079930660625299\n",
      "Starting Epoch 84\n",
      "0.5093697644770145\n",
      "Starting Epoch 85\n",
      "0.5094449979563554\n",
      "Starting Epoch 86\n",
      "0.5069299153983593\n",
      "Starting Epoch 87\n",
      "0.5057239818076292\n",
      "Starting Epoch 88\n",
      "0.5081343203783035\n",
      "Starting Epoch 89\n",
      "0.5080293404559294\n",
      "Starting Epoch 90\n",
      "0.5090214436252912\n",
      "Starting Epoch 91\n",
      "0.5055368145306905\n",
      "New best model found at epoch 91 with validation loss 0.4857974052429199\n",
      "Starting Epoch 92\n",
      "0.5064744340876738\n",
      "Starting Epoch 93\n",
      "0.5100681309898695\n",
      "Starting Epoch 94\n",
      "0.5090869106352329\n",
      "Starting Epoch 95\n",
      "0.5042729700605074\n",
      "Starting Epoch 96\n",
      "0.5040975896020731\n",
      "Starting Epoch 97\n",
      "0.5028457169731458\n",
      "Starting Epoch 98\n",
      "0.4988706596195698\n",
      "Starting Epoch 99\n",
      "0.5029566946129004\n",
      "Starting Epoch 100\n",
      "0.4998881096641223\n",
      "New best model found at epoch 100 with validation loss 0.4844835698604584\n",
      "Starting Epoch 101\n",
      "0.5012132277091345\n",
      "Starting Epoch 102\n",
      "0.5017632183929285\n",
      "Starting Epoch 103\n",
      "0.4997533994416396\n",
      "Starting Epoch 104\n",
      "0.49840423464775085\n",
      "New best model found at epoch 104 with validation loss 0.48089829087257385\n",
      "Starting Epoch 105\n",
      "0.4983115295569102\n",
      "Starting Epoch 106\n",
      "0.4992873954276244\n",
      "Starting Epoch 107\n",
      "0.5039963076512018\n",
      "Starting Epoch 108\n",
      "0.500208372871081\n",
      "Starting Epoch 109\n",
      "0.5006906911730766\n",
      "Starting Epoch 110\n",
      "0.4965297430753708\n",
      "New best model found at epoch 110 with validation loss 0.47951969504356384\n",
      "Starting Epoch 111\n",
      "0.49707891295353573\n",
      "Starting Epoch 112\n",
      "0.49899304161469143\n",
      "Starting Epoch 113\n",
      "0.495885477711757\n",
      "Starting Epoch 114\n",
      "0.5008069463074207\n",
      "Starting Epoch 115\n",
      "0.4993944503366947\n",
      "Starting Epoch 116\n",
      "0.4934447333216667\n",
      "Starting Epoch 117\n",
      "0.5006739658614\n",
      "Starting Epoch 118\n",
      "0.497449804097414\n",
      "Starting Epoch 119\n",
      "0.4964968338608742\n",
      "Starting Epoch 120\n",
      "0.49987561379869777\n",
      "Starting Epoch 121\n",
      "0.49644365534186363\n",
      "Starting Epoch 122\n",
      "0.49238936354716617\n",
      "Starting Epoch 123\n",
      "0.4988459100325902\n",
      "Starting Epoch 124\n",
      "0.4931732925275962\n",
      "Starting Epoch 125\n",
      "0.49130384003122646\n",
      "Starting Epoch 126\n",
      "0.4930450643102328\n",
      "Starting Epoch 127\n",
      "0.49267974371711415\n",
      "Starting Epoch 128\n",
      "0.4909835755825043\n",
      "Starting Epoch 129\n",
      "0.4902540594339371\n",
      "Starting Epoch 130\n",
      "0.4908221724132697\n",
      "Starting Epoch 131\n",
      "0.48763130977749825\n",
      "New best model found at epoch 131 with validation loss 0.47674378752708435\n",
      "Starting Epoch 132\n",
      "0.49152835458517075\n",
      "Starting Epoch 133\n",
      "0.488465528935194\n",
      "Starting Epoch 134\n",
      "0.49810172865788144\n",
      "Starting Epoch 135\n",
      "0.4925132840871811\n",
      "New best model found at epoch 135 with validation loss 0.47194933891296387\n",
      "Starting Epoch 136\n",
      "0.4916505056122939\n",
      "Starting Epoch 137\n",
      "0.4922715450326602\n",
      "Starting Epoch 138\n",
      "0.4908372722566128\n",
      "Starting Epoch 139\n",
      "0.48932555814584094\n",
      "Starting Epoch 140\n",
      "0.49065182233850163\n",
      "Starting Epoch 141\n",
      "0.4904673894246419\n",
      "Starting Epoch 142\n",
      "0.48804603268702823\n",
      "Starting Epoch 143\n",
      "0.48992595200737316\n",
      "Starting Epoch 144\n",
      "0.4891894335548083\n",
      "Starting Epoch 145\n",
      "0.49425867075721425\n",
      "Starting Epoch 146\n",
      "0.4886525285740693\n",
      "Starting Epoch 147\n",
      "0.48681433995564777\n",
      "Starting Epoch 148\n",
      "0.4927693245311578\n",
      "Starting Epoch 149\n",
      "0.49105294172962505\n",
      "Starting Epoch 150\n",
      "0.4904093034565449\n",
      "Starting Epoch 151\n",
      "0.4878721088171005\n",
      "Starting Epoch 152\n",
      "0.4870935802658399\n",
      "Starting Epoch 153\n",
      "0.4897259386877219\n",
      "Starting Epoch 154\n",
      "0.48358213528990746\n",
      "Starting Epoch 155\n",
      "0.48706355566779774\n",
      "Starting Epoch 156\n",
      "0.4875021216770013\n",
      "Starting Epoch 157\n",
      "0.4876779541373253\n",
      "Starting Epoch 158\n",
      "0.4857560371359189\n",
      "Starting Epoch 159\n",
      "0.4910249424477418\n",
      "Starting Epoch 160\n",
      "0.488161767522494\n",
      "Starting Epoch 161\n",
      "0.4864264403780301\n",
      "New best model found at epoch 161 with validation loss 0.4700252413749695\n",
      "Starting Epoch 162\n",
      "0.48488470166921616\n",
      "Starting Epoch 163\n",
      "0.4895431014398734\n",
      "Starting Epoch 164\n",
      "0.4847422043482463\n",
      "Starting Epoch 165\n",
      "0.4836343514422576\n",
      "Starting Epoch 166\n",
      "0.486533264319102\n",
      "Starting Epoch 167\n",
      "0.4829203076660633\n",
      "Starting Epoch 168\n",
      "0.4873063998917739\n",
      "Starting Epoch 169\n",
      "0.4920493873457114\n",
      "New best model found at epoch 169 with validation loss 0.467099666595459\n",
      "Starting Epoch 170\n",
      "0.4837853287657102\n",
      "Starting Epoch 171\n",
      "0.48132679238915443\n",
      "Starting Epoch 172\n",
      "0.4857679357131322\n",
      "Starting Epoch 173\n",
      "0.48485049481193226\n",
      "Starting Epoch 174\n",
      "0.4853166999916236\n",
      "Starting Epoch 175\n",
      "0.48857318237423897\n",
      "Starting Epoch 176\n",
      "0.48973072941104573\n",
      "Starting Epoch 177\n",
      "0.4841948139170806\n",
      "Starting Epoch 178\n",
      "0.48860128099719685\n",
      "Starting Epoch 179\n",
      "0.4842085838317871\n",
      "Starting Epoch 180\n",
      "0.4824752000470956\n",
      "Starting Epoch 181\n",
      "0.4827241698900859\n",
      "Starting Epoch 182\n",
      "0.4823191973070304\n",
      "Starting Epoch 183\n",
      "0.4835199899971485\n",
      "Starting Epoch 184\n",
      "0.4840306304395199\n",
      "Starting Epoch 185\n",
      "0.4861932309965293\n",
      "Starting Epoch 186\n",
      "0.4813579134643078\n",
      "Starting Epoch 187\n",
      "0.48196782916784286\n",
      "Starting Epoch 188\n",
      "0.47972633068760234\n",
      "Starting Epoch 189\n",
      "0.4867449440062046\n",
      "Starting Epoch 190\n",
      "0.4835035167634487\n",
      "Starting Epoch 191\n",
      "0.4824841544032097\n",
      "Starting Epoch 192\n",
      "0.4830433763563633\n",
      "Starting Epoch 193\n",
      "0.48142943034569424\n",
      "Starting Epoch 194\n",
      "0.48442213361461955\n",
      "Starting Epoch 195\n",
      "0.48265230158964795\n",
      "Starting Epoch 196\n",
      "0.4783680662512779\n",
      "Starting Epoch 197\n",
      "0.482554167509079\n",
      "Starting Epoch 198\n",
      "0.4812183404962222\n",
      "New best model found at epoch 198 with validation loss 0.4636378288269043\n",
      "Starting Epoch 199\n",
      "0.48504750803112984\n",
      "Starting Epoch 200\n",
      "0.4866395443677902\n",
      "Starting Epoch 201\n",
      "0.4799003290633361\n",
      "Starting Epoch 202\n",
      "0.4817967178920905\n",
      "Starting Epoch 203\n",
      "0.487242146084706\n",
      "Starting Epoch 204\n",
      "0.4813481755554676\n",
      "Starting Epoch 205\n",
      "0.48521799221634865\n",
      "Starting Epoch 206\n",
      "0.4808882810175419\n",
      "Starting Epoch 207\n",
      "0.4810783887902896\n",
      "Starting Epoch 208\n",
      "0.47983749707539874\n",
      "Starting Epoch 209\n",
      "0.4779219242433707\n",
      "Starting Epoch 210\n",
      "0.48104596758882207\n",
      "Starting Epoch 211\n",
      "0.4810009462138017\n",
      "Starting Epoch 212\n",
      "0.47980573649207753\n",
      "Starting Epoch 213\n",
      "0.47794104740023613\n",
      "Starting Epoch 214\n",
      "0.4794679619371891\n",
      "Starting Epoch 215\n",
      "0.4771295016010602\n",
      "Starting Epoch 216\n",
      "0.480131596326828\n",
      "Starting Epoch 217\n",
      "0.48230788856744766\n",
      "Starting Epoch 218\n",
      "0.4790551885962486\n",
      "Starting Epoch 219\n",
      "0.4769020229578018\n",
      "Starting Epoch 220\n",
      "0.4814801725248496\n",
      "Starting Epoch 221\n",
      "0.47537773847579956\n",
      "Starting Epoch 222\n",
      "0.47759102657437325\n",
      "Starting Epoch 223\n",
      "0.47981835901737213\n",
      "Starting Epoch 224\n",
      "0.4798163212835789\n",
      "Starting Epoch 225\n",
      "0.47772254919012386\n",
      "New best model found at epoch 225 with validation loss 0.46321266889572144\n",
      "Starting Epoch 226\n",
      "0.48046691715717316\n",
      "Starting Epoch 227\n",
      "0.48068036263187724\n",
      "Starting Epoch 228\n",
      "0.47874343519409496\n",
      "Starting Epoch 229\n",
      "0.4768194357554118\n",
      "Starting Epoch 230\n",
      "0.4795994957288106\n",
      "Starting Epoch 231\n",
      "0.48024579882621765\n",
      "Starting Epoch 232\n",
      "0.4743268738190333\n",
      "Starting Epoch 233\n",
      "0.48089975242813426\n",
      "Starting Epoch 234\n",
      "0.4790723646680514\n",
      "Starting Epoch 235\n",
      "0.4804341420531273\n",
      "Starting Epoch 236\n",
      "0.47747930760184926\n",
      "Starting Epoch 237\n",
      "0.4766293875873089\n",
      "Starting Epoch 238\n",
      "0.47928602372606594\n",
      "Starting Epoch 239\n",
      "0.48257018129030865\n",
      "Starting Epoch 240\n",
      "0.47972638408343\n",
      "Starting Epoch 241\n",
      "0.47487203901012737\n",
      "Starting Epoch 242\n",
      "0.476089458912611\n",
      "Starting Epoch 243\n",
      "0.4799931061764558\n",
      "Starting Epoch 244\n",
      "0.47500619540611905\n",
      "Starting Epoch 245\n",
      "0.4803098564346631\n",
      "Starting Epoch 246\n",
      "0.47861940910418826\n",
      "Starting Epoch 247\n",
      "0.47435690090060234\n",
      "Starting Epoch 248\n",
      "0.4761044656236966\n",
      "Starting Epoch 249\n",
      "0.4784583163758119\n",
      "Starting Epoch 250\n",
      "0.4783203800519307\n",
      "Starting Epoch 251\n",
      "0.4795150210460027\n",
      "Starting Epoch 252\n",
      "0.4735600066681703\n",
      "Starting Epoch 253\n",
      "0.4744109660387039\n",
      "Starting Epoch 254\n",
      "0.47547940785686177\n",
      "Starting Epoch 255\n",
      "0.474902231246233\n",
      "Starting Epoch 256\n",
      "0.4765631705522537\n",
      "Starting Epoch 257\n",
      "0.47491060197353363\n",
      "Starting Epoch 258\n",
      "0.476702943444252\n",
      "Starting Epoch 259\n",
      "0.47845083350936574\n",
      "Starting Epoch 260\n",
      "0.4766155146062374\n",
      "Starting Epoch 261\n",
      "0.47347433120012283\n",
      "Starting Epoch 262\n",
      "0.4741175298889478\n",
      "Starting Epoch 263\n",
      "0.47526712715625763\n",
      "Starting Epoch 264\n",
      "0.479557095716397\n",
      "Starting Epoch 265\n",
      "0.47441036502520245\n",
      "Starting Epoch 266\n",
      "0.476360817750295\n",
      "Starting Epoch 267\n",
      "0.47584328800439835\n",
      "New best model found at epoch 267 with validation loss 0.4616685211658478\n",
      "Starting Epoch 268\n",
      "0.47414516905943555\n",
      "Starting Epoch 269\n",
      "0.4765319811801116\n",
      "Starting Epoch 270\n",
      "0.4776206625004609\n",
      "Starting Epoch 271\n",
      "0.47514117881655693\n",
      "Starting Epoch 272\n",
      "0.47627659142017365\n",
      "Starting Epoch 273\n",
      "0.4759240075945854\n",
      "Starting Epoch 274\n",
      "0.4747427627444267\n",
      "Starting Epoch 275\n",
      "0.477559154232343\n",
      "Starting Epoch 276\n",
      "0.47487859427928925\n",
      "Starting Epoch 277\n",
      "0.4744735360145569\n",
      "Starting Epoch 278\n",
      "0.4773267135024071\n",
      "Starting Epoch 279\n",
      "0.47796746840079624\n",
      "Starting Epoch 280\n",
      "0.4754750343660514\n",
      "Starting Epoch 281\n",
      "0.4787899541358153\n",
      "Starting Epoch 282\n",
      "0.47529590378204983\n",
      "Starting Epoch 283\n",
      "0.47749895850817364\n",
      "Starting Epoch 284\n",
      "0.47571729744474095\n",
      "Starting Epoch 285\n",
      "0.47696395218372345\n",
      "Starting Epoch 286\n",
      "0.47760764012734097\n",
      "Starting Epoch 287\n",
      "0.47612513105074566\n",
      "Starting Epoch 288\n",
      "0.47445907443761826\n",
      "Starting Epoch 289\n",
      "0.47307778894901276\n",
      "Starting Epoch 290\n",
      "0.4744819849729538\n",
      "Starting Epoch 291\n",
      "0.4756804679830869\n",
      "Starting Epoch 292\n",
      "0.4744035278757413\n",
      "New best model found at epoch 292 with validation loss 0.46142348647117615\n",
      "Starting Epoch 293\n",
      "0.4756308210392793\n",
      "Starting Epoch 294\n",
      "0.4723040560881297\n",
      "Starting Epoch 295\n",
      "0.47115034610033035\n",
      "Starting Epoch 296\n",
      "0.47739090646306676\n",
      "Starting Epoch 297\n",
      "0.4716144526998202\n",
      "Starting Epoch 298\n",
      "0.47258418425917625\n",
      "New best model found at epoch 298 with validation loss 0.45970794558525085\n",
      "Starting Epoch 299\n",
      "0.4694129501779874\n",
      "Starting Epoch 300\n",
      "0.47265170762936276\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-60-40-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c295c-aee2-4f37-a652-ab6ced0226f2",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 6\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 20 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f14f8113-cc0d-40cc-9144-a64e9f6fd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "3f12125a-f89a-49fa-b71e-7170a7704732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.6168403327465057\n",
      "New best model found at epoch 1 with validation loss 0.602421224117279\n",
      "Starting Epoch 2\n",
      "0.5966758156816164\n",
      "New best model found at epoch 2 with validation loss 0.5816561579704285\n",
      "Starting Epoch 3\n",
      "0.590178906917572\n",
      "New best model found at epoch 3 with validation loss 0.5759998559951782\n",
      "Starting Epoch 4\n",
      "0.5792585909366608\n",
      "New best model found at epoch 4 with validation loss 0.5654559135437012\n",
      "Starting Epoch 5\n",
      "0.5772221485773722\n",
      "Starting Epoch 6\n",
      "0.5727853452165922\n",
      "Starting Epoch 7\n",
      "0.566016019632419\n",
      "Starting Epoch 8\n",
      "0.5633578312893709\n",
      "New best model found at epoch 8 with validation loss 0.5607754588127136\n",
      "Starting Epoch 9\n",
      "0.5621617212891579\n",
      "New best model found at epoch 9 with validation loss 0.5513172745704651\n",
      "Starting Epoch 10\n",
      "0.5581044455369314\n",
      "Starting Epoch 11\n",
      "0.5596617485086123\n",
      "Starting Epoch 12\n",
      "0.5554575410981973\n",
      "New best model found at epoch 12 with validation loss 0.5442996025085449\n",
      "Starting Epoch 13\n",
      "0.5531165835758051\n",
      "Starting Epoch 14\n",
      "0.54637860506773\n",
      "Starting Epoch 15\n",
      "0.5575302143891653\n",
      "Starting Epoch 16\n",
      "0.5533872880041599\n",
      "Starting Epoch 17\n",
      "0.5538137132922808\n",
      "Starting Epoch 18\n",
      "0.544831857085228\n",
      "Starting Epoch 19\n",
      "0.545589325328668\n",
      "New best model found at epoch 19 with validation loss 0.5426962971687317\n",
      "Starting Epoch 20\n",
      "0.5392348368962606\n",
      "New best model found at epoch 20 with validation loss 0.5393802523612976\n",
      "Starting Epoch 21\n",
      "0.5395126702884833\n",
      "New best model found at epoch 21 with validation loss 0.5315788984298706\n",
      "Starting Epoch 22\n",
      "0.5372278851767381\n",
      "Starting Epoch 23\n",
      "0.5415165511270364\n",
      "Starting Epoch 24\n",
      "0.5441933125257492\n",
      "New best model found at epoch 24 with validation loss 0.5280901789665222\n",
      "Starting Epoch 25\n",
      "0.5485593266785145\n",
      "New best model found at epoch 25 with validation loss 0.526207447052002\n",
      "Starting Epoch 26\n",
      "0.5332009606063366\n",
      "Starting Epoch 27\n",
      "0.5369771880408128\n",
      "Starting Epoch 28\n",
      "0.5321568362414837\n",
      "Starting Epoch 29\n",
      "0.5289889238774776\n",
      "Starting Epoch 30\n",
      "0.5334012148280939\n",
      "New best model found at epoch 30 with validation loss 0.5207558870315552\n",
      "Starting Epoch 31\n",
      "0.5287911432484785\n",
      "Starting Epoch 32\n",
      "0.5243886100749174\n",
      "Starting Epoch 33\n",
      "0.5264596218864123\n",
      "Starting Epoch 34\n",
      "0.5260543189942837\n",
      "Starting Epoch 35\n",
      "0.5283330132563909\n",
      "Starting Epoch 36\n",
      "0.5260436572134495\n",
      "Starting Epoch 37\n",
      "0.525142797579368\n",
      "Starting Epoch 38\n",
      "0.5204050180812677\n",
      "Starting Epoch 39\n",
      "0.5211836782594522\n",
      "Starting Epoch 40\n",
      "0.5296170661846796\n",
      "Starting Epoch 41\n",
      "0.5244986489415169\n",
      "New best model found at epoch 41 with validation loss 0.5153278112411499\n",
      "Starting Epoch 42\n",
      "0.5209240317344666\n",
      "Starting Epoch 43\n",
      "0.5244452978173891\n",
      "Starting Epoch 44\n",
      "0.5233927418788274\n",
      "Starting Epoch 45\n",
      "0.5211988277733326\n",
      "New best model found at epoch 45 with validation loss 0.5134837031364441\n",
      "Starting Epoch 46\n",
      "0.5212902302543322\n",
      "Starting Epoch 47\n",
      "0.519945407907168\n",
      "Starting Epoch 48\n",
      "0.5218785392741362\n",
      "Starting Epoch 49\n",
      "0.5185577434798082\n",
      "Starting Epoch 50\n",
      "0.5173085816204548\n",
      "New best model found at epoch 50 with validation loss 0.5107482671737671\n",
      "Starting Epoch 51\n",
      "0.5165627673268318\n",
      "Starting Epoch 52\n",
      "0.5125380679965019\n",
      "Starting Epoch 53\n",
      "0.5245031466086706\n",
      "Starting Epoch 54\n",
      "0.516200220833222\n",
      "Starting Epoch 55\n",
      "0.5126652009785175\n",
      "Starting Epoch 56\n",
      "0.5169453471899033\n",
      "Starting Epoch 57\n",
      "0.5159286831816038\n",
      "Starting Epoch 58\n",
      "0.51421969383955\n",
      "Starting Epoch 59\n",
      "0.5097121248642603\n",
      "Starting Epoch 60\n",
      "0.5163275947173437\n",
      "Starting Epoch 61\n",
      "0.5130799822509289\n",
      "Starting Epoch 62\n",
      "0.5130261294543743\n",
      "Starting Epoch 63\n",
      "0.5082387539247671\n",
      "Starting Epoch 64\n",
      "0.5107421427965164\n",
      "New best model found at epoch 64 with validation loss 0.5051229596138\n",
      "Starting Epoch 65\n",
      "0.5128132651249567\n",
      "Starting Epoch 66\n",
      "0.5089679720501105\n",
      "Starting Epoch 67\n",
      "0.5080660382906595\n",
      "Starting Epoch 68\n",
      "0.5127783082425594\n",
      "Starting Epoch 69\n",
      "0.5094085906942686\n",
      "New best model found at epoch 69 with validation loss 0.5034306645393372\n",
      "Starting Epoch 70\n",
      "0.5129150139788786\n",
      "Starting Epoch 71\n",
      "0.5094022341072559\n",
      "Starting Epoch 72\n",
      "0.5103192081054052\n",
      "Starting Epoch 73\n",
      "0.5107278426488241\n",
      "Starting Epoch 74\n",
      "0.5034167083601157\n",
      "Starting Epoch 75\n",
      "0.5071119368076324\n",
      "Starting Epoch 76\n",
      "0.5050454673667749\n",
      "Starting Epoch 77\n",
      "0.504582600047191\n",
      "Starting Epoch 78\n",
      "0.513379684338967\n",
      "Starting Epoch 79\n",
      "0.507903479039669\n",
      "Starting Epoch 80\n",
      "0.5072204880416393\n",
      "Starting Epoch 81\n",
      "0.5089841286341349\n",
      "Starting Epoch 82\n",
      "0.5048931688070297\n",
      "Starting Epoch 83\n",
      "0.5073090928296248\n",
      "Starting Epoch 84\n",
      "0.5082333236932755\n",
      "Starting Epoch 85\n",
      "0.5056893328825632\n",
      "Starting Epoch 86\n",
      "0.5086355259021124\n",
      "New best model found at epoch 86 with validation loss 0.5029956698417664\n",
      "Starting Epoch 87\n",
      "0.5088388745983442\n",
      "Starting Epoch 88\n",
      "0.5027132133642832\n",
      "Starting Epoch 89\n",
      "0.5040024059514204\n",
      "Starting Epoch 90\n",
      "0.5084169507026672\n",
      "New best model found at epoch 90 with validation loss 0.5021169185638428\n",
      "Starting Epoch 91\n",
      "0.5031635574996471\n",
      "Starting Epoch 92\n",
      "0.5036984905600548\n",
      "Starting Epoch 93\n",
      "0.5031835623085499\n",
      "Starting Epoch 94\n",
      "0.503761055568854\n",
      "Starting Epoch 95\n",
      "0.4995565203328927\n",
      "Starting Epoch 96\n",
      "0.503102192034324\n",
      "Starting Epoch 97\n",
      "0.5003340728580952\n",
      "Starting Epoch 98\n",
      "0.5007531394561132\n",
      "Starting Epoch 99\n",
      "0.5020687443514665\n",
      "Starting Epoch 100\n",
      "0.5009382218122482\n",
      "Starting Epoch 101\n",
      "0.5009825850526491\n",
      "Starting Epoch 102\n",
      "0.4999588243663311\n",
      "New best model found at epoch 102 with validation loss 0.5006547570228577\n",
      "Starting Epoch 103\n",
      "0.499374574671189\n",
      "Starting Epoch 104\n",
      "0.49956168979406357\n",
      "New best model found at epoch 104 with validation loss 0.49688756465911865\n",
      "Starting Epoch 105\n",
      "0.5008025666077932\n",
      "Starting Epoch 106\n",
      "0.5043348173300425\n",
      "Starting Epoch 107\n",
      "0.5059436969459057\n",
      "Starting Epoch 108\n",
      "0.5000704141954581\n",
      "Starting Epoch 109\n",
      "0.5007966806491216\n",
      "Starting Epoch 110\n",
      "0.4998192824423313\n",
      "Starting Epoch 111\n",
      "0.5002138689160347\n",
      "Starting Epoch 112\n",
      "0.4991842495898406\n",
      "Starting Epoch 113\n",
      "0.49910865475734073\n",
      "Starting Epoch 114\n",
      "0.49726638446251553\n",
      "Starting Epoch 115\n",
      "0.5017754932244619\n",
      "Starting Epoch 116\n",
      "0.4997377060353756\n",
      "New best model found at epoch 116 with validation loss 0.4948958456516266\n",
      "Starting Epoch 117\n",
      "0.498352337628603\n",
      "New best model found at epoch 117 with validation loss 0.4948046803474426\n",
      "Starting Epoch 118\n",
      "0.4996750441690286\n",
      "Starting Epoch 119\n",
      "0.5008304292956988\n",
      "Starting Epoch 120\n",
      "0.49680063376824063\n",
      "Starting Epoch 121\n",
      "0.49667344614863396\n",
      "Starting Epoch 122\n",
      "0.49809566140174866\n",
      "Starting Epoch 123\n",
      "0.49920803556839627\n",
      "Starting Epoch 124\n",
      "0.4977804111937682\n",
      "Starting Epoch 125\n",
      "0.501350712031126\n",
      "Starting Epoch 126\n",
      "0.49730313072601956\n",
      "New best model found at epoch 126 with validation loss 0.4940193295478821\n",
      "Starting Epoch 127\n",
      "0.4955517103274663\n",
      "Starting Epoch 128\n",
      "0.496304960300525\n",
      "Starting Epoch 129\n",
      "0.4930541440844536\n",
      "Starting Epoch 130\n",
      "0.5001310507456461\n",
      "Starting Epoch 131\n",
      "0.4946040002008279\n",
      "Starting Epoch 132\n",
      "0.4981503163774808\n",
      "Starting Epoch 133\n",
      "0.49515926589568454\n",
      "Starting Epoch 134\n",
      "0.4984542007247607\n",
      "Starting Epoch 135\n",
      "0.49829407533009845\n",
      "Starting Epoch 136\n",
      "0.4952460564672947\n",
      "Starting Epoch 137\n",
      "0.49464353049794835\n",
      "Starting Epoch 138\n",
      "0.49822092801332474\n",
      "Starting Epoch 139\n",
      "0.49225858350594837\n",
      "Starting Epoch 140\n",
      "0.5027548472086588\n",
      "Starting Epoch 141\n",
      "0.49859585985541344\n",
      "Starting Epoch 142\n",
      "0.49524714301029843\n",
      "Starting Epoch 143\n",
      "0.4961424556871255\n",
      "Starting Epoch 144\n",
      "0.4946244719127814\n",
      "Starting Epoch 145\n",
      "0.49557356784741086\n",
      "Starting Epoch 146\n",
      "0.49765390281875926\n",
      "Starting Epoch 147\n",
      "0.4975436006983121\n",
      "Starting Epoch 148\n",
      "0.49722664554913837\n",
      "Starting Epoch 149\n",
      "0.4938663716117541\n",
      "Starting Epoch 150\n",
      "0.4937831722199917\n",
      "Starting Epoch 151\n",
      "0.49287350103259087\n",
      "Starting Epoch 152\n",
      "0.4941704161465168\n",
      "New best model found at epoch 152 with validation loss 0.49399131536483765\n",
      "Starting Epoch 153\n",
      "0.4956926330924034\n",
      "Starting Epoch 154\n",
      "0.49387940640250844\n",
      "Starting Epoch 155\n",
      "0.49918095643321675\n",
      "Starting Epoch 156\n",
      "0.4934038904805978\n",
      "Starting Epoch 157\n",
      "0.4927993329862754\n",
      "Starting Epoch 158\n",
      "0.4970576576888561\n",
      "Starting Epoch 159\n",
      "0.49417897313833237\n",
      "Starting Epoch 160\n",
      "0.4925067226092021\n",
      "Starting Epoch 161\n",
      "0.4917710746328036\n",
      "Starting Epoch 162\n",
      "0.4951812004049619\n",
      "New best model found at epoch 162 with validation loss 0.49234363436698914\n",
      "Starting Epoch 163\n",
      "0.49398859466115635\n",
      "Starting Epoch 164\n",
      "0.49103107551733655\n",
      "Starting Epoch 165\n",
      "0.49013325820366543\n",
      "Starting Epoch 166\n",
      "0.4931689302126567\n",
      "New best model found at epoch 166 with validation loss 0.4907379150390625\n",
      "Starting Epoch 167\n",
      "0.4942537272969882\n",
      "Starting Epoch 168\n",
      "0.4909107970694701\n",
      "New best model found at epoch 168 with validation loss 0.4877052307128906\n",
      "Starting Epoch 169\n",
      "0.4919198031226794\n",
      "Starting Epoch 170\n",
      "0.4909060286978881\n",
      "Starting Epoch 171\n",
      "0.4895675517618656\n",
      "Starting Epoch 172\n",
      "0.4893539808690548\n",
      "Starting Epoch 173\n",
      "0.4898070606092612\n",
      "Starting Epoch 174\n",
      "0.49526266132791835\n",
      "Starting Epoch 175\n",
      "0.49214132005969685\n",
      "Starting Epoch 176\n",
      "0.49335602546731633\n",
      "Starting Epoch 177\n",
      "0.4934223083158334\n",
      "Starting Epoch 178\n",
      "0.4910806107024352\n",
      "Starting Epoch 179\n",
      "0.48985808218518895\n",
      "Starting Epoch 180\n",
      "0.4901633933186531\n",
      "Starting Epoch 181\n",
      "0.4901089717944463\n",
      "Starting Epoch 182\n",
      "0.4867112512389819\n",
      "Starting Epoch 183\n",
      "0.49244413897395134\n",
      "Starting Epoch 184\n",
      "0.492462186763684\n",
      "Starting Epoch 185\n",
      "0.49007802829146385\n",
      "Starting Epoch 186\n",
      "0.49190619339545566\n",
      "Starting Epoch 187\n",
      "0.49093638484676677\n",
      "Starting Epoch 188\n",
      "0.4898435299595197\n",
      "Starting Epoch 189\n",
      "0.4911377616226673\n",
      "Starting Epoch 190\n",
      "0.491800003995498\n",
      "Starting Epoch 191\n",
      "0.4907655231654644\n",
      "Starting Epoch 192\n",
      "0.48923497274518013\n",
      "Starting Epoch 193\n",
      "0.48686495671669644\n",
      "Starting Epoch 194\n",
      "0.49205080419778824\n",
      "Starting Epoch 195\n",
      "0.4843697187801202\n",
      "Starting Epoch 196\n",
      "0.48552291716138524\n",
      "Starting Epoch 197\n",
      "0.49320852259794873\n",
      "Starting Epoch 198\n",
      "0.48672346770763397\n",
      "Starting Epoch 199\n",
      "0.48687776923179626\n",
      "Starting Epoch 200\n",
      "0.5070444593826929\n",
      "Starting Epoch 201\n",
      "0.5086709211270014\n",
      "Starting Epoch 202\n",
      "0.4994159849981467\n",
      "Starting Epoch 203\n",
      "0.4911130766073863\n",
      "Starting Epoch 204\n",
      "0.48852506776650745\n",
      "Starting Epoch 205\n",
      "0.4859103672206402\n",
      "Starting Epoch 206\n",
      "0.4878610397378604\n",
      "Starting Epoch 207\n",
      "0.48420807843406993\n",
      "Starting Epoch 208\n",
      "0.49021582677960396\n",
      "Starting Epoch 209\n",
      "0.48666494091351825\n",
      "Starting Epoch 210\n",
      "0.487524318198363\n",
      "Starting Epoch 211\n",
      "0.4865444414317608\n",
      "Starting Epoch 212\n",
      "0.4868304170668125\n",
      "Starting Epoch 213\n",
      "0.4867076091468334\n",
      "Starting Epoch 214\n",
      "0.4841873111824195\n",
      "Starting Epoch 215\n",
      "0.48502148563663167\n",
      "Starting Epoch 216\n",
      "0.48620746905605\n",
      "New best model found at epoch 216 with validation loss 0.48741984367370605\n",
      "Starting Epoch 217\n",
      "0.4848992278178533\n",
      "New best model found at epoch 217 with validation loss 0.48344942927360535\n",
      "Starting Epoch 218\n",
      "0.48497017721335095\n",
      "Starting Epoch 219\n",
      "0.4858345153431098\n",
      "Starting Epoch 220\n",
      "0.48643192524711293\n",
      "Starting Epoch 221\n",
      "0.486050259321928\n",
      "Starting Epoch 222\n",
      "0.4852079376578331\n",
      "Starting Epoch 223\n",
      "0.4845764848093192\n",
      "Starting Epoch 224\n",
      "0.4849220874408881\n",
      "Starting Epoch 225\n",
      "0.4852428970237573\n",
      "Starting Epoch 226\n",
      "0.48340902104973793\n",
      "New best model found at epoch 226 with validation loss 0.4831525385379791\n",
      "Starting Epoch 227\n",
      "0.481701847165823\n",
      "Starting Epoch 228\n",
      "0.48423223197460175\n",
      "Starting Epoch 229\n",
      "0.48201630264520645\n",
      "Starting Epoch 230\n",
      "0.48465050384402275\n",
      "Starting Epoch 231\n",
      "0.4834514446556568\n",
      "Starting Epoch 232\n",
      "0.4875841575364272\n",
      "Starting Epoch 233\n",
      "0.4831452878812949\n",
      "Starting Epoch 234\n",
      "0.4847014707823594\n",
      "Starting Epoch 235\n",
      "0.48423465217153233\n",
      "Starting Epoch 236\n",
      "0.48247407873471576\n",
      "Starting Epoch 237\n",
      "0.48252518475055695\n",
      "Starting Epoch 238\n",
      "0.4800577089190483\n",
      "Starting Epoch 239\n",
      "0.4819904627899329\n",
      "Starting Epoch 240\n",
      "0.4873606786131859\n",
      "Starting Epoch 241\n",
      "0.4801314063370228\n",
      "Starting Epoch 242\n",
      "0.4869251474738121\n",
      "Starting Epoch 243\n",
      "0.48155054450035095\n",
      "Starting Epoch 244\n",
      "0.4851682136456172\n",
      "Starting Epoch 245\n",
      "0.48369042202830315\n",
      "Starting Epoch 246\n",
      "0.48336413751045865\n",
      "Starting Epoch 247\n",
      "0.48483432456851006\n",
      "New best model found at epoch 247 with validation loss 0.4819489121437073\n",
      "Starting Epoch 248\n",
      "0.48177595312396687\n",
      "Starting Epoch 249\n",
      "0.47830256447196007\n",
      "Starting Epoch 250\n",
      "0.481660109013319\n",
      "Starting Epoch 251\n",
      "0.4848155714571476\n",
      "Starting Epoch 252\n",
      "0.47683529059092206\n",
      "Starting Epoch 253\n",
      "0.4828071879843871\n",
      "Starting Epoch 254\n",
      "0.4807348536948363\n",
      "Starting Epoch 255\n",
      "0.48066206152240437\n",
      "New best model found at epoch 255 with validation loss 0.480929434299469\n",
      "Starting Epoch 256\n",
      "0.4834979933996995\n",
      "Starting Epoch 257\n",
      "0.4773683014015357\n",
      "Starting Epoch 258\n",
      "0.4803423310319583\n",
      "Starting Epoch 259\n",
      "0.4809694228072961\n",
      "Starting Epoch 260\n",
      "0.4789804741740227\n",
      "Starting Epoch 261\n",
      "0.48380811388293904\n",
      "Starting Epoch 262\n",
      "0.4758590832352638\n",
      "Starting Epoch 263\n",
      "0.4779384210705757\n",
      "Starting Epoch 264\n",
      "0.4813477322459221\n",
      "Starting Epoch 265\n",
      "0.48001233239968616\n",
      "Starting Epoch 266\n",
      "0.48042523488402367\n",
      "Starting Epoch 267\n",
      "0.47734082986911136\n",
      "Starting Epoch 268\n",
      "0.48145664980014163\n",
      "Starting Epoch 269\n",
      "0.4808425505956014\n",
      "Starting Epoch 270\n",
      "0.4749510536591212\n",
      "Starting Epoch 271\n",
      "0.4807620445887248\n",
      "Starting Epoch 272\n",
      "0.4800882215301196\n",
      "Starting Epoch 273\n",
      "0.47819965829451877\n",
      "Starting Epoch 274\n",
      "0.4785260433952014\n",
      "Starting Epoch 275\n",
      "0.47631294404466945\n",
      "Starting Epoch 276\n",
      "0.47741512209177017\n",
      "Starting Epoch 277\n",
      "0.4746849536895752\n",
      "New best model found at epoch 277 with validation loss 0.4807567000389099\n",
      "Starting Epoch 278\n",
      "0.47717714061339694\n",
      "Starting Epoch 279\n",
      "0.4745081315437953\n",
      "Starting Epoch 280\n",
      "0.4734043243030707\n",
      "Starting Epoch 281\n",
      "0.47804034873843193\n",
      "Starting Epoch 282\n",
      "0.47732053076227504\n",
      "Starting Epoch 283\n",
      "0.4795673539241155\n",
      "Starting Epoch 284\n",
      "0.4792158839603265\n",
      "Starting Epoch 285\n",
      "0.4737102761864662\n",
      "Starting Epoch 286\n",
      "0.4767437092959881\n",
      "Starting Epoch 287\n",
      "0.47942734385530156\n",
      "Starting Epoch 288\n",
      "0.4790572337806225\n",
      "Starting Epoch 289\n",
      "0.47622181102633476\n",
      "Starting Epoch 290\n",
      "0.4796473793685436\n",
      "Starting Epoch 291\n",
      "0.4804910408953826\n",
      "Starting Epoch 292\n",
      "0.47462156290809315\n",
      "Starting Epoch 293\n",
      "0.47735753531257313\n",
      "Starting Epoch 294\n",
      "0.4757824279367924\n",
      "Starting Epoch 295\n",
      "0.47505684072772664\n",
      "Starting Epoch 296\n",
      "0.47532480334242183\n",
      "Starting Epoch 297\n",
      "0.47745197266340256\n",
      "Starting Epoch 298\n",
      "0.4753984833757083\n",
      "New best model found at epoch 298 with validation loss 0.47999870777130127\n",
      "Starting Epoch 299\n",
      "0.4714080256720384\n",
      "Starting Epoch 300\n",
      "0.47253261754910153\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-60-20-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ed3fe",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 7\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 80 - 50 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4e741854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "06dabf84-2f16-43d6-be8a-2baaabd03045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.94575268526872\n",
      "New best model found at epoch 1 with validation loss 0.5657620429992676\n",
      "Starting Epoch 2\n",
      "0.5785863101482391\n",
      "Starting Epoch 3\n",
      "0.5737335681915283\n",
      "New best model found at epoch 3 with validation loss 0.5624790787696838\n",
      "Starting Epoch 4\n",
      "0.5702610338727633\n",
      "New best model found at epoch 4 with validation loss 0.5577517747879028\n",
      "Starting Epoch 5\n",
      "0.5666666502753893\n",
      "New best model found at epoch 5 with validation loss 0.5534687638282776\n",
      "Starting Epoch 6\n",
      "0.5601771088937918\n",
      "New best model found at epoch 6 with validation loss 0.5491904616355896\n",
      "Starting Epoch 7\n",
      "0.5597738685707251\n",
      "New best model found at epoch 7 with validation loss 0.5460695624351501\n",
      "Starting Epoch 8\n",
      "0.5548828840255737\n",
      "New best model found at epoch 8 with validation loss 0.538755476474762\n",
      "Starting Epoch 9\n",
      "0.5532625503838062\n",
      "Starting Epoch 10\n",
      "0.5511374572912852\n",
      "New best model found at epoch 10 with validation loss 0.5339456796646118\n",
      "Starting Epoch 11\n",
      "0.5562038471301397\n",
      "Starting Epoch 12\n",
      "0.5507990978658199\n",
      "Starting Epoch 13\n",
      "0.542030264933904\n",
      "Starting Epoch 14\n",
      "0.5464455423255762\n",
      "Starting Epoch 15\n",
      "0.5491482975582281\n",
      "Starting Epoch 16\n",
      "0.5411344220240911\n",
      "Starting Epoch 17\n",
      "0.5423743762075901\n",
      "Starting Epoch 18\n",
      "0.5368492491543293\n",
      "Starting Epoch 19\n",
      "0.5391416748364767\n",
      "New best model found at epoch 19 with validation loss 0.5313915014266968\n",
      "Starting Epoch 20\n",
      "0.5347658582031727\n",
      "Starting Epoch 21\n",
      "0.5377982680996259\n",
      "Starting Epoch 22\n",
      "0.5375410057604313\n",
      "Starting Epoch 23\n",
      "0.5326012633740902\n",
      "New best model found at epoch 23 with validation loss 0.5287644863128662\n",
      "Starting Epoch 24\n",
      "0.5279232834776243\n",
      "Starting Epoch 25\n",
      "0.5345581235984961\n",
      "Starting Epoch 26\n",
      "0.530850887298584\n",
      "Starting Epoch 27\n",
      "0.5310584244628748\n",
      "New best model found at epoch 27 with validation loss 0.5209372043609619\n",
      "Starting Epoch 28\n",
      "0.5296443626284599\n",
      "Starting Epoch 29\n",
      "0.5293750862280527\n",
      "Starting Epoch 30\n",
      "0.5250123403966427\n",
      "Starting Epoch 31\n",
      "0.5227863242228826\n",
      "Starting Epoch 32\n",
      "0.5282134637236595\n",
      "New best model found at epoch 32 with validation loss 0.517322301864624\n",
      "Starting Epoch 33\n",
      "0.5225915809472402\n",
      "Starting Epoch 34\n",
      "0.5253680596748987\n",
      "Starting Epoch 35\n",
      "0.523630520949761\n",
      "Starting Epoch 36\n",
      "0.5221090341607729\n",
      "Starting Epoch 37\n",
      "0.5235567887624105\n",
      "Starting Epoch 38\n",
      "0.5205929366250833\n",
      "Starting Epoch 39\n",
      "0.5171845306952795\n",
      "Starting Epoch 40\n",
      "0.5154057219624519\n",
      "Starting Epoch 41\n",
      "0.5207123334209124\n",
      "Starting Epoch 42\n",
      "0.5153902396559715\n",
      "New best model found at epoch 42 with validation loss 0.515814483165741\n",
      "Starting Epoch 43\n",
      "0.5151883587241173\n",
      "Starting Epoch 44\n",
      "0.516331839064757\n",
      "Starting Epoch 45\n",
      "0.5226243548095226\n",
      "Starting Epoch 46\n",
      "0.5154219071070353\n",
      "Starting Epoch 47\n",
      "0.5163617481788\n",
      "Starting Epoch 48\n",
      "0.5160936390360197\n",
      "Starting Epoch 49\n",
      "0.5188791081309319\n",
      "Starting Epoch 50\n",
      "0.5136520167191824\n",
      "Starting Epoch 51\n",
      "0.5158908193310102\n",
      "Starting Epoch 52\n",
      "0.5138776786625385\n",
      "Starting Epoch 53\n",
      "0.5121768166621526\n",
      "Starting Epoch 54\n",
      "0.5147397716840109\n",
      "Starting Epoch 55\n",
      "0.5129582360386848\n",
      "New best model found at epoch 55 with validation loss 0.5111620426177979\n",
      "Starting Epoch 56\n",
      "0.5147050668795904\n",
      "Starting Epoch 57\n",
      "0.5077734204630057\n",
      "Starting Epoch 58\n",
      "0.5111340234676996\n",
      "Starting Epoch 59\n",
      "0.5074429785211881\n",
      "Starting Epoch 60\n",
      "0.5064167231321335\n",
      "Starting Epoch 61\n",
      "0.5101653722425302\n",
      "Starting Epoch 62\n",
      "0.5056487768888474\n",
      "Starting Epoch 63\n",
      "0.5062180832028389\n",
      "Starting Epoch 64\n",
      "0.5061512303849062\n",
      "Starting Epoch 65\n",
      "0.5104644199212393\n",
      "New best model found at epoch 65 with validation loss 0.5098949074745178\n",
      "Starting Epoch 66\n",
      "0.5047464867432913\n",
      "Starting Epoch 67\n",
      "0.5065751348932584\n",
      "New best model found at epoch 67 with validation loss 0.5092111825942993\n",
      "Starting Epoch 68\n",
      "0.5091727152466774\n",
      "New best model found at epoch 68 with validation loss 0.5075190663337708\n",
      "Starting Epoch 69\n",
      "0.5083587393164635\n",
      "Starting Epoch 70\n",
      "0.5051619969308376\n",
      "Starting Epoch 71\n",
      "0.5064362299938997\n",
      "Starting Epoch 72\n",
      "0.5048302387197813\n",
      "Starting Epoch 73\n",
      "0.5027459400395552\n",
      "Starting Epoch 74\n",
      "0.499184454480807\n",
      "Starting Epoch 75\n",
      "0.5001618737975756\n",
      "Starting Epoch 76\n",
      "0.500153715411822\n",
      "Starting Epoch 77\n",
      "0.5047222326199213\n",
      "Starting Epoch 78\n",
      "0.4967603546877702\n",
      "Starting Epoch 79\n",
      "0.5070385783910751\n",
      "Starting Epoch 80\n",
      "0.5129136790831884\n",
      "New best model found at epoch 80 with validation loss 0.49982085824012756\n",
      "Starting Epoch 81\n",
      "0.49978765845298767\n",
      "Starting Epoch 82\n",
      "0.4981456870834033\n",
      "Starting Epoch 83\n",
      "0.5004194701711336\n",
      "Starting Epoch 84\n",
      "0.5002492864926656\n",
      "Starting Epoch 85\n",
      "0.4998390811185042\n",
      "Starting Epoch 86\n",
      "0.5045272695521513\n",
      "Starting Epoch 87\n",
      "0.4999750132362048\n",
      "Starting Epoch 88\n",
      "0.49460767209529877\n",
      "Starting Epoch 89\n",
      "0.5042208470404148\n",
      "Starting Epoch 90\n",
      "0.5001942428449789\n",
      "Starting Epoch 91\n",
      "0.4980050151546796\n",
      "Starting Epoch 92\n",
      "0.49962712327639264\n",
      "Starting Epoch 93\n",
      "0.49962043389678\n",
      "Starting Epoch 94\n",
      "0.498018824805816\n",
      "Starting Epoch 95\n",
      "0.4980144401391347\n",
      "Starting Epoch 96\n",
      "0.4938649957378705\n",
      "Starting Epoch 97\n",
      "0.4995952273408572\n",
      "Starting Epoch 98\n",
      "0.49784425894419354\n",
      "Starting Epoch 99\n",
      "0.49957936878005665\n",
      "Starting Epoch 100\n",
      "0.501765564084053\n",
      "Starting Epoch 101\n",
      "0.49787603318691254\n",
      "Starting Epoch 102\n",
      "0.49811795105536777\n",
      "Starting Epoch 103\n",
      "0.49491189792752266\n",
      "Starting Epoch 104\n",
      "0.49487703169385594\n",
      "New best model found at epoch 104 with validation loss 0.49923503398895264\n",
      "Starting Epoch 105\n",
      "0.5000239722430706\n",
      "Starting Epoch 106\n",
      "0.49671827256679535\n",
      "Starting Epoch 107\n",
      "0.49733128647009534\n",
      "Starting Epoch 108\n",
      "0.4924032377700011\n",
      "Starting Epoch 109\n",
      "0.495205357670784\n",
      "Starting Epoch 110\n",
      "0.48912810410062474\n",
      "Starting Epoch 111\n",
      "0.4886348123351733\n",
      "Starting Epoch 112\n",
      "0.49639525761206943\n",
      "Starting Epoch 113\n",
      "0.49199716995159787\n",
      "Starting Epoch 114\n",
      "0.4908750653266907\n",
      "Starting Epoch 115\n",
      "0.4923015261689822\n",
      "Starting Epoch 116\n",
      "0.49512356768051785\n",
      "Starting Epoch 117\n",
      "0.49208741386731464\n",
      "New best model found at epoch 117 with validation loss 0.4977566599845886\n",
      "Starting Epoch 118\n",
      "0.4910087150832017\n",
      "Starting Epoch 119\n",
      "0.4903535048166911\n",
      "Starting Epoch 120\n",
      "0.49398135766386986\n",
      "Starting Epoch 121\n",
      "0.4892037858565648\n",
      "Starting Epoch 122\n",
      "0.48872121050953865\n",
      "Starting Epoch 123\n",
      "0.48843899990121525\n",
      "Starting Epoch 124\n",
      "0.4905541365345319\n",
      "Starting Epoch 125\n",
      "0.4885448639591535\n",
      "Starting Epoch 126\n",
      "0.48825878525773686\n",
      "Starting Epoch 127\n",
      "0.48924316838383675\n",
      "New best model found at epoch 127 with validation loss 0.49138176441192627\n",
      "Starting Epoch 128\n",
      "0.4896028848985831\n",
      "Starting Epoch 129\n",
      "0.4857632555067539\n",
      "Starting Epoch 130\n",
      "0.4837161439160506\n",
      "Starting Epoch 131\n",
      "0.4849603809416294\n",
      "Starting Epoch 132\n",
      "0.48731599499781925\n",
      "Starting Epoch 133\n",
      "0.48856501777966815\n",
      "Starting Epoch 134\n",
      "0.48463843390345573\n",
      "Starting Epoch 135\n",
      "0.4835515134036541\n",
      "Starting Epoch 136\n",
      "0.48699795951445896\n",
      "Starting Epoch 137\n",
      "0.4863474890589714\n",
      "Starting Epoch 138\n",
      "0.48347902794679004\n",
      "Starting Epoch 139\n",
      "0.48384422188003856\n",
      "Starting Epoch 140\n",
      "0.48689623922109604\n",
      "Starting Epoch 141\n",
      "0.4852539487183094\n",
      "Starting Epoch 142\n",
      "0.4877910328408082\n",
      "Starting Epoch 143\n",
      "0.4822097333769004\n",
      "Starting Epoch 144\n",
      "0.4799739134808381\n",
      "New best model found at epoch 144 with validation loss 0.48756876587867737\n",
      "Starting Epoch 145\n",
      "0.4853910965224107\n",
      "Starting Epoch 146\n",
      "0.4849731922149658\n",
      "Starting Epoch 147\n",
      "0.48738952726125717\n",
      "Starting Epoch 148\n",
      "0.4832065850496292\n",
      "Starting Epoch 149\n",
      "0.4815235051016013\n",
      "Starting Epoch 150\n",
      "0.48116355761885643\n",
      "Starting Epoch 151\n",
      "0.47980501875281334\n",
      "Starting Epoch 152\n",
      "0.4796549901366234\n",
      "Starting Epoch 153\n",
      "0.48223187401890755\n",
      "Starting Epoch 154\n",
      "0.47931001087029773\n",
      "Starting Epoch 155\n",
      "0.4793647949894269\n",
      "Starting Epoch 156\n",
      "0.48407475898663205\n",
      "Starting Epoch 157\n",
      "0.48100945353507996\n",
      "Starting Epoch 158\n",
      "0.4813151570657889\n",
      "Starting Epoch 159\n",
      "0.48026324436068535\n",
      "Starting Epoch 160\n",
      "0.4785989423592885\n",
      "Starting Epoch 161\n",
      "0.48026226088404655\n",
      "Starting Epoch 162\n",
      "0.4817399171491464\n",
      "New best model found at epoch 162 with validation loss 0.48749643564224243\n",
      "Starting Epoch 163\n",
      "0.483744112153848\n",
      "Starting Epoch 164\n",
      "0.4790227996806304\n",
      "Starting Epoch 165\n",
      "0.4797448292374611\n",
      "Starting Epoch 166\n",
      "0.4751519535978635\n",
      "Starting Epoch 167\n",
      "0.47465114047129947\n",
      "Starting Epoch 168\n",
      "0.4772467290361722\n",
      "Starting Epoch 169\n",
      "0.47844110677639645\n",
      "Starting Epoch 170\n",
      "0.475778433183829\n",
      "Starting Epoch 171\n",
      "0.4823329448699951\n",
      "Starting Epoch 172\n",
      "0.47765641535321873\n",
      "Starting Epoch 173\n",
      "0.4775041763981183\n",
      "Starting Epoch 174\n",
      "0.47862813745935756\n",
      "Starting Epoch 175\n",
      "0.4730684918661912\n",
      "Starting Epoch 176\n",
      "0.4764269106090069\n",
      "Starting Epoch 177\n",
      "0.4772353221972783\n",
      "Starting Epoch 178\n",
      "0.47216934089859325\n",
      "Starting Epoch 179\n",
      "0.4775192228456338\n",
      "Starting Epoch 180\n",
      "0.4724855497479439\n",
      "Starting Epoch 181\n",
      "0.4755437585214774\n",
      "Starting Epoch 182\n",
      "0.4747570604085922\n",
      "Starting Epoch 183\n",
      "0.4753802679479122\n",
      "Starting Epoch 184\n",
      "0.47282277792692184\n",
      "Starting Epoch 185\n",
      "0.47634883349140483\n",
      "New best model found at epoch 185 with validation loss 0.4844813942909241\n",
      "Starting Epoch 186\n",
      "0.47405293956398964\n",
      "Starting Epoch 187\n",
      "0.47593146190047264\n",
      "Starting Epoch 188\n",
      "0.4738577989240487\n",
      "Starting Epoch 189\n",
      "0.4724295722941558\n",
      "Starting Epoch 190\n",
      "0.471678468088309\n",
      "Starting Epoch 191\n",
      "0.4742434124151866\n",
      "Starting Epoch 192\n",
      "0.4718283514181773\n",
      "Starting Epoch 193\n",
      "0.4728806937734286\n",
      "Starting Epoch 194\n",
      "0.47412429625789326\n",
      "New best model found at epoch 194 with validation loss 0.4840237498283386\n",
      "Starting Epoch 195\n",
      "0.47206391394138336\n",
      "Starting Epoch 196\n",
      "0.4726390192906062\n",
      "Starting Epoch 197\n",
      "0.47410789504647255\n",
      "Starting Epoch 198\n",
      "0.4684745743870735\n",
      "Starting Epoch 199\n",
      "0.4670417569577694\n",
      "Starting Epoch 200\n",
      "0.4711645332475503\n",
      "Starting Epoch 201\n",
      "0.4716695435345173\n",
      "Starting Epoch 202\n",
      "0.47157957156499225\n",
      "Starting Epoch 203\n",
      "0.46671778957049054\n",
      "Starting Epoch 204\n",
      "0.4702133846779664\n",
      "Starting Epoch 205\n",
      "0.47122808421651524\n",
      "Starting Epoch 206\n",
      "0.4662853640814622\n",
      "Starting Epoch 207\n",
      "0.46613194420933723\n",
      "Starting Epoch 208\n",
      "0.47141894201437634\n",
      "Starting Epoch 209\n",
      "0.47534193346897763\n",
      "Starting Epoch 210\n",
      "0.4714852037529151\n",
      "New best model found at epoch 210 with validation loss 0.4828351140022278\n",
      "Starting Epoch 211\n",
      "0.47186578810214996\n",
      "Starting Epoch 212\n",
      "0.46545721714695293\n",
      "Starting Epoch 213\n",
      "0.4699704957505067\n",
      "Starting Epoch 214\n",
      "0.4710904235641162\n",
      "Starting Epoch 215\n",
      "0.4701193670431773\n",
      "Starting Epoch 216\n",
      "0.46523985142509144\n",
      "Starting Epoch 217\n",
      "0.4628806710243225\n",
      "Starting Epoch 218\n",
      "0.4687032823761304\n",
      "Starting Epoch 219\n",
      "0.4676175241669019\n",
      "Starting Epoch 220\n",
      "0.46304507926106453\n",
      "Starting Epoch 221\n",
      "0.4668324651817481\n",
      "Starting Epoch 222\n",
      "0.4651436060667038\n",
      "Starting Epoch 223\n",
      "0.46921584755182266\n",
      "Starting Epoch 224\n",
      "0.46320992956558865\n",
      "Starting Epoch 225\n",
      "0.46610844880342484\n",
      "Starting Epoch 226\n",
      "0.4617221876978874\n",
      "Starting Epoch 227\n",
      "0.4622981908420722\n",
      "Starting Epoch 228\n",
      "0.46281066288550693\n",
      "Starting Epoch 229\n",
      "0.4615880933900674\n",
      "New best model found at epoch 229 with validation loss 0.47733575105667114\n",
      "Starting Epoch 230\n",
      "0.4615393976370494\n",
      "Starting Epoch 231\n",
      "0.4662084641555945\n",
      "Starting Epoch 232\n",
      "0.4626365192234516\n",
      "Starting Epoch 233\n",
      "0.4606895868976911\n",
      "Starting Epoch 234\n",
      "0.46342164650559425\n",
      "Starting Epoch 235\n",
      "0.46522387986381847\n",
      "Starting Epoch 236\n",
      "0.46327825138966244\n",
      "Starting Epoch 237\n",
      "0.4668722227215767\n",
      "Starting Epoch 238\n",
      "0.4664747541149457\n",
      "Starting Epoch 239\n",
      "0.4594729269544284\n",
      "Starting Epoch 240\n",
      "0.46053166314959526\n",
      "Starting Epoch 241\n",
      "0.46503616248567897\n",
      "Starting Epoch 242\n",
      "0.4573432045678298\n",
      "Starting Epoch 243\n",
      "0.4622168006996314\n",
      "Starting Epoch 244\n",
      "0.4635868767897288\n",
      "Starting Epoch 245\n",
      "0.46109120920300484\n",
      "Starting Epoch 246\n",
      "0.46047424773375195\n",
      "Starting Epoch 247\n",
      "0.460201408714056\n",
      "Starting Epoch 248\n",
      "0.4647584284345309\n",
      "Starting Epoch 249\n",
      "0.4574887081980705\n",
      "Starting Epoch 250\n",
      "0.46032413964470226\n",
      "Starting Epoch 251\n",
      "0.4591219412783782\n",
      "Starting Epoch 252\n",
      "0.46003610268235207\n",
      "Starting Epoch 253\n",
      "0.4585854485630989\n",
      "Starting Epoch 254\n",
      "0.46159712101022404\n",
      "Starting Epoch 255\n",
      "0.45903289318084717\n",
      "Starting Epoch 256\n",
      "0.4574221173922221\n",
      "New best model found at epoch 256 with validation loss 0.4759243428707123\n",
      "Starting Epoch 257\n",
      "0.45485222339630127\n",
      "Starting Epoch 258\n",
      "0.4577328637242317\n",
      "Starting Epoch 259\n",
      "0.4576472155749798\n",
      "Starting Epoch 260\n",
      "0.45797223970294\n",
      "Starting Epoch 261\n",
      "0.4575594328343868\n",
      "Starting Epoch 262\n",
      "0.461435467004776\n",
      "Starting Epoch 263\n",
      "0.4561016882459323\n",
      "Starting Epoch 264\n",
      "0.4615081548690796\n",
      "Starting Epoch 265\n",
      "0.45420485114057857\n",
      "Starting Epoch 266\n",
      "0.4562588855624199\n",
      "Starting Epoch 267\n",
      "0.45520982270439464\n",
      "Starting Epoch 268\n",
      "0.4587637297809124\n",
      "Starting Epoch 269\n",
      "0.455109187712272\n",
      "Starting Epoch 270\n",
      "0.45584336916605633\n",
      "Starting Epoch 271\n",
      "0.4552275004486243\n",
      "Starting Epoch 272\n",
      "0.4539579538007577\n",
      "Starting Epoch 273\n",
      "0.45761003841956455\n",
      "Starting Epoch 274\n",
      "0.45729247728983563\n",
      "Starting Epoch 275\n",
      "0.45420896510283154\n",
      "Starting Epoch 276\n",
      "0.4530685395002365\n",
      "Starting Epoch 277\n",
      "0.4576798963050048\n",
      "Starting Epoch 278\n",
      "0.4543696977198124\n",
      "Starting Epoch 279\n",
      "0.45838097855448723\n",
      "Starting Epoch 280\n",
      "0.45023348679145175\n",
      "Starting Epoch 281\n",
      "0.4554404392838478\n",
      "Starting Epoch 282\n",
      "0.4525830162068208\n",
      "Starting Epoch 283\n",
      "0.45375989998380345\n",
      "New best model found at epoch 283 with validation loss 0.47090205550193787\n",
      "Starting Epoch 284\n",
      "0.4555441265304883\n",
      "Starting Epoch 285\n",
      "0.45423167447249096\n",
      "Starting Epoch 286\n",
      "0.4520344523092111\n",
      "Starting Epoch 287\n",
      "0.45414595181743306\n",
      "Starting Epoch 288\n",
      "0.45236417402823764\n",
      "Starting Epoch 289\n",
      "0.45214266950885457\n",
      "Starting Epoch 290\n",
      "0.4497189198931058\n",
      "Starting Epoch 291\n",
      "0.45443876336018246\n",
      "Starting Epoch 292\n",
      "0.45145197957754135\n",
      "Starting Epoch 293\n",
      "0.4508485558132331\n",
      "Starting Epoch 294\n",
      "0.4547032279272874\n",
      "Starting Epoch 295\n",
      "0.450489812841018\n",
      "Starting Epoch 296\n",
      "0.4482358731329441\n",
      "Starting Epoch 297\n",
      "0.4503146323064963\n",
      "Starting Epoch 298\n",
      "0.4474884246786435\n",
      "Starting Epoch 299\n",
      "0.45454922194282216\n",
      "Starting Epoch 300\n",
      "0.4537115568916003\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-80-50-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "50b89812-3cab-4764-b436-e1818eb78c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.800758</td>\n",
       "      <td>0.809452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>0.817704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.812879</td>\n",
       "      <td>0.833458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.679181</td>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.684091</td>\n",
       "      <td>0.555139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.533784</td>\n",
       "      <td>0.714773</td>\n",
       "      <td>0.579145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.710606</td>\n",
       "      <td>0.525881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-2</th>\n",
       "      <td>0.720137</td>\n",
       "      <td>0.574324</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-2</th>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.574324</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-2</th>\n",
       "      <td>0.716724</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-2</th>\n",
       "      <td>0.703072</td>\n",
       "      <td>0.614865</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-2</th>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-2</th>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-2</th>\n",
       "      <td>0.706485</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-2</th>\n",
       "      <td>0.774744</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-2</th>\n",
       "      <td>0.754266</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-2</th>\n",
       "      <td>0.706485</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-2</th>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-2</th>\n",
       "      <td>0.730375</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-2</th>\n",
       "      <td>0.774744</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      acc       rec       acc       rec\n",
       "5-NN             0.829352  0.824324  0.800758  0.809452\n",
       "Decision tree    0.836177  0.797297  0.814394  0.817704\n",
       "Random forest    0.832765  0.831081  0.812879  0.833458\n",
       "SVM linear       0.679181  0.506757  0.684091  0.555139\n",
       "SVM poly         0.696246  0.533784  0.714773  0.579145\n",
       "SVM rbf          0.713311  0.513514  0.710606  0.525881\n",
       "MLP: 17-5-2      0.720137  0.574324         -         -\n",
       "MLP: 17-10-2     0.692833  0.574324         -         -\n",
       "MLP: 17-20-2     0.716724  0.587838         -         -\n",
       "MLP: 17-25-2     0.703072  0.614865         -         -\n",
       "MLP: 17-40-2     0.696246  0.608108         -         -\n",
       "MLP: 17-60-2     0.713311  0.655405         -         -\n",
       "MLP: 17-10-5-2   0.706485  0.641892         -         -\n",
       "MLP: 17-20-10-2  0.774744  0.797297         -         -\n",
       "MLP: 17-40-20-2  0.754266  0.729730         -         -\n",
       "MLP: 17-40-10-2  0.706485  0.513514         -         -\n",
       "MLP: 17-60-40-2  0.767918  0.695946         -         -\n",
       "MLP: 17-60-20-2  0.730375  0.641892         -         -\n",
       "MLP: 17-80-50-2  0.774744  0.702703         -         -"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b21b4",
   "metadata": {},
   "source": [
    "best performing model until now: 4 layers, 17-20-10-2/17-80-50-2    \n",
    "We use 17-80-50-2 in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15710149",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "171c2874-92c0-4d56-a35e-a2f3aad9ca2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "013580bf-aeae-4724-ab6d-9d4ac2496e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,9,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7416bf76-cc9b-42b5-b8d7-1bc6e55d30b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'median(container counts)', 'median(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f92d276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "383e0973-cf4c-4bf5-9f2e-697e9e1e4b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.1941103041172028\n",
      "New best model found at epoch 1 with validation loss 0.5679879188537598\n",
      "Starting Epoch 2\n",
      "0.5773982343574365\n",
      "Starting Epoch 3\n",
      "0.5675230212509632\n",
      "Starting Epoch 4\n",
      "0.5796937197446823\n",
      "New best model found at epoch 4 with validation loss 0.5653653144836426\n",
      "Starting Epoch 5\n",
      "0.5641199313104153\n",
      "Starting Epoch 6\n",
      "0.5656998778382937\n",
      "Starting Epoch 7\n",
      "0.557618131240209\n",
      "New best model found at epoch 7 with validation loss 0.5653498768806458\n",
      "Starting Epoch 8\n",
      "0.5675139650702477\n",
      "New best model found at epoch 8 with validation loss 0.5546006560325623\n",
      "Starting Epoch 9\n",
      "0.5550567395985126\n",
      "Starting Epoch 10\n",
      "0.5544591285288334\n",
      "Starting Epoch 11\n",
      "0.5603303263584772\n",
      "Starting Epoch 12\n",
      "0.5556061007082462\n",
      "Starting Epoch 13\n",
      "0.5550740125278631\n",
      "New best model found at epoch 13 with validation loss 0.5526977181434631\n",
      "Starting Epoch 14\n",
      "0.5512407931188742\n",
      "Starting Epoch 15\n",
      "0.5526434468726317\n",
      "New best model found at epoch 15 with validation loss 0.5501917004585266\n",
      "Starting Epoch 16\n",
      "0.5495721027255058\n",
      "Starting Epoch 17\n",
      "0.5528607269128164\n",
      "New best model found at epoch 17 with validation loss 0.5452941656112671\n",
      "Starting Epoch 18\n",
      "0.5509229116141796\n",
      "Starting Epoch 19\n",
      "0.5518969831367334\n",
      "Starting Epoch 20\n",
      "0.5479557191332182\n",
      "Starting Epoch 21\n",
      "0.5454644039273262\n",
      "New best model found at epoch 21 with validation loss 0.5431516766548157\n",
      "Starting Epoch 22\n",
      "0.5495331299801668\n",
      "Starting Epoch 23\n",
      "0.5456586331129074\n",
      "New best model found at epoch 23 with validation loss 0.5415481925010681\n",
      "Starting Epoch 24\n",
      "0.5476568192243576\n",
      "Starting Epoch 25\n",
      "0.5461962210635344\n",
      "Starting Epoch 26\n",
      "0.5493621888260046\n",
      "Starting Epoch 27\n",
      "0.5452630879978339\n",
      "New best model found at epoch 27 with validation loss 0.5364890694618225\n",
      "Starting Epoch 28\n",
      "0.5436705152193705\n",
      "Starting Epoch 29\n",
      "0.5456463483472666\n",
      "Starting Epoch 30\n",
      "0.5457344626386961\n",
      "Starting Epoch 31\n",
      "0.5445234961807728\n",
      "New best model found at epoch 31 with validation loss 0.535167932510376\n",
      "Starting Epoch 32\n",
      "0.5387796399494013\n",
      "Starting Epoch 33\n",
      "0.5494289311269919\n",
      "Starting Epoch 34\n",
      "0.5439590439200401\n",
      "Starting Epoch 35\n",
      "0.5421980917453766\n",
      "Starting Epoch 36\n",
      "0.54264813909928\n",
      "Starting Epoch 37\n",
      "0.5432010168830553\n",
      "Starting Epoch 38\n",
      "0.5404919125139713\n",
      "Starting Epoch 39\n",
      "0.5426140452424685\n",
      "Starting Epoch 40\n",
      "0.5428087872763475\n",
      "Starting Epoch 41\n",
      "0.5410672475894293\n",
      "Starting Epoch 42\n",
      "0.5410439980526766\n",
      "Starting Epoch 43\n",
      "0.5431623260180155\n",
      "Starting Epoch 44\n",
      "0.5412198056777319\n",
      "Starting Epoch 45\n",
      "0.5364885615805784\n",
      "New best model found at epoch 45 with validation loss 0.5343020558357239\n",
      "Starting Epoch 46\n",
      "0.5363203038771948\n",
      "Starting Epoch 47\n",
      "0.5408278964459896\n",
      "Starting Epoch 48\n",
      "0.5339383520185947\n",
      "New best model found at epoch 48 with validation loss 0.531436026096344\n",
      "Starting Epoch 49\n",
      "0.5408679880201817\n",
      "Starting Epoch 50\n",
      "0.5394717628757159\n",
      "Starting Epoch 51\n",
      "0.5407667296628157\n",
      "Starting Epoch 52\n",
      "0.5409826214114825\n",
      "Starting Epoch 53\n",
      "0.5388939293722311\n",
      "New best model found at epoch 53 with validation loss 0.5304905772209167\n",
      "Starting Epoch 54\n",
      "0.5372507659097513\n",
      "Starting Epoch 55\n",
      "0.5362887444595495\n",
      "Starting Epoch 56\n",
      "0.5356987031797568\n",
      "New best model found at epoch 56 with validation loss 0.5297145843505859\n",
      "Starting Epoch 57\n",
      "0.5364185261229674\n",
      "Starting Epoch 58\n",
      "0.5346986378232638\n",
      "Starting Epoch 59\n",
      "0.5383595538636049\n",
      "Starting Epoch 60\n",
      "0.5352859422564507\n",
      "New best model found at epoch 60 with validation loss 0.5287477970123291\n",
      "Starting Epoch 61\n",
      "0.536929818491141\n",
      "Starting Epoch 62\n",
      "0.5362848676741123\n",
      "New best model found at epoch 62 with validation loss 0.526056706905365\n",
      "Starting Epoch 63\n",
      "0.5347625265518824\n",
      "Starting Epoch 64\n",
      "0.531214120487372\n",
      "Starting Epoch 65\n",
      "0.5351129372914633\n",
      "Starting Epoch 66\n",
      "0.5359778627753258\n",
      "New best model found at epoch 66 with validation loss 0.5250893235206604\n",
      "Starting Epoch 67\n",
      "0.5308329251905283\n",
      "Starting Epoch 68\n",
      "0.5337318802873293\n",
      "Starting Epoch 69\n",
      "0.5317364248136679\n",
      "Starting Epoch 70\n",
      "0.5304705301920573\n",
      "Starting Epoch 71\n",
      "0.5317920992771784\n",
      "Starting Epoch 72\n",
      "0.5329996223251025\n",
      "Starting Epoch 73\n",
      "0.5331572704017162\n",
      "Starting Epoch 74\n",
      "0.5311474402745565\n",
      "Starting Epoch 75\n",
      "0.5317941680550575\n",
      "Starting Epoch 76\n",
      "0.5332380446294943\n",
      "Starting Epoch 77\n",
      "0.5310129188001156\n",
      "Starting Epoch 78\n",
      "0.5299974369506041\n",
      "Starting Epoch 79\n",
      "0.5285939673582712\n",
      "Starting Epoch 80\n",
      "0.5312240049242973\n",
      "New best model found at epoch 80 with validation loss 0.5229582786560059\n",
      "Starting Epoch 81\n",
      "0.5316837939123312\n",
      "New best model found at epoch 81 with validation loss 0.5222702622413635\n",
      "Starting Epoch 82\n",
      "0.5270674228668213\n",
      "Starting Epoch 83\n",
      "0.5329535280664762\n",
      "Starting Epoch 84\n",
      "0.5299111120402813\n",
      "Starting Epoch 85\n",
      "0.5313501047591368\n",
      "Starting Epoch 86\n",
      "0.5336419257024924\n",
      "New best model found at epoch 86 with validation loss 0.5213444828987122\n",
      "Starting Epoch 87\n",
      "0.5301989081005255\n",
      "New best model found at epoch 87 with validation loss 0.519684374332428\n",
      "Starting Epoch 88\n",
      "0.533238826940457\n",
      "New best model found at epoch 88 with validation loss 0.519382894039154\n",
      "Starting Epoch 89\n",
      "0.5289242925743262\n",
      "Starting Epoch 90\n",
      "0.5326447648306688\n",
      "Starting Epoch 91\n",
      "0.5267459141711394\n",
      "Starting Epoch 92\n",
      "0.531203436354796\n",
      "Starting Epoch 93\n",
      "0.5288502549131712\n",
      "Starting Epoch 94\n",
      "0.5288503629465898\n",
      "New best model found at epoch 94 with validation loss 0.517582893371582\n",
      "Starting Epoch 95\n",
      "0.529425082107385\n",
      "Starting Epoch 96\n",
      "0.5318439677357674\n",
      "Starting Epoch 97\n",
      "0.5277243070304394\n",
      "Starting Epoch 98\n",
      "0.5269826166331768\n",
      "Starting Epoch 99\n",
      "0.5285722476740679\n",
      "Starting Epoch 100\n",
      "0.5279914053777853\n",
      "Starting Epoch 101\n",
      "0.5304682701826096\n",
      "Starting Epoch 102\n",
      "0.526580477754275\n",
      "Starting Epoch 103\n",
      "0.5263058158258597\n",
      "New best model found at epoch 103 with validation loss 0.5144248604774475\n",
      "Starting Epoch 104\n",
      "0.5262043625116348\n",
      "Starting Epoch 105\n",
      "0.528363806505998\n",
      "Starting Epoch 106\n",
      "0.5295033839841684\n",
      "Starting Epoch 107\n",
      "0.5247655486067136\n",
      "Starting Epoch 108\n",
      "0.5229644303520521\n",
      "Starting Epoch 109\n",
      "0.5297996004422506\n",
      "Starting Epoch 110\n",
      "0.5252932446698347\n",
      "Starting Epoch 111\n",
      "0.5248517406483492\n",
      "Starting Epoch 112\n",
      "0.5250183517734209\n",
      "New best model found at epoch 112 with validation loss 0.5141698718070984\n",
      "Starting Epoch 113\n",
      "0.5257413424551487\n",
      "New best model found at epoch 113 with validation loss 0.5135670900344849\n",
      "Starting Epoch 114\n",
      "0.5231730006635189\n",
      "Starting Epoch 115\n",
      "0.522652784983317\n",
      "Starting Epoch 116\n",
      "0.5217382063468298\n",
      "Starting Epoch 117\n",
      "0.5238109851876894\n",
      "Starting Epoch 118\n",
      "0.5226576266189417\n",
      "New best model found at epoch 118 with validation loss 0.5106191039085388\n",
      "Starting Epoch 119\n",
      "0.5243108769257864\n",
      "Starting Epoch 120\n",
      "0.5205578183134397\n",
      "Starting Epoch 121\n",
      "0.5238927056392034\n",
      "Starting Epoch 122\n",
      "0.522909746815761\n",
      "Starting Epoch 123\n",
      "0.5194768086075783\n",
      "Starting Epoch 124\n",
      "0.5229970713456472\n",
      "Starting Epoch 125\n",
      "0.5224657667179903\n",
      "Starting Epoch 126\n",
      "0.5219691271583239\n",
      "Starting Epoch 127\n",
      "0.5225820342699686\n",
      "Starting Epoch 128\n",
      "0.5204438803096613\n",
      "Starting Epoch 129\n",
      "0.5194196390608946\n",
      "Starting Epoch 130\n",
      "0.5235757641494274\n",
      "Starting Epoch 131\n",
      "0.5193872389694055\n",
      "New best model found at epoch 131 with validation loss 0.5068029165267944\n",
      "Starting Epoch 132\n",
      "0.5221750053266684\n",
      "Starting Epoch 133\n",
      "0.5189411528408527\n",
      "Starting Epoch 134\n",
      "0.5203199436267217\n",
      "Starting Epoch 135\n",
      "0.5164713859558105\n",
      "Starting Epoch 136\n",
      "0.5199044023950895\n",
      "New best model found at epoch 136 with validation loss 0.5063027739524841\n",
      "Starting Epoch 137\n",
      "0.517376895993948\n",
      "Starting Epoch 138\n",
      "0.5166205738981565\n",
      "Starting Epoch 139\n",
      "0.5166706343491873\n",
      "Starting Epoch 140\n",
      "0.5196264361341795\n",
      "New best model found at epoch 140 with validation loss 0.5049235820770264\n",
      "Starting Epoch 141\n",
      "0.5160807569821676\n",
      "Starting Epoch 142\n",
      "0.5168887202938398\n",
      "Starting Epoch 143\n",
      "0.516331979384025\n",
      "Starting Epoch 144\n",
      "0.5162803716957569\n",
      "Starting Epoch 145\n",
      "0.5157641172409058\n",
      "Starting Epoch 146\n",
      "0.5193728966017565\n",
      "Starting Epoch 147\n",
      "0.5190683118999004\n",
      "Starting Epoch 148\n",
      "0.5189678656558195\n",
      "Starting Epoch 149\n",
      "0.5162167524298032\n",
      "Starting Epoch 150\n",
      "0.5184538376828035\n",
      "Starting Epoch 151\n",
      "0.5173096048335234\n",
      "New best model found at epoch 151 with validation loss 0.5047127604484558\n",
      "Starting Epoch 152\n",
      "0.513764093319575\n",
      "Starting Epoch 153\n",
      "0.5175010710954666\n",
      "New best model found at epoch 153 with validation loss 0.5021349787712097\n",
      "Starting Epoch 154\n",
      "0.515505156169335\n",
      "Starting Epoch 155\n",
      "0.5178025166193644\n",
      "Starting Epoch 156\n",
      "0.5127455579737822\n",
      "Starting Epoch 157\n",
      "0.5140945874154568\n",
      "Starting Epoch 158\n",
      "0.5162818245589733\n",
      "Starting Epoch 159\n",
      "0.5142817310988903\n",
      "New best model found at epoch 159 with validation loss 0.5018805861473083\n",
      "Starting Epoch 160\n",
      "0.5145153639217218\n",
      "Starting Epoch 161\n",
      "0.516073697557052\n",
      "New best model found at epoch 161 with validation loss 0.49996504187583923\n",
      "Starting Epoch 162\n",
      "0.5158895030617714\n",
      "Starting Epoch 163\n",
      "0.5129233760138353\n",
      "Starting Epoch 164\n",
      "0.5139317015806834\n",
      "Starting Epoch 165\n",
      "0.5155382926265398\n",
      "Starting Epoch 166\n",
      "0.5149975667397181\n",
      "Starting Epoch 167\n",
      "0.5135404641429583\n",
      "Starting Epoch 168\n",
      "0.5138685504595438\n",
      "Starting Epoch 169\n",
      "0.512484767784675\n",
      "Starting Epoch 170\n",
      "0.514759843548139\n",
      "Starting Epoch 171\n",
      "0.515164619932572\n",
      "Starting Epoch 172\n",
      "0.5141518712043762\n",
      "Starting Epoch 173\n",
      "0.5147324278950691\n",
      "Starting Epoch 174\n",
      "0.5137566377719244\n",
      "Starting Epoch 175\n",
      "0.5147330276668072\n",
      "Starting Epoch 176\n",
      "0.5194107058147589\n",
      "Starting Epoch 177\n",
      "0.5155128737290701\n",
      "Starting Epoch 178\n",
      "0.5100693441927433\n",
      "Starting Epoch 179\n",
      "0.5152603474756082\n",
      "Starting Epoch 180\n",
      "0.5136009777585665\n",
      "Starting Epoch 181\n",
      "0.5121239945292473\n",
      "Starting Epoch 182\n",
      "0.5099910659094652\n",
      "Starting Epoch 183\n",
      "0.5099673134585222\n",
      "Starting Epoch 184\n",
      "0.5128819358845552\n",
      "Starting Epoch 185\n",
      "0.5103907597561678\n",
      "Starting Epoch 186\n",
      "0.5109005259970824\n",
      "Starting Epoch 187\n",
      "0.5081147799889246\n",
      "Starting Epoch 188\n",
      "0.5098068304359913\n",
      "Starting Epoch 189\n",
      "0.5125544344385465\n",
      "Starting Epoch 190\n",
      "0.5143203611175219\n",
      "Starting Epoch 191\n",
      "0.5142656055589517\n",
      "Starting Epoch 192\n",
      "0.5079665618638197\n",
      "Starting Epoch 193\n",
      "0.5137830016513666\n",
      "Starting Epoch 194\n",
      "0.5117988126973311\n",
      "Starting Epoch 195\n",
      "0.5153473826746146\n",
      "New best model found at epoch 195 with validation loss 0.4991547763347626\n",
      "Starting Epoch 196\n",
      "0.5093400739133358\n",
      "Starting Epoch 197\n",
      "0.5119471810758114\n",
      "Starting Epoch 198\n",
      "0.5102911281088988\n",
      "Starting Epoch 199\n",
      "0.5092600422600905\n",
      "Starting Epoch 200\n",
      "0.5103678815066814\n",
      "Starting Epoch 201\n",
      "0.510834256807963\n",
      "Starting Epoch 202\n",
      "0.503914337605238\n",
      "Starting Epoch 203\n",
      "0.5127096710105737\n",
      "Starting Epoch 204\n",
      "0.5099452113111814\n",
      "New best model found at epoch 204 with validation loss 0.49903032183647156\n",
      "Starting Epoch 205\n",
      "0.5107430579761664\n",
      "Starting Epoch 206\n",
      "0.5068150634566942\n",
      "Starting Epoch 207\n",
      "0.5096219268937906\n",
      "New best model found at epoch 207 with validation loss 0.49670395255088806\n",
      "Starting Epoch 208\n",
      "0.5095138822992643\n",
      "Starting Epoch 209\n",
      "0.5096620731055737\n",
      "Starting Epoch 210\n",
      "0.5090976109107336\n",
      "Starting Epoch 211\n",
      "0.5099444302419821\n",
      "Starting Epoch 212\n",
      "0.5074944657584032\n",
      "Starting Epoch 213\n",
      "0.5064770070215067\n",
      "Starting Epoch 214\n",
      "0.5098046623170376\n",
      "Starting Epoch 215\n",
      "0.5117815596361955\n",
      "Starting Epoch 216\n",
      "0.5085612113277117\n",
      "Starting Epoch 217\n",
      "0.5101401979724566\n",
      "Starting Epoch 218\n",
      "0.5055949427187443\n",
      "Starting Epoch 219\n",
      "0.5085667197902998\n",
      "Starting Epoch 220\n",
      "0.5091681058208147\n",
      "Starting Epoch 221\n",
      "0.5074991583824158\n",
      "Starting Epoch 222\n",
      "0.5083173513412476\n",
      "Starting Epoch 223\n",
      "0.505209052314361\n",
      "Starting Epoch 224\n",
      "0.5019591997067133\n",
      "Starting Epoch 225\n",
      "0.5085906746486822\n",
      "Starting Epoch 226\n",
      "0.5083574963112673\n",
      "Starting Epoch 227\n",
      "0.5074423688153425\n",
      "New best model found at epoch 227 with validation loss 0.49626293778419495\n",
      "Starting Epoch 228\n",
      "0.50743701060613\n",
      "Starting Epoch 229\n",
      "0.5080155196289221\n",
      "Starting Epoch 230\n",
      "0.5056805747250716\n",
      "Starting Epoch 231\n",
      "0.5043343926469485\n",
      "Starting Epoch 232\n",
      "0.5092809262375037\n",
      "Starting Epoch 233\n",
      "0.5058597152431806\n",
      "Starting Epoch 234\n",
      "0.5061788732806841\n",
      "Starting Epoch 235\n",
      "0.5060812172790369\n",
      "Starting Epoch 236\n",
      "0.5049315777917703\n",
      "Starting Epoch 237\n",
      "0.5050419345498085\n",
      "Starting Epoch 238\n",
      "0.5037463754415512\n",
      "Starting Epoch 239\n",
      "0.5074542698760828\n",
      "Starting Epoch 240\n",
      "0.5050139712790648\n",
      "Starting Epoch 241\n",
      "0.5083201949795088\n",
      "Starting Epoch 242\n",
      "0.5012022890150547\n",
      "Starting Epoch 243\n",
      "0.5044390186667442\n",
      "Starting Epoch 244\n",
      "0.5050581147273382\n",
      "Starting Epoch 245\n",
      "0.5083520660797755\n",
      "Starting Epoch 246\n",
      "0.5030610784888268\n",
      "Starting Epoch 247\n",
      "0.5038037945826849\n",
      "Starting Epoch 248\n",
      "0.5036493924756845\n",
      "Starting Epoch 249\n",
      "0.5057815673450629\n",
      "Starting Epoch 250\n",
      "0.5068393548329672\n",
      "Starting Epoch 251\n",
      "0.5059318641821543\n",
      "Starting Epoch 252\n",
      "0.5050384663045406\n",
      "Starting Epoch 253\n",
      "0.5053202137351036\n",
      "New best model found at epoch 253 with validation loss 0.49461254477500916\n",
      "Starting Epoch 254\n",
      "0.5046586530903975\n",
      "Starting Epoch 255\n",
      "0.5041988442341486\n",
      "Starting Epoch 256\n",
      "0.5047726680835088\n",
      "Starting Epoch 257\n",
      "0.5019300232330958\n",
      "Starting Epoch 258\n",
      "0.5027915798127651\n",
      "Starting Epoch 259\n",
      "0.4995320687691371\n",
      "Starting Epoch 260\n",
      "0.5028312231103579\n",
      "Starting Epoch 261\n",
      "0.5041739890972773\n",
      "Starting Epoch 262\n",
      "0.5017031307021776\n",
      "Starting Epoch 263\n",
      "0.5001893291870753\n",
      "Starting Epoch 264\n",
      "0.5004223634799322\n",
      "Starting Epoch 265\n",
      "0.5043852428595225\n",
      "Starting Epoch 266\n",
      "0.5019731633365154\n",
      "Starting Epoch 267\n",
      "0.5028648463388284\n",
      "New best model found at epoch 267 with validation loss 0.49424466490745544\n",
      "Starting Epoch 268\n",
      "0.5033946484327316\n",
      "Starting Epoch 269\n",
      "0.5036043040454388\n",
      "Starting Epoch 270\n",
      "0.5023288540542126\n",
      "Starting Epoch 271\n",
      "0.5035182697077593\n",
      "Starting Epoch 272\n",
      "0.5010656577845415\n",
      "Starting Epoch 273\n",
      "0.5018555844823519\n",
      "Starting Epoch 274\n",
      "0.4984507734576861\n",
      "Starting Epoch 275\n",
      "0.4989670279125373\n",
      "Starting Epoch 276\n",
      "0.4992115820447604\n",
      "Starting Epoch 277\n",
      "0.5003463750084242\n",
      "Starting Epoch 278\n",
      "0.49859100580215454\n",
      "Starting Epoch 279\n",
      "0.5021616990367571\n",
      "Starting Epoch 280\n",
      "0.5015962508817514\n",
      "Starting Epoch 281\n",
      "0.4991379790008068\n",
      "Starting Epoch 282\n",
      "0.5017610167463621\n",
      "Starting Epoch 283\n",
      "0.5008839045961698\n",
      "Starting Epoch 284\n",
      "0.4998967833817005\n",
      "Starting Epoch 285\n",
      "0.4969266578555107\n",
      "Starting Epoch 286\n",
      "0.5027974906067053\n",
      "New best model found at epoch 286 with validation loss 0.4939497709274292\n",
      "Starting Epoch 287\n",
      "0.4996146336197853\n",
      "Starting Epoch 288\n",
      "0.500570498406887\n",
      "Starting Epoch 289\n",
      "0.5033859511216482\n",
      "Starting Epoch 290\n",
      "0.5015734794239203\n",
      "Starting Epoch 291\n",
      "0.49949903910358745\n",
      "Starting Epoch 292\n",
      "0.5000233997901281\n",
      "Starting Epoch 293\n",
      "0.49814744542042416\n",
      "Starting Epoch 294\n",
      "0.4983862526714802\n",
      "Starting Epoch 295\n",
      "0.5011123803754648\n",
      "Starting Epoch 296\n",
      "0.49836891889572144\n",
      "Starting Epoch 297\n",
      "0.49759304026762646\n",
      "New best model found at epoch 297 with validation loss 0.49194321036338806\n",
      "Starting Epoch 298\n",
      "0.498485849549373\n",
      "Starting Epoch 299\n",
      "0.5006243512034416\n",
      "Starting Epoch 300\n",
      "0.5002725658317407\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-median: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa15ffb",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a0ec25ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2db33e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,7,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d69770b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'mean(container counts)', 'mean(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bff2a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "6a24bc12-1ab8-4496-beec-38d33887e78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.199772751579682\n",
      "New best model found at epoch 1 with validation loss 0.566110372543335\n",
      "Starting Epoch 2\n",
      "0.5769785344600677\n",
      "Starting Epoch 3\n",
      "0.5685585973163446\n",
      "Starting Epoch 4\n",
      "0.5809292284150919\n",
      "New best model found at epoch 4 with validation loss 0.5645879507064819\n",
      "Starting Epoch 5\n",
      "0.5661864057183266\n",
      "Starting Epoch 6\n",
      "0.5653999683757623\n",
      "Starting Epoch 7\n",
      "0.5593663069109122\n",
      "New best model found at epoch 7 with validation loss 0.5616074800491333\n",
      "Starting Epoch 8\n",
      "0.5691129180292288\n",
      "New best model found at epoch 8 with validation loss 0.5560428500175476\n",
      "Starting Epoch 9\n",
      "0.5555548978348573\n",
      "Starting Epoch 10\n",
      "0.5560624897480011\n",
      "Starting Epoch 11\n",
      "0.5598553357024988\n",
      "Starting Epoch 12\n",
      "0.5570993733902773\n",
      "Starting Epoch 13\n",
      "0.5557901039719582\n",
      "New best model found at epoch 13 with validation loss 0.5498108863830566\n",
      "Starting Epoch 14\n",
      "0.5512930750846863\n",
      "Starting Epoch 15\n",
      "0.5528227041165034\n",
      "Starting Epoch 16\n",
      "0.5488955701390902\n",
      "Starting Epoch 17\n",
      "0.5527802209059397\n",
      "New best model found at epoch 17 with validation loss 0.5441493391990662\n",
      "Starting Epoch 18\n",
      "0.5512701173623403\n",
      "Starting Epoch 19\n",
      "0.5495799121757349\n",
      "New best model found at epoch 19 with validation loss 0.5439329147338867\n",
      "Starting Epoch 20\n",
      "0.5488067368666331\n",
      "Starting Epoch 21\n",
      "0.5453106338779131\n",
      "Starting Epoch 22\n",
      "0.5494735203683376\n",
      "Starting Epoch 23\n",
      "0.5459069808324178\n",
      "New best model found at epoch 23 with validation loss 0.5437449812889099\n",
      "Starting Epoch 24\n",
      "0.5476306776205698\n",
      "New best model found at epoch 24 with validation loss 0.5424054265022278\n",
      "Starting Epoch 25\n",
      "0.5473443021376928\n",
      "Starting Epoch 26\n",
      "0.5476604315141836\n",
      "Starting Epoch 27\n",
      "0.5427041028936704\n",
      "New best model found at epoch 27 with validation loss 0.5376439690589905\n",
      "Starting Epoch 28\n",
      "0.5419065368672212\n",
      "New best model found at epoch 28 with validation loss 0.535743236541748\n",
      "Starting Epoch 29\n",
      "0.5455077911416689\n",
      "Starting Epoch 30\n",
      "0.5467938495179018\n",
      "Starting Epoch 31\n",
      "0.5461079515516758\n",
      "New best model found at epoch 31 with validation loss 0.5331757068634033\n",
      "Starting Epoch 32\n",
      "0.5388384374479452\n",
      "Starting Epoch 33\n",
      "0.550378450502952\n",
      "Starting Epoch 34\n",
      "0.5415344548722109\n",
      "Starting Epoch 35\n",
      "0.5437148027122021\n",
      "Starting Epoch 36\n",
      "0.5409092207749685\n",
      "Starting Epoch 37\n",
      "0.5421079148848852\n",
      "Starting Epoch 38\n",
      "0.5394564171632131\n",
      "Starting Epoch 39\n",
      "0.5419975618521372\n",
      "Starting Epoch 40\n",
      "0.5379641006390253\n",
      "Starting Epoch 41\n",
      "0.540617602566878\n",
      "Starting Epoch 42\n",
      "0.539530411362648\n",
      "Starting Epoch 43\n",
      "0.5447001395126184\n",
      "Starting Epoch 44\n",
      "0.5423322468996048\n",
      "Starting Epoch 45\n",
      "0.5363708920776844\n",
      "New best model found at epoch 45 with validation loss 0.5311025977134705\n",
      "Starting Epoch 46\n",
      "0.5358539869387945\n",
      "Starting Epoch 47\n",
      "0.5451919275025526\n",
      "Starting Epoch 48\n",
      "0.5335441753268242\n",
      "New best model found at epoch 48 with validation loss 0.5283913612365723\n",
      "Starting Epoch 49\n",
      "0.5393443591892719\n",
      "New best model found at epoch 49 with validation loss 0.5274103283882141\n",
      "Starting Epoch 50\n",
      "0.5401275431116422\n",
      "Starting Epoch 51\n",
      "0.5400231952468554\n",
      "Starting Epoch 52\n",
      "0.5384567181269327\n",
      "New best model found at epoch 52 with validation loss 0.5270835161209106\n",
      "Starting Epoch 53\n",
      "0.5411180357138315\n",
      "Starting Epoch 54\n",
      "0.5366907902061939\n",
      "Starting Epoch 55\n",
      "0.5353475362062454\n",
      "Starting Epoch 56\n",
      "0.5359204411506653\n",
      "Starting Epoch 57\n",
      "0.5359516193469366\n",
      "Starting Epoch 58\n",
      "0.5332968135674795\n",
      "Starting Epoch 59\n",
      "0.5370387869576613\n",
      "Starting Epoch 60\n",
      "0.5348549745976925\n",
      "New best model found at epoch 60 with validation loss 0.5257537364959717\n",
      "Starting Epoch 61\n",
      "0.5371242215236028\n",
      "Starting Epoch 62\n",
      "0.5354412955542406\n",
      "Starting Epoch 63\n",
      "0.5329148409267267\n",
      "Starting Epoch 64\n",
      "0.5308502639333407\n",
      "Starting Epoch 65\n",
      "0.535351786762476\n",
      "Starting Epoch 66\n",
      "0.5357572088638941\n",
      "New best model found at epoch 66 with validation loss 0.5218522548675537\n",
      "Starting Epoch 67\n",
      "0.5310957543551922\n",
      "Starting Epoch 68\n",
      "0.533653707553943\n",
      "New best model found at epoch 68 with validation loss 0.5200728178024292\n",
      "Starting Epoch 69\n",
      "0.5309952472647032\n",
      "Starting Epoch 70\n",
      "0.5304237380623817\n",
      "Starting Epoch 71\n",
      "0.5328607521951199\n",
      "Starting Epoch 72\n",
      "0.5344011895358562\n",
      "Starting Epoch 73\n",
      "0.5316454768180847\n",
      "Starting Epoch 74\n",
      "0.5313459895551205\n",
      "Starting Epoch 75\n",
      "0.5327210153142611\n",
      "Starting Epoch 76\n",
      "0.5315900209049383\n",
      "Starting Epoch 77\n",
      "0.5312060378491879\n",
      "Starting Epoch 78\n",
      "0.5300271945695082\n",
      "Starting Epoch 79\n",
      "0.5286341073612372\n",
      "Starting Epoch 80\n",
      "0.5312875074644884\n",
      "Starting Epoch 81\n",
      "0.5316242886086305\n",
      "Starting Epoch 82\n",
      "0.5259048218528429\n",
      "Starting Epoch 83\n",
      "0.5323829340438048\n",
      "Starting Epoch 84\n",
      "0.5290813930332661\n",
      "Starting Epoch 85\n",
      "0.5314809928337733\n",
      "Starting Epoch 86\n",
      "0.5328320662180582\n",
      "Starting Epoch 87\n",
      "0.5307250035305818\n",
      "Starting Epoch 88\n",
      "0.5322697088122368\n",
      "Starting Epoch 89\n",
      "0.5272468241552511\n",
      "Starting Epoch 90\n",
      "0.5313459808627764\n",
      "New best model found at epoch 90 with validation loss 0.5188295245170593\n",
      "Starting Epoch 91\n",
      "0.5262666555742422\n",
      "Starting Epoch 92\n",
      "0.5308941702047983\n",
      "Starting Epoch 93\n",
      "0.5284294784069061\n",
      "Starting Epoch 94\n",
      "0.5281802440683047\n",
      "New best model found at epoch 94 with validation loss 0.5182206034660339\n",
      "Starting Epoch 95\n",
      "0.5312051735818386\n",
      "Starting Epoch 96\n",
      "0.5383187805612882\n",
      "Starting Epoch 97\n",
      "0.5275874063372612\n",
      "Starting Epoch 98\n",
      "0.5271209788819154\n",
      "Starting Epoch 99\n",
      "0.5287687269349893\n",
      "Starting Epoch 100\n",
      "0.5260538272559643\n",
      "Starting Epoch 101\n",
      "0.5300910373528799\n",
      "New best model found at epoch 101 with validation loss 0.5181453824043274\n",
      "Starting Epoch 102\n",
      "0.5262103192508221\n",
      "Starting Epoch 103\n",
      "0.5266037906209627\n",
      "Starting Epoch 104\n",
      "0.5274336636066437\n",
      "Starting Epoch 105\n",
      "0.5282982674737772\n",
      "New best model found at epoch 105 with validation loss 0.5166912078857422\n",
      "Starting Epoch 106\n",
      "0.5269480099280676\n",
      "Starting Epoch 107\n",
      "0.5243843992551168\n",
      "Starting Epoch 108\n",
      "0.5243168659508228\n",
      "Starting Epoch 109\n",
      "0.5276529764135679\n",
      "Starting Epoch 110\n",
      "0.5245521242419878\n",
      "Starting Epoch 111\n",
      "0.5253088548779488\n",
      "Starting Epoch 112\n",
      "0.5253340601921082\n",
      "Starting Epoch 113\n",
      "0.5266380521158377\n",
      "New best model found at epoch 113 with validation loss 0.5117461681365967\n",
      "Starting Epoch 114\n",
      "0.5232612304389477\n",
      "Starting Epoch 115\n",
      "0.5224624201655388\n",
      "Starting Epoch 116\n",
      "0.5217536961038908\n",
      "Starting Epoch 117\n",
      "0.5246126092970371\n",
      "Starting Epoch 118\n",
      "0.5225235670804977\n",
      "Starting Epoch 119\n",
      "0.5260699788729349\n",
      "Starting Epoch 120\n",
      "0.5217493176460266\n",
      "Starting Epoch 121\n",
      "0.5234254313011965\n",
      "Starting Epoch 122\n",
      "0.5242238566279411\n",
      "Starting Epoch 123\n",
      "0.5181121453642845\n",
      "Starting Epoch 124\n",
      "0.524038765579462\n",
      "Starting Epoch 125\n",
      "0.5251432446142038\n",
      "Starting Epoch 126\n",
      "0.5217106752097607\n",
      "Starting Epoch 127\n",
      "0.5221671288212141\n",
      "Starting Epoch 128\n",
      "0.5214980232218901\n",
      "Starting Epoch 129\n",
      "0.5209074740608534\n",
      "Starting Epoch 130\n",
      "0.5254397702713808\n",
      "Starting Epoch 131\n",
      "0.5204634666442871\n",
      "Starting Epoch 132\n",
      "0.5223561686774095\n",
      "New best model found at epoch 132 with validation loss 0.50998854637146\n",
      "Starting Epoch 133\n",
      "0.5199064438541731\n",
      "Starting Epoch 134\n",
      "0.5217186324298382\n",
      "Starting Epoch 135\n",
      "0.5190016391376654\n",
      "Starting Epoch 136\n",
      "0.5199880873163542\n",
      "Starting Epoch 137\n",
      "0.5180380480984846\n",
      "Starting Epoch 138\n",
      "0.517635547866424\n",
      "Starting Epoch 139\n",
      "0.5188615371783575\n",
      "Starting Epoch 140\n",
      "0.5200567667682966\n",
      "New best model found at epoch 140 with validation loss 0.5099665522575378\n",
      "Starting Epoch 141\n",
      "0.5194980005423228\n",
      "Starting Epoch 142\n",
      "0.5169515535235405\n",
      "Starting Epoch 143\n",
      "0.5169843249022961\n",
      "Starting Epoch 144\n",
      "0.5181607380509377\n",
      "Starting Epoch 145\n",
      "0.5185460137824217\n",
      "Starting Epoch 146\n",
      "0.5161688265701135\n",
      "Starting Epoch 147\n",
      "0.5195775926113129\n",
      "Starting Epoch 148\n",
      "0.5177836045622826\n",
      "New best model found at epoch 148 with validation loss 0.5075593590736389\n",
      "Starting Epoch 149\n",
      "0.5178028593460718\n",
      "Starting Epoch 150\n",
      "0.5187004469335079\n",
      "Starting Epoch 151\n",
      "0.5191669923563799\n",
      "Starting Epoch 152\n",
      "0.5158025895555814\n",
      "Starting Epoch 153\n",
      "0.5183047167956829\n",
      "Starting Epoch 154\n",
      "0.5166610243419806\n",
      "Starting Epoch 155\n",
      "0.520821038633585\n",
      "Starting Epoch 156\n",
      "0.5157159902155399\n",
      "Starting Epoch 157\n",
      "0.5167606497804323\n",
      "Starting Epoch 158\n",
      "0.5169254504144192\n",
      "New best model found at epoch 158 with validation loss 0.5068645477294922\n",
      "Starting Epoch 159\n",
      "0.5151504129171371\n",
      "Starting Epoch 160\n",
      "0.5163734517991543\n",
      "Starting Epoch 161\n",
      "0.5189959419270357\n",
      "New best model found at epoch 161 with validation loss 0.5066995620727539\n",
      "Starting Epoch 162\n",
      "0.5174781791865826\n",
      "Starting Epoch 163\n",
      "0.5167720504105091\n",
      "New best model found at epoch 163 with validation loss 0.5059464573860168\n",
      "Starting Epoch 164\n",
      "0.5158890870710214\n",
      "Starting Epoch 165\n",
      "0.5152958184480667\n",
      "Starting Epoch 166\n",
      "0.5153464625279108\n",
      "Starting Epoch 167\n",
      "0.5131566748023033\n",
      "Starting Epoch 168\n",
      "0.5159192817906538\n",
      "Starting Epoch 169\n",
      "0.5149042420089245\n",
      "Starting Epoch 170\n",
      "0.517769955098629\n",
      "Starting Epoch 171\n",
      "0.5164978057146072\n",
      "Starting Epoch 172\n",
      "0.5138946684698263\n",
      "Starting Epoch 173\n",
      "0.5144757901628813\n",
      "Starting Epoch 174\n",
      "0.515122209986051\n",
      "Starting Epoch 175\n",
      "0.519508329530557\n",
      "Starting Epoch 176\n",
      "0.5183604496220747\n",
      "New best model found at epoch 176 with validation loss 0.5048837065696716\n",
      "Starting Epoch 177\n",
      "0.5154440899689993\n",
      "Starting Epoch 178\n",
      "0.5094890060524145\n",
      "Starting Epoch 179\n",
      "0.5171636107067267\n",
      "Starting Epoch 180\n",
      "0.5126183542112509\n",
      "Starting Epoch 181\n",
      "0.5128478196760019\n",
      "Starting Epoch 182\n",
      "0.5103121437132359\n",
      "New best model found at epoch 182 with validation loss 0.5038741827011108\n",
      "Starting Epoch 183\n",
      "0.5100119685133299\n",
      "Starting Epoch 184\n",
      "0.512827013929685\n",
      "Starting Epoch 185\n",
      "0.5133629205326239\n",
      "Starting Epoch 186\n",
      "0.5114557693401972\n",
      "New best model found at epoch 186 with validation loss 0.5037699341773987\n",
      "Starting Epoch 187\n",
      "0.5122249387204647\n",
      "Starting Epoch 188\n",
      "0.5082032072047392\n",
      "Starting Epoch 189\n",
      "0.5126195835570494\n",
      "Starting Epoch 190\n",
      "0.5140674971044064\n",
      "Starting Epoch 191\n",
      "0.5155331691106161\n",
      "Starting Epoch 192\n",
      "0.5084205952783426\n",
      "Starting Epoch 193\n",
      "0.5149614152808984\n",
      "New best model found at epoch 193 with validation loss 0.49985069036483765\n",
      "Starting Epoch 194\n",
      "0.5118097600837549\n",
      "Starting Epoch 195\n",
      "0.5131470349927744\n",
      "New best model found at epoch 195 with validation loss 0.4997207522392273\n",
      "Starting Epoch 196\n",
      "0.5099443619449934\n",
      "Starting Epoch 197\n",
      "0.5109272673726082\n",
      "Starting Epoch 198\n",
      "0.5117792002856731\n",
      "Starting Epoch 199\n",
      "0.5102276094257832\n",
      "Starting Epoch 200\n",
      "0.5094051485260328\n",
      "Starting Epoch 201\n",
      "0.5086859241127968\n",
      "New best model found at epoch 201 with validation loss 0.4968757927417755\n",
      "Starting Epoch 202\n",
      "0.5035997952024142\n",
      "Starting Epoch 203\n",
      "0.513491957137982\n",
      "Starting Epoch 204\n",
      "0.5090618145962557\n",
      "Starting Epoch 205\n",
      "0.5110627363125483\n",
      "New best model found at epoch 205 with validation loss 0.49395444989204407\n",
      "Starting Epoch 206\n",
      "0.505186232427756\n",
      "Starting Epoch 207\n",
      "0.5087472436328729\n",
      "New best model found at epoch 207 with validation loss 0.49369552731513977\n",
      "Starting Epoch 208\n",
      "0.5074906535446644\n",
      "Starting Epoch 209\n",
      "0.5077795473237833\n",
      "Starting Epoch 210\n",
      "0.5081305081645647\n",
      "Starting Epoch 211\n",
      "0.5095158716042837\n",
      "Starting Epoch 212\n",
      "0.5071173372368017\n",
      "Starting Epoch 213\n",
      "0.5062095361451308\n",
      "Starting Epoch 214\n",
      "0.5092775536080202\n",
      "Starting Epoch 215\n",
      "0.5091020154456297\n",
      "Starting Epoch 216\n",
      "0.5058059406777223\n",
      "Starting Epoch 217\n",
      "0.5076114038626353\n",
      "Starting Epoch 218\n",
      "0.5054914789895216\n",
      "Starting Epoch 219\n",
      "0.5062930981318156\n",
      "Starting Epoch 220\n",
      "0.5082241855561733\n",
      "Starting Epoch 221\n",
      "0.5065545837084452\n",
      "Starting Epoch 222\n",
      "0.5066382822891077\n",
      "Starting Epoch 223\n",
      "0.5030286262432734\n",
      "Starting Epoch 224\n",
      "0.5025245857735475\n",
      "Starting Epoch 225\n",
      "0.507280013213555\n",
      "Starting Epoch 226\n",
      "0.5040915372471014\n",
      "Starting Epoch 227\n",
      "0.5073044784367085\n",
      "New best model found at epoch 227 with validation loss 0.4912344217300415\n",
      "Starting Epoch 228\n",
      "0.506005613754193\n",
      "Starting Epoch 229\n",
      "0.5062987717489401\n",
      "Starting Epoch 230\n",
      "0.5025500990450382\n",
      "Starting Epoch 231\n",
      "0.5037477302054564\n",
      "Starting Epoch 232\n",
      "0.5050410578648249\n",
      "Starting Epoch 233\n",
      "0.5037554167211056\n",
      "Starting Epoch 234\n",
      "0.5056442307929198\n",
      "Starting Epoch 235\n",
      "0.5047448600331942\n",
      "Starting Epoch 236\n",
      "0.5025694482028484\n",
      "Starting Epoch 237\n",
      "0.5049068878094355\n",
      "Starting Epoch 238\n",
      "0.5017136211196581\n",
      "Starting Epoch 239\n",
      "0.506004891047875\n",
      "Starting Epoch 240\n",
      "0.5028633798162142\n",
      "Starting Epoch 241\n",
      "0.5065935055414835\n",
      "Starting Epoch 242\n",
      "0.49950243160128593\n",
      "Starting Epoch 243\n",
      "0.503050971776247\n",
      "Starting Epoch 244\n",
      "0.502688301106294\n",
      "Starting Epoch 245\n",
      "0.5050641447305679\n",
      "Starting Epoch 246\n",
      "0.5031231890122095\n",
      "Starting Epoch 247\n",
      "0.5028632717827956\n",
      "Starting Epoch 248\n",
      "0.5020864680409431\n",
      "Starting Epoch 249\n",
      "0.50563316543897\n",
      "Starting Epoch 250\n",
      "0.5029203233619531\n",
      "Starting Epoch 251\n",
      "0.5032577266295751\n",
      "Starting Epoch 252\n",
      "0.5041076218088468\n",
      "Starting Epoch 253\n",
      "0.5040746778249741\n",
      "Starting Epoch 254\n",
      "0.5041014564534029\n",
      "Starting Epoch 255\n",
      "0.5033483915030956\n",
      "Starting Epoch 256\n",
      "0.5029300811390082\n",
      "Starting Epoch 257\n",
      "0.5008362444738547\n",
      "Starting Epoch 258\n",
      "0.5015726114312807\n",
      "Starting Epoch 259\n",
      "0.496922105550766\n",
      "Starting Epoch 260\n",
      "0.500370517373085\n",
      "Starting Epoch 261\n",
      "0.5019188970327377\n",
      "Starting Epoch 262\n",
      "0.500801108777523\n",
      "Starting Epoch 263\n",
      "0.49979675685365993\n",
      "Starting Epoch 264\n",
      "0.49822530274589855\n",
      "Starting Epoch 265\n",
      "0.5021870943407217\n",
      "Starting Epoch 266\n",
      "0.5008058386544386\n",
      "Starting Epoch 267\n",
      "0.5005186547835668\n",
      "Starting Epoch 268\n",
      "0.5039889365434647\n",
      "Starting Epoch 269\n",
      "0.5012569688260555\n",
      "Starting Epoch 270\n",
      "0.5005211817721525\n",
      "Starting Epoch 271\n",
      "0.49960025524099666\n",
      "Starting Epoch 272\n",
      "0.49820779263973236\n",
      "Starting Epoch 273\n",
      "0.49885839099685353\n",
      "Starting Epoch 274\n",
      "0.49842001497745514\n",
      "Starting Epoch 275\n",
      "0.49858026454846066\n",
      "Starting Epoch 276\n",
      "0.49881210426489514\n",
      "Starting Epoch 277\n",
      "0.5001097768545151\n",
      "Starting Epoch 278\n",
      "0.49549245834350586\n",
      "Starting Epoch 279\n",
      "0.500290590027968\n",
      "Starting Epoch 280\n",
      "0.5018685447673003\n",
      "Starting Epoch 281\n",
      "0.49776389201482135\n",
      "Starting Epoch 282\n",
      "0.49969683090845746\n",
      "Starting Epoch 283\n",
      "0.4996398525933425\n",
      "Starting Epoch 284\n",
      "0.49834834163387615\n",
      "Starting Epoch 285\n",
      "0.4954800034562747\n",
      "Starting Epoch 286\n",
      "0.5014909220238527\n",
      "Starting Epoch 287\n",
      "0.49921609088778496\n",
      "Starting Epoch 288\n",
      "0.49835633983214694\n",
      "Starting Epoch 289\n",
      "0.5033879292507967\n",
      "Starting Epoch 290\n",
      "0.5014324660102526\n",
      "Starting Epoch 291\n",
      "0.49731628596782684\n",
      "Starting Epoch 292\n",
      "0.4991569295525551\n",
      "Starting Epoch 293\n",
      "0.49666986366113025\n",
      "Starting Epoch 294\n",
      "0.4964616497357686\n",
      "Starting Epoch 295\n",
      "0.498898687462012\n",
      "Starting Epoch 296\n",
      "0.49519070486227673\n",
      "Starting Epoch 297\n",
      "0.49589822068810463\n",
      "New best model found at epoch 297 with validation loss 0.4911401569843292\n",
      "Starting Epoch 298\n",
      "0.49685631940762204\n",
      "New best model found at epoch 298 with validation loss 0.48792096972465515\n",
      "Starting Epoch 299\n",
      "0.4998260798553626\n",
      "Starting Epoch 300\n",
      "0.499630868434906\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-mean: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31900fe2",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 3\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9bd76e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d88f28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,5,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "54f1900e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'min(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "6d4111d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6bcd284a-0e34-4b79-b394-9007eaad52a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.0683407858014107\n",
      "New best model found at epoch 1 with validation loss 0.5817959904670715\n",
      "Starting Epoch 2\n",
      "0.5847990649441878\n",
      "New best model found at epoch 2 with validation loss 0.5679823756217957\n",
      "Starting Epoch 3\n",
      "0.5725962668657303\n",
      "Starting Epoch 4\n",
      "0.5800903824468454\n",
      "New best model found at epoch 4 with validation loss 0.5670592784881592\n",
      "Starting Epoch 5\n",
      "0.5741396521528562\n",
      "Starting Epoch 6\n",
      "0.5718634749452273\n",
      "Starting Epoch 7\n",
      "0.5675254700084528\n",
      "Starting Epoch 8\n",
      "0.5745077195266882\n",
      "New best model found at epoch 8 with validation loss 0.5634781718254089\n",
      "Starting Epoch 9\n",
      "0.5645273365080357\n",
      "Starting Epoch 10\n",
      "0.5638110476235548\n",
      "Starting Epoch 11\n",
      "0.5644657090306282\n",
      "Starting Epoch 12\n",
      "0.5626631788909435\n",
      "Starting Epoch 13\n",
      "0.5632949136197567\n",
      "New best model found at epoch 13 with validation loss 0.5533090829849243\n",
      "Starting Epoch 14\n",
      "0.5575248822569847\n",
      "Starting Epoch 15\n",
      "0.5592766056458155\n",
      "Starting Epoch 16\n",
      "0.5545084973176321\n",
      "Starting Epoch 17\n",
      "0.5566127176086108\n",
      "Starting Epoch 18\n",
      "0.5561941564083099\n",
      "Starting Epoch 19\n",
      "0.5567646101117134\n",
      "Starting Epoch 20\n",
      "0.5530597406129042\n",
      "New best model found at epoch 20 with validation loss 0.5507575273513794\n",
      "Starting Epoch 21\n",
      "0.5513581360379854\n",
      "Starting Epoch 22\n",
      "0.5547983832657337\n",
      "Starting Epoch 23\n",
      "0.5539910482863585\n",
      "Starting Epoch 24\n",
      "0.5543903981645902\n",
      "New best model found at epoch 24 with validation loss 0.5484617948532104\n",
      "Starting Epoch 25\n",
      "0.5529160251220068\n",
      "Starting Epoch 26\n",
      "0.5536309853196144\n",
      "Starting Epoch 27\n",
      "0.5520617539683977\n",
      "New best model found at epoch 27 with validation loss 0.5439645051956177\n",
      "Starting Epoch 28\n",
      "0.549234806249539\n",
      "Starting Epoch 29\n",
      "0.5504509508609772\n",
      "Starting Epoch 30\n",
      "0.5511302563051382\n",
      "Starting Epoch 31\n",
      "0.5492383825282255\n",
      "New best model found at epoch 31 with validation loss 0.5425653457641602\n",
      "Starting Epoch 32\n",
      "0.5460445769131184\n",
      "Starting Epoch 33\n",
      "0.5534144900739193\n",
      "Starting Epoch 34\n",
      "0.5478668175637722\n",
      "Starting Epoch 35\n",
      "0.5478373331328233\n",
      "Starting Epoch 36\n",
      "0.5468426073590914\n",
      "Starting Epoch 37\n",
      "0.5473751810689768\n",
      "Starting Epoch 38\n",
      "0.5457282637556394\n",
      "Starting Epoch 39\n",
      "0.5495560852189859\n",
      "Starting Epoch 40\n",
      "0.545007993777593\n",
      "Starting Epoch 41\n",
      "0.5459595086673895\n",
      "Starting Epoch 42\n",
      "0.5479748534659544\n",
      "Starting Epoch 43\n",
      "0.5457446575164795\n",
      "Starting Epoch 44\n",
      "0.544782929122448\n",
      "Starting Epoch 45\n",
      "0.5408621989190578\n",
      "New best model found at epoch 45 with validation loss 0.5384955406188965\n",
      "Starting Epoch 46\n",
      "0.5389893588920435\n",
      "Starting Epoch 47\n",
      "0.5453512258827686\n",
      "Starting Epoch 48\n",
      "0.5360768387715021\n",
      "New best model found at epoch 48 with validation loss 0.5365801453590393\n",
      "Starting Epoch 49\n",
      "0.5427876276274523\n",
      "Starting Epoch 50\n",
      "0.5417886773745219\n",
      "New best model found at epoch 50 with validation loss 0.5347548127174377\n",
      "Starting Epoch 51\n",
      "0.5424893200397491\n",
      "Starting Epoch 52\n",
      "0.5406352480252584\n",
      "Starting Epoch 53\n",
      "0.5429437632362047\n",
      "New best model found at epoch 53 with validation loss 0.5345099568367004\n",
      "Starting Epoch 54\n",
      "0.5376226802666982\n",
      "Starting Epoch 55\n",
      "0.5374511803189913\n",
      "Starting Epoch 56\n",
      "0.5373313998182615\n",
      "Starting Epoch 57\n",
      "0.5378757789731026\n",
      "Starting Epoch 58\n",
      "0.5350810637076696\n",
      "Starting Epoch 59\n",
      "0.5411805734038353\n",
      "Starting Epoch 60\n",
      "0.5369336195290089\n",
      "New best model found at epoch 60 with validation loss 0.533227264881134\n",
      "Starting Epoch 61\n",
      "0.5379938868184885\n",
      "Starting Epoch 62\n",
      "0.5389710652331511\n",
      "Starting Epoch 63\n",
      "0.5349595819910368\n",
      "Starting Epoch 64\n",
      "0.5319362543523312\n",
      "Starting Epoch 65\n",
      "0.5358423727254072\n",
      "Starting Epoch 66\n",
      "0.5359707189102968\n",
      "New best model found at epoch 66 with validation loss 0.5283054113388062\n",
      "Starting Epoch 67\n",
      "0.5327975079417229\n",
      "Starting Epoch 68\n",
      "0.5364554189145565\n",
      "Starting Epoch 69\n",
      "0.5343400277197361\n",
      "Starting Epoch 70\n",
      "0.5322981178760529\n",
      "Starting Epoch 71\n",
      "0.5339066982269287\n",
      "Starting Epoch 72\n",
      "0.5335517711937428\n",
      "Starting Epoch 73\n",
      "0.5337811137239138\n",
      "Starting Epoch 74\n",
      "0.5320241500933965\n",
      "Starting Epoch 75\n",
      "0.5321257325510184\n",
      "Starting Epoch 76\n",
      "0.5336365140974522\n",
      "Starting Epoch 77\n",
      "0.5297757275402546\n",
      "Starting Epoch 78\n",
      "0.5295756421983242\n",
      "Starting Epoch 79\n",
      "0.5291442722082138\n",
      "New best model found at epoch 79 with validation loss 0.5260159373283386\n",
      "Starting Epoch 80\n",
      "0.5304125609497229\n",
      "Starting Epoch 81\n",
      "0.5318237841129303\n",
      "Starting Epoch 82\n",
      "0.527083141108354\n",
      "Starting Epoch 83\n",
      "0.5325493005414804\n",
      "Starting Epoch 84\n",
      "0.5289514598747095\n",
      "Starting Epoch 85\n",
      "0.5312861825029055\n",
      "Starting Epoch 86\n",
      "0.5324021590252718\n",
      "Starting Epoch 87\n",
      "0.532114410152038\n",
      "Starting Epoch 88\n",
      "0.5352945079406103\n",
      "New best model found at epoch 88 with validation loss 0.5250731706619263\n",
      "Starting Epoch 89\n",
      "0.5295437487463156\n",
      "Starting Epoch 90\n",
      "0.5324330714841684\n",
      "Starting Epoch 91\n",
      "0.5274138636887074\n",
      "Starting Epoch 92\n",
      "0.5317246913909912\n",
      "Starting Epoch 93\n",
      "0.5309465266764164\n",
      "Starting Epoch 94\n",
      "0.5304531194269657\n",
      "New best model found at epoch 94 with validation loss 0.524945855140686\n",
      "Starting Epoch 95\n",
      "0.5310797629257044\n",
      "Starting Epoch 96\n",
      "0.5322249184052149\n",
      "Starting Epoch 97\n",
      "0.5289091827968756\n",
      "Starting Epoch 98\n",
      "0.5288834149638811\n",
      "Starting Epoch 99\n",
      "0.531871477762858\n",
      "Starting Epoch 100\n",
      "0.5290589096645514\n",
      "Starting Epoch 101\n",
      "0.5319441395501295\n",
      "Starting Epoch 102\n",
      "0.5262273202339808\n",
      "Starting Epoch 103\n",
      "0.5281575073798498\n",
      "Starting Epoch 104\n",
      "0.5305288682381312\n",
      "Starting Epoch 105\n",
      "0.5295407027006149\n",
      "Starting Epoch 106\n",
      "0.531760673969984\n",
      "Starting Epoch 107\n",
      "0.528227345397075\n",
      "Starting Epoch 108\n",
      "0.5251799722512563\n",
      "Starting Epoch 109\n",
      "0.5272958539426327\n",
      "Starting Epoch 110\n",
      "0.5272180462876955\n",
      "Starting Epoch 111\n",
      "0.5274200203518072\n",
      "Starting Epoch 112\n",
      "0.5282466784119606\n",
      "Starting Epoch 113\n",
      "0.5282202623784542\n",
      "New best model found at epoch 113 with validation loss 0.5238888263702393\n",
      "Starting Epoch 114\n",
      "0.5267232730984688\n",
      "Starting Epoch 115\n",
      "0.526381827890873\n",
      "New best model found at epoch 115 with validation loss 0.5235027074813843\n",
      "Starting Epoch 116\n",
      "0.524273888518413\n",
      "Starting Epoch 117\n",
      "0.5264736823737621\n",
      "Starting Epoch 118\n",
      "0.5240111661454042\n",
      "Starting Epoch 119\n",
      "0.5312111005187035\n",
      "Starting Epoch 120\n",
      "0.5275596256057421\n",
      "New best model found at epoch 120 with validation loss 0.5223193168640137\n",
      "Starting Epoch 121\n",
      "0.5273377274473509\n",
      "Starting Epoch 122\n",
      "0.5288912976781527\n",
      "Starting Epoch 123\n",
      "0.5222794860601425\n",
      "Starting Epoch 124\n",
      "0.5268252578874429\n",
      "Starting Epoch 125\n",
      "0.5267847763995329\n",
      "Starting Epoch 126\n",
      "0.5247939079999924\n",
      "Starting Epoch 127\n",
      "0.5281767485042413\n",
      "Starting Epoch 128\n",
      "0.5283139956494173\n",
      "Starting Epoch 129\n",
      "0.5241341516375542\n",
      "Starting Epoch 130\n",
      "0.5290337552626928\n",
      "Starting Epoch 131\n",
      "0.5241799938182036\n",
      "Starting Epoch 132\n",
      "0.5253301486372948\n",
      "New best model found at epoch 132 with validation loss 0.5217874646186829\n",
      "Starting Epoch 133\n",
      "0.5233342808981737\n",
      "Starting Epoch 134\n",
      "0.5262616189817587\n",
      "Starting Epoch 135\n",
      "0.5236399993300438\n",
      "Starting Epoch 136\n",
      "0.5238427768150965\n",
      "Starting Epoch 137\n",
      "0.523808608452479\n",
      "Starting Epoch 138\n",
      "0.5223191430171331\n",
      "Starting Epoch 139\n",
      "0.5235278767844042\n",
      "Starting Epoch 140\n",
      "0.5237046008308729\n",
      "Starting Epoch 141\n",
      "0.5221681408584118\n",
      "Starting Epoch 142\n",
      "0.5227870394786199\n",
      "Starting Epoch 143\n",
      "0.5232589182754358\n",
      "Starting Epoch 144\n",
      "0.522101362546285\n",
      "Starting Epoch 145\n",
      "0.5221477647622427\n",
      "Starting Epoch 146\n",
      "0.5229440641899904\n",
      "Starting Epoch 147\n",
      "0.5227875287334124\n",
      "Starting Epoch 148\n",
      "0.5244729556143284\n",
      "Starting Epoch 149\n",
      "0.5219123798112074\n",
      "Starting Epoch 150\n",
      "0.5213915159304937\n",
      "Starting Epoch 151\n",
      "0.5237796107927958\n",
      "Starting Epoch 152\n",
      "0.5202432672182719\n",
      "Starting Epoch 153\n",
      "0.5248366904755434\n",
      "New best model found at epoch 153 with validation loss 0.5214320421218872\n",
      "Starting Epoch 154\n",
      "0.5205854984621207\n",
      "Starting Epoch 155\n",
      "0.5249577648937702\n",
      "Starting Epoch 156\n",
      "0.5193641409277916\n",
      "Starting Epoch 157\n",
      "0.5213756151497364\n",
      "Starting Epoch 158\n",
      "0.5215639087061087\n",
      "Starting Epoch 159\n",
      "0.5211987160146236\n",
      "Starting Epoch 160\n",
      "0.5194032117724419\n",
      "Starting Epoch 161\n",
      "0.5219603180885315\n",
      "Starting Epoch 162\n",
      "0.5244946541885535\n",
      "Starting Epoch 163\n",
      "0.5218451122442881\n",
      "New best model found at epoch 163 with validation loss 0.5212723016738892\n",
      "Starting Epoch 164\n",
      "0.5216015738745531\n",
      "Starting Epoch 165\n",
      "0.5218713755408922\n",
      "Starting Epoch 166\n",
      "0.5204250079890093\n",
      "Starting Epoch 167\n",
      "0.5202902543048064\n",
      "New best model found at epoch 167 with validation loss 0.5203465223312378\n",
      "Starting Epoch 168\n",
      "0.521205261349678\n",
      "Starting Epoch 169\n",
      "0.5215459143122038\n",
      "Starting Epoch 170\n",
      "0.5227374533812205\n",
      "Starting Epoch 171\n",
      "0.5210006348788738\n",
      "Starting Epoch 172\n",
      "0.521542859574159\n",
      "Starting Epoch 173\n",
      "0.5210021063685417\n",
      "Starting Epoch 174\n",
      "0.5219003943105539\n",
      "Starting Epoch 175\n",
      "0.5218478379150232\n",
      "Starting Epoch 176\n",
      "0.5242306180298328\n",
      "Starting Epoch 177\n",
      "0.5233208773036798\n",
      "Starting Epoch 178\n",
      "0.5157322982947031\n",
      "Starting Epoch 179\n",
      "0.5217924974858761\n",
      "Starting Epoch 180\n",
      "0.5184422942499319\n",
      "Starting Epoch 181\n",
      "0.5189241493741671\n",
      "Starting Epoch 182\n",
      "0.5183592351774374\n",
      "Starting Epoch 183\n",
      "0.5201394359270731\n",
      "Starting Epoch 184\n",
      "0.5193846685190996\n",
      "Starting Epoch 185\n",
      "0.5216805537541708\n",
      "Starting Epoch 186\n",
      "0.5189849349359671\n",
      "Starting Epoch 187\n",
      "0.5172319374978542\n",
      "Starting Epoch 188\n",
      "0.5154391924540201\n",
      "Starting Epoch 189\n",
      "0.5199590250849724\n",
      "Starting Epoch 190\n",
      "0.5230695816377798\n",
      "Starting Epoch 191\n",
      "0.520140336205562\n",
      "Starting Epoch 192\n",
      "0.5163989961147308\n",
      "Starting Epoch 193\n",
      "0.5213795204957327\n",
      "Starting Epoch 194\n",
      "0.5211933801571528\n",
      "Starting Epoch 195\n",
      "0.519805001715819\n",
      "Starting Epoch 196\n",
      "0.518548671156168\n",
      "Starting Epoch 197\n",
      "0.5186893592278162\n",
      "Starting Epoch 198\n",
      "0.5196215411027273\n",
      "Starting Epoch 199\n",
      "0.520601232846578\n",
      "Starting Epoch 200\n",
      "0.518030259758234\n",
      "Starting Epoch 201\n",
      "0.5183217401305834\n",
      "Starting Epoch 202\n",
      "0.5140640810132027\n",
      "Starting Epoch 203\n",
      "0.5188448081413904\n",
      "New best model found at epoch 203 with validation loss 0.5174023509025574\n",
      "Starting Epoch 204\n",
      "0.5176948023339113\n",
      "Starting Epoch 205\n",
      "0.519368477165699\n",
      "Starting Epoch 206\n",
      "0.5142451226711273\n",
      "Starting Epoch 207\n",
      "0.5162177781263987\n",
      "Starting Epoch 208\n",
      "0.5199613099296888\n",
      "Starting Epoch 209\n",
      "0.516390656431516\n",
      "Starting Epoch 210\n",
      "0.5179928988218307\n",
      "Starting Epoch 211\n",
      "0.5226449084778627\n",
      "Starting Epoch 212\n",
      "0.5144517061611017\n",
      "Starting Epoch 213\n",
      "0.5161767316361269\n",
      "Starting Epoch 214\n",
      "0.5184236901501814\n",
      "Starting Epoch 215\n",
      "0.5184957049787045\n",
      "Starting Epoch 216\n",
      "0.5163147536416849\n",
      "Starting Epoch 217\n",
      "0.5186020570496718\n",
      "Starting Epoch 218\n",
      "0.5167320594191551\n",
      "Starting Epoch 219\n",
      "0.5169516801834106\n",
      "Starting Epoch 220\n",
      "0.5171045747896036\n",
      "Starting Epoch 221\n",
      "0.515733706454436\n",
      "Starting Epoch 222\n",
      "0.5153198465704918\n",
      "Starting Epoch 223\n",
      "0.5145475876828035\n",
      "Starting Epoch 224\n",
      "0.5111403030653795\n",
      "Starting Epoch 225\n",
      "0.5149384575585524\n",
      "Starting Epoch 226\n",
      "0.514125802864631\n",
      "Starting Epoch 227\n",
      "0.5155296872059504\n",
      "Starting Epoch 228\n",
      "0.5142113268375397\n",
      "Starting Epoch 229\n",
      "0.5144882115224997\n",
      "New best model found at epoch 229 with validation loss 0.5152285099029541\n",
      "Starting Epoch 230\n",
      "0.5136139715711275\n",
      "Starting Epoch 231\n",
      "0.5130412057042122\n",
      "Starting Epoch 232\n",
      "0.5138611781100432\n",
      "Starting Epoch 233\n",
      "0.5141657056907812\n",
      "Starting Epoch 234\n",
      "0.5127826432387034\n",
      "Starting Epoch 235\n",
      "0.5129538948337237\n",
      "Starting Epoch 236\n",
      "0.5123721659183502\n",
      "Starting Epoch 237\n",
      "0.5125232674181461\n",
      "Starting Epoch 238\n",
      "0.5114580405255159\n",
      "Starting Epoch 239\n",
      "0.5136912378172079\n",
      "Starting Epoch 240\n",
      "0.5135431215167046\n",
      "New best model found at epoch 240 with validation loss 0.5112882256507874\n",
      "Starting Epoch 241\n",
      "0.5158683694899082\n",
      "Starting Epoch 242\n",
      "0.5093639232218266\n",
      "Starting Epoch 243\n",
      "0.5132871679961681\n",
      "Starting Epoch 244\n",
      "0.5134884503980478\n",
      "Starting Epoch 245\n",
      "0.5160155581931273\n",
      "Starting Epoch 246\n",
      "0.5123472039898237\n",
      "Starting Epoch 247\n",
      "0.5122667551040649\n",
      "Starting Epoch 248\n",
      "0.5118137995402018\n",
      "Starting Epoch 249\n",
      "0.5141633339226246\n",
      "Starting Epoch 250\n",
      "0.5157135166227818\n",
      "Starting Epoch 251\n",
      "0.5143654197454453\n",
      "Starting Epoch 252\n",
      "0.5133164251844088\n",
      "Starting Epoch 253\n",
      "0.5141450949013233\n",
      "Starting Epoch 254\n",
      "0.5144909160832564\n",
      "Starting Epoch 255\n",
      "0.5126985386013985\n",
      "Starting Epoch 256\n",
      "0.5104182126621405\n",
      "Starting Epoch 257\n",
      "0.5125225906570753\n",
      "Starting Epoch 258\n",
      "0.5110056983927885\n",
      "Starting Epoch 259\n",
      "0.509513029207786\n",
      "Starting Epoch 260\n",
      "0.5099310427904129\n",
      "Starting Epoch 261\n",
      "0.5134290034572283\n",
      "Starting Epoch 262\n",
      "0.5103319423894087\n",
      "Starting Epoch 263\n",
      "0.5124568454921246\n",
      "Starting Epoch 264\n",
      "0.5091226051251093\n",
      "Starting Epoch 265\n",
      "0.5134976481397947\n",
      "Starting Epoch 266\n",
      "0.5103103245298067\n",
      "Starting Epoch 267\n",
      "0.5135107139746348\n",
      "Starting Epoch 268\n",
      "0.5140184859434763\n",
      "Starting Epoch 269\n",
      "0.5135912311573824\n",
      "Starting Epoch 270\n",
      "0.5102371970812479\n",
      "Starting Epoch 271\n",
      "0.5092921989659468\n",
      "Starting Epoch 272\n",
      "0.509303999443849\n",
      "Starting Epoch 273\n",
      "0.5096874944865704\n",
      "Starting Epoch 274\n",
      "0.5075322315096855\n",
      "Starting Epoch 275\n",
      "0.5090674956639608\n",
      "Starting Epoch 276\n",
      "0.5076771241923174\n",
      "Starting Epoch 277\n",
      "0.5117758636673292\n",
      "Starting Epoch 278\n",
      "0.5050174382825693\n",
      "Starting Epoch 279\n",
      "0.5094723117848238\n",
      "Starting Epoch 280\n",
      "0.5116459565858046\n",
      "New best model found at epoch 280 with validation loss 0.509710967540741\n",
      "Starting Epoch 281\n",
      "0.5088108281294504\n",
      "Starting Epoch 282\n",
      "0.5105945083002249\n",
      "Starting Epoch 283\n",
      "0.5093767307698727\n",
      "Starting Epoch 284\n",
      "0.5081236151357492\n",
      "Starting Epoch 285\n",
      "0.5039160673816999\n",
      "Starting Epoch 286\n",
      "0.5110625786085924\n",
      "Starting Epoch 287\n",
      "0.509766069551309\n",
      "Starting Epoch 288\n",
      "0.5074728106458982\n",
      "Starting Epoch 289\n",
      "0.510308655599753\n",
      "Starting Epoch 290\n",
      "0.5087347452839216\n",
      "Starting Epoch 291\n",
      "0.5048654625813166\n",
      "Starting Epoch 292\n",
      "0.5070800756414732\n",
      "Starting Epoch 293\n",
      "0.5073734534283479\n",
      "Starting Epoch 294\n",
      "0.506698856751124\n",
      "Starting Epoch 295\n",
      "0.5073874381681284\n",
      "Starting Epoch 296\n",
      "0.50561565036575\n",
      "Starting Epoch 297\n",
      "0.507556593666474\n",
      "New best model found at epoch 297 with validation loss 0.5076883435249329\n",
      "Starting Epoch 298\n",
      "0.5067557469010353\n",
      "Starting Epoch 299\n",
      "0.5085106007754803\n",
      "Starting Epoch 300\n",
      "0.5105031679073969\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-min: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79fd46",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f68c8a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7ad7363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,6,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "30a50646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'max(container counts)', 'max(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "adc37e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2e807b58-d8cc-4794-abd8-bdadae092f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.9597549103200436\n",
      "New best model found at epoch 1 with validation loss 0.5679944157600403\n",
      "Starting Epoch 2\n",
      "0.5788349236051241\n",
      "New best model found at epoch 2 with validation loss 0.5584002137184143\n",
      "Starting Epoch 3\n",
      "0.5669113472104073\n",
      "Starting Epoch 4\n",
      "0.5689643211662769\n",
      "New best model found at epoch 4 with validation loss 0.5580035448074341\n",
      "Starting Epoch 5\n",
      "0.5661774538457394\n",
      "Starting Epoch 6\n",
      "0.562707339723905\n",
      "Starting Epoch 7\n",
      "0.5599695059160391\n",
      "New best model found at epoch 7 with validation loss 0.5503727197647095\n",
      "Starting Epoch 8\n",
      "0.565498032917579\n",
      "Starting Epoch 9\n",
      "0.5577017813920975\n",
      "Starting Epoch 10\n",
      "0.5574480270346006\n",
      "New best model found at epoch 10 with validation loss 0.548666775226593\n",
      "Starting Epoch 11\n",
      "0.5548442974686623\n",
      "New best model found at epoch 11 with validation loss 0.5447261333465576\n",
      "Starting Epoch 12\n",
      "0.5555318457384905\n",
      "Starting Epoch 13\n",
      "0.5527842404941717\n",
      "New best model found at epoch 13 with validation loss 0.541551947593689\n",
      "Starting Epoch 14\n",
      "0.5479947105050087\n",
      "Starting Epoch 15\n",
      "0.547244668006897\n",
      "Starting Epoch 16\n",
      "0.5439369405309359\n",
      "Starting Epoch 17\n",
      "0.544992179920276\n",
      "New best model found at epoch 17 with validation loss 0.5358710885047913\n",
      "Starting Epoch 18\n",
      "0.5432405831913153\n",
      "Starting Epoch 19\n",
      "0.5396043782432874\n",
      "New best model found at epoch 19 with validation loss 0.530663788318634\n",
      "Starting Epoch 20\n",
      "0.5386358462274075\n",
      "Starting Epoch 21\n",
      "0.5354736459751924\n",
      "Starting Epoch 22\n",
      "0.5363499832650026\n",
      "Starting Epoch 23\n",
      "0.5348741374909878\n",
      "Starting Epoch 24\n",
      "0.5373506819208463\n",
      "Starting Epoch 25\n",
      "0.5331066772341728\n",
      "Starting Epoch 26\n",
      "0.5334677087763945\n",
      "Starting Epoch 27\n",
      "0.5283817462623119\n",
      "New best model found at epoch 27 with validation loss 0.5243144631385803\n",
      "Starting Epoch 28\n",
      "0.5269182908038298\n",
      "Starting Epoch 29\n",
      "0.5280811823904514\n",
      "Starting Epoch 30\n",
      "0.5294200927019119\n",
      "Starting Epoch 31\n",
      "0.5275004046658675\n",
      "Starting Epoch 32\n",
      "0.5216615237295628\n",
      "New best model found at epoch 32 with validation loss 0.5212199687957764\n",
      "Starting Epoch 33\n",
      "0.5329604583481947\n",
      "Starting Epoch 34\n",
      "0.5230619510014852\n",
      "Starting Epoch 35\n",
      "0.5236944655577341\n",
      "Starting Epoch 36\n",
      "0.5238879186411699\n",
      "Starting Epoch 37\n",
      "0.5233741886913776\n",
      "Starting Epoch 38\n",
      "0.5174347721040249\n",
      "Starting Epoch 39\n",
      "0.5218101553618908\n",
      "Starting Epoch 40\n",
      "0.5160862157742182\n",
      "Starting Epoch 41\n",
      "0.5221322067081928\n",
      "Starting Epoch 42\n",
      "0.5198420012990633\n",
      "Starting Epoch 43\n",
      "0.5200890637934208\n",
      "Starting Epoch 44\n",
      "0.5253640127678713\n",
      "Starting Epoch 45\n",
      "0.5147593518098196\n",
      "Starting Epoch 46\n",
      "0.515255137036244\n",
      "New best model found at epoch 46 with validation loss 0.5122843384742737\n",
      "Starting Epoch 47\n",
      "0.5174327045679092\n",
      "Starting Epoch 48\n",
      "0.5114705065886179\n",
      "Starting Epoch 49\n",
      "0.5199299044907093\n",
      "Starting Epoch 50\n",
      "0.5147640456755956\n",
      "Starting Epoch 51\n",
      "0.5166806454459826\n",
      "Starting Epoch 52\n",
      "0.5144128613173962\n",
      "Starting Epoch 53\n",
      "0.5175869179268678\n",
      "Starting Epoch 54\n",
      "0.510598553965489\n",
      "New best model found at epoch 54 with validation loss 0.5122169256210327\n",
      "Starting Epoch 55\n",
      "0.5102632803221544\n",
      "Starting Epoch 56\n",
      "0.510789462675651\n",
      "New best model found at epoch 56 with validation loss 0.5099479556083679\n",
      "Starting Epoch 57\n",
      "0.5129822194576263\n",
      "New best model found at epoch 57 with validation loss 0.5095527172088623\n",
      "Starting Epoch 58\n",
      "0.5082511939108372\n",
      "New best model found at epoch 58 with validation loss 0.5083962678909302\n",
      "Starting Epoch 59\n",
      "0.5087681487202644\n",
      "Starting Epoch 60\n",
      "0.5101400638620058\n",
      "New best model found at epoch 60 with validation loss 0.5070294141769409\n",
      "Starting Epoch 61\n",
      "0.5129949934780598\n",
      "Starting Epoch 62\n",
      "0.5086652164657911\n",
      "New best model found at epoch 62 with validation loss 0.5029385685920715\n",
      "Starting Epoch 63\n",
      "0.5077286710341772\n",
      "Starting Epoch 64\n",
      "0.5044028634826342\n",
      "Starting Epoch 65\n",
      "0.5077891771992048\n",
      "Starting Epoch 66\n",
      "0.5112095971902212\n",
      "Starting Epoch 67\n",
      "0.5007585572699705\n",
      "Starting Epoch 68\n",
      "0.509066586693128\n",
      "Starting Epoch 69\n",
      "0.5032603020469347\n",
      "Starting Epoch 70\n",
      "0.5020435936748981\n",
      "New best model found at epoch 70 with validation loss 0.49969637393951416\n",
      "Starting Epoch 71\n",
      "0.5075959836443266\n",
      "Starting Epoch 72\n",
      "0.5067415808637937\n",
      "Starting Epoch 73\n",
      "0.5046906173229218\n",
      "Starting Epoch 74\n",
      "0.5057116287449995\n",
      "Starting Epoch 75\n",
      "0.5027498193085194\n",
      "Starting Epoch 76\n",
      "0.5038091515501341\n",
      "Starting Epoch 77\n",
      "0.5022146167854468\n",
      "Starting Epoch 78\n",
      "0.5022919575373331\n",
      "Starting Epoch 79\n",
      "0.5008768625557423\n",
      "New best model found at epoch 79 with validation loss 0.4975135922431946\n",
      "Starting Epoch 80\n",
      "0.501255389302969\n",
      "Starting Epoch 81\n",
      "0.5028057806193829\n",
      "Starting Epoch 82\n",
      "0.4954814873635769\n",
      "Starting Epoch 83\n",
      "0.5022098434468111\n",
      "Starting Epoch 84\n",
      "0.49894244968891144\n",
      "Starting Epoch 85\n",
      "0.5060456184049448\n",
      "Starting Epoch 86\n",
      "0.5042168162763119\n",
      "Starting Epoch 87\n",
      "0.5003739595413208\n",
      "Starting Epoch 88\n",
      "0.5045365951955318\n",
      "New best model found at epoch 88 with validation loss 0.4969598650932312\n",
      "Starting Epoch 89\n",
      "0.4992700492342313\n",
      "Starting Epoch 90\n",
      "0.5013455040752888\n",
      "Starting Epoch 91\n",
      "0.49910389880339306\n",
      "Starting Epoch 92\n",
      "0.5043423213064671\n",
      "Starting Epoch 93\n",
      "0.5037565355499586\n",
      "Starting Epoch 94\n",
      "0.5016033388674259\n",
      "New best model found at epoch 94 with validation loss 0.49026644229888916\n",
      "Starting Epoch 95\n",
      "0.49751107891400653\n",
      "Starting Epoch 96\n",
      "0.5027659398814043\n",
      "Starting Epoch 97\n",
      "0.5002095674475034\n",
      "Starting Epoch 98\n",
      "0.49703383073210716\n",
      "Starting Epoch 99\n",
      "0.4984992655615012\n",
      "Starting Epoch 100\n",
      "0.4982426290710767\n",
      "Starting Epoch 101\n",
      "0.5009941657384237\n",
      "Starting Epoch 102\n",
      "0.5001167406638464\n",
      "Starting Epoch 103\n",
      "0.4996190629899502\n",
      "Starting Epoch 104\n",
      "0.5010237569610277\n",
      "Starting Epoch 105\n",
      "0.4978424397607644\n",
      "Starting Epoch 106\n",
      "0.4984070509672165\n",
      "Starting Epoch 107\n",
      "0.4967902923623721\n",
      "Starting Epoch 108\n",
      "0.4968043466409047\n",
      "Starting Epoch 109\n",
      "0.5018744419018427\n",
      "Starting Epoch 110\n",
      "0.49697545046607655\n",
      "Starting Epoch 111\n",
      "0.4968869512279828\n",
      "Starting Epoch 112\n",
      "0.4978117843468984\n",
      "Starting Epoch 113\n",
      "0.49598164359728497\n",
      "Starting Epoch 114\n",
      "0.49447161083420116\n",
      "Starting Epoch 115\n",
      "0.4942883973320325\n",
      "Starting Epoch 116\n",
      "0.49414225791891414\n",
      "Starting Epoch 117\n",
      "0.49927528326710063\n",
      "Starting Epoch 118\n",
      "0.4944497098525365\n",
      "New best model found at epoch 118 with validation loss 0.4869575500488281\n",
      "Starting Epoch 119\n",
      "0.49746491263310116\n",
      "Starting Epoch 120\n",
      "0.4943251498043537\n",
      "Starting Epoch 121\n",
      "0.49657907833655673\n",
      "Starting Epoch 122\n",
      "0.49621818338831264\n",
      "Starting Epoch 123\n",
      "0.4910746403038502\n",
      "Starting Epoch 124\n",
      "0.4985016422967116\n",
      "Starting Epoch 125\n",
      "0.4984615271290143\n",
      "Starting Epoch 126\n",
      "0.4946492252250512\n",
      "Starting Epoch 127\n",
      "0.4971455360452334\n",
      "Starting Epoch 128\n",
      "0.49194489667812985\n",
      "Starting Epoch 129\n",
      "0.4949697479605675\n",
      "Starting Epoch 130\n",
      "0.4980543541411559\n",
      "Starting Epoch 131\n",
      "0.49364616846044856\n",
      "Starting Epoch 132\n",
      "0.4922282708187898\n",
      "New best model found at epoch 132 with validation loss 0.48657649755477905\n",
      "Starting Epoch 133\n",
      "0.4918737920622031\n",
      "Starting Epoch 134\n",
      "0.4953866936266422\n",
      "New best model found at epoch 134 with validation loss 0.4862542152404785\n",
      "Starting Epoch 135\n",
      "0.48943329850832623\n",
      "Starting Epoch 136\n",
      "0.4968743473291397\n",
      "Starting Epoch 137\n",
      "0.48973003029823303\n",
      "Starting Epoch 138\n",
      "0.49382294714450836\n",
      "Starting Epoch 139\n",
      "0.49179066345095634\n",
      "Starting Epoch 140\n",
      "0.49230169132351875\n",
      "New best model found at epoch 140 with validation loss 0.483627051115036\n",
      "Starting Epoch 141\n",
      "0.489437581350406\n",
      "Starting Epoch 142\n",
      "0.491201954583327\n",
      "Starting Epoch 143\n",
      "0.4893728631238143\n",
      "Starting Epoch 144\n",
      "0.49184199422597885\n",
      "Starting Epoch 145\n",
      "0.49147230635086697\n",
      "Starting Epoch 146\n",
      "0.49325353279709816\n",
      "Starting Epoch 147\n",
      "0.4916572955747445\n",
      "Starting Epoch 148\n",
      "0.49040090292692184\n",
      "New best model found at epoch 148 with validation loss 0.48275288939476013\n",
      "Starting Epoch 149\n",
      "0.4934023916721344\n",
      "Starting Epoch 150\n",
      "0.49043180669347447\n",
      "Starting Epoch 151\n",
      "0.49174925436576206\n",
      "Starting Epoch 152\n",
      "0.48972103620568913\n",
      "Starting Epoch 153\n",
      "0.49028342838088673\n",
      "Starting Epoch 154\n",
      "0.4910535005231698\n",
      "Starting Epoch 155\n",
      "0.49290595576167107\n",
      "Starting Epoch 156\n",
      "0.489235270768404\n",
      "Starting Epoch 157\n",
      "0.4915159270167351\n",
      "Starting Epoch 158\n",
      "0.48941727727651596\n",
      "Starting Epoch 159\n",
      "0.48916640505194664\n",
      "Starting Epoch 160\n",
      "0.4910674877464771\n",
      "Starting Epoch 161\n",
      "0.4904288090765476\n",
      "Starting Epoch 162\n",
      "0.48981564740339917\n",
      "Starting Epoch 163\n",
      "0.49025921523571014\n",
      "New best model found at epoch 163 with validation loss 0.4804743230342865\n",
      "Starting Epoch 164\n",
      "0.48875146235028905\n",
      "Starting Epoch 165\n",
      "0.4909217270712058\n",
      "Starting Epoch 166\n",
      "0.4893853838245074\n",
      "Starting Epoch 167\n",
      "0.4880638010799885\n",
      "Starting Epoch 168\n",
      "0.49074822664260864\n",
      "Starting Epoch 169\n",
      "0.4898485156397025\n",
      "Starting Epoch 170\n",
      "0.48991241057713825\n",
      "Starting Epoch 171\n",
      "0.49120765924453735\n",
      "Starting Epoch 172\n",
      "0.4882289618253708\n",
      "Starting Epoch 173\n",
      "0.4881599148114522\n",
      "Starting Epoch 174\n",
      "0.4910480740169684\n",
      "Starting Epoch 175\n",
      "0.48811470220486325\n",
      "Starting Epoch 176\n",
      "0.4950125093261401\n",
      "Starting Epoch 177\n",
      "0.49011295661330223\n",
      "Starting Epoch 178\n",
      "0.48523575564225513\n",
      "Starting Epoch 179\n",
      "0.4937126897275448\n",
      "Starting Epoch 180\n",
      "0.4880230861405532\n",
      "Starting Epoch 181\n",
      "0.48898936187227565\n",
      "Starting Epoch 182\n",
      "0.48618680362900096\n",
      "Starting Epoch 183\n",
      "0.48573872074484825\n",
      "Starting Epoch 184\n",
      "0.48805762206514675\n",
      "Starting Epoch 185\n",
      "0.488264790425698\n",
      "Starting Epoch 186\n",
      "0.48582188909252483\n",
      "Starting Epoch 187\n",
      "0.48880867784221965\n",
      "Starting Epoch 188\n",
      "0.48372451091806096\n",
      "Starting Epoch 189\n",
      "0.4886416805287202\n",
      "Starting Epoch 190\n",
      "0.48962927733858425\n",
      "Starting Epoch 191\n",
      "0.4904738689462344\n",
      "Starting Epoch 192\n",
      "0.4849789800743262\n",
      "Starting Epoch 193\n",
      "0.48966854562362033\n",
      "Starting Epoch 194\n",
      "0.4881777788201968\n",
      "New best model found at epoch 194 with validation loss 0.4801667630672455\n",
      "Starting Epoch 195\n",
      "0.48767167950669926\n",
      "Starting Epoch 196\n",
      "0.48499181494116783\n",
      "Starting Epoch 197\n",
      "0.4894707053899765\n",
      "Starting Epoch 198\n",
      "0.4881040578087171\n",
      "Starting Epoch 199\n",
      "0.48935147002339363\n",
      "Starting Epoch 200\n",
      "0.48479950552185375\n",
      "Starting Epoch 201\n",
      "0.4863068337241809\n",
      "New best model found at epoch 201 with validation loss 0.4783029854297638\n",
      "Starting Epoch 202\n",
      "0.48151205480098724\n",
      "Starting Epoch 203\n",
      "0.489180039614439\n",
      "Starting Epoch 204\n",
      "0.488393634557724\n",
      "Starting Epoch 205\n",
      "0.48689306775728863\n",
      "Starting Epoch 206\n",
      "0.4819994531571865\n",
      "Starting Epoch 207\n",
      "0.4842963442206383\n",
      "Starting Epoch 208\n",
      "0.4870072230696678\n",
      "Starting Epoch 209\n",
      "0.484880896906058\n",
      "Starting Epoch 210\n",
      "0.48527105276783306\n",
      "New best model found at epoch 210 with validation loss 0.47817426919937134\n",
      "Starting Epoch 211\n",
      "0.4865911826491356\n",
      "Starting Epoch 212\n",
      "0.4839965005715688\n",
      "Starting Epoch 213\n",
      "0.4832936090727647\n",
      "Starting Epoch 214\n",
      "0.48505381246407825\n",
      "New best model found at epoch 214 with validation loss 0.4771229028701782\n",
      "Starting Epoch 215\n",
      "0.488891822596391\n",
      "Starting Epoch 216\n",
      "0.4832502380013466\n",
      "Starting Epoch 217\n",
      "0.4865313470363617\n",
      "Starting Epoch 218\n",
      "0.4818514212965965\n",
      "Starting Epoch 219\n",
      "0.48540155217051506\n",
      "Starting Epoch 220\n",
      "0.4873207559188207\n",
      "Starting Epoch 221\n",
      "0.48205312217275303\n",
      "Starting Epoch 222\n",
      "0.48597634707887966\n",
      "Starting Epoch 223\n",
      "0.4842838707069556\n",
      "Starting Epoch 224\n",
      "0.4799840984245141\n",
      "Starting Epoch 225\n",
      "0.4882093022267024\n",
      "Starting Epoch 226\n",
      "0.48317322010795277\n",
      "Starting Epoch 227\n",
      "0.4841871013243993\n",
      "Starting Epoch 228\n",
      "0.4799920742710431\n",
      "Starting Epoch 229\n",
      "0.4867457039654255\n",
      "Starting Epoch 230\n",
      "0.48148422688245773\n",
      "Starting Epoch 231\n",
      "0.4786109613875548\n",
      "Starting Epoch 232\n",
      "0.4824024861057599\n",
      "Starting Epoch 233\n",
      "0.4826889323691527\n",
      "Starting Epoch 234\n",
      "0.4816421332458655\n",
      "Starting Epoch 235\n",
      "0.4812794029712677\n",
      "Starting Epoch 236\n",
      "0.48207614446679753\n",
      "Starting Epoch 237\n",
      "0.48084085807204247\n",
      "Starting Epoch 238\n",
      "0.48057566086451214\n",
      "New best model found at epoch 238 with validation loss 0.4766937792301178\n",
      "Starting Epoch 239\n",
      "0.48189838975667953\n",
      "Starting Epoch 240\n",
      "0.4814025821785132\n",
      "Starting Epoch 241\n",
      "0.4840435174604257\n",
      "Starting Epoch 242\n",
      "0.477415107190609\n",
      "Starting Epoch 243\n",
      "0.4795631406207879\n",
      "Starting Epoch 244\n",
      "0.4826589897274971\n",
      "New best model found at epoch 244 with validation loss 0.47314566373825073\n",
      "Starting Epoch 245\n",
      "0.48329226424296695\n",
      "New best model found at epoch 245 with validation loss 0.47249865531921387\n",
      "Starting Epoch 246\n",
      "0.47842205688357353\n",
      "Starting Epoch 247\n",
      "0.4812085380156835\n",
      "Starting Epoch 248\n",
      "0.4824480985601743\n",
      "Starting Epoch 249\n",
      "0.48568915327390033\n",
      "Starting Epoch 250\n",
      "0.4814208423097928\n",
      "Starting Epoch 251\n",
      "0.4833369428912799\n",
      "Starting Epoch 252\n",
      "0.4813949962457021\n",
      "Starting Epoch 253\n",
      "0.4801209072271983\n",
      "Starting Epoch 254\n",
      "0.48590929930408794\n",
      "Starting Epoch 255\n",
      "0.4800681173801422\n",
      "Starting Epoch 256\n",
      "0.48070400456587475\n",
      "Starting Epoch 257\n",
      "0.47986194988091785\n",
      "Starting Epoch 258\n",
      "0.47961699590086937\n",
      "Starting Epoch 259\n",
      "0.475637499243021\n",
      "Starting Epoch 260\n",
      "0.4779960761467616\n",
      "Starting Epoch 261\n",
      "0.4799564878145854\n",
      "Starting Epoch 262\n",
      "0.47657617181539536\n",
      "Starting Epoch 263\n",
      "0.4781177168091138\n",
      "Starting Epoch 264\n",
      "0.47937339792648953\n",
      "Starting Epoch 265\n",
      "0.48203720276554424\n",
      "Starting Epoch 266\n",
      "0.4776458802322547\n",
      "Starting Epoch 267\n",
      "0.47818053886294365\n",
      "Starting Epoch 268\n",
      "0.4810587515433629\n",
      "Starting Epoch 269\n",
      "0.48102464775244397\n",
      "Starting Epoch 270\n",
      "0.47823742777109146\n",
      "Starting Epoch 271\n",
      "0.4788789575298627\n",
      "Starting Epoch 272\n",
      "0.47618114203214645\n",
      "Starting Epoch 273\n",
      "0.4806819756825765\n",
      "Starting Epoch 274\n",
      "0.47528840228915215\n",
      "Starting Epoch 275\n",
      "0.47536859412988025\n",
      "Starting Epoch 276\n",
      "0.4759162900348504\n",
      "Starting Epoch 277\n",
      "0.47995760664343834\n",
      "Starting Epoch 278\n",
      "0.47380709399779636\n",
      "Starting Epoch 279\n",
      "0.4830661329130332\n",
      "Starting Epoch 280\n",
      "0.4858090914785862\n",
      "Starting Epoch 281\n",
      "0.47724682092666626\n",
      "Starting Epoch 282\n",
      "0.4766804339985053\n",
      "Starting Epoch 283\n",
      "0.47892430797219276\n",
      "Starting Epoch 284\n",
      "0.47773009166121483\n",
      "Starting Epoch 285\n",
      "0.4760213668147723\n",
      "Starting Epoch 286\n",
      "0.47904805714885396\n",
      "Starting Epoch 287\n",
      "0.47848524029056233\n",
      "Starting Epoch 288\n",
      "0.47507058704892796\n",
      "Starting Epoch 289\n",
      "0.4805191345512867\n",
      "Starting Epoch 290\n",
      "0.47749030093352\n",
      "Starting Epoch 291\n",
      "0.4748336722453435\n",
      "Starting Epoch 292\n",
      "0.478450670838356\n",
      "Starting Epoch 293\n",
      "0.47610367586215335\n",
      "Starting Epoch 294\n",
      "0.47681528329849243\n",
      "Starting Epoch 295\n",
      "0.47695547714829445\n",
      "Starting Epoch 296\n",
      "0.4762354828417301\n",
      "Starting Epoch 297\n",
      "0.4808891328672568\n",
      "New best model found at epoch 297 with validation loss 0.4719575345516205\n",
      "Starting Epoch 298\n",
      "0.47615821411212284\n",
      "Starting Epoch 299\n",
      "0.47915226469437283\n",
      "Starting Epoch 300\n",
      "0.4789572445054849\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-max: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da889a35",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.25-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9130c42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3f05c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,8,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f5668796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'q25(container counts)', 'q25(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "2193133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8f1c41a8-c8cd-48b1-b51b-71e9e3fdfe87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.0350202322006226\n",
      "New best model found at epoch 1 with validation loss 0.5915510654449463\n",
      "Starting Epoch 2\n",
      "0.5927498526871204\n",
      "New best model found at epoch 2 with validation loss 0.5785017609596252\n",
      "Starting Epoch 3\n",
      "0.5790461810926596\n",
      "New best model found at epoch 3 with validation loss 0.567690372467041\n",
      "Starting Epoch 4\n",
      "0.5820698079963526\n",
      "New best model found at epoch 4 with validation loss 0.5670992136001587\n",
      "Starting Epoch 5\n",
      "0.5759094568590323\n",
      "Starting Epoch 6\n",
      "0.5713519155979156\n",
      "New best model found at epoch 6 with validation loss 0.5636286735534668\n",
      "Starting Epoch 7\n",
      "0.5671512335538864\n",
      "Starting Epoch 8\n",
      "0.574251209696134\n",
      "New best model found at epoch 8 with validation loss 0.5600624680519104\n",
      "Starting Epoch 9\n",
      "0.5649247616529465\n",
      "Starting Epoch 10\n",
      "0.564932061980168\n",
      "Starting Epoch 11\n",
      "0.5681399976213773\n",
      "Starting Epoch 12\n",
      "0.5659620575606823\n",
      "Starting Epoch 13\n",
      "0.5659208198388418\n",
      "New best model found at epoch 13 with validation loss 0.5576311349868774\n",
      "Starting Epoch 14\n",
      "0.5630253752072653\n",
      "Starting Epoch 15\n",
      "0.5630087070167065\n",
      "Starting Epoch 16\n",
      "0.5605856813490391\n",
      "New best model found at epoch 16 with validation loss 0.5537779331207275\n",
      "Starting Epoch 17\n",
      "0.5602943561971188\n",
      "New best model found at epoch 17 with validation loss 0.5506553649902344\n",
      "Starting Epoch 18\n",
      "0.5627512981494268\n",
      "Starting Epoch 19\n",
      "0.5594553165137768\n",
      "Starting Epoch 20\n",
      "0.5596105096240839\n",
      "Starting Epoch 21\n",
      "0.5580813263853391\n",
      "New best model found at epoch 21 with validation loss 0.55057293176651\n",
      "Starting Epoch 22\n",
      "0.5605439978341261\n",
      "Starting Epoch 23\n",
      "0.5584203886489073\n",
      "New best model found at epoch 23 with validation loss 0.5501739382743835\n",
      "Starting Epoch 24\n",
      "0.5596595443785191\n",
      "New best model found at epoch 24 with validation loss 0.548547089099884\n",
      "Starting Epoch 25\n",
      "0.5567075721919537\n",
      "Starting Epoch 26\n",
      "0.559650108218193\n",
      "Starting Epoch 27\n",
      "0.556402621169885\n",
      "Starting Epoch 28\n",
      "0.5548207138975462\n",
      "Starting Epoch 29\n",
      "0.5574238747358322\n",
      "Starting Epoch 30\n",
      "0.5585693096121153\n",
      "Starting Epoch 31\n",
      "0.5566255375742912\n",
      "New best model found at epoch 31 with validation loss 0.5451722741127014\n",
      "Starting Epoch 32\n",
      "0.5528637655079365\n",
      "Starting Epoch 33\n",
      "0.5603180825710297\n",
      "Starting Epoch 34\n",
      "0.5541487398246924\n",
      "Starting Epoch 35\n",
      "0.5553063104550043\n",
      "Starting Epoch 36\n",
      "0.5533602684736252\n",
      "New best model found at epoch 36 with validation loss 0.5438337922096252\n",
      "Starting Epoch 37\n",
      "0.5550196121136347\n",
      "Starting Epoch 38\n",
      "0.549670102695624\n",
      "Starting Epoch 39\n",
      "0.5542325067023436\n",
      "Starting Epoch 40\n",
      "0.5491218529641628\n",
      "Starting Epoch 41\n",
      "0.5520737146337827\n",
      "Starting Epoch 42\n",
      "0.5527663591007391\n",
      "Starting Epoch 43\n",
      "0.5543388550480207\n",
      "Starting Epoch 44\n",
      "0.5540980945030848\n",
      "Starting Epoch 45\n",
      "0.5476313754916191\n",
      "Starting Epoch 46\n",
      "0.5482290014624596\n",
      "Starting Epoch 47\n",
      "0.5536165535449982\n",
      "Starting Epoch 48\n",
      "0.5460897994538149\n",
      "New best model found at epoch 48 with validation loss 0.5409436821937561\n",
      "Starting Epoch 49\n",
      "0.5512708984315395\n",
      "Starting Epoch 50\n",
      "0.5509501484533151\n",
      "Starting Epoch 51\n",
      "0.5517349864045779\n",
      "Starting Epoch 52\n",
      "0.5510031878948212\n",
      "New best model found at epoch 52 with validation loss 0.5382564663887024\n",
      "Starting Epoch 53\n",
      "0.5504964726666609\n",
      "New best model found at epoch 53 with validation loss 0.5363003611564636\n",
      "Starting Epoch 54\n",
      "0.5477960370481014\n",
      "Starting Epoch 55\n",
      "0.5477484712998072\n",
      "Starting Epoch 56\n",
      "0.548053236057361\n",
      "Starting Epoch 57\n",
      "0.5478392156461874\n",
      "Starting Epoch 58\n",
      "0.5442744642496109\n",
      "Starting Epoch 59\n",
      "0.5486214086413383\n",
      "Starting Epoch 60\n",
      "0.5454221330583096\n",
      "Starting Epoch 61\n",
      "0.5477347572644552\n",
      "Starting Epoch 62\n",
      "0.5474901174505552\n",
      "New best model found at epoch 62 with validation loss 0.5359119176864624\n",
      "Starting Epoch 63\n",
      "0.5444769437114397\n",
      "Starting Epoch 64\n",
      "0.5408751691381136\n",
      "Starting Epoch 65\n",
      "0.5467016448577245\n",
      "Starting Epoch 66\n",
      "0.5478674210608006\n",
      "New best model found at epoch 66 with validation loss 0.5337586402893066\n",
      "Starting Epoch 67\n",
      "0.5421368281046549\n",
      "Starting Epoch 68\n",
      "0.5455831475555897\n",
      "Starting Epoch 69\n",
      "0.5426689920326074\n",
      "Starting Epoch 70\n",
      "0.5421626903116703\n",
      "Starting Epoch 71\n",
      "0.5453069570163885\n",
      "Starting Epoch 72\n",
      "0.5446146788696448\n",
      "Starting Epoch 73\n",
      "0.5435439571738243\n",
      "Starting Epoch 74\n",
      "0.5416043189664682\n",
      "New best model found at epoch 74 with validation loss 0.5329852104187012\n",
      "Starting Epoch 75\n",
      "0.5432353268067042\n",
      "Starting Epoch 76\n",
      "0.5418764837086201\n",
      "Starting Epoch 77\n",
      "0.5422179015974203\n",
      "Starting Epoch 78\n",
      "0.5410184835394224\n",
      "Starting Epoch 79\n",
      "0.5398572670916716\n",
      "Starting Epoch 80\n",
      "0.5424228794872761\n",
      "Starting Epoch 81\n",
      "0.5433554500341415\n",
      "Starting Epoch 82\n",
      "0.5382797432442507\n",
      "Starting Epoch 83\n",
      "0.5432292545835177\n",
      "Starting Epoch 84\n",
      "0.5411651507019997\n",
      "Starting Epoch 85\n",
      "0.5430194598933061\n",
      "Starting Epoch 86\n",
      "0.545001033693552\n",
      "Starting Epoch 87\n",
      "0.542158362766107\n",
      "New best model found at epoch 87 with validation loss 0.52994704246521\n",
      "Starting Epoch 88\n",
      "0.5440149952967962\n",
      "Starting Epoch 89\n",
      "0.5395770482718945\n",
      "Starting Epoch 90\n",
      "0.5420625247061253\n",
      "Starting Epoch 91\n",
      "0.5378046482801437\n",
      "New best model found at epoch 91 with validation loss 0.5297124981880188\n",
      "Starting Epoch 92\n",
      "0.5424560916920503\n",
      "Starting Epoch 93\n",
      "0.5406309142708778\n",
      "Starting Epoch 94\n",
      "0.5415883635481199\n",
      "New best model found at epoch 94 with validation loss 0.5272353887557983\n",
      "Starting Epoch 95\n",
      "0.540922279159228\n",
      "Starting Epoch 96\n",
      "0.5418050512671471\n",
      "Starting Epoch 97\n",
      "0.5389167579511801\n",
      "Starting Epoch 98\n",
      "0.5408782462279002\n",
      "Starting Epoch 99\n",
      "0.5409137134750684\n",
      "Starting Epoch 100\n",
      "0.5394779480993748\n",
      "Starting Epoch 101\n",
      "0.5428930843869845\n",
      "Starting Epoch 102\n",
      "0.5392282952864965\n",
      "Starting Epoch 103\n",
      "0.538658894598484\n",
      "Starting Epoch 104\n",
      "0.5399529250959555\n",
      "Starting Epoch 105\n",
      "0.5412014797329903\n",
      "Starting Epoch 106\n",
      "0.5406214073300362\n",
      "Starting Epoch 107\n",
      "0.5385187591115633\n",
      "Starting Epoch 108\n",
      "0.5373494935532411\n",
      "Starting Epoch 109\n",
      "0.5394537846247355\n",
      "Starting Epoch 110\n",
      "0.5391113435228666\n",
      "Starting Epoch 111\n",
      "0.5388460295895735\n",
      "Starting Epoch 112\n",
      "0.5375646923979124\n",
      "Starting Epoch 113\n",
      "0.5395888251562914\n",
      "New best model found at epoch 113 with validation loss 0.5242984294891357\n",
      "Starting Epoch 114\n",
      "0.5370841734111309\n",
      "Starting Epoch 115\n",
      "0.5361462359627088\n",
      "Starting Epoch 116\n",
      "0.5350779506067435\n",
      "Starting Epoch 117\n",
      "0.53813819338878\n",
      "Starting Epoch 118\n",
      "0.5377118214964867\n",
      "New best model found at epoch 118 with validation loss 0.5237913131713867\n",
      "Starting Epoch 119\n",
      "0.538424820949634\n",
      "Starting Epoch 120\n",
      "0.5359053773184618\n",
      "Starting Epoch 121\n",
      "0.5369188189506531\n",
      "Starting Epoch 122\n",
      "0.5384328116973242\n",
      "Starting Epoch 123\n",
      "0.5327843974033991\n",
      "Starting Epoch 124\n",
      "0.5372863883773485\n",
      "Starting Epoch 125\n",
      "0.5384360228975614\n",
      "Starting Epoch 126\n",
      "0.536264218389988\n",
      "Starting Epoch 127\n",
      "0.5357646507521471\n",
      "Starting Epoch 128\n",
      "0.5350648971895376\n",
      "Starting Epoch 129\n",
      "0.5367006448407968\n",
      "Starting Epoch 130\n",
      "0.5382592429717382\n",
      "Starting Epoch 131\n",
      "0.5346191450953484\n",
      "New best model found at epoch 131 with validation loss 0.5204383134841919\n",
      "Starting Epoch 132\n",
      "0.5358269276718298\n",
      "Starting Epoch 133\n",
      "0.5339769770701727\n",
      "Starting Epoch 134\n",
      "0.5341301051278909\n",
      "Starting Epoch 135\n",
      "0.5337404807408651\n",
      "Starting Epoch 136\n",
      "0.5344166258970896\n",
      "Starting Epoch 137\n",
      "0.5328186464806398\n",
      "Starting Epoch 138\n",
      "0.5339065380394459\n",
      "Starting Epoch 139\n",
      "0.5334133716921011\n",
      "Starting Epoch 140\n",
      "0.5339745283126831\n",
      "Starting Epoch 141\n",
      "0.5327658727765083\n",
      "Starting Epoch 142\n",
      "0.5333923424283663\n",
      "Starting Epoch 143\n",
      "0.5308124162256718\n",
      "Starting Epoch 144\n",
      "0.5321988885601362\n",
      "Starting Epoch 145\n",
      "0.5332178970177969\n",
      "Starting Epoch 146\n",
      "0.5351378271977106\n",
      "Starting Epoch 147\n",
      "0.5332174984117349\n",
      "Starting Epoch 148\n",
      "0.5326058976352215\n",
      "Starting Epoch 149\n",
      "0.5329650901257992\n",
      "Starting Epoch 150\n",
      "0.5334643647074699\n",
      "Starting Epoch 151\n",
      "0.5334955640137196\n",
      "Starting Epoch 152\n",
      "0.5319472998380661\n",
      "Starting Epoch 153\n",
      "0.5328461366395155\n",
      "New best model found at epoch 153 with validation loss 0.5196976661682129\n",
      "Starting Epoch 154\n",
      "0.531894234319528\n",
      "Starting Epoch 155\n",
      "0.5340991988778114\n",
      "Starting Epoch 156\n",
      "0.5314246527850628\n",
      "Starting Epoch 157\n",
      "0.5325041761000952\n",
      "Starting Epoch 158\n",
      "0.5306552325685819\n",
      "Starting Epoch 159\n",
      "0.5304642257591089\n",
      "Starting Epoch 160\n",
      "0.532238973925511\n",
      "Starting Epoch 161\n",
      "0.5317154799898466\n",
      "Starting Epoch 162\n",
      "0.5329099285105864\n",
      "Starting Epoch 163\n",
      "0.5315266251564026\n",
      "Starting Epoch 164\n",
      "0.531927956889073\n",
      "Starting Epoch 165\n",
      "0.531614205489556\n",
      "Starting Epoch 166\n",
      "0.5322228719790777\n",
      "Starting Epoch 167\n",
      "0.530832560112079\n",
      "Starting Epoch 168\n",
      "0.5320460833609104\n",
      "Starting Epoch 169\n",
      "0.5312852139274279\n",
      "Starting Epoch 170\n",
      "0.5323444716632366\n",
      "New best model found at epoch 170 with validation loss 0.5181115865707397\n",
      "Starting Epoch 171\n",
      "0.530577347924312\n",
      "Starting Epoch 172\n",
      "0.5300679765641689\n",
      "Starting Epoch 173\n",
      "0.531143290301164\n",
      "Starting Epoch 174\n",
      "0.5313011296093464\n",
      "Starting Epoch 175\n",
      "0.5303184315562248\n",
      "Starting Epoch 176\n",
      "0.5340661741793156\n",
      "Starting Epoch 177\n",
      "0.5306205141047636\n",
      "Starting Epoch 178\n",
      "0.5261847600340843\n",
      "Starting Epoch 179\n",
      "0.5323839324216048\n",
      "Starting Epoch 180\n",
      "0.5305739355583986\n",
      "Starting Epoch 181\n",
      "0.5299194877346357\n",
      "Starting Epoch 182\n",
      "0.5296783509353796\n",
      "Starting Epoch 183\n",
      "0.5282642133533955\n",
      "Starting Epoch 184\n",
      "0.5309426685174307\n",
      "Starting Epoch 185\n",
      "0.5282082222402096\n",
      "Starting Epoch 186\n",
      "0.5295218887428442\n",
      "Starting Epoch 187\n",
      "0.5276491021116575\n",
      "Starting Epoch 188\n",
      "0.5278612996141115\n",
      "Starting Epoch 189\n",
      "0.5297609530389309\n",
      "Starting Epoch 190\n",
      "0.531561321268479\n",
      "Starting Epoch 191\n",
      "0.5316905553142229\n",
      "Starting Epoch 192\n",
      "0.5257745596269766\n",
      "Starting Epoch 193\n",
      "0.5307100663582484\n",
      "Starting Epoch 194\n",
      "0.5302280609806379\n",
      "Starting Epoch 195\n",
      "0.5304699006179968\n",
      "Starting Epoch 196\n",
      "0.5281089097261429\n",
      "Starting Epoch 197\n",
      "0.5291298143565655\n",
      "Starting Epoch 198\n",
      "0.5281782696644465\n",
      "Starting Epoch 199\n",
      "0.5290962134798368\n",
      "Starting Epoch 200\n",
      "0.5290256515145302\n",
      "Starting Epoch 201\n",
      "0.5292895821233591\n",
      "New best model found at epoch 201 with validation loss 0.5173330903053284\n",
      "Starting Epoch 202\n",
      "0.5261384807527065\n",
      "Starting Epoch 203\n",
      "0.5294878780841827\n",
      "Starting Epoch 204\n",
      "0.526926023264726\n",
      "Starting Epoch 205\n",
      "0.5274836036066214\n",
      "New best model found at epoch 205 with validation loss 0.5169122815132141\n",
      "Starting Epoch 206\n",
      "0.5245465921858946\n",
      "New best model found at epoch 206 with validation loss 0.5167382955551147\n",
      "Starting Epoch 207\n",
      "0.5273250838120779\n",
      "Starting Epoch 208\n",
      "0.5276762234667937\n",
      "New best model found at epoch 208 with validation loss 0.5158230066299438\n",
      "Starting Epoch 209\n",
      "0.5282726796964804\n",
      "Starting Epoch 210\n",
      "0.52922631179293\n",
      "Starting Epoch 211\n",
      "0.527828315893809\n",
      "Starting Epoch 212\n",
      "0.5260979433854421\n",
      "Starting Epoch 213\n",
      "0.5249257112542788\n",
      "Starting Epoch 214\n",
      "0.5276834691564242\n",
      "Starting Epoch 215\n",
      "0.5282845124602318\n",
      "Starting Epoch 216\n",
      "0.525335393846035\n",
      "Starting Epoch 217\n",
      "0.5278272951642672\n",
      "Starting Epoch 218\n",
      "0.5241479799151421\n",
      "Starting Epoch 219\n",
      "0.5266961505015691\n",
      "Starting Epoch 220\n",
      "0.526413694024086\n",
      "Starting Epoch 221\n",
      "0.525094248354435\n",
      "Starting Epoch 222\n",
      "0.5262905570367972\n",
      "Starting Epoch 223\n",
      "0.5238022270301977\n",
      "Starting Epoch 224\n",
      "0.5209076814353466\n",
      "Starting Epoch 225\n",
      "0.525661022712787\n",
      "Starting Epoch 226\n",
      "0.5266671627759933\n",
      "Starting Epoch 227\n",
      "0.5253912284970284\n",
      "New best model found at epoch 227 with validation loss 0.515402615070343\n",
      "Starting Epoch 228\n",
      "0.5253015620013078\n",
      "Starting Epoch 229\n",
      "0.5242153654495875\n",
      "Starting Epoch 230\n",
      "0.5226336680352688\n",
      "Starting Epoch 231\n",
      "0.5221664557854334\n",
      "Starting Epoch 232\n",
      "0.5236852852006754\n",
      "New best model found at epoch 232 with validation loss 0.513175904750824\n",
      "Starting Epoch 233\n",
      "0.5245456794897715\n",
      "Starting Epoch 234\n",
      "0.5233230864008268\n",
      "Starting Epoch 235\n",
      "0.5227128366629282\n",
      "Starting Epoch 236\n",
      "0.5227316704889139\n",
      "Starting Epoch 237\n",
      "0.5233148348828157\n",
      "Starting Epoch 238\n",
      "0.5210255918403467\n",
      "Starting Epoch 239\n",
      "0.5231432343522707\n",
      "Starting Epoch 240\n",
      "0.5223021134734154\n",
      "New best model found at epoch 240 with validation loss 0.5123177170753479\n",
      "Starting Epoch 241\n",
      "0.5257612727582455\n",
      "Starting Epoch 242\n",
      "0.5197097323834896\n",
      "New best model found at epoch 242 with validation loss 0.5122221112251282\n",
      "Starting Epoch 243\n",
      "0.5234798515836397\n",
      "Starting Epoch 244\n",
      "0.5212139040231705\n",
      "Starting Epoch 245\n",
      "0.5245297600825628\n",
      "Starting Epoch 246\n",
      "0.5216021053493023\n",
      "Starting Epoch 247\n",
      "0.5214926898479462\n",
      "Starting Epoch 248\n",
      "0.5193885316451391\n",
      "Starting Epoch 249\n",
      "0.5235027099649111\n",
      "Starting Epoch 250\n",
      "0.5214257054030895\n",
      "Starting Epoch 251\n",
      "0.5222614767650763\n",
      "Starting Epoch 252\n",
      "0.5218450551231703\n",
      "Starting Epoch 253\n",
      "0.5211450892190138\n",
      "Starting Epoch 254\n",
      "0.5225322234133879\n",
      "Starting Epoch 255\n",
      "0.5223107698063055\n",
      "New best model found at epoch 255 with validation loss 0.5101853013038635\n",
      "Starting Epoch 256\n",
      "0.5193363651633263\n",
      "Starting Epoch 257\n",
      "0.5189285936454932\n",
      "Starting Epoch 258\n",
      "0.5166957651575407\n",
      "Starting Epoch 259\n",
      "0.5163661489884058\n",
      "Starting Epoch 260\n",
      "0.5174823527534803\n",
      "Starting Epoch 261\n",
      "0.5201646300653616\n",
      "Starting Epoch 262\n",
      "0.5178447067737579\n",
      "Starting Epoch 263\n",
      "0.5175572993854681\n",
      "Starting Epoch 264\n",
      "0.5158382505178452\n",
      "Starting Epoch 265\n",
      "0.5194010597964128\n",
      "New best model found at epoch 265 with validation loss 0.5081959962844849\n",
      "Starting Epoch 266\n",
      "0.5153690713147322\n",
      "Starting Epoch 267\n",
      "0.5166766258577505\n",
      "New best model found at epoch 267 with validation loss 0.5068138241767883\n",
      "Starting Epoch 268\n",
      "0.5199958682060242\n",
      "Starting Epoch 269\n",
      "0.5174237030247847\n",
      "Starting Epoch 270\n",
      "0.516054417937994\n",
      "Starting Epoch 271\n",
      "0.5177000090479851\n",
      "Starting Epoch 272\n",
      "0.5138927499453226\n",
      "Starting Epoch 273\n",
      "0.5170622368653616\n",
      "Starting Epoch 274\n",
      "0.5143831496437391\n",
      "Starting Epoch 275\n",
      "0.5135132148861885\n",
      "Starting Epoch 276\n",
      "0.5134326480329037\n",
      "Starting Epoch 277\n",
      "0.5153393174211184\n",
      "Starting Epoch 278\n",
      "0.5130927811066309\n",
      "Starting Epoch 279\n",
      "0.5164835651715597\n",
      "Starting Epoch 280\n",
      "0.5168833620846272\n",
      "Starting Epoch 281\n",
      "0.5115743118027846\n",
      "Starting Epoch 282\n",
      "0.5162195141116778\n",
      "Starting Epoch 283\n",
      "0.5147789157927036\n",
      "Starting Epoch 284\n",
      "0.5149942065278689\n",
      "Starting Epoch 285\n",
      "0.5107297860085964\n",
      "Starting Epoch 286\n",
      "0.5126255949338278\n",
      "New best model found at epoch 286 with validation loss 0.5048719048500061\n",
      "Starting Epoch 287\n",
      "0.512589119374752\n",
      "Starting Epoch 288\n",
      "0.5126268590490023\n",
      "Starting Epoch 289\n",
      "0.515101108700037\n",
      "Starting Epoch 290\n",
      "0.514433242380619\n",
      "Starting Epoch 291\n",
      "0.5113800379137198\n",
      "Starting Epoch 292\n",
      "0.5141018877426783\n",
      "Starting Epoch 293\n",
      "0.5111529752612114\n",
      "New best model found at epoch 293 with validation loss 0.5038614869117737\n",
      "Starting Epoch 294\n",
      "0.5110526792705059\n",
      "Starting Epoch 295\n",
      "0.5129854045808315\n",
      "New best model found at epoch 295 with validation loss 0.5032559633255005\n",
      "Starting Epoch 296\n",
      "0.512323814133803\n",
      "Starting Epoch 297\n",
      "0.5114761081834635\n",
      "Starting Epoch 298\n",
      "0.5109847063819567\n",
      "Starting Epoch 299\n",
      "0.5115531124174595\n",
      "Starting Epoch 300\n",
      "0.5132022500038147\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-q25: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c4323",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 6\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.75-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "11d4370d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d0c62f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,10,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "38336583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'q75(container counts)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "9c115271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "84769b16-d905-4b1b-bd15-6ebdeaf6e2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.125189339121183\n",
      "New best model found at epoch 1 with validation loss 0.560612142086029\n",
      "Starting Epoch 2\n",
      "0.5699146824578444\n",
      "New best model found at epoch 2 with validation loss 0.5597674250602722\n",
      "Starting Epoch 3\n",
      "0.558877669274807\n",
      "Starting Epoch 4\n",
      "0.5690227399269739\n",
      "New best model found at epoch 4 with validation loss 0.5563669800758362\n",
      "Starting Epoch 5\n",
      "0.5599567505220572\n",
      "Starting Epoch 6\n",
      "0.5583255849778652\n",
      "Starting Epoch 7\n",
      "0.5533184955517451\n",
      "New best model found at epoch 7 with validation loss 0.5554958581924438\n",
      "Starting Epoch 8\n",
      "0.5623197642465433\n",
      "New best model found at epoch 8 with validation loss 0.5504093170166016\n",
      "Starting Epoch 9\n",
      "0.5504742152988911\n",
      "New best model found at epoch 9 with validation loss 0.5472540855407715\n",
      "Starting Epoch 10\n",
      "0.5517649004856745\n",
      "Starting Epoch 11\n",
      "0.5525078736245632\n",
      "New best model found at epoch 11 with validation loss 0.542212188243866\n",
      "Starting Epoch 12\n",
      "0.5488509262601534\n",
      "Starting Epoch 13\n",
      "0.5500875699023405\n",
      "Starting Epoch 14\n",
      "0.5472383834421635\n",
      "New best model found at epoch 14 with validation loss 0.5412839651107788\n",
      "Starting Epoch 15\n",
      "0.5462893831233183\n",
      "New best model found at epoch 15 with validation loss 0.5375570058822632\n",
      "Starting Epoch 16\n",
      "0.5458891056478024\n",
      "New best model found at epoch 16 with validation loss 0.5348438620567322\n",
      "Starting Epoch 17\n",
      "0.5461531082789103\n",
      "Starting Epoch 18\n",
      "0.5487209322551886\n",
      "Starting Epoch 19\n",
      "0.5449217048784097\n",
      "New best model found at epoch 19 with validation loss 0.5343927145004272\n",
      "Starting Epoch 20\n",
      "0.5439116035898527\n",
      "Starting Epoch 21\n",
      "0.5408019162714481\n",
      "New best model found at epoch 21 with validation loss 0.5302141308784485\n",
      "Starting Epoch 22\n",
      "0.5432896638909975\n",
      "Starting Epoch 23\n",
      "0.5431734522183737\n",
      "Starting Epoch 24\n",
      "0.5446471311151981\n",
      "Starting Epoch 25\n",
      "0.543011624366045\n",
      "Starting Epoch 26\n",
      "0.545018001149098\n",
      "Starting Epoch 27\n",
      "0.5414260774850845\n",
      "New best model found at epoch 27 with validation loss 0.524549126625061\n",
      "Starting Epoch 28\n",
      "0.5394948087632656\n",
      "Starting Epoch 29\n",
      "0.542802402128776\n",
      "Starting Epoch 30\n",
      "0.5425517571469148\n",
      "Starting Epoch 31\n",
      "0.5417725009222826\n",
      "Starting Epoch 32\n",
      "0.5369059592485428\n",
      "Starting Epoch 33\n",
      "0.5462752940754095\n",
      "Starting Epoch 34\n",
      "0.5400830060243607\n",
      "Starting Epoch 35\n",
      "0.5410431573788325\n",
      "Starting Epoch 36\n",
      "0.5384451175729433\n",
      "Starting Epoch 37\n",
      "0.5405797188480695\n",
      "Starting Epoch 38\n",
      "0.5363801419734955\n",
      "Starting Epoch 39\n",
      "0.5407341209550699\n",
      "Starting Epoch 40\n",
      "0.5356050878763199\n",
      "Starting Epoch 41\n",
      "0.5378587755064169\n",
      "Starting Epoch 42\n",
      "0.5371099884311358\n",
      "Starting Epoch 43\n",
      "0.5407916232943535\n",
      "Starting Epoch 44\n",
      "0.5403256602585316\n",
      "Starting Epoch 45\n",
      "0.534292737642924\n",
      "New best model found at epoch 45 with validation loss 0.5244610905647278\n",
      "Starting Epoch 46\n",
      "0.5343036241829395\n",
      "Starting Epoch 47\n",
      "0.5403656574587027\n",
      "Starting Epoch 48\n",
      "0.5315697950621446\n",
      "New best model found at epoch 48 with validation loss 0.5202265977859497\n",
      "Starting Epoch 49\n",
      "0.5394164236883322\n",
      "New best model found at epoch 49 with validation loss 0.5191347002983093\n",
      "Starting Epoch 50\n",
      "0.5375873272617658\n",
      "Starting Epoch 51\n",
      "0.5384210497140884\n",
      "Starting Epoch 52\n",
      "0.5383191096285979\n",
      "Starting Epoch 53\n",
      "0.5408492808540662\n",
      "Starting Epoch 54\n",
      "0.5353011041879654\n",
      "Starting Epoch 55\n",
      "0.5340805115799109\n",
      "Starting Epoch 56\n",
      "0.534829014291366\n",
      "Starting Epoch 57\n",
      "0.5362337330977122\n",
      "Starting Epoch 58\n",
      "0.531786635518074\n",
      "New best model found at epoch 58 with validation loss 0.518058717250824\n",
      "Starting Epoch 59\n",
      "0.5349905317028364\n",
      "Starting Epoch 60\n",
      "0.5320686399936676\n",
      "Starting Epoch 61\n",
      "0.5356118393441042\n",
      "Starting Epoch 62\n",
      "0.5354626998305321\n",
      "New best model found at epoch 62 with validation loss 0.5161925554275513\n",
      "Starting Epoch 63\n",
      "0.5328764282166958\n",
      "Starting Epoch 64\n",
      "0.5317509174346924\n",
      "Starting Epoch 65\n",
      "0.5322555713355541\n",
      "Starting Epoch 66\n",
      "0.5344257056713104\n",
      "New best model found at epoch 66 with validation loss 0.50968998670578\n",
      "Starting Epoch 67\n",
      "0.5293138151367506\n",
      "Starting Epoch 68\n",
      "0.5325350910425186\n",
      "Starting Epoch 69\n",
      "0.5300971294442812\n",
      "Starting Epoch 70\n",
      "0.530973686526219\n",
      "Starting Epoch 71\n",
      "0.5314502231776714\n",
      "Starting Epoch 72\n",
      "0.5318176274498304\n",
      "Starting Epoch 73\n",
      "0.5309931176404158\n",
      "Starting Epoch 74\n",
      "0.5309884026646614\n",
      "Starting Epoch 75\n",
      "0.5321168278654417\n",
      "Starting Epoch 76\n",
      "0.5317393826941649\n",
      "Starting Epoch 77\n",
      "0.5307730560501417\n",
      "Starting Epoch 78\n",
      "0.5287699649731318\n",
      "Starting Epoch 79\n",
      "0.528995061914126\n",
      "Starting Epoch 80\n",
      "0.5306565165519714\n",
      "Starting Epoch 81\n",
      "0.530879953255256\n",
      "Starting Epoch 82\n",
      "0.5266418705383936\n",
      "Starting Epoch 83\n",
      "0.5322063937783241\n",
      "Starting Epoch 84\n",
      "0.5293037593364716\n",
      "Starting Epoch 85\n",
      "0.5330468068520228\n",
      "Starting Epoch 86\n",
      "0.5309112208584944\n",
      "Starting Epoch 87\n",
      "0.5309507101774216\n",
      "Starting Epoch 88\n",
      "0.5340764671564102\n",
      "Starting Epoch 89\n",
      "0.5285647623240948\n",
      "Starting Epoch 90\n",
      "0.5312114345530669\n",
      "Starting Epoch 91\n",
      "0.5256561227142811\n",
      "Starting Epoch 92\n",
      "0.5319756381213665\n",
      "Starting Epoch 93\n",
      "0.5285441502928734\n",
      "Starting Epoch 94\n",
      "0.5300705296297868\n",
      "Starting Epoch 95\n",
      "0.5288089190920194\n",
      "Starting Epoch 96\n",
      "0.5300398940841357\n",
      "Starting Epoch 97\n",
      "0.5292147770524025\n",
      "Starting Epoch 98\n",
      "0.5252595903972784\n",
      "Starting Epoch 99\n",
      "0.5302634264032046\n",
      "Starting Epoch 100\n",
      "0.5276156564553579\n",
      "Starting Epoch 101\n",
      "0.5319890106717745\n",
      "Starting Epoch 102\n",
      "0.527433268725872\n",
      "Starting Epoch 103\n",
      "0.5264605370660623\n",
      "Starting Epoch 104\n",
      "0.5275571520129839\n",
      "Starting Epoch 105\n",
      "0.529797475785017\n",
      "Starting Epoch 106\n",
      "0.5290519843498865\n",
      "Starting Epoch 107\n",
      "0.5266715524097284\n",
      "Starting Epoch 108\n",
      "0.5238941585024198\n",
      "Starting Epoch 109\n",
      "0.5271265072127184\n",
      "Starting Epoch 110\n",
      "0.5253938821454843\n",
      "Starting Epoch 111\n",
      "0.527052945146958\n",
      "New best model found at epoch 111 with validation loss 0.507742166519165\n",
      "Starting Epoch 112\n",
      "0.526274673640728\n",
      "Starting Epoch 113\n",
      "0.5272238266964754\n",
      "New best model found at epoch 113 with validation loss 0.5068637728691101\n",
      "Starting Epoch 114\n",
      "0.5258085913956165\n",
      "Starting Epoch 115\n",
      "0.5245100073516369\n",
      "Starting Epoch 116\n",
      "0.5246040833493074\n",
      "Starting Epoch 117\n",
      "0.5260418467223644\n",
      "New best model found at epoch 117 with validation loss 0.5053861737251282\n",
      "Starting Epoch 118\n",
      "0.5251859501004219\n",
      "New best model found at epoch 118 with validation loss 0.5050172805786133\n",
      "Starting Epoch 119\n",
      "0.5273150205612183\n",
      "Starting Epoch 120\n",
      "0.5258991320927938\n",
      "Starting Epoch 121\n",
      "0.5256442489723364\n",
      "Starting Epoch 122\n",
      "0.5277721943954626\n",
      "Starting Epoch 123\n",
      "0.5209411246081194\n",
      "Starting Epoch 124\n",
      "0.5287969261407852\n",
      "Starting Epoch 125\n",
      "0.5258287948866686\n",
      "Starting Epoch 126\n",
      "0.5236872608462969\n",
      "Starting Epoch 127\n",
      "0.525044015298287\n",
      "Starting Epoch 128\n",
      "0.5232460324962934\n",
      "Starting Epoch 129\n",
      "0.5226396185656389\n",
      "Starting Epoch 130\n",
      "0.5274552119274935\n",
      "Starting Epoch 131\n",
      "0.5230007519324621\n",
      "New best model found at epoch 131 with validation loss 0.5020914077758789\n",
      "Starting Epoch 132\n",
      "0.5243574852744738\n",
      "New best model found at epoch 132 with validation loss 0.5006101727485657\n",
      "Starting Epoch 133\n",
      "0.5219164788722992\n",
      "Starting Epoch 134\n",
      "0.5243260003626347\n",
      "Starting Epoch 135\n",
      "0.5211647972464561\n",
      "Starting Epoch 136\n",
      "0.5224942900240421\n",
      "Starting Epoch 137\n",
      "0.5220641940832138\n",
      "Starting Epoch 138\n",
      "0.5199060204128424\n",
      "Starting Epoch 139\n",
      "0.5225089949866136\n",
      "Starting Epoch 140\n",
      "0.5216200749079386\n",
      "Starting Epoch 141\n",
      "0.5211873228351275\n",
      "Starting Epoch 142\n",
      "0.5195617079734802\n",
      "Starting Epoch 143\n",
      "0.5197214049597582\n",
      "Starting Epoch 144\n",
      "0.5210436855753263\n",
      "Starting Epoch 145\n",
      "0.5203854801754156\n",
      "Starting Epoch 146\n",
      "0.5210417993366718\n",
      "Starting Epoch 147\n",
      "0.5220872747401396\n",
      "Starting Epoch 148\n",
      "0.5212417704363664\n",
      "Starting Epoch 149\n",
      "0.5215396819015344\n",
      "New best model found at epoch 149 with validation loss 0.5005549788475037\n",
      "Starting Epoch 150\n",
      "0.5211758079628149\n",
      "Starting Epoch 151\n",
      "0.5220760442316532\n",
      "Starting Epoch 152\n",
      "0.5188121646642685\n",
      "Starting Epoch 153\n",
      "0.5217258185148239\n",
      "Starting Epoch 154\n",
      "0.5189870223402977\n",
      "Starting Epoch 155\n",
      "0.5223989722629389\n",
      "Starting Epoch 156\n",
      "0.5161295036474863\n",
      "Starting Epoch 157\n",
      "0.5203090757131577\n",
      "Starting Epoch 158\n",
      "0.5195363238453865\n",
      "New best model found at epoch 158 with validation loss 0.4998784065246582\n",
      "Starting Epoch 159\n",
      "0.5215043599406878\n",
      "Starting Epoch 160\n",
      "0.5184040504197279\n",
      "Starting Epoch 161\n",
      "0.5199994804958502\n",
      "Starting Epoch 162\n",
      "0.5189992735783259\n",
      "Starting Epoch 163\n",
      "0.5190993125240008\n",
      "Starting Epoch 164\n",
      "0.5199041118224462\n",
      "Starting Epoch 165\n",
      "0.5191599614918232\n",
      "Starting Epoch 166\n",
      "0.5198360097905\n",
      "Starting Epoch 167\n",
      "0.5183561109006405\n",
      "Starting Epoch 168\n",
      "0.5182159841060638\n",
      "Starting Epoch 169\n",
      "0.5199386638899645\n",
      "Starting Epoch 170\n",
      "0.5193422089020411\n",
      "Starting Epoch 171\n",
      "0.5182603076100349\n",
      "Starting Epoch 172\n",
      "0.5168315507471561\n",
      "Starting Epoch 173\n",
      "0.5187523563702902\n",
      "Starting Epoch 174\n",
      "0.5179263104995092\n",
      "Starting Epoch 175\n",
      "0.5198364742100239\n",
      "Starting Epoch 176\n",
      "0.5217602203289667\n",
      "New best model found at epoch 176 with validation loss 0.49939751625061035\n",
      "Starting Epoch 177\n",
      "0.5185443311929703\n",
      "Starting Epoch 178\n",
      "0.5116236470639706\n",
      "Starting Epoch 179\n",
      "0.5200830201307932\n",
      "Starting Epoch 180\n",
      "0.5155096376935641\n",
      "Starting Epoch 181\n",
      "0.5169034786522388\n",
      "Starting Epoch 182\n",
      "0.5161640557150046\n",
      "New best model found at epoch 182 with validation loss 0.4989449679851532\n",
      "Starting Epoch 183\n",
      "0.5138073141376177\n",
      "Starting Epoch 184\n",
      "0.5177775410314401\n",
      "Starting Epoch 185\n",
      "0.5155311872561773\n",
      "Starting Epoch 186\n",
      "0.5152014568448067\n",
      "Starting Epoch 187\n",
      "0.5125812304516634\n",
      "Starting Epoch 188\n",
      "0.5136631441613039\n",
      "Starting Epoch 189\n",
      "0.517319289346536\n",
      "Starting Epoch 190\n",
      "0.5159817164142927\n",
      "Starting Epoch 191\n",
      "0.5172715758283933\n",
      "New best model found at epoch 191 with validation loss 0.4973171651363373\n",
      "Starting Epoch 192\n",
      "0.5133135778208574\n",
      "New best model found at epoch 192 with validation loss 0.496660977602005\n",
      "Starting Epoch 193\n",
      "0.5166148617863655\n",
      "Starting Epoch 194\n",
      "0.5180720364054044\n",
      "Starting Epoch 195\n",
      "0.5163244555393854\n",
      "Starting Epoch 196\n",
      "0.5131001596649488\n",
      "Starting Epoch 197\n",
      "0.5143189008037249\n",
      "Starting Epoch 198\n",
      "0.5170753399531046\n",
      "Starting Epoch 199\n",
      "0.5143829062581062\n",
      "Starting Epoch 200\n",
      "0.5147552639245987\n",
      "Starting Epoch 201\n",
      "0.514379528661569\n",
      "New best model found at epoch 201 with validation loss 0.49661123752593994\n",
      "Starting Epoch 202\n",
      "0.5117831105987231\n",
      "Starting Epoch 203\n",
      "0.5161852451662222\n",
      "Starting Epoch 204\n",
      "0.5143281010289987\n",
      "Starting Epoch 205\n",
      "0.5142475118239721\n",
      "New best model found at epoch 205 with validation loss 0.4932796359062195\n",
      "Starting Epoch 206\n",
      "0.5105633226533731\n",
      "Starting Epoch 207\n",
      "0.5125751358767351\n",
      "New best model found at epoch 207 with validation loss 0.4927635192871094\n",
      "Starting Epoch 208\n",
      "0.5133779793977737\n",
      "Starting Epoch 209\n",
      "0.512495885292689\n",
      "Starting Epoch 210\n",
      "0.5152494596938292\n",
      "Starting Epoch 211\n",
      "0.5147164563337961\n",
      "Starting Epoch 212\n",
      "0.5132121592760086\n",
      "Starting Epoch 213\n",
      "0.5120089389383793\n",
      "Starting Epoch 214\n",
      "0.5139702570935091\n",
      "Starting Epoch 215\n",
      "0.5146427502234777\n",
      "Starting Epoch 216\n",
      "0.5107960514724255\n",
      "Starting Epoch 217\n",
      "0.513845091064771\n",
      "Starting Epoch 218\n",
      "0.5104183877507845\n",
      "Starting Epoch 219\n",
      "0.5118035587171713\n",
      "Starting Epoch 220\n",
      "0.5126607989271482\n",
      "Starting Epoch 221\n",
      "0.5108418414990107\n",
      "Starting Epoch 222\n",
      "0.513120119770368\n",
      "Starting Epoch 223\n",
      "0.5083193952838579\n",
      "Starting Epoch 224\n",
      "0.5076568735142549\n",
      "Starting Epoch 225\n",
      "0.5120602200428644\n",
      "Starting Epoch 226\n",
      "0.5107906696697077\n",
      "Starting Epoch 227\n",
      "0.5115240762631098\n",
      "New best model found at epoch 227 with validation loss 0.4926544725894928\n",
      "Starting Epoch 228\n",
      "0.5111524760723114\n",
      "Starting Epoch 229\n",
      "0.5105978747208914\n",
      "Starting Epoch 230\n",
      "0.5082297834257284\n",
      "Starting Epoch 231\n",
      "0.50846574579676\n",
      "New best model found at epoch 231 with validation loss 0.4904208779335022\n",
      "Starting Epoch 232\n",
      "0.509469081958135\n",
      "Starting Epoch 233\n",
      "0.5083940327167511\n",
      "Starting Epoch 234\n",
      "0.5093103622396787\n",
      "Starting Epoch 235\n",
      "0.5091967123250166\n",
      "Starting Epoch 236\n",
      "0.5082104504108429\n",
      "Starting Epoch 237\n",
      "0.5098121874034405\n",
      "Starting Epoch 238\n",
      "0.5067095706860224\n",
      "New best model found at epoch 238 with validation loss 0.4888943135738373\n",
      "Starting Epoch 239\n",
      "0.5100627715388933\n",
      "Starting Epoch 240\n",
      "0.5080123084286848\n",
      "New best model found at epoch 240 with validation loss 0.48747092485427856\n",
      "Starting Epoch 241\n",
      "0.5105811953544617\n",
      "Starting Epoch 242\n",
      "0.5035518370568752\n",
      "Starting Epoch 243\n",
      "0.5080976920823256\n",
      "Starting Epoch 244\n",
      "0.5096462778747082\n",
      "Starting Epoch 245\n",
      "0.5101995505392551\n",
      "Starting Epoch 246\n",
      "0.5084677487611771\n",
      "Starting Epoch 247\n",
      "0.5051193498075008\n",
      "Starting Epoch 248\n",
      "0.5066770526270071\n",
      "Starting Epoch 249\n",
      "0.5099967531859875\n",
      "Starting Epoch 250\n",
      "0.5079902559518814\n",
      "Starting Epoch 251\n",
      "0.5070188914736112\n",
      "Starting Epoch 252\n",
      "0.5089240732292334\n",
      "Starting Epoch 253\n",
      "0.5069487194220225\n",
      "Starting Epoch 254\n",
      "0.5088390534122785\n",
      "Starting Epoch 255\n",
      "0.5061633810400963\n",
      "Starting Epoch 256\n",
      "0.5065441193679968\n",
      "Starting Epoch 257\n",
      "0.5048750465114912\n",
      "Starting Epoch 258\n",
      "0.5054564289748669\n",
      "Starting Epoch 259\n",
      "0.5040848789115747\n",
      "Starting Epoch 260\n",
      "0.504130999247233\n",
      "Starting Epoch 261\n",
      "0.5076383712391058\n",
      "Starting Epoch 262\n",
      "0.5051497854292393\n",
      "Starting Epoch 263\n",
      "0.5045403502881527\n",
      "Starting Epoch 264\n",
      "0.5033397724231085\n",
      "Starting Epoch 265\n",
      "0.5055062447985014\n",
      "Starting Epoch 266\n",
      "0.5048325583338737\n",
      "Starting Epoch 267\n",
      "0.5045936616758505\n",
      "Starting Epoch 268\n",
      "0.5073295595745245\n",
      "Starting Epoch 269\n",
      "0.5070067755877972\n",
      "Starting Epoch 270\n",
      "0.5031148369113604\n",
      "Starting Epoch 271\n",
      "0.503784446666638\n",
      "Starting Epoch 272\n",
      "0.5023352814217409\n",
      "Starting Epoch 273\n",
      "0.5032009283701578\n",
      "Starting Epoch 274\n",
      "0.5027191378176212\n",
      "Starting Epoch 275\n",
      "0.5014480588336786\n",
      "Starting Epoch 276\n",
      "0.5009659317632517\n",
      "Starting Epoch 277\n",
      "0.5039132659633955\n",
      "New best model found at epoch 277 with validation loss 0.48733511567115784\n",
      "Starting Epoch 278\n",
      "0.49962375313043594\n",
      "Starting Epoch 279\n",
      "0.5055575110018253\n",
      "Starting Epoch 280\n",
      "0.5040120172003905\n",
      "Starting Epoch 281\n",
      "0.5016702190041542\n",
      "Starting Epoch 282\n",
      "0.5025331837435564\n",
      "Starting Epoch 283\n",
      "0.5027518346905708\n",
      "Starting Epoch 284\n",
      "0.5016971838970979\n",
      "Starting Epoch 285\n",
      "0.5001178905367851\n",
      "Starting Epoch 286\n",
      "0.5031005628407001\n",
      "Starting Epoch 287\n",
      "0.5025304282704989\n",
      "Starting Epoch 288\n",
      "0.501709371805191\n",
      "Starting Epoch 289\n",
      "0.5044016862908999\n",
      "Starting Epoch 290\n",
      "0.5025947714845339\n",
      "Starting Epoch 291\n",
      "0.5007582654555639\n",
      "Starting Epoch 292\n",
      "0.5030643120408058\n",
      "Starting Epoch 293\n",
      "0.49908530587951344\n",
      "Starting Epoch 294\n",
      "0.4991588977475961\n",
      "New best model found at epoch 294 with validation loss 0.4844353199005127\n",
      "Starting Epoch 295\n",
      "0.5023531839251518\n",
      "Starting Epoch 296\n",
      "0.49827051783601445\n",
      "Starting Epoch 297\n",
      "0.501827126989762\n",
      "Starting Epoch 298\n",
      "0.498405396938324\n",
      "Starting Epoch 299\n",
      "0.503924993177255\n",
      "Starting Epoch 300\n",
      "0.5034514019886652\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-q75: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f48ba-fe74-4a4a-b707-924ae5a562d2",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, custom layer\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  Adding a custom layer, where we group all features occuring multiple times together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "7d247ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(X_train, y1_train)\n",
    "trainloader = DataLoader(custom_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1485b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e3499296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 1)  \n",
    "        self.fc2 = nn.Linear(1, 1)  \n",
    "        self.fc3 = nn.Linear(1, 1)  \n",
    "        self.fc4 = nn.Linear(1, 1)  \n",
    "        self.fc5 = nn.Linear(1, 1)  \n",
    "        self.fc6 = nn.Linear(6, 1)  \n",
    "        self.fc7 = nn.Linear(6, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        grouped_features = torch.cat((self.fc1(x[:, 0:1]), self.fc2(x[:, 1:2]), self.fc3(x[:, 2:3]), self.fc4(x[:, 3:4]), \n",
    "                                      self.fc5(x[:, 4:5]), self.fc6(x[:, 5:11]), self.fc7(x[:, 11:17])), dim=1)\n",
    "        \n",
    "        return grouped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "16d45a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.custom_layer = CustomLayer()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.custom_layer(x)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "fbb06bf7-d140-4b92-8e0d-046f5396a017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.2839001913865407\n",
      "New best model found at epoch 1 with validation loss 0.582731306552887\n",
      "Starting Epoch 2\n",
      "0.5895801509420077\n",
      "New best model found at epoch 2 with validation loss 0.5608305931091309\n",
      "Starting Epoch 3\n",
      "0.5706149935722351\n",
      "Starting Epoch 4\n",
      "0.5701020546257496\n",
      "Starting Epoch 5\n",
      "0.5681403254469236\n",
      "New best model found at epoch 5 with validation loss 0.5551002621650696\n",
      "Starting Epoch 6\n",
      "0.5658280613521735\n",
      "New best model found at epoch 6 with validation loss 0.5513900518417358\n",
      "Starting Epoch 7\n",
      "0.5624306884904703\n",
      "New best model found at epoch 7 with validation loss 0.5414990186691284\n",
      "Starting Epoch 8\n",
      "0.5588880144059658\n",
      "Starting Epoch 9\n",
      "0.5584352227548758\n",
      "Starting Epoch 10\n",
      "0.5532222377757231\n",
      "Starting Epoch 11\n",
      "0.5541372001171112\n",
      "New best model found at epoch 11 with validation loss 0.5387904047966003\n",
      "Starting Epoch 12\n",
      "0.5518736553688844\n",
      "Starting Epoch 13\n",
      "0.5494735091924667\n",
      "New best model found at epoch 13 with validation loss 0.5305429100990295\n",
      "Starting Epoch 14\n",
      "0.5480901772777239\n",
      "New best model found at epoch 14 with validation loss 0.5263665914535522\n",
      "Starting Epoch 15\n",
      "0.5456140413880348\n",
      "Starting Epoch 16\n",
      "0.5459992662072182\n",
      "Starting Epoch 17\n",
      "0.5434806769092878\n",
      "New best model found at epoch 17 with validation loss 0.5251122117042542\n",
      "Starting Epoch 18\n",
      "0.543840496490399\n",
      "New best model found at epoch 18 with validation loss 0.5246491432189941\n",
      "Starting Epoch 19\n",
      "0.5410811677575111\n",
      "Starting Epoch 20\n",
      "0.5437332900861899\n",
      "Starting Epoch 21\n",
      "0.5392067655920982\n",
      "New best model found at epoch 21 with validation loss 0.522350549697876\n",
      "Starting Epoch 22\n",
      "0.5351355647047361\n",
      "New best model found at epoch 22 with validation loss 0.5169757604598999\n",
      "Starting Epoch 23\n",
      "0.5355321479340395\n",
      "Starting Epoch 24\n",
      "0.5371226109564304\n",
      "Starting Epoch 25\n",
      "0.5342477311690649\n",
      "Starting Epoch 26\n",
      "0.5333337585131327\n",
      "Starting Epoch 27\n",
      "0.5372468456625938\n",
      "New best model found at epoch 27 with validation loss 0.5144960284233093\n",
      "Starting Epoch 28\n",
      "0.5300194236139456\n",
      "Starting Epoch 29\n",
      "0.5293890871107578\n",
      "Starting Epoch 30\n",
      "0.5258113456269106\n",
      "Starting Epoch 31\n",
      "0.5274062218765417\n",
      "New best model found at epoch 31 with validation loss 0.5135493874549866\n",
      "Starting Epoch 32\n",
      "0.5228873789310455\n",
      "Starting Epoch 33\n",
      "0.527966478218635\n",
      "Starting Epoch 34\n",
      "0.5237788533171018\n",
      "Starting Epoch 35\n",
      "0.5252470001578331\n",
      "Starting Epoch 36\n",
      "0.5229635251065096\n",
      "Starting Epoch 37\n",
      "0.5223198955257734\n",
      "Starting Epoch 38\n",
      "0.5263786961634954\n",
      "Starting Epoch 39\n",
      "0.5180040523409843\n",
      "Starting Epoch 40\n",
      "0.5171617865562439\n",
      "New best model found at epoch 40 with validation loss 0.5085242986679077\n",
      "Starting Epoch 41\n",
      "0.5216643263896307\n",
      "Starting Epoch 42\n",
      "0.5141371289889017\n",
      "Starting Epoch 43\n",
      "0.5191880700488886\n",
      "Starting Epoch 44\n",
      "0.5168051856259505\n",
      "Starting Epoch 45\n",
      "0.5175613425672054\n",
      "Starting Epoch 46\n",
      "0.5173612385988235\n",
      "Starting Epoch 47\n",
      "0.517180223017931\n",
      "New best model found at epoch 47 with validation loss 0.5054866671562195\n",
      "Starting Epoch 48\n",
      "0.5119938105344772\n",
      "Starting Epoch 49\n",
      "0.509217398862044\n",
      "Starting Epoch 50\n",
      "0.5103996892770132\n",
      "New best model found at epoch 50 with validation loss 0.4995393753051758\n",
      "Starting Epoch 51\n",
      "0.5117447550098101\n",
      "Starting Epoch 52\n",
      "0.5104760179917017\n",
      "Starting Epoch 53\n",
      "0.5092191422979037\n",
      "Starting Epoch 54\n",
      "0.50837974747022\n",
      "Starting Epoch 55\n",
      "0.5104067424933115\n",
      "Starting Epoch 56\n",
      "0.5089770878354708\n",
      "Starting Epoch 57\n",
      "0.5055040381848812\n",
      "Starting Epoch 58\n",
      "0.5020687244832516\n",
      "Starting Epoch 59\n",
      "0.5044178801278273\n",
      "Starting Epoch 60\n",
      "0.5069058115283648\n",
      "New best model found at epoch 60 with validation loss 0.49802833795547485\n",
      "Starting Epoch 61\n",
      "0.4990299753844738\n",
      "Starting Epoch 62\n",
      "0.5058756532768408\n",
      "Starting Epoch 63\n",
      "0.4992383122444153\n",
      "Starting Epoch 64\n",
      "0.5009536755581697\n",
      "Starting Epoch 65\n",
      "0.5034531056880951\n",
      "Starting Epoch 66\n",
      "0.5027161203324795\n",
      "Starting Epoch 67\n",
      "0.4990268250306447\n",
      "New best model found at epoch 67 with validation loss 0.4949781000614166\n",
      "Starting Epoch 68\n",
      "0.4987780600786209\n",
      "Starting Epoch 69\n",
      "0.49585941558082897\n",
      "Starting Epoch 70\n",
      "0.4957183947165807\n",
      "New best model found at epoch 70 with validation loss 0.49246424436569214\n",
      "Starting Epoch 71\n",
      "0.4967806674540043\n",
      "Starting Epoch 72\n",
      "0.49318841968973476\n",
      "Starting Epoch 73\n",
      "0.49376393233736354\n",
      "Starting Epoch 74\n",
      "0.4941377441088359\n",
      "Starting Epoch 75\n",
      "0.49515937517086667\n",
      "Starting Epoch 76\n",
      "0.4903844781219959\n",
      "Starting Epoch 77\n",
      "0.4954291023313999\n",
      "Starting Epoch 78\n",
      "0.4904167490700881\n",
      "Starting Epoch 79\n",
      "0.4940184143682321\n",
      "Starting Epoch 80\n",
      "0.4928824057181676\n",
      "Starting Epoch 81\n",
      "0.49297740310430527\n",
      "New best model found at epoch 81 with validation loss 0.4886085093021393\n",
      "Starting Epoch 82\n",
      "0.49616309627890587\n",
      "Starting Epoch 83\n",
      "0.4922812891503175\n",
      "Starting Epoch 84\n",
      "0.4901554174721241\n",
      "Starting Epoch 85\n",
      "0.4919573503235976\n",
      "Starting Epoch 86\n",
      "0.496050542841355\n",
      "Starting Epoch 87\n",
      "0.4934755166371663\n",
      "Starting Epoch 88\n",
      "0.4910166909297307\n",
      "Starting Epoch 89\n",
      "0.48780438924829167\n",
      "Starting Epoch 90\n",
      "0.49325461064775783\n",
      "Starting Epoch 91\n",
      "0.4875321500003338\n",
      "Starting Epoch 92\n",
      "0.48684148242076236\n",
      "Starting Epoch 93\n",
      "0.4858161670466264\n",
      "Starting Epoch 94\n",
      "0.4863755951325099\n",
      "Starting Epoch 95\n",
      "0.4880039282143116\n",
      "Starting Epoch 96\n",
      "0.4880583758155505\n",
      "Starting Epoch 97\n",
      "0.48634688307841617\n",
      "Starting Epoch 98\n",
      "0.48788032680749893\n",
      "Starting Epoch 99\n",
      "0.4846652535100778\n",
      "New best model found at epoch 99 with validation loss 0.4836694896221161\n",
      "Starting Epoch 100\n",
      "0.4866063582400481\n",
      "Starting Epoch 101\n",
      "0.4822198537488778\n",
      "Starting Epoch 102\n",
      "0.4812862848242124\n",
      "Starting Epoch 103\n",
      "0.48728226001063984\n",
      "Starting Epoch 104\n",
      "0.48178769275546074\n",
      "Starting Epoch 105\n",
      "0.4818620793521404\n",
      "Starting Epoch 106\n",
      "0.4812682457268238\n",
      "Starting Epoch 107\n",
      "0.4810556185742219\n",
      "Starting Epoch 108\n",
      "0.4810132247706254\n",
      "Starting Epoch 109\n",
      "0.4775013364851475\n",
      "Starting Epoch 110\n",
      "0.47844840462009114\n",
      "Starting Epoch 111\n",
      "0.4818694827457269\n",
      "Starting Epoch 112\n",
      "0.47736434390147525\n",
      "New best model found at epoch 112 with validation loss 0.4823029339313507\n",
      "Starting Epoch 113\n",
      "0.4806430625418822\n",
      "Starting Epoch 114\n",
      "0.47885357216000557\n",
      "New best model found at epoch 114 with validation loss 0.48153582215309143\n",
      "Starting Epoch 115\n",
      "0.4788737433652083\n",
      "Starting Epoch 116\n",
      "0.4815201573073864\n",
      "Starting Epoch 117\n",
      "0.472783421476682\n",
      "Starting Epoch 118\n",
      "0.47904111941655475\n",
      "Starting Epoch 119\n",
      "0.47823208446304005\n",
      "Starting Epoch 120\n",
      "0.4762442732850711\n",
      "Starting Epoch 121\n",
      "0.47929488494992256\n",
      "Starting Epoch 122\n",
      "0.4757579614718755\n",
      "Starting Epoch 123\n",
      "0.47756915415326756\n",
      "Starting Epoch 124\n",
      "0.4804601880411307\n",
      "Starting Epoch 125\n",
      "0.4762657843530178\n",
      "Starting Epoch 126\n",
      "0.47508304317792255\n",
      "New best model found at epoch 126 with validation loss 0.47979623079299927\n",
      "Starting Epoch 127\n",
      "0.4736928232014179\n",
      "Starting Epoch 128\n",
      "0.4749765172600746\n",
      "Starting Epoch 129\n",
      "0.47368328149120015\n",
      "Starting Epoch 130\n",
      "0.4738978259265423\n",
      "Starting Epoch 131\n",
      "0.4704466449717681\n",
      "Starting Epoch 132\n",
      "0.47432837014396984\n",
      "Starting Epoch 133\n",
      "0.4710347962876161\n",
      "Starting Epoch 134\n",
      "0.4742264772454898\n",
      "Starting Epoch 135\n",
      "0.4704125374555588\n",
      "Starting Epoch 136\n",
      "0.4720852350195249\n",
      "Starting Epoch 137\n",
      "0.46910061314702034\n",
      "Starting Epoch 138\n",
      "0.4678083285689354\n",
      "Starting Epoch 139\n",
      "0.4713166455427806\n",
      "Starting Epoch 140\n",
      "0.4703821452955405\n",
      "Starting Epoch 141\n",
      "0.47008022541801137\n",
      "Starting Epoch 142\n",
      "0.4707361062367757\n",
      "New best model found at epoch 142 with validation loss 0.47594594955444336\n",
      "Starting Epoch 143\n",
      "0.46879607314864796\n",
      "Starting Epoch 144\n",
      "0.46948617075880367\n",
      "Starting Epoch 145\n",
      "0.469752957423528\n",
      "Starting Epoch 146\n",
      "0.4687224787970384\n",
      "Starting Epoch 147\n",
      "0.4680099089940389\n",
      "Starting Epoch 148\n",
      "0.46605738004048664\n",
      "Starting Epoch 149\n",
      "0.47030479709307355\n",
      "Starting Epoch 150\n",
      "0.4661746583878994\n",
      "Starting Epoch 151\n",
      "0.46853920817375183\n",
      "New best model found at epoch 151 with validation loss 0.47584959864616394\n",
      "Starting Epoch 152\n",
      "0.46612528214852017\n",
      "Starting Epoch 153\n",
      "0.4660518604020278\n",
      "Starting Epoch 154\n",
      "0.46668004989624023\n",
      "Starting Epoch 155\n",
      "0.46565719197193783\n",
      "Starting Epoch 156\n",
      "0.4662352241575718\n",
      "Starting Epoch 157\n",
      "0.4638567653795083\n",
      "Starting Epoch 158\n",
      "0.4661947079002857\n",
      "Starting Epoch 159\n",
      "0.46696031590302783\n",
      "Starting Epoch 160\n",
      "0.46740961571534473\n",
      "Starting Epoch 161\n",
      "0.46451323851943016\n",
      "New best model found at epoch 161 with validation loss 0.4734485149383545\n",
      "Starting Epoch 162\n",
      "0.46658356487751007\n",
      "Starting Epoch 163\n",
      "0.4633580185472965\n",
      "Starting Epoch 164\n",
      "0.46520047386487323\n",
      "Starting Epoch 165\n",
      "0.4682440447310607\n",
      "Starting Epoch 166\n",
      "0.463115976502498\n",
      "Starting Epoch 167\n",
      "0.4617830974360307\n",
      "Starting Epoch 168\n",
      "0.4680420358975728\n",
      "Starting Epoch 169\n",
      "0.46249393994609517\n",
      "Starting Epoch 170\n",
      "0.4672394481798013\n",
      "New best model found at epoch 170 with validation loss 0.47257307171821594\n",
      "Starting Epoch 171\n",
      "0.46429477135340375\n",
      "Starting Epoch 172\n",
      "0.45982620244224864\n",
      "Starting Epoch 173\n",
      "0.4664780410627524\n",
      "Starting Epoch 174\n",
      "0.4631369200845559\n",
      "Starting Epoch 175\n",
      "0.4611906905968984\n",
      "Starting Epoch 176\n",
      "0.45912597080071765\n",
      "Starting Epoch 177\n",
      "0.46094948674241704\n",
      "Starting Epoch 178\n",
      "0.4628700477381547\n",
      "Starting Epoch 179\n",
      "0.461498461663723\n",
      "Starting Epoch 180\n",
      "0.46114301433165866\n",
      "Starting Epoch 181\n",
      "0.46022743235031766\n",
      "Starting Epoch 182\n",
      "0.4589846668144067\n",
      "Starting Epoch 183\n",
      "0.4632829676071803\n",
      "Starting Epoch 184\n",
      "0.46517008418838185\n",
      "Starting Epoch 185\n",
      "0.46520959958434105\n",
      "Starting Epoch 186\n",
      "0.4596179897586505\n",
      "New best model found at epoch 186 with validation loss 0.47240617871284485\n",
      "Starting Epoch 187\n",
      "0.46350254739324254\n",
      "Starting Epoch 188\n",
      "0.46179774155219394\n",
      "New best model found at epoch 188 with validation loss 0.46859732270240784\n",
      "Starting Epoch 189\n",
      "0.4615325555205345\n",
      "Starting Epoch 190\n",
      "0.4598679567376773\n",
      "Starting Epoch 191\n",
      "0.46317217250665027\n",
      "Starting Epoch 192\n",
      "0.4632616216937701\n",
      "Starting Epoch 193\n",
      "0.46297020465135574\n",
      "Starting Epoch 194\n",
      "0.4598473571240902\n",
      "Starting Epoch 195\n",
      "0.46068161725997925\n",
      "Starting Epoch 196\n",
      "0.45697768156727153\n",
      "Starting Epoch 197\n",
      "0.46673035124937695\n",
      "Starting Epoch 198\n",
      "0.4588303156197071\n",
      "Starting Epoch 199\n",
      "0.45847202464938164\n",
      "Starting Epoch 200\n",
      "0.45578410973151523\n",
      "New best model found at epoch 200 with validation loss 0.46801185607910156\n",
      "Starting Epoch 201\n",
      "0.460364505648613\n",
      "Starting Epoch 202\n",
      "0.46114519238471985\n",
      "Starting Epoch 203\n",
      "0.460896464685599\n",
      "Starting Epoch 204\n",
      "0.45866933340827626\n",
      "Starting Epoch 205\n",
      "0.4571788099904855\n",
      "Starting Epoch 206\n",
      "0.4553542646269004\n",
      "Starting Epoch 207\n",
      "0.45718693484862644\n",
      "Starting Epoch 208\n",
      "0.4588769773642222\n",
      "New best model found at epoch 208 with validation loss 0.4679648280143738\n",
      "Starting Epoch 209\n",
      "0.458067636936903\n",
      "Starting Epoch 210\n",
      "0.45299716542164487\n",
      "Starting Epoch 211\n",
      "0.45614223803083104\n",
      "Starting Epoch 212\n",
      "0.45559245844682056\n",
      "Starting Epoch 213\n",
      "0.45572059725721675\n",
      "Starting Epoch 214\n",
      "0.4585087050994237\n",
      "Starting Epoch 215\n",
      "0.45657964423298836\n",
      "Starting Epoch 216\n",
      "0.458861630409956\n",
      "Starting Epoch 217\n",
      "0.4542693942785263\n",
      "New best model found at epoch 217 with validation loss 0.46670594811439514\n",
      "Starting Epoch 218\n",
      "0.4543612288932006\n",
      "New best model found at epoch 218 with validation loss 0.465822696685791\n",
      "Starting Epoch 219\n",
      "0.45965369666616124\n",
      "Starting Epoch 220\n",
      "0.45552651459972066\n",
      "Starting Epoch 221\n",
      "0.45348961527148884\n",
      "New best model found at epoch 221 with validation loss 0.46473678946495056\n",
      "Starting Epoch 222\n",
      "0.454744603484869\n",
      "Starting Epoch 223\n",
      "0.4551109919945399\n",
      "Starting Epoch 224\n",
      "0.45407989621162415\n",
      "Starting Epoch 225\n",
      "0.45244817808270454\n",
      "Starting Epoch 226\n",
      "0.4541811856130759\n",
      "Starting Epoch 227\n",
      "0.45388303076227504\n",
      "Starting Epoch 228\n",
      "0.45255567878484726\n",
      "New best model found at epoch 228 with validation loss 0.46194422245025635\n",
      "Starting Epoch 229\n",
      "0.45207470655441284\n",
      "Starting Epoch 230\n",
      "0.4532867483794689\n",
      "Starting Epoch 231\n",
      "0.4529190311829249\n",
      "Starting Epoch 232\n",
      "0.45025159791111946\n",
      "Starting Epoch 233\n",
      "0.45324166988333064\n",
      "Starting Epoch 234\n",
      "0.4536389869948228\n",
      "Starting Epoch 235\n",
      "0.4542566028734048\n",
      "New best model found at epoch 235 with validation loss 0.46018674969673157\n",
      "Starting Epoch 236\n",
      "0.4506409913301468\n",
      "New best model found at epoch 236 with validation loss 0.4585023522377014\n",
      "Starting Epoch 237\n",
      "0.4502835584183534\n",
      "Starting Epoch 238\n",
      "0.45391970376173657\n",
      "Starting Epoch 239\n",
      "0.453876210997502\n",
      "Starting Epoch 240\n",
      "0.45287591094772023\n",
      "Starting Epoch 241\n",
      "0.4523115394016107\n",
      "Starting Epoch 242\n",
      "0.45277635380625725\n",
      "Starting Epoch 243\n",
      "0.4547542333602905\n",
      "Starting Epoch 244\n",
      "0.45226530482371646\n",
      "Starting Epoch 245\n",
      "0.4528631853560607\n",
      "Starting Epoch 246\n",
      "0.4526180910567443\n",
      "Starting Epoch 247\n",
      "0.45268987119197845\n",
      "Starting Epoch 248\n",
      "0.4557549978295962\n",
      "Starting Epoch 249\n",
      "0.4517754440506299\n",
      "Starting Epoch 250\n",
      "0.44872398550311726\n",
      "Starting Epoch 251\n",
      "0.451028769214948\n",
      "Starting Epoch 252\n",
      "0.45062242324153584\n",
      "Starting Epoch 253\n",
      "0.44683635607361794\n",
      "New best model found at epoch 253 with validation loss 0.4573383927345276\n",
      "Starting Epoch 254\n",
      "0.44650740300615627\n",
      "Starting Epoch 255\n",
      "0.45073555409908295\n",
      "Starting Epoch 256\n",
      "0.4474218897521496\n",
      "Starting Epoch 257\n",
      "0.4470575588444869\n",
      "Starting Epoch 258\n",
      "0.4474647144476573\n",
      "Starting Epoch 259\n",
      "0.44988129287958145\n",
      "New best model found at epoch 259 with validation loss 0.45348745584487915\n",
      "Starting Epoch 260\n",
      "0.44709641362229985\n",
      "Starting Epoch 261\n",
      "0.4490572325885296\n",
      "Starting Epoch 262\n",
      "0.4535142506162326\n",
      "Starting Epoch 263\n",
      "0.4520445230106513\n",
      "Starting Epoch 264\n",
      "0.4495084136724472\n",
      "Starting Epoch 265\n",
      "0.4473988860845566\n",
      "Starting Epoch 266\n",
      "0.4448181800544262\n",
      "Starting Epoch 267\n",
      "0.45023007194201153\n",
      "Starting Epoch 268\n",
      "0.44413573915759724\n",
      "Starting Epoch 269\n",
      "0.4464414765437444\n",
      "Starting Epoch 270\n",
      "0.44495194032788277\n",
      "Starting Epoch 271\n",
      "0.44763239721457165\n",
      "Starting Epoch 272\n",
      "0.4429710693657398\n",
      "Starting Epoch 273\n",
      "0.4477452871700128\n",
      "Starting Epoch 274\n",
      "0.4501958539088567\n",
      "New best model found at epoch 274 with validation loss 0.4519551396369934\n",
      "Starting Epoch 275\n",
      "0.44576339051127434\n",
      "Starting Epoch 276\n",
      "0.4472518712282181\n",
      "Starting Epoch 277\n",
      "0.45085782185196877\n",
      "Starting Epoch 278\n",
      "0.44500822201371193\n",
      "Starting Epoch 279\n",
      "0.44376970703403157\n",
      "Starting Epoch 280\n",
      "0.4466390311717987\n",
      "Starting Epoch 281\n",
      "0.44691526889801025\n",
      "Starting Epoch 282\n",
      "0.44381097828348476\n",
      "Starting Epoch 283\n",
      "0.45143050452073413\n",
      "Starting Epoch 284\n",
      "0.44788027306397754\n",
      "Starting Epoch 285\n",
      "0.44328320274750393\n",
      "Starting Epoch 286\n",
      "0.44619019826253253\n",
      "Starting Epoch 287\n",
      "0.4443385899066925\n",
      "Starting Epoch 288\n",
      "0.44399598240852356\n",
      "Starting Epoch 289\n",
      "0.4463588533302148\n",
      "Starting Epoch 290\n",
      "0.44570717712243396\n",
      "Starting Epoch 291\n",
      "0.446521141876777\n",
      "New best model found at epoch 291 with validation loss 0.4478072226047516\n",
      "Starting Epoch 292\n",
      "0.44607408220569295\n",
      "Starting Epoch 293\n",
      "0.4463052886227767\n",
      "Starting Epoch 294\n",
      "0.4494500954945882\n",
      "Starting Epoch 295\n",
      "0.44505999982357025\n",
      "Starting Epoch 296\n",
      "0.44644468277692795\n",
      "Starting Epoch 297\n",
      "0.44237952803572017\n",
      "Starting Epoch 298\n",
      "0.44520944729447365\n",
      "Starting Epoch 299\n",
      "0.44693108027180034\n",
      "Starting Epoch 300\n",
      "0.4440779623885949\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP, custom: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "dfcf6c32-772e-41d6-b08d-c1aac78d36fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.800758</td>\n",
       "      <td>0.809452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>0.817704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.812879</td>\n",
       "      <td>0.833458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.679181</td>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.684091</td>\n",
       "      <td>0.555139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.533784</td>\n",
       "      <td>0.714773</td>\n",
       "      <td>0.579145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.710606</td>\n",
       "      <td>0.525881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-2</th>\n",
       "      <td>0.720137</td>\n",
       "      <td>0.574324</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-2</th>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.574324</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-2</th>\n",
       "      <td>0.716724</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-2</th>\n",
       "      <td>0.703072</td>\n",
       "      <td>0.614865</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-2</th>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-2</th>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-2</th>\n",
       "      <td>0.706485</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-2</th>\n",
       "      <td>0.774744</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-2</th>\n",
       "      <td>0.754266</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-2</th>\n",
       "      <td>0.706485</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-2</th>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-2</th>\n",
       "      <td>0.730375</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-2</th>\n",
       "      <td>0.774744</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-2</th>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-2</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-2</th>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-2</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-2</th>\n",
       "      <td>0.750853</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-2</th>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-2</th>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   acc       rec       acc       rec\n",
       "5-NN                          0.829352  0.824324  0.800758  0.809452\n",
       "Decision tree                 0.836177  0.797297  0.814394  0.817704\n",
       "Random forest                 0.832765  0.831081  0.812879  0.833458\n",
       "SVM linear                    0.679181  0.506757  0.684091  0.555139\n",
       "SVM poly                      0.696246  0.533784  0.714773  0.579145\n",
       "SVM rbf                       0.713311  0.513514  0.710606  0.525881\n",
       "MLP: 17-5-2                   0.720137  0.574324         -         -\n",
       "MLP: 17-10-2                  0.692833  0.574324         -         -\n",
       "MLP: 17-20-2                  0.716724  0.587838         -         -\n",
       "MLP: 17-25-2                  0.703072  0.614865         -         -\n",
       "MLP: 17-40-2                  0.696246  0.608108         -         -\n",
       "MLP: 17-60-2                  0.713311  0.655405         -         -\n",
       "MLP: 17-10-5-2                0.706485  0.641892         -         -\n",
       "MLP: 17-20-10-2               0.774744  0.797297         -         -\n",
       "MLP: 17-40-20-2               0.754266  0.729730         -         -\n",
       "MLP: 17-40-10-2               0.706485  0.513514         -         -\n",
       "MLP: 17-60-40-2               0.767918  0.695946         -         -\n",
       "MLP: 17-60-20-2               0.730375  0.641892         -         -\n",
       "MLP: 17-80-50-2               0.774744  0.702703         -         -\n",
       "MLP, small-median: 7-80-50-2  0.767918  0.702703         -         -\n",
       "MLP, small-mean: 7-80-50-2    0.744027  0.655405         -         -\n",
       "MLP, small-min: 7-80-50-2     0.737201  0.689189         -         -\n",
       "MLP, small-max: 7-80-50-2     0.744027  0.709459         -         -\n",
       "MLP, small-q25: 7-80-50-2     0.750853  0.662162         -         -\n",
       "MLP, small-q75: 7-80-50-2     0.737201  0.655405         -         -\n",
       "MLP, custom: 7-80-50-2        0.767918  0.743243         -         -"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d211f-84e7-4572-95ad-7f690c205df5",
   "metadata": {},
   "source": [
    "### Deep MLP with three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ed9b7-78c8-4d7d-95b7-a0920245ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_train_mlp = y1_equal_05_train + 1\n",
    "y1_equal_05_val_mlp = y1_equal_05_val + 1\n",
    "y1_equal_01_train_mlp = y1_equal_01_train + 1\n",
    "y1_equal_01_val_mlp = y1_equal_01_val + 1\n",
    "y1_equal_005_train_mlp = y1_equal_005_train + 1\n",
    "y1_equal_005_val_mlp = y1_equal_005_val + 1\n",
    "y1_equal_001_train_mlp = y1_equal_001_train + 1\n",
    "y1_equal_001_val_mlp = y1_equal_001_val + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.values).float()  # Convert DataFrame to tensor\n",
    "        self.y = torch.from_numpy(y.values).float()  # Convert DataFrame to tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b23c8",
   "metadata": {},
   "source": [
    "#### 3-layer MLP\n",
    "*  Loss: Cross-Entropy\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4398bde2",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 1, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 5 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e5dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 3)\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963815a-24bb-47a6-9bec-530befb1b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102caf85-5c58-493f-b537-9e018b8b7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36c950-5edf-4130-8a77-eaa18de1c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8d7f8-be76-471f-9434-e88c37b6f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-5-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ec50d",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 2, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 10 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fabc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159e38e-0150-4672-8d4f-65ecf9829b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650c13e-1701-4bcb-a606-546b44860d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6db479-b96f-4577-94d5-3342de39c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f3222-facb-48fe-b7b1-18620516ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-10-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6f9b1",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 3, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 20 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd3f01-4cc1-4ce1-9439-135b87ea7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b7d2e-da52-42ad-a7ee-91c2bb011721",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13fcc30-22bc-45bc-8f9e-647414de6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099dd9d7-516a-4e35-8aa1-0c0f35cd1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-20-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d82414b",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 4, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 25 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56cda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df8f3b1-d7f1-4c77-8027-4d724838446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-25-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8151a-aa3a-4ab6-b584-325ab115f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-25-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530c87f-297f-4ba2-9c2a-bbc927a40528",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-25-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52799feb-48d3-4ff5-9e9c-ca3b3972ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-25-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b973983",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 5, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 40 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a06a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c95bb68-4936-4eb1-96c8-9ecf66694148",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466353e-80f0-4663-a237-2e160d214590",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3932c5-b9e9-45b5-95f6-833ea8df8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02cd381-8869-49b3-8f76-ea258a167c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-40-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd548efc",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 6, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 60 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe2484-8cd1-4458-9f80-028626758ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-60-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a39e80-531e-42b4-8857-522445450288",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-60-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cdf2e-1f3a-48be-bb1a-bafa856cd5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-60-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4261fb9-95dc-4ca3-b161-5355bf2cdc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-60-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8266617",
   "metadata": {},
   "source": [
    "#### 4-layer MLP\n",
    "*  Loss: Cross-entropy\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91bc9bf",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 1, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 10 - 5 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b134b59-3293-4158-913c-72067cb498f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-10-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7b10b-7ec2-4713-b394-04cf0c22ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-10-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a01ad-9e06-4387-bd2d-53e82703d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-10-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22014df1-5a55-48f6-8173-610b5d8e9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-10-5-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05523747",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 2, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 20 - 10 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12219b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b4f16-2797-4d69-a048-8ee88cc67422",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-20-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333ce2d-d3f9-438a-9a5c-7906c5c1dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-20-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eee324-fe9e-4592-a989-ea93aff01046",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-20-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951583da-2c9d-4e84-aec0-9b7be63db9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-20-10-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8bf3d",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 3, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 20 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87001a65-8c3d-4bde-a024-0ea33f4cd8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-40-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34048d50-99cd-4cb8-81ce-26d7f8bb4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-40-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771fc293-4e96-47be-b524-3c1368bf31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-40-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a56ee-8671-4c31-9f1d-5787ebd74bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-40-20-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac158a",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 4, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 10 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f3058-04cf-4f60-846f-9caa294451ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-40-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3cc4d-4b25-4d08-b8f0-c380fba8f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-40-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8a60a-6d33-41d3-b7a1-5e7b3cbc224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-40-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c05f8-d6f0-4ff9-8bc6-390ac975bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-40-10-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e096df",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 5, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 40 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f5cb9-775b-4c31-bae9-cb7eddf2a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-60-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1868044-5266-4793-bffc-02839f770ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-60-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914242a5-3568-40df-9d67-1f564ee0ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-60-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948cbc5-dc74-4ae4-878d-69739376ed9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-60-40-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c67be7",
   "metadata": {},
   "source": [
    "##### 4-layers MLP: Version 6, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 20 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb635d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3274689-b0f2-4158-abc5-14ba670ac4f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8c8a1-4737-4f23-9355-9f70516eeb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c02e0-366a-4aef-a470-11f788a27283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751884a-5150-4316-9db2-15e9b528581c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-60-20-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6fec98",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 7, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 80 - 50 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76887ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84858f-4bb4-4f71-8aed-0437f66fbad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e4c7f-40aa-4478-9a3d-48f7b4665699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bacc3e1-a68a-4915-84be-d7f119e5dcb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824cb04-c96e-44b8-bb71-77c830d24d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d489cb-9856-4d8e-a93f-d4ccadcb987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "table_3_classes[:76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565bd87-c60d-43cb-b844-ea1f6bf9497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = table_3_classes.iloc[::4][6:19]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93fee26-8fb1-4049-90cb-76f7bbaecf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = table_3_classes.iloc[1::4][6:19]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458a5ae-e8e6-422a-804c-3b625a11a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = table_3_classes.iloc[2::4][6:19]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d388eff-4904-4752-878f-0cc510d7204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = table_3_classes.iloc[3::4][6:19]\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6162045a",
   "metadata": {},
   "source": [
    "best performing model until now: \n",
    "*  cut-off 0.5: 4 layers, 17-60-40-3\n",
    "*  cut-off 0.1: 4 layers, 17-60-20-3\n",
    "*  cut-off 0.05: 4 layers, 17-80-50-3\n",
    "*  cut-off 0.01: 4 layers, 17-80-50-3\n",
    "\n",
    "For comparibility we decide to use 17-80-50-3 as \"best model\" for all the next models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889c99c",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 1, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb81d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,9,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a364cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a783da-7da2-4414-b1de-6c64d873cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_median: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db798375-d7e0-4105-a57f-e88bb984a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_median: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1359623-79e9-49df-919c-719d1894a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_median: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd57a00-396b-4f40-8675-2bf296502abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_median: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62121ea3",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 2, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896dd70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,7,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9418b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551fdd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c59552-a1a7-4d74-b63c-6ab1fad8013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_mean: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb968d-71f0-4b5a-98a1-d2afbc1ef100",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_mean: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7568a41-30a2-460b-acd7-ba295ee36eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_mean: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3d2b3-f930-4696-bac9-3bc4be287d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_mean: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2573f11",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 3, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,5,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dbeb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af8df9-793d-426a-b94e-ae36d2276b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_min: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0d6e9-d704-45d4-9fee-03ccb037abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_min: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cfa07-512b-4d78-9788-23f2bc889c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_min: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020df786-30cc-4145-9829-acd0333a02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_min: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b495992",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 4, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,6,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51793d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f6b23-0776-443e-bdfd-7f0087c7555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_max: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db6f28-ee20-4380-a070-33c608317ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_max: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dedaac-4ff5-48b3-8353-6abb30bc66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_max: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a027e74-cc46-4370-b7e4-ee2d2a1cc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_max: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e60356",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 5, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.25-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f05e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0f4c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,8,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8eac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc1d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a17189-1774-44b7-8b9d-3566b3f1c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_q25: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b812ee3-c4ac-47bf-bd51-4601dded3d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_q25: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2bd1b-7b18-4bfe-bab0-03e6136bf72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_q25: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2fe1e6-fda9-4bc7-b4cf-d72b96cb3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_q25: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216add0b",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 6, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.75-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deacd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,10,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1612a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220a45c-7014-47b4-9258-d6c0e1eb85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_q75: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886a94ae-8b3f-492c-9a78-af47454dfa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_q75: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a4838-fd1d-489c-9cb1-a0bf630dda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_q75: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe632b03-ddfa-4ec6-9d80-e5cd899a1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_q75: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c852afb",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, custom layer, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  Adding a custom layer, where we group all features occuring multiple times together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13529344",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 1)  \n",
    "        self.fc2 = nn.Linear(1, 1)  \n",
    "        self.fc3 = nn.Linear(1, 1)  \n",
    "        self.fc4 = nn.Linear(1, 1)  \n",
    "        self.fc5 = nn.Linear(1, 1)  \n",
    "        self.fc6 = nn.Linear(6, 1)  \n",
    "        self.fc7 = nn.Linear(6, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        grouped_features = torch.cat((self.fc1(x[:, 0:1]), self.fc2(x[:, 1:2]), self.fc3(x[:, 2:3]), self.fc4(x[:, 3:4]), \n",
    "                                      self.fc5(x[:, 4:5]), self.fc6(x[:, 5:11]), self.fc7(x[:, 11:17])), dim=1)\n",
    "        \n",
    "        return grouped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.custom_layer = CustomLayer()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.custom_layer(x)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee277fab-ab7e-4ce0-9050-c2932c946359",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, custom: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44466c-6757-4845-8358-ea6251e2f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, custom: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab05a3e-9ef0-4c01-908b-88c6f04b61e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, custom: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb448d4a-3ab1-47bd-bdf8-7cb82f1b0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, custom: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2088d-dff8-454c-a8ed-87d71b45dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6aec2f",
   "metadata": {},
   "source": [
    "### Deep MLP with time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "925b6880-d278-436c-81dc-587a2808c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.values).float()  # Convert DataFrame to tensor\n",
    "        self.y = torch.from_numpy(y.values).float()  # Convert DataFrame to tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d0ad622c-7c29-43d9-bca2-d48eb3437a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_regression(X_training, y_training, X_validation, y_validation, text):\n",
    "    custom_dataset = CustomDataset(X_training, y_training)\n",
    "    trainloader = torch.utils.data.DataLoader(custom_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "    mlp = MLP(random_seed=20)\n",
    "    \n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adagrad(mlp.parameters(), lr=0.01)\n",
    "    \n",
    "    val_data = torch.tensor(X_validation.values, dtype=torch.float32)\n",
    "    val_targets = torch.tensor(y_validation.values, dtype=torch.float32)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(0,300):\n",
    "        print(f'Starting Epoch {epoch+1}')\n",
    "    \n",
    "        current_loss = 0.0\n",
    "    \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.float(), targets.float()\n",
    "            targets = targets.reshape((targets.shape[0], 1))\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = mlp(inputs)\n",
    "    \n",
    "            loss = loss_function(outputs, targets)\n",
    "    \n",
    "            loss.backward()\n",
    "    \n",
    "            optimizer.step()\n",
    "    \n",
    "            current_loss += loss.item()\n",
    "    \n",
    "        print(current_loss/len(trainloader))\n",
    "    \n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = mlp(val_data)\n",
    "            val_loss = loss_function(val_outputs, val_targets.reshape(val_targets.shape[0], 1)).item()\n",
    "            print(f'Validation loss: {val_loss}')\n",
    "            print(\"mse\", mean_squared_error(np.array(val_targets), np.array(val_outputs.squeeze().tolist())))\n",
    "    \n",
    "        # Check if this is the best model so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = deepcopy(mlp.state_dict())\n",
    "            print(f'New best model found at epoch {epoch+1} with validation loss {best_val_loss}')\n",
    "    \n",
    "    \n",
    "    print(\"Training has completed\")\n",
    "\n",
    "    mlp2 = MLP(random_seed=20)\n",
    "    mlp2.load_state_dict(best_model_state)\n",
    "\n",
    "    mlp2.eval() \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = mlp2(val_data)\n",
    "        predicted_labels = outputs.squeeze().tolist()\n",
    "    \n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    val_targets = np.array(val_targets)\n",
    "    \n",
    "    mse = mean_squared_error(val_targets, predicted_labels)\n",
    "    mae = mean_absolute_error(val_targets, predicted_labels)\n",
    "    r2 = r2_score(val_targets, predicted_labels)\n",
    "    \n",
    "    table_time_diff.loc[text] = [mse, mae, r2, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b3dde-40da-4508-b3ab-f21545d5a14d",
   "metadata": {},
   "source": [
    "#### 3-layer MLP\n",
    "*  Loss: MSE\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca9fc6-2fa6-4b8e-a43c-5a082d450165",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 1\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 5 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "7030ab18-5d89-446f-a151-cdc4cb0cfdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "1f527fb9-3fbb-4e56-9ac3-33ecd7ce92e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.4748054444789886\n",
      "Validation loss: 2.3131253719329834\n",
      "mse 2.3131253145312716\n",
      "New best model found at epoch 1 with validation loss 2.3131253719329834\n",
      "Starting Epoch 2\n",
      "2.1883013546466827\n",
      "Validation loss: 2.1612210273742676\n",
      "mse 2.1612210580650917\n",
      "New best model found at epoch 2 with validation loss 2.1612210273742676\n",
      "Starting Epoch 3\n",
      "2.091853156685829\n",
      "Validation loss: 2.0660154819488525\n",
      "mse 2.0660156652306183\n",
      "New best model found at epoch 3 with validation loss 2.0660154819488525\n",
      "Starting Epoch 4\n",
      "2.0264879018068314\n",
      "Validation loss: 1.9931461811065674\n",
      "mse 1.9931460773856788\n",
      "New best model found at epoch 4 with validation loss 1.9931461811065674\n",
      "Starting Epoch 5\n",
      "1.9772141476472218\n",
      "Validation loss: 1.937849521636963\n",
      "mse 1.9378496496607702\n",
      "New best model found at epoch 5 with validation loss 1.937849521636963\n",
      "Starting Epoch 6\n",
      "1.940019925435384\n",
      "Validation loss: 1.8976496458053589\n",
      "mse 1.897649583564918\n",
      "New best model found at epoch 6 with validation loss 1.8976496458053589\n",
      "Starting Epoch 7\n",
      "1.9114986906449\n",
      "Validation loss: 1.8642171621322632\n",
      "mse 1.8642172208902483\n",
      "New best model found at epoch 7 with validation loss 1.8642171621322632\n",
      "Starting Epoch 8\n",
      "1.888767381509145\n",
      "Validation loss: 1.8382431268692017\n",
      "mse 1.8382430666710612\n",
      "New best model found at epoch 8 with validation loss 1.8382431268692017\n",
      "Starting Epoch 9\n",
      "1.8697325338919957\n",
      "Validation loss: 1.8170068264007568\n",
      "mse 1.8170067535597296\n",
      "New best model found at epoch 9 with validation loss 1.8170068264007568\n",
      "Starting Epoch 10\n",
      "1.853279784321785\n",
      "Validation loss: 1.7978928089141846\n",
      "mse 1.7978927283017092\n",
      "New best model found at epoch 10 with validation loss 1.7978928089141846\n",
      "Starting Epoch 11\n",
      "1.8386985162893932\n",
      "Validation loss: 1.7809451818466187\n",
      "mse 1.7809453470572174\n",
      "New best model found at epoch 11 with validation loss 1.7809451818466187\n",
      "Starting Epoch 12\n",
      "1.8250610033671062\n",
      "Validation loss: 1.7649680376052856\n",
      "mse 1.7649680000548107\n",
      "New best model found at epoch 12 with validation loss 1.7649680376052856\n",
      "Starting Epoch 13\n",
      "1.812946394085884\n",
      "Validation loss: 1.7505546808242798\n",
      "mse 1.750554619817302\n",
      "New best model found at epoch 13 with validation loss 1.7505546808242798\n",
      "Starting Epoch 14\n",
      "1.8014616072177887\n",
      "Validation loss: 1.7369518280029297\n",
      "mse 1.7369516483010519\n",
      "New best model found at epoch 14 with validation loss 1.7369518280029297\n",
      "Starting Epoch 15\n",
      "1.7907029141982396\n",
      "Validation loss: 1.7238837480545044\n",
      "mse 1.7238836278432559\n",
      "New best model found at epoch 15 with validation loss 1.7238837480545044\n",
      "Starting Epoch 16\n",
      "1.780742014447848\n",
      "Validation loss: 1.7114955186843872\n",
      "mse 1.7114955001934768\n",
      "New best model found at epoch 16 with validation loss 1.7114955186843872\n",
      "Starting Epoch 17\n",
      "1.7714360803365707\n",
      "Validation loss: 1.6999974250793457\n",
      "mse 1.6999974581669055\n",
      "New best model found at epoch 17 with validation loss 1.6999974250793457\n",
      "Starting Epoch 18\n",
      "1.7626558740933735\n",
      "Validation loss: 1.6893471479415894\n",
      "mse 1.6893470921876743\n",
      "New best model found at epoch 18 with validation loss 1.6893471479415894\n",
      "Starting Epoch 19\n",
      "1.7544285158316295\n",
      "Validation loss: 1.6792402267456055\n",
      "mse 1.6792403438824266\n",
      "New best model found at epoch 19 with validation loss 1.6792402267456055\n",
      "Starting Epoch 20\n",
      "1.7466975351174672\n",
      "Validation loss: 1.6697659492492676\n",
      "mse 1.6697659748663773\n",
      "New best model found at epoch 20 with validation loss 1.6697659492492676\n",
      "Starting Epoch 21\n",
      "1.7393826991319656\n",
      "Validation loss: 1.6604843139648438\n",
      "mse 1.6604843837888201\n",
      "New best model found at epoch 21 with validation loss 1.6604843139648438\n",
      "Starting Epoch 22\n",
      "1.7321959485610325\n",
      "Validation loss: 1.6517845392227173\n",
      "mse 1.651784489368172\n",
      "New best model found at epoch 22 with validation loss 1.6517845392227173\n",
      "Starting Epoch 23\n",
      "1.7252616981665294\n",
      "Validation loss: 1.6434458494186401\n",
      "mse 1.6434457813106995\n",
      "New best model found at epoch 23 with validation loss 1.6434458494186401\n",
      "Starting Epoch 24\n",
      "1.7186764280001323\n",
      "Validation loss: 1.6356312036514282\n",
      "mse 1.635630962913215\n",
      "New best model found at epoch 24 with validation loss 1.6356312036514282\n",
      "Starting Epoch 25\n",
      "1.7123938252528508\n",
      "Validation loss: 1.6282027959823608\n",
      "mse 1.6282028259457402\n",
      "New best model found at epoch 25 with validation loss 1.6282027959823608\n",
      "Starting Epoch 26\n",
      "1.7064276834328969\n",
      "Validation loss: 1.621036410331726\n",
      "mse 1.621036417742046\n",
      "New best model found at epoch 26 with validation loss 1.621036410331726\n",
      "Starting Epoch 27\n",
      "1.700672412912051\n",
      "Validation loss: 1.6144967079162598\n",
      "mse 1.6144967483073243\n",
      "New best model found at epoch 27 with validation loss 1.6144967079162598\n",
      "Starting Epoch 28\n",
      "1.6951708147923152\n",
      "Validation loss: 1.608168363571167\n",
      "mse 1.6081684889819183\n",
      "New best model found at epoch 28 with validation loss 1.608168363571167\n",
      "Starting Epoch 29\n",
      "1.689805383483569\n",
      "Validation loss: 1.60201895236969\n",
      "mse 1.6020188035380836\n",
      "New best model found at epoch 29 with validation loss 1.60201895236969\n",
      "Starting Epoch 30\n",
      "1.6845223009586334\n",
      "Validation loss: 1.596157193183899\n",
      "mse 1.5961573923273251\n",
      "New best model found at epoch 30 with validation loss 1.596157193183899\n",
      "Starting Epoch 31\n",
      "1.6794963677724202\n",
      "Validation loss: 1.5905475616455078\n",
      "mse 1.5905474934769683\n",
      "New best model found at epoch 31 with validation loss 1.5905475616455078\n",
      "Starting Epoch 32\n",
      "1.6747458229462306\n",
      "Validation loss: 1.585133671760559\n",
      "mse 1.58513361337834\n",
      "New best model found at epoch 32 with validation loss 1.585133671760559\n",
      "Starting Epoch 33\n",
      "1.6701593051354091\n",
      "Validation loss: 1.5798695087432861\n",
      "mse 1.579869482292412\n",
      "New best model found at epoch 33 with validation loss 1.5798695087432861\n",
      "Starting Epoch 34\n",
      "1.6657014787197113\n",
      "Validation loss: 1.5749642848968506\n",
      "mse 1.5749642644128194\n",
      "New best model found at epoch 34 with validation loss 1.5749642848968506\n",
      "Starting Epoch 35\n",
      "1.6614624311526616\n",
      "Validation loss: 1.5702133178710938\n",
      "mse 1.570213226712756\n",
      "New best model found at epoch 35 with validation loss 1.5702133178710938\n",
      "Starting Epoch 36\n",
      "1.6573497305313747\n",
      "Validation loss: 1.5656543970108032\n",
      "mse 1.5656545038582024\n",
      "New best model found at epoch 36 with validation loss 1.5656543970108032\n",
      "Starting Epoch 37\n",
      "1.6533123701810837\n",
      "Validation loss: 1.561267614364624\n",
      "mse 1.561267589778433\n",
      "New best model found at epoch 37 with validation loss 1.561267614364624\n",
      "Starting Epoch 38\n",
      "1.6494549264510472\n",
      "Validation loss: 1.5570496320724487\n",
      "mse 1.5570495417885901\n",
      "New best model found at epoch 38 with validation loss 1.5570496320724487\n",
      "Starting Epoch 39\n",
      "1.645730550090472\n",
      "Validation loss: 1.5531718730926514\n",
      "mse 1.5531719775404604\n",
      "New best model found at epoch 39 with validation loss 1.5531718730926514\n",
      "Starting Epoch 40\n",
      "1.6421605696280797\n",
      "Validation loss: 1.5497363805770874\n",
      "mse 1.5497363483442288\n",
      "New best model found at epoch 40 with validation loss 1.5497363805770874\n",
      "Starting Epoch 41\n",
      "1.6387436240911484\n",
      "Validation loss: 1.5458122491836548\n",
      "mse 1.545812361416004\n",
      "New best model found at epoch 41 with validation loss 1.5458122491836548\n",
      "Starting Epoch 42\n",
      "1.6353524972995122\n",
      "Validation loss: 1.542009949684143\n",
      "mse 1.5420098465252614\n",
      "New best model found at epoch 42 with validation loss 1.542009949684143\n",
      "Starting Epoch 43\n",
      "1.6321358730395634\n",
      "Validation loss: 1.5388089418411255\n",
      "mse 1.5388090009403035\n",
      "New best model found at epoch 43 with validation loss 1.5388089418411255\n",
      "Starting Epoch 44\n",
      "1.6289693812529247\n",
      "Validation loss: 1.5350310802459717\n",
      "mse 1.5350310045800029\n",
      "New best model found at epoch 44 with validation loss 1.5350310802459717\n",
      "Starting Epoch 45\n",
      "1.625899185736974\n",
      "Validation loss: 1.5320106744766235\n",
      "mse 1.5320106794239383\n",
      "New best model found at epoch 45 with validation loss 1.5320106744766235\n",
      "Starting Epoch 46\n",
      "1.6229789108037949\n",
      "Validation loss: 1.5288313627243042\n",
      "mse 1.528831317205653\n",
      "New best model found at epoch 46 with validation loss 1.5288313627243042\n",
      "Starting Epoch 47\n",
      "1.6201644589503605\n",
      "Validation loss: 1.5256576538085938\n",
      "mse 1.5256576672493338\n",
      "New best model found at epoch 47 with validation loss 1.5256576538085938\n",
      "Starting Epoch 48\n",
      "1.6174022853374481\n",
      "Validation loss: 1.5226874351501465\n",
      "mse 1.5226874800383288\n",
      "New best model found at epoch 48 with validation loss 1.5226874351501465\n",
      "Starting Epoch 49\n",
      "1.614746128519376\n",
      "Validation loss: 1.5197995901107788\n",
      "mse 1.5197993991272776\n",
      "New best model found at epoch 49 with validation loss 1.5197995901107788\n",
      "Starting Epoch 50\n",
      "1.6121468593676884\n",
      "Validation loss: 1.5170522928237915\n",
      "mse 1.5170523046263495\n",
      "New best model found at epoch 50 with validation loss 1.5170522928237915\n",
      "Starting Epoch 51\n",
      "1.6096465984980266\n",
      "Validation loss: 1.5143861770629883\n",
      "mse 1.5143860841348096\n",
      "New best model found at epoch 51 with validation loss 1.5143861770629883\n",
      "Starting Epoch 52\n",
      "1.6071897745132446\n",
      "Validation loss: 1.5118366479873657\n",
      "mse 1.5118366940585637\n",
      "New best model found at epoch 52 with validation loss 1.5118366479873657\n",
      "Starting Epoch 53\n",
      "1.6048272748788197\n",
      "Validation loss: 1.5093342065811157\n",
      "mse 1.5093341988953737\n",
      "New best model found at epoch 53 with validation loss 1.5093342065811157\n",
      "Starting Epoch 54\n",
      "1.6025252938270569\n",
      "Validation loss: 1.506940245628357\n",
      "mse 1.506940261664367\n",
      "New best model found at epoch 54 with validation loss 1.506940245628357\n",
      "Starting Epoch 55\n",
      "1.6002784272034962\n",
      "Validation loss: 1.5046145915985107\n",
      "mse 1.5046146469256851\n",
      "New best model found at epoch 55 with validation loss 1.5046145915985107\n",
      "Starting Epoch 56\n",
      "1.5980899631977081\n",
      "Validation loss: 1.502366542816162\n",
      "mse 1.502366448837207\n",
      "New best model found at epoch 56 with validation loss 1.502366542816162\n",
      "Starting Epoch 57\n",
      "1.5959822684526443\n",
      "Validation loss: 1.5002195835113525\n",
      "mse 1.500219506796896\n",
      "New best model found at epoch 57 with validation loss 1.5002195835113525\n",
      "Starting Epoch 58\n",
      "1.5938577701648076\n",
      "Validation loss: 1.4980816841125488\n",
      "mse 1.4980816117932492\n",
      "New best model found at epoch 58 with validation loss 1.4980816841125488\n",
      "Starting Epoch 59\n",
      "1.591787725687027\n",
      "Validation loss: 1.4960362911224365\n",
      "mse 1.4960362217028822\n",
      "New best model found at epoch 59 with validation loss 1.4960362911224365\n",
      "Starting Epoch 60\n",
      "1.589828183253606\n",
      "Validation loss: 1.4942541122436523\n",
      "mse 1.494254098749849\n",
      "New best model found at epoch 60 with validation loss 1.4942541122436523\n",
      "Starting Epoch 61\n",
      "1.587972030043602\n",
      "Validation loss: 1.4923253059387207\n",
      "mse 1.492325226421652\n",
      "New best model found at epoch 61 with validation loss 1.4923253059387207\n",
      "Starting Epoch 62\n",
      "1.5861056099335353\n",
      "Validation loss: 1.4904171228408813\n",
      "mse 1.4904171254166099\n",
      "New best model found at epoch 62 with validation loss 1.4904171228408813\n",
      "Starting Epoch 63\n",
      "1.5842448770999908\n",
      "Validation loss: 1.4886410236358643\n",
      "mse 1.4886409730856947\n",
      "New best model found at epoch 63 with validation loss 1.4886410236358643\n",
      "Starting Epoch 64\n",
      "1.5824900815884273\n",
      "Validation loss: 1.4868440628051758\n",
      "mse 1.4868439395341233\n",
      "New best model found at epoch 64 with validation loss 1.4868440628051758\n",
      "Starting Epoch 65\n",
      "1.5807364284992218\n",
      "Validation loss: 1.4849557876586914\n",
      "mse 1.4849559719954497\n",
      "New best model found at epoch 65 with validation loss 1.4849557876586914\n",
      "Starting Epoch 66\n",
      "1.5789708346128464\n",
      "Validation loss: 1.4832279682159424\n",
      "mse 1.483227956799028\n",
      "New best model found at epoch 66 with validation loss 1.4832279682159424\n",
      "Starting Epoch 67\n",
      "1.57728977004687\n",
      "Validation loss: 1.4815977811813354\n",
      "mse 1.481597610094981\n",
      "New best model found at epoch 67 with validation loss 1.4815977811813354\n",
      "Starting Epoch 68\n",
      "1.5756562650203705\n",
      "Validation loss: 1.4799612760543823\n",
      "mse 1.4799612494007626\n",
      "New best model found at epoch 68 with validation loss 1.4799612760543823\n",
      "Starting Epoch 69\n",
      "1.5740616122881572\n",
      "Validation loss: 1.4784048795700073\n",
      "mse 1.4784050040397936\n",
      "New best model found at epoch 69 with validation loss 1.4784048795700073\n",
      "Starting Epoch 70\n",
      "1.5724939157565434\n",
      "Validation loss: 1.4768823385238647\n",
      "mse 1.476882302810701\n",
      "New best model found at epoch 70 with validation loss 1.4768823385238647\n",
      "Starting Epoch 71\n",
      "1.5709566126267116\n",
      "Validation loss: 1.4752908945083618\n",
      "mse 1.4752907347236726\n",
      "New best model found at epoch 71 with validation loss 1.4752908945083618\n",
      "Starting Epoch 72\n",
      "1.5694316079219182\n",
      "Validation loss: 1.4737050533294678\n",
      "mse 1.473705118256634\n",
      "New best model found at epoch 72 with validation loss 1.4737050533294678\n",
      "Starting Epoch 73\n",
      "1.567966769138972\n",
      "Validation loss: 1.4722579717636108\n",
      "mse 1.472258064685271\n",
      "New best model found at epoch 73 with validation loss 1.4722579717636108\n",
      "Starting Epoch 74\n",
      "1.566518947482109\n",
      "Validation loss: 1.4707585573196411\n",
      "mse 1.4707585070810463\n",
      "New best model found at epoch 74 with validation loss 1.4707585573196411\n",
      "Starting Epoch 75\n",
      "1.5651085029045742\n",
      "Validation loss: 1.4693059921264648\n",
      "mse 1.4693059978061316\n",
      "New best model found at epoch 75 with validation loss 1.4693059921264648\n",
      "Starting Epoch 76\n",
      "1.5636784931023915\n",
      "Validation loss: 1.4680994749069214\n",
      "mse 1.4680994801183347\n",
      "New best model found at epoch 76 with validation loss 1.4680994749069214\n",
      "Starting Epoch 77\n",
      "1.5623849133650463\n",
      "Validation loss: 1.466732144355774\n",
      "mse 1.4667320502426902\n",
      "New best model found at epoch 77 with validation loss 1.466732144355774\n",
      "Starting Epoch 78\n",
      "1.5610074698925018\n",
      "Validation loss: 1.4655171632766724\n",
      "mse 1.4655171044789461\n",
      "New best model found at epoch 78 with validation loss 1.4655171632766724\n",
      "Starting Epoch 79\n",
      "1.559746618072192\n",
      "Validation loss: 1.4642342329025269\n",
      "mse 1.4642340430825012\n",
      "New best model found at epoch 79 with validation loss 1.4642342329025269\n",
      "Starting Epoch 80\n",
      "1.5584743420283\n",
      "Validation loss: 1.4633593559265137\n",
      "mse 1.4633591727116388\n",
      "New best model found at epoch 80 with validation loss 1.4633593559265137\n",
      "Starting Epoch 81\n",
      "1.5573284725348155\n",
      "Validation loss: 1.4621633291244507\n",
      "mse 1.4621633230159132\n",
      "New best model found at epoch 81 with validation loss 1.4621633291244507\n",
      "Starting Epoch 82\n",
      "1.556143472592036\n",
      "Validation loss: 1.4609932899475098\n",
      "mse 1.4609932967693195\n",
      "New best model found at epoch 82 with validation loss 1.4609932899475098\n",
      "Starting Epoch 83\n",
      "1.5549847384293873\n",
      "Validation loss: 1.459856390953064\n",
      "mse 1.45985629629759\n",
      "New best model found at epoch 83 with validation loss 1.459856390953064\n",
      "Starting Epoch 84\n",
      "1.55384960770607\n",
      "Validation loss: 1.4587287902832031\n",
      "mse 1.4587288000331606\n",
      "New best model found at epoch 84 with validation loss 1.4587287902832031\n",
      "Starting Epoch 85\n",
      "1.552735964457194\n",
      "Validation loss: 1.4576177597045898\n",
      "mse 1.4576177824092234\n",
      "New best model found at epoch 85 with validation loss 1.4576177597045898\n",
      "Starting Epoch 86\n",
      "1.551648572087288\n",
      "Validation loss: 1.4564285278320312\n",
      "mse 1.4564284171740969\n",
      "New best model found at epoch 86 with validation loss 1.4564285278320312\n",
      "Starting Epoch 87\n",
      "1.5505791902542114\n",
      "Validation loss: 1.4553534984588623\n",
      "mse 1.4553535404844362\n",
      "New best model found at epoch 87 with validation loss 1.4553534984588623\n",
      "Starting Epoch 88\n",
      "1.549530064066251\n",
      "Validation loss: 1.4542845487594604\n",
      "mse 1.4542845825331412\n",
      "New best model found at epoch 88 with validation loss 1.4542845487594604\n",
      "Starting Epoch 89\n",
      "1.5484909911950429\n",
      "Validation loss: 1.4532558917999268\n",
      "mse 1.4532559170358668\n",
      "New best model found at epoch 89 with validation loss 1.4532558917999268\n",
      "Starting Epoch 90\n",
      "1.5474778066078823\n",
      "Validation loss: 1.4522459506988525\n",
      "mse 1.4522459246832187\n",
      "New best model found at epoch 90 with validation loss 1.4522459506988525\n",
      "Starting Epoch 91\n",
      "1.546485349535942\n",
      "Validation loss: 1.4508161544799805\n",
      "mse 1.4508162733614753\n",
      "New best model found at epoch 91 with validation loss 1.4508161544799805\n",
      "Starting Epoch 92\n",
      "1.545436720053355\n",
      "Validation loss: 1.449869155883789\n",
      "mse 1.4498692113248093\n",
      "New best model found at epoch 92 with validation loss 1.449869155883789\n",
      "Starting Epoch 93\n",
      "1.5444818586111069\n",
      "Validation loss: 1.4489779472351074\n",
      "mse 1.4489780259313443\n",
      "New best model found at epoch 93 with validation loss 1.4489779472351074\n",
      "Starting Epoch 94\n",
      "1.543545330564181\n",
      "Validation loss: 1.4485622644424438\n",
      "mse 1.4485623276979158\n",
      "New best model found at epoch 94 with validation loss 1.4485622644424438\n",
      "Starting Epoch 95\n",
      "1.5426778048276901\n",
      "Validation loss: 1.4472168684005737\n",
      "mse 1.4472168256208084\n",
      "New best model found at epoch 95 with validation loss 1.4472168684005737\n",
      "Starting Epoch 96\n",
      "1.5417182197173436\n",
      "Validation loss: 1.4463868141174316\n",
      "mse 1.4463868430364673\n",
      "New best model found at epoch 96 with validation loss 1.4463868141174316\n",
      "Starting Epoch 97\n",
      "1.540833741426468\n",
      "Validation loss: 1.4455064535140991\n",
      "mse 1.4455063711993095\n",
      "New best model found at epoch 97 with validation loss 1.4455064535140991\n",
      "Starting Epoch 98\n",
      "1.5399459252754848\n",
      "Validation loss: 1.4447413682937622\n",
      "mse 1.4447413531000763\n",
      "New best model found at epoch 98 with validation loss 1.4447413682937622\n",
      "Starting Epoch 99\n",
      "1.539091298977534\n",
      "Validation loss: 1.4439224004745483\n",
      "mse 1.4439225149218164\n",
      "New best model found at epoch 99 with validation loss 1.4439224004745483\n",
      "Starting Epoch 100\n",
      "1.5382383366425831\n",
      "Validation loss: 1.4431827068328857\n",
      "mse 1.4431826792939646\n",
      "New best model found at epoch 100 with validation loss 1.4431827068328857\n",
      "Starting Epoch 101\n",
      "1.5374123553435008\n",
      "Validation loss: 1.442411184310913\n",
      "mse 1.4424111650726874\n",
      "New best model found at epoch 101 with validation loss 1.442411184310913\n",
      "Starting Epoch 102\n",
      "1.5365912914276123\n",
      "Validation loss: 1.4419087171554565\n",
      "mse 1.4419086778694326\n",
      "New best model found at epoch 102 with validation loss 1.4419087171554565\n",
      "Starting Epoch 103\n",
      "1.535812998811404\n",
      "Validation loss: 1.4409047365188599\n",
      "mse 1.4409047456055888\n",
      "New best model found at epoch 103 with validation loss 1.4409047365188599\n",
      "Starting Epoch 104\n",
      "1.5349775503079097\n",
      "Validation loss: 1.4402239322662354\n",
      "mse 1.4402239071031908\n",
      "New best model found at epoch 104 with validation loss 1.4402239322662354\n",
      "Starting Epoch 105\n",
      "1.53420257071654\n",
      "Validation loss: 1.439715027809143\n",
      "mse 1.4397149306489967\n",
      "New best model found at epoch 105 with validation loss 1.439715027809143\n",
      "Starting Epoch 106\n",
      "1.5334624747435253\n",
      "Validation loss: 1.4387873411178589\n",
      "mse 1.4387875066917384\n",
      "New best model found at epoch 106 with validation loss 1.4387873411178589\n",
      "Starting Epoch 107\n",
      "1.5326565603415172\n",
      "Validation loss: 1.4383350610733032\n",
      "mse 1.4383350969085404\n",
      "New best model found at epoch 107 with validation loss 1.4383350610733032\n",
      "Starting Epoch 108\n",
      "1.5319463511308034\n",
      "Validation loss: 1.437470555305481\n",
      "mse 1.4374703435169198\n",
      "New best model found at epoch 108 with validation loss 1.437470555305481\n",
      "Starting Epoch 109\n",
      "1.5311784148216248\n",
      "Validation loss: 1.436830997467041\n",
      "mse 1.436830997640669\n",
      "New best model found at epoch 109 with validation loss 1.436830997467041\n",
      "Starting Epoch 110\n",
      "1.5304610133171082\n",
      "Validation loss: 1.4362316131591797\n",
      "mse 1.4362315905488496\n",
      "New best model found at epoch 110 with validation loss 1.4362316131591797\n",
      "Starting Epoch 111\n",
      "1.5297624866167705\n",
      "Validation loss: 1.4355007410049438\n",
      "mse 1.4355007222298128\n",
      "New best model found at epoch 111 with validation loss 1.4355007410049438\n",
      "Starting Epoch 112\n",
      "1.5290312220652897\n",
      "Validation loss: 1.4348551034927368\n",
      "mse 1.4348551209642861\n",
      "New best model found at epoch 112 with validation loss 1.4348551034927368\n",
      "Starting Epoch 113\n",
      "1.5283380796511967\n",
      "Validation loss: 1.4342262744903564\n",
      "mse 1.4342262701509028\n",
      "New best model found at epoch 113 with validation loss 1.4342262744903564\n",
      "Starting Epoch 114\n",
      "1.5276529242595036\n",
      "Validation loss: 1.4336555004119873\n",
      "mse 1.4336555594343334\n",
      "New best model found at epoch 114 with validation loss 1.4336555004119873\n",
      "Starting Epoch 115\n",
      "1.5270125567913055\n",
      "Validation loss: 1.4329873323440552\n",
      "mse 1.4329873469869367\n",
      "New best model found at epoch 115 with validation loss 1.4329873323440552\n",
      "Starting Epoch 116\n",
      "1.526311958829562\n",
      "Validation loss: 1.4324032068252563\n",
      "mse 1.4324031480582613\n",
      "New best model found at epoch 116 with validation loss 1.4324032068252563\n",
      "Starting Epoch 117\n",
      "1.5256559203068416\n",
      "Validation loss: 1.4318374395370483\n",
      "mse 1.4318375611009164\n",
      "New best model found at epoch 117 with validation loss 1.4318374395370483\n",
      "Starting Epoch 118\n",
      "1.5250083605448406\n",
      "Validation loss: 1.4313127994537354\n",
      "mse 1.431312877007188\n",
      "New best model found at epoch 118 with validation loss 1.4313127994537354\n",
      "Starting Epoch 119\n",
      "1.5244040687878926\n",
      "Validation loss: 1.430687665939331\n",
      "mse 1.4306876333262317\n",
      "New best model found at epoch 119 with validation loss 1.430687665939331\n",
      "Starting Epoch 120\n",
      "1.5237360497315724\n",
      "Validation loss: 1.4301443099975586\n",
      "mse 1.430144348867261\n",
      "New best model found at epoch 120 with validation loss 1.4301443099975586\n",
      "Starting Epoch 121\n",
      "1.5231127838293712\n",
      "Validation loss: 1.4296146631240845\n",
      "mse 1.42961468555838\n",
      "New best model found at epoch 121 with validation loss 1.4296146631240845\n",
      "Starting Epoch 122\n",
      "1.5225057403246562\n",
      "Validation loss: 1.4290846586227417\n",
      "mse 1.4290846912555446\n",
      "New best model found at epoch 122 with validation loss 1.4290846586227417\n",
      "Starting Epoch 123\n",
      "1.5219188233216603\n",
      "Validation loss: 1.428531527519226\n",
      "mse 1.4285316899068605\n",
      "New best model found at epoch 123 with validation loss 1.428531527519226\n",
      "Starting Epoch 124\n",
      "1.521313841144244\n",
      "Validation loss: 1.4279975891113281\n",
      "mse 1.4279976305476032\n",
      "New best model found at epoch 124 with validation loss 1.4279975891113281\n",
      "Starting Epoch 125\n",
      "1.5207541833321254\n",
      "Validation loss: 1.4274994134902954\n",
      "mse 1.427499386444749\n",
      "New best model found at epoch 125 with validation loss 1.4274994134902954\n",
      "Starting Epoch 126\n",
      "1.5201808363199234\n",
      "Validation loss: 1.4269936084747314\n",
      "mse 1.426993755559302\n",
      "New best model found at epoch 126 with validation loss 1.4269936084747314\n",
      "Starting Epoch 127\n",
      "1.5196048816045125\n",
      "Validation loss: 1.4264862537384033\n",
      "mse 1.4264861959973854\n",
      "New best model found at epoch 127 with validation loss 1.4264862537384033\n",
      "Starting Epoch 128\n",
      "1.519036168853442\n",
      "Validation loss: 1.4259827136993408\n",
      "mse 1.4259827248257042\n",
      "New best model found at epoch 128 with validation loss 1.4259827136993408\n",
      "Starting Epoch 129\n",
      "1.5184735854466755\n",
      "Validation loss: 1.425485610961914\n",
      "mse 1.425485732537495\n",
      "New best model found at epoch 129 with validation loss 1.425485610961914\n",
      "Starting Epoch 130\n",
      "1.5179223169883092\n",
      "Validation loss: 1.4249604940414429\n",
      "mse 1.4249605351229782\n",
      "New best model found at epoch 130 with validation loss 1.4249604940414429\n",
      "Starting Epoch 131\n",
      "1.5173675765593846\n",
      "Validation loss: 1.4244956970214844\n",
      "mse 1.4244956235411443\n",
      "New best model found at epoch 131 with validation loss 1.4244956970214844\n",
      "Starting Epoch 132\n",
      "1.516829897960027\n",
      "Validation loss: 1.424006700515747\n",
      "mse 1.4240066777551867\n",
      "New best model found at epoch 132 with validation loss 1.424006700515747\n",
      "Starting Epoch 133\n",
      "1.51629339158535\n",
      "Validation loss: 1.4235026836395264\n",
      "mse 1.423502631582713\n",
      "New best model found at epoch 133 with validation loss 1.4235026836395264\n",
      "Starting Epoch 134\n",
      "1.5157548139492671\n",
      "Validation loss: 1.4230616092681885\n",
      "mse 1.423061699427231\n",
      "New best model found at epoch 134 with validation loss 1.4230616092681885\n",
      "Starting Epoch 135\n",
      "1.5152264734109242\n",
      "Validation loss: 1.4226187467575073\n",
      "mse 1.42261885285356\n",
      "New best model found at epoch 135 with validation loss 1.4226187467575073\n",
      "Starting Epoch 136\n",
      "1.5147099991639454\n",
      "Validation loss: 1.422144889831543\n",
      "mse 1.4221448695660692\n",
      "New best model found at epoch 136 with validation loss 1.422144889831543\n",
      "Starting Epoch 137\n",
      "1.5141879220803578\n",
      "Validation loss: 1.4217265844345093\n",
      "mse 1.4217265748929997\n",
      "New best model found at epoch 137 with validation loss 1.4217265844345093\n",
      "Starting Epoch 138\n",
      "1.5136817395687103\n",
      "Validation loss: 1.4212702512741089\n",
      "mse 1.4212702216689288\n",
      "New best model found at epoch 138 with validation loss 1.4212702512741089\n",
      "Starting Epoch 139\n",
      "1.5131702820460002\n",
      "Validation loss: 1.4208658933639526\n",
      "mse 1.420865855162523\n",
      "New best model found at epoch 139 with validation loss 1.4208658933639526\n",
      "Starting Epoch 140\n",
      "1.5126748283704121\n",
      "Validation loss: 1.4204223155975342\n",
      "mse 1.4204223464578332\n",
      "New best model found at epoch 140 with validation loss 1.4204223155975342\n",
      "Starting Epoch 141\n",
      "1.5121567000945408\n",
      "Validation loss: 1.4200294017791748\n",
      "mse 1.4200293566634647\n",
      "New best model found at epoch 141 with validation loss 1.4200294017791748\n",
      "Starting Epoch 142\n",
      "1.5116547644138336\n",
      "Validation loss: 1.4196559190750122\n",
      "mse 1.4196559266206594\n",
      "New best model found at epoch 142 with validation loss 1.4196559190750122\n",
      "Starting Epoch 143\n",
      "1.5111772517363231\n",
      "Validation loss: 1.419288992881775\n",
      "mse 1.4192889829059372\n",
      "New best model found at epoch 143 with validation loss 1.419288992881775\n",
      "Starting Epoch 144\n",
      "1.5107421576976776\n",
      "Validation loss: 1.4188326597213745\n",
      "mse 1.4188326462377367\n",
      "New best model found at epoch 144 with validation loss 1.4188326597213745\n",
      "Starting Epoch 145\n",
      "1.510242263476054\n",
      "Validation loss: 1.4184343814849854\n",
      "mse 1.41843431879788\n",
      "New best model found at epoch 145 with validation loss 1.4184343814849854\n",
      "Starting Epoch 146\n",
      "1.5097616314888\n",
      "Validation loss: 1.4180432558059692\n",
      "mse 1.4180432342568843\n",
      "New best model found at epoch 146 with validation loss 1.4180432558059692\n",
      "Starting Epoch 147\n",
      "1.5093006193637848\n",
      "Validation loss: 1.4176760911941528\n",
      "mse 1.4176760605510546\n",
      "New best model found at epoch 147 with validation loss 1.4176760911941528\n",
      "Starting Epoch 148\n",
      "1.5088792542616527\n",
      "Validation loss: 1.41722571849823\n",
      "mse 1.4172256846844151\n",
      "New best model found at epoch 148 with validation loss 1.41722571849823\n",
      "Starting Epoch 149\n",
      "1.5083835124969482\n",
      "Validation loss: 1.4168846607208252\n",
      "mse 1.4168847079465583\n",
      "New best model found at epoch 149 with validation loss 1.4168846607208252\n",
      "Starting Epoch 150\n",
      "1.5079704225063324\n",
      "Validation loss: 1.416455626487732\n",
      "mse 1.416455525144067\n",
      "New best model found at epoch 150 with validation loss 1.416455626487732\n",
      "Starting Epoch 151\n",
      "1.507487545410792\n",
      "Validation loss: 1.4160820245742798\n",
      "mse 1.4160820910249496\n",
      "New best model found at epoch 151 with validation loss 1.4160820245742798\n",
      "Starting Epoch 152\n",
      "1.507045512398084\n",
      "Validation loss: 1.4157088994979858\n",
      "mse 1.4157089690918085\n",
      "New best model found at epoch 152 with validation loss 1.4157088994979858\n",
      "Starting Epoch 153\n",
      "1.5066098769505818\n",
      "Validation loss: 1.415358543395996\n",
      "mse 1.4153585095497743\n",
      "New best model found at epoch 153 with validation loss 1.415358543395996\n",
      "Starting Epoch 154\n",
      "1.5062086830536525\n",
      "Validation loss: 1.4149454832077026\n",
      "mse 1.4149455735137302\n",
      "New best model found at epoch 154 with validation loss 1.4149454832077026\n",
      "Starting Epoch 155\n",
      "1.5057362864414852\n",
      "Validation loss: 1.4146342277526855\n",
      "mse 1.4146343180548226\n",
      "New best model found at epoch 155 with validation loss 1.4146342277526855\n",
      "Starting Epoch 156\n",
      "1.5053461839755375\n",
      "Validation loss: 1.4142441749572754\n",
      "mse 1.4142441136030057\n",
      "New best model found at epoch 156 with validation loss 1.4142441749572754\n",
      "Starting Epoch 157\n",
      "1.5048787345488865\n",
      "Validation loss: 1.4139649868011475\n",
      "mse 1.413964862477672\n",
      "New best model found at epoch 157 with validation loss 1.4139649868011475\n",
      "Starting Epoch 158\n",
      "1.50450699031353\n",
      "Validation loss: 1.413562297821045\n",
      "mse 1.4135623808851916\n",
      "New best model found at epoch 158 with validation loss 1.413562297821045\n",
      "Starting Epoch 159\n",
      "1.5040494203567505\n",
      "Validation loss: 1.4132686853408813\n",
      "mse 1.4132686035203288\n",
      "New best model found at epoch 159 with validation loss 1.4132686853408813\n",
      "Starting Epoch 160\n",
      "1.5036724110444386\n",
      "Validation loss: 1.412928581237793\n",
      "mse 1.4129286687612723\n",
      "New best model found at epoch 160 with validation loss 1.412928581237793\n",
      "Starting Epoch 161\n",
      "1.5032749076684315\n",
      "Validation loss: 1.4125386476516724\n",
      "mse 1.4125384751182466\n",
      "New best model found at epoch 161 with validation loss 1.4125386476516724\n",
      "Starting Epoch 162\n",
      "1.5028225580851238\n",
      "Validation loss: 1.4122756719589233\n",
      "mse 1.4122756289151321\n",
      "New best model found at epoch 162 with validation loss 1.4122756719589233\n",
      "Starting Epoch 163\n",
      "1.5024574398994446\n",
      "Validation loss: 1.4119300842285156\n",
      "mse 1.4119301680156118\n",
      "New best model found at epoch 163 with validation loss 1.4119300842285156\n",
      "Starting Epoch 164\n",
      "1.5020361145337422\n",
      "Validation loss: 1.4116123914718628\n",
      "mse 1.411612321978004\n",
      "New best model found at epoch 164 with validation loss 1.4116123914718628\n",
      "Starting Epoch 165\n",
      "1.501659209529559\n",
      "Validation loss: 1.4113271236419678\n",
      "mse 1.4113272058016866\n",
      "New best model found at epoch 165 with validation loss 1.4113271236419678\n",
      "Starting Epoch 166\n",
      "1.5012832432985306\n",
      "Validation loss: 1.4109641313552856\n",
      "mse 1.4109641683068348\n",
      "New best model found at epoch 166 with validation loss 1.4109641313552856\n",
      "Starting Epoch 167\n",
      "1.5008608152468998\n",
      "Validation loss: 1.4106805324554443\n",
      "mse 1.4106805813418244\n",
      "New best model found at epoch 167 with validation loss 1.4106805324554443\n",
      "Starting Epoch 168\n",
      "1.5005005200703938\n",
      "Validation loss: 1.4103772640228271\n",
      "mse 1.4103772702651762\n",
      "New best model found at epoch 168 with validation loss 1.4103772640228271\n",
      "Starting Epoch 169\n",
      "1.5001025100549061\n",
      "Validation loss: 1.4100675582885742\n",
      "mse 1.4100675158007971\n",
      "New best model found at epoch 169 with validation loss 1.4100675582885742\n",
      "Starting Epoch 170\n",
      "1.4997439285119374\n",
      "Validation loss: 1.4097851514816284\n",
      "mse 1.4097851356359814\n",
      "New best model found at epoch 170 with validation loss 1.4097851514816284\n",
      "Starting Epoch 171\n",
      "1.4993706146876018\n",
      "Validation loss: 1.4094754457473755\n",
      "mse 1.409475468887797\n",
      "New best model found at epoch 171 with validation loss 1.4094754457473755\n",
      "Starting Epoch 172\n",
      "1.4989800403515499\n",
      "Validation loss: 1.4091684818267822\n",
      "mse 1.409168464186386\n",
      "New best model found at epoch 172 with validation loss 1.4091684818267822\n",
      "Starting Epoch 173\n",
      "1.4986268331607182\n",
      "Validation loss: 1.4088999032974243\n",
      "mse 1.4088999392069694\n",
      "New best model found at epoch 173 with validation loss 1.4088999032974243\n",
      "Starting Epoch 174\n",
      "1.4982707301775615\n",
      "Validation loss: 1.4085702896118164\n",
      "mse 1.408570305000838\n",
      "New best model found at epoch 174 with validation loss 1.4085702896118164\n",
      "Starting Epoch 175\n",
      "1.4978723128636677\n",
      "Validation loss: 1.4083138704299927\n",
      "mse 1.4083138781883755\n",
      "New best model found at epoch 175 with validation loss 1.4083138704299927\n",
      "Starting Epoch 176\n",
      "1.4975423365831375\n",
      "Validation loss: 1.4080300331115723\n",
      "mse 1.4080299226984974\n",
      "New best model found at epoch 176 with validation loss 1.4080300331115723\n",
      "Starting Epoch 177\n",
      "1.4971833030382793\n",
      "Validation loss: 1.407758355140686\n",
      "mse 1.4077583105094087\n",
      "New best model found at epoch 177 with validation loss 1.407758355140686\n",
      "Starting Epoch 178\n",
      "1.4968191037575405\n",
      "Validation loss: 1.4075037240982056\n",
      "mse 1.4075036856233907\n",
      "New best model found at epoch 178 with validation loss 1.4075037240982056\n",
      "Starting Epoch 179\n",
      "1.4964574873447418\n",
      "Validation loss: 1.407213568687439\n",
      "mse 1.4072135588071712\n",
      "New best model found at epoch 179 with validation loss 1.407213568687439\n",
      "Starting Epoch 180\n",
      "1.4961296369632084\n",
      "Validation loss: 1.4069401025772095\n",
      "mse 1.4069401594538993\n",
      "New best model found at epoch 180 with validation loss 1.4069401025772095\n",
      "Starting Epoch 181\n",
      "1.4957739065090816\n",
      "Validation loss: 1.4067070484161377\n",
      "mse 1.4067070854606967\n",
      "New best model found at epoch 181 with validation loss 1.4067070484161377\n",
      "Starting Epoch 182\n",
      "1.495416487256686\n",
      "Validation loss: 1.4063621759414673\n",
      "mse 1.406362154261003\n",
      "New best model found at epoch 182 with validation loss 1.4063621759414673\n",
      "Starting Epoch 183\n",
      "1.4950581590334575\n",
      "Validation loss: 1.406112551689148\n",
      "mse 1.4061124377453058\n",
      "New best model found at epoch 183 with validation loss 1.406112551689148\n",
      "Starting Epoch 184\n",
      "1.4947286397218704\n",
      "Validation loss: 1.4058657884597778\n",
      "mse 1.405865731555239\n",
      "New best model found at epoch 184 with validation loss 1.4058657884597778\n",
      "Starting Epoch 185\n",
      "1.4943951268990834\n",
      "Validation loss: 1.4056508541107178\n",
      "mse 1.4056508338034142\n",
      "New best model found at epoch 185 with validation loss 1.4056508541107178\n",
      "Starting Epoch 186\n",
      "1.4940847903490067\n",
      "Validation loss: 1.4053735733032227\n",
      "mse 1.4053735191831973\n",
      "New best model found at epoch 186 with validation loss 1.4053735733032227\n",
      "Starting Epoch 187\n",
      "1.4937589665253956\n",
      "Validation loss: 1.4051260948181152\n",
      "mse 1.405126119236328\n",
      "New best model found at epoch 187 with validation loss 1.4051260948181152\n",
      "Starting Epoch 188\n",
      "1.4934229304393132\n",
      "Validation loss: 1.4049144983291626\n",
      "mse 1.4049144827500317\n",
      "New best model found at epoch 188 with validation loss 1.4049144983291626\n",
      "Starting Epoch 189\n",
      "1.4930817584196727\n",
      "Validation loss: 1.4046612977981567\n",
      "mse 1.4046613361037348\n",
      "New best model found at epoch 189 with validation loss 1.4046612977981567\n",
      "Starting Epoch 190\n",
      "1.4927646567424138\n",
      "Validation loss: 1.4044452905654907\n",
      "mse 1.4044452276173656\n",
      "New best model found at epoch 190 with validation loss 1.4044452905654907\n",
      "Starting Epoch 191\n",
      "1.4924590388933818\n",
      "Validation loss: 1.4041881561279297\n",
      "mse 1.4041881093758912\n",
      "New best model found at epoch 191 with validation loss 1.4041881561279297\n",
      "Starting Epoch 192\n",
      "1.492148260275523\n",
      "Validation loss: 1.403981328010559\n",
      "mse 1.403981311817331\n",
      "New best model found at epoch 192 with validation loss 1.403981328010559\n",
      "Starting Epoch 193\n",
      "1.4918565899133682\n",
      "Validation loss: 1.4037232398986816\n",
      "mse 1.4037231261684826\n",
      "New best model found at epoch 193 with validation loss 1.4037232398986816\n",
      "Starting Epoch 194\n",
      "1.4915264199177425\n",
      "Validation loss: 1.4035155773162842\n",
      "mse 1.4035155690578043\n",
      "New best model found at epoch 194 with validation loss 1.4035155773162842\n",
      "Starting Epoch 195\n",
      "1.4912306567033131\n",
      "Validation loss: 1.4032959938049316\n",
      "mse 1.4032958418408217\n",
      "New best model found at epoch 195 with validation loss 1.4032959938049316\n",
      "Starting Epoch 196\n",
      "1.4909414450327556\n",
      "Validation loss: 1.4030474424362183\n",
      "mse 1.4030475167541736\n",
      "New best model found at epoch 196 with validation loss 1.4030474424362183\n",
      "Starting Epoch 197\n",
      "1.4906564305226009\n",
      "Validation loss: 1.402837872505188\n",
      "mse 1.4028378851884522\n",
      "New best model found at epoch 197 with validation loss 1.402837872505188\n",
      "Starting Epoch 198\n",
      "1.4903465112050374\n",
      "Validation loss: 1.4026285409927368\n",
      "mse 1.4026286108500943\n",
      "New best model found at epoch 198 with validation loss 1.4026285409927368\n",
      "Starting Epoch 199\n",
      "1.4900763034820557\n",
      "Validation loss: 1.402347207069397\n",
      "mse 1.402347280889144\n",
      "New best model found at epoch 199 with validation loss 1.402347207069397\n",
      "Starting Epoch 200\n",
      "1.4897657583157222\n",
      "Validation loss: 1.4021708965301514\n",
      "mse 1.4021708647256699\n",
      "New best model found at epoch 200 with validation loss 1.4021708965301514\n",
      "Starting Epoch 201\n",
      "1.4894861578941345\n",
      "Validation loss: 1.4019598960876465\n",
      "mse 1.4019599262940752\n",
      "New best model found at epoch 201 with validation loss 1.4019598960876465\n",
      "Starting Epoch 202\n",
      "1.4892067561546962\n",
      "Validation loss: 1.4017263650894165\n",
      "mse 1.40172634752299\n",
      "New best model found at epoch 202 with validation loss 1.4017263650894165\n",
      "Starting Epoch 203\n",
      "1.4889132231473923\n",
      "Validation loss: 1.4015427827835083\n",
      "mse 1.4015428461287263\n",
      "New best model found at epoch 203 with validation loss 1.4015427827835083\n",
      "Starting Epoch 204\n",
      "1.4886535952488582\n",
      "Validation loss: 1.401277780532837\n",
      "mse 1.4012777219141834\n",
      "New best model found at epoch 204 with validation loss 1.401277780532837\n",
      "Starting Epoch 205\n",
      "1.4883535653352737\n",
      "Validation loss: 1.4011085033416748\n",
      "mse 1.4011084683945245\n",
      "New best model found at epoch 205 with validation loss 1.4011085033416748\n",
      "Starting Epoch 206\n",
      "1.4880895962317784\n",
      "Validation loss: 1.4008796215057373\n",
      "mse 1.400879507579371\n",
      "New best model found at epoch 206 with validation loss 1.4008796215057373\n",
      "Starting Epoch 207\n",
      "1.4878049145142238\n",
      "Validation loss: 1.400669813156128\n",
      "mse 1.4006696678732948\n",
      "New best model found at epoch 207 with validation loss 1.400669813156128\n",
      "Starting Epoch 208\n",
      "1.4875399470329285\n",
      "Validation loss: 1.400462031364441\n",
      "mse 1.400462073546492\n",
      "New best model found at epoch 208 with validation loss 1.400462031364441\n",
      "Starting Epoch 209\n",
      "1.4872621794541676\n",
      "Validation loss: 1.4002569913864136\n",
      "mse 1.4002569901316015\n",
      "New best model found at epoch 209 with validation loss 1.4002569913864136\n",
      "Starting Epoch 210\n",
      "1.486999273300171\n",
      "Validation loss: 1.4000400304794312\n",
      "mse 1.4000400689007975\n",
      "New best model found at epoch 210 with validation loss 1.4000400304794312\n",
      "Starting Epoch 211\n",
      "1.4867244710524876\n",
      "Validation loss: 1.3998652696609497\n",
      "mse 1.39986524897113\n",
      "New best model found at epoch 211 with validation loss 1.3998652696609497\n",
      "Starting Epoch 212\n",
      "1.4864693929751713\n",
      "Validation loss: 1.3996479511260986\n",
      "mse 1.399648002061415\n",
      "New best model found at epoch 212 with validation loss 1.3996479511260986\n",
      "Starting Epoch 213\n",
      "1.4862045844395955\n",
      "Validation loss: 1.3994712829589844\n",
      "mse 1.3994711143580991\n",
      "New best model found at epoch 213 with validation loss 1.3994712829589844\n",
      "Starting Epoch 214\n",
      "1.485964501897494\n",
      "Validation loss: 1.3992501497268677\n",
      "mse 1.3992500802643986\n",
      "New best model found at epoch 214 with validation loss 1.3992501497268677\n",
      "Starting Epoch 215\n",
      "1.4856776495774586\n",
      "Validation loss: 1.3990747928619385\n",
      "mse 1.3990747099482972\n",
      "New best model found at epoch 215 with validation loss 1.3990747928619385\n",
      "Starting Epoch 216\n",
      "1.485428551832835\n",
      "Validation loss: 1.3988577127456665\n",
      "mse 1.398857840700421\n",
      "New best model found at epoch 216 with validation loss 1.3988577127456665\n",
      "Starting Epoch 217\n",
      "1.485160619020462\n",
      "Validation loss: 1.3986977338790894\n",
      "mse 1.398697775128962\n",
      "New best model found at epoch 217 with validation loss 1.3986977338790894\n",
      "Starting Epoch 218\n",
      "1.48491832613945\n",
      "Validation loss: 1.3984754085540771\n",
      "mse 1.398475462869988\n",
      "New best model found at epoch 218 with validation loss 1.3984754085540771\n",
      "Starting Epoch 219\n",
      "1.4846529910961788\n",
      "Validation loss: 1.3983135223388672\n",
      "mse 1.3983136734069859\n",
      "New best model found at epoch 219 with validation loss 1.3983135223388672\n",
      "Starting Epoch 220\n",
      "1.4844131171703339\n",
      "Validation loss: 1.3980915546417236\n",
      "mse 1.3980914992476738\n",
      "New best model found at epoch 220 with validation loss 1.3980915546417236\n",
      "Starting Epoch 221\n",
      "1.4841467241446178\n",
      "Validation loss: 1.3979532718658447\n",
      "mse 1.3979533747696633\n",
      "New best model found at epoch 221 with validation loss 1.3979532718658447\n",
      "Starting Epoch 222\n",
      "1.4839248657226562\n",
      "Validation loss: 1.397796630859375\n",
      "mse 1.3977966213617845\n",
      "New best model found at epoch 222 with validation loss 1.397796630859375\n",
      "Starting Epoch 223\n",
      "1.4836897452672322\n",
      "Validation loss: 1.3975965976715088\n",
      "mse 1.3975967685286965\n",
      "New best model found at epoch 223 with validation loss 1.3975965976715088\n",
      "Starting Epoch 224\n",
      "1.4834365596373875\n",
      "Validation loss: 1.3974376916885376\n",
      "mse 1.3974376777655453\n",
      "New best model found at epoch 224 with validation loss 1.3974376916885376\n",
      "Starting Epoch 225\n",
      "1.4832154760758083\n",
      "Validation loss: 1.3972476720809937\n",
      "mse 1.3972476467352721\n",
      "New best model found at epoch 225 with validation loss 1.3972476720809937\n",
      "Starting Epoch 226\n",
      "1.482950473825137\n",
      "Validation loss: 1.397050380706787\n",
      "mse 1.3970502984214648\n",
      "New best model found at epoch 226 with validation loss 1.397050380706787\n",
      "Starting Epoch 227\n",
      "1.4827115734418232\n",
      "Validation loss: 1.3968842029571533\n",
      "mse 1.3968842606172838\n",
      "New best model found at epoch 227 with validation loss 1.3968842029571533\n",
      "Starting Epoch 228\n",
      "1.4824933061997096\n",
      "Validation loss: 1.3966923952102661\n",
      "mse 1.3966922693334256\n",
      "New best model found at epoch 228 with validation loss 1.3966923952102661\n",
      "Starting Epoch 229\n",
      "1.4822526474793751\n",
      "Validation loss: 1.3965219259262085\n",
      "mse 1.3965218487101752\n",
      "New best model found at epoch 229 with validation loss 1.3965219259262085\n",
      "Starting Epoch 230\n",
      "1.4820066789786022\n",
      "Validation loss: 1.3963261842727661\n",
      "mse 1.396326123096484\n",
      "New best model found at epoch 230 with validation loss 1.3963261842727661\n",
      "Starting Epoch 231\n",
      "1.4817631741364796\n",
      "Validation loss: 1.3961619138717651\n",
      "mse 1.3961619387042914\n",
      "New best model found at epoch 231 with validation loss 1.3961619138717651\n",
      "Starting Epoch 232\n",
      "1.4815496057271957\n",
      "Validation loss: 1.3959712982177734\n",
      "mse 1.3959714209922163\n",
      "New best model found at epoch 232 with validation loss 1.3959712982177734\n",
      "Starting Epoch 233\n",
      "1.4813126077254613\n",
      "Validation loss: 1.3958438634872437\n",
      "mse 1.3958438586906994\n",
      "New best model found at epoch 233 with validation loss 1.3958438634872437\n",
      "Starting Epoch 234\n",
      "1.4810902575651805\n",
      "Validation loss: 1.3956490755081177\n",
      "mse 1.3956490144637956\n",
      "New best model found at epoch 234 with validation loss 1.3956490755081177\n",
      "Starting Epoch 235\n",
      "1.4808392524719238\n",
      "Validation loss: 1.3954719305038452\n",
      "mse 1.3954719383355556\n",
      "New best model found at epoch 235 with validation loss 1.3954719305038452\n",
      "Starting Epoch 236\n",
      "1.4806290566921234\n",
      "Validation loss: 1.3952722549438477\n",
      "mse 1.39527210270477\n",
      "New best model found at epoch 236 with validation loss 1.3952722549438477\n",
      "Starting Epoch 237\n",
      "1.480399250984192\n",
      "Validation loss: 1.3951412439346313\n",
      "mse 1.3951413541249877\n",
      "New best model found at epoch 237 with validation loss 1.3951412439346313\n",
      "Starting Epoch 238\n",
      "1.480181063214938\n",
      "Validation loss: 1.3949459791183472\n",
      "mse 1.3949460417990167\n",
      "New best model found at epoch 238 with validation loss 1.3949459791183472\n",
      "Starting Epoch 239\n",
      "1.4799481978019078\n",
      "Validation loss: 1.3948134183883667\n",
      "mse 1.394813426309458\n",
      "New best model found at epoch 239 with validation loss 1.3948134183883667\n",
      "Starting Epoch 240\n",
      "1.4797330697377522\n",
      "Validation loss: 1.394619345664978\n",
      "mse 1.394619449243231\n",
      "New best model found at epoch 240 with validation loss 1.394619345664978\n",
      "Starting Epoch 241\n",
      "1.479500616590182\n",
      "Validation loss: 1.3944679498672485\n",
      "mse 1.3944678974202342\n",
      "New best model found at epoch 241 with validation loss 1.3944679498672485\n",
      "Starting Epoch 242\n",
      "1.4792939126491547\n",
      "Validation loss: 1.394294261932373\n",
      "mse 1.3942943840707747\n",
      "New best model found at epoch 242 with validation loss 1.394294261932373\n",
      "Starting Epoch 243\n",
      "1.4790653735399246\n",
      "Validation loss: 1.3941457271575928\n",
      "mse 1.3941458083594098\n",
      "New best model found at epoch 243 with validation loss 1.3941457271575928\n",
      "Starting Epoch 244\n",
      "1.4788564642270405\n",
      "Validation loss: 1.3939710855484009\n",
      "mse 1.3939710083712267\n",
      "New best model found at epoch 244 with validation loss 1.3939710855484009\n",
      "Starting Epoch 245\n",
      "1.478631888826688\n",
      "Validation loss: 1.393845796585083\n",
      "mse 1.39384575785125\n",
      "New best model found at epoch 245 with validation loss 1.393845796585083\n",
      "Starting Epoch 246\n",
      "1.4784179379542668\n",
      "Validation loss: 1.393701195716858\n",
      "mse 1.3937010749145031\n",
      "New best model found at epoch 246 with validation loss 1.393701195716858\n",
      "Starting Epoch 247\n",
      "1.4782035946846008\n",
      "Validation loss: 1.3935025930404663\n",
      "mse 1.3935025908260565\n",
      "New best model found at epoch 247 with validation loss 1.3935025930404663\n",
      "Starting Epoch 248\n",
      "1.4779869516690571\n",
      "Validation loss: 1.393375277519226\n",
      "mse 1.3933753727601217\n",
      "New best model found at epoch 248 with validation loss 1.393375277519226\n",
      "Starting Epoch 249\n",
      "1.4777701050043106\n",
      "Validation loss: 1.3932236433029175\n",
      "mse 1.3932236994143226\n",
      "New best model found at epoch 249 with validation loss 1.3932236433029175\n",
      "Starting Epoch 250\n",
      "1.4775649110476177\n",
      "Validation loss: 1.3930248022079468\n",
      "mse 1.3930247264843312\n",
      "New best model found at epoch 250 with validation loss 1.3930248022079468\n",
      "Starting Epoch 251\n",
      "1.4773512184619904\n",
      "Validation loss: 1.3929033279418945\n",
      "mse 1.3929032708642635\n",
      "New best model found at epoch 251 with validation loss 1.3929033279418945\n",
      "Starting Epoch 252\n",
      "1.4771440923213959\n",
      "Validation loss: 1.3927545547485352\n",
      "mse 1.3927546026333089\n",
      "New best model found at epoch 252 with validation loss 1.3927545547485352\n",
      "Starting Epoch 253\n",
      "1.4769353320201237\n",
      "Validation loss: 1.392554759979248\n",
      "mse 1.3925547540087801\n",
      "New best model found at epoch 253 with validation loss 1.392554759979248\n",
      "Starting Epoch 254\n",
      "1.4767246792713802\n",
      "Validation loss: 1.3924334049224854\n",
      "mse 1.3924334041975746\n",
      "New best model found at epoch 254 with validation loss 1.3924334049224854\n",
      "Starting Epoch 255\n",
      "1.4765198081731796\n",
      "Validation loss: 1.3922864198684692\n",
      "mse 1.3922863998209356\n",
      "New best model found at epoch 255 with validation loss 1.3922864198684692\n",
      "Starting Epoch 256\n",
      "1.4763180514176686\n",
      "Validation loss: 1.392102599143982\n",
      "mse 1.3921024627484035\n",
      "New best model found at epoch 256 with validation loss 1.392102599143982\n",
      "Starting Epoch 257\n",
      "1.476101592183113\n",
      "Validation loss: 1.391964077949524\n",
      "mse 1.3919641701024748\n",
      "New best model found at epoch 257 with validation loss 1.391964077949524\n",
      "Starting Epoch 258\n",
      "1.4759030938148499\n",
      "Validation loss: 1.3918261528015137\n",
      "mse 1.3918261217831023\n",
      "New best model found at epoch 258 with validation loss 1.3918261528015137\n",
      "Starting Epoch 259\n",
      "1.4757103770971298\n",
      "Validation loss: 1.3917083740234375\n",
      "mse 1.3917083885166317\n",
      "New best model found at epoch 259 with validation loss 1.3917083740234375\n",
      "Starting Epoch 260\n",
      "1.4754811177651088\n",
      "Validation loss: 1.3914806842803955\n",
      "mse 1.3914806490857525\n",
      "New best model found at epoch 260 with validation loss 1.3914806842803955\n",
      "Starting Epoch 261\n",
      "1.4752886891365051\n",
      "Validation loss: 1.39137601852417\n",
      "mse 1.391375896860625\n",
      "New best model found at epoch 261 with validation loss 1.39137601852417\n",
      "Starting Epoch 262\n",
      "1.4750836143891017\n",
      "Validation loss: 1.3912389278411865\n",
      "mse 1.3912389786401675\n",
      "New best model found at epoch 262 with validation loss 1.3912389278411865\n",
      "Starting Epoch 263\n",
      "1.474872002998988\n",
      "Validation loss: 1.391090750694275\n",
      "mse 1.3910907781519126\n",
      "New best model found at epoch 263 with validation loss 1.391090750694275\n",
      "Starting Epoch 264\n",
      "1.474684238433838\n",
      "Validation loss: 1.390951156616211\n",
      "mse 1.3909511089887945\n",
      "New best model found at epoch 264 with validation loss 1.390951156616211\n",
      "Starting Epoch 265\n",
      "1.4744854718446732\n",
      "Validation loss: 1.390763521194458\n",
      "mse 1.3907634402344269\n",
      "New best model found at epoch 265 with validation loss 1.390763521194458\n",
      "Starting Epoch 266\n",
      "1.4742881904045742\n",
      "Validation loss: 1.3906371593475342\n",
      "mse 1.3906371845383365\n",
      "New best model found at epoch 266 with validation loss 1.3906371593475342\n",
      "Starting Epoch 267\n",
      "1.4740880330403645\n",
      "Validation loss: 1.390484094619751\n",
      "mse 1.3904840306323842\n",
      "New best model found at epoch 267 with validation loss 1.390484094619751\n",
      "Starting Epoch 268\n",
      "1.4739105651775997\n",
      "Validation loss: 1.3903638124465942\n",
      "mse 1.3903637883180875\n",
      "New best model found at epoch 268 with validation loss 1.3903638124465942\n",
      "Starting Epoch 269\n",
      "1.4736995200316112\n",
      "Validation loss: 1.3902113437652588\n",
      "mse 1.3902113029663994\n",
      "New best model found at epoch 269 with validation loss 1.3902113437652588\n",
      "Starting Epoch 270\n",
      "1.4735056708256404\n",
      "Validation loss: 1.3900564908981323\n",
      "mse 1.3900565432905598\n",
      "New best model found at epoch 270 with validation loss 1.3900564908981323\n",
      "Starting Epoch 271\n",
      "1.4733317742745082\n",
      "Validation loss: 1.3899298906326294\n",
      "mse 1.3899300027822372\n",
      "New best model found at epoch 271 with validation loss 1.3899298906326294\n",
      "Starting Epoch 272\n",
      "1.4731291284163792\n",
      "Validation loss: 1.3897817134857178\n",
      "mse 1.3897818011198355\n",
      "New best model found at epoch 272 with validation loss 1.3897817134857178\n",
      "Starting Epoch 273\n",
      "1.4729493459065754\n",
      "Validation loss: 1.389654517173767\n",
      "mse 1.3896544066427974\n",
      "New best model found at epoch 273 with validation loss 1.389654517173767\n",
      "Starting Epoch 274\n",
      "1.4727460245291393\n",
      "Validation loss: 1.3894609212875366\n",
      "mse 1.389461001647959\n",
      "New best model found at epoch 274 with validation loss 1.3894609212875366\n",
      "Starting Epoch 275\n",
      "1.4725703299045563\n",
      "Validation loss: 1.389343500137329\n",
      "mse 1.389343429744606\n",
      "New best model found at epoch 275 with validation loss 1.389343500137329\n",
      "Starting Epoch 276\n",
      "1.4723835339148839\n",
      "Validation loss: 1.3892139196395874\n",
      "mse 1.389213947057242\n",
      "New best model found at epoch 276 with validation loss 1.3892139196395874\n",
      "Starting Epoch 277\n",
      "1.472190335392952\n",
      "Validation loss: 1.389073133468628\n",
      "mse 1.3890731370503697\n",
      "New best model found at epoch 277 with validation loss 1.389073133468628\n",
      "Starting Epoch 278\n",
      "1.4720097581545513\n",
      "Validation loss: 1.3889386653900146\n",
      "mse 1.3889386644525592\n",
      "New best model found at epoch 278 with validation loss 1.3889386653900146\n",
      "Starting Epoch 279\n",
      "1.4718212485313416\n",
      "Validation loss: 1.3888174295425415\n",
      "mse 1.388817501819481\n",
      "New best model found at epoch 279 with validation loss 1.3888174295425415\n",
      "Starting Epoch 280\n",
      "1.4716185082991917\n",
      "Validation loss: 1.3886632919311523\n",
      "mse 1.3886632890836577\n",
      "New best model found at epoch 280 with validation loss 1.3886632919311523\n",
      "Starting Epoch 281\n",
      "1.4714471250772476\n",
      "Validation loss: 1.3885506391525269\n",
      "mse 1.3885506244290773\n",
      "New best model found at epoch 281 with validation loss 1.3885506391525269\n",
      "Starting Epoch 282\n",
      "1.4712733576695125\n",
      "Validation loss: 1.388391375541687\n",
      "mse 1.3883915048503506\n",
      "New best model found at epoch 282 with validation loss 1.388391375541687\n",
      "Starting Epoch 283\n",
      "1.4710664103428523\n",
      "Validation loss: 1.3882795572280884\n",
      "mse 1.3882796434341302\n",
      "New best model found at epoch 283 with validation loss 1.3882795572280884\n",
      "Starting Epoch 284\n",
      "1.4709082941214244\n",
      "Validation loss: 1.3881207704544067\n",
      "mse 1.3881208599227761\n",
      "New best model found at epoch 284 with validation loss 1.3881207704544067\n",
      "Starting Epoch 285\n",
      "1.4707029263178508\n",
      "Validation loss: 1.3880082368850708\n",
      "mse 1.3880081259433634\n",
      "New best model found at epoch 285 with validation loss 1.3880082368850708\n",
      "Starting Epoch 286\n",
      "1.4705297201871872\n",
      "Validation loss: 1.3878549337387085\n",
      "mse 1.3878550010429687\n",
      "New best model found at epoch 286 with validation loss 1.3878549337387085\n",
      "Starting Epoch 287\n",
      "1.470356211066246\n",
      "Validation loss: 1.387738823890686\n",
      "mse 1.38773877874414\n",
      "New best model found at epoch 287 with validation loss 1.387738823890686\n",
      "Starting Epoch 288\n",
      "1.470178097486496\n",
      "Validation loss: 1.3875815868377686\n",
      "mse 1.3875816943644756\n",
      "New best model found at epoch 288 with validation loss 1.3875815868377686\n",
      "Starting Epoch 289\n",
      "1.469997728864352\n",
      "Validation loss: 1.3874664306640625\n",
      "mse 1.3874663652293533\n",
      "New best model found at epoch 289 with validation loss 1.3874664306640625\n",
      "Starting Epoch 290\n",
      "1.4698265840609868\n",
      "Validation loss: 1.387317180633545\n",
      "mse 1.3873171211779338\n",
      "New best model found at epoch 290 with validation loss 1.387317180633545\n",
      "Starting Epoch 291\n",
      "1.4696280161539714\n",
      "Validation loss: 1.3872054815292358\n",
      "mse 1.3872055308225926\n",
      "New best model found at epoch 291 with validation loss 1.3872054815292358\n",
      "Starting Epoch 292\n",
      "1.469458907842636\n",
      "Validation loss: 1.3870548009872437\n",
      "mse 1.3870546904775778\n",
      "New best model found at epoch 292 with validation loss 1.3870548009872437\n",
      "Starting Epoch 293\n",
      "1.4692752907673519\n",
      "Validation loss: 1.3869434595108032\n",
      "mse 1.3869436139225617\n",
      "New best model found at epoch 293 with validation loss 1.3869434595108032\n",
      "Starting Epoch 294\n",
      "1.4691018412510555\n",
      "Validation loss: 1.3868138790130615\n",
      "mse 1.3868138551084643\n",
      "New best model found at epoch 294 with validation loss 1.3868138790130615\n",
      "Starting Epoch 295\n",
      "1.4689329316218693\n",
      "Validation loss: 1.3866608142852783\n",
      "mse 1.386660851917991\n",
      "New best model found at epoch 295 with validation loss 1.3866608142852783\n",
      "Starting Epoch 296\n",
      "1.4687509785095851\n",
      "Validation loss: 1.3865485191345215\n",
      "mse 1.386548577108961\n",
      "New best model found at epoch 296 with validation loss 1.3865485191345215\n",
      "Starting Epoch 297\n",
      "1.4685920824607213\n",
      "Validation loss: 1.3864206075668335\n",
      "mse 1.386420596123718\n",
      "New best model found at epoch 297 with validation loss 1.3864206075668335\n",
      "Starting Epoch 298\n",
      "1.4684118926525116\n",
      "Validation loss: 1.3862688541412354\n",
      "mse 1.3862686962239537\n",
      "New best model found at epoch 298 with validation loss 1.3862688541412354\n",
      "Starting Epoch 299\n",
      "1.4682318717241287\n",
      "Validation loss: 1.3861573934555054\n",
      "mse 1.3861573938408787\n",
      "New best model found at epoch 299 with validation loss 1.3861573934555054\n",
      "Starting Epoch 300\n",
      "1.4680747638146083\n",
      "Validation loss: 1.3860301971435547\n",
      "mse 1.3860301859842825\n",
      "New best model found at epoch 300 with validation loss 1.3860301971435547\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-5-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d8c11e",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 2\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 10 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "84554db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "7a63c91c-6491-4b5a-ba8e-595a47b9548e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.5455425828695297\n",
      "Validation loss: 2.687329053878784\n",
      "mse 2.687329046006583\n",
      "New best model found at epoch 1 with validation loss 2.687329053878784\n",
      "Starting Epoch 2\n",
      "2.504354546467463\n",
      "Validation loss: 2.4632318019866943\n",
      "mse 2.4632320327358483\n",
      "New best model found at epoch 2 with validation loss 2.4632318019866943\n",
      "Starting Epoch 3\n",
      "2.3547663440306983\n",
      "Validation loss: 2.328735828399658\n",
      "mse 2.3287356964501598\n",
      "New best model found at epoch 3 with validation loss 2.328735828399658\n",
      "Starting Epoch 4\n",
      "2.260785296559334\n",
      "Validation loss: 2.23599910736084\n",
      "mse 2.2359988265646518\n",
      "New best model found at epoch 4 with validation loss 2.23599910736084\n",
      "Starting Epoch 5\n",
      "2.1958915988604226\n",
      "Validation loss: 2.1697962284088135\n",
      "mse 2.1697963287922746\n",
      "New best model found at epoch 5 with validation loss 2.1697962284088135\n",
      "Starting Epoch 6\n",
      "2.149283508459727\n",
      "Validation loss: 2.1201250553131104\n",
      "mse 2.1201250053457095\n",
      "New best model found at epoch 6 with validation loss 2.1201250553131104\n",
      "Starting Epoch 7\n",
      "2.1127095967531204\n",
      "Validation loss: 2.081066846847534\n",
      "mse 2.0810666422346684\n",
      "New best model found at epoch 7 with validation loss 2.081066846847534\n",
      "Starting Epoch 8\n",
      "2.0851679941018424\n",
      "Validation loss: 2.0503525733947754\n",
      "mse 2.050352583332549\n",
      "New best model found at epoch 8 with validation loss 2.0503525733947754\n",
      "Starting Epoch 9\n",
      "2.0641032457351685\n",
      "Validation loss: 2.023845672607422\n",
      "mse 2.02384604379666\n",
      "New best model found at epoch 9 with validation loss 2.023845672607422\n",
      "Starting Epoch 10\n",
      "2.0463965634504953\n",
      "Validation loss: 2.003253936767578\n",
      "mse 2.0032538062406093\n",
      "New best model found at epoch 10 with validation loss 2.003253936767578\n",
      "Starting Epoch 11\n",
      "2.0309615979592004\n",
      "Validation loss: 1.9836875200271606\n",
      "mse 1.9836875282173763\n",
      "New best model found at epoch 11 with validation loss 1.9836875200271606\n",
      "Starting Epoch 12\n",
      "2.016969824830691\n",
      "Validation loss: 1.9666767120361328\n",
      "mse 1.966676797124543\n",
      "New best model found at epoch 12 with validation loss 1.9666767120361328\n",
      "Starting Epoch 13\n",
      "2.0038183530171714\n",
      "Validation loss: 1.9503154754638672\n",
      "mse 1.9503154836572127\n",
      "New best model found at epoch 13 with validation loss 1.9503154754638672\n",
      "Starting Epoch 14\n",
      "1.9913146942853928\n",
      "Validation loss: 1.9358268976211548\n",
      "mse 1.9358268870851545\n",
      "New best model found at epoch 14 with validation loss 1.9358268976211548\n",
      "Starting Epoch 15\n",
      "1.9794906377792358\n",
      "Validation loss: 1.922268271446228\n",
      "mse 1.9222682943072\n",
      "New best model found at epoch 15 with validation loss 1.922268271446228\n",
      "Starting Epoch 16\n",
      "1.9681509484847386\n",
      "Validation loss: 1.9095782041549683\n",
      "mse 1.9095780815293777\n",
      "New best model found at epoch 16 with validation loss 1.9095782041549683\n",
      "Starting Epoch 17\n",
      "1.957502340277036\n",
      "Validation loss: 1.8973103761672974\n",
      "mse 1.8973103712790524\n",
      "New best model found at epoch 17 with validation loss 1.8973103761672974\n",
      "Starting Epoch 18\n",
      "1.9473299235105515\n",
      "Validation loss: 1.8853832483291626\n",
      "mse 1.8853832951615626\n",
      "New best model found at epoch 18 with validation loss 1.8853832483291626\n",
      "Starting Epoch 19\n",
      "1.9375813951094945\n",
      "Validation loss: 1.8743540048599243\n",
      "mse 1.8743539622529253\n",
      "New best model found at epoch 19 with validation loss 1.8743540048599243\n",
      "Starting Epoch 20\n",
      "1.9282449682553608\n",
      "Validation loss: 1.8637229204177856\n",
      "mse 1.8637227914622057\n",
      "New best model found at epoch 20 with validation loss 1.8637229204177856\n",
      "Starting Epoch 21\n",
      "1.9192571739355724\n",
      "Validation loss: 1.853572130203247\n",
      "mse 1.8535721449216804\n",
      "New best model found at epoch 21 with validation loss 1.853572130203247\n",
      "Starting Epoch 22\n",
      "1.9105224112669628\n",
      "Validation loss: 1.844638466835022\n",
      "mse 1.8446383382004061\n",
      "New best model found at epoch 22 with validation loss 1.844638466835022\n",
      "Starting Epoch 23\n",
      "1.9020448525746663\n",
      "Validation loss: 1.8356889486312866\n",
      "mse 1.8356889173351851\n",
      "New best model found at epoch 23 with validation loss 1.8356889486312866\n",
      "Starting Epoch 24\n",
      "1.893806020418803\n",
      "Validation loss: 1.826917052268982\n",
      "mse 1.826917151650553\n",
      "New best model found at epoch 24 with validation loss 1.826917052268982\n",
      "Starting Epoch 25\n",
      "1.8859590540329616\n",
      "Validation loss: 1.8179073333740234\n",
      "mse 1.817907170831325\n",
      "New best model found at epoch 25 with validation loss 1.8179073333740234\n",
      "Starting Epoch 26\n",
      "1.8783624668916066\n",
      "Validation loss: 1.8092503547668457\n",
      "mse 1.8092503148840797\n",
      "New best model found at epoch 26 with validation loss 1.8092503547668457\n",
      "Starting Epoch 27\n",
      "1.8709841966629028\n",
      "Validation loss: 1.8007889986038208\n",
      "mse 1.8007889099303693\n",
      "New best model found at epoch 27 with validation loss 1.8007889986038208\n",
      "Starting Epoch 28\n",
      "1.8639458964268367\n",
      "Validation loss: 1.7930244207382202\n",
      "mse 1.7930244490447855\n",
      "New best model found at epoch 28 with validation loss 1.7930244207382202\n",
      "Starting Epoch 29\n",
      "1.85727825264136\n",
      "Validation loss: 1.7846927642822266\n",
      "mse 1.784692806003016\n",
      "New best model found at epoch 29 with validation loss 1.7846927642822266\n",
      "Starting Epoch 30\n",
      "1.8506247003873189\n",
      "Validation loss: 1.7773334980010986\n",
      "mse 1.7773333778161788\n",
      "New best model found at epoch 30 with validation loss 1.7773334980010986\n",
      "Starting Epoch 31\n",
      "1.844360167781512\n",
      "Validation loss: 1.7699882984161377\n",
      "mse 1.7699883764867272\n",
      "New best model found at epoch 31 with validation loss 1.7699882984161377\n",
      "Starting Epoch 32\n",
      "1.8382217437028885\n",
      "Validation loss: 1.7628892660140991\n",
      "mse 1.762889170303677\n",
      "New best model found at epoch 32 with validation loss 1.7628892660140991\n",
      "Starting Epoch 33\n",
      "1.8322912404934566\n",
      "Validation loss: 1.7565137147903442\n",
      "mse 1.756513753422731\n",
      "New best model found at epoch 33 with validation loss 1.7565137147903442\n",
      "Starting Epoch 34\n",
      "1.826526979605357\n",
      "Validation loss: 1.7504462003707886\n",
      "mse 1.750446240250777\n",
      "New best model found at epoch 34 with validation loss 1.7504462003707886\n",
      "Starting Epoch 35\n",
      "1.8209179540475209\n",
      "Validation loss: 1.7445319890975952\n",
      "mse 1.7445318694788223\n",
      "New best model found at epoch 35 with validation loss 1.7445319890975952\n",
      "Starting Epoch 36\n",
      "1.8154607613881428\n",
      "Validation loss: 1.7387080192565918\n",
      "mse 1.73870796486659\n",
      "New best model found at epoch 36 with validation loss 1.7387080192565918\n",
      "Starting Epoch 37\n",
      "1.81016306579113\n",
      "Validation loss: 1.7333325147628784\n",
      "mse 1.733332479553566\n",
      "New best model found at epoch 37 with validation loss 1.7333325147628784\n",
      "Starting Epoch 38\n",
      "1.8050022621949513\n",
      "Validation loss: 1.7276519536972046\n",
      "mse 1.7276519297290729\n",
      "New best model found at epoch 38 with validation loss 1.7276519536972046\n",
      "Starting Epoch 39\n",
      "1.8000398029883702\n",
      "Validation loss: 1.7220994234085083\n",
      "mse 1.7220995084570594\n",
      "New best model found at epoch 39 with validation loss 1.7220994234085083\n",
      "Starting Epoch 40\n",
      "1.7951678484678268\n",
      "Validation loss: 1.7166248559951782\n",
      "mse 1.7166247865395596\n",
      "New best model found at epoch 40 with validation loss 1.7166248559951782\n",
      "Starting Epoch 41\n",
      "1.7905385941267014\n",
      "Validation loss: 1.7112317085266113\n",
      "mse 1.7112318070770864\n",
      "New best model found at epoch 41 with validation loss 1.7112317085266113\n",
      "Starting Epoch 42\n",
      "1.785998562971751\n",
      "Validation loss: 1.706110954284668\n",
      "mse 1.7061107923583223\n",
      "New best model found at epoch 42 with validation loss 1.706110954284668\n",
      "Starting Epoch 43\n",
      "1.7816434452931087\n",
      "Validation loss: 1.7010631561279297\n",
      "mse 1.701063080835488\n",
      "New best model found at epoch 43 with validation loss 1.7010631561279297\n",
      "Starting Epoch 44\n",
      "1.7772904882828395\n",
      "Validation loss: 1.696241855621338\n",
      "mse 1.6962419840285432\n",
      "New best model found at epoch 44 with validation loss 1.696241855621338\n",
      "Starting Epoch 45\n",
      "1.7731668104728062\n",
      "Validation loss: 1.6915355920791626\n",
      "mse 1.6915355464800006\n",
      "New best model found at epoch 45 with validation loss 1.6915355920791626\n",
      "Starting Epoch 46\n",
      "1.7692173669735591\n",
      "Validation loss: 1.6870694160461426\n",
      "mse 1.6870695018292734\n",
      "New best model found at epoch 46 with validation loss 1.6870694160461426\n",
      "Starting Epoch 47\n",
      "1.7653432190418243\n",
      "Validation loss: 1.682490587234497\n",
      "mse 1.6824907728926226\n",
      "New best model found at epoch 47 with validation loss 1.682490587234497\n",
      "Starting Epoch 48\n",
      "1.7615712136030197\n",
      "Validation loss: 1.6784052848815918\n",
      "mse 1.6784052033978962\n",
      "New best model found at epoch 48 with validation loss 1.6784052848815918\n",
      "Starting Epoch 49\n",
      "1.7579052696625392\n",
      "Validation loss: 1.6743264198303223\n",
      "mse 1.6743264875758956\n",
      "New best model found at epoch 49 with validation loss 1.6743264198303223\n",
      "Starting Epoch 50\n",
      "1.7543535927931468\n",
      "Validation loss: 1.6704576015472412\n",
      "mse 1.670457646708298\n",
      "New best model found at epoch 50 with validation loss 1.6704576015472412\n",
      "Starting Epoch 51\n",
      "1.7509472866853077\n",
      "Validation loss: 1.6665265560150146\n",
      "mse 1.6665265300810945\n",
      "New best model found at epoch 51 with validation loss 1.6665265560150146\n",
      "Starting Epoch 52\n",
      "1.7476217250029247\n",
      "Validation loss: 1.6627939939498901\n",
      "mse 1.6627938437876137\n",
      "New best model found at epoch 52 with validation loss 1.6627939939498901\n",
      "Starting Epoch 53\n",
      "1.7443871597448986\n",
      "Validation loss: 1.6592615842819214\n",
      "mse 1.6592614013686195\n",
      "New best model found at epoch 53 with validation loss 1.6592615842819214\n",
      "Starting Epoch 54\n",
      "1.74123914539814\n",
      "Validation loss: 1.6562800407409668\n",
      "mse 1.6562797934789808\n",
      "New best model found at epoch 54 with validation loss 1.6562800407409668\n",
      "Starting Epoch 55\n",
      "1.7382502605517705\n",
      "Validation loss: 1.652443289756775\n",
      "mse 1.652443331053816\n",
      "New best model found at epoch 55 with validation loss 1.652443289756775\n",
      "Starting Epoch 56\n",
      "1.7352307637532551\n",
      "Validation loss: 1.649468183517456\n",
      "mse 1.6494682523708417\n",
      "New best model found at epoch 56 with validation loss 1.649468183517456\n",
      "Starting Epoch 57\n",
      "1.7323799928029378\n",
      "Validation loss: 1.6464444398880005\n",
      "mse 1.646444501789862\n",
      "New best model found at epoch 57 with validation loss 1.6464444398880005\n",
      "Starting Epoch 58\n",
      "1.7296212365229924\n",
      "Validation loss: 1.643160104751587\n",
      "mse 1.64316020535861\n",
      "New best model found at epoch 58 with validation loss 1.643160104751587\n",
      "Starting Epoch 59\n",
      "1.726900691787402\n",
      "Validation loss: 1.6401677131652832\n",
      "mse 1.6401676881731586\n",
      "New best model found at epoch 59 with validation loss 1.6401677131652832\n",
      "Starting Epoch 60\n",
      "1.7242557903130848\n",
      "Validation loss: 1.637279987335205\n",
      "mse 1.6372798241150006\n",
      "New best model found at epoch 60 with validation loss 1.637279987335205\n",
      "Starting Epoch 61\n",
      "1.721682478984197\n",
      "Validation loss: 1.6345973014831543\n",
      "mse 1.6345973967070928\n",
      "New best model found at epoch 61 with validation loss 1.6345973014831543\n",
      "Starting Epoch 62\n",
      "1.7191986590623856\n",
      "Validation loss: 1.631811261177063\n",
      "mse 1.6318111888736768\n",
      "New best model found at epoch 62 with validation loss 1.631811261177063\n",
      "Starting Epoch 63\n",
      "1.7167661041021347\n",
      "Validation loss: 1.629090428352356\n",
      "mse 1.629090359367747\n",
      "New best model found at epoch 63 with validation loss 1.629090428352356\n",
      "Starting Epoch 64\n",
      "1.7143955528736115\n",
      "Validation loss: 1.626470923423767\n",
      "mse 1.6264709487912619\n",
      "New best model found at epoch 64 with validation loss 1.626470923423767\n",
      "Starting Epoch 65\n",
      "1.7120949526627858\n",
      "Validation loss: 1.6239691972732544\n",
      "mse 1.6239691396622749\n",
      "New best model found at epoch 65 with validation loss 1.6239691972732544\n",
      "Starting Epoch 66\n",
      "1.7098488509654999\n",
      "Validation loss: 1.6214691400527954\n",
      "mse 1.6214690963613494\n",
      "New best model found at epoch 66 with validation loss 1.6214691400527954\n",
      "Starting Epoch 67\n",
      "1.707659622033437\n",
      "Validation loss: 1.6193068027496338\n",
      "mse 1.6193067752045527\n",
      "New best model found at epoch 67 with validation loss 1.6193068027496338\n",
      "Starting Epoch 68\n",
      "1.7055562535921733\n",
      "Validation loss: 1.6169310808181763\n",
      "mse 1.61693116304754\n",
      "New best model found at epoch 68 with validation loss 1.6169310808181763\n",
      "Starting Epoch 69\n",
      "1.70347560942173\n",
      "Validation loss: 1.6147050857543945\n",
      "mse 1.614705040965719\n",
      "New best model found at epoch 69 with validation loss 1.6147050857543945\n",
      "Starting Epoch 70\n",
      "1.701399231950442\n",
      "Validation loss: 1.6127947568893433\n",
      "mse 1.6127947620990446\n",
      "New best model found at epoch 70 with validation loss 1.6127947568893433\n",
      "Starting Epoch 71\n",
      "1.6994608789682388\n",
      "Validation loss: 1.6107943058013916\n",
      "mse 1.6107944191470083\n",
      "New best model found at epoch 71 with validation loss 1.6107943058013916\n",
      "Starting Epoch 72\n",
      "1.697505200902621\n",
      "Validation loss: 1.6089152097702026\n",
      "mse 1.608915199944373\n",
      "New best model found at epoch 72 with validation loss 1.6089152097702026\n",
      "Starting Epoch 73\n",
      "1.6954435755809147\n",
      "Validation loss: 1.6069918870925903\n",
      "mse 1.6069919718663528\n",
      "New best model found at epoch 73 with validation loss 1.6069918870925903\n",
      "Starting Epoch 74\n",
      "1.69345918794473\n",
      "Validation loss: 1.6051433086395264\n",
      "mse 1.6051432629447502\n",
      "New best model found at epoch 74 with validation loss 1.6051433086395264\n",
      "Starting Epoch 75\n",
      "1.6915879746278126\n",
      "Validation loss: 1.603114128112793\n",
      "mse 1.603114279948303\n",
      "New best model found at epoch 75 with validation loss 1.603114128112793\n",
      "Starting Epoch 76\n",
      "1.6897171040376027\n",
      "Validation loss: 1.601190447807312\n",
      "mse 1.6011903573526436\n",
      "New best model found at epoch 76 with validation loss 1.601190447807312\n",
      "Starting Epoch 77\n",
      "1.6878897647062938\n",
      "Validation loss: 1.599370002746582\n",
      "mse 1.5993699896381388\n",
      "New best model found at epoch 77 with validation loss 1.599370002746582\n",
      "Starting Epoch 78\n",
      "1.6861023604869843\n",
      "Validation loss: 1.5974743366241455\n",
      "mse 1.5974742369712696\n",
      "New best model found at epoch 78 with validation loss 1.5974743366241455\n",
      "Starting Epoch 79\n",
      "1.6843830744425456\n",
      "Validation loss: 1.595510721206665\n",
      "mse 1.5955107169291003\n",
      "New best model found at epoch 79 with validation loss 1.595510721206665\n",
      "Starting Epoch 80\n",
      "1.6827048063278198\n",
      "Validation loss: 1.5936790704727173\n",
      "mse 1.5936789623938559\n",
      "New best model found at epoch 80 with validation loss 1.5936790704727173\n",
      "Starting Epoch 81\n",
      "1.6810629119475682\n",
      "Validation loss: 1.5919952392578125\n",
      "mse 1.5919950286412614\n",
      "New best model found at epoch 81 with validation loss 1.5919952392578125\n",
      "Starting Epoch 82\n",
      "1.6794991940259933\n",
      "Validation loss: 1.5902912616729736\n",
      "mse 1.590291225408175\n",
      "New best model found at epoch 82 with validation loss 1.5902912616729736\n",
      "Starting Epoch 83\n",
      "1.6779434730609257\n",
      "Validation loss: 1.588722825050354\n",
      "mse 1.5887228162471332\n",
      "New best model found at epoch 83 with validation loss 1.588722825050354\n",
      "Starting Epoch 84\n",
      "1.6764273742834728\n",
      "Validation loss: 1.5872427225112915\n",
      "mse 1.587242825429704\n",
      "New best model found at epoch 84 with validation loss 1.5872427225112915\n",
      "Starting Epoch 85\n",
      "1.6749464521805446\n",
      "Validation loss: 1.5858272314071655\n",
      "mse 1.585827150846045\n",
      "New best model found at epoch 85 with validation loss 1.5858272314071655\n",
      "Starting Epoch 86\n",
      "1.6735024601221085\n",
      "Validation loss: 1.5844544172286987\n",
      "mse 1.5844544967659084\n",
      "New best model found at epoch 86 with validation loss 1.5844544172286987\n",
      "Starting Epoch 87\n",
      "1.6721091320117314\n",
      "Validation loss: 1.5830321311950684\n",
      "mse 1.583032270807285\n",
      "New best model found at epoch 87 with validation loss 1.5830321311950684\n",
      "Starting Epoch 88\n",
      "1.6707168519496918\n",
      "Validation loss: 1.5817362070083618\n",
      "mse 1.581736121699024\n",
      "New best model found at epoch 88 with validation loss 1.5817362070083618\n",
      "Starting Epoch 89\n",
      "1.6693520347277324\n",
      "Validation loss: 1.5805262327194214\n",
      "mse 1.5805261652254987\n",
      "New best model found at epoch 89 with validation loss 1.5805262327194214\n",
      "Starting Epoch 90\n",
      "1.6680147449175518\n",
      "Validation loss: 1.5793302059173584\n",
      "mse 1.5793301575362773\n",
      "New best model found at epoch 90 with validation loss 1.5793302059173584\n",
      "Starting Epoch 91\n",
      "1.6667027026414871\n",
      "Validation loss: 1.5781514644622803\n",
      "mse 1.5781513551815396\n",
      "New best model found at epoch 91 with validation loss 1.5781514644622803\n",
      "Starting Epoch 92\n",
      "1.6654150138298671\n",
      "Validation loss: 1.5769931077957153\n",
      "mse 1.5769931477657415\n",
      "New best model found at epoch 92 with validation loss 1.5769931077957153\n",
      "Starting Epoch 93\n",
      "1.664150873819987\n",
      "Validation loss: 1.575857162475586\n",
      "mse 1.5758571885885082\n",
      "New best model found at epoch 93 with validation loss 1.575857162475586\n",
      "Starting Epoch 94\n",
      "1.6629206438859303\n",
      "Validation loss: 1.574769377708435\n",
      "mse 1.5747693021378781\n",
      "New best model found at epoch 94 with validation loss 1.574769377708435\n",
      "Starting Epoch 95\n",
      "1.6617092837889988\n",
      "Validation loss: 1.5736823081970215\n",
      "mse 1.5736822569489997\n",
      "New best model found at epoch 95 with validation loss 1.5736823081970215\n",
      "Starting Epoch 96\n",
      "1.6605416536331177\n",
      "Validation loss: 1.5724570751190186\n",
      "mse 1.572457271858821\n",
      "New best model found at epoch 96 with validation loss 1.5724570751190186\n",
      "Starting Epoch 97\n",
      "1.65937440097332\n",
      "Validation loss: 1.5713086128234863\n",
      "mse 1.5713085459758582\n",
      "New best model found at epoch 97 with validation loss 1.5713086128234863\n",
      "Starting Epoch 98\n",
      "1.6582320133845012\n",
      "Validation loss: 1.570224404335022\n",
      "mse 1.5702245013556166\n",
      "New best model found at epoch 98 with validation loss 1.570224404335022\n",
      "Starting Epoch 99\n",
      "1.6571137209733326\n",
      "Validation loss: 1.5691882371902466\n",
      "mse 1.5691881917079893\n",
      "New best model found at epoch 99 with validation loss 1.5691882371902466\n",
      "Starting Epoch 100\n",
      "1.6560175120830536\n",
      "Validation loss: 1.5681923627853394\n",
      "mse 1.5681923809589315\n",
      "New best model found at epoch 100 with validation loss 1.5681923627853394\n",
      "Starting Epoch 101\n",
      "1.6549418816963832\n",
      "Validation loss: 1.5672731399536133\n",
      "mse 1.5672729535858132\n",
      "New best model found at epoch 101 with validation loss 1.5672731399536133\n",
      "Starting Epoch 102\n",
      "1.6538978765408199\n",
      "Validation loss: 1.5662705898284912\n",
      "mse 1.5662707583604927\n",
      "New best model found at epoch 102 with validation loss 1.5662705898284912\n",
      "Starting Epoch 103\n",
      "1.6528619676828384\n",
      "Validation loss: 1.5653347969055176\n",
      "mse 1.565334617439084\n",
      "New best model found at epoch 103 with validation loss 1.5653347969055176\n",
      "Starting Epoch 104\n",
      "1.6518476754426956\n",
      "Validation loss: 1.5643112659454346\n",
      "mse 1.5643111633387017\n",
      "New best model found at epoch 104 with validation loss 1.5643112659454346\n",
      "Starting Epoch 105\n",
      "1.6508504798014958\n",
      "Validation loss: 1.5633697509765625\n",
      "mse 1.5633697571470353\n",
      "New best model found at epoch 105 with validation loss 1.5633697509765625\n",
      "Starting Epoch 106\n",
      "1.6498734305302303\n",
      "Validation loss: 1.562490701675415\n",
      "mse 1.5624907872387328\n",
      "New best model found at epoch 106 with validation loss 1.562490701675415\n",
      "Starting Epoch 107\n",
      "1.6489110787709553\n",
      "Validation loss: 1.5616775751113892\n",
      "mse 1.5616776557170353\n",
      "New best model found at epoch 107 with validation loss 1.5616775751113892\n",
      "Starting Epoch 108\n",
      "1.6479646861553192\n",
      "Validation loss: 1.5608099699020386\n",
      "mse 1.5608098030094664\n",
      "New best model found at epoch 108 with validation loss 1.5608099699020386\n",
      "Starting Epoch 109\n",
      "1.647031898299853\n",
      "Validation loss: 1.5599839687347412\n",
      "mse 1.5599839157722872\n",
      "New best model found at epoch 109 with validation loss 1.5599839687347412\n",
      "Starting Epoch 110\n",
      "1.6461082796255748\n",
      "Validation loss: 1.5592193603515625\n",
      "mse 1.5592193284666132\n",
      "New best model found at epoch 110 with validation loss 1.5592193603515625\n",
      "Starting Epoch 111\n",
      "1.6452053586641948\n",
      "Validation loss: 1.5584694147109985\n",
      "mse 1.5584692326073788\n",
      "New best model found at epoch 111 with validation loss 1.5584694147109985\n",
      "Starting Epoch 112\n",
      "1.6443181037902832\n",
      "Validation loss: 1.5577110052108765\n",
      "mse 1.5577110147991975\n",
      "New best model found at epoch 112 with validation loss 1.5577110052108765\n",
      "Starting Epoch 113\n",
      "1.6434457153081894\n",
      "Validation loss: 1.5569701194763184\n",
      "mse 1.5569702101123222\n",
      "New best model found at epoch 113 with validation loss 1.5569701194763184\n",
      "Starting Epoch 114\n",
      "1.642576664686203\n",
      "Validation loss: 1.5562106370925903\n",
      "mse 1.5562107066082937\n",
      "New best model found at epoch 114 with validation loss 1.5562106370925903\n",
      "Starting Epoch 115\n",
      "1.6417236228783925\n",
      "Validation loss: 1.5554687976837158\n",
      "mse 1.5554687724648237\n",
      "New best model found at epoch 115 with validation loss 1.5554687976837158\n",
      "Starting Epoch 116\n",
      "1.640883892774582\n",
      "Validation loss: 1.554747223854065\n",
      "mse 1.5547471791842207\n",
      "New best model found at epoch 116 with validation loss 1.554747223854065\n",
      "Starting Epoch 117\n",
      "1.6400536447763443\n",
      "Validation loss: 1.5540727376937866\n",
      "mse 1.5540726352087966\n",
      "New best model found at epoch 117 with validation loss 1.5540727376937866\n",
      "Starting Epoch 118\n",
      "1.6392384469509125\n",
      "Validation loss: 1.5534065961837769\n",
      "mse 1.5534066395710595\n",
      "New best model found at epoch 118 with validation loss 1.5534065961837769\n",
      "Starting Epoch 119\n",
      "1.6384369681278865\n",
      "Validation loss: 1.5527487993240356\n",
      "mse 1.5527488389106736\n",
      "New best model found at epoch 119 with validation loss 1.5527487993240356\n",
      "Starting Epoch 120\n",
      "1.637647936741511\n",
      "Validation loss: 1.552101492881775\n",
      "mse 1.5521015198001566\n",
      "New best model found at epoch 120 with validation loss 1.552101492881775\n",
      "Starting Epoch 121\n",
      "1.6369313100973766\n",
      "Validation loss: 1.551112174987793\n",
      "mse 1.5511120584840128\n",
      "New best model found at epoch 121 with validation loss 1.551112174987793\n",
      "Starting Epoch 122\n",
      "1.636120503147443\n",
      "Validation loss: 1.550718069076538\n",
      "mse 1.5507180142814967\n",
      "New best model found at epoch 122 with validation loss 1.550718069076538\n",
      "Starting Epoch 123\n",
      "1.635459582010905\n",
      "Validation loss: 1.5498512983322144\n",
      "mse 1.549851162060526\n",
      "New best model found at epoch 123 with validation loss 1.5498512983322144\n",
      "Starting Epoch 124\n",
      "1.6347320328156154\n",
      "Validation loss: 1.5491156578063965\n",
      "mse 1.5491157156835313\n",
      "New best model found at epoch 124 with validation loss 1.5491156578063965\n",
      "Starting Epoch 125\n",
      "1.6340259561936061\n",
      "Validation loss: 1.548485517501831\n",
      "mse 1.5484855519016285\n",
      "New best model found at epoch 125 with validation loss 1.548485517501831\n",
      "Starting Epoch 126\n",
      "1.633337731162707\n",
      "Validation loss: 1.54792320728302\n",
      "mse 1.547923303031508\n",
      "New best model found at epoch 126 with validation loss 1.54792320728302\n",
      "Starting Epoch 127\n",
      "1.6326630115509033\n",
      "Validation loss: 1.5474039316177368\n",
      "mse 1.547404072656618\n",
      "New best model found at epoch 127 with validation loss 1.5474039316177368\n",
      "Starting Epoch 128\n",
      "1.6319995075464249\n",
      "Validation loss: 1.5469132661819458\n",
      "mse 1.546913098815527\n",
      "New best model found at epoch 128 with validation loss 1.5469132661819458\n",
      "Starting Epoch 129\n",
      "1.6313442786534627\n",
      "Validation loss: 1.546453595161438\n",
      "mse 1.546453749657483\n",
      "New best model found at epoch 129 with validation loss 1.546453595161438\n",
      "Starting Epoch 130\n",
      "1.6307128171126049\n",
      "Validation loss: 1.5459134578704834\n",
      "mse 1.5459133492288406\n",
      "New best model found at epoch 130 with validation loss 1.5459134578704834\n",
      "Starting Epoch 131\n",
      "1.6300819863875706\n",
      "Validation loss: 1.545405387878418\n",
      "mse 1.5454054914623634\n",
      "New best model found at epoch 131 with validation loss 1.545405387878418\n",
      "Starting Epoch 132\n",
      "1.6294595847527187\n",
      "Validation loss: 1.5449270009994507\n",
      "mse 1.5449269694882235\n",
      "New best model found at epoch 132 with validation loss 1.5449270009994507\n",
      "Starting Epoch 133\n",
      "1.6288340985774994\n",
      "Validation loss: 1.5444539785385132\n",
      "mse 1.5444540425251807\n",
      "New best model found at epoch 133 with validation loss 1.5444539785385132\n",
      "Starting Epoch 134\n",
      "1.6282051503658295\n",
      "Validation loss: 1.5438687801361084\n",
      "mse 1.5438688756808923\n",
      "New best model found at epoch 134 with validation loss 1.5438687801361084\n",
      "Starting Epoch 135\n",
      "1.627604454755783\n",
      "Validation loss: 1.5433589220046997\n",
      "mse 1.5433588245489298\n",
      "New best model found at epoch 135 with validation loss 1.5433589220046997\n",
      "Starting Epoch 136\n",
      "1.6270164102315903\n",
      "Validation loss: 1.5429062843322754\n",
      "mse 1.5429062525727986\n",
      "New best model found at epoch 136 with validation loss 1.5429062843322754\n",
      "Starting Epoch 137\n",
      "1.6264392236868541\n",
      "Validation loss: 1.5424907207489014\n",
      "mse 1.5424906190461363\n",
      "New best model found at epoch 137 with validation loss 1.5424907207489014\n",
      "Starting Epoch 138\n",
      "1.6258748670419056\n",
      "Validation loss: 1.5420383214950562\n",
      "mse 1.5420383996608447\n",
      "New best model found at epoch 138 with validation loss 1.5420383214950562\n",
      "Starting Epoch 139\n",
      "1.6253224164247513\n",
      "Validation loss: 1.5416234731674194\n",
      "mse 1.541623396896845\n",
      "New best model found at epoch 139 with validation loss 1.5416234731674194\n",
      "Starting Epoch 140\n",
      "1.6247786184151967\n",
      "Validation loss: 1.5412346124649048\n",
      "mse 1.541234560206747\n",
      "New best model found at epoch 140 with validation loss 1.5412346124649048\n",
      "Starting Epoch 141\n",
      "1.6242535213629405\n",
      "Validation loss: 1.5408122539520264\n",
      "mse 1.5408122517893093\n",
      "New best model found at epoch 141 with validation loss 1.5408122539520264\n",
      "Starting Epoch 142\n",
      "1.6237312853336334\n",
      "Validation loss: 1.5402904748916626\n",
      "mse 1.5402905439185453\n",
      "New best model found at epoch 142 with validation loss 1.5402904748916626\n",
      "Starting Epoch 143\n",
      "1.6232259074846904\n",
      "Validation loss: 1.539934754371643\n",
      "mse 1.5399347262699377\n",
      "New best model found at epoch 143 with validation loss 1.539934754371643\n",
      "Starting Epoch 144\n",
      "1.6227203458547592\n",
      "Validation loss: 1.5394937992095947\n",
      "mse 1.5394936975451257\n",
      "New best model found at epoch 144 with validation loss 1.5394937992095947\n",
      "Starting Epoch 145\n",
      "1.6222325265407562\n",
      "Validation loss: 1.5390729904174805\n",
      "mse 1.5390729887655672\n",
      "New best model found at epoch 145 with validation loss 1.5390729904174805\n",
      "Starting Epoch 146\n",
      "1.621750106414159\n",
      "Validation loss: 1.5386794805526733\n",
      "mse 1.5386795251631489\n",
      "New best model found at epoch 146 with validation loss 1.5386794805526733\n",
      "Starting Epoch 147\n",
      "1.6212734580039978\n",
      "Validation loss: 1.538315773010254\n",
      "mse 1.5383159272261322\n",
      "New best model found at epoch 147 with validation loss 1.538315773010254\n",
      "Starting Epoch 148\n",
      "1.6208041260639827\n",
      "Validation loss: 1.5379739999771118\n",
      "mse 1.5379738448769864\n",
      "New best model found at epoch 148 with validation loss 1.5379739999771118\n",
      "Starting Epoch 149\n",
      "1.6203411271174748\n",
      "Validation loss: 1.5376451015472412\n",
      "mse 1.5376450203719214\n",
      "New best model found at epoch 149 with validation loss 1.5376451015472412\n",
      "Starting Epoch 150\n",
      "1.6198847939570744\n",
      "Validation loss: 1.5373177528381348\n",
      "mse 1.5373178822561717\n",
      "New best model found at epoch 150 with validation loss 1.5373177528381348\n",
      "Starting Epoch 151\n",
      "1.6194330503543217\n",
      "Validation loss: 1.5370018482208252\n",
      "mse 1.5370018539014665\n",
      "New best model found at epoch 151 with validation loss 1.5370018482208252\n",
      "Starting Epoch 152\n",
      "1.6189868748188019\n",
      "Validation loss: 1.5366939306259155\n",
      "mse 1.536693774780948\n",
      "New best model found at epoch 152 with validation loss 1.5366939306259155\n",
      "Starting Epoch 153\n",
      "1.6185458103815715\n",
      "Validation loss: 1.5363918542861938\n",
      "mse 1.5363918189556751\n",
      "New best model found at epoch 153 with validation loss 1.5363918542861938\n",
      "Starting Epoch 154\n",
      "1.6181096235911052\n",
      "Validation loss: 1.536095380783081\n",
      "mse 1.5360954564141462\n",
      "New best model found at epoch 154 with validation loss 1.536095380783081\n",
      "Starting Epoch 155\n",
      "1.6177167842785518\n",
      "Validation loss: 1.5356359481811523\n",
      "mse 1.5356359358151823\n",
      "New best model found at epoch 155 with validation loss 1.5356359481811523\n",
      "Starting Epoch 156\n",
      "1.6172828674316406\n",
      "Validation loss: 1.5353809595108032\n",
      "mse 1.535381032332606\n",
      "New best model found at epoch 156 with validation loss 1.5353809595108032\n",
      "Starting Epoch 157\n",
      "1.6168380677700043\n",
      "Validation loss: 1.5351871252059937\n",
      "mse 1.5351871392512773\n",
      "New best model found at epoch 157 with validation loss 1.5351871252059937\n",
      "Starting Epoch 158\n",
      "1.6164683600266774\n",
      "Validation loss: 1.5348124504089355\n",
      "mse 1.5348123428323943\n",
      "New best model found at epoch 158 with validation loss 1.5348124504089355\n",
      "Starting Epoch 159\n",
      "1.6160559157530467\n",
      "Validation loss: 1.5345759391784668\n",
      "mse 1.5345757669394118\n",
      "New best model found at epoch 159 with validation loss 1.5345759391784668\n",
      "Starting Epoch 160\n",
      "1.6156529287497203\n",
      "Validation loss: 1.5342159271240234\n",
      "mse 1.5342159208292547\n",
      "New best model found at epoch 160 with validation loss 1.5342159271240234\n",
      "Starting Epoch 161\n",
      "1.6152774393558502\n",
      "Validation loss: 1.5340067148208618\n",
      "mse 1.5340067773214945\n",
      "New best model found at epoch 161 with validation loss 1.5340067148208618\n",
      "Starting Epoch 162\n",
      "1.614877387881279\n",
      "Validation loss: 1.5336917638778687\n",
      "mse 1.5336917950117415\n",
      "New best model found at epoch 162 with validation loss 1.5336917638778687\n",
      "Starting Epoch 163\n",
      "1.614501714706421\n",
      "Validation loss: 1.5335016250610352\n",
      "mse 1.533501515120418\n",
      "New best model found at epoch 163 with validation loss 1.5335016250610352\n",
      "Starting Epoch 164\n",
      "1.6141250083843868\n",
      "Validation loss: 1.5332051515579224\n",
      "mse 1.5332051615729667\n",
      "New best model found at epoch 164 with validation loss 1.5332051515579224\n",
      "Starting Epoch 165\n",
      "1.6137353579203289\n",
      "Validation loss: 1.5330157279968262\n",
      "mse 1.5330157221585974\n",
      "New best model found at epoch 165 with validation loss 1.5330157279968262\n",
      "Starting Epoch 166\n",
      "1.613357702891032\n",
      "Validation loss: 1.5326790809631348\n",
      "mse 1.5326791510419182\n",
      "New best model found at epoch 166 with validation loss 1.5326790809631348\n",
      "Starting Epoch 167\n",
      "1.613018199801445\n",
      "Validation loss: 1.53249192237854\n",
      "mse 1.5324920285216839\n",
      "New best model found at epoch 167 with validation loss 1.53249192237854\n",
      "Starting Epoch 168\n",
      "1.6126629660526912\n",
      "Validation loss: 1.5321462154388428\n",
      "mse 1.53214623166088\n",
      "New best model found at epoch 168 with validation loss 1.5321462154388428\n",
      "Starting Epoch 169\n",
      "1.6123071660598118\n",
      "Validation loss: 1.5319609642028809\n",
      "mse 1.5319610949697728\n",
      "New best model found at epoch 169 with validation loss 1.5319609642028809\n",
      "Starting Epoch 170\n",
      "1.6119623929262161\n",
      "Validation loss: 1.5316030979156494\n",
      "mse 1.531603184677438\n",
      "New best model found at epoch 170 with validation loss 1.5316030979156494\n",
      "Starting Epoch 171\n",
      "1.6116155833005905\n",
      "Validation loss: 1.5314515829086304\n",
      "mse 1.5314517547966409\n",
      "New best model found at epoch 171 with validation loss 1.5314515829086304\n",
      "Starting Epoch 172\n",
      "1.6112877875566483\n",
      "Validation loss: 1.531134009361267\n",
      "mse 1.5311339344457007\n",
      "New best model found at epoch 172 with validation loss 1.531134009361267\n",
      "Starting Epoch 173\n",
      "1.6109252174695332\n",
      "Validation loss: 1.530967116355896\n",
      "mse 1.5309671083242267\n",
      "New best model found at epoch 173 with validation loss 1.530967116355896\n",
      "Starting Epoch 174\n",
      "1.610611801346143\n",
      "Validation loss: 1.5306532382965088\n",
      "mse 1.5306531689928304\n",
      "New best model found at epoch 174 with validation loss 1.5306532382965088\n",
      "Starting Epoch 175\n",
      "1.6103033969799678\n",
      "Validation loss: 1.530443787574768\n",
      "mse 1.5304438341207498\n",
      "New best model found at epoch 175 with validation loss 1.530443787574768\n",
      "Starting Epoch 176\n",
      "1.6099511881669362\n",
      "Validation loss: 1.530277132987976\n",
      "mse 1.5302770759256208\n",
      "New best model found at epoch 176 with validation loss 1.530277132987976\n",
      "Starting Epoch 177\n",
      "1.6096296360095341\n",
      "Validation loss: 1.5300709009170532\n",
      "mse 1.5300710016628531\n",
      "New best model found at epoch 177 with validation loss 1.5300709009170532\n",
      "Starting Epoch 178\n",
      "1.6093056400616963\n",
      "Validation loss: 1.5298795700073242\n",
      "mse 1.5298796632074536\n",
      "New best model found at epoch 178 with validation loss 1.5298795700073242\n",
      "Starting Epoch 179\n",
      "1.608998954296112\n",
      "Validation loss: 1.5296517610549927\n",
      "mse 1.529651735108857\n",
      "New best model found at epoch 179 with validation loss 1.5296517610549927\n",
      "Starting Epoch 180\n",
      "1.6087027341127396\n",
      "Validation loss: 1.5294456481933594\n",
      "mse 1.5294455671480498\n",
      "New best model found at epoch 180 with validation loss 1.5294456481933594\n",
      "Starting Epoch 181\n",
      "1.6083810081084569\n",
      "Validation loss: 1.5292563438415527\n",
      "mse 1.5292564273986982\n",
      "New best model found at epoch 181 with validation loss 1.5292563438415527\n",
      "Starting Epoch 182\n",
      "1.6080802480379741\n",
      "Validation loss: 1.5290718078613281\n",
      "mse 1.529071694361716\n",
      "New best model found at epoch 182 with validation loss 1.5290718078613281\n",
      "Starting Epoch 183\n",
      "1.607782244682312\n",
      "Validation loss: 1.5288965702056885\n",
      "mse 1.5288965558453833\n",
      "New best model found at epoch 183 with validation loss 1.5288965702056885\n",
      "Starting Epoch 184\n",
      "1.607488031188647\n",
      "Validation loss: 1.5287123918533325\n",
      "mse 1.5287123955971387\n",
      "New best model found at epoch 184 with validation loss 1.5287123918533325\n",
      "Starting Epoch 185\n",
      "1.6072118331988652\n",
      "Validation loss: 1.5285422801971436\n",
      "mse 1.528542229179854\n",
      "New best model found at epoch 185 with validation loss 1.5285422801971436\n",
      "Starting Epoch 186\n",
      "1.6069065630435944\n",
      "Validation loss: 1.5283704996109009\n",
      "mse 1.5283705262939384\n",
      "New best model found at epoch 186 with validation loss 1.5283704996109009\n",
      "Starting Epoch 187\n",
      "1.6066352128982544\n",
      "Validation loss: 1.5281927585601807\n",
      "mse 1.5281927023276434\n",
      "New best model found at epoch 187 with validation loss 1.5281927585601807\n",
      "Starting Epoch 188\n",
      "1.6063452810049057\n",
      "Validation loss: 1.5280097723007202\n",
      "mse 1.5280097473826044\n",
      "New best model found at epoch 188 with validation loss 1.5280097723007202\n",
      "Starting Epoch 189\n",
      "1.606065387527148\n",
      "Validation loss: 1.5278395414352417\n",
      "mse 1.527839457229506\n",
      "New best model found at epoch 189 with validation loss 1.5278395414352417\n",
      "Starting Epoch 190\n",
      "1.6057904064655304\n",
      "Validation loss: 1.527673363685608\n",
      "mse 1.527673464465407\n",
      "New best model found at epoch 190 with validation loss 1.527673363685608\n",
      "Starting Epoch 191\n",
      "1.6055179238319397\n",
      "Validation loss: 1.5275086164474487\n",
      "mse 1.527508621915536\n",
      "New best model found at epoch 191 with validation loss 1.5275086164474487\n",
      "Starting Epoch 192\n",
      "1.6052562644084294\n",
      "Validation loss: 1.527331829071045\n",
      "mse 1.5273317651885505\n",
      "New best model found at epoch 192 with validation loss 1.527331829071045\n",
      "Starting Epoch 193\n",
      "1.6049865931272507\n",
      "Validation loss: 1.5271650552749634\n",
      "mse 1.5271649888784333\n",
      "New best model found at epoch 193 with validation loss 1.5271650552749634\n",
      "Starting Epoch 194\n",
      "1.6047182182470958\n",
      "Validation loss: 1.5269972085952759\n",
      "mse 1.5269972461650547\n",
      "New best model found at epoch 194 with validation loss 1.5269972085952759\n",
      "Starting Epoch 195\n",
      "1.6044660359621048\n",
      "Validation loss: 1.5268256664276123\n",
      "mse 1.5268256308697508\n",
      "New best model found at epoch 195 with validation loss 1.5268256664276123\n",
      "Starting Epoch 196\n",
      "1.6041999955972035\n",
      "Validation loss: 1.5266594886779785\n",
      "mse 1.526659583472624\n",
      "New best model found at epoch 196 with validation loss 1.5266594886779785\n",
      "Starting Epoch 197\n",
      "1.6039414256811142\n",
      "Validation loss: 1.526495337486267\n",
      "mse 1.5264954101855173\n",
      "New best model found at epoch 197 with validation loss 1.526495337486267\n",
      "Starting Epoch 198\n",
      "1.6036843061447144\n",
      "Validation loss: 1.5263357162475586\n",
      "mse 1.5263357457004019\n",
      "New best model found at epoch 198 with validation loss 1.5263357162475586\n",
      "Starting Epoch 199\n",
      "1.6034376919269562\n",
      "Validation loss: 1.5261683464050293\n",
      "mse 1.5261682266566479\n",
      "New best model found at epoch 199 with validation loss 1.5261683464050293\n",
      "Starting Epoch 200\n",
      "1.6031771500905354\n",
      "Validation loss: 1.526016116142273\n",
      "mse 1.5260160229317765\n",
      "New best model found at epoch 200 with validation loss 1.526016116142273\n",
      "Starting Epoch 201\n",
      "1.6029345591862996\n",
      "Validation loss: 1.5258557796478271\n",
      "mse 1.5258557175886625\n",
      "New best model found at epoch 201 with validation loss 1.5258557796478271\n",
      "Starting Epoch 202\n",
      "1.6026860823233922\n",
      "Validation loss: 1.5256983041763306\n",
      "mse 1.525698333034674\n",
      "New best model found at epoch 202 with validation loss 1.5256983041763306\n",
      "Starting Epoch 203\n",
      "1.602439324061076\n",
      "Validation loss: 1.5255446434020996\n",
      "mse 1.525544653178257\n",
      "New best model found at epoch 203 with validation loss 1.5255446434020996\n",
      "Starting Epoch 204\n",
      "1.602194458246231\n",
      "Validation loss: 1.5253936052322388\n",
      "mse 1.5253936048367476\n",
      "New best model found at epoch 204 with validation loss 1.5253936052322388\n",
      "Starting Epoch 205\n",
      "1.6019513607025146\n",
      "Validation loss: 1.5252445936203003\n",
      "mse 1.525244605980158\n",
      "New best model found at epoch 205 with validation loss 1.5252445936203003\n",
      "Starting Epoch 206\n",
      "1.6017099171876907\n",
      "Validation loss: 1.525097370147705\n",
      "mse 1.525097345866328\n",
      "New best model found at epoch 206 with validation loss 1.525097370147705\n",
      "Starting Epoch 207\n",
      "1.6014701873064041\n",
      "Validation loss: 1.524951457977295\n",
      "mse 1.5249512940778382\n",
      "New best model found at epoch 207 with validation loss 1.524951457977295\n",
      "Starting Epoch 208\n",
      "1.601232002178828\n",
      "Validation loss: 1.5248064994812012\n",
      "mse 1.524806463078429\n",
      "New best model found at epoch 208 with validation loss 1.5248064994812012\n",
      "Starting Epoch 209\n",
      "1.601004034280777\n",
      "Validation loss: 1.5246540307998657\n",
      "mse 1.5246540492891774\n",
      "New best model found at epoch 209 with validation loss 1.5246540307998657\n",
      "Starting Epoch 210\n",
      "1.600755309065183\n",
      "Validation loss: 1.5245239734649658\n",
      "mse 1.5245239407141806\n",
      "New best model found at epoch 210 with validation loss 1.5245239734649658\n",
      "Starting Epoch 211\n",
      "1.6005284388860066\n",
      "Validation loss: 1.524388313293457\n",
      "mse 1.5243883707719512\n",
      "New best model found at epoch 211 with validation loss 1.524388313293457\n",
      "Starting Epoch 212\n",
      "1.6003056863943736\n",
      "Validation loss: 1.5242446660995483\n",
      "mse 1.5242446851010931\n",
      "New best model found at epoch 212 with validation loss 1.5242446660995483\n",
      "Starting Epoch 213\n",
      "1.6000674764315288\n",
      "Validation loss: 1.5241103172302246\n",
      "mse 1.5241103950812591\n",
      "New best model found at epoch 213 with validation loss 1.5241103172302246\n",
      "Starting Epoch 214\n",
      "1.599847878019015\n",
      "Validation loss: 1.523970603942871\n",
      "mse 1.5239705431781767\n",
      "New best model found at epoch 214 with validation loss 1.523970603942871\n",
      "Starting Epoch 215\n",
      "1.5996211965878804\n",
      "Validation loss: 1.523831844329834\n",
      "mse 1.5238318926469696\n",
      "New best model found at epoch 215 with validation loss 1.523831844329834\n",
      "Starting Epoch 216\n",
      "1.5993864784638088\n",
      "Validation loss: 1.5237042903900146\n",
      "mse 1.5237044012921186\n",
      "New best model found at epoch 216 with validation loss 1.5237042903900146\n",
      "Starting Epoch 217\n",
      "1.599172055721283\n",
      "Validation loss: 1.5235704183578491\n",
      "mse 1.5235703810452548\n",
      "New best model found at epoch 217 with validation loss 1.5235704183578491\n",
      "Starting Epoch 218\n",
      "1.5989498694737752\n",
      "Validation loss: 1.5234357118606567\n",
      "mse 1.5234357371382041\n",
      "New best model found at epoch 218 with validation loss 1.5234357118606567\n",
      "Starting Epoch 219\n",
      "1.5987285822629929\n",
      "Validation loss: 1.5233042240142822\n",
      "mse 1.523304283450754\n",
      "New best model found at epoch 219 with validation loss 1.5233042240142822\n",
      "Starting Epoch 220\n",
      "1.5985087951024373\n",
      "Validation loss: 1.523175597190857\n",
      "mse 1.523175466623767\n",
      "New best model found at epoch 220 with validation loss 1.523175597190857\n",
      "Starting Epoch 221\n",
      "1.5982904583215714\n",
      "Validation loss: 1.5230482816696167\n",
      "mse 1.5230483191403252\n",
      "New best model found at epoch 221 with validation loss 1.5230482816696167\n",
      "Starting Epoch 222\n",
      "1.5980733583370845\n",
      "Validation loss: 1.522922396659851\n",
      "mse 1.5229222998144492\n",
      "New best model found at epoch 222 with validation loss 1.522922396659851\n",
      "Starting Epoch 223\n",
      "1.5978576590617497\n",
      "Validation loss: 1.5227971076965332\n",
      "mse 1.5227970338415018\n",
      "New best model found at epoch 223 with validation loss 1.5227971076965332\n",
      "Starting Epoch 224\n",
      "1.5976430277029674\n",
      "Validation loss: 1.5226725339889526\n",
      "mse 1.522672386345203\n",
      "New best model found at epoch 224 with validation loss 1.5226725339889526\n",
      "Starting Epoch 225\n",
      "1.5974296828111012\n",
      "Validation loss: 1.5225481986999512\n",
      "mse 1.522548318446482\n",
      "New best model found at epoch 225 with validation loss 1.5225481986999512\n",
      "Starting Epoch 226\n",
      "1.5972174853086472\n",
      "Validation loss: 1.5224246978759766\n",
      "mse 1.522424538056806\n",
      "New best model found at epoch 226 with validation loss 1.5224246978759766\n",
      "Starting Epoch 227\n",
      "1.597006395459175\n",
      "Validation loss: 1.5223013162612915\n",
      "mse 1.5223013804018652\n",
      "New best model found at epoch 227 with validation loss 1.5223013162612915\n",
      "Starting Epoch 228\n",
      "1.5967964679002762\n",
      "Validation loss: 1.5221786499023438\n",
      "mse 1.5221786674674858\n",
      "New best model found at epoch 228 with validation loss 1.5221786499023438\n",
      "Starting Epoch 229\n",
      "1.5965876132249832\n",
      "Validation loss: 1.5220561027526855\n",
      "mse 1.5220561520735776\n",
      "New best model found at epoch 229 with validation loss 1.5220561027526855\n",
      "Starting Epoch 230\n",
      "1.5963798314332962\n",
      "Validation loss: 1.521934151649475\n",
      "mse 1.5219340972339466\n",
      "New best model found at epoch 230 with validation loss 1.521934151649475\n",
      "Starting Epoch 231\n",
      "1.5961732218662898\n",
      "Validation loss: 1.5218123197555542\n",
      "mse 1.5218124457488622\n",
      "New best model found at epoch 231 with validation loss 1.5218123197555542\n",
      "Starting Epoch 232\n",
      "1.5959674964348476\n",
      "Validation loss: 1.5216909646987915\n",
      "mse 1.5216910520090963\n",
      "New best model found at epoch 232 with validation loss 1.5216909646987915\n",
      "Starting Epoch 233\n",
      "1.5957628935575485\n",
      "Validation loss: 1.5215699672698975\n",
      "mse 1.5215699488391143\n",
      "New best model found at epoch 233 with validation loss 1.5215699672698975\n",
      "Starting Epoch 234\n",
      "1.5955593138933182\n",
      "Validation loss: 1.5214494466781616\n",
      "mse 1.521449435573104\n",
      "New best model found at epoch 234 with validation loss 1.5214494466781616\n",
      "Starting Epoch 235\n",
      "1.5953579793373744\n",
      "Validation loss: 1.5213181972503662\n",
      "mse 1.5213180936473705\n",
      "New best model found at epoch 235 with validation loss 1.5213181972503662\n",
      "Starting Epoch 236\n",
      "1.5951547920703888\n",
      "Validation loss: 1.521194338798523\n",
      "mse 1.521194236709759\n",
      "New best model found at epoch 236 with validation loss 1.521194338798523\n",
      "Starting Epoch 237\n",
      "1.5949520121018093\n",
      "Validation loss: 1.5210834741592407\n",
      "mse 1.5210834506275281\n",
      "New best model found at epoch 237 with validation loss 1.5210834741592407\n",
      "Starting Epoch 238\n",
      "1.594753846526146\n",
      "Validation loss: 1.5209670066833496\n",
      "mse 1.5209671189350098\n",
      "New best model found at epoch 238 with validation loss 1.5209670066833496\n",
      "Starting Epoch 239\n",
      "1.5945558349291484\n",
      "Validation loss: 1.5208491086959839\n",
      "mse 1.5208490924333382\n",
      "New best model found at epoch 239 with validation loss 1.5208491086959839\n",
      "Starting Epoch 240\n",
      "1.5943585534890492\n",
      "Validation loss: 1.52073073387146\n",
      "mse 1.520730712858967\n",
      "New best model found at epoch 240 with validation loss 1.52073073387146\n",
      "Starting Epoch 241\n",
      "1.5941620916128159\n",
      "Validation loss: 1.520612359046936\n",
      "mse 1.5206123411218224\n",
      "New best model found at epoch 241 with validation loss 1.520612359046936\n",
      "Starting Epoch 242\n",
      "1.5939666330814362\n",
      "Validation loss: 1.5204941034317017\n",
      "mse 1.5204940210960236\n",
      "New best model found at epoch 242 with validation loss 1.5204941034317017\n",
      "Starting Epoch 243\n",
      "1.5937719941139221\n",
      "Validation loss: 1.5203759670257568\n",
      "mse 1.5203759923675768\n",
      "New best model found at epoch 243 with validation loss 1.5203759670257568\n",
      "Starting Epoch 244\n",
      "1.5935781796773274\n",
      "Validation loss: 1.5202583074569702\n",
      "mse 1.5202581675579263\n",
      "New best model found at epoch 244 with validation loss 1.5202583074569702\n",
      "Starting Epoch 245\n",
      "1.5933852394421895\n",
      "Validation loss: 1.5201408863067627\n",
      "mse 1.520140789098864\n",
      "New best model found at epoch 245 with validation loss 1.5201408863067627\n",
      "Starting Epoch 246\n",
      "1.5931932578484218\n",
      "Validation loss: 1.5200235843658447\n",
      "mse 1.5200236506268154\n",
      "New best model found at epoch 246 with validation loss 1.5200235843658447\n",
      "Starting Epoch 247\n",
      "1.5930081605911255\n",
      "Validation loss: 1.5198912620544434\n",
      "mse 1.5198912309169916\n",
      "New best model found at epoch 247 with validation loss 1.5198912620544434\n",
      "Starting Epoch 248\n",
      "1.5928139090538025\n",
      "Validation loss: 1.5197696685791016\n",
      "mse 1.5197696325676007\n",
      "New best model found at epoch 248 with validation loss 1.5197696685791016\n",
      "Starting Epoch 249\n",
      "1.5926225731770198\n",
      "Validation loss: 1.5196552276611328\n",
      "mse 1.5196551644869878\n",
      "New best model found at epoch 249 with validation loss 1.5196552276611328\n",
      "Starting Epoch 250\n",
      "1.592437411348025\n",
      "Validation loss: 1.5195070505142212\n",
      "mse 1.5195070693080648\n",
      "New best model found at epoch 250 with validation loss 1.5195070505142212\n",
      "Starting Epoch 251\n",
      "1.5922388831774394\n",
      "Validation loss: 1.5192149877548218\n",
      "mse 1.519214955957099\n",
      "New best model found at epoch 251 with validation loss 1.5192149877548218\n",
      "Starting Epoch 252\n",
      "1.591991459329923\n",
      "Validation loss: 1.5188145637512207\n",
      "mse 1.5188144465720292\n",
      "New best model found at epoch 252 with validation loss 1.5188145637512207\n",
      "Starting Epoch 253\n",
      "1.5917404343684514\n",
      "Validation loss: 1.5184447765350342\n",
      "mse 1.5184448963924815\n",
      "New best model found at epoch 253 with validation loss 1.5184447765350342\n",
      "Starting Epoch 254\n",
      "1.5914935171604156\n",
      "Validation loss: 1.5180362462997437\n",
      "mse 1.518036153188891\n",
      "New best model found at epoch 254 with validation loss 1.5180362462997437\n",
      "Starting Epoch 255\n",
      "1.5912320017814636\n",
      "Validation loss: 1.517727017402649\n",
      "mse 1.517727076383945\n",
      "New best model found at epoch 255 with validation loss 1.517727017402649\n",
      "Starting Epoch 256\n",
      "1.5909842948118846\n",
      "Validation loss: 1.5174671411514282\n",
      "mse 1.5174672923113006\n",
      "New best model found at epoch 256 with validation loss 1.5174671411514282\n",
      "Starting Epoch 257\n",
      "1.5907438546419144\n",
      "Validation loss: 1.5172382593154907\n",
      "mse 1.517238244386004\n",
      "New best model found at epoch 257 with validation loss 1.5172382593154907\n",
      "Starting Epoch 258\n",
      "1.5905083119869232\n",
      "Validation loss: 1.5170296430587769\n",
      "mse 1.5170296263621028\n",
      "New best model found at epoch 258 with validation loss 1.5170296430587769\n",
      "Starting Epoch 259\n",
      "1.590276688337326\n",
      "Validation loss: 1.5168354511260986\n",
      "mse 1.516835349578653\n",
      "New best model found at epoch 259 with validation loss 1.5168354511260986\n",
      "Starting Epoch 260\n",
      "1.590048263470332\n",
      "Validation loss: 1.516650915145874\n",
      "mse 1.5166509919832798\n",
      "New best model found at epoch 260 with validation loss 1.516650915145874\n",
      "Starting Epoch 261\n",
      "1.5898225953181584\n",
      "Validation loss: 1.5164741277694702\n",
      "mse 1.5164740083841894\n",
      "New best model found at epoch 261 with validation loss 1.5164741277694702\n",
      "Starting Epoch 262\n",
      "1.5895995597044628\n",
      "Validation loss: 1.5163025856018066\n",
      "mse 1.5163026475769523\n",
      "New best model found at epoch 262 with validation loss 1.5163025856018066\n",
      "Starting Epoch 263\n",
      "1.589378794034322\n",
      "Validation loss: 1.5161352157592773\n",
      "mse 1.5161352297688362\n",
      "New best model found at epoch 263 with validation loss 1.5161352157592773\n",
      "Starting Epoch 264\n",
      "1.5891602436701457\n",
      "Validation loss: 1.515971302986145\n",
      "mse 1.5159714411449219\n",
      "New best model found at epoch 264 with validation loss 1.515971302986145\n",
      "Starting Epoch 265\n",
      "1.5889438837766647\n",
      "Validation loss: 1.515810251235962\n",
      "mse 1.515810255366046\n",
      "New best model found at epoch 265 with validation loss 1.515810251235962\n",
      "Starting Epoch 266\n",
      "1.5887295007705688\n",
      "Validation loss: 1.5156513452529907\n",
      "mse 1.5156514129095744\n",
      "New best model found at epoch 266 with validation loss 1.5156513452529907\n",
      "Starting Epoch 267\n",
      "1.5885144621133804\n",
      "Validation loss: 1.5155022144317627\n",
      "mse 1.5155020779769877\n",
      "New best model found at epoch 267 with validation loss 1.5155022144317627\n",
      "Starting Epoch 268\n",
      "1.5883034865061443\n",
      "Validation loss: 1.5153610706329346\n",
      "mse 1.5153611101896058\n",
      "New best model found at epoch 268 with validation loss 1.5153610706329346\n",
      "Starting Epoch 269\n",
      "1.5880958586931229\n",
      "Validation loss: 1.515223741531372\n",
      "mse 1.5152237734058147\n",
      "New best model found at epoch 269 with validation loss 1.515223741531372\n",
      "Starting Epoch 270\n",
      "1.587892323732376\n",
      "Validation loss: 1.515081763267517\n",
      "mse 1.5150816571894465\n",
      "New best model found at epoch 270 with validation loss 1.515081763267517\n",
      "Starting Epoch 271\n",
      "1.587688793738683\n",
      "Validation loss: 1.5149542093276978\n",
      "mse 1.5149541060985787\n",
      "New best model found at epoch 271 with validation loss 1.5149542093276978\n",
      "Starting Epoch 272\n",
      "1.5874899278084438\n",
      "Validation loss: 1.5148175954818726\n",
      "mse 1.5148175838204083\n",
      "New best model found at epoch 272 with validation loss 1.5148175954818726\n",
      "Starting Epoch 273\n",
      "1.5872918367385864\n",
      "Validation loss: 1.5146780014038086\n",
      "mse 1.5146779344338184\n",
      "New best model found at epoch 273 with validation loss 1.5146780014038086\n",
      "Starting Epoch 274\n",
      "1.587094858288765\n",
      "Validation loss: 1.514536738395691\n",
      "mse 1.5145367071987825\n",
      "New best model found at epoch 274 with validation loss 1.514536738395691\n",
      "Starting Epoch 275\n",
      "1.5868990818659465\n",
      "Validation loss: 1.5143951177597046\n",
      "mse 1.5143949878966643\n",
      "New best model found at epoch 275 with validation loss 1.5143951177597046\n",
      "Starting Epoch 276\n",
      "1.5867026696602504\n",
      "Validation loss: 1.5142638683319092\n",
      "mse 1.514263999220992\n",
      "New best model found at epoch 276 with validation loss 1.5142638683319092\n",
      "Starting Epoch 277\n",
      "1.586507687966029\n",
      "Validation loss: 1.5141446590423584\n",
      "mse 1.5141447245859208\n",
      "New best model found at epoch 277 with validation loss 1.5141446590423584\n",
      "Starting Epoch 278\n",
      "1.5863219896952312\n",
      "Validation loss: 1.5140248537063599\n",
      "mse 1.5140248558524452\n",
      "New best model found at epoch 278 with validation loss 1.5140248537063599\n",
      "Starting Epoch 279\n",
      "1.586136132478714\n",
      "Validation loss: 1.5139042139053345\n",
      "mse 1.5139042881002958\n",
      "New best model found at epoch 279 with validation loss 1.5139042139053345\n",
      "Starting Epoch 280\n",
      "1.5859538863102596\n",
      "Validation loss: 1.5137842893600464\n",
      "mse 1.5137842128089596\n",
      "New best model found at epoch 280 with validation loss 1.5137842893600464\n",
      "Starting Epoch 281\n",
      "1.5857736219962437\n",
      "Validation loss: 1.513666033744812\n",
      "mse 1.5136660555117871\n",
      "New best model found at epoch 281 with validation loss 1.513666033744812\n",
      "Starting Epoch 282\n",
      "1.5855956425269444\n",
      "Validation loss: 1.5135678052902222\n",
      "mse 1.5135676657207626\n",
      "New best model found at epoch 282 with validation loss 1.5135678052902222\n",
      "Starting Epoch 283\n",
      "1.585420365134875\n",
      "Validation loss: 1.5134572982788086\n",
      "mse 1.5134574140393953\n",
      "New best model found at epoch 283 with validation loss 1.5134572982788086\n",
      "Starting Epoch 284\n",
      "1.5852450182040532\n",
      "Validation loss: 1.513340711593628\n",
      "mse 1.5133407238256924\n",
      "New best model found at epoch 284 with validation loss 1.513340711593628\n",
      "Starting Epoch 285\n",
      "1.5850701679786046\n",
      "Validation loss: 1.5132240056991577\n",
      "mse 1.5132239839427408\n",
      "New best model found at epoch 285 with validation loss 1.5132240056991577\n",
      "Starting Epoch 286\n",
      "1.5848966042200725\n",
      "Validation loss: 1.5131032466888428\n",
      "mse 1.513103196325523\n",
      "New best model found at epoch 286 with validation loss 1.5131032466888428\n",
      "Starting Epoch 287\n",
      "1.5847237706184387\n",
      "Validation loss: 1.5129890441894531\n",
      "mse 1.5129890852077241\n",
      "New best model found at epoch 287 with validation loss 1.5129890441894531\n",
      "Starting Epoch 288\n",
      "1.5845527897278469\n",
      "Validation loss: 1.5128697156906128\n",
      "mse 1.5128696549355767\n",
      "New best model found at epoch 288 with validation loss 1.5128697156906128\n",
      "Starting Epoch 289\n",
      "1.5843820919593175\n",
      "Validation loss: 1.5127476453781128\n",
      "mse 1.5127475699608826\n",
      "New best model found at epoch 289 with validation loss 1.5127476453781128\n",
      "Starting Epoch 290\n",
      "1.5842118958632152\n",
      "Validation loss: 1.5126243829727173\n",
      "mse 1.512624318176057\n",
      "New best model found at epoch 290 with validation loss 1.5126243829727173\n",
      "Starting Epoch 291\n",
      "1.5840425193309784\n",
      "Validation loss: 1.512500286102295\n",
      "mse 1.5125004340305028\n",
      "New best model found at epoch 291 with validation loss 1.512500286102295\n",
      "Starting Epoch 292\n",
      "1.5838737587134044\n",
      "Validation loss: 1.512376308441162\n",
      "mse 1.5123762655329818\n",
      "New best model found at epoch 292 with validation loss 1.512376308441162\n",
      "Starting Epoch 293\n",
      "1.5837056785821915\n",
      "Validation loss: 1.512251853942871\n",
      "mse 1.5122518426148865\n",
      "New best model found at epoch 293 with validation loss 1.512251853942871\n",
      "Starting Epoch 294\n",
      "1.5835383087396622\n",
      "Validation loss: 1.5121275186538696\n",
      "mse 1.5121276911368644\n",
      "New best model found at epoch 294 with validation loss 1.5121275186538696\n",
      "Starting Epoch 295\n",
      "1.5833715746800106\n",
      "Validation loss: 1.5120036602020264\n",
      "mse 1.5120037226363376\n",
      "New best model found at epoch 295 with validation loss 1.5120036602020264\n",
      "Starting Epoch 296\n",
      "1.5832056452830632\n",
      "Validation loss: 1.5118800401687622\n",
      "mse 1.5118800052529116\n",
      "New best model found at epoch 296 with validation loss 1.5118800401687622\n",
      "Starting Epoch 297\n",
      "1.5830402821302414\n",
      "Validation loss: 1.5117568969726562\n",
      "mse 1.5117568147672822\n",
      "New best model found at epoch 297 with validation loss 1.5117568969726562\n",
      "Starting Epoch 298\n",
      "1.5828756392002106\n",
      "Validation loss: 1.5116338729858398\n",
      "mse 1.511633921384845\n",
      "New best model found at epoch 298 with validation loss 1.5116338729858398\n",
      "Starting Epoch 299\n",
      "1.5827117015918095\n",
      "Validation loss: 1.5115114450454712\n",
      "mse 1.5115113579052701\n",
      "New best model found at epoch 299 with validation loss 1.5115114450454712\n",
      "Starting Epoch 300\n",
      "1.5825483351945877\n",
      "Validation loss: 1.5113892555236816\n",
      "mse 1.5113892236974185\n",
      "New best model found at epoch 300 with validation loss 1.5113892555236816\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-10-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf6e76",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 3\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 20 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "233fd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d5df51ba-a4b0-4341-96ae-0bb4fc6a6672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.459526479244232\n",
      "Validation loss: 2.693554639816284\n",
      "mse 2.6935546938171884\n",
      "New best model found at epoch 1 with validation loss 2.693554639816284\n",
      "Starting Epoch 2\n",
      "2.4239876021941504\n",
      "Validation loss: 2.4096505641937256\n",
      "mse 2.40965050277002\n",
      "New best model found at epoch 2 with validation loss 2.4096505641937256\n",
      "Starting Epoch 3\n",
      "2.2789927075306573\n",
      "Validation loss: 2.2913897037506104\n",
      "mse 2.291389718326348\n",
      "New best model found at epoch 3 with validation loss 2.2913897037506104\n",
      "Starting Epoch 4\n",
      "2.1957459996143975\n",
      "Validation loss: 2.2024447917938232\n",
      "mse 2.2024450440201835\n",
      "New best model found at epoch 4 with validation loss 2.2024447917938232\n",
      "Starting Epoch 5\n",
      "2.132352297504743\n",
      "Validation loss: 2.1302337646484375\n",
      "mse 2.130233729642197\n",
      "New best model found at epoch 5 with validation loss 2.1302337646484375\n",
      "Starting Epoch 6\n",
      "2.0788908700148263\n",
      "Validation loss: 2.0684335231781006\n",
      "mse 2.0684334534696727\n",
      "New best model found at epoch 6 with validation loss 2.0684335231781006\n",
      "Starting Epoch 7\n",
      "2.0334249387184777\n",
      "Validation loss: 2.0152995586395264\n",
      "mse 2.0152997056687996\n",
      "New best model found at epoch 7 with validation loss 2.0152995586395264\n",
      "Starting Epoch 8\n",
      "1.995764156182607\n",
      "Validation loss: 1.9716005325317383\n",
      "mse 1.9716005412853626\n",
      "New best model found at epoch 8 with validation loss 1.9716005325317383\n",
      "Starting Epoch 9\n",
      "1.9645128746827443\n",
      "Validation loss: 1.934746503829956\n",
      "mse 1.9347464827814034\n",
      "New best model found at epoch 9 with validation loss 1.934746503829956\n",
      "Starting Epoch 10\n",
      "1.9368306696414948\n",
      "Validation loss: 1.9003522396087646\n",
      "mse 1.9003521004105275\n",
      "New best model found at epoch 10 with validation loss 1.9003522396087646\n",
      "Starting Epoch 11\n",
      "1.9123915831247966\n",
      "Validation loss: 1.8717830181121826\n",
      "mse 1.871783080534619\n",
      "New best model found at epoch 11 with validation loss 1.8717830181121826\n",
      "Starting Epoch 12\n",
      "1.891444926460584\n",
      "Validation loss: 1.8475162982940674\n",
      "mse 1.8475161555610655\n",
      "New best model found at epoch 12 with validation loss 1.8475162982940674\n",
      "Starting Epoch 13\n",
      "1.8731908996899922\n",
      "Validation loss: 1.8260427713394165\n",
      "mse 1.8260426958202134\n",
      "New best model found at epoch 13 with validation loss 1.8260427713394165\n",
      "Starting Epoch 14\n",
      "1.8568446238835652\n",
      "Validation loss: 1.8068903684616089\n",
      "mse 1.8068903557249962\n",
      "New best model found at epoch 14 with validation loss 1.8068903684616089\n",
      "Starting Epoch 15\n",
      "1.8418268809715908\n",
      "Validation loss: 1.7889699935913086\n",
      "mse 1.7889701165475844\n",
      "New best model found at epoch 15 with validation loss 1.7889699935913086\n",
      "Starting Epoch 16\n",
      "1.8279505123694737\n",
      "Validation loss: 1.7725802659988403\n",
      "mse 1.772580486422487\n",
      "New best model found at epoch 16 with validation loss 1.7725802659988403\n",
      "Starting Epoch 17\n",
      "1.8152449627717335\n",
      "Validation loss: 1.7578155994415283\n",
      "mse 1.7578156823062223\n",
      "New best model found at epoch 17 with validation loss 1.7578155994415283\n",
      "Starting Epoch 18\n",
      "1.8035232871770859\n",
      "Validation loss: 1.7440650463104248\n",
      "mse 1.7440649250608844\n",
      "New best model found at epoch 18 with validation loss 1.7440650463104248\n",
      "Starting Epoch 19\n",
      "1.792634293437004\n",
      "Validation loss: 1.7312926054000854\n",
      "mse 1.7312925907023906\n",
      "New best model found at epoch 19 with validation loss 1.7312926054000854\n",
      "Starting Epoch 20\n",
      "1.7825702726840973\n",
      "Validation loss: 1.7193759679794312\n",
      "mse 1.7193760339665412\n",
      "New best model found at epoch 20 with validation loss 1.7193759679794312\n",
      "Starting Epoch 21\n",
      "1.7731510152419407\n",
      "Validation loss: 1.708463191986084\n",
      "mse 1.708463169289318\n",
      "New best model found at epoch 21 with validation loss 1.708463191986084\n",
      "Starting Epoch 22\n",
      "1.7643667608499527\n",
      "Validation loss: 1.6982579231262207\n",
      "mse 1.6982579337668882\n",
      "New best model found at epoch 22 with validation loss 1.6982579231262207\n",
      "Starting Epoch 23\n",
      "1.7561123768488567\n",
      "Validation loss: 1.6887673139572144\n",
      "mse 1.68876726820209\n",
      "New best model found at epoch 23 with validation loss 1.6887673139572144\n",
      "Starting Epoch 24\n",
      "1.7483149816592534\n",
      "Validation loss: 1.680108666419983\n",
      "mse 1.6801088350330873\n",
      "New best model found at epoch 24 with validation loss 1.680108666419983\n",
      "Starting Epoch 25\n",
      "1.7410040646791458\n",
      "Validation loss: 1.6715235710144043\n",
      "mse 1.671523591062386\n",
      "New best model found at epoch 25 with validation loss 1.6715235710144043\n",
      "Starting Epoch 26\n",
      "1.7340815713008244\n",
      "Validation loss: 1.664186954498291\n",
      "mse 1.6641867462389466\n",
      "New best model found at epoch 26 with validation loss 1.664186954498291\n",
      "Starting Epoch 27\n",
      "1.7276767740646999\n",
      "Validation loss: 1.6566483974456787\n",
      "mse 1.6566483945187118\n",
      "New best model found at epoch 27 with validation loss 1.6566483974456787\n",
      "Starting Epoch 28\n",
      "1.721556931734085\n",
      "Validation loss: 1.649571418762207\n",
      "mse 1.6495713460046912\n",
      "New best model found at epoch 28 with validation loss 1.649571418762207\n",
      "Starting Epoch 29\n",
      "1.7157879521449406\n",
      "Validation loss: 1.6429719924926758\n",
      "mse 1.642971920977306\n",
      "New best model found at epoch 29 with validation loss 1.6429719924926758\n",
      "Starting Epoch 30\n",
      "1.710297668973605\n",
      "Validation loss: 1.6367285251617432\n",
      "mse 1.636728539184224\n",
      "New best model found at epoch 30 with validation loss 1.6367285251617432\n",
      "Starting Epoch 31\n",
      "1.7051357229550679\n",
      "Validation loss: 1.6307637691497803\n",
      "mse 1.6307637263270605\n",
      "New best model found at epoch 31 with validation loss 1.6307637691497803\n",
      "Starting Epoch 32\n",
      "1.700095718105634\n",
      "Validation loss: 1.6251918077468872\n",
      "mse 1.6251918100421445\n",
      "New best model found at epoch 32 with validation loss 1.6251918077468872\n",
      "Starting Epoch 33\n",
      "1.6952507098515828\n",
      "Validation loss: 1.6198090314865112\n",
      "mse 1.619808959149659\n",
      "New best model found at epoch 33 with validation loss 1.6198090314865112\n",
      "Starting Epoch 34\n",
      "1.6905870934327443\n",
      "Validation loss: 1.6147725582122803\n",
      "mse 1.6147725557394788\n",
      "New best model found at epoch 34 with validation loss 1.6147725582122803\n",
      "Starting Epoch 35\n",
      "1.6861912906169891\n",
      "Validation loss: 1.610036849975586\n",
      "mse 1.610036896359046\n",
      "New best model found at epoch 35 with validation loss 1.610036849975586\n",
      "Starting Epoch 36\n",
      "1.6820099254449208\n",
      "Validation loss: 1.6053487062454224\n",
      "mse 1.6053486915685342\n",
      "New best model found at epoch 36 with validation loss 1.6053487062454224\n",
      "Starting Epoch 37\n",
      "1.677970290184021\n",
      "Validation loss: 1.6008706092834473\n",
      "mse 1.6008705867848003\n",
      "New best model found at epoch 37 with validation loss 1.6008706092834473\n",
      "Starting Epoch 38\n",
      "1.674095332622528\n",
      "Validation loss: 1.5967350006103516\n",
      "mse 1.5967350172070705\n",
      "New best model found at epoch 38 with validation loss 1.5967350006103516\n",
      "Starting Epoch 39\n",
      "1.6704087505737941\n",
      "Validation loss: 1.5926724672317505\n",
      "mse 1.5926725088434097\n",
      "New best model found at epoch 39 with validation loss 1.5926724672317505\n",
      "Starting Epoch 40\n",
      "1.6669050604104996\n",
      "Validation loss: 1.5888768434524536\n",
      "mse 1.5888768058747886\n",
      "New best model found at epoch 40 with validation loss 1.5888768434524536\n",
      "Starting Epoch 41\n",
      "1.6635053356488545\n",
      "Validation loss: 1.5851753950119019\n",
      "mse 1.5851752972382462\n",
      "New best model found at epoch 41 with validation loss 1.5851753950119019\n",
      "Starting Epoch 42\n",
      "1.6602218945821126\n",
      "Validation loss: 1.58158540725708\n",
      "mse 1.5815853465794762\n",
      "New best model found at epoch 42 with validation loss 1.58158540725708\n",
      "Starting Epoch 43\n",
      "1.6570315112670262\n",
      "Validation loss: 1.5782420635223389\n",
      "mse 1.5782420417846599\n",
      "New best model found at epoch 43 with validation loss 1.5782420635223389\n",
      "Starting Epoch 44\n",
      "1.6539827485879262\n",
      "Validation loss: 1.574997901916504\n",
      "mse 1.5749980650630808\n",
      "New best model found at epoch 44 with validation loss 1.574997901916504\n",
      "Starting Epoch 45\n",
      "1.6510368784268696\n",
      "Validation loss: 1.572090983390808\n",
      "mse 1.57209090919877\n",
      "New best model found at epoch 45 with validation loss 1.572090983390808\n",
      "Starting Epoch 46\n",
      "1.6482567141453426\n",
      "Validation loss: 1.5692086219787598\n",
      "mse 1.569208650308268\n",
      "New best model found at epoch 46 with validation loss 1.5692086219787598\n",
      "Starting Epoch 47\n",
      "1.6455996582905452\n",
      "Validation loss: 1.5663951635360718\n",
      "mse 1.5663951585192901\n",
      "New best model found at epoch 47 with validation loss 1.5663951635360718\n",
      "Starting Epoch 48\n",
      "1.6430082072814305\n",
      "Validation loss: 1.5636820793151855\n",
      "mse 1.5636821517372375\n",
      "New best model found at epoch 48 with validation loss 1.5636820793151855\n",
      "Starting Epoch 49\n",
      "1.6404981464147568\n",
      "Validation loss: 1.5611579418182373\n",
      "mse 1.5611580411062684\n",
      "New best model found at epoch 49 with validation loss 1.5611579418182373\n",
      "Starting Epoch 50\n",
      "1.6381123512983322\n",
      "Validation loss: 1.5587234497070312\n",
      "mse 1.55872349345419\n",
      "New best model found at epoch 50 with validation loss 1.5587234497070312\n",
      "Starting Epoch 51\n",
      "1.635805105169614\n",
      "Validation loss: 1.5563770532608032\n",
      "mse 1.5563772410079102\n",
      "New best model found at epoch 51 with validation loss 1.5563770532608032\n",
      "Starting Epoch 52\n",
      "1.6335681627194087\n",
      "Validation loss: 1.5541130304336548\n",
      "mse 1.5541129001143854\n",
      "New best model found at epoch 52 with validation loss 1.5541130304336548\n",
      "Starting Epoch 53\n",
      "1.6313635458548863\n",
      "Validation loss: 1.5519412755966187\n",
      "mse 1.5519413544669647\n",
      "New best model found at epoch 53 with validation loss 1.5519412755966187\n",
      "Starting Epoch 54\n",
      "1.6292853554089863\n",
      "Validation loss: 1.5498937368392944\n",
      "mse 1.5498937724615585\n",
      "New best model found at epoch 54 with validation loss 1.5498937368392944\n",
      "Starting Epoch 55\n",
      "1.6272401760021846\n",
      "Validation loss: 1.547946572303772\n",
      "mse 1.5479465855096257\n",
      "New best model found at epoch 55 with validation loss 1.547946572303772\n",
      "Starting Epoch 56\n",
      "1.6252941091855366\n",
      "Validation loss: 1.5460422039031982\n",
      "mse 1.5460421779735611\n",
      "New best model found at epoch 56 with validation loss 1.5460422039031982\n",
      "Starting Epoch 57\n",
      "1.6233783811330795\n",
      "Validation loss: 1.5442734956741333\n",
      "mse 1.5442734250382235\n",
      "New best model found at epoch 57 with validation loss 1.5442734956741333\n",
      "Starting Epoch 58\n",
      "1.6215405116478603\n",
      "Validation loss: 1.542437195777893\n",
      "mse 1.5424371821576175\n",
      "New best model found at epoch 58 with validation loss 1.542437195777893\n",
      "Starting Epoch 59\n",
      "1.6197658826907475\n",
      "Validation loss: 1.5407665967941284\n",
      "mse 1.5407665344886634\n",
      "New best model found at epoch 59 with validation loss 1.5407665967941284\n",
      "Starting Epoch 60\n",
      "1.618074397246043\n",
      "Validation loss: 1.539184808731079\n",
      "mse 1.5391848326667277\n",
      "New best model found at epoch 60 with validation loss 1.539184808731079\n",
      "Starting Epoch 61\n",
      "1.6164007037878036\n",
      "Validation loss: 1.5375202894210815\n",
      "mse 1.5375201272105283\n",
      "New best model found at epoch 61 with validation loss 1.5375202894210815\n",
      "Starting Epoch 62\n",
      "1.6147886663675308\n",
      "Validation loss: 1.5360219478607178\n",
      "mse 1.5360219509977269\n",
      "New best model found at epoch 62 with validation loss 1.5360219478607178\n",
      "Starting Epoch 63\n",
      "1.6132052093744278\n",
      "Validation loss: 1.5345028638839722\n",
      "mse 1.5345029263271872\n",
      "New best model found at epoch 63 with validation loss 1.5345028638839722\n",
      "Starting Epoch 64\n",
      "1.6117014239231746\n",
      "Validation loss: 1.533076524734497\n",
      "mse 1.5330765452508137\n",
      "New best model found at epoch 64 with validation loss 1.533076524734497\n",
      "Starting Epoch 65\n",
      "1.6101858069499333\n",
      "Validation loss: 1.5316418409347534\n",
      "mse 1.5316418283315099\n",
      "New best model found at epoch 65 with validation loss 1.5316418409347534\n",
      "Starting Epoch 66\n",
      "1.608693520228068\n",
      "Validation loss: 1.5301876068115234\n",
      "mse 1.530187422605535\n",
      "New best model found at epoch 66 with validation loss 1.5301876068115234\n",
      "Starting Epoch 67\n",
      "1.6072755207618077\n",
      "Validation loss: 1.5288418531417847\n",
      "mse 1.5288418560352046\n",
      "New best model found at epoch 67 with validation loss 1.5288418531417847\n",
      "Starting Epoch 68\n",
      "1.6059021453062694\n",
      "Validation loss: 1.5275195837020874\n",
      "mse 1.5275194832157564\n",
      "New best model found at epoch 68 with validation loss 1.5275195837020874\n",
      "Starting Epoch 69\n",
      "1.604568635423978\n",
      "Validation loss: 1.526218056678772\n",
      "mse 1.526218025213377\n",
      "New best model found at epoch 69 with validation loss 1.526218056678772\n",
      "Starting Epoch 70\n",
      "1.6032872597376506\n",
      "Validation loss: 1.5249842405319214\n",
      "mse 1.5249841511728142\n",
      "New best model found at epoch 70 with validation loss 1.5249842405319214\n",
      "Starting Epoch 71\n",
      "1.6020273317893345\n",
      "Validation loss: 1.523800015449524\n",
      "mse 1.5238001017958682\n",
      "New best model found at epoch 71 with validation loss 1.523800015449524\n",
      "Starting Epoch 72\n",
      "1.6007880369822185\n",
      "Validation loss: 1.5225831270217896\n",
      "mse 1.5225830493841976\n",
      "New best model found at epoch 72 with validation loss 1.5225831270217896\n",
      "Starting Epoch 73\n",
      "1.5996125588814418\n",
      "Validation loss: 1.5215214490890503\n",
      "mse 1.5215214536619612\n",
      "New best model found at epoch 73 with validation loss 1.5215214490890503\n",
      "Starting Epoch 74\n",
      "1.5984433392683666\n",
      "Validation loss: 1.5203896760940552\n",
      "mse 1.5203897638197037\n",
      "New best model found at epoch 74 with validation loss 1.5203896760940552\n",
      "Starting Epoch 75\n",
      "1.597327098250389\n",
      "Validation loss: 1.5193830728530884\n",
      "mse 1.519383020086722\n",
      "New best model found at epoch 75 with validation loss 1.5193830728530884\n",
      "Starting Epoch 76\n",
      "1.5961921413739522\n",
      "Validation loss: 1.5184099674224854\n",
      "mse 1.518409941706653\n",
      "New best model found at epoch 76 with validation loss 1.5184099674224854\n",
      "Starting Epoch 77\n",
      "1.5950763672590256\n",
      "Validation loss: 1.5174835920333862\n",
      "mse 1.5174836531486562\n",
      "New best model found at epoch 77 with validation loss 1.5174835920333862\n",
      "Starting Epoch 78\n",
      "1.5939377397298813\n",
      "Validation loss: 1.5166120529174805\n",
      "mse 1.5166120579031435\n",
      "New best model found at epoch 78 with validation loss 1.5166120529174805\n",
      "Starting Epoch 79\n",
      "1.5928567002216976\n",
      "Validation loss: 1.5156786441802979\n",
      "mse 1.5156787020579416\n",
      "New best model found at epoch 79 with validation loss 1.5156786441802979\n",
      "Starting Epoch 80\n",
      "1.5917785068353016\n",
      "Validation loss: 1.5147948265075684\n",
      "mse 1.5147949038173885\n",
      "New best model found at epoch 80 with validation loss 1.5147948265075684\n",
      "Starting Epoch 81\n",
      "1.590748444199562\n",
      "Validation loss: 1.5139187574386597\n",
      "mse 1.5139186790795287\n",
      "New best model found at epoch 81 with validation loss 1.5139187574386597\n",
      "Starting Epoch 82\n",
      "1.5897410263617833\n",
      "Validation loss: 1.5130698680877686\n",
      "mse 1.5130698200640587\n",
      "New best model found at epoch 82 with validation loss 1.5130698680877686\n",
      "Starting Epoch 83\n",
      "1.5887557317813237\n",
      "Validation loss: 1.5122206211090088\n",
      "mse 1.5122205926942223\n",
      "New best model found at epoch 83 with validation loss 1.5122206211090088\n",
      "Starting Epoch 84\n",
      "1.5878068059682846\n",
      "Validation loss: 1.5113863945007324\n",
      "mse 1.5113864094812184\n",
      "New best model found at epoch 84 with validation loss 1.5113863945007324\n",
      "Starting Epoch 85\n",
      "1.5868434309959412\n",
      "Validation loss: 1.5106055736541748\n",
      "mse 1.51060541622694\n",
      "New best model found at epoch 85 with validation loss 1.5106055736541748\n",
      "Starting Epoch 86\n",
      "1.5859230210383732\n",
      "Validation loss: 1.509835124015808\n",
      "mse 1.5098351689473044\n",
      "New best model found at epoch 86 with validation loss 1.509835124015808\n",
      "Starting Epoch 87\n",
      "1.5850161264340084\n",
      "Validation loss: 1.509082555770874\n",
      "mse 1.5090826034694678\n",
      "New best model found at epoch 87 with validation loss 1.509082555770874\n",
      "Starting Epoch 88\n",
      "1.5841298202673595\n",
      "Validation loss: 1.5083481073379517\n",
      "mse 1.5083480586494824\n",
      "New best model found at epoch 88 with validation loss 1.5083481073379517\n",
      "Starting Epoch 89\n",
      "1.5832893053690593\n",
      "Validation loss: 1.507589340209961\n",
      "mse 1.5075894757798216\n",
      "New best model found at epoch 89 with validation loss 1.507589340209961\n",
      "Starting Epoch 90\n",
      "1.582438622911771\n",
      "Validation loss: 1.506879448890686\n",
      "mse 1.506879384111411\n",
      "New best model found at epoch 90 with validation loss 1.506879448890686\n",
      "Starting Epoch 91\n",
      "1.581605965892474\n",
      "Validation loss: 1.5061944723129272\n",
      "mse 1.5061943717159907\n",
      "New best model found at epoch 91 with validation loss 1.5061944723129272\n",
      "Starting Epoch 92\n",
      "1.5808002601067226\n",
      "Validation loss: 1.505510926246643\n",
      "mse 1.505510880583395\n",
      "New best model found at epoch 92 with validation loss 1.505510926246643\n",
      "Starting Epoch 93\n",
      "1.5800031423568726\n",
      "Validation loss: 1.5048503875732422\n",
      "mse 1.5048504104378322\n",
      "New best model found at epoch 93 with validation loss 1.5048503875732422\n",
      "Starting Epoch 94\n",
      "1.5792217552661896\n",
      "Validation loss: 1.5042091608047485\n",
      "mse 1.5042092530622615\n",
      "New best model found at epoch 94 with validation loss 1.5042091608047485\n",
      "Starting Epoch 95\n",
      "1.578454002737999\n",
      "Validation loss: 1.5036143064498901\n",
      "mse 1.503614260826\n",
      "New best model found at epoch 95 with validation loss 1.5036143064498901\n",
      "Starting Epoch 96\n",
      "1.577706555525462\n",
      "Validation loss: 1.5030336380004883\n",
      "mse 1.5030335407486983\n",
      "New best model found at epoch 96 with validation loss 1.5030336380004883\n",
      "Starting Epoch 97\n",
      "1.576977252960205\n",
      "Validation loss: 1.5025200843811035\n",
      "mse 1.5025199710452481\n",
      "New best model found at epoch 97 with validation loss 1.5025200843811035\n",
      "Starting Epoch 98\n",
      "1.5762636909882228\n",
      "Validation loss: 1.5018779039382935\n",
      "mse 1.501877937671717\n",
      "New best model found at epoch 98 with validation loss 1.5018779039382935\n",
      "Starting Epoch 99\n",
      "1.5755549271901448\n",
      "Validation loss: 1.5013740062713623\n",
      "mse 1.5013739882711414\n",
      "New best model found at epoch 99 with validation loss 1.5013740062713623\n",
      "Starting Epoch 100\n",
      "1.5748679886261623\n",
      "Validation loss: 1.5008479356765747\n",
      "mse 1.5008479612573127\n",
      "New best model found at epoch 100 with validation loss 1.5008479356765747\n",
      "Starting Epoch 101\n",
      "1.5741949081420898\n",
      "Validation loss: 1.5001970529556274\n",
      "mse 1.500197062689451\n",
      "New best model found at epoch 101 with validation loss 1.5001970529556274\n",
      "Starting Epoch 102\n",
      "1.5735177447398503\n",
      "Validation loss: 1.4997262954711914\n",
      "mse 1.4997262414100487\n",
      "New best model found at epoch 102 with validation loss 1.4997262954711914\n",
      "Starting Epoch 103\n",
      "1.5728727579116821\n",
      "Validation loss: 1.4992101192474365\n",
      "mse 1.4992101792417412\n",
      "New best model found at epoch 103 with validation loss 1.4992101192474365\n",
      "Starting Epoch 104\n",
      "1.5722350279490154\n",
      "Validation loss: 1.4986835718154907\n",
      "mse 1.4986835331896071\n",
      "New best model found at epoch 104 with validation loss 1.4986835718154907\n",
      "Starting Epoch 105\n",
      "1.5716033031543095\n",
      "Validation loss: 1.4981862306594849\n",
      "mse 1.4981862923027236\n",
      "New best model found at epoch 105 with validation loss 1.4981862306594849\n",
      "Starting Epoch 106\n",
      "1.5709834098815918\n",
      "Validation loss: 1.4976884126663208\n",
      "mse 1.497688298489811\n",
      "New best model found at epoch 106 with validation loss 1.4976884126663208\n",
      "Starting Epoch 107\n",
      "1.5703750501076381\n",
      "Validation loss: 1.4971812963485718\n",
      "mse 1.4971812505253943\n",
      "New best model found at epoch 107 with validation loss 1.4971812963485718\n",
      "Starting Epoch 108\n",
      "1.5697748760382335\n",
      "Validation loss: 1.4966775178909302\n",
      "mse 1.4966776279286655\n",
      "New best model found at epoch 108 with validation loss 1.4966775178909302\n",
      "Starting Epoch 109\n",
      "1.569183776775996\n",
      "Validation loss: 1.4962118864059448\n",
      "mse 1.4962118503921191\n",
      "New best model found at epoch 109 with validation loss 1.4962118864059448\n",
      "Starting Epoch 110\n",
      "1.5686040669679642\n",
      "Validation loss: 1.4957464933395386\n",
      "mse 1.4957466453513624\n",
      "New best model found at epoch 110 with validation loss 1.4957464933395386\n",
      "Starting Epoch 111\n",
      "1.568032130599022\n",
      "Validation loss: 1.4952768087387085\n",
      "mse 1.495276907569847\n",
      "New best model found at epoch 111 with validation loss 1.4952768087387085\n",
      "Starting Epoch 112\n",
      "1.5674694379170735\n",
      "Validation loss: 1.4948396682739258\n",
      "mse 1.4948396095389875\n",
      "New best model found at epoch 112 with validation loss 1.4948396682739258\n",
      "Starting Epoch 113\n",
      "1.5669158200422924\n",
      "Validation loss: 1.4944078922271729\n",
      "mse 1.4944078701885364\n",
      "New best model found at epoch 113 with validation loss 1.4944078922271729\n",
      "Starting Epoch 114\n",
      "1.5663702189922333\n",
      "Validation loss: 1.4939675331115723\n",
      "mse 1.4939675182068275\n",
      "New best model found at epoch 114 with validation loss 1.4939675331115723\n",
      "Starting Epoch 115\n",
      "1.5658315767844517\n",
      "Validation loss: 1.4935578107833862\n",
      "mse 1.4935577459239677\n",
      "New best model found at epoch 115 with validation loss 1.4935578107833862\n",
      "Starting Epoch 116\n",
      "1.5653016020854313\n",
      "Validation loss: 1.493151307106018\n",
      "mse 1.4931514657597327\n",
      "New best model found at epoch 116 with validation loss 1.493151307106018\n",
      "Starting Epoch 117\n",
      "1.564781169096629\n",
      "Validation loss: 1.49272620677948\n",
      "mse 1.4927261950037412\n",
      "New best model found at epoch 117 with validation loss 1.49272620677948\n",
      "Starting Epoch 118\n",
      "1.5642626881599426\n",
      "Validation loss: 1.4923412799835205\n",
      "mse 1.4923412191954213\n",
      "New best model found at epoch 118 with validation loss 1.4923412799835205\n",
      "Starting Epoch 119\n",
      "1.5637575338284175\n",
      "Validation loss: 1.4919410943984985\n",
      "mse 1.4919410666011048\n",
      "New best model found at epoch 119 with validation loss 1.4919410943984985\n",
      "Starting Epoch 120\n",
      "1.5632544159889221\n",
      "Validation loss: 1.4915440082550049\n",
      "mse 1.4915438947601616\n",
      "New best model found at epoch 120 with validation loss 1.4915440082550049\n",
      "Starting Epoch 121\n",
      "1.5627595434586208\n",
      "Validation loss: 1.491167664527893\n",
      "mse 1.4911678178271404\n",
      "New best model found at epoch 121 with validation loss 1.491167664527893\n",
      "Starting Epoch 122\n",
      "1.5622704426447551\n",
      "Validation loss: 1.4907881021499634\n",
      "mse 1.4907880991318827\n",
      "New best model found at epoch 122 with validation loss 1.4907881021499634\n",
      "Starting Epoch 123\n",
      "1.5617881019910176\n",
      "Validation loss: 1.490431308746338\n",
      "mse 1.490431427033151\n",
      "New best model found at epoch 123 with validation loss 1.490431308746338\n",
      "Starting Epoch 124\n",
      "1.5613140314817429\n",
      "Validation loss: 1.4900704622268677\n",
      "mse 1.4900704504721933\n",
      "New best model found at epoch 124 with validation loss 1.4900704622268677\n",
      "Starting Epoch 125\n",
      "1.5608446548382442\n",
      "Validation loss: 1.489697813987732\n",
      "mse 1.489697815340244\n",
      "New best model found at epoch 125 with validation loss 1.489697813987732\n",
      "Starting Epoch 126\n",
      "1.56037933131059\n",
      "Validation loss: 1.489353895187378\n",
      "mse 1.4893538639041413\n",
      "New best model found at epoch 126 with validation loss 1.489353895187378\n",
      "Starting Epoch 127\n",
      "1.5599225362141926\n",
      "Validation loss: 1.4889947175979614\n",
      "mse 1.4889946046767817\n",
      "New best model found at epoch 127 with validation loss 1.4889947175979614\n",
      "Starting Epoch 128\n",
      "1.5594682097434998\n",
      "Validation loss: 1.4886631965637207\n",
      "mse 1.4886633004537857\n",
      "New best model found at epoch 128 with validation loss 1.4886631965637207\n",
      "Starting Epoch 129\n",
      "1.5590226997931798\n",
      "Validation loss: 1.488326072692871\n",
      "mse 1.4883259793627222\n",
      "New best model found at epoch 129 with validation loss 1.488326072692871\n",
      "Starting Epoch 130\n",
      "1.5585817495981853\n",
      "Validation loss: 1.4879775047302246\n",
      "mse 1.4879775625425584\n",
      "New best model found at epoch 130 with validation loss 1.4879775047302246\n",
      "Starting Epoch 131\n",
      "1.5581452151139576\n",
      "Validation loss: 1.4876564741134644\n",
      "mse 1.4876564657428593\n",
      "New best model found at epoch 131 with validation loss 1.4876564741134644\n",
      "Starting Epoch 132\n",
      "1.5577155599991481\n",
      "Validation loss: 1.4873323440551758\n",
      "mse 1.4873322836148668\n",
      "New best model found at epoch 132 with validation loss 1.4873323440551758\n",
      "Starting Epoch 133\n",
      "1.5572903553644817\n",
      "Validation loss: 1.4869966506958008\n",
      "mse 1.486996615755497\n",
      "New best model found at epoch 133 with validation loss 1.4869966506958008\n",
      "Starting Epoch 134\n",
      "1.556868592898051\n",
      "Validation loss: 1.4866878986358643\n",
      "mse 1.4866879046286643\n",
      "New best model found at epoch 134 with validation loss 1.4866878986358643\n",
      "Starting Epoch 135\n",
      "1.5564511517683666\n",
      "Validation loss: 1.4863760471343994\n",
      "mse 1.4863760133264103\n",
      "New best model found at epoch 135 with validation loss 1.4863760471343994\n",
      "Starting Epoch 136\n",
      "1.5560420602560043\n",
      "Validation loss: 1.4860522747039795\n",
      "mse 1.4860521936130977\n",
      "New best model found at epoch 136 with validation loss 1.4860522747039795\n",
      "Starting Epoch 137\n",
      "1.555632491906484\n",
      "Validation loss: 1.4857553243637085\n",
      "mse 1.485755251851423\n",
      "New best model found at epoch 137 with validation loss 1.4857553243637085\n",
      "Starting Epoch 138\n",
      "1.5552282681067784\n",
      "Validation loss: 1.4854402542114258\n",
      "mse 1.4854400953362437\n",
      "New best model found at epoch 138 with validation loss 1.4854402542114258\n",
      "Starting Epoch 139\n",
      "1.5548293838898342\n",
      "Validation loss: 1.485150694847107\n",
      "mse 1.4851507873970817\n",
      "New best model found at epoch 139 with validation loss 1.485150694847107\n",
      "Starting Epoch 140\n",
      "1.5544365247090657\n",
      "Validation loss: 1.4848579168319702\n",
      "mse 1.4848579654501803\n",
      "New best model found at epoch 140 with validation loss 1.4848579168319702\n",
      "Starting Epoch 141\n",
      "1.5540435413519542\n",
      "Validation loss: 1.4845706224441528\n",
      "mse 1.4845704822524632\n",
      "New best model found at epoch 141 with validation loss 1.4845706224441528\n",
      "Starting Epoch 142\n",
      "1.5536630749702454\n",
      "Validation loss: 1.4842661619186401\n",
      "mse 1.4842660834377102\n",
      "New best model found at epoch 142 with validation loss 1.4842661619186401\n",
      "Starting Epoch 143\n",
      "1.5532749940951665\n",
      "Validation loss: 1.4840089082717896\n",
      "mse 1.4840088396763842\n",
      "New best model found at epoch 143 with validation loss 1.4840089082717896\n",
      "Starting Epoch 144\n",
      "1.552894413471222\n",
      "Validation loss: 1.4837392568588257\n",
      "mse 1.4837391510416997\n",
      "New best model found at epoch 144 with validation loss 1.4837392568588257\n",
      "Starting Epoch 145\n",
      "1.5525252670049667\n",
      "Validation loss: 1.4834623336791992\n",
      "mse 1.483462401079811\n",
      "New best model found at epoch 145 with validation loss 1.4834623336791992\n",
      "Starting Epoch 146\n",
      "1.5521604766448338\n",
      "Validation loss: 1.4831669330596924\n",
      "mse 1.4831668885329081\n",
      "New best model found at epoch 146 with validation loss 1.4831669330596924\n",
      "Starting Epoch 147\n",
      "1.5517890999714534\n",
      "Validation loss: 1.4829021692276\n",
      "mse 1.4829021396858135\n",
      "New best model found at epoch 147 with validation loss 1.4829021692276\n",
      "Starting Epoch 148\n",
      "1.5514252831538518\n",
      "Validation loss: 1.4826328754425049\n",
      "mse 1.4826328425401551\n",
      "New best model found at epoch 148 with validation loss 1.4826328754425049\n",
      "Starting Epoch 149\n",
      "1.5510663588841755\n",
      "Validation loss: 1.482363224029541\n",
      "mse 1.482363148457912\n",
      "New best model found at epoch 149 with validation loss 1.482363224029541\n",
      "Starting Epoch 150\n",
      "1.5507140159606934\n",
      "Validation loss: 1.4820948839187622\n",
      "mse 1.4820948424642277\n",
      "New best model found at epoch 150 with validation loss 1.4820948839187622\n",
      "Starting Epoch 151\n",
      "1.5503596564133961\n",
      "Validation loss: 1.4818273782730103\n",
      "mse 1.4818273266078597\n",
      "New best model found at epoch 151 with validation loss 1.4818273782730103\n",
      "Starting Epoch 152\n",
      "1.5500198304653168\n",
      "Validation loss: 1.481546401977539\n",
      "mse 1.4815464024164067\n",
      "New best model found at epoch 152 with validation loss 1.481546401977539\n",
      "Starting Epoch 153\n",
      "1.5496643235286076\n",
      "Validation loss: 1.4812954664230347\n",
      "mse 1.4812953983018091\n",
      "New best model found at epoch 153 with validation loss 1.4812954664230347\n",
      "Starting Epoch 154\n",
      "1.5493229528268178\n",
      "Validation loss: 1.4810409545898438\n",
      "mse 1.4810409473571369\n",
      "New best model found at epoch 154 with validation loss 1.4810409545898438\n",
      "Starting Epoch 155\n",
      "1.5489839315414429\n",
      "Validation loss: 1.4807850122451782\n",
      "mse 1.4807852143311544\n",
      "New best model found at epoch 155 with validation loss 1.4807850122451782\n",
      "Starting Epoch 156\n",
      "1.5486481537421544\n",
      "Validation loss: 1.48052978515625\n",
      "mse 1.4805297215537685\n",
      "New best model found at epoch 156 with validation loss 1.48052978515625\n",
      "Starting Epoch 157\n",
      "1.54832228521506\n",
      "Validation loss: 1.4802590608596802\n",
      "mse 1.4802591332202901\n",
      "New best model found at epoch 157 with validation loss 1.4802590608596802\n",
      "Starting Epoch 158\n",
      "1.5479832241932552\n",
      "Validation loss: 1.480019450187683\n",
      "mse 1.4800194334272163\n",
      "New best model found at epoch 158 with validation loss 1.480019450187683\n",
      "Starting Epoch 159\n",
      "1.5476560990015666\n",
      "Validation loss: 1.479776382446289\n",
      "mse 1.4797762278435331\n",
      "New best model found at epoch 159 with validation loss 1.479776382446289\n",
      "Starting Epoch 160\n",
      "1.54733207821846\n",
      "Validation loss: 1.4795312881469727\n",
      "mse 1.4795312708519455\n",
      "New best model found at epoch 160 with validation loss 1.4795312881469727\n",
      "Starting Epoch 161\n",
      "1.547017052769661\n",
      "Validation loss: 1.4792709350585938\n",
      "mse 1.4792708796008838\n",
      "New best model found at epoch 161 with validation loss 1.4792709350585938\n",
      "Starting Epoch 162\n",
      "1.54668993751208\n",
      "Validation loss: 1.4790387153625488\n",
      "mse 1.479038705531617\n",
      "New best model found at epoch 162 with validation loss 1.4790387153625488\n",
      "Starting Epoch 163\n",
      "1.546369383732478\n",
      "Validation loss: 1.4788154363632202\n",
      "mse 1.4788155484279\n",
      "New best model found at epoch 163 with validation loss 1.4788154363632202\n",
      "Starting Epoch 164\n",
      "1.5460616250832875\n",
      "Validation loss: 1.4785696268081665\n",
      "mse 1.4785697002252363\n",
      "New best model found at epoch 164 with validation loss 1.4785696268081665\n",
      "Starting Epoch 165\n",
      "1.5457450201114018\n",
      "Validation loss: 1.4783419370651245\n",
      "mse 1.4783418588724\n",
      "New best model found at epoch 165 with validation loss 1.4783419370651245\n",
      "Starting Epoch 166\n",
      "1.5454368541638057\n",
      "Validation loss: 1.4781087636947632\n",
      "mse 1.4781087714874628\n",
      "New best model found at epoch 166 with validation loss 1.4781087636947632\n",
      "Starting Epoch 167\n",
      "1.545142153898875\n",
      "Validation loss: 1.4778465032577515\n",
      "mse 1.4778465316119134\n",
      "New best model found at epoch 167 with validation loss 1.4778465032577515\n",
      "Starting Epoch 168\n",
      "1.5448242624600728\n",
      "Validation loss: 1.4776326417922974\n",
      "mse 1.477632639201933\n",
      "New best model found at epoch 168 with validation loss 1.4776326417922974\n",
      "Starting Epoch 169\n",
      "1.5445236563682556\n",
      "Validation loss: 1.4774097204208374\n",
      "mse 1.4774097293901542\n",
      "New best model found at epoch 169 with validation loss 1.4774097204208374\n",
      "Starting Epoch 170\n",
      "1.5442251960436504\n",
      "Validation loss: 1.4771831035614014\n",
      "mse 1.477183015533141\n",
      "New best model found at epoch 170 with validation loss 1.4771831035614014\n",
      "Starting Epoch 171\n",
      "1.5439305951197941\n",
      "Validation loss: 1.476974606513977\n",
      "mse 1.476974664728387\n",
      "New best model found at epoch 171 with validation loss 1.476974606513977\n",
      "Starting Epoch 172\n",
      "1.543635254104932\n",
      "Validation loss: 1.4767354726791382\n",
      "mse 1.4767354168948534\n",
      "New best model found at epoch 172 with validation loss 1.4767354726791382\n",
      "Starting Epoch 173\n",
      "1.543343683083852\n",
      "Validation loss: 1.4765243530273438\n",
      "mse 1.4765244470305372\n",
      "New best model found at epoch 173 with validation loss 1.4765243530273438\n",
      "Starting Epoch 174\n",
      "1.5430586685736973\n",
      "Validation loss: 1.4762705564498901\n",
      "mse 1.476270519337762\n",
      "New best model found at epoch 174 with validation loss 1.4762705564498901\n",
      "Starting Epoch 175\n",
      "1.542762075861295\n",
      "Validation loss: 1.4760515689849854\n",
      "mse 1.4760516423505028\n",
      "New best model found at epoch 175 with validation loss 1.4760515689849854\n",
      "Starting Epoch 176\n",
      "1.5424798329671223\n",
      "Validation loss: 1.4758503437042236\n",
      "mse 1.4758502852622872\n",
      "New best model found at epoch 176 with validation loss 1.4758503437042236\n",
      "Starting Epoch 177\n",
      "1.5421956529219945\n",
      "Validation loss: 1.4756171703338623\n",
      "mse 1.4756170255366619\n",
      "New best model found at epoch 177 with validation loss 1.4756171703338623\n",
      "Starting Epoch 178\n",
      "1.5419154614210129\n",
      "Validation loss: 1.4754105806350708\n",
      "mse 1.475410590468596\n",
      "New best model found at epoch 178 with validation loss 1.4754105806350708\n",
      "Starting Epoch 179\n",
      "1.5416329652071\n",
      "Validation loss: 1.4751683473587036\n",
      "mse 1.475168324193633\n",
      "New best model found at epoch 179 with validation loss 1.4751683473587036\n",
      "Starting Epoch 180\n",
      "1.5413604627052944\n",
      "Validation loss: 1.474971890449524\n",
      "mse 1.4749718792042854\n",
      "New best model found at epoch 180 with validation loss 1.474971890449524\n",
      "Starting Epoch 181\n",
      "1.5410820146401722\n",
      "Validation loss: 1.474743127822876\n",
      "mse 1.47474311162706\n",
      "New best model found at epoch 181 with validation loss 1.474743127822876\n",
      "Starting Epoch 182\n",
      "1.5408098250627518\n",
      "Validation loss: 1.4745336771011353\n",
      "mse 1.4745334988095802\n",
      "New best model found at epoch 182 with validation loss 1.4745336771011353\n",
      "Starting Epoch 183\n",
      "1.5405356884002686\n",
      "Validation loss: 1.4743132591247559\n",
      "mse 1.4743131461550536\n",
      "New best model found at epoch 183 with validation loss 1.4743132591247559\n",
      "Starting Epoch 184\n",
      "1.5402686148881912\n",
      "Validation loss: 1.474098563194275\n",
      "mse 1.4740985633000439\n",
      "New best model found at epoch 184 with validation loss 1.474098563194275\n",
      "Starting Epoch 185\n",
      "1.539997711777687\n",
      "Validation loss: 1.4738959074020386\n",
      "mse 1.4738958397350959\n",
      "New best model found at epoch 185 with validation loss 1.4738959074020386\n",
      "Starting Epoch 186\n",
      "1.5397339463233948\n",
      "Validation loss: 1.473681092262268\n",
      "mse 1.4736811340156373\n",
      "New best model found at epoch 186 with validation loss 1.473681092262268\n",
      "Starting Epoch 187\n",
      "1.5394687950611115\n",
      "Validation loss: 1.4734885692596436\n",
      "mse 1.4734884538721467\n",
      "New best model found at epoch 187 with validation loss 1.4734885692596436\n",
      "Starting Epoch 188\n",
      "1.539204145471255\n",
      "Validation loss: 1.4732677936553955\n",
      "mse 1.4732678543323352\n",
      "New best model found at epoch 188 with validation loss 1.4732677936553955\n",
      "Starting Epoch 189\n",
      "1.5389443784952164\n",
      "Validation loss: 1.4730662107467651\n",
      "mse 1.473066262098612\n",
      "New best model found at epoch 189 with validation loss 1.4730662107467651\n",
      "Starting Epoch 190\n",
      "1.5386786212523778\n",
      "Validation loss: 1.4728678464889526\n",
      "mse 1.4728679805374034\n",
      "New best model found at epoch 190 with validation loss 1.4728678464889526\n",
      "Starting Epoch 191\n",
      "1.5384185661872227\n",
      "Validation loss: 1.472601056098938\n",
      "mse 1.4726011154240637\n",
      "New best model found at epoch 191 with validation loss 1.472601056098938\n",
      "Starting Epoch 192\n",
      "1.538158357143402\n",
      "Validation loss: 1.4723440408706665\n",
      "mse 1.4723441302073677\n",
      "New best model found at epoch 192 with validation loss 1.4723440408706665\n",
      "Starting Epoch 193\n",
      "1.5378875682751338\n",
      "Validation loss: 1.4720652103424072\n",
      "mse 1.472065140485681\n",
      "New best model found at epoch 193 with validation loss 1.4720652103424072\n",
      "Starting Epoch 194\n",
      "1.5376141667366028\n",
      "Validation loss: 1.471798062324524\n",
      "mse 1.4717980958682881\n",
      "New best model found at epoch 194 with validation loss 1.471798062324524\n",
      "Starting Epoch 195\n",
      "1.537350798646609\n",
      "Validation loss: 1.4715473651885986\n",
      "mse 1.4715474539200883\n",
      "New best model found at epoch 195 with validation loss 1.4715473651885986\n",
      "Starting Epoch 196\n",
      "1.5370891044537227\n",
      "Validation loss: 1.4713106155395508\n",
      "mse 1.4713106016118431\n",
      "New best model found at epoch 196 with validation loss 1.4713106155395508\n",
      "Starting Epoch 197\n",
      "1.5368199149767559\n",
      "Validation loss: 1.4710795879364014\n",
      "mse 1.4710795421195737\n",
      "New best model found at epoch 197 with validation loss 1.4710795879364014\n",
      "Starting Epoch 198\n",
      "1.5365579426288605\n",
      "Validation loss: 1.470847725868225\n",
      "mse 1.4708476350400905\n",
      "New best model found at epoch 198 with validation loss 1.470847725868225\n",
      "Starting Epoch 199\n",
      "1.536301463842392\n",
      "Validation loss: 1.4706144332885742\n",
      "mse 1.4706145391842416\n",
      "New best model found at epoch 199 with validation loss 1.4706144332885742\n",
      "Starting Epoch 200\n",
      "1.5360456655422847\n",
      "Validation loss: 1.4703822135925293\n",
      "mse 1.4703822638423536\n",
      "New best model found at epoch 200 with validation loss 1.4703822135925293\n",
      "Starting Epoch 201\n",
      "1.5357930461565654\n",
      "Validation loss: 1.4701553583145142\n",
      "mse 1.4701553406072985\n",
      "New best model found at epoch 201 with validation loss 1.4701553583145142\n",
      "Starting Epoch 202\n",
      "1.5355386634667714\n",
      "Validation loss: 1.4699290990829468\n",
      "mse 1.4699289910464077\n",
      "New best model found at epoch 202 with validation loss 1.4699290990829468\n",
      "Starting Epoch 203\n",
      "1.535290499528249\n",
      "Validation loss: 1.4697080850601196\n",
      "mse 1.4697082257229783\n",
      "New best model found at epoch 203 with validation loss 1.4697080850601196\n",
      "Starting Epoch 204\n",
      "1.5350390474001567\n",
      "Validation loss: 1.4694886207580566\n",
      "mse 1.4694886810856764\n",
      "New best model found at epoch 204 with validation loss 1.4694886207580566\n",
      "Starting Epoch 205\n",
      "1.534791146715482\n",
      "Validation loss: 1.4692715406417847\n",
      "mse 1.4692714726260252\n",
      "New best model found at epoch 205 with validation loss 1.4692715406417847\n",
      "Starting Epoch 206\n",
      "1.5345462063948314\n",
      "Validation loss: 1.4690630435943604\n",
      "mse 1.4690630063370957\n",
      "New best model found at epoch 206 with validation loss 1.4690630435943604\n",
      "Starting Epoch 207\n",
      "1.5342992891867955\n",
      "Validation loss: 1.46885085105896\n",
      "mse 1.4688507899099028\n",
      "New best model found at epoch 207 with validation loss 1.46885085105896\n",
      "Starting Epoch 208\n",
      "1.5340616603692372\n",
      "Validation loss: 1.468645691871643\n",
      "mse 1.4686456419191853\n",
      "New best model found at epoch 208 with validation loss 1.468645691871643\n",
      "Starting Epoch 209\n",
      "1.5338170230388641\n",
      "Validation loss: 1.4684489965438843\n",
      "mse 1.4684489932554645\n",
      "New best model found at epoch 209 with validation loss 1.4684489965438843\n",
      "Starting Epoch 210\n",
      "1.5335786541302998\n",
      "Validation loss: 1.4682273864746094\n",
      "mse 1.4682274022779909\n",
      "New best model found at epoch 210 with validation loss 1.4682273864746094\n",
      "Starting Epoch 211\n",
      "1.5333408613999684\n",
      "Validation loss: 1.4680112600326538\n",
      "mse 1.4680112706030923\n",
      "New best model found at epoch 211 with validation loss 1.4680112600326538\n",
      "Starting Epoch 212\n",
      "1.5330949624379475\n",
      "Validation loss: 1.4678319692611694\n",
      "mse 1.4678320934481657\n",
      "New best model found at epoch 212 with validation loss 1.4678319692611694\n",
      "Starting Epoch 213\n",
      "1.5328730245431264\n",
      "Validation loss: 1.4676045179367065\n",
      "mse 1.467604505324434\n",
      "New best model found at epoch 213 with validation loss 1.4676045179367065\n",
      "Starting Epoch 214\n",
      "1.5326391458511353\n",
      "Validation loss: 1.4673970937728882\n",
      "mse 1.4673970989762506\n",
      "New best model found at epoch 214 with validation loss 1.4673970937728882\n",
      "Starting Epoch 215\n",
      "1.5324089924494426\n",
      "Validation loss: 1.4672118425369263\n",
      "mse 1.4672119529261258\n",
      "New best model found at epoch 215 with validation loss 1.4672118425369263\n",
      "Starting Epoch 216\n",
      "1.5321835974852245\n",
      "Validation loss: 1.467009425163269\n",
      "mse 1.4670095345537302\n",
      "New best model found at epoch 216 with validation loss 1.467009425163269\n",
      "Starting Epoch 217\n",
      "1.5319538712501526\n",
      "Validation loss: 1.466820478439331\n",
      "mse 1.4668204863999146\n",
      "New best model found at epoch 217 with validation loss 1.466820478439331\n",
      "Starting Epoch 218\n",
      "1.5317229727904003\n",
      "Validation loss: 1.4666303396224976\n",
      "mse 1.4666305051936686\n",
      "New best model found at epoch 218 with validation loss 1.4666303396224976\n",
      "Starting Epoch 219\n",
      "1.5315010249614716\n",
      "Validation loss: 1.4664355516433716\n",
      "mse 1.4664356043711642\n",
      "New best model found at epoch 219 with validation loss 1.4664355516433716\n",
      "Starting Epoch 220\n",
      "1.5312769164641697\n",
      "Validation loss: 1.4662392139434814\n",
      "mse 1.4662391457783401\n",
      "New best model found at epoch 220 with validation loss 1.4662392139434814\n",
      "Starting Epoch 221\n",
      "1.5310535728931427\n",
      "Validation loss: 1.4660425186157227\n",
      "mse 1.4660423592459202\n",
      "New best model found at epoch 221 with validation loss 1.4660425186157227\n",
      "Starting Epoch 222\n",
      "1.5308254112799962\n",
      "Validation loss: 1.4658699035644531\n",
      "mse 1.4658699194858296\n",
      "New best model found at epoch 222 with validation loss 1.4658699035644531\n",
      "Starting Epoch 223\n",
      "1.53061148027579\n",
      "Validation loss: 1.4656479358673096\n",
      "mse 1.4656479305316503\n",
      "New best model found at epoch 223 with validation loss 1.4656479358673096\n",
      "Starting Epoch 224\n",
      "1.5303917427857716\n",
      "Validation loss: 1.4654388427734375\n",
      "mse 1.4654389527516238\n",
      "New best model found at epoch 224 with validation loss 1.4654388427734375\n",
      "Starting Epoch 225\n",
      "1.5301671971877415\n",
      "Validation loss: 1.4652568101882935\n",
      "mse 1.4652569698301936\n",
      "New best model found at epoch 225 with validation loss 1.4652568101882935\n",
      "Starting Epoch 226\n",
      "1.5299535244703293\n",
      "Validation loss: 1.4650533199310303\n",
      "mse 1.4650532942747547\n",
      "New best model found at epoch 226 with validation loss 1.4650533199310303\n",
      "Starting Epoch 227\n",
      "1.5297345320383708\n",
      "Validation loss: 1.464860439300537\n",
      "mse 1.464860495921447\n",
      "New best model found at epoch 227 with validation loss 1.464860439300537\n",
      "Starting Epoch 228\n",
      "1.5295183062553406\n",
      "Validation loss: 1.4646689891815186\n",
      "mse 1.46466892664407\n",
      "New best model found at epoch 228 with validation loss 1.4646689891815186\n",
      "Starting Epoch 229\n",
      "1.5293041964371998\n",
      "Validation loss: 1.4644731283187866\n",
      "mse 1.4644731578755261\n",
      "New best model found at epoch 229 with validation loss 1.4644731283187866\n",
      "Starting Epoch 230\n",
      "1.5290857553482056\n",
      "Validation loss: 1.4642997980117798\n",
      "mse 1.4642998897964983\n",
      "New best model found at epoch 230 with validation loss 1.4642997980117798\n",
      "Starting Epoch 231\n",
      "1.5288749138514202\n",
      "Validation loss: 1.4641042947769165\n",
      "mse 1.4641043677206358\n",
      "New best model found at epoch 231 with validation loss 1.4641042947769165\n",
      "Starting Epoch 232\n",
      "1.5286644448836644\n",
      "Validation loss: 1.4639148712158203\n",
      "mse 1.4639148540606743\n",
      "New best model found at epoch 232 with validation loss 1.4639148712158203\n",
      "Starting Epoch 233\n",
      "1.5284543484449387\n",
      "Validation loss: 1.4637213945388794\n",
      "mse 1.4637212868163547\n",
      "New best model found at epoch 233 with validation loss 1.4637213945388794\n",
      "Starting Epoch 234\n",
      "1.5282390862703323\n",
      "Validation loss: 1.4635422229766846\n",
      "mse 1.463542348365076\n",
      "New best model found at epoch 234 with validation loss 1.4635422229766846\n",
      "Starting Epoch 235\n",
      "1.5280362715323765\n",
      "Validation loss: 1.4633413553237915\n",
      "mse 1.463341481396981\n",
      "New best model found at epoch 235 with validation loss 1.4633413553237915\n",
      "Starting Epoch 236\n",
      "1.5278256783882778\n",
      "Validation loss: 1.463172435760498\n",
      "mse 1.4631725453443047\n",
      "New best model found at epoch 236 with validation loss 1.463172435760498\n",
      "Starting Epoch 237\n",
      "1.527619019150734\n",
      "Validation loss: 1.4629796743392944\n",
      "mse 1.462979820575792\n",
      "New best model found at epoch 237 with validation loss 1.4629796743392944\n",
      "Starting Epoch 238\n",
      "1.5274107803901036\n",
      "Validation loss: 1.4627982378005981\n",
      "mse 1.4627981194655617\n",
      "New best model found at epoch 238 with validation loss 1.4627982378005981\n",
      "Starting Epoch 239\n",
      "1.5272066593170166\n",
      "Validation loss: 1.4626110792160034\n",
      "mse 1.462611107438445\n",
      "New best model found at epoch 239 with validation loss 1.4626110792160034\n",
      "Starting Epoch 240\n",
      "1.5270095864931743\n",
      "Validation loss: 1.4624210596084595\n",
      "mse 1.462421044820032\n",
      "New best model found at epoch 240 with validation loss 1.4624210596084595\n",
      "Starting Epoch 241\n",
      "1.5267971754074097\n",
      "Validation loss: 1.4622259140014648\n",
      "mse 1.4622259896775704\n",
      "New best model found at epoch 241 with validation loss 1.4622259140014648\n",
      "Starting Epoch 242\n",
      "1.5265829116106033\n",
      "Validation loss: 1.462027907371521\n",
      "mse 1.4620279308052235\n",
      "New best model found at epoch 242 with validation loss 1.462027907371521\n",
      "Starting Epoch 243\n",
      "1.5263640880584717\n",
      "Validation loss: 1.4617676734924316\n",
      "mse 1.4617676020987838\n",
      "New best model found at epoch 243 with validation loss 1.4617676734924316\n",
      "Starting Epoch 244\n",
      "1.526085764169693\n",
      "Validation loss: 1.461504340171814\n",
      "mse 1.461504306846172\n",
      "New best model found at epoch 244 with validation loss 1.461504340171814\n",
      "Starting Epoch 245\n",
      "1.5257947494586308\n",
      "Validation loss: 1.4612226486206055\n",
      "mse 1.4612225444691391\n",
      "New best model found at epoch 245 with validation loss 1.4612226486206055\n",
      "Starting Epoch 246\n",
      "1.525509998202324\n",
      "Validation loss: 1.4609309434890747\n",
      "mse 1.460930775599672\n",
      "New best model found at epoch 246 with validation loss 1.4609309434890747\n",
      "Starting Epoch 247\n",
      "1.5252281725406647\n",
      "Validation loss: 1.4606332778930664\n",
      "mse 1.4606332774941044\n",
      "New best model found at epoch 247 with validation loss 1.4606332778930664\n",
      "Starting Epoch 248\n",
      "1.524949128429095\n",
      "Validation loss: 1.4603363275527954\n",
      "mse 1.4603363252309032\n",
      "New best model found at epoch 248 with validation loss 1.4603363275527954\n",
      "Starting Epoch 249\n",
      "1.524673268198967\n",
      "Validation loss: 1.4600595235824585\n",
      "mse 1.4600595943340342\n",
      "New best model found at epoch 249 with validation loss 1.4600595235824585\n",
      "Starting Epoch 250\n",
      "1.5244051963090897\n",
      "Validation loss: 1.4597574472427368\n",
      "mse 1.4597574703343261\n",
      "New best model found at epoch 250 with validation loss 1.4597574472427368\n",
      "Starting Epoch 251\n",
      "1.524126335978508\n",
      "Validation loss: 1.459488034248352\n",
      "mse 1.4594880543779563\n",
      "New best model found at epoch 251 with validation loss 1.459488034248352\n",
      "Starting Epoch 252\n",
      "1.5238573799530666\n",
      "Validation loss: 1.4592114686965942\n",
      "mse 1.4592113679232093\n",
      "New best model found at epoch 252 with validation loss 1.4592114686965942\n",
      "Starting Epoch 253\n",
      "1.5235891689856846\n",
      "Validation loss: 1.4589345455169678\n",
      "mse 1.4589345844510813\n",
      "New best model found at epoch 253 with validation loss 1.4589345455169678\n",
      "Starting Epoch 254\n",
      "1.5233227560917537\n",
      "Validation loss: 1.4586585760116577\n",
      "mse 1.4586586021460826\n",
      "New best model found at epoch 254 with validation loss 1.4586585760116577\n",
      "Starting Epoch 255\n",
      "1.523058921098709\n",
      "Validation loss: 1.4583852291107178\n",
      "mse 1.4583852108332223\n",
      "New best model found at epoch 255 with validation loss 1.4583852291107178\n",
      "Starting Epoch 256\n",
      "1.5227952599525452\n",
      "Validation loss: 1.458117127418518\n",
      "mse 1.4581171755855278\n",
      "New best model found at epoch 256 with validation loss 1.458117127418518\n",
      "Starting Epoch 257\n",
      "1.5225403606891632\n",
      "Validation loss: 1.4578303098678589\n",
      "mse 1.4578303864481867\n",
      "New best model found at epoch 257 with validation loss 1.4578303098678589\n",
      "Starting Epoch 258\n",
      "1.5222717821598053\n",
      "Validation loss: 1.4575774669647217\n",
      "mse 1.4575775134743183\n",
      "New best model found at epoch 258 with validation loss 1.4575774669647217\n",
      "Starting Epoch 259\n",
      "1.5219645549853642\n",
      "Validation loss: 1.457163691520691\n",
      "mse 1.4571637164865936\n",
      "New best model found at epoch 259 with validation loss 1.457163691520691\n",
      "Starting Epoch 260\n",
      "1.5216466287771861\n",
      "Validation loss: 1.4567391872406006\n",
      "mse 1.456739145115197\n",
      "New best model found at epoch 260 with validation loss 1.4567391872406006\n",
      "Starting Epoch 261\n",
      "1.5213311463594437\n",
      "Validation loss: 1.4563153982162476\n",
      "mse 1.4563154185293408\n",
      "New best model found at epoch 261 with validation loss 1.4563153982162476\n",
      "Starting Epoch 262\n",
      "1.5210197667280834\n",
      "Validation loss: 1.455910325050354\n",
      "mse 1.4559101762037832\n",
      "New best model found at epoch 262 with validation loss 1.455910325050354\n",
      "Starting Epoch 263\n",
      "1.520720511674881\n",
      "Validation loss: 1.455536961555481\n",
      "mse 1.455536904662301\n",
      "New best model found at epoch 263 with validation loss 1.455536961555481\n",
      "Starting Epoch 264\n",
      "1.5204363862673442\n",
      "Validation loss: 1.4551585912704468\n",
      "mse 1.4551584969536104\n",
      "New best model found at epoch 264 with validation loss 1.4551585912704468\n",
      "Starting Epoch 265\n",
      "1.5201505323251088\n",
      "Validation loss: 1.4547929763793945\n",
      "mse 1.4547930158982154\n",
      "New best model found at epoch 265 with validation loss 1.4547929763793945\n",
      "Starting Epoch 266\n",
      "1.519866536060969\n",
      "Validation loss: 1.4544371366500854\n",
      "mse 1.4544370032633014\n",
      "New best model found at epoch 266 with validation loss 1.4544371366500854\n",
      "Starting Epoch 267\n",
      "1.519585520029068\n",
      "Validation loss: 1.4540876150131226\n",
      "mse 1.4540875821676442\n",
      "New best model found at epoch 267 with validation loss 1.4540876150131226\n",
      "Starting Epoch 268\n",
      "1.5193046828111012\n",
      "Validation loss: 1.4537440538406372\n",
      "mse 1.4537441406531058\n",
      "New best model found at epoch 268 with validation loss 1.4537440538406372\n",
      "Starting Epoch 269\n",
      "1.5190275112787883\n",
      "Validation loss: 1.4533836841583252\n",
      "mse 1.4533838496460785\n",
      "New best model found at epoch 269 with validation loss 1.4533836841583252\n",
      "Starting Epoch 270\n",
      "1.5187501559654872\n",
      "Validation loss: 1.4530396461486816\n",
      "mse 1.4530396885554928\n",
      "New best model found at epoch 270 with validation loss 1.4530396461486816\n",
      "Starting Epoch 271\n",
      "1.518474613626798\n",
      "Validation loss: 1.4527020454406738\n",
      "mse 1.4527020271431192\n",
      "New best model found at epoch 271 with validation loss 1.4527020454406738\n",
      "Starting Epoch 272\n",
      "1.5182013163963954\n",
      "Validation loss: 1.4523708820343018\n",
      "mse 1.4523709923426553\n",
      "New best model found at epoch 272 with validation loss 1.4523708820343018\n",
      "Starting Epoch 273\n",
      "1.5179247905810673\n",
      "Validation loss: 1.452068567276001\n",
      "mse 1.4520686388937618\n",
      "New best model found at epoch 273 with validation loss 1.452068567276001\n",
      "Starting Epoch 274\n",
      "1.5176643232504528\n",
      "Validation loss: 1.451741337776184\n",
      "mse 1.451741293902196\n",
      "New best model found at epoch 274 with validation loss 1.451741337776184\n",
      "Starting Epoch 275\n",
      "1.5173893024524052\n",
      "Validation loss: 1.4513837099075317\n",
      "mse 1.451383649756415\n",
      "New best model found at epoch 275 with validation loss 1.4513837099075317\n",
      "Starting Epoch 276\n",
      "1.5171397179365158\n",
      "Validation loss: 1.4511173963546753\n",
      "mse 1.4511173561264268\n",
      "New best model found at epoch 276 with validation loss 1.4511173963546753\n",
      "Starting Epoch 277\n",
      "1.5168703595797222\n",
      "Validation loss: 1.4507883787155151\n",
      "mse 1.4507883823869807\n",
      "New best model found at epoch 277 with validation loss 1.4507883787155151\n",
      "Starting Epoch 278\n",
      "1.5166188180446625\n",
      "Validation loss: 1.4505423307418823\n",
      "mse 1.4505422781122623\n",
      "New best model found at epoch 278 with validation loss 1.4505423307418823\n",
      "Starting Epoch 279\n",
      "1.516352817416191\n",
      "Validation loss: 1.4502253532409668\n",
      "mse 1.4502253005266585\n",
      "New best model found at epoch 279 with validation loss 1.4502253532409668\n",
      "Starting Epoch 280\n",
      "1.5161547164122264\n",
      "Validation loss: 1.4499216079711914\n",
      "mse 1.4499216924437583\n",
      "New best model found at epoch 280 with validation loss 1.4499216079711914\n",
      "Starting Epoch 281\n",
      "1.5157073338826497\n",
      "Validation loss: 1.4493709802627563\n",
      "mse 1.4493710729029752\n",
      "New best model found at epoch 281 with validation loss 1.4493709802627563\n",
      "Starting Epoch 282\n",
      "1.5150332003831863\n",
      "Validation loss: 1.4487628936767578\n",
      "mse 1.4487628034494149\n",
      "New best model found at epoch 282 with validation loss 1.4487628936767578\n",
      "Starting Epoch 283\n",
      "1.5143802016973495\n",
      "Validation loss: 1.448164701461792\n",
      "mse 1.448164800681529\n",
      "New best model found at epoch 283 with validation loss 1.448164701461792\n",
      "Starting Epoch 284\n",
      "1.513755237062772\n",
      "Validation loss: 1.4475815296173096\n",
      "mse 1.44758139493337\n",
      "New best model found at epoch 284 with validation loss 1.4475815296173096\n",
      "Starting Epoch 285\n",
      "1.5131720801194508\n",
      "Validation loss: 1.4470055103302002\n",
      "mse 1.447005549967581\n",
      "New best model found at epoch 285 with validation loss 1.4470055103302002\n",
      "Starting Epoch 286\n",
      "1.5126051555077236\n",
      "Validation loss: 1.4464398622512817\n",
      "mse 1.4464399077330998\n",
      "New best model found at epoch 286 with validation loss 1.4464398622512817\n",
      "Starting Epoch 287\n",
      "1.512051060795784\n",
      "Validation loss: 1.4458836317062378\n",
      "mse 1.4458837093872006\n",
      "New best model found at epoch 287 with validation loss 1.4458836317062378\n",
      "Starting Epoch 288\n",
      "1.5115036964416504\n",
      "Validation loss: 1.4453246593475342\n",
      "mse 1.4453246338633097\n",
      "New best model found at epoch 288 with validation loss 1.4453246593475342\n",
      "Starting Epoch 289\n",
      "1.510965218146642\n",
      "Validation loss: 1.4447821378707886\n",
      "mse 1.4447823204358239\n",
      "New best model found at epoch 289 with validation loss 1.4447821378707886\n",
      "Starting Epoch 290\n",
      "1.510434314608574\n",
      "Validation loss: 1.4442546367645264\n",
      "mse 1.444254635780712\n",
      "New best model found at epoch 290 with validation loss 1.4442546367645264\n",
      "Starting Epoch 291\n",
      "1.5099448561668396\n",
      "Validation loss: 1.4437185525894165\n",
      "mse 1.4437185477284886\n",
      "New best model found at epoch 291 with validation loss 1.4437185525894165\n",
      "Starting Epoch 292\n",
      "1.5093878259261448\n",
      "Validation loss: 1.4432367086410522\n",
      "mse 1.4432366654789526\n",
      "New best model found at epoch 292 with validation loss 1.4432367086410522\n",
      "Starting Epoch 293\n",
      "1.5087739775578182\n",
      "Validation loss: 1.4430121183395386\n",
      "mse 1.443012139369813\n",
      "New best model found at epoch 293 with validation loss 1.4430121183395386\n",
      "Starting Epoch 294\n",
      "1.5078516254822414\n",
      "Validation loss: 1.442960500717163\n",
      "mse 1.4429605138624426\n",
      "New best model found at epoch 294 with validation loss 1.442960500717163\n",
      "Starting Epoch 295\n",
      "1.506615787744522\n",
      "Validation loss: 1.4430221319198608\n",
      "mse 1.4430220701271501\n",
      "Starting Epoch 296\n",
      "1.505342036485672\n",
      "Validation loss: 1.4430614709854126\n",
      "mse 1.4430614274140408\n",
      "Starting Epoch 297\n",
      "1.5042404780785243\n",
      "Validation loss: 1.4430201053619385\n",
      "mse 1.4430200924673988\n",
      "Starting Epoch 298\n",
      "1.5032720069090526\n",
      "Validation loss: 1.4429792165756226\n",
      "mse 1.4429792024306716\n",
      "Starting Epoch 299\n",
      "1.5024026781320572\n",
      "Validation loss: 1.4429503679275513\n",
      "mse 1.4429503860971136\n",
      "New best model found at epoch 299 with validation loss 1.4429503679275513\n",
      "Starting Epoch 300\n",
      "1.501522461573283\n",
      "Validation loss: 1.4428762197494507\n",
      "mse 1.4428763460466931\n",
      "New best model found at epoch 300 with validation loss 1.4428762197494507\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-20-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225023a",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 4\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 25 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "09ddcc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "3c53eee6-4d3e-4614-aef5-55f857f19eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.5364241848389306\n",
      "Validation loss: 2.3880887031555176\n",
      "mse 2.388088678656928\n",
      "New best model found at epoch 1 with validation loss 2.3880887031555176\n",
      "Starting Epoch 2\n",
      "2.261597956220309\n",
      "Validation loss: 2.249227523803711\n",
      "mse 2.249227466259872\n",
      "New best model found at epoch 2 with validation loss 2.249227523803711\n",
      "Starting Epoch 3\n",
      "2.1630040456851325\n",
      "Validation loss: 2.1474287509918213\n",
      "mse 2.1474289452099784\n",
      "New best model found at epoch 3 with validation loss 2.1474287509918213\n",
      "Starting Epoch 4\n",
      "2.0813528498013816\n",
      "Validation loss: 2.062229633331299\n",
      "mse 2.062229617227152\n",
      "New best model found at epoch 4 with validation loss 2.062229633331299\n",
      "Starting Epoch 5\n",
      "2.0180400361617408\n",
      "Validation loss: 1.9971811771392822\n",
      "mse 1.997181109699635\n",
      "New best model found at epoch 5 with validation loss 1.9971811771392822\n",
      "Starting Epoch 6\n",
      "1.9677212784687679\n",
      "Validation loss: 1.9424062967300415\n",
      "mse 1.9424062943492304\n",
      "New best model found at epoch 6 with validation loss 1.9424062967300415\n",
      "Starting Epoch 7\n",
      "1.9248723983764648\n",
      "Validation loss: 1.8961877822875977\n",
      "mse 1.896187874308806\n",
      "New best model found at epoch 7 with validation loss 1.8961877822875977\n",
      "Starting Epoch 8\n",
      "1.8883561740318935\n",
      "Validation loss: 1.853638768196106\n",
      "mse 1.8536386969655883\n",
      "New best model found at epoch 8 with validation loss 1.853638768196106\n",
      "Starting Epoch 9\n",
      "1.8569933374722798\n",
      "Validation loss: 1.8174784183502197\n",
      "mse 1.8174783025592753\n",
      "New best model found at epoch 9 with validation loss 1.8174784183502197\n",
      "Starting Epoch 10\n",
      "1.8293286363283794\n",
      "Validation loss: 1.7856976985931396\n",
      "mse 1.7856976252946735\n",
      "New best model found at epoch 10 with validation loss 1.7856976985931396\n",
      "Starting Epoch 11\n",
      "1.804699718952179\n",
      "Validation loss: 1.75838303565979\n",
      "mse 1.75838317928514\n",
      "New best model found at epoch 11 with validation loss 1.75838303565979\n",
      "Starting Epoch 12\n",
      "1.7829698125521343\n",
      "Validation loss: 1.7334394454956055\n",
      "mse 1.7334393950189815\n",
      "New best model found at epoch 12 with validation loss 1.7334394454956055\n",
      "Starting Epoch 13\n",
      "1.7635298172632854\n",
      "Validation loss: 1.7120317220687866\n",
      "mse 1.7120318238650198\n",
      "New best model found at epoch 13 with validation loss 1.7120317220687866\n",
      "Starting Epoch 14\n",
      "1.7462261319160461\n",
      "Validation loss: 1.692729115486145\n",
      "mse 1.692729065654925\n",
      "New best model found at epoch 14 with validation loss 1.692729115486145\n",
      "Starting Epoch 15\n",
      "1.7306557993094127\n",
      "Validation loss: 1.6748735904693604\n",
      "mse 1.674873592426237\n",
      "New best model found at epoch 15 with validation loss 1.6748735904693604\n",
      "Starting Epoch 16\n",
      "1.7166165014108021\n",
      "Validation loss: 1.6595215797424316\n",
      "mse 1.659521518407224\n",
      "New best model found at epoch 16 with validation loss 1.6595215797424316\n",
      "Starting Epoch 17\n",
      "1.703976069887479\n",
      "Validation loss: 1.6453373432159424\n",
      "mse 1.645337221779247\n",
      "New best model found at epoch 17 with validation loss 1.6453373432159424\n",
      "Starting Epoch 18\n",
      "1.6924979438384373\n",
      "Validation loss: 1.632392168045044\n",
      "mse 1.632392243361355\n",
      "New best model found at epoch 18 with validation loss 1.632392168045044\n",
      "Starting Epoch 19\n",
      "1.681948537627856\n",
      "Validation loss: 1.6207164525985718\n",
      "mse 1.6207163694482867\n",
      "New best model found at epoch 19 with validation loss 1.6207164525985718\n",
      "Starting Epoch 20\n",
      "1.672375738620758\n",
      "Validation loss: 1.6100714206695557\n",
      "mse 1.610071461722748\n",
      "New best model found at epoch 20 with validation loss 1.6100714206695557\n",
      "Starting Epoch 21\n",
      "1.6636199603478115\n",
      "Validation loss: 1.6001522541046143\n",
      "mse 1.6001522999222504\n",
      "New best model found at epoch 21 with validation loss 1.6001522541046143\n",
      "Starting Epoch 22\n",
      "1.6555327375729878\n",
      "Validation loss: 1.5911494493484497\n",
      "mse 1.5911494265135988\n",
      "New best model found at epoch 22 with validation loss 1.5911494493484497\n",
      "Starting Epoch 23\n",
      "1.6480401307344437\n",
      "Validation loss: 1.5829484462738037\n",
      "mse 1.582948549662254\n",
      "New best model found at epoch 23 with validation loss 1.5829484462738037\n",
      "Starting Epoch 24\n",
      "1.6411637763182323\n",
      "Validation loss: 1.5753499269485474\n",
      "mse 1.5753500146416355\n",
      "New best model found at epoch 24 with validation loss 1.5753499269485474\n",
      "Starting Epoch 25\n",
      "1.634689177076022\n",
      "Validation loss: 1.5684155225753784\n",
      "mse 1.5684154995927755\n",
      "New best model found at epoch 25 with validation loss 1.5684155225753784\n",
      "Starting Epoch 26\n",
      "1.6287542035182316\n",
      "Validation loss: 1.562042474746704\n",
      "mse 1.5620424029839701\n",
      "New best model found at epoch 26 with validation loss 1.562042474746704\n",
      "Starting Epoch 27\n",
      "1.6232316295305889\n",
      "Validation loss: 1.5559133291244507\n",
      "mse 1.5559132282944306\n",
      "New best model found at epoch 27 with validation loss 1.5559133291244507\n",
      "Starting Epoch 28\n",
      "1.618030697107315\n",
      "Validation loss: 1.5504099130630493\n",
      "mse 1.5504098039464587\n",
      "New best model found at epoch 28 with validation loss 1.5504099130630493\n",
      "Starting Epoch 29\n",
      "1.6131670574347179\n",
      "Validation loss: 1.5450166463851929\n",
      "mse 1.545016524244334\n",
      "New best model found at epoch 29 with validation loss 1.5450166463851929\n",
      "Starting Epoch 30\n",
      "1.608630433678627\n",
      "Validation loss: 1.5401275157928467\n",
      "mse 1.5401274804694627\n",
      "New best model found at epoch 30 with validation loss 1.5401275157928467\n",
      "Starting Epoch 31\n",
      "1.6043250411748886\n",
      "Validation loss: 1.5355522632598877\n",
      "mse 1.535552224719028\n",
      "New best model found at epoch 31 with validation loss 1.5355522632598877\n",
      "Starting Epoch 32\n",
      "1.600288564960162\n",
      "Validation loss: 1.531214952468872\n",
      "mse 1.5312150314513802\n",
      "New best model found at epoch 32 with validation loss 1.531214952468872\n",
      "Starting Epoch 33\n",
      "1.5964246988296509\n",
      "Validation loss: 1.527209758758545\n",
      "mse 1.5272099178467557\n",
      "New best model found at epoch 33 with validation loss 1.527209758758545\n",
      "Starting Epoch 34\n",
      "1.5928521851698558\n",
      "Validation loss: 1.5232250690460205\n",
      "mse 1.523225130708132\n",
      "New best model found at epoch 34 with validation loss 1.5232250690460205\n",
      "Starting Epoch 35\n",
      "1.5893620451291401\n",
      "Validation loss: 1.519505262374878\n",
      "mse 1.5195051553133083\n",
      "New best model found at epoch 35 with validation loss 1.519505262374878\n",
      "Starting Epoch 36\n",
      "1.5860323856274288\n",
      "Validation loss: 1.51608145236969\n",
      "mse 1.5160814209795335\n",
      "New best model found at epoch 36 with validation loss 1.51608145236969\n",
      "Starting Epoch 37\n",
      "1.5829523106416066\n",
      "Validation loss: 1.5128389596939087\n",
      "mse 1.5128389604061858\n",
      "New best model found at epoch 37 with validation loss 1.5128389596939087\n",
      "Starting Epoch 38\n",
      "1.5799760570128758\n",
      "Validation loss: 1.5097042322158813\n",
      "mse 1.5097040954755414\n",
      "New best model found at epoch 38 with validation loss 1.5097042322158813\n",
      "Starting Epoch 39\n",
      "1.5771269500255585\n",
      "Validation loss: 1.5068604946136475\n",
      "mse 1.5068603735262058\n",
      "New best model found at epoch 39 with validation loss 1.5068604946136475\n",
      "Starting Epoch 40\n",
      "1.5744206706682842\n",
      "Validation loss: 1.5041441917419434\n",
      "mse 1.5041441614724305\n",
      "New best model found at epoch 40 with validation loss 1.5041441917419434\n",
      "Starting Epoch 41\n",
      "1.5718511939048767\n",
      "Validation loss: 1.501713752746582\n",
      "mse 1.5017138019721772\n",
      "New best model found at epoch 41 with validation loss 1.501713752746582\n",
      "Starting Epoch 42\n",
      "1.5693858216206233\n",
      "Validation loss: 1.4991384744644165\n",
      "mse 1.4991386018291621\n",
      "New best model found at epoch 42 with validation loss 1.4991384744644165\n",
      "Starting Epoch 43\n",
      "1.5669627636671066\n",
      "Validation loss: 1.4967695474624634\n",
      "mse 1.4967696095339187\n",
      "New best model found at epoch 43 with validation loss 1.4967695474624634\n",
      "Starting Epoch 44\n",
      "1.5647313296794891\n",
      "Validation loss: 1.4943166971206665\n",
      "mse 1.4943166554385963\n",
      "New best model found at epoch 44 with validation loss 1.4943166971206665\n",
      "Starting Epoch 45\n",
      "1.5624805788199108\n",
      "Validation loss: 1.4920389652252197\n",
      "mse 1.4920389597666617\n",
      "New best model found at epoch 45 with validation loss 1.4920389652252197\n",
      "Starting Epoch 46\n",
      "1.5603652149438858\n",
      "Validation loss: 1.489897608757019\n",
      "mse 1.4898975926857945\n",
      "New best model found at epoch 46 with validation loss 1.489897608757019\n",
      "Starting Epoch 47\n",
      "1.5583225538333256\n",
      "Validation loss: 1.4875764846801758\n",
      "mse 1.4875764721521851\n",
      "New best model found at epoch 47 with validation loss 1.4875764846801758\n",
      "Starting Epoch 48\n",
      "1.5563030342260997\n",
      "Validation loss: 1.4855282306671143\n",
      "mse 1.4855282496146045\n",
      "New best model found at epoch 48 with validation loss 1.4855282306671143\n",
      "Starting Epoch 49\n",
      "1.554325317343076\n",
      "Validation loss: 1.4838318824768066\n",
      "mse 1.4838319136684823\n",
      "New best model found at epoch 49 with validation loss 1.4838318824768066\n",
      "Starting Epoch 50\n",
      "1.5525423338015873\n",
      "Validation loss: 1.4818722009658813\n",
      "mse 1.4818722710261278\n",
      "New best model found at epoch 50 with validation loss 1.4818722009658813\n",
      "Starting Epoch 51\n",
      "1.550710196296374\n",
      "Validation loss: 1.4801050424575806\n",
      "mse 1.4801051062121655\n",
      "New best model found at epoch 51 with validation loss 1.4801050424575806\n",
      "Starting Epoch 52\n",
      "1.5489713698625565\n",
      "Validation loss: 1.4783605337142944\n",
      "mse 1.4783605022164807\n",
      "New best model found at epoch 52 with validation loss 1.4783605337142944\n",
      "Starting Epoch 53\n",
      "1.547281449039777\n",
      "Validation loss: 1.4766275882720947\n",
      "mse 1.476627556845492\n",
      "New best model found at epoch 53 with validation loss 1.4766275882720947\n",
      "Starting Epoch 54\n",
      "1.545636514822642\n",
      "Validation loss: 1.4749876260757446\n",
      "mse 1.4749876198134584\n",
      "New best model found at epoch 54 with validation loss 1.4749876260757446\n",
      "Starting Epoch 55\n",
      "1.5440408041079838\n",
      "Validation loss: 1.4734364748001099\n",
      "mse 1.473436480636902\n",
      "New best model found at epoch 55 with validation loss 1.4734364748001099\n",
      "Starting Epoch 56\n",
      "1.5424737284580867\n",
      "Validation loss: 1.4719687700271606\n",
      "mse 1.4719686279245636\n",
      "New best model found at epoch 56 with validation loss 1.4719687700271606\n",
      "Starting Epoch 57\n",
      "1.5409868309895198\n",
      "Validation loss: 1.4704618453979492\n",
      "mse 1.4704617992402906\n",
      "New best model found at epoch 57 with validation loss 1.4704618453979492\n",
      "Starting Epoch 58\n",
      "1.5395051836967468\n",
      "Validation loss: 1.4690425395965576\n",
      "mse 1.4690424937298978\n",
      "New best model found at epoch 58 with validation loss 1.4690425395965576\n",
      "Starting Epoch 59\n",
      "1.538066287835439\n",
      "Validation loss: 1.467685341835022\n",
      "mse 1.4676852505113929\n",
      "New best model found at epoch 59 with validation loss 1.467685341835022\n",
      "Starting Epoch 60\n",
      "1.5367370794216793\n",
      "Validation loss: 1.4659444093704224\n",
      "mse 1.4659444878988386\n",
      "New best model found at epoch 60 with validation loss 1.4659444093704224\n",
      "Starting Epoch 61\n",
      "1.535227010647456\n",
      "Validation loss: 1.4647523164749146\n",
      "mse 1.4647523434252847\n",
      "New best model found at epoch 61 with validation loss 1.4647523164749146\n",
      "Starting Epoch 62\n",
      "1.5339184999465942\n",
      "Validation loss: 1.4632995128631592\n",
      "mse 1.4632996321129288\n",
      "New best model found at epoch 62 with validation loss 1.4632995128631592\n",
      "Starting Epoch 63\n",
      "1.5325360695521038\n",
      "Validation loss: 1.4620991945266724\n",
      "mse 1.4620991956043385\n",
      "New best model found at epoch 63 with validation loss 1.4620991945266724\n",
      "Starting Epoch 64\n",
      "1.5312026341756184\n",
      "Validation loss: 1.4608945846557617\n",
      "mse 1.4608945572742416\n",
      "New best model found at epoch 64 with validation loss 1.4608945846557617\n",
      "Starting Epoch 65\n",
      "1.529978523651759\n",
      "Validation loss: 1.4596161842346191\n",
      "mse 1.459616228393447\n",
      "New best model found at epoch 65 with validation loss 1.4596161842346191\n",
      "Starting Epoch 66\n",
      "1.528679336110751\n",
      "Validation loss: 1.45846426486969\n",
      "mse 1.4584641218709682\n",
      "New best model found at epoch 66 with validation loss 1.45846426486969\n",
      "Starting Epoch 67\n",
      "1.5274378955364227\n",
      "Validation loss: 1.4573360681533813\n",
      "mse 1.4573361151567408\n",
      "New best model found at epoch 67 with validation loss 1.4573360681533813\n",
      "Starting Epoch 68\n",
      "1.5262259244918823\n",
      "Validation loss: 1.456230878829956\n",
      "mse 1.456230876804546\n",
      "New best model found at epoch 68 with validation loss 1.456230878829956\n",
      "Starting Epoch 69\n",
      "1.5250313182671864\n",
      "Validation loss: 1.4551485776901245\n",
      "mse 1.455148592597336\n",
      "New best model found at epoch 69 with validation loss 1.4551485776901245\n",
      "Starting Epoch 70\n",
      "1.523854191104571\n",
      "Validation loss: 1.4541964530944824\n",
      "mse 1.454196624628073\n",
      "New best model found at epoch 70 with validation loss 1.4541964530944824\n",
      "Starting Epoch 71\n",
      "1.5227483212947845\n",
      "Validation loss: 1.4531450271606445\n",
      "mse 1.4531449396951006\n",
      "New best model found at epoch 71 with validation loss 1.4531450271606445\n",
      "Starting Epoch 72\n",
      "1.5216207752625148\n",
      "Validation loss: 1.4520996809005737\n",
      "mse 1.4520996818075824\n",
      "New best model found at epoch 72 with validation loss 1.4520996809005737\n",
      "Starting Epoch 73\n",
      "1.5204920669396718\n",
      "Validation loss: 1.4511065483093262\n",
      "mse 1.4511065496842284\n",
      "New best model found at epoch 73 with validation loss 1.4511065483093262\n",
      "Starting Epoch 74\n",
      "1.5194065173467\n",
      "Validation loss: 1.4502025842666626\n",
      "mse 1.4502024502066604\n",
      "New best model found at epoch 74 with validation loss 1.4502025842666626\n",
      "Starting Epoch 75\n",
      "1.51835993429025\n",
      "Validation loss: 1.449184536933899\n",
      "mse 1.4491847006778367\n",
      "New best model found at epoch 75 with validation loss 1.449184536933899\n",
      "Starting Epoch 76\n",
      "1.51729816198349\n",
      "Validation loss: 1.448216199874878\n",
      "mse 1.448216195337452\n",
      "New best model found at epoch 76 with validation loss 1.448216199874878\n",
      "Starting Epoch 77\n",
      "1.5162746558586757\n",
      "Validation loss: 1.4473028182983398\n",
      "mse 1.4473027247245804\n",
      "New best model found at epoch 77 with validation loss 1.4473028182983398\n",
      "Starting Epoch 78\n",
      "1.5152766307195027\n",
      "Validation loss: 1.4463917016983032\n",
      "mse 1.4463918256116581\n",
      "New best model found at epoch 78 with validation loss 1.4463917016983032\n",
      "Starting Epoch 79\n",
      "1.5142879684766133\n",
      "Validation loss: 1.4454822540283203\n",
      "mse 1.4454822439094974\n",
      "New best model found at epoch 79 with validation loss 1.4454822540283203\n",
      "Starting Epoch 80\n",
      "1.5133287658294041\n",
      "Validation loss: 1.4446163177490234\n",
      "mse 1.444616356343051\n",
      "New best model found at epoch 80 with validation loss 1.4446163177490234\n",
      "Starting Epoch 81\n",
      "1.5123554319143295\n",
      "Validation loss: 1.443819284439087\n",
      "mse 1.4438192710039301\n",
      "New best model found at epoch 81 with validation loss 1.443819284439087\n",
      "Starting Epoch 82\n",
      "1.5114496300617855\n",
      "Validation loss: 1.4429131746292114\n",
      "mse 1.4429131603465795\n",
      "New best model found at epoch 82 with validation loss 1.4429131746292114\n",
      "Starting Epoch 83\n",
      "1.510510414838791\n",
      "Validation loss: 1.4421336650848389\n",
      "mse 1.442133746883289\n",
      "New best model found at epoch 83 with validation loss 1.4421336650848389\n",
      "Starting Epoch 84\n",
      "1.5096006294091542\n",
      "Validation loss: 1.4413435459136963\n",
      "mse 1.4413436208416657\n",
      "New best model found at epoch 84 with validation loss 1.4413435459136963\n",
      "Starting Epoch 85\n",
      "1.5087217291196187\n",
      "Validation loss: 1.4404624700546265\n",
      "mse 1.4404624311552763\n",
      "New best model found at epoch 85 with validation loss 1.4404624700546265\n",
      "Starting Epoch 86\n",
      "1.507789785663287\n",
      "Validation loss: 1.4397801160812378\n",
      "mse 1.4397800530233884\n",
      "New best model found at epoch 86 with validation loss 1.4397801160812378\n",
      "Starting Epoch 87\n",
      "1.5069643010695775\n",
      "Validation loss: 1.4389519691467285\n",
      "mse 1.4389518959874648\n",
      "New best model found at epoch 87 with validation loss 1.4389519691467285\n",
      "Starting Epoch 88\n",
      "1.5060858130455017\n",
      "Validation loss: 1.4382017850875854\n",
      "mse 1.4382018597391806\n",
      "New best model found at epoch 88 with validation loss 1.4382017850875854\n",
      "Starting Epoch 89\n",
      "1.5051700721184413\n",
      "Validation loss: 1.437477707862854\n",
      "mse 1.4374776678624153\n",
      "New best model found at epoch 89 with validation loss 1.437477707862854\n",
      "Starting Epoch 90\n",
      "1.5044264992078145\n",
      "Validation loss: 1.436713457107544\n",
      "mse 1.4367134778708455\n",
      "New best model found at epoch 90 with validation loss 1.436713457107544\n",
      "Starting Epoch 91\n",
      "1.5035464614629745\n",
      "Validation loss: 1.4363209009170532\n",
      "mse 1.4363210185542807\n",
      "New best model found at epoch 91 with validation loss 1.4363209009170532\n",
      "Starting Epoch 92\n",
      "1.5025805830955505\n",
      "Validation loss: 1.4356979131698608\n",
      "mse 1.4356977790689789\n",
      "New best model found at epoch 92 with validation loss 1.4356979131698608\n",
      "Starting Epoch 93\n",
      "1.5017351011435192\n",
      "Validation loss: 1.4350169897079468\n",
      "mse 1.4350171241133574\n",
      "New best model found at epoch 93 with validation loss 1.4350169897079468\n",
      "Starting Epoch 94\n",
      "1.5008333424727123\n",
      "Validation loss: 1.4343533515930176\n",
      "mse 1.4343534619751912\n",
      "New best model found at epoch 94 with validation loss 1.4343533515930176\n",
      "Starting Epoch 95\n",
      "1.4999249478181202\n",
      "Validation loss: 1.4336377382278442\n",
      "mse 1.4336376537885434\n",
      "New best model found at epoch 95 with validation loss 1.4336377382278442\n",
      "Starting Epoch 96\n",
      "1.4990067183971405\n",
      "Validation loss: 1.4330182075500488\n",
      "mse 1.4330181388865812\n",
      "New best model found at epoch 96 with validation loss 1.4330182075500488\n",
      "Starting Epoch 97\n",
      "1.4981658309698105\n",
      "Validation loss: 1.4322693347930908\n",
      "mse 1.432269275331748\n",
      "New best model found at epoch 97 with validation loss 1.4322693347930908\n",
      "Starting Epoch 98\n",
      "1.4973356276750565\n",
      "Validation loss: 1.4316492080688477\n",
      "mse 1.4316489878681984\n",
      "New best model found at epoch 98 with validation loss 1.4316492080688477\n",
      "Starting Epoch 99\n",
      "1.4964598814646404\n",
      "Validation loss: 1.431086540222168\n",
      "mse 1.4310865255319403\n",
      "New best model found at epoch 99 with validation loss 1.431086540222168\n",
      "Starting Epoch 100\n",
      "1.4956402033567429\n",
      "Validation loss: 1.4303992986679077\n",
      "mse 1.4303993095725818\n",
      "New best model found at epoch 100 with validation loss 1.4303992986679077\n",
      "Starting Epoch 101\n",
      "1.4948579569657643\n",
      "Validation loss: 1.4296270608901978\n",
      "mse 1.4296269961306776\n",
      "New best model found at epoch 101 with validation loss 1.4296270608901978\n",
      "Starting Epoch 102\n",
      "1.4940279722213745\n",
      "Validation loss: 1.4291250705718994\n",
      "mse 1.4291250044489205\n",
      "New best model found at epoch 102 with validation loss 1.4291250705718994\n",
      "Starting Epoch 103\n",
      "1.4932756870985031\n",
      "Validation loss: 1.4285191297531128\n",
      "mse 1.4285190962542151\n",
      "New best model found at epoch 103 with validation loss 1.4285191297531128\n",
      "Starting Epoch 104\n",
      "1.4925077607234318\n",
      "Validation loss: 1.427881121635437\n",
      "mse 1.4278810911745095\n",
      "New best model found at epoch 104 with validation loss 1.427881121635437\n",
      "Starting Epoch 105\n",
      "1.491725688179334\n",
      "Validation loss: 1.4273632764816284\n",
      "mse 1.4273632592635164\n",
      "New best model found at epoch 105 with validation loss 1.4273632764816284\n",
      "Starting Epoch 106\n",
      "1.4910014520088832\n",
      "Validation loss: 1.4266759157180786\n",
      "mse 1.4266760252581543\n",
      "New best model found at epoch 106 with validation loss 1.4266759157180786\n",
      "Starting Epoch 107\n",
      "1.4902253150939941\n",
      "Validation loss: 1.4261231422424316\n",
      "mse 1.4261231226613942\n",
      "New best model found at epoch 107 with validation loss 1.4261231422424316\n",
      "Starting Epoch 108\n",
      "1.489494909842809\n",
      "Validation loss: 1.4255181550979614\n",
      "mse 1.4255182012063858\n",
      "New best model found at epoch 108 with validation loss 1.4255181550979614\n",
      "Starting Epoch 109\n",
      "1.4887643655141194\n",
      "Validation loss: 1.4249316453933716\n",
      "mse 1.4249317575406792\n",
      "New best model found at epoch 109 with validation loss 1.4249316453933716\n",
      "Starting Epoch 110\n",
      "1.48807659248511\n",
      "Validation loss: 1.4242812395095825\n",
      "mse 1.424281170818896\n",
      "New best model found at epoch 110 with validation loss 1.4242812395095825\n",
      "Starting Epoch 111\n",
      "1.4873104989528656\n",
      "Validation loss: 1.423779845237732\n",
      "mse 1.4237798876183536\n",
      "New best model found at epoch 111 with validation loss 1.423779845237732\n",
      "Starting Epoch 112\n",
      "1.4866337180137634\n",
      "Validation loss: 1.4232159852981567\n",
      "mse 1.4232160210247657\n",
      "New best model found at epoch 112 with validation loss 1.4232159852981567\n",
      "Starting Epoch 113\n",
      "1.4859216213226318\n",
      "Validation loss: 1.4226675033569336\n",
      "mse 1.4226674639095236\n",
      "New best model found at epoch 113 with validation loss 1.4226675033569336\n",
      "Starting Epoch 114\n",
      "1.485237956047058\n",
      "Validation loss: 1.422123908996582\n",
      "mse 1.4221240321773354\n",
      "New best model found at epoch 114 with validation loss 1.422123908996582\n",
      "Starting Epoch 115\n",
      "1.4845593969027202\n",
      "Validation loss: 1.4215734004974365\n",
      "mse 1.4215733888551298\n",
      "New best model found at epoch 115 with validation loss 1.4215734004974365\n",
      "Starting Epoch 116\n",
      "1.483920951684316\n",
      "Validation loss: 1.420963168144226\n",
      "mse 1.420962979356467\n",
      "New best model found at epoch 116 with validation loss 1.420963168144226\n",
      "Starting Epoch 117\n",
      "1.4832204083601634\n",
      "Validation loss: 1.4204639196395874\n",
      "mse 1.4204638656274395\n",
      "New best model found at epoch 117 with validation loss 1.4204639196395874\n",
      "Starting Epoch 118\n",
      "1.4825749844312668\n",
      "Validation loss: 1.419897437095642\n",
      "mse 1.4198974258816668\n",
      "New best model found at epoch 118 with validation loss 1.419897437095642\n",
      "Starting Epoch 119\n",
      "1.4819227506717045\n",
      "Validation loss: 1.4193800687789917\n",
      "mse 1.419380122203352\n",
      "New best model found at epoch 119 with validation loss 1.4193800687789917\n",
      "Starting Epoch 120\n",
      "1.4812869727611542\n",
      "Validation loss: 1.4188662767410278\n",
      "mse 1.418866287810378\n",
      "New best model found at epoch 120 with validation loss 1.4188662767410278\n",
      "Starting Epoch 121\n",
      "1.4806639403104782\n",
      "Validation loss: 1.4183287620544434\n",
      "mse 1.418328825969124\n",
      "New best model found at epoch 121 with validation loss 1.4183287620544434\n",
      "Starting Epoch 122\n",
      "1.4800277749697368\n",
      "Validation loss: 1.417846441268921\n",
      "mse 1.4178464447373906\n",
      "New best model found at epoch 122 with validation loss 1.417846441268921\n",
      "Starting Epoch 123\n",
      "1.4794196337461472\n",
      "Validation loss: 1.4173383712768555\n",
      "mse 1.4173383762553744\n",
      "New best model found at epoch 123 with validation loss 1.4173383712768555\n",
      "Starting Epoch 124\n",
      "1.4787988513708115\n",
      "Validation loss: 1.4168570041656494\n",
      "mse 1.416856979293379\n",
      "New best model found at epoch 124 with validation loss 1.4168570041656494\n",
      "Starting Epoch 125\n",
      "1.4781940877437592\n",
      "Validation loss: 1.4163768291473389\n",
      "mse 1.4163768112781672\n",
      "New best model found at epoch 125 with validation loss 1.4163768291473389\n",
      "Starting Epoch 126\n",
      "1.4775868207216263\n",
      "Validation loss: 1.4157613515853882\n",
      "mse 1.4157613820089923\n",
      "New best model found at epoch 126 with validation loss 1.4157613515853882\n",
      "Starting Epoch 127\n",
      "1.4770206312338512\n",
      "Validation loss: 1.415348768234253\n",
      "mse 1.415348890666126\n",
      "New best model found at epoch 127 with validation loss 1.415348768234253\n",
      "Starting Epoch 128\n",
      "1.4763963719209034\n",
      "Validation loss: 1.4148133993148804\n",
      "mse 1.4148133171184603\n",
      "New best model found at epoch 128 with validation loss 1.4148133993148804\n",
      "Starting Epoch 129\n",
      "1.4758190164963405\n",
      "Validation loss: 1.414345622062683\n",
      "mse 1.4143455943176155\n",
      "New best model found at epoch 129 with validation loss 1.414345622062683\n",
      "Starting Epoch 130\n",
      "1.475238601366679\n",
      "Validation loss: 1.4138482809066772\n",
      "mse 1.4138482483332564\n",
      "New best model found at epoch 130 with validation loss 1.4138482809066772\n",
      "Starting Epoch 131\n",
      "1.474650263786316\n",
      "Validation loss: 1.4133411645889282\n",
      "mse 1.4133412248112216\n",
      "New best model found at epoch 131 with validation loss 1.4133411645889282\n",
      "Starting Epoch 132\n",
      "1.4734649906555812\n",
      "Validation loss: 1.412312388420105\n",
      "mse 1.4123124759814316\n",
      "New best model found at epoch 132 with validation loss 1.412312388420105\n",
      "Starting Epoch 133\n",
      "1.4720980177323024\n",
      "Validation loss: 1.41117525100708\n",
      "mse 1.411175159945045\n",
      "New best model found at epoch 133 with validation loss 1.41117525100708\n",
      "Starting Epoch 134\n",
      "1.4708617130915325\n",
      "Validation loss: 1.4101892709732056\n",
      "mse 1.4101892327142687\n",
      "New best model found at epoch 134 with validation loss 1.4101892709732056\n",
      "Starting Epoch 135\n",
      "1.4696984092394512\n",
      "Validation loss: 1.4091925621032715\n",
      "mse 1.4091925482768672\n",
      "New best model found at epoch 135 with validation loss 1.4091925621032715\n",
      "Starting Epoch 136\n",
      "1.4685643712679546\n",
      "Validation loss: 1.4082626104354858\n",
      "mse 1.4082626523933441\n",
      "New best model found at epoch 136 with validation loss 1.4082626104354858\n",
      "Starting Epoch 137\n",
      "1.467469761768977\n",
      "Validation loss: 1.4073128700256348\n",
      "mse 1.4073129396847677\n",
      "New best model found at epoch 137 with validation loss 1.4073128700256348\n",
      "Starting Epoch 138\n",
      "1.4664073934157689\n",
      "Validation loss: 1.406387209892273\n",
      "mse 1.4063872129481567\n",
      "New best model found at epoch 138 with validation loss 1.406387209892273\n",
      "Starting Epoch 139\n",
      "1.4654033084710438\n",
      "Validation loss: 1.4054490327835083\n",
      "mse 1.4054491140591028\n",
      "New best model found at epoch 139 with validation loss 1.4054490327835083\n",
      "Starting Epoch 140\n",
      "1.4644520406921704\n",
      "Validation loss: 1.4046849012374878\n",
      "mse 1.4046849807240045\n",
      "New best model found at epoch 140 with validation loss 1.4046849012374878\n",
      "Starting Epoch 141\n",
      "1.463536207874616\n",
      "Validation loss: 1.4038479328155518\n",
      "mse 1.4038479981324032\n",
      "New best model found at epoch 141 with validation loss 1.4038479328155518\n",
      "Starting Epoch 142\n",
      "1.4626230597496033\n",
      "Validation loss: 1.403148889541626\n",
      "mse 1.4031488583460574\n",
      "New best model found at epoch 142 with validation loss 1.403148889541626\n",
      "Starting Epoch 143\n",
      "1.46173507720232\n",
      "Validation loss: 1.4023480415344238\n",
      "mse 1.4023480666238852\n",
      "New best model found at epoch 143 with validation loss 1.4023480415344238\n",
      "Starting Epoch 144\n",
      "1.4608446558316548\n",
      "Validation loss: 1.4016419649124146\n",
      "mse 1.4016419829255844\n",
      "New best model found at epoch 144 with validation loss 1.4016419649124146\n",
      "Starting Epoch 145\n",
      "1.45997088154157\n",
      "Validation loss: 1.4009538888931274\n",
      "mse 1.4009538916426567\n",
      "New best model found at epoch 145 with validation loss 1.4009538888931274\n",
      "Starting Epoch 146\n",
      "1.4591193919380505\n",
      "Validation loss: 1.4002822637557983\n",
      "mse 1.4002822538300628\n",
      "New best model found at epoch 146 with validation loss 1.4002822637557983\n",
      "Starting Epoch 147\n",
      "1.4582824384172757\n",
      "Validation loss: 1.39963698387146\n",
      "mse 1.399636926745571\n",
      "New best model found at epoch 147 with validation loss 1.39963698387146\n",
      "Starting Epoch 148\n",
      "1.4574628546833992\n",
      "Validation loss: 1.3989908695220947\n",
      "mse 1.3989909059012082\n",
      "New best model found at epoch 148 with validation loss 1.3989908695220947\n",
      "Starting Epoch 149\n",
      "1.4566916177670162\n",
      "Validation loss: 1.3983932733535767\n",
      "mse 1.3983931231202422\n",
      "New best model found at epoch 149 with validation loss 1.3983932733535767\n",
      "Starting Epoch 150\n",
      "1.4557670876383781\n",
      "Validation loss: 1.3979721069335938\n",
      "mse 1.3979721697811718\n",
      "New best model found at epoch 150 with validation loss 1.3979721069335938\n",
      "Starting Epoch 151\n",
      "1.4548823932806652\n",
      "Validation loss: 1.397311806678772\n",
      "mse 1.3973117861986837\n",
      "New best model found at epoch 151 with validation loss 1.397311806678772\n",
      "Starting Epoch 152\n",
      "1.453959549466769\n",
      "Validation loss: 1.3967376947402954\n",
      "mse 1.396737804378202\n",
      "New best model found at epoch 152 with validation loss 1.3967376947402954\n",
      "Starting Epoch 153\n",
      "1.4530522599816322\n",
      "Validation loss: 1.3960249423980713\n",
      "mse 1.396025049163826\n",
      "New best model found at epoch 153 with validation loss 1.3960249423980713\n",
      "Starting Epoch 154\n",
      "1.4521458894014359\n",
      "Validation loss: 1.3954648971557617\n",
      "mse 1.3954648743991764\n",
      "New best model found at epoch 154 with validation loss 1.3954648971557617\n",
      "Starting Epoch 155\n",
      "1.451267513136069\n",
      "Validation loss: 1.3948432207107544\n",
      "mse 1.3948430505884284\n",
      "New best model found at epoch 155 with validation loss 1.3948432207107544\n",
      "Starting Epoch 156\n",
      "1.4504318907856941\n",
      "Validation loss: 1.3942744731903076\n",
      "mse 1.3942744424297753\n",
      "New best model found at epoch 156 with validation loss 1.3942744731903076\n",
      "Starting Epoch 157\n",
      "1.449603113035361\n",
      "Validation loss: 1.393746018409729\n",
      "mse 1.3937460595203113\n",
      "New best model found at epoch 157 with validation loss 1.393746018409729\n",
      "Starting Epoch 158\n",
      "1.448649749159813\n",
      "Validation loss: 1.392918348312378\n",
      "mse 1.392918318065612\n",
      "New best model found at epoch 158 with validation loss 1.392918348312378\n",
      "Starting Epoch 159\n",
      "1.4473707228899002\n",
      "Validation loss: 1.3918696641921997\n",
      "mse 1.3918696870672924\n",
      "New best model found at epoch 159 with validation loss 1.3918696641921997\n",
      "Starting Epoch 160\n",
      "1.4462002217769623\n",
      "Validation loss: 1.390752911567688\n",
      "mse 1.3907529825143983\n",
      "New best model found at epoch 160 with validation loss 1.390752911567688\n",
      "Starting Epoch 161\n",
      "1.445187081893285\n",
      "Validation loss: 1.3898046016693115\n",
      "mse 1.3898047513256195\n",
      "New best model found at epoch 161 with validation loss 1.3898046016693115\n",
      "Starting Epoch 162\n",
      "1.4443011979262035\n",
      "Validation loss: 1.3889310359954834\n",
      "mse 1.388931060322822\n",
      "New best model found at epoch 162 with validation loss 1.3889310359954834\n",
      "Starting Epoch 163\n",
      "1.4434742058316867\n",
      "Validation loss: 1.3883455991744995\n",
      "mse 1.3883455630063488\n",
      "New best model found at epoch 163 with validation loss 1.3883455991744995\n",
      "Starting Epoch 164\n",
      "1.4427186623215675\n",
      "Validation loss: 1.3877153396606445\n",
      "mse 1.3877152965339765\n",
      "New best model found at epoch 164 with validation loss 1.3877153396606445\n",
      "Starting Epoch 165\n",
      "1.4418952564398448\n",
      "Validation loss: 1.387228012084961\n",
      "mse 1.3872280247698994\n",
      "New best model found at epoch 165 with validation loss 1.387228012084961\n",
      "Starting Epoch 166\n",
      "1.4411121731003125\n",
      "Validation loss: 1.3867071866989136\n",
      "mse 1.3867071587993138\n",
      "New best model found at epoch 166 with validation loss 1.3867071866989136\n",
      "Starting Epoch 167\n",
      "1.4403587579727173\n",
      "Validation loss: 1.3861753940582275\n",
      "mse 1.3861753511495813\n",
      "New best model found at epoch 167 with validation loss 1.3861753940582275\n",
      "Starting Epoch 168\n",
      "1.4396522790193558\n",
      "Validation loss: 1.3855676651000977\n",
      "mse 1.385567716368786\n",
      "New best model found at epoch 168 with validation loss 1.3855676651000977\n",
      "Starting Epoch 169\n",
      "1.4388756280144055\n",
      "Validation loss: 1.385035753250122\n",
      "mse 1.3850358778599539\n",
      "New best model found at epoch 169 with validation loss 1.385035753250122\n",
      "Starting Epoch 170\n",
      "1.4381550252437592\n",
      "Validation loss: 1.3845196962356567\n",
      "mse 1.3845197018796354\n",
      "New best model found at epoch 170 with validation loss 1.3845196962356567\n",
      "Starting Epoch 171\n",
      "1.4374308014909427\n",
      "Validation loss: 1.3839802742004395\n",
      "mse 1.3839802623654232\n",
      "New best model found at epoch 171 with validation loss 1.3839802742004395\n",
      "Starting Epoch 172\n",
      "1.436738130946954\n",
      "Validation loss: 1.3834742307662964\n",
      "mse 1.3834741694369537\n",
      "New best model found at epoch 172 with validation loss 1.3834742307662964\n",
      "Starting Epoch 173\n",
      "1.436032382150491\n",
      "Validation loss: 1.3829407691955566\n",
      "mse 1.3829408222045294\n",
      "New best model found at epoch 173 with validation loss 1.3829407691955566\n",
      "Starting Epoch 174\n",
      "1.435337856411934\n",
      "Validation loss: 1.3824489116668701\n",
      "mse 1.3824488235441355\n",
      "New best model found at epoch 174 with validation loss 1.3824489116668701\n",
      "Starting Epoch 175\n",
      "1.4346341788768768\n",
      "Validation loss: 1.3819499015808105\n",
      "mse 1.381949892379111\n",
      "New best model found at epoch 175 with validation loss 1.3819499015808105\n",
      "Starting Epoch 176\n",
      "1.433948166668415\n",
      "Validation loss: 1.38145911693573\n",
      "mse 1.3814591210493739\n",
      "New best model found at epoch 176 with validation loss 1.38145911693573\n",
      "Starting Epoch 177\n",
      "1.4332705313960712\n",
      "Validation loss: 1.3809480667114258\n",
      "mse 1.3809482104751372\n",
      "New best model found at epoch 177 with validation loss 1.3809480667114258\n",
      "Starting Epoch 178\n",
      "1.4326168249050777\n",
      "Validation loss: 1.3804157972335815\n",
      "mse 1.3804157257384397\n",
      "New best model found at epoch 178 with validation loss 1.3804157972335815\n",
      "Starting Epoch 179\n",
      "1.4318711509307225\n",
      "Validation loss: 1.3799070119857788\n",
      "mse 1.37990695553032\n",
      "New best model found at epoch 179 with validation loss 1.3799070119857788\n",
      "Starting Epoch 180\n",
      "1.4312272270520527\n",
      "Validation loss: 1.3793277740478516\n",
      "mse 1.379327743218337\n",
      "New best model found at epoch 180 with validation loss 1.3793277740478516\n",
      "Starting Epoch 181\n",
      "1.4306196322043736\n",
      "Validation loss: 1.3788031339645386\n",
      "mse 1.378803119265636\n",
      "New best model found at epoch 181 with validation loss 1.3788031339645386\n",
      "Starting Epoch 182\n",
      "1.4299555296699207\n",
      "Validation loss: 1.3783369064331055\n",
      "mse 1.3783368640806848\n",
      "New best model found at epoch 182 with validation loss 1.3783369064331055\n",
      "Starting Epoch 183\n",
      "1.429346648355325\n",
      "Validation loss: 1.3778009414672852\n",
      "mse 1.3778009720850959\n",
      "New best model found at epoch 183 with validation loss 1.3778009414672852\n",
      "Starting Epoch 184\n",
      "1.4287121792634327\n",
      "Validation loss: 1.3773843050003052\n",
      "mse 1.377384423753849\n",
      "New best model found at epoch 184 with validation loss 1.3773843050003052\n",
      "Starting Epoch 185\n",
      "1.428117647767067\n",
      "Validation loss: 1.3768953084945679\n",
      "mse 1.3768951207607918\n",
      "New best model found at epoch 185 with validation loss 1.3768953084945679\n",
      "Starting Epoch 186\n",
      "1.4275511900583904\n",
      "Validation loss: 1.3763158321380615\n",
      "mse 1.3763157914809458\n",
      "New best model found at epoch 186 with validation loss 1.3763158321380615\n",
      "Starting Epoch 187\n",
      "1.4269147589802742\n",
      "Validation loss: 1.3758519887924194\n",
      "mse 1.3758520106972172\n",
      "New best model found at epoch 187 with validation loss 1.3758519887924194\n",
      "Starting Epoch 188\n",
      "1.4263682961463928\n",
      "Validation loss: 1.375373363494873\n",
      "mse 1.3753733578139498\n",
      "New best model found at epoch 188 with validation loss 1.375373363494873\n",
      "Starting Epoch 189\n",
      "1.4257518847783406\n",
      "Validation loss: 1.374993920326233\n",
      "mse 1.3749939217505602\n",
      "New best model found at epoch 189 with validation loss 1.374993920326233\n",
      "Starting Epoch 190\n",
      "1.425234427054723\n",
      "Validation loss: 1.374524474143982\n",
      "mse 1.3745245850707122\n",
      "New best model found at epoch 190 with validation loss 1.374524474143982\n",
      "Starting Epoch 191\n",
      "1.4246868416666985\n",
      "Validation loss: 1.3740094900131226\n",
      "mse 1.374009375928124\n",
      "New best model found at epoch 191 with validation loss 1.3740094900131226\n",
      "Starting Epoch 192\n",
      "1.4242010513941448\n",
      "Validation loss: 1.373569369316101\n",
      "mse 1.3735694666670342\n",
      "New best model found at epoch 192 with validation loss 1.373569369316101\n",
      "Starting Epoch 193\n",
      "1.423634372651577\n",
      "Validation loss: 1.373223066329956\n",
      "mse 1.3732230942381183\n",
      "New best model found at epoch 193 with validation loss 1.373223066329956\n",
      "Starting Epoch 194\n",
      "1.4231116051475208\n",
      "Validation loss: 1.3729225397109985\n",
      "mse 1.372922435884597\n",
      "New best model found at epoch 194 with validation loss 1.3729225397109985\n",
      "Starting Epoch 195\n",
      "1.4226366852720578\n",
      "Validation loss: 1.3724268674850464\n",
      "mse 1.3724268379847528\n",
      "New best model found at epoch 195 with validation loss 1.3724268674850464\n",
      "Starting Epoch 196\n",
      "1.4220986117919285\n",
      "Validation loss: 1.3720450401306152\n",
      "mse 1.3720449524665512\n",
      "New best model found at epoch 196 with validation loss 1.3720450401306152\n",
      "Starting Epoch 197\n",
      "1.421632322172324\n",
      "Validation loss: 1.3716351985931396\n",
      "mse 1.3716354154749777\n",
      "New best model found at epoch 197 with validation loss 1.3716351985931396\n",
      "Starting Epoch 198\n",
      "1.4210846722126007\n",
      "Validation loss: 1.3712959289550781\n",
      "mse 1.3712959294174498\n",
      "New best model found at epoch 198 with validation loss 1.3712959289550781\n",
      "Starting Epoch 199\n",
      "1.420606513818105\n",
      "Validation loss: 1.3709367513656616\n",
      "mse 1.3709367239134629\n",
      "New best model found at epoch 199 with validation loss 1.3709367513656616\n",
      "Starting Epoch 200\n",
      "1.4201395014921825\n",
      "Validation loss: 1.370548129081726\n",
      "mse 1.3705482772998019\n",
      "New best model found at epoch 200 with validation loss 1.370548129081726\n",
      "Starting Epoch 201\n",
      "1.4196212366223335\n",
      "Validation loss: 1.3702309131622314\n",
      "mse 1.3702308695968568\n",
      "New best model found at epoch 201 with validation loss 1.3702309131622314\n",
      "Starting Epoch 202\n",
      "1.4191445981462796\n",
      "Validation loss: 1.3698463439941406\n",
      "mse 1.3698464626783022\n",
      "New best model found at epoch 202 with validation loss 1.3698463439941406\n",
      "Starting Epoch 203\n",
      "1.418633999923865\n",
      "Validation loss: 1.369516372680664\n",
      "mse 1.3695163729945439\n",
      "New best model found at epoch 203 with validation loss 1.369516372680664\n",
      "Starting Epoch 204\n",
      "1.4182123268644016\n",
      "Validation loss: 1.369117259979248\n",
      "mse 1.3691172184455633\n",
      "New best model found at epoch 204 with validation loss 1.369117259979248\n",
      "Starting Epoch 205\n",
      "1.41768416762352\n",
      "Validation loss: 1.368807077407837\n",
      "mse 1.36880713350749\n",
      "New best model found at epoch 205 with validation loss 1.368807077407837\n",
      "Starting Epoch 206\n",
      "1.4172882586717606\n",
      "Validation loss: 1.368402123451233\n",
      "mse 1.3684021407811193\n",
      "New best model found at epoch 206 with validation loss 1.368402123451233\n",
      "Starting Epoch 207\n",
      "1.416779858370622\n",
      "Validation loss: 1.3680726289749146\n",
      "mse 1.3680726199091608\n",
      "New best model found at epoch 207 with validation loss 1.3680726289749146\n",
      "Starting Epoch 208\n",
      "1.4163067936897278\n",
      "Validation loss: 1.3677446842193604\n",
      "mse 1.3677447558519673\n",
      "New best model found at epoch 208 with validation loss 1.3677446842193604\n",
      "Starting Epoch 209\n",
      "1.4158620312809944\n",
      "Validation loss: 1.3674116134643555\n",
      "mse 1.3674116822499527\n",
      "New best model found at epoch 209 with validation loss 1.3674116134643555\n",
      "Starting Epoch 210\n",
      "1.4154037882884343\n",
      "Validation loss: 1.367113471031189\n",
      "mse 1.3671133839020742\n",
      "New best model found at epoch 210 with validation loss 1.367113471031189\n",
      "Starting Epoch 211\n",
      "1.4149509966373444\n",
      "Validation loss: 1.3667716979980469\n",
      "mse 1.366771808683414\n",
      "New best model found at epoch 211 with validation loss 1.3667716979980469\n",
      "Starting Epoch 212\n",
      "1.4144852682948112\n",
      "Validation loss: 1.3664692640304565\n",
      "mse 1.3664693144528293\n",
      "New best model found at epoch 212 with validation loss 1.3664692640304565\n",
      "Starting Epoch 213\n",
      "1.4140493050217628\n",
      "Validation loss: 1.3661173582077026\n",
      "mse 1.3661173618995006\n",
      "New best model found at epoch 213 with validation loss 1.3661173582077026\n",
      "Starting Epoch 214\n",
      "1.413626658419768\n",
      "Validation loss: 1.3657385110855103\n",
      "mse 1.3657384900209117\n",
      "New best model found at epoch 214 with validation loss 1.3657385110855103\n",
      "Starting Epoch 215\n",
      "1.4131333455443382\n",
      "Validation loss: 1.365518569946289\n",
      "mse 1.3655186253651297\n",
      "New best model found at epoch 215 with validation loss 1.365518569946289\n",
      "Starting Epoch 216\n",
      "1.4127917885780334\n",
      "Validation loss: 1.3651241064071655\n",
      "mse 1.3651240963899374\n",
      "New best model found at epoch 216 with validation loss 1.3651241064071655\n",
      "Starting Epoch 217\n",
      "1.41233475257953\n",
      "Validation loss: 1.364791750907898\n",
      "mse 1.3647917106044074\n",
      "New best model found at epoch 217 with validation loss 1.364791750907898\n",
      "Starting Epoch 218\n",
      "1.4118888701001804\n",
      "Validation loss: 1.3642464876174927\n",
      "mse 1.364246517531716\n",
      "New best model found at epoch 218 with validation loss 1.3642464876174927\n",
      "Starting Epoch 219\n",
      "1.4115367457270622\n",
      "Validation loss: 1.3641432523727417\n",
      "mse 1.3641432626526397\n",
      "New best model found at epoch 219 with validation loss 1.3641432523727417\n",
      "Starting Epoch 220\n",
      "1.4110886032382648\n",
      "Validation loss: 1.3638062477111816\n",
      "mse 1.3638061118713396\n",
      "New best model found at epoch 220 with validation loss 1.3638062477111816\n",
      "Starting Epoch 221\n",
      "1.4106848662098248\n",
      "Validation loss: 1.3632761240005493\n",
      "mse 1.363276067181511\n",
      "New best model found at epoch 221 with validation loss 1.3632761240005493\n",
      "Starting Epoch 222\n",
      "1.4102587029337883\n",
      "Validation loss: 1.3631868362426758\n",
      "mse 1.363186861397149\n",
      "New best model found at epoch 222 with validation loss 1.3631868362426758\n",
      "Starting Epoch 223\n",
      "1.4098696783185005\n",
      "Validation loss: 1.362887978553772\n",
      "mse 1.3628878627550929\n",
      "New best model found at epoch 223 with validation loss 1.362887978553772\n",
      "Starting Epoch 224\n",
      "1.4094480574131012\n",
      "Validation loss: 1.3625738620758057\n",
      "mse 1.3625737353903746\n",
      "New best model found at epoch 224 with validation loss 1.3625738620758057\n",
      "Starting Epoch 225\n",
      "1.4090700124700863\n",
      "Validation loss: 1.3619780540466309\n",
      "mse 1.3619779980318882\n",
      "New best model found at epoch 225 with validation loss 1.3619780540466309\n",
      "Starting Epoch 226\n",
      "1.408632146815459\n",
      "Validation loss: 1.361951231956482\n",
      "mse 1.3619512499640365\n",
      "New best model found at epoch 226 with validation loss 1.361951231956482\n",
      "Starting Epoch 227\n",
      "1.4082561408480008\n",
      "Validation loss: 1.361651062965393\n",
      "mse 1.3616508245427943\n",
      "New best model found at epoch 227 with validation loss 1.361651062965393\n",
      "Starting Epoch 228\n",
      "1.4078864082694054\n",
      "Validation loss: 1.3611215353012085\n",
      "mse 1.3611215902485698\n",
      "New best model found at epoch 228 with validation loss 1.3611215353012085\n",
      "Starting Epoch 229\n",
      "1.4074761494994164\n",
      "Validation loss: 1.3610583543777466\n",
      "mse 1.361058297690774\n",
      "New best model found at epoch 229 with validation loss 1.3610583543777466\n",
      "Starting Epoch 230\n",
      "1.4070988123615582\n",
      "Validation loss: 1.3607629537582397\n",
      "mse 1.3607629257115041\n",
      "New best model found at epoch 230 with validation loss 1.3607629537582397\n",
      "Starting Epoch 231\n",
      "1.4067159444093704\n",
      "Validation loss: 1.3601939678192139\n",
      "mse 1.3601940392288723\n",
      "New best model found at epoch 231 with validation loss 1.3601939678192139\n",
      "Starting Epoch 232\n",
      "1.40629776318868\n",
      "Validation loss: 1.360131025314331\n",
      "mse 1.360131085455928\n",
      "New best model found at epoch 232 with validation loss 1.360131025314331\n",
      "Starting Epoch 233\n",
      "1.4059352998932202\n",
      "Validation loss: 1.3595879077911377\n",
      "mse 1.3595877623889714\n",
      "New best model found at epoch 233 with validation loss 1.3595879077911377\n",
      "Starting Epoch 234\n",
      "1.4055460790793102\n",
      "Validation loss: 1.3595832586288452\n",
      "mse 1.359583187259285\n",
      "New best model found at epoch 234 with validation loss 1.3595832586288452\n",
      "Starting Epoch 235\n",
      "1.4051660348971684\n",
      "Validation loss: 1.3592841625213623\n",
      "mse 1.3592841381196514\n",
      "New best model found at epoch 235 with validation loss 1.3592841625213623\n",
      "Starting Epoch 236\n",
      "1.4047901878754299\n",
      "Validation loss: 1.3587279319763184\n",
      "mse 1.3587278460198906\n",
      "New best model found at epoch 236 with validation loss 1.3587279319763184\n",
      "Starting Epoch 237\n",
      "1.404397318760554\n",
      "Validation loss: 1.3587039709091187\n",
      "mse 1.358703962279708\n",
      "New best model found at epoch 237 with validation loss 1.3587039709091187\n",
      "Starting Epoch 238\n",
      "1.4040482665101688\n",
      "Validation loss: 1.3581925630569458\n",
      "mse 1.3581925293168247\n",
      "New best model found at epoch 238 with validation loss 1.3581925630569458\n",
      "Starting Epoch 239\n",
      "1.4036964923143387\n",
      "Validation loss: 1.3581987619400024\n",
      "mse 1.3581988760869455\n",
      "Starting Epoch 240\n",
      "1.4033643652995427\n",
      "Validation loss: 1.3577136993408203\n",
      "mse 1.357713752604373\n",
      "New best model found at epoch 240 with validation loss 1.3577136993408203\n",
      "Starting Epoch 241\n",
      "1.4029549236098926\n",
      "Validation loss: 1.357464075088501\n",
      "mse 1.357464006317885\n",
      "New best model found at epoch 241 with validation loss 1.357464075088501\n",
      "Starting Epoch 242\n",
      "1.4025670761863391\n",
      "Validation loss: 1.357236623764038\n",
      "mse 1.3572366155389948\n",
      "New best model found at epoch 242 with validation loss 1.357236623764038\n",
      "Starting Epoch 243\n",
      "1.4022430181503296\n",
      "Validation loss: 1.3572312593460083\n",
      "mse 1.3572313004413152\n",
      "New best model found at epoch 243 with validation loss 1.3572312593460083\n",
      "Starting Epoch 244\n",
      "1.4018945718804996\n",
      "Validation loss: 1.3567196130752563\n",
      "mse 1.3567195721195555\n",
      "New best model found at epoch 244 with validation loss 1.3567196130752563\n",
      "Starting Epoch 245\n",
      "1.4015300100048382\n",
      "Validation loss: 1.3566765785217285\n",
      "mse 1.3566765455229712\n",
      "New best model found at epoch 245 with validation loss 1.3566765785217285\n",
      "Starting Epoch 246\n",
      "1.4011807839075725\n",
      "Validation loss: 1.3561910390853882\n",
      "mse 1.3561909841187738\n",
      "New best model found at epoch 246 with validation loss 1.3561910390853882\n",
      "Starting Epoch 247\n",
      "1.4008006925384204\n",
      "Validation loss: 1.355960726737976\n",
      "mse 1.3559608212471563\n",
      "New best model found at epoch 247 with validation loss 1.355960726737976\n",
      "Starting Epoch 248\n",
      "1.4004555369416873\n",
      "Validation loss: 1.3559623956680298\n",
      "mse 1.3559624968537776\n",
      "Starting Epoch 249\n",
      "1.4000995457172394\n",
      "Validation loss: 1.355402946472168\n",
      "mse 1.3554029042634086\n",
      "New best model found at epoch 249 with validation loss 1.355402946472168\n",
      "Starting Epoch 250\n",
      "1.3997395808498065\n",
      "Validation loss: 1.3553364276885986\n",
      "mse 1.35533651231832\n",
      "New best model found at epoch 250 with validation loss 1.3553364276885986\n",
      "Starting Epoch 251\n",
      "1.399383505185445\n",
      "Validation loss: 1.3548129796981812\n",
      "mse 1.3548131245196222\n",
      "New best model found at epoch 251 with validation loss 1.3548129796981812\n",
      "Starting Epoch 252\n",
      "1.3990334222714107\n",
      "Validation loss: 1.354754090309143\n",
      "mse 1.3547540466466144\n",
      "New best model found at epoch 252 with validation loss 1.354754090309143\n",
      "Starting Epoch 253\n",
      "1.398685907324155\n",
      "Validation loss: 1.3542240858078003\n",
      "mse 1.354224213329918\n",
      "New best model found at epoch 253 with validation loss 1.3542240858078003\n",
      "Starting Epoch 254\n",
      "1.3983230044444401\n",
      "Validation loss: 1.354166865348816\n",
      "mse 1.3541669710929467\n",
      "New best model found at epoch 254 with validation loss 1.354166865348816\n",
      "Starting Epoch 255\n",
      "1.3980054631829262\n",
      "Validation loss: 1.3536862134933472\n",
      "mse 1.3536862827949938\n",
      "New best model found at epoch 255 with validation loss 1.3536862134933472\n",
      "Starting Epoch 256\n",
      "1.397635204096635\n",
      "Validation loss: 1.3536510467529297\n",
      "mse 1.353651114048621\n",
      "New best model found at epoch 256 with validation loss 1.3536510467529297\n",
      "Starting Epoch 257\n",
      "1.3973094845811527\n",
      "Validation loss: 1.353163719177246\n",
      "mse 1.3531636925493606\n",
      "New best model found at epoch 257 with validation loss 1.353163719177246\n",
      "Starting Epoch 258\n",
      "1.3969727108875911\n",
      "Validation loss: 1.352817416191101\n",
      "mse 1.3528172165340544\n",
      "New best model found at epoch 258 with validation loss 1.352817416191101\n",
      "Starting Epoch 259\n",
      "1.396611864368121\n",
      "Validation loss: 1.3526135683059692\n",
      "mse 1.3526134849102809\n",
      "New best model found at epoch 259 with validation loss 1.3526135683059692\n",
      "Starting Epoch 260\n",
      "1.396295887728532\n",
      "Validation loss: 1.3525667190551758\n",
      "mse 1.352566695957832\n",
      "New best model found at epoch 260 with validation loss 1.3525667190551758\n",
      "Starting Epoch 261\n",
      "1.3959585825602214\n",
      "Validation loss: 1.3521097898483276\n",
      "mse 1.352109827320654\n",
      "New best model found at epoch 261 with validation loss 1.3521097898483276\n",
      "Starting Epoch 262\n",
      "1.3956282312671344\n",
      "Validation loss: 1.3517881631851196\n",
      "mse 1.3517882430772543\n",
      "New best model found at epoch 262 with validation loss 1.3517881631851196\n",
      "Starting Epoch 263\n",
      "1.395273360113303\n",
      "Validation loss: 1.3515836000442505\n",
      "mse 1.3515836221267417\n",
      "New best model found at epoch 263 with validation loss 1.3515836000442505\n",
      "Starting Epoch 264\n",
      "1.3949627702434857\n",
      "Validation loss: 1.3513113260269165\n",
      "mse 1.3513113773761016\n",
      "New best model found at epoch 264 with validation loss 1.3513113260269165\n",
      "Starting Epoch 265\n",
      "1.394620696703593\n",
      "Validation loss: 1.3512985706329346\n",
      "mse 1.3512986140638714\n",
      "New best model found at epoch 265 with validation loss 1.3512985706329346\n",
      "Starting Epoch 266\n",
      "1.3943222264448802\n",
      "Validation loss: 1.3508273363113403\n",
      "mse 1.350827341912978\n",
      "New best model found at epoch 266 with validation loss 1.3508273363113403\n",
      "Starting Epoch 267\n",
      "1.3939659496148427\n",
      "Validation loss: 1.3505606651306152\n",
      "mse 1.3505606492093374\n",
      "New best model found at epoch 267 with validation loss 1.3505606651306152\n",
      "Starting Epoch 268\n",
      "1.3936534176270168\n",
      "Validation loss: 1.350318431854248\n",
      "mse 1.3503183846581246\n",
      "New best model found at epoch 268 with validation loss 1.350318431854248\n",
      "Starting Epoch 269\n",
      "1.3933150817950566\n",
      "Validation loss: 1.35008704662323\n",
      "mse 1.3500870941701615\n",
      "New best model found at epoch 269 with validation loss 1.35008704662323\n",
      "Starting Epoch 270\n",
      "1.393017905453841\n",
      "Validation loss: 1.3500497341156006\n",
      "mse 1.3500496794914818\n",
      "New best model found at epoch 270 with validation loss 1.3500497341156006\n",
      "Starting Epoch 271\n",
      "1.392705224454403\n",
      "Validation loss: 1.3496036529541016\n",
      "mse 1.3496037276629207\n",
      "New best model found at epoch 271 with validation loss 1.3496036529541016\n",
      "Starting Epoch 272\n",
      "1.3923604488372803\n",
      "Validation loss: 1.3493231534957886\n",
      "mse 1.3493231383822233\n",
      "New best model found at epoch 272 with validation loss 1.3493231534957886\n",
      "Starting Epoch 273\n",
      "1.392057773967584\n",
      "Validation loss: 1.349317193031311\n",
      "mse 1.3493170852929004\n",
      "New best model found at epoch 273 with validation loss 1.349317193031311\n",
      "Starting Epoch 274\n",
      "1.3917352159818013\n",
      "Validation loss: 1.3489136695861816\n",
      "mse 1.3489136602844471\n",
      "New best model found at epoch 274 with validation loss 1.3489136695861816\n",
      "Starting Epoch 275\n",
      "1.3914282495776813\n",
      "Validation loss: 1.3486007452011108\n",
      "mse 1.3486005437741089\n",
      "New best model found at epoch 275 with validation loss 1.3486007452011108\n",
      "Starting Epoch 276\n",
      "1.391112153728803\n",
      "Validation loss: 1.3486032485961914\n",
      "mse 1.3486032574884907\n",
      "Starting Epoch 277\n",
      "1.3908146396279335\n",
      "Validation loss: 1.3481676578521729\n",
      "mse 1.3481678015711278\n",
      "New best model found at epoch 277 with validation loss 1.3481676578521729\n",
      "Starting Epoch 278\n",
      "1.3904758741458256\n",
      "Validation loss: 1.3479076623916626\n",
      "mse 1.3479076820496774\n",
      "New best model found at epoch 278 with validation loss 1.3479076623916626\n",
      "Starting Epoch 279\n",
      "1.390179343521595\n",
      "Validation loss: 1.3478939533233643\n",
      "mse 1.347893959437507\n",
      "New best model found at epoch 279 with validation loss 1.3478939533233643\n",
      "Starting Epoch 280\n",
      "1.3898866921663284\n",
      "Validation loss: 1.347463846206665\n",
      "mse 1.3474638939474206\n",
      "New best model found at epoch 280 with validation loss 1.347463846206665\n",
      "Starting Epoch 281\n",
      "1.3895509416858356\n",
      "Validation loss: 1.3472002744674683\n",
      "mse 1.3472003307773528\n",
      "New best model found at epoch 281 with validation loss 1.3472002744674683\n",
      "Starting Epoch 282\n",
      "1.3892577588558197\n",
      "Validation loss: 1.346928358078003\n",
      "mse 1.3469285387572278\n",
      "New best model found at epoch 282 with validation loss 1.346928358078003\n",
      "Starting Epoch 283\n",
      "1.3889484653870265\n",
      "Validation loss: 1.3467271327972412\n",
      "mse 1.346727088771487\n",
      "New best model found at epoch 283 with validation loss 1.3467271327972412\n",
      "Starting Epoch 284\n",
      "1.388646091024081\n",
      "Validation loss: 1.346736192703247\n",
      "mse 1.3467362042657212\n",
      "Starting Epoch 285\n",
      "1.3882965743541718\n",
      "Validation loss: 1.346449851989746\n",
      "mse 1.346449806902005\n",
      "New best model found at epoch 285 with validation loss 1.346449851989746\n",
      "Starting Epoch 286\n",
      "1.3879846433798473\n",
      "Validation loss: 1.3462189435958862\n",
      "mse 1.346218886358674\n",
      "New best model found at epoch 286 with validation loss 1.3462189435958862\n",
      "Starting Epoch 287\n",
      "1.3877046902974446\n",
      "Validation loss: 1.3459715843200684\n",
      "mse 1.34597151664304\n",
      "New best model found at epoch 287 with validation loss 1.3459715843200684\n",
      "Starting Epoch 288\n",
      "1.3873540585239728\n",
      "Validation loss: 1.345786213874817\n",
      "mse 1.3457862541352672\n",
      "New best model found at epoch 288 with validation loss 1.345786213874817\n",
      "Starting Epoch 289\n",
      "1.387056365609169\n",
      "Validation loss: 1.3455792665481567\n",
      "mse 1.345579282385334\n",
      "New best model found at epoch 289 with validation loss 1.3455792665481567\n",
      "Starting Epoch 290\n",
      "1.386834795276324\n",
      "Validation loss: 1.3451942205429077\n",
      "mse 1.3451942146424327\n",
      "New best model found at epoch 290 with validation loss 1.3451942205429077\n",
      "Starting Epoch 291\n",
      "1.3864970977107685\n",
      "Validation loss: 1.3450888395309448\n",
      "mse 1.3450888110408095\n",
      "New best model found at epoch 291 with validation loss 1.3450888395309448\n",
      "Starting Epoch 292\n",
      "1.3862038503090541\n",
      "Validation loss: 1.3449147939682007\n",
      "mse 1.34491479476528\n",
      "New best model found at epoch 292 with validation loss 1.3449147939682007\n",
      "Starting Epoch 293\n",
      "1.3859446470936139\n",
      "Validation loss: 1.344637155532837\n",
      "mse 1.3446371472519842\n",
      "New best model found at epoch 293 with validation loss 1.344637155532837\n",
      "Starting Epoch 294\n",
      "1.385651782155037\n",
      "Validation loss: 1.3444201946258545\n",
      "mse 1.344420160462228\n",
      "New best model found at epoch 294 with validation loss 1.3444201946258545\n",
      "Starting Epoch 295\n",
      "1.3853845298290253\n",
      "Validation loss: 1.3441953659057617\n",
      "mse 1.3441953578897834\n",
      "New best model found at epoch 295 with validation loss 1.3441953659057617\n",
      "Starting Epoch 296\n",
      "1.3851065387328465\n",
      "Validation loss: 1.3439141511917114\n",
      "mse 1.3439141186113746\n",
      "New best model found at epoch 296 with validation loss 1.3439141511917114\n",
      "Starting Epoch 297\n",
      "1.3848161101341248\n",
      "Validation loss: 1.3437082767486572\n",
      "mse 1.3437082509498575\n",
      "New best model found at epoch 297 with validation loss 1.3437082767486572\n",
      "Starting Epoch 298\n",
      "1.3845668509602547\n",
      "Validation loss: 1.3434466123580933\n",
      "mse 1.3434465616942661\n",
      "New best model found at epoch 298 with validation loss 1.3434466123580933\n",
      "Starting Epoch 299\n",
      "1.3842894037564595\n",
      "Validation loss: 1.3432525396347046\n",
      "mse 1.3432525619971636\n",
      "New best model found at epoch 299 with validation loss 1.3432525396347046\n",
      "Starting Epoch 300\n",
      "1.384030448893706\n",
      "Validation loss: 1.343066692352295\n",
      "mse 1.3430667219593604\n",
      "New best model found at epoch 300 with validation loss 1.343066692352295\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-25-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65049334",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 5\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 40 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "1ef1b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ebefd968-738d-4bba-a2b9-fcda275aa43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.7176657915115356\n",
      "Validation loss: 2.3429489135742188\n",
      "mse 2.3429488016682107\n",
      "New best model found at epoch 1 with validation loss 2.3429489135742188\n",
      "Starting Epoch 2\n",
      "2.2514345794916153\n",
      "Validation loss: 2.205026865005493\n",
      "mse 2.2050270487698342\n",
      "New best model found at epoch 2 with validation loss 2.205026865005493\n",
      "Starting Epoch 3\n",
      "2.16513292491436\n",
      "Validation loss: 2.1198084354400635\n",
      "mse 2.1198084265823565\n",
      "New best model found at epoch 3 with validation loss 2.1198084354400635\n",
      "Starting Epoch 4\n",
      "2.098970671494802\n",
      "Validation loss: 2.049424409866333\n",
      "mse 2.0494241903944297\n",
      "New best model found at epoch 4 with validation loss 2.049424409866333\n",
      "Starting Epoch 5\n",
      "2.0446797410647073\n",
      "Validation loss: 1.9886611700057983\n",
      "mse 1.9886612439477844\n",
      "New best model found at epoch 5 with validation loss 1.9886611700057983\n",
      "Starting Epoch 6\n",
      "1.9998067965110142\n",
      "Validation loss: 1.9394831657409668\n",
      "mse 1.9394832582809522\n",
      "New best model found at epoch 6 with validation loss 1.9394831657409668\n",
      "Starting Epoch 7\n",
      "1.9626565873622894\n",
      "Validation loss: 1.8982808589935303\n",
      "mse 1.8982807501843157\n",
      "New best model found at epoch 7 with validation loss 1.8982808589935303\n",
      "Starting Epoch 8\n",
      "1.9299048334360123\n",
      "Validation loss: 1.8616312742233276\n",
      "mse 1.8616312583279329\n",
      "New best model found at epoch 8 with validation loss 1.8616312742233276\n",
      "Starting Epoch 9\n",
      "1.9005543043216069\n",
      "Validation loss: 1.8308457136154175\n",
      "mse 1.8308458593304697\n",
      "New best model found at epoch 9 with validation loss 1.8308457136154175\n",
      "Starting Epoch 10\n",
      "1.8754806170860927\n",
      "Validation loss: 1.8037928342819214\n",
      "mse 1.803792855551038\n",
      "New best model found at epoch 10 with validation loss 1.8037928342819214\n",
      "Starting Epoch 11\n",
      "1.8532725622256596\n",
      "Validation loss: 1.7796480655670166\n",
      "mse 1.7796480425587629\n",
      "New best model found at epoch 11 with validation loss 1.7796480655670166\n",
      "Starting Epoch 12\n",
      "1.83323239783446\n",
      "Validation loss: 1.7578543424606323\n",
      "mse 1.7578543996036637\n",
      "New best model found at epoch 12 with validation loss 1.7578543424606323\n",
      "Starting Epoch 13\n",
      "1.815276136000951\n",
      "Validation loss: 1.738629937171936\n",
      "mse 1.7386299383554007\n",
      "New best model found at epoch 13 with validation loss 1.738629937171936\n",
      "Starting Epoch 14\n",
      "1.7989377578099568\n",
      "Validation loss: 1.7214430570602417\n",
      "mse 1.7214430262541227\n",
      "New best model found at epoch 14 with validation loss 1.7214430570602417\n",
      "Starting Epoch 15\n",
      "1.7840371280908585\n",
      "Validation loss: 1.705837368965149\n",
      "mse 1.7058372740903358\n",
      "New best model found at epoch 15 with validation loss 1.705837368965149\n",
      "Starting Epoch 16\n",
      "1.7704015026489894\n",
      "Validation loss: 1.6915526390075684\n",
      "mse 1.6915526679105035\n",
      "New best model found at epoch 16 with validation loss 1.6915526390075684\n",
      "Starting Epoch 17\n",
      "1.7577323218186696\n",
      "Validation loss: 1.678574800491333\n",
      "mse 1.67857488852029\n",
      "New best model found at epoch 17 with validation loss 1.678574800491333\n",
      "Starting Epoch 18\n",
      "1.746016189455986\n",
      "Validation loss: 1.6667155027389526\n",
      "mse 1.666715569942091\n",
      "New best model found at epoch 18 with validation loss 1.6667155027389526\n",
      "Starting Epoch 19\n",
      "1.7352346430222194\n",
      "Validation loss: 1.6551839113235474\n",
      "mse 1.6551836691922688\n",
      "New best model found at epoch 19 with validation loss 1.6551839113235474\n",
      "Starting Epoch 20\n",
      "1.725203037261963\n",
      "Validation loss: 1.64475679397583\n",
      "mse 1.644756892129485\n",
      "New best model found at epoch 20 with validation loss 1.64475679397583\n",
      "Starting Epoch 21\n",
      "1.7158770660559337\n",
      "Validation loss: 1.6353598833084106\n",
      "mse 1.6353598898557442\n",
      "New best model found at epoch 21 with validation loss 1.6353598833084106\n",
      "Starting Epoch 22\n",
      "1.707022135456403\n",
      "Validation loss: 1.6262307167053223\n",
      "mse 1.626230671409053\n",
      "New best model found at epoch 22 with validation loss 1.6262307167053223\n",
      "Starting Epoch 23\n",
      "1.6985207597414653\n",
      "Validation loss: 1.618097186088562\n",
      "mse 1.6180972384470174\n",
      "New best model found at epoch 23 with validation loss 1.618097186088562\n",
      "Starting Epoch 24\n",
      "1.690743053952853\n",
      "Validation loss: 1.61063551902771\n",
      "mse 1.61063569270792\n",
      "New best model found at epoch 24 with validation loss 1.61063551902771\n",
      "Starting Epoch 25\n",
      "1.6834029654661815\n",
      "Validation loss: 1.603479027748108\n",
      "mse 1.6034790415479292\n",
      "New best model found at epoch 25 with validation loss 1.603479027748108\n",
      "Starting Epoch 26\n",
      "1.6764857470989227\n",
      "Validation loss: 1.5968284606933594\n",
      "mse 1.596828388348197\n",
      "New best model found at epoch 26 with validation loss 1.5968284606933594\n",
      "Starting Epoch 27\n",
      "1.6699596047401428\n",
      "Validation loss: 1.5909686088562012\n",
      "mse 1.5909685532415758\n",
      "New best model found at epoch 27 with validation loss 1.5909686088562012\n",
      "Starting Epoch 28\n",
      "1.663720816373825\n",
      "Validation loss: 1.5847867727279663\n",
      "mse 1.5847867939355083\n",
      "New best model found at epoch 28 with validation loss 1.5847867727279663\n",
      "Starting Epoch 29\n",
      "1.6577451874812443\n",
      "Validation loss: 1.5793328285217285\n",
      "mse 1.5793327412179297\n",
      "New best model found at epoch 29 with validation loss 1.5793328285217285\n",
      "Starting Epoch 30\n",
      "1.6521358042955399\n",
      "Validation loss: 1.5742082595825195\n",
      "mse 1.5742082609034493\n",
      "New best model found at epoch 30 with validation loss 1.5742082595825195\n",
      "Starting Epoch 31\n",
      "1.6467239558696747\n",
      "Validation loss: 1.5692778825759888\n",
      "mse 1.5692779096679768\n",
      "New best model found at epoch 31 with validation loss 1.5692778825759888\n",
      "Starting Epoch 32\n",
      "1.6415328184763591\n",
      "Validation loss: 1.5646504163742065\n",
      "mse 1.5646504405606576\n",
      "New best model found at epoch 32 with validation loss 1.5646504163742065\n",
      "Starting Epoch 33\n",
      "1.636529117822647\n",
      "Validation loss: 1.5600175857543945\n",
      "mse 1.5600176382411277\n",
      "New best model found at epoch 33 with validation loss 1.5600175857543945\n",
      "Starting Epoch 34\n",
      "1.6316825201114018\n",
      "Validation loss: 1.5556639432907104\n",
      "mse 1.5556639023741077\n",
      "New best model found at epoch 34 with validation loss 1.5556639432907104\n",
      "Starting Epoch 35\n",
      "1.627072845896085\n",
      "Validation loss: 1.5517234802246094\n",
      "mse 1.551723519027842\n",
      "New best model found at epoch 35 with validation loss 1.5517234802246094\n",
      "Starting Epoch 36\n",
      "1.6225452274084091\n",
      "Validation loss: 1.5480538606643677\n",
      "mse 1.5480538487041864\n",
      "New best model found at epoch 36 with validation loss 1.5480538606643677\n",
      "Starting Epoch 37\n",
      "1.6183407008647919\n",
      "Validation loss: 1.5443459749221802\n",
      "mse 1.5443460539113887\n",
      "New best model found at epoch 37 with validation loss 1.5443459749221802\n",
      "Starting Epoch 38\n",
      "1.6141465157270432\n",
      "Validation loss: 1.5412925481796265\n",
      "mse 1.541292743161138\n",
      "New best model found at epoch 38 with validation loss 1.5412925481796265\n",
      "Starting Epoch 39\n",
      "1.6103105197350185\n",
      "Validation loss: 1.5377506017684937\n",
      "mse 1.5377504732444858\n",
      "New best model found at epoch 39 with validation loss 1.5377506017684937\n",
      "Starting Epoch 40\n",
      "1.606431211034457\n",
      "Validation loss: 1.5341821908950806\n",
      "mse 1.5341821108295288\n",
      "New best model found at epoch 40 with validation loss 1.5341821908950806\n",
      "Starting Epoch 41\n",
      "1.60282597442468\n",
      "Validation loss: 1.5317111015319824\n",
      "mse 1.5317110264799596\n",
      "New best model found at epoch 41 with validation loss 1.5317111015319824\n",
      "Starting Epoch 42\n",
      "1.599319413304329\n",
      "Validation loss: 1.528515338897705\n",
      "mse 1.5285153123696575\n",
      "New best model found at epoch 42 with validation loss 1.528515338897705\n",
      "Starting Epoch 43\n",
      "1.5958839505910873\n",
      "Validation loss: 1.5256274938583374\n",
      "mse 1.5256274368068987\n",
      "New best model found at epoch 43 with validation loss 1.5256274938583374\n",
      "Starting Epoch 44\n",
      "1.59263480703036\n",
      "Validation loss: 1.5224096775054932\n",
      "mse 1.5224096972736263\n",
      "New best model found at epoch 44 with validation loss 1.5224096775054932\n",
      "Starting Epoch 45\n",
      "1.5893810788790386\n",
      "Validation loss: 1.5201144218444824\n",
      "mse 1.5201144546695051\n",
      "New best model found at epoch 45 with validation loss 1.5201144218444824\n",
      "Starting Epoch 46\n",
      "1.5863399902979534\n",
      "Validation loss: 1.5173170566558838\n",
      "mse 1.5173170215240421\n",
      "New best model found at epoch 46 with validation loss 1.5173170566558838\n",
      "Starting Epoch 47\n",
      "1.5833830833435059\n",
      "Validation loss: 1.5146329402923584\n",
      "mse 1.5146327999258233\n",
      "New best model found at epoch 47 with validation loss 1.5146329402923584\n",
      "Starting Epoch 48\n",
      "1.5804391006628673\n",
      "Validation loss: 1.5124822854995728\n",
      "mse 1.5124824211901597\n",
      "New best model found at epoch 48 with validation loss 1.5124822854995728\n",
      "Starting Epoch 49\n",
      "1.5776383131742477\n",
      "Validation loss: 1.508881688117981\n",
      "mse 1.5088817230400053\n",
      "New best model found at epoch 49 with validation loss 1.508881688117981\n",
      "Starting Epoch 50\n",
      "1.574833075205485\n",
      "Validation loss: 1.5064146518707275\n",
      "mse 1.5064146053082546\n",
      "New best model found at epoch 50 with validation loss 1.5064146518707275\n",
      "Starting Epoch 51\n",
      "1.572205772002538\n",
      "Validation loss: 1.5047471523284912\n",
      "mse 1.50474731632225\n",
      "New best model found at epoch 51 with validation loss 1.5047471523284912\n",
      "Starting Epoch 52\n",
      "1.5696169187625248\n",
      "Validation loss: 1.502615213394165\n",
      "mse 1.5026153032489415\n",
      "New best model found at epoch 52 with validation loss 1.502615213394165\n",
      "Starting Epoch 53\n",
      "1.5670277277628581\n",
      "Validation loss: 1.5001384019851685\n",
      "mse 1.5001384133784434\n",
      "New best model found at epoch 53 with validation loss 1.5001384019851685\n",
      "Starting Epoch 54\n",
      "1.5645179897546768\n",
      "Validation loss: 1.4980591535568237\n",
      "mse 1.4980591028522472\n",
      "New best model found at epoch 54 with validation loss 1.4980591535568237\n",
      "Starting Epoch 55\n",
      "1.562115266919136\n",
      "Validation loss: 1.4959501028060913\n",
      "mse 1.4959500740029419\n",
      "New best model found at epoch 55 with validation loss 1.4959501028060913\n",
      "Starting Epoch 56\n",
      "1.5597615887721379\n",
      "Validation loss: 1.4937753677368164\n",
      "mse 1.493775392122568\n",
      "New best model found at epoch 56 with validation loss 1.4937753677368164\n",
      "Starting Epoch 57\n",
      "1.5574369380871456\n",
      "Validation loss: 1.4920132160186768\n",
      "mse 1.492013309660131\n",
      "New best model found at epoch 57 with validation loss 1.4920132160186768\n",
      "Starting Epoch 58\n",
      "1.5552333096663158\n",
      "Validation loss: 1.48993718624115\n",
      "mse 1.4899374595643105\n",
      "New best model found at epoch 58 with validation loss 1.48993718624115\n",
      "Starting Epoch 59\n",
      "1.553034355243047\n",
      "Validation loss: 1.4881837368011475\n",
      "mse 1.4881837623218166\n",
      "New best model found at epoch 59 with validation loss 1.4881837368011475\n",
      "Starting Epoch 60\n",
      "1.5509041597445805\n",
      "Validation loss: 1.4861760139465332\n",
      "mse 1.4861760839628064\n",
      "New best model found at epoch 60 with validation loss 1.4861760139465332\n",
      "Starting Epoch 61\n",
      "1.548756405711174\n",
      "Validation loss: 1.4847309589385986\n",
      "mse 1.4847311145811997\n",
      "New best model found at epoch 61 with validation loss 1.4847309589385986\n",
      "Starting Epoch 62\n",
      "1.5467734634876251\n",
      "Validation loss: 1.4830904006958008\n",
      "mse 1.4830903609931416\n",
      "New best model found at epoch 62 with validation loss 1.4830904006958008\n",
      "Starting Epoch 63\n",
      "1.5447754512230556\n",
      "Validation loss: 1.4808107614517212\n",
      "mse 1.4808108011765482\n",
      "New best model found at epoch 63 with validation loss 1.4808107614517212\n",
      "Starting Epoch 64\n",
      "1.5428152481714885\n",
      "Validation loss: 1.4793862104415894\n",
      "mse 1.4793860932070693\n",
      "New best model found at epoch 64 with validation loss 1.4793862104415894\n",
      "Starting Epoch 65\n",
      "1.5409661928812664\n",
      "Validation loss: 1.4781737327575684\n",
      "mse 1.4781738143614742\n",
      "New best model found at epoch 65 with validation loss 1.4781737327575684\n",
      "Starting Epoch 66\n",
      "1.539168154199918\n",
      "Validation loss: 1.47673499584198\n",
      "mse 1.476734877240456\n",
      "New best model found at epoch 66 with validation loss 1.47673499584198\n",
      "Starting Epoch 67\n",
      "1.5373754103978474\n",
      "Validation loss: 1.4753745794296265\n",
      "mse 1.4753745431393182\n",
      "New best model found at epoch 67 with validation loss 1.4753745794296265\n",
      "Starting Epoch 68\n",
      "1.5356257061163585\n",
      "Validation loss: 1.4739221334457397\n",
      "mse 1.473922248305515\n",
      "New best model found at epoch 68 with validation loss 1.4739221334457397\n",
      "Starting Epoch 69\n",
      "1.5339499364296596\n",
      "Validation loss: 1.4725236892700195\n",
      "mse 1.4725236994214086\n",
      "New best model found at epoch 69 with validation loss 1.4725236892700195\n",
      "Starting Epoch 70\n",
      "1.5322501411040623\n",
      "Validation loss: 1.4713118076324463\n",
      "mse 1.4713119209417216\n",
      "New best model found at epoch 70 with validation loss 1.4713118076324463\n",
      "Starting Epoch 71\n",
      "1.5305921485026677\n",
      "Validation loss: 1.4698123931884766\n",
      "mse 1.4698123851701477\n",
      "New best model found at epoch 71 with validation loss 1.4698123931884766\n",
      "Starting Epoch 72\n",
      "1.5290176222721736\n",
      "Validation loss: 1.4686594009399414\n",
      "mse 1.4686594326051279\n",
      "New best model found at epoch 72 with validation loss 1.4686594009399414\n",
      "Starting Epoch 73\n",
      "1.5274001409610112\n",
      "Validation loss: 1.4668583869934082\n",
      "mse 1.4668585455680998\n",
      "New best model found at epoch 73 with validation loss 1.4668583869934082\n",
      "Starting Epoch 74\n",
      "1.5258514980475109\n",
      "Validation loss: 1.4660917520523071\n",
      "mse 1.466091715364816\n",
      "New best model found at epoch 74 with validation loss 1.4660917520523071\n",
      "Starting Epoch 75\n",
      "1.5243326773246129\n",
      "Validation loss: 1.4644004106521606\n",
      "mse 1.4644004663891612\n",
      "New best model found at epoch 75 with validation loss 1.4644004106521606\n",
      "Starting Epoch 76\n",
      "1.522843360900879\n",
      "Validation loss: 1.4637209177017212\n",
      "mse 1.4637210000432663\n",
      "New best model found at epoch 76 with validation loss 1.4637209177017212\n",
      "Starting Epoch 77\n",
      "1.5213654239972432\n",
      "Validation loss: 1.4622673988342285\n",
      "mse 1.4622673642973372\n",
      "New best model found at epoch 77 with validation loss 1.4622673988342285\n",
      "Starting Epoch 78\n",
      "1.5199263195196788\n",
      "Validation loss: 1.4613239765167236\n",
      "mse 1.461323988583423\n",
      "New best model found at epoch 78 with validation loss 1.4613239765167236\n",
      "Starting Epoch 79\n",
      "1.518489400545756\n",
      "Validation loss: 1.4604018926620483\n",
      "mse 1.4604018921495943\n",
      "New best model found at epoch 79 with validation loss 1.4604018926620483\n",
      "Starting Epoch 80\n",
      "1.517145613829295\n",
      "Validation loss: 1.458774447441101\n",
      "mse 1.458774473999272\n",
      "New best model found at epoch 80 with validation loss 1.458774447441101\n",
      "Starting Epoch 81\n",
      "1.5157410303751628\n",
      "Validation loss: 1.4576361179351807\n",
      "mse 1.4576361481508384\n",
      "New best model found at epoch 81 with validation loss 1.4576361179351807\n",
      "Starting Epoch 82\n",
      "1.5144182642300923\n",
      "Validation loss: 1.457120418548584\n",
      "mse 1.4571204339861756\n",
      "New best model found at epoch 82 with validation loss 1.457120418548584\n",
      "Starting Epoch 83\n",
      "1.513073871533076\n",
      "Validation loss: 1.455506443977356\n",
      "mse 1.455506455576688\n",
      "New best model found at epoch 83 with validation loss 1.455506443977356\n",
      "Starting Epoch 84\n",
      "1.511760875582695\n",
      "Validation loss: 1.4552738666534424\n",
      "mse 1.4552739814593598\n",
      "New best model found at epoch 84 with validation loss 1.4552738666534424\n",
      "Starting Epoch 85\n",
      "1.510511224468549\n",
      "Validation loss: 1.4537253379821777\n",
      "mse 1.453725432446958\n",
      "New best model found at epoch 85 with validation loss 1.4537253379821777\n",
      "Starting Epoch 86\n",
      "1.5091934005419414\n",
      "Validation loss: 1.4527820348739624\n",
      "mse 1.4527819436534535\n",
      "New best model found at epoch 86 with validation loss 1.4527820348739624\n",
      "Starting Epoch 87\n",
      "1.5079549302657445\n",
      "Validation loss: 1.4518259763717651\n",
      "mse 1.4518261012707432\n",
      "New best model found at epoch 87 with validation loss 1.4518259763717651\n",
      "Starting Epoch 88\n",
      "1.5067358911037445\n",
      "Validation loss: 1.451137900352478\n",
      "mse 1.4511379148058086\n",
      "New best model found at epoch 88 with validation loss 1.451137900352478\n",
      "Starting Epoch 89\n",
      "1.5055076132218044\n",
      "Validation loss: 1.449842095375061\n",
      "mse 1.4498421374269221\n",
      "New best model found at epoch 89 with validation loss 1.449842095375061\n",
      "Starting Epoch 90\n",
      "1.5043171147505443\n",
      "Validation loss: 1.4492590427398682\n",
      "mse 1.4492589963839195\n",
      "New best model found at epoch 90 with validation loss 1.4492590427398682\n",
      "Starting Epoch 91\n",
      "1.5031053771575291\n",
      "Validation loss: 1.4479478597640991\n",
      "mse 1.4479480114944034\n",
      "New best model found at epoch 91 with validation loss 1.4479478597640991\n",
      "Starting Epoch 92\n",
      "1.501939634482066\n",
      "Validation loss: 1.4470618963241577\n",
      "mse 1.4470618641649753\n",
      "New best model found at epoch 92 with validation loss 1.4470618963241577\n",
      "Starting Epoch 93\n",
      "1.500800982117653\n",
      "Validation loss: 1.4465656280517578\n",
      "mse 1.446565630389238\n",
      "New best model found at epoch 93 with validation loss 1.4465656280517578\n",
      "Starting Epoch 94\n",
      "1.4996869067351024\n",
      "Validation loss: 1.4451912641525269\n",
      "mse 1.445191365986876\n",
      "New best model found at epoch 94 with validation loss 1.4451912641525269\n",
      "Starting Epoch 95\n",
      "1.4985488057136536\n",
      "Validation loss: 1.4447212219238281\n",
      "mse 1.4447211828290296\n",
      "New best model found at epoch 95 with validation loss 1.4447212219238281\n",
      "Starting Epoch 96\n",
      "1.4974207232395809\n",
      "Validation loss: 1.4434620141983032\n",
      "mse 1.4434621234640312\n",
      "New best model found at epoch 96 with validation loss 1.4434620141983032\n",
      "Starting Epoch 97\n",
      "1.4963068217039108\n",
      "Validation loss: 1.4429656267166138\n",
      "mse 1.4429656650777796\n",
      "New best model found at epoch 97 with validation loss 1.4429656267166138\n",
      "Starting Epoch 98\n",
      "1.4952216297388077\n",
      "Validation loss: 1.4416180849075317\n",
      "mse 1.4416182137850029\n",
      "New best model found at epoch 98 with validation loss 1.4416180849075317\n",
      "Starting Epoch 99\n",
      "1.4941097249587376\n",
      "Validation loss: 1.440804123878479\n",
      "mse 1.4408041227817519\n",
      "New best model found at epoch 99 with validation loss 1.440804123878479\n",
      "Starting Epoch 100\n",
      "1.4930408547321956\n",
      "Validation loss: 1.4402011632919312\n",
      "mse 1.440201061194727\n",
      "New best model found at epoch 100 with validation loss 1.4402011632919312\n",
      "Starting Epoch 101\n",
      "1.4919767330090206\n",
      "Validation loss: 1.4393137693405151\n",
      "mse 1.4393138383291648\n",
      "New best model found at epoch 101 with validation loss 1.4393137693405151\n",
      "Starting Epoch 102\n",
      "1.4909273236989975\n",
      "Validation loss: 1.4380757808685303\n",
      "mse 1.4380757544375415\n",
      "New best model found at epoch 102 with validation loss 1.4380757808685303\n",
      "Starting Epoch 103\n",
      "1.4898866017659504\n",
      "Validation loss: 1.4375990629196167\n",
      "mse 1.437599078716454\n",
      "New best model found at epoch 103 with validation loss 1.4375990629196167\n",
      "Starting Epoch 104\n",
      "1.48873304327329\n",
      "Validation loss: 1.436665654182434\n",
      "mse 1.4366656327516631\n",
      "New best model found at epoch 104 with validation loss 1.436665654182434\n",
      "Starting Epoch 105\n",
      "1.4877172162135441\n",
      "Validation loss: 1.4358441829681396\n",
      "mse 1.4358442767722708\n",
      "New best model found at epoch 105 with validation loss 1.4358441829681396\n",
      "Starting Epoch 106\n",
      "1.4867110401391983\n",
      "Validation loss: 1.4350506067276\n",
      "mse 1.4350505713102237\n",
      "New best model found at epoch 106 with validation loss 1.4350506067276\n",
      "Starting Epoch 107\n",
      "1.4857433537642162\n",
      "Validation loss: 1.434267520904541\n",
      "mse 1.4342674633188939\n",
      "New best model found at epoch 107 with validation loss 1.434267520904541\n",
      "Starting Epoch 108\n",
      "1.4847659071286519\n",
      "Validation loss: 1.4334659576416016\n",
      "mse 1.433465900319624\n",
      "New best model found at epoch 108 with validation loss 1.4334659576416016\n",
      "Starting Epoch 109\n",
      "1.4838473250468571\n",
      "Validation loss: 1.4326386451721191\n",
      "mse 1.432638747466059\n",
      "New best model found at epoch 109 with validation loss 1.4326386451721191\n",
      "Starting Epoch 110\n",
      "1.482926607131958\n",
      "Validation loss: 1.4319405555725098\n",
      "mse 1.4319405893745814\n",
      "New best model found at epoch 110 with validation loss 1.4319405555725098\n",
      "Starting Epoch 111\n",
      "1.481914833188057\n",
      "Validation loss: 1.431316614151001\n",
      "mse 1.4313165185276482\n",
      "New best model found at epoch 111 with validation loss 1.431316614151001\n",
      "Starting Epoch 112\n",
      "1.4810345818599064\n",
      "Validation loss: 1.4306179285049438\n",
      "mse 1.4306179627590685\n",
      "New best model found at epoch 112 with validation loss 1.4306179285049438\n",
      "Starting Epoch 113\n",
      "1.4801515340805054\n",
      "Validation loss: 1.4299427270889282\n",
      "mse 1.4299428900433682\n",
      "New best model found at epoch 113 with validation loss 1.4299427270889282\n",
      "Starting Epoch 114\n",
      "1.4792662312587102\n",
      "Validation loss: 1.4291760921478271\n",
      "mse 1.429176039908227\n",
      "New best model found at epoch 114 with validation loss 1.4291760921478271\n",
      "Starting Epoch 115\n",
      "1.4783603847026825\n",
      "Validation loss: 1.4283770322799683\n",
      "mse 1.4283768516492545\n",
      "New best model found at epoch 115 with validation loss 1.4283770322799683\n",
      "Starting Epoch 116\n",
      "1.4774453242619832\n",
      "Validation loss: 1.427734613418579\n",
      "mse 1.427734668542607\n",
      "New best model found at epoch 116 with validation loss 1.427734613418579\n",
      "Starting Epoch 117\n",
      "1.4765664388736088\n",
      "Validation loss: 1.4270477294921875\n",
      "mse 1.4270477046340606\n",
      "New best model found at epoch 117 with validation loss 1.4270477294921875\n",
      "Starting Epoch 118\n",
      "1.475687379638354\n",
      "Validation loss: 1.426210880279541\n",
      "mse 1.4262108943734275\n",
      "New best model found at epoch 118 with validation loss 1.426210880279541\n",
      "Starting Epoch 119\n",
      "1.4748430500427883\n",
      "Validation loss: 1.4257007837295532\n",
      "mse 1.4257007973232227\n",
      "New best model found at epoch 119 with validation loss 1.4257007837295532\n",
      "Starting Epoch 120\n",
      "1.473743995030721\n",
      "Validation loss: 1.4247957468032837\n",
      "mse 1.4247956638196233\n",
      "New best model found at epoch 120 with validation loss 1.4247957468032837\n",
      "Starting Epoch 121\n",
      "1.472193494439125\n",
      "Validation loss: 1.4235042333602905\n",
      "mse 1.4235041258343466\n",
      "New best model found at epoch 121 with validation loss 1.4235042333602905\n",
      "Starting Epoch 122\n",
      "1.4696741650501888\n",
      "Validation loss: 1.422041893005371\n",
      "mse 1.4220418642646906\n",
      "New best model found at epoch 122 with validation loss 1.422041893005371\n",
      "Starting Epoch 123\n",
      "1.466894323627154\n",
      "Validation loss: 1.420581579208374\n",
      "mse 1.4205816090077037\n",
      "New best model found at epoch 123 with validation loss 1.420581579208374\n",
      "Starting Epoch 124\n",
      "1.4644235173861186\n",
      "Validation loss: 1.419339656829834\n",
      "mse 1.4193397306334146\n",
      "New best model found at epoch 124 with validation loss 1.419339656829834\n",
      "Starting Epoch 125\n",
      "1.462453732887904\n",
      "Validation loss: 1.4184590578079224\n",
      "mse 1.4184589771214815\n",
      "New best model found at epoch 125 with validation loss 1.4184590578079224\n",
      "Starting Epoch 126\n",
      "1.460515687863032\n",
      "Validation loss: 1.4174494743347168\n",
      "mse 1.4174494378633102\n",
      "New best model found at epoch 126 with validation loss 1.4174494743347168\n",
      "Starting Epoch 127\n",
      "1.458439017335574\n",
      "Validation loss: 1.4166020154953003\n",
      "mse 1.4166019716953486\n",
      "New best model found at epoch 127 with validation loss 1.4166020154953003\n",
      "Starting Epoch 128\n",
      "1.4571454549829166\n",
      "Validation loss: 1.4158748388290405\n",
      "mse 1.415874930469048\n",
      "New best model found at epoch 128 with validation loss 1.4158748388290405\n",
      "Starting Epoch 129\n",
      "1.4562028075257938\n",
      "Validation loss: 1.4150867462158203\n",
      "mse 1.4150866781401679\n",
      "New best model found at epoch 129 with validation loss 1.4150867462158203\n",
      "Starting Epoch 130\n",
      "1.4553566028674443\n",
      "Validation loss: 1.414421558380127\n",
      "mse 1.4144215315564734\n",
      "New best model found at epoch 130 with validation loss 1.414421558380127\n",
      "Starting Epoch 131\n",
      "1.4545001635948818\n",
      "Validation loss: 1.4137548208236694\n",
      "mse 1.4137548294321298\n",
      "New best model found at epoch 131 with validation loss 1.4137548208236694\n",
      "Starting Epoch 132\n",
      "1.4536440993348758\n",
      "Validation loss: 1.4129494428634644\n",
      "mse 1.4129495676756922\n",
      "New best model found at epoch 132 with validation loss 1.4129494428634644\n",
      "Starting Epoch 133\n",
      "1.4528286804755528\n",
      "Validation loss: 1.4124056100845337\n",
      "mse 1.4124055931795787\n",
      "New best model found at epoch 133 with validation loss 1.4124056100845337\n",
      "Starting Epoch 134\n",
      "1.4520432005325954\n",
      "Validation loss: 1.4115315675735474\n",
      "mse 1.4115315030413829\n",
      "New best model found at epoch 134 with validation loss 1.4115315675735474\n",
      "Starting Epoch 135\n",
      "1.4512255986531575\n",
      "Validation loss: 1.411082148551941\n",
      "mse 1.4110823637401306\n",
      "New best model found at epoch 135 with validation loss 1.411082148551941\n",
      "Starting Epoch 136\n",
      "1.4504623611768086\n",
      "Validation loss: 1.4103602170944214\n",
      "mse 1.410360248150476\n",
      "New best model found at epoch 136 with validation loss 1.4103602170944214\n",
      "Starting Epoch 137\n",
      "1.4496616050601006\n",
      "Validation loss: 1.4096148014068604\n",
      "mse 1.409614652871601\n",
      "New best model found at epoch 137 with validation loss 1.4096148014068604\n",
      "Starting Epoch 138\n",
      "1.448909727235635\n",
      "Validation loss: 1.40911865234375\n",
      "mse 1.4091186785486223\n",
      "New best model found at epoch 138 with validation loss 1.40911865234375\n",
      "Starting Epoch 139\n",
      "1.4481468349695206\n",
      "Validation loss: 1.4085131883621216\n",
      "mse 1.408513145844618\n",
      "New best model found at epoch 139 with validation loss 1.4085131883621216\n",
      "Starting Epoch 140\n",
      "1.4473815883199375\n",
      "Validation loss: 1.4082376956939697\n",
      "mse 1.40823769887313\n",
      "New best model found at epoch 140 with validation loss 1.4082376956939697\n",
      "Starting Epoch 141\n",
      "1.4466623763243358\n",
      "Validation loss: 1.4076846837997437\n",
      "mse 1.4076846525618685\n",
      "New best model found at epoch 141 with validation loss 1.4076846837997437\n",
      "Starting Epoch 142\n",
      "1.4459220493833225\n",
      "Validation loss: 1.4070922136306763\n",
      "mse 1.4070921208046796\n",
      "New best model found at epoch 142 with validation loss 1.4070922136306763\n",
      "Starting Epoch 143\n",
      "1.445171758532524\n",
      "Validation loss: 1.4064528942108154\n",
      "mse 1.4064530202965353\n",
      "New best model found at epoch 143 with validation loss 1.4064528942108154\n",
      "Starting Epoch 144\n",
      "1.444415253897508\n",
      "Validation loss: 1.4057765007019043\n",
      "mse 1.4057764622248416\n",
      "New best model found at epoch 144 with validation loss 1.4057765007019043\n",
      "Starting Epoch 145\n",
      "1.443664309879144\n",
      "Validation loss: 1.4052565097808838\n",
      "mse 1.405256541120436\n",
      "New best model found at epoch 145 with validation loss 1.4052565097808838\n",
      "Starting Epoch 146\n",
      "1.4429509018858273\n",
      "Validation loss: 1.4047050476074219\n",
      "mse 1.4047049567741225\n",
      "New best model found at epoch 146 with validation loss 1.4047050476074219\n",
      "Starting Epoch 147\n",
      "1.442215124766032\n",
      "Validation loss: 1.4040122032165527\n",
      "mse 1.4040122562152413\n",
      "New best model found at epoch 147 with validation loss 1.4040122032165527\n",
      "Starting Epoch 148\n",
      "1.4414901981751125\n",
      "Validation loss: 1.403491497039795\n",
      "mse 1.4034913673553748\n",
      "New best model found at epoch 148 with validation loss 1.403491497039795\n",
      "Starting Epoch 149\n",
      "1.4407942816615105\n",
      "Validation loss: 1.4028984308242798\n",
      "mse 1.4028984533462796\n",
      "New best model found at epoch 149 with validation loss 1.4028984308242798\n",
      "Starting Epoch 150\n",
      "1.4400891413291295\n",
      "Validation loss: 1.4023488759994507\n",
      "mse 1.4023488816927416\n",
      "New best model found at epoch 150 with validation loss 1.4023488759994507\n",
      "Starting Epoch 151\n",
      "1.4393654838204384\n",
      "Validation loss: 1.401882529258728\n",
      "mse 1.40188252296514\n",
      "New best model found at epoch 151 with validation loss 1.401882529258728\n",
      "Starting Epoch 152\n",
      "1.438674196600914\n",
      "Validation loss: 1.4014817476272583\n",
      "mse 1.4014817585489312\n",
      "New best model found at epoch 152 with validation loss 1.4014817476272583\n",
      "Starting Epoch 153\n",
      "1.4379879037539165\n",
      "Validation loss: 1.4009590148925781\n",
      "mse 1.400958974130704\n",
      "New best model found at epoch 153 with validation loss 1.4009590148925781\n",
      "Starting Epoch 154\n",
      "1.4373207564155261\n",
      "Validation loss: 1.4003444910049438\n",
      "mse 1.4003444149084958\n",
      "New best model found at epoch 154 with validation loss 1.4003444910049438\n",
      "Starting Epoch 155\n",
      "1.436651811003685\n",
      "Validation loss: 1.3998162746429443\n",
      "mse 1.399816384669542\n",
      "New best model found at epoch 155 with validation loss 1.3998162746429443\n",
      "Starting Epoch 156\n",
      "1.4359944785634677\n",
      "Validation loss: 1.3992093801498413\n",
      "mse 1.3992093740148064\n",
      "New best model found at epoch 156 with validation loss 1.3992093801498413\n",
      "Starting Epoch 157\n",
      "1.435322326918443\n",
      "Validation loss: 1.3988627195358276\n",
      "mse 1.398862806089715\n",
      "New best model found at epoch 157 with validation loss 1.3988627195358276\n",
      "Starting Epoch 158\n",
      "1.4346533368031185\n",
      "Validation loss: 1.3984222412109375\n",
      "mse 1.3984223188818998\n",
      "New best model found at epoch 158 with validation loss 1.3984222412109375\n",
      "Starting Epoch 159\n",
      "1.4339717701077461\n",
      "Validation loss: 1.397802472114563\n",
      "mse 1.3978025869312065\n",
      "New best model found at epoch 159 with validation loss 1.397802472114563\n",
      "Starting Epoch 160\n",
      "1.4333443890015285\n",
      "Validation loss: 1.3973984718322754\n",
      "mse 1.3973982987625397\n",
      "New best model found at epoch 160 with validation loss 1.3973984718322754\n",
      "Starting Epoch 161\n",
      "1.432689758638541\n",
      "Validation loss: 1.3969104290008545\n",
      "mse 1.3969104735591646\n",
      "New best model found at epoch 161 with validation loss 1.3969104290008545\n",
      "Starting Epoch 162\n",
      "1.4320327068368595\n",
      "Validation loss: 1.3964163064956665\n",
      "mse 1.3964164594252475\n",
      "New best model found at epoch 162 with validation loss 1.3964163064956665\n",
      "Starting Epoch 163\n",
      "1.4314040591319401\n",
      "Validation loss: 1.3959115743637085\n",
      "mse 1.3959115434865081\n",
      "New best model found at epoch 163 with validation loss 1.3959115743637085\n",
      "Starting Epoch 164\n",
      "1.4307644714911778\n",
      "Validation loss: 1.3954323530197144\n",
      "mse 1.395432254940885\n",
      "New best model found at epoch 164 with validation loss 1.3954323530197144\n",
      "Starting Epoch 165\n",
      "1.430129277209441\n",
      "Validation loss: 1.394979476928711\n",
      "mse 1.3949794788467014\n",
      "New best model found at epoch 165 with validation loss 1.394979476928711\n",
      "Starting Epoch 166\n",
      "1.4294928436477978\n",
      "Validation loss: 1.3944859504699707\n",
      "mse 1.394485913710521\n",
      "New best model found at epoch 166 with validation loss 1.3944859504699707\n",
      "Starting Epoch 167\n",
      "1.4288441762328148\n",
      "Validation loss: 1.3940563201904297\n",
      "mse 1.3940561824076003\n",
      "New best model found at epoch 167 with validation loss 1.3940563201904297\n",
      "Starting Epoch 168\n",
      "1.4282343884309132\n",
      "Validation loss: 1.39361572265625\n",
      "mse 1.393615781157297\n",
      "New best model found at epoch 168 with validation loss 1.39361572265625\n",
      "Starting Epoch 169\n",
      "1.4276186004281044\n",
      "Validation loss: 1.3930716514587402\n",
      "mse 1.3930716522259021\n",
      "New best model found at epoch 169 with validation loss 1.3930716514587402\n",
      "Starting Epoch 170\n",
      "1.4270005772511165\n",
      "Validation loss: 1.3926044702529907\n",
      "mse 1.3926044482597904\n",
      "New best model found at epoch 170 with validation loss 1.3926044702529907\n",
      "Starting Epoch 171\n",
      "1.4263768643140793\n",
      "Validation loss: 1.3922690153121948\n",
      "mse 1.3922690406924503\n",
      "New best model found at epoch 171 with validation loss 1.3922690153121948\n",
      "Starting Epoch 172\n",
      "1.42576968173186\n",
      "Validation loss: 1.3918194770812988\n",
      "mse 1.3918194333107856\n",
      "New best model found at epoch 172 with validation loss 1.3918194770812988\n",
      "Starting Epoch 173\n",
      "1.4251958057284355\n",
      "Validation loss: 1.3913280963897705\n",
      "mse 1.391328201129243\n",
      "New best model found at epoch 173 with validation loss 1.3913280963897705\n",
      "Starting Epoch 174\n",
      "1.424568849305312\n",
      "Validation loss: 1.3909493684768677\n",
      "mse 1.3909494659724113\n",
      "New best model found at epoch 174 with validation loss 1.3909493684768677\n",
      "Starting Epoch 175\n",
      "1.4239451761047046\n",
      "Validation loss: 1.3904660940170288\n",
      "mse 1.390465969973212\n",
      "New best model found at epoch 175 with validation loss 1.3904660940170288\n",
      "Starting Epoch 176\n",
      "1.4233934928973515\n",
      "Validation loss: 1.3901305198669434\n",
      "mse 1.3901304946595416\n",
      "New best model found at epoch 176 with validation loss 1.3901305198669434\n",
      "Starting Epoch 177\n",
      "1.422787678738435\n",
      "Validation loss: 1.3895283937454224\n",
      "mse 1.3895284276419935\n",
      "New best model found at epoch 177 with validation loss 1.3895283937454224\n",
      "Starting Epoch 178\n",
      "1.422188992301623\n",
      "Validation loss: 1.3889966011047363\n",
      "mse 1.3889967280066529\n",
      "New best model found at epoch 178 with validation loss 1.3889966011047363\n",
      "Starting Epoch 179\n",
      "1.421627476811409\n",
      "Validation loss: 1.3886237144470215\n",
      "mse 1.3886236650665373\n",
      "New best model found at epoch 179 with validation loss 1.3886237144470215\n",
      "Starting Epoch 180\n",
      "1.421040989458561\n",
      "Validation loss: 1.388301968574524\n",
      "mse 1.3883019318611407\n",
      "New best model found at epoch 180 with validation loss 1.388301968574524\n",
      "Starting Epoch 181\n",
      "1.4204590742786725\n",
      "Validation loss: 1.3878051042556763\n",
      "mse 1.3878050649703553\n",
      "New best model found at epoch 181 with validation loss 1.3878051042556763\n",
      "Starting Epoch 182\n",
      "1.419885923465093\n",
      "Validation loss: 1.3874706029891968\n",
      "mse 1.3874706579659912\n",
      "New best model found at epoch 182 with validation loss 1.3874706029891968\n",
      "Starting Epoch 183\n",
      "1.4193153157830238\n",
      "Validation loss: 1.3870643377304077\n",
      "mse 1.387064438865885\n",
      "New best model found at epoch 183 with validation loss 1.3870643377304077\n",
      "Starting Epoch 184\n",
      "1.4187815710902214\n",
      "Validation loss: 1.3866058588027954\n",
      "mse 1.3866058896897746\n",
      "New best model found at epoch 184 with validation loss 1.3866058588027954\n",
      "Starting Epoch 185\n",
      "1.4182184611757596\n",
      "Validation loss: 1.3862844705581665\n",
      "mse 1.386284554307138\n",
      "New best model found at epoch 185 with validation loss 1.3862844705581665\n",
      "Starting Epoch 186\n",
      "1.4176589623093605\n",
      "Validation loss: 1.3858592510223389\n",
      "mse 1.3858592837236872\n",
      "New best model found at epoch 186 with validation loss 1.3858592510223389\n",
      "Starting Epoch 187\n",
      "1.4170930112401645\n",
      "Validation loss: 1.3854728937149048\n",
      "mse 1.3854728881437768\n",
      "New best model found at epoch 187 with validation loss 1.3854728937149048\n",
      "Starting Epoch 188\n",
      "1.4165533234675725\n",
      "Validation loss: 1.385048270225525\n",
      "mse 1.385048374704459\n",
      "New best model found at epoch 188 with validation loss 1.385048270225525\n",
      "Starting Epoch 189\n",
      "1.4159937649965286\n",
      "Validation loss: 1.3845930099487305\n",
      "mse 1.3845931088957124\n",
      "New best model found at epoch 189 with validation loss 1.3845930099487305\n",
      "Starting Epoch 190\n",
      "1.4154384483893712\n",
      "Validation loss: 1.3843590021133423\n",
      "mse 1.3843589706916055\n",
      "New best model found at epoch 190 with validation loss 1.3843590021133423\n",
      "Starting Epoch 191\n",
      "1.414894513785839\n",
      "Validation loss: 1.3838472366333008\n",
      "mse 1.3838471436815218\n",
      "New best model found at epoch 191 with validation loss 1.3838472366333008\n",
      "Starting Epoch 192\n",
      "1.4143685301144917\n",
      "Validation loss: 1.3834774494171143\n",
      "mse 1.3834775523167964\n",
      "New best model found at epoch 192 with validation loss 1.3834774494171143\n",
      "Starting Epoch 193\n",
      "1.4138334020972252\n",
      "Validation loss: 1.3830536603927612\n",
      "mse 1.3830536308255754\n",
      "New best model found at epoch 193 with validation loss 1.3830536603927612\n",
      "Starting Epoch 194\n",
      "1.4132729818423588\n",
      "Validation loss: 1.3827190399169922\n",
      "mse 1.3827191196023276\n",
      "New best model found at epoch 194 with validation loss 1.3827190399169922\n",
      "Starting Epoch 195\n",
      "1.4127538998921711\n",
      "Validation loss: 1.382431149482727\n",
      "mse 1.382431182905714\n",
      "New best model found at epoch 195 with validation loss 1.382431149482727\n",
      "Starting Epoch 196\n",
      "1.4122147286931674\n",
      "Validation loss: 1.3820761442184448\n",
      "mse 1.382076045180853\n",
      "New best model found at epoch 196 with validation loss 1.3820761442184448\n",
      "Starting Epoch 197\n",
      "1.4116872275869052\n",
      "Validation loss: 1.3818515539169312\n",
      "mse 1.3818514650693405\n",
      "New best model found at epoch 197 with validation loss 1.3818515539169312\n",
      "Starting Epoch 198\n",
      "1.4111356909076374\n",
      "Validation loss: 1.3816182613372803\n",
      "mse 1.3816183467580934\n",
      "New best model found at epoch 198 with validation loss 1.3816182613372803\n",
      "Starting Epoch 199\n",
      "1.4105722854534786\n",
      "Validation loss: 1.3814493417739868\n",
      "mse 1.3814492890964274\n",
      "New best model found at epoch 199 with validation loss 1.3814493417739868\n",
      "Starting Epoch 200\n",
      "1.410008393228054\n",
      "Validation loss: 1.3813236951828003\n",
      "mse 1.3813237022402123\n",
      "New best model found at epoch 200 with validation loss 1.3813236951828003\n",
      "Starting Epoch 201\n",
      "1.4094939356048901\n",
      "Validation loss: 1.3810807466506958\n",
      "mse 1.3810806550735293\n",
      "New best model found at epoch 201 with validation loss 1.3810807466506958\n",
      "Starting Epoch 202\n",
      "1.4089259405930836\n",
      "Validation loss: 1.3807728290557861\n",
      "mse 1.3807728057837942\n",
      "New best model found at epoch 202 with validation loss 1.3807728290557861\n",
      "Starting Epoch 203\n",
      "1.4083841492732365\n",
      "Validation loss: 1.3802061080932617\n",
      "mse 1.3802060145456543\n",
      "New best model found at epoch 203 with validation loss 1.3802061080932617\n",
      "Starting Epoch 204\n",
      "1.407867429157098\n",
      "Validation loss: 1.3797941207885742\n",
      "mse 1.3797942011836273\n",
      "New best model found at epoch 204 with validation loss 1.3797941207885742\n",
      "Starting Epoch 205\n",
      "1.407348056634267\n",
      "Validation loss: 1.3793836832046509\n",
      "mse 1.3793837460082174\n",
      "New best model found at epoch 205 with validation loss 1.3793836832046509\n",
      "Starting Epoch 206\n",
      "1.4068190678954124\n",
      "Validation loss: 1.3789772987365723\n",
      "mse 1.3789774055917918\n",
      "New best model found at epoch 206 with validation loss 1.3789772987365723\n",
      "Starting Epoch 207\n",
      "1.4063221663236618\n",
      "Validation loss: 1.3785769939422607\n",
      "mse 1.3785770315742814\n",
      "New best model found at epoch 207 with validation loss 1.3785769939422607\n",
      "Starting Epoch 208\n",
      "1.4058143148819606\n",
      "Validation loss: 1.378183364868164\n",
      "mse 1.3781835139124226\n",
      "New best model found at epoch 208 with validation loss 1.378183364868164\n",
      "Starting Epoch 209\n",
      "1.4053140357136726\n",
      "Validation loss: 1.3777955770492554\n",
      "mse 1.377795459460403\n",
      "New best model found at epoch 209 with validation loss 1.3777955770492554\n",
      "Starting Epoch 210\n",
      "1.404793697098891\n",
      "Validation loss: 1.3773727416992188\n",
      "mse 1.3773727942729288\n",
      "New best model found at epoch 210 with validation loss 1.3773727416992188\n",
      "Starting Epoch 211\n",
      "1.4043207963307698\n",
      "Validation loss: 1.3769203424453735\n",
      "mse 1.3769203357770943\n",
      "New best model found at epoch 211 with validation loss 1.3769203424453735\n",
      "Starting Epoch 212\n",
      "1.4037794520457585\n",
      "Validation loss: 1.3765630722045898\n",
      "mse 1.3765631061221757\n",
      "New best model found at epoch 212 with validation loss 1.3765630722045898\n",
      "Starting Epoch 213\n",
      "1.4033243184288342\n",
      "Validation loss: 1.3761658668518066\n",
      "mse 1.3761658815361504\n",
      "New best model found at epoch 213 with validation loss 1.3761658668518066\n",
      "Starting Epoch 214\n",
      "1.4028059939543407\n",
      "Validation loss: 1.3758516311645508\n",
      "mse 1.3758516452639058\n",
      "New best model found at epoch 214 with validation loss 1.3758516311645508\n",
      "Starting Epoch 215\n",
      "1.4023609533905983\n",
      "Validation loss: 1.3754887580871582\n",
      "mse 1.3754888101561245\n",
      "New best model found at epoch 215 with validation loss 1.3754887580871582\n",
      "Starting Epoch 216\n",
      "1.401840793589751\n",
      "Validation loss: 1.3751451969146729\n",
      "mse 1.375145185981378\n",
      "New best model found at epoch 216 with validation loss 1.3751451969146729\n",
      "Starting Epoch 217\n",
      "1.4014009237289429\n",
      "Validation loss: 1.3746421337127686\n",
      "mse 1.3746420272069941\n",
      "New best model found at epoch 217 with validation loss 1.3746421337127686\n",
      "Starting Epoch 218\n",
      "1.4008679017424583\n",
      "Validation loss: 1.374300479888916\n",
      "mse 1.3743005590025839\n",
      "New best model found at epoch 218 with validation loss 1.374300479888916\n",
      "Starting Epoch 219\n",
      "1.4003957137465477\n",
      "Validation loss: 1.3741368055343628\n",
      "mse 1.3741367012324712\n",
      "New best model found at epoch 219 with validation loss 1.3741368055343628\n",
      "Starting Epoch 220\n",
      "1.399939666191737\n",
      "Validation loss: 1.3739150762557983\n",
      "mse 1.373915189140939\n",
      "New best model found at epoch 220 with validation loss 1.3739150762557983\n",
      "Starting Epoch 221\n",
      "1.3994252507885296\n",
      "Validation loss: 1.3736282587051392\n",
      "mse 1.3736282279367988\n",
      "New best model found at epoch 221 with validation loss 1.3736282587051392\n",
      "Starting Epoch 222\n",
      "1.398988999426365\n",
      "Validation loss: 1.373180866241455\n",
      "mse 1.373180790748011\n",
      "New best model found at epoch 222 with validation loss 1.373180866241455\n",
      "Starting Epoch 223\n",
      "1.3984261527657509\n",
      "Validation loss: 1.3730154037475586\n",
      "mse 1.3730154516483322\n",
      "New best model found at epoch 223 with validation loss 1.3730154037475586\n",
      "Starting Epoch 224\n",
      "1.3979169875383377\n",
      "Validation loss: 1.3727772235870361\n",
      "mse 1.3727772771505313\n",
      "New best model found at epoch 224 with validation loss 1.3727772235870361\n",
      "Starting Epoch 225\n",
      "1.3974430089195569\n",
      "Validation loss: 1.3724913597106934\n",
      "mse 1.3724912230478838\n",
      "New best model found at epoch 225 with validation loss 1.3724913597106934\n",
      "Starting Epoch 226\n",
      "1.3969204897681873\n",
      "Validation loss: 1.3721437454223633\n",
      "mse 1.3721437261904788\n",
      "New best model found at epoch 226 with validation loss 1.3721437454223633\n",
      "Starting Epoch 227\n",
      "1.3964525312185287\n",
      "Validation loss: 1.3717292547225952\n",
      "mse 1.3717293998840434\n",
      "New best model found at epoch 227 with validation loss 1.3717292547225952\n",
      "Starting Epoch 228\n",
      "1.39594720552365\n",
      "Validation loss: 1.3715137243270874\n",
      "mse 1.3715137490870877\n",
      "New best model found at epoch 228 with validation loss 1.3715137243270874\n",
      "Starting Epoch 229\n",
      "1.3954608341058095\n",
      "Validation loss: 1.3711824417114258\n",
      "mse 1.3711822844025081\n",
      "New best model found at epoch 229 with validation loss 1.3711824417114258\n",
      "Starting Epoch 230\n",
      "1.394966537753741\n",
      "Validation loss: 1.370885968208313\n",
      "mse 1.3708859158246571\n",
      "New best model found at epoch 230 with validation loss 1.370885968208313\n",
      "Starting Epoch 231\n",
      "1.3944969102740288\n",
      "Validation loss: 1.3704098463058472\n",
      "mse 1.3704098723242257\n",
      "New best model found at epoch 231 with validation loss 1.3704098463058472\n",
      "Starting Epoch 232\n",
      "1.3939968794584274\n",
      "Validation loss: 1.3701401948928833\n",
      "mse 1.3701402002418237\n",
      "New best model found at epoch 232 with validation loss 1.3701401948928833\n",
      "Starting Epoch 233\n",
      "1.3935233404239018\n",
      "Validation loss: 1.3698172569274902\n",
      "mse 1.3698171655796303\n",
      "New best model found at epoch 233 with validation loss 1.3698172569274902\n",
      "Starting Epoch 234\n",
      "1.393051063021024\n",
      "Validation loss: 1.3693981170654297\n",
      "mse 1.369398058090876\n",
      "New best model found at epoch 234 with validation loss 1.3693981170654297\n",
      "Starting Epoch 235\n",
      "1.392566978931427\n",
      "Validation loss: 1.3691233396530151\n",
      "mse 1.369123335727284\n",
      "New best model found at epoch 235 with validation loss 1.3691233396530151\n",
      "Starting Epoch 236\n",
      "1.392094189922015\n",
      "Validation loss: 1.3688074350357056\n",
      "mse 1.3688073986259992\n",
      "New best model found at epoch 236 with validation loss 1.3688074350357056\n",
      "Starting Epoch 237\n",
      "1.391622746984164\n",
      "Validation loss: 1.3683911561965942\n",
      "mse 1.3683910210253094\n",
      "New best model found at epoch 237 with validation loss 1.3683911561965942\n",
      "Starting Epoch 238\n",
      "1.3911035483082135\n",
      "Validation loss: 1.3681529760360718\n",
      "mse 1.3681529557301972\n",
      "New best model found at epoch 238 with validation loss 1.3681529760360718\n",
      "Starting Epoch 239\n",
      "1.3905877247452736\n",
      "Validation loss: 1.3678920269012451\n",
      "mse 1.3678921017806835\n",
      "New best model found at epoch 239 with validation loss 1.3678920269012451\n",
      "Starting Epoch 240\n",
      "1.3900889232754707\n",
      "Validation loss: 1.3675693273544312\n",
      "mse 1.3675692974102127\n",
      "New best model found at epoch 240 with validation loss 1.3675693273544312\n",
      "Starting Epoch 241\n",
      "1.389573869605859\n",
      "Validation loss: 1.3671127557754517\n",
      "mse 1.36711269790563\n",
      "New best model found at epoch 241 with validation loss 1.3671127557754517\n",
      "Starting Epoch 242\n",
      "1.3890681316455205\n",
      "Validation loss: 1.366876482963562\n",
      "mse 1.3668764317209563\n",
      "New best model found at epoch 242 with validation loss 1.366876482963562\n",
      "Starting Epoch 243\n",
      "1.388537327448527\n",
      "Validation loss: 1.366551160812378\n",
      "mse 1.3665512621152902\n",
      "New best model found at epoch 243 with validation loss 1.366551160812378\n",
      "Starting Epoch 244\n",
      "1.3880439897378285\n",
      "Validation loss: 1.3661322593688965\n",
      "mse 1.366132203832517\n",
      "New best model found at epoch 244 with validation loss 1.3661322593688965\n",
      "Starting Epoch 245\n",
      "1.3875123709440231\n",
      "Validation loss: 1.3658145666122437\n",
      "mse 1.3658143752069534\n",
      "New best model found at epoch 245 with validation loss 1.3658145666122437\n",
      "Starting Epoch 246\n",
      "1.387028639515241\n",
      "Validation loss: 1.365401268005371\n",
      "mse 1.3654013670534608\n",
      "New best model found at epoch 246 with validation loss 1.365401268005371\n",
      "Starting Epoch 247\n",
      "1.3865166480342548\n",
      "Validation loss: 1.3650368452072144\n",
      "mse 1.3650368480658797\n",
      "New best model found at epoch 247 with validation loss 1.3650368452072144\n",
      "Starting Epoch 248\n",
      "1.3860066011548042\n",
      "Validation loss: 1.3647310733795166\n",
      "mse 1.3647310681622398\n",
      "New best model found at epoch 248 with validation loss 1.3647310733795166\n",
      "Starting Epoch 249\n",
      "1.3855284104744594\n",
      "Validation loss: 1.3642951250076294\n",
      "mse 1.3642951788208169\n",
      "New best model found at epoch 249 with validation loss 1.3642951250076294\n",
      "Starting Epoch 250\n",
      "1.3850223099191983\n",
      "Validation loss: 1.3639031648635864\n",
      "mse 1.3639031474327479\n",
      "New best model found at epoch 250 with validation loss 1.3639031648635864\n",
      "Starting Epoch 251\n",
      "1.3845687185724576\n",
      "Validation loss: 1.3633830547332764\n",
      "mse 1.363383110867745\n",
      "New best model found at epoch 251 with validation loss 1.3633830547332764\n",
      "Starting Epoch 252\n",
      "1.3840933193763096\n",
      "Validation loss: 1.3629506826400757\n",
      "mse 1.3629506859151987\n",
      "New best model found at epoch 252 with validation loss 1.3629506826400757\n",
      "Starting Epoch 253\n",
      "1.3836550588409107\n",
      "Validation loss: 1.3624563217163086\n",
      "mse 1.3624563180030966\n",
      "New best model found at epoch 253 with validation loss 1.3624563217163086\n",
      "Starting Epoch 254\n",
      "1.3831814900040627\n",
      "Validation loss: 1.3620350360870361\n",
      "mse 1.3620349787661825\n",
      "New best model found at epoch 254 with validation loss 1.3620350360870361\n",
      "Starting Epoch 255\n",
      "1.3827218065659206\n",
      "Validation loss: 1.3617253303527832\n",
      "mse 1.3617253592841139\n",
      "New best model found at epoch 255 with validation loss 1.3617253303527832\n",
      "Starting Epoch 256\n",
      "1.3822920471429825\n",
      "Validation loss: 1.3611807823181152\n",
      "mse 1.3611807141516794\n",
      "New best model found at epoch 256 with validation loss 1.3611807823181152\n",
      "Starting Epoch 257\n",
      "1.3818129301071167\n",
      "Validation loss: 1.3609012365341187\n",
      "mse 1.3609010820494054\n",
      "New best model found at epoch 257 with validation loss 1.3609012365341187\n",
      "Starting Epoch 258\n",
      "1.3813960154851277\n",
      "Validation loss: 1.3605045080184937\n",
      "mse 1.3605043990733796\n",
      "New best model found at epoch 258 with validation loss 1.3605045080184937\n",
      "Starting Epoch 259\n",
      "1.3809247737129529\n",
      "Validation loss: 1.3601548671722412\n",
      "mse 1.3601549294775022\n",
      "New best model found at epoch 259 with validation loss 1.3601548671722412\n",
      "Starting Epoch 260\n",
      "1.3805203884840012\n",
      "Validation loss: 1.359842300415039\n",
      "mse 1.3598421627133996\n",
      "New best model found at epoch 260 with validation loss 1.359842300415039\n",
      "Starting Epoch 261\n",
      "1.3801090096433957\n",
      "Validation loss: 1.3593251705169678\n",
      "mse 1.359325189886021\n",
      "New best model found at epoch 261 with validation loss 1.3593251705169678\n",
      "Starting Epoch 262\n",
      "1.3796981871128082\n",
      "Validation loss: 1.359092116355896\n",
      "mse 1.3590920880398023\n",
      "New best model found at epoch 262 with validation loss 1.359092116355896\n",
      "Starting Epoch 263\n",
      "1.3792737498879433\n",
      "Validation loss: 1.3587883710861206\n",
      "mse 1.3587884917482396\n",
      "New best model found at epoch 263 with validation loss 1.3587883710861206\n",
      "Starting Epoch 264\n",
      "1.3788627063234646\n",
      "Validation loss: 1.3584429025650024\n",
      "mse 1.3584428466196075\n",
      "New best model found at epoch 264 with validation loss 1.3584429025650024\n",
      "Starting Epoch 265\n",
      "1.3784242918093998\n",
      "Validation loss: 1.3581689596176147\n",
      "mse 1.358168925320583\n",
      "New best model found at epoch 265 with validation loss 1.3581689596176147\n",
      "Starting Epoch 266\n",
      "1.3780281071861584\n",
      "Validation loss: 1.3577868938446045\n",
      "mse 1.3577869070076862\n",
      "New best model found at epoch 266 with validation loss 1.3577868938446045\n",
      "Starting Epoch 267\n",
      "1.377637043595314\n",
      "Validation loss: 1.357480525970459\n",
      "mse 1.3574804638293418\n",
      "New best model found at epoch 267 with validation loss 1.357480525970459\n",
      "Starting Epoch 268\n",
      "1.3772143324216206\n",
      "Validation loss: 1.3571574687957764\n",
      "mse 1.3571575782076952\n",
      "New best model found at epoch 268 with validation loss 1.3571574687957764\n",
      "Starting Epoch 269\n",
      "1.376794087390105\n",
      "Validation loss: 1.3568980693817139\n",
      "mse 1.356898066055875\n",
      "New best model found at epoch 269 with validation loss 1.3568980693817139\n",
      "Starting Epoch 270\n",
      "1.3763910233974457\n",
      "Validation loss: 1.3565484285354614\n",
      "mse 1.356548554054207\n",
      "New best model found at epoch 270 with validation loss 1.3565484285354614\n",
      "Starting Epoch 271\n",
      "1.3759621754288673\n",
      "Validation loss: 1.356149673461914\n",
      "mse 1.3561497453730396\n",
      "New best model found at epoch 271 with validation loss 1.356149673461914\n",
      "Starting Epoch 272\n",
      "1.375568076968193\n",
      "Validation loss: 1.3558399677276611\n",
      "mse 1.3558399374465178\n",
      "New best model found at epoch 272 with validation loss 1.3558399677276611\n",
      "Starting Epoch 273\n",
      "1.3751642157634099\n",
      "Validation loss: 1.3555529117584229\n",
      "mse 1.3555528753518447\n",
      "New best model found at epoch 273 with validation loss 1.3555529117584229\n",
      "Starting Epoch 274\n",
      "1.3747769917050998\n",
      "Validation loss: 1.3551461696624756\n",
      "mse 1.3551462654625572\n",
      "New best model found at epoch 274 with validation loss 1.3551461696624756\n",
      "Starting Epoch 275\n",
      "1.3743688389658928\n",
      "Validation loss: 1.3548953533172607\n",
      "mse 1.3548953981796754\n",
      "New best model found at epoch 275 with validation loss 1.3548953533172607\n",
      "Starting Epoch 276\n",
      "1.37396885206302\n",
      "Validation loss: 1.3545470237731934\n",
      "mse 1.3545470697508355\n",
      "New best model found at epoch 276 with validation loss 1.3545470237731934\n",
      "Starting Epoch 277\n",
      "1.3735765839616458\n",
      "Validation loss: 1.3543084859848022\n",
      "mse 1.3543084515460486\n",
      "New best model found at epoch 277 with validation loss 1.3543084859848022\n",
      "Starting Epoch 278\n",
      "1.3731916025280952\n",
      "Validation loss: 1.3539470434188843\n",
      "mse 1.3539470633032227\n",
      "New best model found at epoch 278 with validation loss 1.3539470434188843\n",
      "Starting Epoch 279\n",
      "1.372816373904546\n",
      "Validation loss: 1.35367751121521\n",
      "mse 1.3536774480809954\n",
      "New best model found at epoch 279 with validation loss 1.35367751121521\n",
      "Starting Epoch 280\n",
      "1.372433530787627\n",
      "Validation loss: 1.353499174118042\n",
      "mse 1.3534991283137119\n",
      "New best model found at epoch 280 with validation loss 1.353499174118042\n",
      "Starting Epoch 281\n",
      "1.372058928012848\n",
      "Validation loss: 1.3530726432800293\n",
      "mse 1.3530726961820558\n",
      "New best model found at epoch 281 with validation loss 1.3530726432800293\n",
      "Starting Epoch 282\n",
      "1.3716824625929196\n",
      "Validation loss: 1.352917194366455\n",
      "mse 1.3529171955688877\n",
      "New best model found at epoch 282 with validation loss 1.352917194366455\n",
      "Starting Epoch 283\n",
      "1.371313527226448\n",
      "Validation loss: 1.3524891138076782\n",
      "mse 1.3524889394493842\n",
      "New best model found at epoch 283 with validation loss 1.3524891138076782\n",
      "Starting Epoch 284\n",
      "1.3709174692630768\n",
      "Validation loss: 1.3522731065750122\n",
      "mse 1.3522732148692291\n",
      "New best model found at epoch 284 with validation loss 1.3522731065750122\n",
      "Starting Epoch 285\n",
      "1.3705564240614574\n",
      "Validation loss: 1.352006435394287\n",
      "mse 1.3520063953675545\n",
      "New best model found at epoch 285 with validation loss 1.352006435394287\n",
      "Starting Epoch 286\n",
      "1.3701676304141681\n",
      "Validation loss: 1.351678490638733\n",
      "mse 1.3516784648770375\n",
      "New best model found at epoch 286 with validation loss 1.351678490638733\n",
      "Starting Epoch 287\n",
      "1.369797279437383\n",
      "Validation loss: 1.3513712882995605\n",
      "mse 1.3513712391317414\n",
      "New best model found at epoch 287 with validation loss 1.3513712882995605\n",
      "Starting Epoch 288\n",
      "1.3694462353984516\n",
      "Validation loss: 1.3511348962783813\n",
      "mse 1.3511349356919717\n",
      "New best model found at epoch 288 with validation loss 1.3511348962783813\n",
      "Starting Epoch 289\n",
      "1.3690662582715352\n",
      "Validation loss: 1.3508808612823486\n",
      "mse 1.350880981737744\n",
      "New best model found at epoch 289 with validation loss 1.3508808612823486\n",
      "Starting Epoch 290\n",
      "1.3686968336502712\n",
      "Validation loss: 1.3506559133529663\n",
      "mse 1.3506559044458484\n",
      "New best model found at epoch 290 with validation loss 1.3506559133529663\n",
      "Starting Epoch 291\n",
      "1.3683629035949707\n",
      "Validation loss: 1.3503249883651733\n",
      "mse 1.3503249339647934\n",
      "New best model found at epoch 291 with validation loss 1.3503249883651733\n",
      "Starting Epoch 292\n",
      "1.3679802939295769\n",
      "Validation loss: 1.3500723838806152\n",
      "mse 1.3500723092831652\n",
      "New best model found at epoch 292 with validation loss 1.3500723838806152\n",
      "Starting Epoch 293\n",
      "1.3676350687940915\n",
      "Validation loss: 1.349758505821228\n",
      "mse 1.3497585230233335\n",
      "New best model found at epoch 293 with validation loss 1.349758505821228\n",
      "Starting Epoch 294\n",
      "1.367285358409087\n",
      "Validation loss: 1.3494460582733154\n",
      "mse 1.3494459330154895\n",
      "New best model found at epoch 294 with validation loss 1.3494460582733154\n",
      "Starting Epoch 295\n",
      "1.3669203594326973\n",
      "Validation loss: 1.349252700805664\n",
      "mse 1.3492527078113334\n",
      "New best model found at epoch 295 with validation loss 1.349252700805664\n",
      "Starting Epoch 296\n",
      "1.3665638292829196\n",
      "Validation loss: 1.3489967584609985\n",
      "mse 1.3489968600933253\n",
      "New best model found at epoch 296 with validation loss 1.3489967584609985\n",
      "Starting Epoch 297\n",
      "1.366213026146094\n",
      "Validation loss: 1.3486860990524292\n",
      "mse 1.348686096535604\n",
      "New best model found at epoch 297 with validation loss 1.3486860990524292\n",
      "Starting Epoch 298\n",
      "1.3658463309208553\n",
      "Validation loss: 1.3484307527542114\n",
      "mse 1.3484308084847996\n",
      "New best model found at epoch 298 with validation loss 1.3484307527542114\n",
      "Starting Epoch 299\n",
      "1.3655131459236145\n",
      "Validation loss: 1.3481999635696411\n",
      "mse 1.3481998740996624\n",
      "New best model found at epoch 299 with validation loss 1.3481999635696411\n",
      "Starting Epoch 300\n",
      "1.3651627128322918\n",
      "Validation loss: 1.3479045629501343\n",
      "mse 1.347904577976888\n",
      "New best model found at epoch 300 with validation loss 1.3479045629501343\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-40-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54231bf",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 6\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 60 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "e14fe9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "c1d5c604-c3e2-4744-b751-fd26d700707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.6640206774075827\n",
      "Validation loss: 2.36230206489563\n",
      "mse 2.3623018178134485\n",
      "New best model found at epoch 1 with validation loss 2.36230206489563\n",
      "Starting Epoch 2\n",
      "2.273967901865641\n",
      "Validation loss: 2.228398323059082\n",
      "mse 2.2283983924787893\n",
      "New best model found at epoch 2 with validation loss 2.228398323059082\n",
      "Starting Epoch 3\n",
      "2.183718264102936\n",
      "Validation loss: 2.143355369567871\n",
      "mse 2.1433552414730324\n",
      "New best model found at epoch 3 with validation loss 2.143355369567871\n",
      "Starting Epoch 4\n",
      "2.1180048684279122\n",
      "Validation loss: 2.0730087757110596\n",
      "mse 2.073008767685184\n",
      "New best model found at epoch 4 with validation loss 2.0730087757110596\n",
      "Starting Epoch 5\n",
      "2.06427364051342\n",
      "Validation loss: 2.0156126022338867\n",
      "mse 2.0156123122612466\n",
      "New best model found at epoch 5 with validation loss 2.0156126022338867\n",
      "Starting Epoch 6\n",
      "2.0194487323363624\n",
      "Validation loss: 1.9650003910064697\n",
      "mse 1.9650001758269913\n",
      "New best model found at epoch 6 with validation loss 1.9650003910064697\n",
      "Starting Epoch 7\n",
      "1.9800730645656586\n",
      "Validation loss: 1.920588493347168\n",
      "mse 1.9205883774627637\n",
      "New best model found at epoch 7 with validation loss 1.920588493347168\n",
      "Starting Epoch 8\n",
      "1.9452638030052185\n",
      "Validation loss: 1.8813116550445557\n",
      "mse 1.8813118469162664\n",
      "New best model found at epoch 8 with validation loss 1.8813116550445557\n",
      "Starting Epoch 9\n",
      "1.914471020301183\n",
      "Validation loss: 1.8477662801742554\n",
      "mse 1.8477662062377807\n",
      "New best model found at epoch 9 with validation loss 1.8477662801742554\n",
      "Starting Epoch 10\n",
      "1.8870168626308441\n",
      "Validation loss: 1.8154913187026978\n",
      "mse 1.8154912473557865\n",
      "New best model found at epoch 10 with validation loss 1.8154913187026978\n",
      "Starting Epoch 11\n",
      "1.8623547703027725\n",
      "Validation loss: 1.788769245147705\n",
      "mse 1.7887693158200413\n",
      "New best model found at epoch 11 with validation loss 1.788769245147705\n",
      "Starting Epoch 12\n",
      "1.8403054475784302\n",
      "Validation loss: 1.7647292613983154\n",
      "mse 1.764729269928542\n",
      "New best model found at epoch 12 with validation loss 1.7647292613983154\n",
      "Starting Epoch 13\n",
      "1.8206416567166646\n",
      "Validation loss: 1.7422596216201782\n",
      "mse 1.742259538628437\n",
      "New best model found at epoch 13 with validation loss 1.7422596216201782\n",
      "Starting Epoch 14\n",
      "1.8027548889319103\n",
      "Validation loss: 1.7213283777236938\n",
      "mse 1.7213284656223524\n",
      "New best model found at epoch 14 with validation loss 1.7213283777236938\n",
      "Starting Epoch 15\n",
      "1.7864968826373417\n",
      "Validation loss: 1.7032591104507446\n",
      "mse 1.703259153489901\n",
      "New best model found at epoch 15 with validation loss 1.7032591104507446\n",
      "Starting Epoch 16\n",
      "1.7719202389319737\n",
      "Validation loss: 1.6880370378494263\n",
      "mse 1.6880370604948263\n",
      "New best model found at epoch 16 with validation loss 1.6880370378494263\n",
      "Starting Epoch 17\n",
      "1.758702923854192\n",
      "Validation loss: 1.6733983755111694\n",
      "mse 1.673398430198438\n",
      "New best model found at epoch 17 with validation loss 1.6733983755111694\n",
      "Starting Epoch 18\n",
      "1.7466008514165878\n",
      "Validation loss: 1.659645915031433\n",
      "mse 1.6596457116904184\n",
      "New best model found at epoch 18 with validation loss 1.659645915031433\n",
      "Starting Epoch 19\n",
      "1.7351809293031693\n",
      "Validation loss: 1.6473959684371948\n",
      "mse 1.647395860583613\n",
      "New best model found at epoch 19 with validation loss 1.6473959684371948\n",
      "Starting Epoch 20\n",
      "1.725062573949496\n",
      "Validation loss: 1.6365641355514526\n",
      "mse 1.6365641045836086\n",
      "New best model found at epoch 20 with validation loss 1.6365641355514526\n",
      "Starting Epoch 21\n",
      "1.7158678869406383\n",
      "Validation loss: 1.6268573999404907\n",
      "mse 1.6268572724739683\n",
      "New best model found at epoch 21 with validation loss 1.6268573999404907\n",
      "Starting Epoch 22\n",
      "1.707362785935402\n",
      "Validation loss: 1.6178926229476929\n",
      "mse 1.6178925922875498\n",
      "New best model found at epoch 22 with validation loss 1.6178926229476929\n",
      "Starting Epoch 23\n",
      "1.6997446616490681\n",
      "Validation loss: 1.609330415725708\n",
      "mse 1.609330275687056\n",
      "New best model found at epoch 23 with validation loss 1.609330415725708\n",
      "Starting Epoch 24\n",
      "1.692523181438446\n",
      "Validation loss: 1.6017544269561768\n",
      "mse 1.6017544986383603\n",
      "New best model found at epoch 24 with validation loss 1.6017544269561768\n",
      "Starting Epoch 25\n",
      "1.6858080079158146\n",
      "Validation loss: 1.59442138671875\n",
      "mse 1.5944213807435275\n",
      "New best model found at epoch 25 with validation loss 1.59442138671875\n",
      "Starting Epoch 26\n",
      "1.6796793391307194\n",
      "Validation loss: 1.587519884109497\n",
      "mse 1.5875199505341735\n",
      "New best model found at epoch 26 with validation loss 1.587519884109497\n",
      "Starting Epoch 27\n",
      "1.6738641460736592\n",
      "Validation loss: 1.5812703371047974\n",
      "mse 1.5812703636875267\n",
      "New best model found at epoch 27 with validation loss 1.5812703371047974\n",
      "Starting Epoch 28\n",
      "1.6683129221200943\n",
      "Validation loss: 1.5753066539764404\n",
      "mse 1.5753066145064898\n",
      "New best model found at epoch 28 with validation loss 1.5753066539764404\n",
      "Starting Epoch 29\n",
      "1.663105641802152\n",
      "Validation loss: 1.5694644451141357\n",
      "mse 1.5694646072077316\n",
      "New best model found at epoch 29 with validation loss 1.5694644451141357\n",
      "Starting Epoch 30\n",
      "1.6578807632128398\n",
      "Validation loss: 1.5641722679138184\n",
      "mse 1.5641721977246852\n",
      "New best model found at epoch 30 with validation loss 1.5641722679138184\n",
      "Starting Epoch 31\n",
      "1.6531004408995311\n",
      "Validation loss: 1.5590651035308838\n",
      "mse 1.5590650521434708\n",
      "New best model found at epoch 31 with validation loss 1.5590651035308838\n",
      "Starting Epoch 32\n",
      "1.6484467734893162\n",
      "Validation loss: 1.5547189712524414\n",
      "mse 1.5547189831124604\n",
      "New best model found at epoch 32 with validation loss 1.5547189712524414\n",
      "Starting Epoch 33\n",
      "1.6442442188660304\n",
      "Validation loss: 1.550644874572754\n",
      "mse 1.5506448706999019\n",
      "New best model found at epoch 33 with validation loss 1.550644874572754\n",
      "Starting Epoch 34\n",
      "1.640273819367091\n",
      "Validation loss: 1.5471186637878418\n",
      "mse 1.5471184771810336\n",
      "New best model found at epoch 34 with validation loss 1.5471186637878418\n",
      "Starting Epoch 35\n",
      "1.6363837520281475\n",
      "Validation loss: 1.543624758720398\n",
      "mse 1.543624782416568\n",
      "New best model found at epoch 35 with validation loss 1.543624758720398\n",
      "Starting Epoch 36\n",
      "1.6327159802118938\n",
      "Validation loss: 1.540636420249939\n",
      "mse 1.5406364960116627\n",
      "New best model found at epoch 36 with validation loss 1.540636420249939\n",
      "Starting Epoch 37\n",
      "1.6292918076117833\n",
      "Validation loss: 1.5375378131866455\n",
      "mse 1.537538105047259\n",
      "New best model found at epoch 37 with validation loss 1.5375378131866455\n",
      "Starting Epoch 38\n",
      "1.6260251551866531\n",
      "Validation loss: 1.5347070693969727\n",
      "mse 1.5347070023187217\n",
      "New best model found at epoch 38 with validation loss 1.5347070693969727\n",
      "Starting Epoch 39\n",
      "1.6230069696903229\n",
      "Validation loss: 1.5321661233901978\n",
      "mse 1.5321661530912374\n",
      "New best model found at epoch 39 with validation loss 1.5321661233901978\n",
      "Starting Epoch 40\n",
      "1.6199291547139485\n",
      "Validation loss: 1.5296040773391724\n",
      "mse 1.529604071616491\n",
      "New best model found at epoch 40 with validation loss 1.5296040773391724\n",
      "Starting Epoch 41\n",
      "1.6169533828894298\n",
      "Validation loss: 1.5273857116699219\n",
      "mse 1.5273857306668857\n",
      "New best model found at epoch 41 with validation loss 1.5273857116699219\n",
      "Starting Epoch 42\n",
      "1.6139121601978939\n",
      "Validation loss: 1.5260862112045288\n",
      "mse 1.5260860704297436\n",
      "New best model found at epoch 42 with validation loss 1.5260862112045288\n",
      "Starting Epoch 43\n",
      "1.6109593907992046\n",
      "Validation loss: 1.5232954025268555\n",
      "mse 1.5232955053552761\n",
      "New best model found at epoch 43 with validation loss 1.5232954025268555\n",
      "Starting Epoch 44\n",
      "1.6076840261618297\n",
      "Validation loss: 1.5207804441452026\n",
      "mse 1.5207804381826453\n",
      "New best model found at epoch 44 with validation loss 1.5207804441452026\n",
      "Starting Epoch 45\n",
      "1.6045234203338623\n",
      "Validation loss: 1.5183382034301758\n",
      "mse 1.5183381165800358\n",
      "New best model found at epoch 45 with validation loss 1.5183382034301758\n",
      "Starting Epoch 46\n",
      "1.6011862754821777\n",
      "Validation loss: 1.5158036947250366\n",
      "mse 1.5158038219081538\n",
      "New best model found at epoch 46 with validation loss 1.5158036947250366\n",
      "Starting Epoch 47\n",
      "1.5979955544074376\n",
      "Validation loss: 1.5138695240020752\n",
      "mse 1.5138696597231076\n",
      "New best model found at epoch 47 with validation loss 1.5138695240020752\n",
      "Starting Epoch 48\n",
      "1.595076451698939\n",
      "Validation loss: 1.510965347290039\n",
      "mse 1.5109653951204876\n",
      "New best model found at epoch 48 with validation loss 1.510965347290039\n",
      "Starting Epoch 49\n",
      "1.592230275273323\n",
      "Validation loss: 1.5087110996246338\n",
      "mse 1.5087110929688345\n",
      "New best model found at epoch 49 with validation loss 1.5087110996246338\n",
      "Starting Epoch 50\n",
      "1.5894590765237808\n",
      "Validation loss: 1.5070226192474365\n",
      "mse 1.5070225869810647\n",
      "New best model found at epoch 50 with validation loss 1.5070226192474365\n",
      "Starting Epoch 51\n",
      "1.5870243906974792\n",
      "Validation loss: 1.5053892135620117\n",
      "mse 1.505389203727719\n",
      "New best model found at epoch 51 with validation loss 1.5053892135620117\n",
      "Starting Epoch 52\n",
      "1.5847168664137523\n",
      "Validation loss: 1.5037966966629028\n",
      "mse 1.503796840147195\n",
      "New best model found at epoch 52 with validation loss 1.5037966966629028\n",
      "Starting Epoch 53\n",
      "1.5825828860203426\n",
      "Validation loss: 1.5022631883621216\n",
      "mse 1.5022631147373358\n",
      "New best model found at epoch 53 with validation loss 1.5022631883621216\n",
      "Starting Epoch 54\n",
      "1.5805758734544118\n",
      "Validation loss: 1.5009241104125977\n",
      "mse 1.5009241108360365\n",
      "New best model found at epoch 54 with validation loss 1.5009241104125977\n",
      "Starting Epoch 55\n",
      "1.5786201655864716\n",
      "Validation loss: 1.4994428157806396\n",
      "mse 1.4994428102711934\n",
      "New best model found at epoch 55 with validation loss 1.4994428157806396\n",
      "Starting Epoch 56\n",
      "1.5765897184610367\n",
      "Validation loss: 1.4981497526168823\n",
      "mse 1.498149783568492\n",
      "New best model found at epoch 56 with validation loss 1.4981497526168823\n",
      "Starting Epoch 57\n",
      "1.5747230698664982\n",
      "Validation loss: 1.4967117309570312\n",
      "mse 1.496711701182803\n",
      "New best model found at epoch 57 with validation loss 1.4967117309570312\n",
      "Starting Epoch 58\n",
      "1.572810818751653\n",
      "Validation loss: 1.4955744743347168\n",
      "mse 1.49557443023779\n",
      "New best model found at epoch 58 with validation loss 1.4955744743347168\n",
      "Starting Epoch 59\n",
      "1.5709886401891708\n",
      "Validation loss: 1.494306206703186\n",
      "mse 1.494306243637865\n",
      "New best model found at epoch 59 with validation loss 1.494306206703186\n",
      "Starting Epoch 60\n",
      "1.5692526251077652\n",
      "Validation loss: 1.4932835102081299\n",
      "mse 1.49328347709728\n",
      "New best model found at epoch 60 with validation loss 1.4932835102081299\n",
      "Starting Epoch 61\n",
      "1.5674846023321152\n",
      "Validation loss: 1.4922269582748413\n",
      "mse 1.4922269856782886\n",
      "New best model found at epoch 61 with validation loss 1.4922269582748413\n",
      "Starting Epoch 62\n",
      "1.565885638197263\n",
      "Validation loss: 1.49082350730896\n",
      "mse 1.490823492306995\n",
      "New best model found at epoch 62 with validation loss 1.49082350730896\n",
      "Starting Epoch 63\n",
      "1.5640693803628285\n",
      "Validation loss: 1.4903430938720703\n",
      "mse 1.490343136314505\n",
      "New best model found at epoch 63 with validation loss 1.4903430938720703\n",
      "Starting Epoch 64\n",
      "1.5625313768784206\n",
      "Validation loss: 1.4884450435638428\n",
      "mse 1.4884452002444242\n",
      "New best model found at epoch 64 with validation loss 1.4884450435638428\n",
      "Starting Epoch 65\n",
      "1.5609304457902908\n",
      "Validation loss: 1.487359881401062\n",
      "mse 1.4873598943387976\n",
      "New best model found at epoch 65 with validation loss 1.487359881401062\n",
      "Starting Epoch 66\n",
      "1.5592261801163356\n",
      "Validation loss: 1.486527919769287\n",
      "mse 1.4865278978209842\n",
      "New best model found at epoch 66 with validation loss 1.486527919769287\n",
      "Starting Epoch 67\n",
      "1.557761127750079\n",
      "Validation loss: 1.4856284856796265\n",
      "mse 1.4856284678502127\n",
      "New best model found at epoch 67 with validation loss 1.4856284856796265\n",
      "Starting Epoch 68\n",
      "1.5563708593448002\n",
      "Validation loss: 1.484649419784546\n",
      "mse 1.4846495361078993\n",
      "New best model found at epoch 68 with validation loss 1.484649419784546\n",
      "Starting Epoch 69\n",
      "1.554779127240181\n",
      "Validation loss: 1.4840667247772217\n",
      "mse 1.48406682544324\n",
      "New best model found at epoch 69 with validation loss 1.4840667247772217\n",
      "Starting Epoch 70\n",
      "1.5533916751543682\n",
      "Validation loss: 1.4830540418624878\n",
      "mse 1.4830540199853706\n",
      "New best model found at epoch 70 with validation loss 1.4830540418624878\n",
      "Starting Epoch 71\n",
      "1.551956867178281\n",
      "Validation loss: 1.4822529554367065\n",
      "mse 1.4822530041696211\n",
      "New best model found at epoch 71 with validation loss 1.4822529554367065\n",
      "Starting Epoch 72\n",
      "1.5505370150009792\n",
      "Validation loss: 1.4819518327713013\n",
      "mse 1.4819518052049356\n",
      "New best model found at epoch 72 with validation loss 1.4819518327713013\n",
      "Starting Epoch 73\n",
      "1.5492153565088909\n",
      "Validation loss: 1.481194257736206\n",
      "mse 1.4811943702944257\n",
      "New best model found at epoch 73 with validation loss 1.481194257736206\n",
      "Starting Epoch 74\n",
      "1.5479357292254765\n",
      "Validation loss: 1.480124831199646\n",
      "mse 1.4801248478672124\n",
      "New best model found at epoch 74 with validation loss 1.480124831199646\n",
      "Starting Epoch 75\n",
      "1.5464567641417186\n",
      "Validation loss: 1.4795740842819214\n",
      "mse 1.4795740839537825\n",
      "New best model found at epoch 75 with validation loss 1.4795740842819214\n",
      "Starting Epoch 76\n",
      "1.5452707062164943\n",
      "Validation loss: 1.4786376953125\n",
      "mse 1.4786375188879917\n",
      "New best model found at epoch 76 with validation loss 1.4786376953125\n",
      "Starting Epoch 77\n",
      "1.5439183463652928\n",
      "Validation loss: 1.4780796766281128\n",
      "mse 1.4780797353550115\n",
      "New best model found at epoch 77 with validation loss 1.4780796766281128\n",
      "Starting Epoch 78\n",
      "1.5427172233661015\n",
      "Validation loss: 1.4773824214935303\n",
      "mse 1.477382492463812\n",
      "New best model found at epoch 78 with validation loss 1.4773824214935303\n",
      "Starting Epoch 79\n",
      "1.5414696832497914\n",
      "Validation loss: 1.476506233215332\n",
      "mse 1.4765063259221853\n",
      "New best model found at epoch 79 with validation loss 1.476506233215332\n",
      "Starting Epoch 80\n",
      "1.5402268220980961\n",
      "Validation loss: 1.4759290218353271\n",
      "mse 1.475929030379065\n",
      "New best model found at epoch 80 with validation loss 1.4759290218353271\n",
      "Starting Epoch 81\n",
      "1.5391204953193665\n",
      "Validation loss: 1.4749226570129395\n",
      "mse 1.4749226400703839\n",
      "New best model found at epoch 81 with validation loss 1.4749226570129395\n",
      "Starting Epoch 82\n",
      "1.5379039694865544\n",
      "Validation loss: 1.474530577659607\n",
      "mse 1.4745305177482522\n",
      "New best model found at epoch 82 with validation loss 1.474530577659607\n",
      "Starting Epoch 83\n",
      "1.5367808938026428\n",
      "Validation loss: 1.4738130569458008\n",
      "mse 1.4738132182458525\n",
      "New best model found at epoch 83 with validation loss 1.4738130569458008\n",
      "Starting Epoch 84\n",
      "1.5356557468573253\n",
      "Validation loss: 1.4732130765914917\n",
      "mse 1.4732131500300696\n",
      "New best model found at epoch 84 with validation loss 1.4732130765914917\n",
      "Starting Epoch 85\n",
      "1.5345456004142761\n",
      "Validation loss: 1.4725756645202637\n",
      "mse 1.4725756098420009\n",
      "New best model found at epoch 85 with validation loss 1.4725756645202637\n",
      "Starting Epoch 86\n",
      "1.5334124565124512\n",
      "Validation loss: 1.4719748497009277\n",
      "mse 1.4719748355525986\n",
      "New best model found at epoch 86 with validation loss 1.4719748497009277\n",
      "Starting Epoch 87\n",
      "1.5323583682378132\n",
      "Validation loss: 1.471251130104065\n",
      "mse 1.471251095313233\n",
      "New best model found at epoch 87 with validation loss 1.471251130104065\n",
      "Starting Epoch 88\n",
      "1.5312336683273315\n",
      "Validation loss: 1.4706484079360962\n",
      "mse 1.4706484553631027\n",
      "New best model found at epoch 88 with validation loss 1.4706484079360962\n",
      "Starting Epoch 89\n",
      "1.530232384800911\n",
      "Validation loss: 1.4700956344604492\n",
      "mse 1.470095690720084\n",
      "New best model found at epoch 89 with validation loss 1.4700956344604492\n",
      "Starting Epoch 90\n",
      "1.5291787733634312\n",
      "Validation loss: 1.4695236682891846\n",
      "mse 1.4695237823331162\n",
      "New best model found at epoch 90 with validation loss 1.4695236682891846\n",
      "Starting Epoch 91\n",
      "1.5281081050634384\n",
      "Validation loss: 1.4689511060714722\n",
      "mse 1.468951024009689\n",
      "New best model found at epoch 91 with validation loss 1.4689511060714722\n",
      "Starting Epoch 92\n",
      "1.5270989189545314\n",
      "Validation loss: 1.4682713747024536\n",
      "mse 1.4682713702411796\n",
      "New best model found at epoch 92 with validation loss 1.4682713747024536\n",
      "Starting Epoch 93\n",
      "1.526048978169759\n",
      "Validation loss: 1.4676915407180786\n",
      "mse 1.4676916115560346\n",
      "New best model found at epoch 93 with validation loss 1.4676915407180786\n",
      "Starting Epoch 94\n",
      "1.5250131438175838\n",
      "Validation loss: 1.4671286344528198\n",
      "mse 1.4671285932062816\n",
      "New best model found at epoch 94 with validation loss 1.4671286344528198\n",
      "Starting Epoch 95\n",
      "1.5240459839502971\n",
      "Validation loss: 1.4661102294921875\n",
      "mse 1.4661100937050235\n",
      "New best model found at epoch 95 with validation loss 1.4661102294921875\n",
      "Starting Epoch 96\n",
      "1.5229879120985668\n",
      "Validation loss: 1.4659600257873535\n",
      "mse 1.4659599098564453\n",
      "New best model found at epoch 96 with validation loss 1.4659600257873535\n",
      "Starting Epoch 97\n",
      "1.522059440612793\n",
      "Validation loss: 1.465001106262207\n",
      "mse 1.4650011801041118\n",
      "New best model found at epoch 97 with validation loss 1.465001106262207\n",
      "Starting Epoch 98\n",
      "1.521028384566307\n",
      "Validation loss: 1.4644144773483276\n",
      "mse 1.464414546620951\n",
      "New best model found at epoch 98 with validation loss 1.4644144773483276\n",
      "Starting Epoch 99\n",
      "1.520002047220866\n",
      "Validation loss: 1.4639531373977661\n",
      "mse 1.4639531096125389\n",
      "New best model found at epoch 99 with validation loss 1.4639531373977661\n",
      "Starting Epoch 100\n",
      "1.5191180408000946\n",
      "Validation loss: 1.4637768268585205\n",
      "mse 1.46377694938554\n",
      "New best model found at epoch 100 with validation loss 1.4637768268585205\n",
      "Starting Epoch 101\n",
      "1.5181909451882045\n",
      "Validation loss: 1.4633413553237915\n",
      "mse 1.4633415203535265\n",
      "New best model found at epoch 101 with validation loss 1.4633413553237915\n",
      "Starting Epoch 102\n",
      "1.5172326415777206\n",
      "Validation loss: 1.4627964496612549\n",
      "mse 1.4627964809940244\n",
      "New best model found at epoch 102 with validation loss 1.4627964496612549\n",
      "Starting Epoch 103\n",
      "1.5163702964782715\n",
      "Validation loss: 1.4616150856018066\n",
      "mse 1.461615095626169\n",
      "New best model found at epoch 103 with validation loss 1.4616150856018066\n",
      "Starting Epoch 104\n",
      "1.515260025858879\n",
      "Validation loss: 1.4613703489303589\n",
      "mse 1.4613704071270726\n",
      "New best model found at epoch 104 with validation loss 1.4613703489303589\n",
      "Starting Epoch 105\n",
      "1.5143693188826244\n",
      "Validation loss: 1.460732102394104\n",
      "mse 1.4607319377423675\n",
      "New best model found at epoch 105 with validation loss 1.460732102394104\n",
      "Starting Epoch 106\n",
      "1.5133258899052937\n",
      "Validation loss: 1.4608477354049683\n",
      "mse 1.4608477183066328\n",
      "Starting Epoch 107\n",
      "1.5125511139631271\n",
      "Validation loss: 1.459524154663086\n",
      "mse 1.459524178012692\n",
      "New best model found at epoch 107 with validation loss 1.459524154663086\n",
      "Starting Epoch 108\n",
      "1.5114191770553589\n",
      "Validation loss: 1.4591423273086548\n",
      "mse 1.459142422007562\n",
      "New best model found at epoch 108 with validation loss 1.4591423273086548\n",
      "Starting Epoch 109\n",
      "1.5105527987082799\n",
      "Validation loss: 1.4584035873413086\n",
      "mse 1.4584036395748539\n",
      "New best model found at epoch 109 with validation loss 1.4584035873413086\n",
      "Starting Epoch 110\n",
      "1.5095537503560383\n",
      "Validation loss: 1.4585847854614258\n",
      "mse 1.4585848893581068\n",
      "Starting Epoch 111\n",
      "1.5087828189134598\n",
      "Validation loss: 1.457801342010498\n",
      "mse 1.457801366851002\n",
      "New best model found at epoch 111 with validation loss 1.457801342010498\n",
      "Starting Epoch 112\n",
      "1.507802685101827\n",
      "Validation loss: 1.4567649364471436\n",
      "mse 1.4567649719391271\n",
      "New best model found at epoch 112 with validation loss 1.4567649364471436\n",
      "Starting Epoch 113\n",
      "1.5069286574920018\n",
      "Validation loss: 1.4562965631484985\n",
      "mse 1.4562966046175754\n",
      "New best model found at epoch 113 with validation loss 1.4562965631484985\n",
      "Starting Epoch 114\n",
      "1.5059518218040466\n",
      "Validation loss: 1.456670880317688\n",
      "mse 1.4566707756413027\n",
      "Starting Epoch 115\n",
      "1.505160724123319\n",
      "Validation loss: 1.4553720951080322\n",
      "mse 1.455372024525585\n",
      "New best model found at epoch 115 with validation loss 1.4553720951080322\n",
      "Starting Epoch 116\n",
      "1.5043259114027023\n",
      "Validation loss: 1.454677700996399\n",
      "mse 1.454677754127335\n",
      "New best model found at epoch 116 with validation loss 1.454677700996399\n",
      "Starting Epoch 117\n",
      "1.503321647644043\n",
      "Validation loss: 1.4550917148590088\n",
      "mse 1.4550917153590923\n",
      "Starting Epoch 118\n",
      "1.5026334077119827\n",
      "Validation loss: 1.4544050693511963\n",
      "mse 1.454405140465751\n",
      "New best model found at epoch 118 with validation loss 1.4544050693511963\n",
      "Starting Epoch 119\n",
      "1.5016341308752696\n",
      "Validation loss: 1.45408296585083\n",
      "mse 1.454083079451273\n",
      "New best model found at epoch 119 with validation loss 1.45408296585083\n",
      "Starting Epoch 120\n",
      "1.5008506973584492\n",
      "Validation loss: 1.4534614086151123\n",
      "mse 1.4534613706414135\n",
      "New best model found at epoch 120 with validation loss 1.4534614086151123\n",
      "Starting Epoch 121\n",
      "1.4998639971017838\n",
      "Validation loss: 1.4531208276748657\n",
      "mse 1.4531208761664431\n",
      "New best model found at epoch 121 with validation loss 1.4531208276748657\n",
      "Starting Epoch 122\n",
      "1.4991335074106853\n",
      "Validation loss: 1.4526077508926392\n",
      "mse 1.452607676985361\n",
      "New best model found at epoch 122 with validation loss 1.4526077508926392\n",
      "Starting Epoch 123\n",
      "1.498126486937205\n",
      "Validation loss: 1.4522629976272583\n",
      "mse 1.4522630225696882\n",
      "New best model found at epoch 123 with validation loss 1.4522629976272583\n",
      "Starting Epoch 124\n",
      "1.4974715858697891\n",
      "Validation loss: 1.4515955448150635\n",
      "mse 1.451595544282889\n",
      "New best model found at epoch 124 with validation loss 1.4515955448150635\n",
      "Starting Epoch 125\n",
      "1.4965208719174068\n",
      "Validation loss: 1.4510992765426636\n",
      "mse 1.4510993214333503\n",
      "New best model found at epoch 125 with validation loss 1.4510992765426636\n",
      "Starting Epoch 126\n",
      "1.4956404318412144\n",
      "Validation loss: 1.4508610963821411\n",
      "mse 1.4508611252271644\n",
      "New best model found at epoch 126 with validation loss 1.4508610963821411\n",
      "Starting Epoch 127\n",
      "1.4949011653661728\n",
      "Validation loss: 1.4501148462295532\n",
      "mse 1.4501149295191296\n",
      "New best model found at epoch 127 with validation loss 1.4501148462295532\n",
      "Starting Epoch 128\n",
      "1.4938741226991017\n",
      "Validation loss: 1.4489933252334595\n",
      "mse 1.4489932492397686\n",
      "New best model found at epoch 128 with validation loss 1.4489933252334595\n",
      "Starting Epoch 129\n",
      "1.4930902620156605\n",
      "Validation loss: 1.4490753412246704\n",
      "mse 1.449075369216041\n",
      "Starting Epoch 130\n",
      "1.4922180424133937\n",
      "Validation loss: 1.4485427141189575\n",
      "mse 1.4485425818905415\n",
      "New best model found at epoch 130 with validation loss 1.4485427141189575\n",
      "Starting Epoch 131\n",
      "1.4913952598969142\n",
      "Validation loss: 1.4475135803222656\n",
      "mse 1.4475135195077404\n",
      "New best model found at epoch 131 with validation loss 1.4475135803222656\n",
      "Starting Epoch 132\n",
      "1.4905612468719482\n",
      "Validation loss: 1.4473868608474731\n",
      "mse 1.4473868722407568\n",
      "New best model found at epoch 132 with validation loss 1.4473868608474731\n",
      "Starting Epoch 133\n",
      "1.4897551288207371\n",
      "Validation loss: 1.4468239545822144\n",
      "mse 1.4468239002740282\n",
      "New best model found at epoch 133 with validation loss 1.4468239545822144\n",
      "Starting Epoch 134\n",
      "1.4888863911231358\n",
      "Validation loss: 1.4464352130889893\n",
      "mse 1.4464353015768432\n",
      "New best model found at epoch 134 with validation loss 1.4464352130889893\n",
      "Starting Epoch 135\n",
      "1.488075186808904\n",
      "Validation loss: 1.4454094171524048\n",
      "mse 1.4454093868409716\n",
      "New best model found at epoch 135 with validation loss 1.4454094171524048\n",
      "Starting Epoch 136\n",
      "1.4873234182596207\n",
      "Validation loss: 1.445477843284607\n",
      "mse 1.445477894433284\n",
      "Starting Epoch 137\n",
      "1.486609806617101\n",
      "Validation loss: 1.4448908567428589\n",
      "mse 1.4448908709782704\n",
      "New best model found at epoch 137 with validation loss 1.4448908567428589\n",
      "Starting Epoch 138\n",
      "1.4858131458361943\n",
      "Validation loss: 1.4439592361450195\n",
      "mse 1.4439592142986397\n",
      "New best model found at epoch 138 with validation loss 1.4439592361450195\n",
      "Starting Epoch 139\n",
      "1.4850582281748455\n",
      "Validation loss: 1.4434925317764282\n",
      "mse 1.4434925929984104\n",
      "New best model found at epoch 139 with validation loss 1.4434925317764282\n",
      "Starting Epoch 140\n",
      "1.4843184103568394\n",
      "Validation loss: 1.4435657262802124\n",
      "mse 1.4435657627341665\n",
      "Starting Epoch 141\n",
      "1.483615403374036\n",
      "Validation loss: 1.4431923627853394\n",
      "mse 1.443192330790977\n",
      "New best model found at epoch 141 with validation loss 1.4431923627853394\n",
      "Starting Epoch 142\n",
      "1.482934872309367\n",
      "Validation loss: 1.442682147026062\n",
      "mse 1.4426821867270696\n",
      "New best model found at epoch 142 with validation loss 1.442682147026062\n",
      "Starting Epoch 143\n",
      "1.482084075609843\n",
      "Validation loss: 1.4417351484298706\n",
      "mse 1.4417351864707884\n",
      "New best model found at epoch 143 with validation loss 1.4417351484298706\n",
      "Starting Epoch 144\n",
      "1.4814329693714778\n",
      "Validation loss: 1.4411282539367676\n",
      "mse 1.4411281595529473\n",
      "New best model found at epoch 144 with validation loss 1.4411282539367676\n",
      "Starting Epoch 145\n",
      "1.4807459811369579\n",
      "Validation loss: 1.440678358078003\n",
      "mse 1.4406782895817003\n",
      "New best model found at epoch 145 with validation loss 1.440678358078003\n",
      "Starting Epoch 146\n",
      "1.4799322883288066\n",
      "Validation loss: 1.4410430192947388\n",
      "mse 1.4410430420902527\n",
      "Starting Epoch 147\n",
      "1.4793306738138199\n",
      "Validation loss: 1.4398826360702515\n",
      "mse 1.4398826573624723\n",
      "New best model found at epoch 147 with validation loss 1.4398826360702515\n",
      "Starting Epoch 148\n",
      "1.4786367615063984\n",
      "Validation loss: 1.440048098564148\n",
      "mse 1.4400480930251451\n",
      "Starting Epoch 149\n",
      "1.4779525846242905\n",
      "Validation loss: 1.4396028518676758\n",
      "mse 1.4396028187813732\n",
      "New best model found at epoch 149 with validation loss 1.4396028518676758\n",
      "Starting Epoch 150\n",
      "1.4772487779458363\n",
      "Validation loss: 1.4392856359481812\n",
      "mse 1.4392856585500375\n",
      "New best model found at epoch 150 with validation loss 1.4392856359481812\n",
      "Starting Epoch 151\n",
      "1.4765696624914806\n",
      "Validation loss: 1.4390132427215576\n",
      "mse 1.4390132532101958\n",
      "New best model found at epoch 151 with validation loss 1.4390132427215576\n",
      "Starting Epoch 152\n",
      "1.4758965174357097\n",
      "Validation loss: 1.4385613203048706\n",
      "mse 1.438561309008485\n",
      "New best model found at epoch 152 with validation loss 1.4385613203048706\n",
      "Starting Epoch 153\n",
      "1.4752249320348103\n",
      "Validation loss: 1.438236117362976\n",
      "mse 1.4382362645767428\n",
      "New best model found at epoch 153 with validation loss 1.438236117362976\n",
      "Starting Epoch 154\n",
      "1.474554494023323\n",
      "Validation loss: 1.437788486480713\n",
      "mse 1.437788407531506\n",
      "New best model found at epoch 154 with validation loss 1.437788486480713\n",
      "Starting Epoch 155\n",
      "1.47393203775088\n",
      "Validation loss: 1.4373174905776978\n",
      "mse 1.4373175419766124\n",
      "New best model found at epoch 155 with validation loss 1.4373174905776978\n",
      "Starting Epoch 156\n",
      "1.4732216596603394\n",
      "Validation loss: 1.4363701343536377\n",
      "mse 1.4363700554278116\n",
      "New best model found at epoch 156 with validation loss 1.4363701343536377\n",
      "Starting Epoch 157\n",
      "1.4725346366564434\n",
      "Validation loss: 1.436445713043213\n",
      "mse 1.436445748582281\n",
      "Starting Epoch 158\n",
      "1.4719009796778362\n",
      "Validation loss: 1.4365119934082031\n",
      "mse 1.4365117738292161\n",
      "Starting Epoch 159\n",
      "1.4713038802146912\n",
      "Validation loss: 1.435747742652893\n",
      "mse 1.4357477212013852\n",
      "New best model found at epoch 159 with validation loss 1.435747742652893\n",
      "Starting Epoch 160\n",
      "1.470597003897031\n",
      "Validation loss: 1.4359792470932007\n",
      "mse 1.4359792106700664\n",
      "Starting Epoch 161\n",
      "1.4700525104999542\n",
      "Validation loss: 1.4348894357681274\n",
      "mse 1.4348893878432514\n",
      "New best model found at epoch 161 with validation loss 1.4348894357681274\n",
      "Starting Epoch 162\n",
      "1.4692972352107365\n",
      "Validation loss: 1.434892177581787\n",
      "mse 1.4348920489247663\n",
      "Starting Epoch 163\n",
      "1.468742127219836\n",
      "Validation loss: 1.434181571006775\n",
      "mse 1.434181768221885\n",
      "New best model found at epoch 163 with validation loss 1.434181571006775\n",
      "Starting Epoch 164\n",
      "1.4681166460116704\n",
      "Validation loss: 1.4335827827453613\n",
      "mse 1.4335828615254107\n",
      "New best model found at epoch 164 with validation loss 1.4335827827453613\n",
      "Starting Epoch 165\n",
      "1.4674133012692134\n",
      "Validation loss: 1.4333722591400146\n",
      "mse 1.433372156929128\n",
      "New best model found at epoch 165 with validation loss 1.4333722591400146\n",
      "Starting Epoch 166\n",
      "1.4667642265558243\n",
      "Validation loss: 1.4329140186309814\n",
      "mse 1.4329139166784408\n",
      "New best model found at epoch 166 with validation loss 1.4329140186309814\n",
      "Starting Epoch 167\n",
      "1.466127132376035\n",
      "Validation loss: 1.432679533958435\n",
      "mse 1.4326794902640674\n",
      "New best model found at epoch 167 with validation loss 1.432679533958435\n",
      "Starting Epoch 168\n",
      "1.4655172129472096\n",
      "Validation loss: 1.4323229789733887\n",
      "mse 1.432322982820223\n",
      "New best model found at epoch 168 with validation loss 1.4323229789733887\n",
      "Starting Epoch 169\n",
      "1.46491772433122\n",
      "Validation loss: 1.4316802024841309\n",
      "mse 1.4316802628587704\n",
      "New best model found at epoch 169 with validation loss 1.4316802024841309\n",
      "Starting Epoch 170\n",
      "1.4642376452684402\n",
      "Validation loss: 1.4313315153121948\n",
      "mse 1.4313314953618659\n",
      "New best model found at epoch 170 with validation loss 1.4313315153121948\n",
      "Starting Epoch 171\n",
      "1.4635998258988063\n",
      "Validation loss: 1.4310556650161743\n",
      "mse 1.4310556038125388\n",
      "New best model found at epoch 171 with validation loss 1.4310556650161743\n",
      "Starting Epoch 172\n",
      "1.4630320767561595\n",
      "Validation loss: 1.4306951761245728\n",
      "mse 1.4306951243016295\n",
      "New best model found at epoch 172 with validation loss 1.4306951761245728\n",
      "Starting Epoch 173\n",
      "1.4624656091133754\n",
      "Validation loss: 1.4300353527069092\n",
      "mse 1.430035476339877\n",
      "New best model found at epoch 173 with validation loss 1.4300353527069092\n",
      "Starting Epoch 174\n",
      "1.4616557111342747\n",
      "Validation loss: 1.4299774169921875\n",
      "mse 1.4299774692406881\n",
      "New best model found at epoch 174 with validation loss 1.4299774169921875\n",
      "Starting Epoch 175\n",
      "1.4611147493124008\n",
      "Validation loss: 1.4295153617858887\n",
      "mse 1.429515344529656\n",
      "New best model found at epoch 175 with validation loss 1.4295153617858887\n",
      "Starting Epoch 176\n",
      "1.4606015185515087\n",
      "Validation loss: 1.4289848804473877\n",
      "mse 1.4289849703002575\n",
      "New best model found at epoch 176 with validation loss 1.4289848804473877\n",
      "Starting Epoch 177\n",
      "1.4599563280741374\n",
      "Validation loss: 1.4286916255950928\n",
      "mse 1.4286916453352372\n",
      "New best model found at epoch 177 with validation loss 1.4286916255950928\n",
      "Starting Epoch 178\n",
      "1.4592962712049484\n",
      "Validation loss: 1.428445816040039\n",
      "mse 1.428445808664947\n",
      "New best model found at epoch 178 with validation loss 1.428445816040039\n",
      "Starting Epoch 179\n",
      "1.458694686492284\n",
      "Validation loss: 1.427971601486206\n",
      "mse 1.4279715797650778\n",
      "New best model found at epoch 179 with validation loss 1.427971601486206\n",
      "Starting Epoch 180\n",
      "1.458252231280009\n",
      "Validation loss: 1.4274320602416992\n",
      "mse 1.4274319323216709\n",
      "New best model found at epoch 180 with validation loss 1.4274320602416992\n",
      "Starting Epoch 181\n",
      "1.4576310614744823\n",
      "Validation loss: 1.4271838665008545\n",
      "mse 1.4271838026018773\n",
      "New best model found at epoch 181 with validation loss 1.4271838665008545\n",
      "Starting Epoch 182\n",
      "1.4570169299840927\n",
      "Validation loss: 1.4269706010818481\n",
      "mse 1.42697067216434\n",
      "New best model found at epoch 182 with validation loss 1.4269706010818481\n",
      "Starting Epoch 183\n",
      "1.456502303481102\n",
      "Validation loss: 1.4266023635864258\n",
      "mse 1.4266024044332122\n",
      "New best model found at epoch 183 with validation loss 1.4266023635864258\n",
      "Starting Epoch 184\n",
      "1.4558306088050206\n",
      "Validation loss: 1.426003098487854\n",
      "mse 1.4260031681034404\n",
      "New best model found at epoch 184 with validation loss 1.426003098487854\n",
      "Starting Epoch 185\n",
      "1.455287943283717\n",
      "Validation loss: 1.4258971214294434\n",
      "mse 1.4258970528200932\n",
      "New best model found at epoch 185 with validation loss 1.4258971214294434\n",
      "Starting Epoch 186\n",
      "1.4547630151112874\n",
      "Validation loss: 1.425522804260254\n",
      "mse 1.4255229845556596\n",
      "New best model found at epoch 186 with validation loss 1.425522804260254\n",
      "Starting Epoch 187\n",
      "1.4541605760653813\n",
      "Validation loss: 1.4251707792282104\n",
      "mse 1.4251706963348012\n",
      "New best model found at epoch 187 with validation loss 1.4251707792282104\n",
      "Starting Epoch 188\n",
      "1.4536981731653214\n",
      "Validation loss: 1.424654483795166\n",
      "mse 1.424654427806221\n",
      "New best model found at epoch 188 with validation loss 1.424654483795166\n",
      "Starting Epoch 189\n",
      "1.4530936479568481\n",
      "Validation loss: 1.4243148565292358\n",
      "mse 1.424314849391028\n",
      "New best model found at epoch 189 with validation loss 1.4243148565292358\n",
      "Starting Epoch 190\n",
      "1.4525124231974285\n",
      "Validation loss: 1.4239718914031982\n",
      "mse 1.423971955960255\n",
      "New best model found at epoch 190 with validation loss 1.4239718914031982\n",
      "Starting Epoch 191\n",
      "1.4520577887694042\n",
      "Validation loss: 1.4236923456192017\n",
      "mse 1.4236922862495898\n",
      "New best model found at epoch 191 with validation loss 1.4236923456192017\n",
      "Starting Epoch 192\n",
      "1.4515032668908436\n",
      "Validation loss: 1.4233685731887817\n",
      "mse 1.4233685056990213\n",
      "New best model found at epoch 192 with validation loss 1.4233685731887817\n",
      "Starting Epoch 193\n",
      "1.4509892364343007\n",
      "Validation loss: 1.4228909015655518\n",
      "mse 1.4228910786013387\n",
      "New best model found at epoch 193 with validation loss 1.4228909015655518\n",
      "Starting Epoch 194\n",
      "1.45039102435112\n",
      "Validation loss: 1.422741174697876\n",
      "mse 1.422741066351524\n",
      "New best model found at epoch 194 with validation loss 1.422741174697876\n",
      "Starting Epoch 195\n",
      "1.4499741246302922\n",
      "Validation loss: 1.42194664478302\n",
      "mse 1.4219466187317138\n",
      "New best model found at epoch 195 with validation loss 1.42194664478302\n",
      "Starting Epoch 196\n",
      "1.4493544052044551\n",
      "Validation loss: 1.4216691255569458\n",
      "mse 1.421669141017021\n",
      "New best model found at epoch 196 with validation loss 1.4216691255569458\n",
      "Starting Epoch 197\n",
      "1.448854128519694\n",
      "Validation loss: 1.4213740825653076\n",
      "mse 1.421374023599803\n",
      "New best model found at epoch 197 with validation loss 1.4213740825653076\n",
      "Starting Epoch 198\n",
      "1.4483004361391068\n",
      "Validation loss: 1.4210271835327148\n",
      "mse 1.421027162655621\n",
      "New best model found at epoch 198 with validation loss 1.4210271835327148\n",
      "Starting Epoch 199\n",
      "1.4479010303815205\n",
      "Validation loss: 1.4204679727554321\n",
      "mse 1.420467926432098\n",
      "New best model found at epoch 199 with validation loss 1.4204679727554321\n",
      "Starting Epoch 200\n",
      "1.4473606596390407\n",
      "Validation loss: 1.4201475381851196\n",
      "mse 1.420147532584896\n",
      "New best model found at epoch 200 with validation loss 1.4201475381851196\n",
      "Starting Epoch 201\n",
      "1.4467631081740062\n",
      "Validation loss: 1.419852614402771\n",
      "mse 1.419852572889138\n",
      "New best model found at epoch 201 with validation loss 1.419852614402771\n",
      "Starting Epoch 202\n",
      "1.446162263552348\n",
      "Validation loss: 1.419600009918213\n",
      "mse 1.4195999624202829\n",
      "New best model found at epoch 202 with validation loss 1.419600009918213\n",
      "Starting Epoch 203\n",
      "1.4456606010595958\n",
      "Validation loss: 1.4193180799484253\n",
      "mse 1.4193180641812453\n",
      "New best model found at epoch 203 with validation loss 1.4193180799484253\n",
      "Starting Epoch 204\n",
      "1.4451825618743896\n",
      "Validation loss: 1.4189502000808716\n",
      "mse 1.418950150931668\n",
      "New best model found at epoch 204 with validation loss 1.4189502000808716\n",
      "Starting Epoch 205\n",
      "1.4448120594024658\n",
      "Validation loss: 1.418071985244751\n",
      "mse 1.4180720705594851\n",
      "New best model found at epoch 205 with validation loss 1.418071985244751\n",
      "Starting Epoch 206\n",
      "1.444199765721957\n",
      "Validation loss: 1.4178506135940552\n",
      "mse 1.4178506113811447\n",
      "New best model found at epoch 206 with validation loss 1.4178506135940552\n",
      "Starting Epoch 207\n",
      "1.443644533554713\n",
      "Validation loss: 1.4177048206329346\n",
      "mse 1.4177049088463796\n",
      "New best model found at epoch 207 with validation loss 1.4177048206329346\n",
      "Starting Epoch 208\n",
      "1.4431620637575786\n",
      "Validation loss: 1.4174206256866455\n",
      "mse 1.4174207594115562\n",
      "New best model found at epoch 208 with validation loss 1.4174206256866455\n",
      "Starting Epoch 209\n",
      "1.442654773592949\n",
      "Validation loss: 1.4170727729797363\n",
      "mse 1.4170728187049673\n",
      "New best model found at epoch 209 with validation loss 1.4170727729797363\n",
      "Starting Epoch 210\n",
      "1.4422085881233215\n",
      "Validation loss: 1.416690707206726\n",
      "mse 1.4166908724330975\n",
      "New best model found at epoch 210 with validation loss 1.416690707206726\n",
      "Starting Epoch 211\n",
      "1.441610390941302\n",
      "Validation loss: 1.4163453578948975\n",
      "mse 1.4163453556681844\n",
      "New best model found at epoch 211 with validation loss 1.4163453578948975\n",
      "Starting Epoch 212\n",
      "1.441153198480606\n",
      "Validation loss: 1.4160449504852295\n",
      "mse 1.41604515826667\n",
      "New best model found at epoch 212 with validation loss 1.4160449504852295\n",
      "Starting Epoch 213\n",
      "1.4406806478897731\n",
      "Validation loss: 1.4156769514083862\n",
      "mse 1.4156768184413353\n",
      "New best model found at epoch 213 with validation loss 1.4156769514083862\n",
      "Starting Epoch 214\n",
      "1.4402746309836705\n",
      "Validation loss: 1.414982795715332\n",
      "mse 1.414982928635753\n",
      "New best model found at epoch 214 with validation loss 1.414982795715332\n",
      "Starting Epoch 215\n",
      "1.4397151172161102\n",
      "Validation loss: 1.4147751331329346\n",
      "mse 1.4147750298153212\n",
      "New best model found at epoch 215 with validation loss 1.4147751331329346\n",
      "Starting Epoch 216\n",
      "1.4392234335343044\n",
      "Validation loss: 1.4145616292953491\n",
      "mse 1.4145617408112257\n",
      "New best model found at epoch 216 with validation loss 1.4145616292953491\n",
      "Starting Epoch 217\n",
      "1.438825731476148\n",
      "Validation loss: 1.4140660762786865\n",
      "mse 1.4140661042677236\n",
      "New best model found at epoch 217 with validation loss 1.4140660762786865\n",
      "Starting Epoch 218\n",
      "1.4381991078456242\n",
      "Validation loss: 1.4138836860656738\n",
      "mse 1.4138836436520796\n",
      "New best model found at epoch 218 with validation loss 1.4138836860656738\n",
      "Starting Epoch 219\n",
      "1.4377917299667995\n",
      "Validation loss: 1.4135044813156128\n",
      "mse 1.413504526855995\n",
      "New best model found at epoch 219 with validation loss 1.4135044813156128\n",
      "Starting Epoch 220\n",
      "1.4372900128364563\n",
      "Validation loss: 1.413184404373169\n",
      "mse 1.4131844632190178\n",
      "New best model found at epoch 220 with validation loss 1.413184404373169\n",
      "Starting Epoch 221\n",
      "1.4367857774098713\n",
      "Validation loss: 1.4129624366760254\n",
      "mse 1.4129624107023087\n",
      "New best model found at epoch 221 with validation loss 1.4129624366760254\n",
      "Starting Epoch 222\n",
      "1.436383455991745\n",
      "Validation loss: 1.4126396179199219\n",
      "mse 1.4126396184755365\n",
      "New best model found at epoch 222 with validation loss 1.4126396179199219\n",
      "Starting Epoch 223\n",
      "1.4358719487984974\n",
      "Validation loss: 1.4123873710632324\n",
      "mse 1.4123874027754806\n",
      "New best model found at epoch 223 with validation loss 1.4123873710632324\n",
      "Starting Epoch 224\n",
      "1.4354615012804668\n",
      "Validation loss: 1.4120829105377197\n",
      "mse 1.4120828539685328\n",
      "New best model found at epoch 224 with validation loss 1.4120829105377197\n",
      "Starting Epoch 225\n",
      "1.4350332419077556\n",
      "Validation loss: 1.4116311073303223\n",
      "mse 1.411631191694771\n",
      "New best model found at epoch 225 with validation loss 1.4116311073303223\n",
      "Starting Epoch 226\n",
      "1.4344793160756428\n",
      "Validation loss: 1.4115021228790283\n",
      "mse 1.4115022353594935\n",
      "New best model found at epoch 226 with validation loss 1.4115021228790283\n",
      "Starting Epoch 227\n",
      "1.4341770857572556\n",
      "Validation loss: 1.410589337348938\n",
      "mse 1.4105893659228892\n",
      "New best model found at epoch 227 with validation loss 1.410589337348938\n",
      "Starting Epoch 228\n",
      "1.4335776666800182\n",
      "Validation loss: 1.4106804132461548\n",
      "mse 1.4106804536043807\n",
      "Starting Epoch 229\n",
      "1.433162699143092\n",
      "Validation loss: 1.4103366136550903\n",
      "mse 1.410336451834295\n",
      "New best model found at epoch 229 with validation loss 1.4103366136550903\n",
      "Starting Epoch 230\n",
      "1.4326689839363098\n",
      "Validation loss: 1.4100030660629272\n",
      "mse 1.4100030948720033\n",
      "New best model found at epoch 230 with validation loss 1.4100030660629272\n",
      "Starting Epoch 231\n",
      "1.4322214722633362\n",
      "Validation loss: 1.4097429513931274\n",
      "mse 1.4097429557787176\n",
      "New best model found at epoch 231 with validation loss 1.4097429513931274\n",
      "Starting Epoch 232\n",
      "1.4318291048208873\n",
      "Validation loss: 1.4093751907348633\n",
      "mse 1.4093751515889021\n",
      "New best model found at epoch 232 with validation loss 1.4093751907348633\n",
      "Starting Epoch 233\n",
      "1.4313749372959137\n",
      "Validation loss: 1.4090683460235596\n",
      "mse 1.409068263544646\n",
      "New best model found at epoch 233 with validation loss 1.4090683460235596\n",
      "Starting Epoch 234\n",
      "1.4309933831294377\n",
      "Validation loss: 1.408679723739624\n",
      "mse 1.4086798745012423\n",
      "New best model found at epoch 234 with validation loss 1.408679723739624\n",
      "Starting Epoch 235\n",
      "1.430474077661832\n",
      "Validation loss: 1.4083856344223022\n",
      "mse 1.4083856007633504\n",
      "New best model found at epoch 235 with validation loss 1.4083856344223022\n",
      "Starting Epoch 236\n",
      "1.430056427915891\n",
      "Validation loss: 1.408054232597351\n",
      "mse 1.4080541171540033\n",
      "New best model found at epoch 236 with validation loss 1.408054232597351\n",
      "Starting Epoch 237\n",
      "1.4295891324679058\n",
      "Validation loss: 1.4078446626663208\n",
      "mse 1.4078446989856812\n",
      "New best model found at epoch 237 with validation loss 1.4078446626663208\n",
      "Starting Epoch 238\n",
      "1.4292029440402985\n",
      "Validation loss: 1.407440423965454\n",
      "mse 1.407440400673749\n",
      "New best model found at epoch 238 with validation loss 1.407440423965454\n",
      "Starting Epoch 239\n",
      "1.4287047038475673\n",
      "Validation loss: 1.4070883989334106\n",
      "mse 1.4070885000745985\n",
      "New best model found at epoch 239 with validation loss 1.4070883989334106\n",
      "Starting Epoch 240\n",
      "1.4283055315415065\n",
      "Validation loss: 1.4066557884216309\n",
      "mse 1.406655753366604\n",
      "New best model found at epoch 240 with validation loss 1.4066557884216309\n",
      "Starting Epoch 241\n",
      "1.4277814676364262\n",
      "Validation loss: 1.4064334630966187\n",
      "mse 1.4064334573197326\n",
      "New best model found at epoch 241 with validation loss 1.4064334630966187\n",
      "Starting Epoch 242\n",
      "1.4273847192525864\n",
      "Validation loss: 1.405968189239502\n",
      "mse 1.405968099107006\n",
      "New best model found at epoch 242 with validation loss 1.405968189239502\n",
      "Starting Epoch 243\n",
      "1.4268839955329895\n",
      "Validation loss: 1.4057806730270386\n",
      "mse 1.4057807227798498\n",
      "New best model found at epoch 243 with validation loss 1.4057806730270386\n",
      "Starting Epoch 244\n",
      "1.4265367289384205\n",
      "Validation loss: 1.4052610397338867\n",
      "mse 1.4052609334438628\n",
      "New best model found at epoch 244 with validation loss 1.4052610397338867\n",
      "Starting Epoch 245\n",
      "1.4260035107533138\n",
      "Validation loss: 1.405023455619812\n",
      "mse 1.405023504895961\n",
      "New best model found at epoch 245 with validation loss 1.405023455619812\n",
      "Starting Epoch 246\n",
      "1.4256222148736317\n",
      "Validation loss: 1.404693603515625\n",
      "mse 1.4046935794220452\n",
      "New best model found at epoch 246 with validation loss 1.404693603515625\n",
      "Starting Epoch 247\n",
      "1.4252140372991562\n",
      "Validation loss: 1.404241681098938\n",
      "mse 1.4042417192695094\n",
      "New best model found at epoch 247 with validation loss 1.404241681098938\n",
      "Starting Epoch 248\n",
      "1.4246848970651627\n",
      "Validation loss: 1.4040387868881226\n",
      "mse 1.404038864672318\n",
      "New best model found at epoch 248 with validation loss 1.4040387868881226\n",
      "Starting Epoch 249\n",
      "1.4243371436993282\n",
      "Validation loss: 1.4040522575378418\n",
      "mse 1.404052291683013\n",
      "Starting Epoch 250\n",
      "1.4239779909451802\n",
      "Validation loss: 1.4034581184387207\n",
      "mse 1.4034580659957039\n",
      "New best model found at epoch 250 with validation loss 1.4034581184387207\n",
      "Starting Epoch 251\n",
      "1.4234646658102672\n",
      "Validation loss: 1.4030694961547852\n",
      "mse 1.403069555359885\n",
      "New best model found at epoch 251 with validation loss 1.4030694961547852\n",
      "Starting Epoch 252\n",
      "1.4230781843264897\n",
      "Validation loss: 1.402762532234192\n",
      "mse 1.4027625882836174\n",
      "New best model found at epoch 252 with validation loss 1.402762532234192\n",
      "Starting Epoch 253\n",
      "1.4225919644037883\n",
      "Validation loss: 1.4025940895080566\n",
      "mse 1.4025940950928306\n",
      "New best model found at epoch 253 with validation loss 1.4025940895080566\n",
      "Starting Epoch 254\n",
      "1.4222641587257385\n",
      "Validation loss: 1.4024956226348877\n",
      "mse 1.4024956055662678\n",
      "New best model found at epoch 254 with validation loss 1.4024956226348877\n",
      "Starting Epoch 255\n",
      "1.4218863447507222\n",
      "Validation loss: 1.4019017219543457\n",
      "mse 1.4019017553435142\n",
      "New best model found at epoch 255 with validation loss 1.4019017219543457\n",
      "Starting Epoch 256\n",
      "1.4214142113924026\n",
      "Validation loss: 1.4015653133392334\n",
      "mse 1.4015653523574956\n",
      "New best model found at epoch 256 with validation loss 1.4015653133392334\n",
      "Starting Epoch 257\n",
      "1.4209391524394352\n",
      "Validation loss: 1.4013090133666992\n",
      "mse 1.4013089398064327\n",
      "New best model found at epoch 257 with validation loss 1.4013090133666992\n",
      "Starting Epoch 258\n",
      "1.420535405476888\n",
      "Validation loss: 1.401482343673706\n",
      "mse 1.4014824694243369\n",
      "Starting Epoch 259\n",
      "1.420232857267062\n",
      "Validation loss: 1.4008376598358154\n",
      "mse 1.4008377796932525\n",
      "New best model found at epoch 259 with validation loss 1.4008376598358154\n",
      "Starting Epoch 260\n",
      "1.4198171645402908\n",
      "Validation loss: 1.4003649950027466\n",
      "mse 1.4003651657951912\n",
      "New best model found at epoch 260 with validation loss 1.4003649950027466\n",
      "Starting Epoch 261\n",
      "1.4194046060244243\n",
      "Validation loss: 1.4003292322158813\n",
      "mse 1.4003292414229562\n",
      "New best model found at epoch 261 with validation loss 1.4003292322158813\n",
      "Starting Epoch 262\n",
      "1.419034590323766\n",
      "Validation loss: 1.3997626304626465\n",
      "mse 1.3997626465762616\n",
      "New best model found at epoch 262 with validation loss 1.3997626304626465\n",
      "Starting Epoch 263\n",
      "1.4185593922932942\n",
      "Validation loss: 1.3998446464538574\n",
      "mse 1.3998447265389566\n",
      "Starting Epoch 264\n",
      "1.418248936533928\n",
      "Validation loss: 1.3992083072662354\n",
      "mse 1.3992083686990326\n",
      "New best model found at epoch 264 with validation loss 1.3992083072662354\n",
      "Starting Epoch 265\n",
      "1.41777998705705\n",
      "Validation loss: 1.399166464805603\n",
      "mse 1.399166573512579\n",
      "New best model found at epoch 265 with validation loss 1.399166464805603\n",
      "Starting Epoch 266\n",
      "1.4174518932898839\n",
      "Validation loss: 1.3984949588775635\n",
      "mse 1.398495069567968\n",
      "New best model found at epoch 266 with validation loss 1.3984949588775635\n",
      "Starting Epoch 267\n",
      "1.4170033882061641\n",
      "Validation loss: 1.398518443107605\n",
      "mse 1.398518413920916\n",
      "Starting Epoch 268\n",
      "1.416633779803912\n",
      "Validation loss: 1.3979616165161133\n",
      "mse 1.397961441267728\n",
      "New best model found at epoch 268 with validation loss 1.3979616165161133\n",
      "Starting Epoch 269\n",
      "1.4162220259507496\n",
      "Validation loss: 1.3979511260986328\n",
      "mse 1.3979510505590393\n",
      "New best model found at epoch 269 with validation loss 1.3979511260986328\n",
      "Starting Epoch 270\n",
      "1.415916845202446\n",
      "Validation loss: 1.3967560529708862\n",
      "mse 1.3967560778762513\n",
      "New best model found at epoch 270 with validation loss 1.3967560529708862\n",
      "Starting Epoch 271\n",
      "1.4154145866632462\n",
      "Validation loss: 1.3973100185394287\n",
      "mse 1.3973100059004344\n",
      "Starting Epoch 272\n",
      "1.4151640087366104\n",
      "Validation loss: 1.3961315155029297\n",
      "mse 1.3961315336284716\n",
      "New best model found at epoch 272 with validation loss 1.3961315155029297\n",
      "Starting Epoch 273\n",
      "1.414645751317342\n",
      "Validation loss: 1.3967398405075073\n",
      "mse 1.3967398383818046\n",
      "Starting Epoch 274\n",
      "1.4143921732902527\n",
      "Validation loss: 1.3955705165863037\n",
      "mse 1.3955706038677533\n",
      "New best model found at epoch 274 with validation loss 1.3955705165863037\n",
      "Starting Epoch 275\n",
      "1.4139450242122014\n",
      "Validation loss: 1.3960367441177368\n",
      "mse 1.396036813353846\n",
      "Starting Epoch 276\n",
      "1.4135262568791707\n",
      "Validation loss: 1.3955414295196533\n",
      "mse 1.3955414416987024\n",
      "New best model found at epoch 276 with validation loss 1.3955414295196533\n",
      "Starting Epoch 277\n",
      "1.413168693582217\n",
      "Validation loss: 1.3953527212142944\n",
      "mse 1.3953527634408363\n",
      "New best model found at epoch 277 with validation loss 1.3953527212142944\n",
      "Starting Epoch 278\n",
      "1.4128297468026478\n",
      "Validation loss: 1.3953298330307007\n",
      "mse 1.3953298815729416\n",
      "New best model found at epoch 278 with validation loss 1.3953298330307007\n",
      "Starting Epoch 279\n",
      "1.412481312950452\n",
      "Validation loss: 1.3941906690597534\n",
      "mse 1.3941906203951553\n",
      "New best model found at epoch 279 with validation loss 1.3941906690597534\n",
      "Starting Epoch 280\n",
      "1.412048210700353\n",
      "Validation loss: 1.3947057723999023\n",
      "mse 1.394705769991141\n",
      "Starting Epoch 281\n",
      "1.411694089571635\n",
      "Validation loss: 1.3940566778182983\n",
      "mse 1.3940567942515911\n",
      "New best model found at epoch 281 with validation loss 1.3940566778182983\n",
      "Starting Epoch 282\n",
      "1.411317800482114\n",
      "Validation loss: 1.393877625465393\n",
      "mse 1.3938776540250133\n",
      "New best model found at epoch 282 with validation loss 1.393877625465393\n",
      "Starting Epoch 283\n",
      "1.4109737326701481\n",
      "Validation loss: 1.3938629627227783\n",
      "mse 1.3938628550985372\n",
      "New best model found at epoch 283 with validation loss 1.3938629627227783\n",
      "Starting Epoch 284\n",
      "1.4106500645478566\n",
      "Validation loss: 1.3927518129348755\n",
      "mse 1.3927519358282552\n",
      "New best model found at epoch 284 with validation loss 1.3927518129348755\n",
      "Starting Epoch 285\n",
      "1.4102153182029724\n",
      "Validation loss: 1.3932210206985474\n",
      "mse 1.3932210543414683\n",
      "Starting Epoch 286\n",
      "1.4098717073599498\n",
      "Validation loss: 1.3926362991333008\n",
      "mse 1.392636175273277\n",
      "New best model found at epoch 286 with validation loss 1.3926362991333008\n",
      "Starting Epoch 287\n",
      "1.409500350554784\n",
      "Validation loss: 1.3924604654312134\n",
      "mse 1.3924603969273701\n",
      "New best model found at epoch 287 with validation loss 1.3924604654312134\n",
      "Starting Epoch 288\n",
      "1.409163196881612\n",
      "Validation loss: 1.3923442363739014\n",
      "mse 1.3923443242587\n",
      "New best model found at epoch 288 with validation loss 1.3923442363739014\n",
      "Starting Epoch 289\n",
      "1.40874582529068\n",
      "Validation loss: 1.3918030261993408\n",
      "mse 1.391803096309728\n",
      "New best model found at epoch 289 with validation loss 1.3918030261993408\n",
      "Starting Epoch 290\n",
      "1.4083983798821766\n",
      "Validation loss: 1.391579270362854\n",
      "mse 1.391579131162699\n",
      "New best model found at epoch 290 with validation loss 1.391579270362854\n",
      "Starting Epoch 291\n",
      "1.4080637047688167\n",
      "Validation loss: 1.3914995193481445\n",
      "mse 1.3914995933274714\n",
      "New best model found at epoch 291 with validation loss 1.3914995193481445\n",
      "Starting Epoch 292\n",
      "1.4077008962631226\n",
      "Validation loss: 1.3909343481063843\n",
      "mse 1.390934382859032\n",
      "New best model found at epoch 292 with validation loss 1.3909343481063843\n",
      "Starting Epoch 293\n",
      "1.4073003828525543\n",
      "Validation loss: 1.3908549547195435\n",
      "mse 1.390855051447151\n",
      "New best model found at epoch 293 with validation loss 1.3908549547195435\n",
      "Starting Epoch 294\n",
      "1.406959240635236\n",
      "Validation loss: 1.3903216123580933\n",
      "mse 1.3903215176296617\n",
      "New best model found at epoch 294 with validation loss 1.3903216123580933\n",
      "Starting Epoch 295\n",
      "1.406587744752566\n",
      "Validation loss: 1.390191912651062\n",
      "mse 1.3901917668515247\n",
      "New best model found at epoch 295 with validation loss 1.390191912651062\n",
      "Starting Epoch 296\n",
      "1.4061947514613469\n",
      "Validation loss: 1.3896307945251465\n",
      "mse 1.3896308877595964\n",
      "New best model found at epoch 296 with validation loss 1.3896307945251465\n",
      "Starting Epoch 297\n",
      "1.4058726330598195\n",
      "Validation loss: 1.3892799615859985\n",
      "mse 1.3892799960134017\n",
      "New best model found at epoch 297 with validation loss 1.3892799615859985\n",
      "Starting Epoch 298\n",
      "1.405481646458308\n",
      "Validation loss: 1.3892269134521484\n",
      "mse 1.3892268296663506\n",
      "New best model found at epoch 298 with validation loss 1.3892269134521484\n",
      "Starting Epoch 299\n",
      "1.4050752421220143\n",
      "Validation loss: 1.3887858390808105\n",
      "mse 1.3887856804402638\n",
      "New best model found at epoch 299 with validation loss 1.3887858390808105\n",
      "Starting Epoch 300\n",
      "1.404809723297755\n",
      "Validation loss: 1.3885109424591064\n",
      "mse 1.3885109529875417\n",
      "New best model found at epoch 300 with validation loss 1.3885109424591064\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-60-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94d16c-f981-498f-bbf2-5d335b8b72ec",
   "metadata": {},
   "source": [
    "#### 4-layer MLP\n",
    "*  Loss: MSE\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb20c43",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 10 - 5 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f72895bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "0e5f2d2a-72ff-4e8a-8eb5-1b9bb946c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.583277632792791\n",
      "Validation loss: 2.4190306663513184\n",
      "mse 2.4190305481166923\n",
      "New best model found at epoch 1 with validation loss 2.4190306663513184\n",
      "Starting Epoch 2\n",
      "2.2515040139357247\n",
      "Validation loss: 2.1765105724334717\n",
      "mse 2.176510427922961\n",
      "New best model found at epoch 2 with validation loss 2.1765105724334717\n",
      "Starting Epoch 3\n",
      "2.1194065312544503\n",
      "Validation loss: 2.059854507446289\n",
      "mse 2.0598543325146492\n",
      "New best model found at epoch 3 with validation loss 2.059854507446289\n",
      "Starting Epoch 4\n",
      "2.053546205163002\n",
      "Validation loss: 2.0059611797332764\n",
      "mse 2.005961240507063\n",
      "New best model found at epoch 4 with validation loss 2.0059611797332764\n",
      "Starting Epoch 5\n",
      "2.018025820453962\n",
      "Validation loss: 1.9757734537124634\n",
      "mse 1.975773362198051\n",
      "New best model found at epoch 5 with validation loss 1.9757734537124634\n",
      "Starting Epoch 6\n",
      "1.9946102251609166\n",
      "Validation loss: 1.9513157606124878\n",
      "mse 1.9513157684955051\n",
      "New best model found at epoch 6 with validation loss 1.9513157606124878\n",
      "Starting Epoch 7\n",
      "1.97698375582695\n",
      "Validation loss: 1.9323430061340332\n",
      "mse 1.9323430266787216\n",
      "New best model found at epoch 7 with validation loss 1.9323430061340332\n",
      "Starting Epoch 8\n",
      "1.9621494958798091\n",
      "Validation loss: 1.9133292436599731\n",
      "mse 1.9133290262067364\n",
      "New best model found at epoch 8 with validation loss 1.9133292436599731\n",
      "Starting Epoch 9\n",
      "1.948411504427592\n",
      "Validation loss: 1.8977285623550415\n",
      "mse 1.8977286745725392\n",
      "New best model found at epoch 9 with validation loss 1.8977285623550415\n",
      "Starting Epoch 10\n",
      "1.936672255396843\n",
      "Validation loss: 1.8839794397354126\n",
      "mse 1.883979391141858\n",
      "New best model found at epoch 10 with validation loss 1.8839794397354126\n",
      "Starting Epoch 11\n",
      "1.9266207019488018\n",
      "Validation loss: 1.873063564300537\n",
      "mse 1.8730635305929682\n",
      "New best model found at epoch 11 with validation loss 1.873063564300537\n",
      "Starting Epoch 12\n",
      "1.9173393547534943\n",
      "Validation loss: 1.8623671531677246\n",
      "mse 1.862367058246135\n",
      "New best model found at epoch 12 with validation loss 1.8623671531677246\n",
      "Starting Epoch 13\n",
      "1.9084564248720806\n",
      "Validation loss: 1.852551817893982\n",
      "mse 1.85255161627049\n",
      "New best model found at epoch 13 with validation loss 1.852551817893982\n",
      "Starting Epoch 14\n",
      "1.8999832024176915\n",
      "Validation loss: 1.8427714109420776\n",
      "mse 1.8427712337272826\n",
      "New best model found at epoch 14 with validation loss 1.8427714109420776\n",
      "Starting Epoch 15\n",
      "1.890935609738032\n",
      "Validation loss: 1.832857608795166\n",
      "mse 1.832857535445445\n",
      "New best model found at epoch 15 with validation loss 1.832857608795166\n",
      "Starting Epoch 16\n",
      "1.8820783197879791\n",
      "Validation loss: 1.822393536567688\n",
      "mse 1.8223936455271026\n",
      "New best model found at epoch 16 with validation loss 1.822393536567688\n",
      "Starting Epoch 17\n",
      "1.8734416266282399\n",
      "Validation loss: 1.8132965564727783\n",
      "mse 1.8132965436713184\n",
      "New best model found at epoch 17 with validation loss 1.8132965564727783\n",
      "Starting Epoch 18\n",
      "1.8652497331301372\n",
      "Validation loss: 1.8044852018356323\n",
      "mse 1.8044853437022714\n",
      "New best model found at epoch 18 with validation loss 1.8044852018356323\n",
      "Starting Epoch 19\n",
      "1.8573817163705826\n",
      "Validation loss: 1.795663833618164\n",
      "mse 1.7956637753125166\n",
      "New best model found at epoch 19 with validation loss 1.795663833618164\n",
      "Starting Epoch 20\n",
      "1.8496780792872112\n",
      "Validation loss: 1.78751540184021\n",
      "mse 1.7875152273324253\n",
      "New best model found at epoch 20 with validation loss 1.78751540184021\n",
      "Starting Epoch 21\n",
      "1.8422448982795079\n",
      "Validation loss: 1.778943419456482\n",
      "mse 1.7789435278053498\n",
      "New best model found at epoch 21 with validation loss 1.778943419456482\n",
      "Starting Epoch 22\n",
      "1.8347908904155095\n",
      "Validation loss: 1.770761489868164\n",
      "mse 1.7707616110412794\n",
      "New best model found at epoch 22 with validation loss 1.770761489868164\n",
      "Starting Epoch 23\n",
      "1.827533667286237\n",
      "Validation loss: 1.762679100036621\n",
      "mse 1.7626790473189158\n",
      "New best model found at epoch 23 with validation loss 1.762679100036621\n",
      "Starting Epoch 24\n",
      "1.8203586637973785\n",
      "Validation loss: 1.7547610998153687\n",
      "mse 1.7547612917079973\n",
      "New best model found at epoch 24 with validation loss 1.7547610998153687\n",
      "Starting Epoch 25\n",
      "1.8132993628581364\n",
      "Validation loss: 1.7468501329421997\n",
      "mse 1.7468500959644697\n",
      "New best model found at epoch 25 with validation loss 1.7468501329421997\n",
      "Starting Epoch 26\n",
      "1.806368201971054\n",
      "Validation loss: 1.7394682168960571\n",
      "mse 1.7394682220084126\n",
      "New best model found at epoch 26 with validation loss 1.7394682168960571\n",
      "Starting Epoch 27\n",
      "1.7995619972546895\n",
      "Validation loss: 1.732127070426941\n",
      "mse 1.7321269609740146\n",
      "New best model found at epoch 27 with validation loss 1.732127070426941\n",
      "Starting Epoch 28\n",
      "1.7928992956876755\n",
      "Validation loss: 1.72489595413208\n",
      "mse 1.7248960481092004\n",
      "New best model found at epoch 28 with validation loss 1.72489595413208\n",
      "Starting Epoch 29\n",
      "1.7863981525103252\n",
      "Validation loss: 1.717458724975586\n",
      "mse 1.717458854116595\n",
      "New best model found at epoch 29 with validation loss 1.717458724975586\n",
      "Starting Epoch 30\n",
      "1.7799374610185623\n",
      "Validation loss: 1.7104564905166626\n",
      "mse 1.7104564564597264\n",
      "New best model found at epoch 30 with validation loss 1.7104564905166626\n",
      "Starting Epoch 31\n",
      "1.773759717742602\n",
      "Validation loss: 1.7035480737686157\n",
      "mse 1.7035480742006621\n",
      "New best model found at epoch 31 with validation loss 1.7035480737686157\n",
      "Starting Epoch 32\n",
      "1.7677058180173237\n",
      "Validation loss: 1.6966087818145752\n",
      "mse 1.6966087929606721\n",
      "New best model found at epoch 32 with validation loss 1.6966087818145752\n",
      "Starting Epoch 33\n",
      "1.761776253581047\n",
      "Validation loss: 1.6894710063934326\n",
      "mse 1.6894711792838175\n",
      "New best model found at epoch 33 with validation loss 1.6894710063934326\n",
      "Starting Epoch 34\n",
      "1.7561683853467305\n",
      "Validation loss: 1.6833486557006836\n",
      "mse 1.6833485335322942\n",
      "New best model found at epoch 34 with validation loss 1.6833486557006836\n",
      "Starting Epoch 35\n",
      "1.7506905843814213\n",
      "Validation loss: 1.6774773597717285\n",
      "mse 1.6774772799848023\n",
      "New best model found at epoch 35 with validation loss 1.6774773597717285\n",
      "Starting Epoch 36\n",
      "1.7450011571248372\n",
      "Validation loss: 1.6715397834777832\n",
      "mse 1.671539864634796\n",
      "New best model found at epoch 36 with validation loss 1.6715397834777832\n",
      "Starting Epoch 37\n",
      "1.7394057561953862\n",
      "Validation loss: 1.6658891439437866\n",
      "mse 1.6658891214485503\n",
      "New best model found at epoch 37 with validation loss 1.6658891439437866\n",
      "Starting Epoch 38\n",
      "1.733972763021787\n",
      "Validation loss: 1.6598867177963257\n",
      "mse 1.6598868190696405\n",
      "New best model found at epoch 38 with validation loss 1.6598867177963257\n",
      "Starting Epoch 39\n",
      "1.7288549989461899\n",
      "Validation loss: 1.6543020009994507\n",
      "mse 1.6543018895116768\n",
      "New best model found at epoch 39 with validation loss 1.6543020009994507\n",
      "Starting Epoch 40\n",
      "1.7237473676602046\n",
      "Validation loss: 1.6488385200500488\n",
      "mse 1.6488384490027554\n",
      "New best model found at epoch 40 with validation loss 1.6488385200500488\n",
      "Starting Epoch 41\n",
      "1.7188554604848225\n",
      "Validation loss: 1.6434684991836548\n",
      "mse 1.6434685296486666\n",
      "New best model found at epoch 41 with validation loss 1.6434684991836548\n",
      "Starting Epoch 42\n",
      "1.7140882164239883\n",
      "Validation loss: 1.638726830482483\n",
      "mse 1.638726829878029\n",
      "New best model found at epoch 42 with validation loss 1.638726830482483\n",
      "Starting Epoch 43\n",
      "1.7095857659975688\n",
      "Validation loss: 1.6337660551071167\n",
      "mse 1.6337661412480922\n",
      "New best model found at epoch 43 with validation loss 1.6337660551071167\n",
      "Starting Epoch 44\n",
      "1.7053095996379852\n",
      "Validation loss: 1.6287354230880737\n",
      "mse 1.6287354471348472\n",
      "New best model found at epoch 44 with validation loss 1.6287354230880737\n",
      "Starting Epoch 45\n",
      "1.7011091709136963\n",
      "Validation loss: 1.6237623691558838\n",
      "mse 1.62376226176735\n",
      "New best model found at epoch 45 with validation loss 1.6237623691558838\n",
      "Starting Epoch 46\n",
      "1.6970327844222386\n",
      "Validation loss: 1.6191586256027222\n",
      "mse 1.6191585760893639\n",
      "New best model found at epoch 46 with validation loss 1.6191586256027222\n",
      "Starting Epoch 47\n",
      "1.693070501089096\n",
      "Validation loss: 1.6149473190307617\n",
      "mse 1.6149473352901733\n",
      "New best model found at epoch 47 with validation loss 1.6149473190307617\n",
      "Starting Epoch 48\n",
      "1.6892165541648865\n",
      "Validation loss: 1.610810399055481\n",
      "mse 1.6108103437215633\n",
      "New best model found at epoch 48 with validation loss 1.610810399055481\n",
      "Starting Epoch 49\n",
      "1.685510481397311\n",
      "Validation loss: 1.6069588661193848\n",
      "mse 1.6069588420205987\n",
      "New best model found at epoch 49 with validation loss 1.6069588661193848\n",
      "Starting Epoch 50\n",
      "1.681950494647026\n",
      "Validation loss: 1.6026805639266968\n",
      "mse 1.602680617142148\n",
      "New best model found at epoch 50 with validation loss 1.6026805639266968\n",
      "Starting Epoch 51\n",
      "1.6783298303683598\n",
      "Validation loss: 1.5985872745513916\n",
      "mse 1.5985873216098012\n",
      "New best model found at epoch 51 with validation loss 1.5985872745513916\n",
      "Starting Epoch 52\n",
      "1.6748070220152538\n",
      "Validation loss: 1.5947264432907104\n",
      "mse 1.5947264681853706\n",
      "New best model found at epoch 52 with validation loss 1.5947264432907104\n",
      "Starting Epoch 53\n",
      "1.6714598884185154\n",
      "Validation loss: 1.5908195972442627\n",
      "mse 1.590819764260781\n",
      "New best model found at epoch 53 with validation loss 1.5908195972442627\n",
      "Starting Epoch 54\n",
      "1.6681298464536667\n",
      "Validation loss: 1.587082028388977\n",
      "mse 1.5870819842959394\n",
      "New best model found at epoch 54 with validation loss 1.587082028388977\n",
      "Starting Epoch 55\n",
      "1.664940968155861\n",
      "Validation loss: 1.583622694015503\n",
      "mse 1.5836227628285158\n",
      "New best model found at epoch 55 with validation loss 1.583622694015503\n",
      "Starting Epoch 56\n",
      "1.6619018763303757\n",
      "Validation loss: 1.5799641609191895\n",
      "mse 1.579964097505818\n",
      "New best model found at epoch 56 with validation loss 1.5799641609191895\n",
      "Starting Epoch 57\n",
      "1.6588137398163478\n",
      "Validation loss: 1.5769749879837036\n",
      "mse 1.5769749716946306\n",
      "New best model found at epoch 57 with validation loss 1.5769749879837036\n",
      "Starting Epoch 58\n",
      "1.655944695075353\n",
      "Validation loss: 1.5739669799804688\n",
      "mse 1.5739670337255496\n",
      "New best model found at epoch 58 with validation loss 1.5739669799804688\n",
      "Starting Epoch 59\n",
      "1.6527949124574661\n",
      "Validation loss: 1.5709919929504395\n",
      "mse 1.570992090900457\n",
      "New best model found at epoch 59 with validation loss 1.5709919929504395\n",
      "Starting Epoch 60\n",
      "1.6496940553188324\n",
      "Validation loss: 1.567899227142334\n",
      "mse 1.5678992341105444\n",
      "New best model found at epoch 60 with validation loss 1.567899227142334\n",
      "Starting Epoch 61\n",
      "1.646618554989497\n",
      "Validation loss: 1.5650371313095093\n",
      "mse 1.5650370672839498\n",
      "New best model found at epoch 61 with validation loss 1.5650371313095093\n",
      "Starting Epoch 62\n",
      "1.6436231036980946\n",
      "Validation loss: 1.5622000694274902\n",
      "mse 1.5622000109062588\n",
      "New best model found at epoch 62 with validation loss 1.5622000694274902\n",
      "Starting Epoch 63\n",
      "1.6406754851341248\n",
      "Validation loss: 1.5594494342803955\n",
      "mse 1.5594493918750323\n",
      "New best model found at epoch 63 with validation loss 1.5594494342803955\n",
      "Starting Epoch 64\n",
      "1.6378721445798874\n",
      "Validation loss: 1.5566967725753784\n",
      "mse 1.5566967311436657\n",
      "New best model found at epoch 64 with validation loss 1.5566967725753784\n",
      "Starting Epoch 65\n",
      "1.6348681698242824\n",
      "Validation loss: 1.5531601905822754\n",
      "mse 1.5531601911183832\n",
      "New best model found at epoch 65 with validation loss 1.5531601905822754\n",
      "Starting Epoch 66\n",
      "1.6305096298456192\n",
      "Validation loss: 1.5486741065979004\n",
      "mse 1.5486741955288332\n",
      "New best model found at epoch 66 with validation loss 1.5486741065979004\n",
      "Starting Epoch 67\n",
      "1.626122698187828\n",
      "Validation loss: 1.5442432165145874\n",
      "mse 1.5442432596061728\n",
      "New best model found at epoch 67 with validation loss 1.5442432165145874\n",
      "Starting Epoch 68\n",
      "1.6218633999427159\n",
      "Validation loss: 1.5403138399124146\n",
      "mse 1.5403137706932493\n",
      "New best model found at epoch 68 with validation loss 1.5403138399124146\n",
      "Starting Epoch 69\n",
      "1.6175760229428608\n",
      "Validation loss: 1.5365784168243408\n",
      "mse 1.5365783462725018\n",
      "New best model found at epoch 69 with validation loss 1.5365784168243408\n",
      "Starting Epoch 70\n",
      "1.6131139695644379\n",
      "Validation loss: 1.5327961444854736\n",
      "mse 1.5327960757780688\n",
      "New best model found at epoch 70 with validation loss 1.5327961444854736\n",
      "Starting Epoch 71\n",
      "1.6090706090132396\n",
      "Validation loss: 1.529435634613037\n",
      "mse 1.5294356804563107\n",
      "New best model found at epoch 71 with validation loss 1.529435634613037\n",
      "Starting Epoch 72\n",
      "1.605206236243248\n",
      "Validation loss: 1.5265185832977295\n",
      "mse 1.5265186966333424\n",
      "New best model found at epoch 72 with validation loss 1.5265185832977295\n",
      "Starting Epoch 73\n",
      "1.6014398038387299\n",
      "Validation loss: 1.523438572883606\n",
      "mse 1.523438460081856\n",
      "New best model found at epoch 73 with validation loss 1.523438572883606\n",
      "Starting Epoch 74\n",
      "1.5977748036384583\n",
      "Validation loss: 1.5205219984054565\n",
      "mse 1.520521895481287\n",
      "New best model found at epoch 74 with validation loss 1.5205219984054565\n",
      "Starting Epoch 75\n",
      "1.59426545103391\n",
      "Validation loss: 1.517811894416809\n",
      "mse 1.5178118868911126\n",
      "New best model found at epoch 75 with validation loss 1.517811894416809\n",
      "Starting Epoch 76\n",
      "1.590722680091858\n",
      "Validation loss: 1.514843225479126\n",
      "mse 1.51484309037346\n",
      "New best model found at epoch 76 with validation loss 1.514843225479126\n",
      "Starting Epoch 77\n",
      "1.5867075473070145\n",
      "Validation loss: 1.5111830234527588\n",
      "mse 1.5111830887142434\n",
      "New best model found at epoch 77 with validation loss 1.5111830234527588\n",
      "Starting Epoch 78\n",
      "1.5827330847581227\n",
      "Validation loss: 1.507685661315918\n",
      "mse 1.5076857178185492\n",
      "New best model found at epoch 78 with validation loss 1.507685661315918\n",
      "Starting Epoch 79\n",
      "1.5788202385107677\n",
      "Validation loss: 1.5044159889221191\n",
      "mse 1.5044159753817268\n",
      "New best model found at epoch 79 with validation loss 1.5044159889221191\n",
      "Starting Epoch 80\n",
      "1.5751150945822399\n",
      "Validation loss: 1.50092613697052\n",
      "mse 1.500926024446767\n",
      "New best model found at epoch 80 with validation loss 1.50092613697052\n",
      "Starting Epoch 81\n",
      "1.5715621709823608\n",
      "Validation loss: 1.4975346326828003\n",
      "mse 1.4975346936277998\n",
      "New best model found at epoch 81 with validation loss 1.4975346326828003\n",
      "Starting Epoch 82\n",
      "1.5684946080048878\n",
      "Validation loss: 1.4946614503860474\n",
      "mse 1.4946614998085377\n",
      "New best model found at epoch 82 with validation loss 1.4946614503860474\n",
      "Starting Epoch 83\n",
      "1.5656906763712566\n",
      "Validation loss: 1.4922659397125244\n",
      "mse 1.4922659896653099\n",
      "New best model found at epoch 83 with validation loss 1.4922659397125244\n",
      "Starting Epoch 84\n",
      "1.5630272775888443\n",
      "Validation loss: 1.490135669708252\n",
      "mse 1.4901355760305142\n",
      "New best model found at epoch 84 with validation loss 1.490135669708252\n",
      "Starting Epoch 85\n",
      "1.5604950735966365\n",
      "Validation loss: 1.4882174730300903\n",
      "mse 1.4882175047802415\n",
      "New best model found at epoch 85 with validation loss 1.4882174730300903\n",
      "Starting Epoch 86\n",
      "1.5580113182465236\n",
      "Validation loss: 1.4864133596420288\n",
      "mse 1.4864133313535246\n",
      "New best model found at epoch 86 with validation loss 1.4864133596420288\n",
      "Starting Epoch 87\n",
      "1.5555944939454396\n",
      "Validation loss: 1.4842936992645264\n",
      "mse 1.4842937652714785\n",
      "New best model found at epoch 87 with validation loss 1.4842936992645264\n",
      "Starting Epoch 88\n",
      "1.5531708548466365\n",
      "Validation loss: 1.482539415359497\n",
      "mse 1.4825393358638586\n",
      "New best model found at epoch 88 with validation loss 1.482539415359497\n",
      "Starting Epoch 89\n",
      "1.5508269220590591\n",
      "Validation loss: 1.4809255599975586\n",
      "mse 1.4809254358633959\n",
      "New best model found at epoch 89 with validation loss 1.4809255599975586\n",
      "Starting Epoch 90\n",
      "1.548578421274821\n",
      "Validation loss: 1.4791545867919922\n",
      "mse 1.4791546277945622\n",
      "New best model found at epoch 90 with validation loss 1.4791545867919922\n",
      "Starting Epoch 91\n",
      "1.5463556200265884\n",
      "Validation loss: 1.4776415824890137\n",
      "mse 1.477641604753717\n",
      "New best model found at epoch 91 with validation loss 1.4776415824890137\n",
      "Starting Epoch 92\n",
      "1.5442248334487279\n",
      "Validation loss: 1.476060152053833\n",
      "mse 1.4760602599563815\n",
      "New best model found at epoch 92 with validation loss 1.476060152053833\n",
      "Starting Epoch 93\n",
      "1.5421203325192134\n",
      "Validation loss: 1.4747896194458008\n",
      "mse 1.4747895180848256\n",
      "New best model found at epoch 93 with validation loss 1.4747896194458008\n",
      "Starting Epoch 94\n",
      "1.5400419284900029\n",
      "Validation loss: 1.4733699560165405\n",
      "mse 1.4733698978074334\n",
      "New best model found at epoch 94 with validation loss 1.4733699560165405\n",
      "Starting Epoch 95\n",
      "1.538124367594719\n",
      "Validation loss: 1.4715842008590698\n",
      "mse 1.4715841540460886\n",
      "New best model found at epoch 95 with validation loss 1.4715842008590698\n",
      "Starting Epoch 96\n",
      "1.5360129177570343\n",
      "Validation loss: 1.469910979270935\n",
      "mse 1.4699110051275326\n",
      "New best model found at epoch 96 with validation loss 1.469910979270935\n",
      "Starting Epoch 97\n",
      "1.5341244637966156\n",
      "Validation loss: 1.4687281847000122\n",
      "mse 1.4687281628222855\n",
      "New best model found at epoch 97 with validation loss 1.4687281847000122\n",
      "Starting Epoch 98\n",
      "1.5324374934037526\n",
      "Validation loss: 1.46720290184021\n",
      "mse 1.4672029262763688\n",
      "New best model found at epoch 98 with validation loss 1.46720290184021\n",
      "Starting Epoch 99\n",
      "1.5308144738276799\n",
      "Validation loss: 1.4663482904434204\n",
      "mse 1.4663481714376598\n",
      "New best model found at epoch 99 with validation loss 1.4663482904434204\n",
      "Starting Epoch 100\n",
      "1.5293509811162949\n",
      "Validation loss: 1.4651516675949097\n",
      "mse 1.4651516525000843\n",
      "New best model found at epoch 100 with validation loss 1.4651516675949097\n",
      "Starting Epoch 101\n",
      "1.5278564989566803\n",
      "Validation loss: 1.4642882347106934\n",
      "mse 1.4642880721584839\n",
      "New best model found at epoch 101 with validation loss 1.4642882347106934\n",
      "Starting Epoch 102\n",
      "1.526474192738533\n",
      "Validation loss: 1.4633067846298218\n",
      "mse 1.4633066668567467\n",
      "New best model found at epoch 102 with validation loss 1.4633067846298218\n",
      "Starting Epoch 103\n",
      "1.525077039996783\n",
      "Validation loss: 1.4624077081680298\n",
      "mse 1.4624076257344387\n",
      "New best model found at epoch 103 with validation loss 1.4624077081680298\n",
      "Starting Epoch 104\n",
      "1.523748258749644\n",
      "Validation loss: 1.4617254734039307\n",
      "mse 1.4617254526601071\n",
      "New best model found at epoch 104 with validation loss 1.4617254734039307\n",
      "Starting Epoch 105\n",
      "1.5224341650803883\n",
      "Validation loss: 1.4608194828033447\n",
      "mse 1.4608193456729994\n",
      "New best model found at epoch 105 with validation loss 1.4608194828033447\n",
      "Starting Epoch 106\n",
      "1.5211690664291382\n",
      "Validation loss: 1.46003258228302\n",
      "mse 1.4600326033614355\n",
      "New best model found at epoch 106 with validation loss 1.46003258228302\n",
      "Starting Epoch 107\n",
      "1.5199382851521175\n",
      "Validation loss: 1.4591325521469116\n",
      "mse 1.4591325704168712\n",
      "New best model found at epoch 107 with validation loss 1.4591325521469116\n",
      "Starting Epoch 108\n",
      "1.518690546353658\n",
      "Validation loss: 1.458322286605835\n",
      "mse 1.4583222374799065\n",
      "New best model found at epoch 108 with validation loss 1.458322286605835\n",
      "Starting Epoch 109\n",
      "1.5175307542085648\n",
      "Validation loss: 1.4575402736663818\n",
      "mse 1.4575403387569457\n",
      "New best model found at epoch 109 with validation loss 1.4575402736663818\n",
      "Starting Epoch 110\n",
      "1.5163955042759578\n",
      "Validation loss: 1.4568679332733154\n",
      "mse 1.4568678189960351\n",
      "New best model found at epoch 110 with validation loss 1.4568679332733154\n",
      "Starting Epoch 111\n",
      "1.5152821093797684\n",
      "Validation loss: 1.4561572074890137\n",
      "mse 1.4561570622669457\n",
      "New best model found at epoch 111 with validation loss 1.4561572074890137\n",
      "Starting Epoch 112\n",
      "1.514174963037173\n",
      "Validation loss: 1.455363392829895\n",
      "mse 1.4553634033368714\n",
      "New best model found at epoch 112 with validation loss 1.455363392829895\n",
      "Starting Epoch 113\n",
      "1.5131055762370427\n",
      "Validation loss: 1.4546235799789429\n",
      "mse 1.4546236445474185\n",
      "New best model found at epoch 113 with validation loss 1.4546235799789429\n",
      "Starting Epoch 114\n",
      "1.5120442509651184\n",
      "Validation loss: 1.4539244174957275\n",
      "mse 1.4539244867859302\n",
      "New best model found at epoch 114 with validation loss 1.4539244174957275\n",
      "Starting Epoch 115\n",
      "1.511010800798734\n",
      "Validation loss: 1.4532513618469238\n",
      "mse 1.4532514105676628\n",
      "New best model found at epoch 115 with validation loss 1.4532513618469238\n",
      "Starting Epoch 116\n",
      "1.5100434521834056\n",
      "Validation loss: 1.452497959136963\n",
      "mse 1.4524980287868912\n",
      "New best model found at epoch 116 with validation loss 1.452497959136963\n",
      "Starting Epoch 117\n",
      "1.5089914600054424\n",
      "Validation loss: 1.4518972635269165\n",
      "mse 1.4518970661667274\n",
      "New best model found at epoch 117 with validation loss 1.4518972635269165\n",
      "Starting Epoch 118\n",
      "1.5080086539189022\n",
      "Validation loss: 1.4510595798492432\n",
      "mse 1.4510595038173466\n",
      "New best model found at epoch 118 with validation loss 1.4510595798492432\n",
      "Starting Epoch 119\n",
      "1.5070042957862217\n",
      "Validation loss: 1.4504104852676392\n",
      "mse 1.4504105060083134\n",
      "New best model found at epoch 119 with validation loss 1.4504104852676392\n",
      "Starting Epoch 120\n",
      "1.506051744023959\n",
      "Validation loss: 1.4497466087341309\n",
      "mse 1.4497466142491664\n",
      "New best model found at epoch 120 with validation loss 1.4497466087341309\n",
      "Starting Epoch 121\n",
      "1.5050986111164093\n",
      "Validation loss: 1.4490385055541992\n",
      "mse 1.4490386267428834\n",
      "New best model found at epoch 121 with validation loss 1.4490385055541992\n",
      "Starting Epoch 122\n",
      "1.5041397164265315\n",
      "Validation loss: 1.4483639001846313\n",
      "mse 1.4483637369634283\n",
      "New best model found at epoch 122 with validation loss 1.4483639001846313\n",
      "Starting Epoch 123\n",
      "1.503198613723119\n",
      "Validation loss: 1.4475092887878418\n",
      "mse 1.4475092218431678\n",
      "New best model found at epoch 123 with validation loss 1.4475092887878418\n",
      "Starting Epoch 124\n",
      "1.502251868446668\n",
      "Validation loss: 1.4467949867248535\n",
      "mse 1.446795030951414\n",
      "New best model found at epoch 124 with validation loss 1.4467949867248535\n",
      "Starting Epoch 125\n",
      "1.501331443587939\n",
      "Validation loss: 1.4461113214492798\n",
      "mse 1.446111257992645\n",
      "New best model found at epoch 125 with validation loss 1.4461113214492798\n",
      "Starting Epoch 126\n",
      "1.5003710339466731\n",
      "Validation loss: 1.4456859827041626\n",
      "mse 1.4456858383522264\n",
      "New best model found at epoch 126 with validation loss 1.4456859827041626\n",
      "Starting Epoch 127\n",
      "1.499625712633133\n",
      "Validation loss: 1.4441709518432617\n",
      "mse 1.4441709855933018\n",
      "New best model found at epoch 127 with validation loss 1.4441709518432617\n",
      "Starting Epoch 128\n",
      "1.4985260864098866\n",
      "Validation loss: 1.4431947469711304\n",
      "mse 1.443194811071813\n",
      "New best model found at epoch 128 with validation loss 1.4431947469711304\n",
      "Starting Epoch 129\n",
      "1.4975197613239288\n",
      "Validation loss: 1.4423245191574097\n",
      "mse 1.442324462347461\n",
      "New best model found at epoch 129 with validation loss 1.4423245191574097\n",
      "Starting Epoch 130\n",
      "1.4965343326330185\n",
      "Validation loss: 1.4409035444259644\n",
      "mse 1.440903587256392\n",
      "New best model found at epoch 130 with validation loss 1.4409035444259644\n",
      "Starting Epoch 131\n",
      "1.4954438656568527\n",
      "Validation loss: 1.439977765083313\n",
      "mse 1.4399776631927108\n",
      "New best model found at epoch 131 with validation loss 1.439977765083313\n",
      "Starting Epoch 132\n",
      "1.494424467285474\n",
      "Validation loss: 1.4390884637832642\n",
      "mse 1.4390884011084508\n",
      "New best model found at epoch 132 with validation loss 1.4390884637832642\n",
      "Starting Epoch 133\n",
      "1.4934435784816742\n",
      "Validation loss: 1.4382286071777344\n",
      "mse 1.438228506711404\n",
      "New best model found at epoch 133 with validation loss 1.4382286071777344\n",
      "Starting Epoch 134\n",
      "1.4924711883068085\n",
      "Validation loss: 1.4376293420791626\n",
      "mse 1.4376293262934878\n",
      "New best model found at epoch 134 with validation loss 1.4376293420791626\n",
      "Starting Epoch 135\n",
      "1.4915663599967957\n",
      "Validation loss: 1.4366763830184937\n",
      "mse 1.4366763908375502\n",
      "New best model found at epoch 135 with validation loss 1.4366763830184937\n",
      "Starting Epoch 136\n",
      "1.4906276265780132\n",
      "Validation loss: 1.4353857040405273\n",
      "mse 1.435385743927675\n",
      "New best model found at epoch 136 with validation loss 1.4353857040405273\n",
      "Starting Epoch 137\n",
      "1.4894632945458095\n",
      "Validation loss: 1.4345088005065918\n",
      "mse 1.434508894442893\n",
      "New best model found at epoch 137 with validation loss 1.4345088005065918\n",
      "Starting Epoch 138\n",
      "1.4885150690873463\n",
      "Validation loss: 1.4335525035858154\n",
      "mse 1.4335524416937515\n",
      "New best model found at epoch 138 with validation loss 1.4335525035858154\n",
      "Starting Epoch 139\n",
      "1.4874182442824047\n",
      "Validation loss: 1.4331611394882202\n",
      "mse 1.433161002214425\n",
      "New best model found at epoch 139 with validation loss 1.4331611394882202\n",
      "Starting Epoch 140\n",
      "1.4865414053201675\n",
      "Validation loss: 1.432297706604004\n",
      "mse 1.4322978527350738\n",
      "New best model found at epoch 140 with validation loss 1.432297706604004\n",
      "Starting Epoch 141\n",
      "1.4854934761921565\n",
      "Validation loss: 1.4317270517349243\n",
      "mse 1.4317271429308185\n",
      "New best model found at epoch 141 with validation loss 1.4317270517349243\n",
      "Starting Epoch 142\n",
      "1.484617715080579\n",
      "Validation loss: 1.4309262037277222\n",
      "mse 1.4309262014641841\n",
      "New best model found at epoch 142 with validation loss 1.4309262037277222\n",
      "Starting Epoch 143\n",
      "1.4836319983005524\n",
      "Validation loss: 1.4305037260055542\n",
      "mse 1.430503711004166\n",
      "New best model found at epoch 143 with validation loss 1.4305037260055542\n",
      "Starting Epoch 144\n",
      "1.4827832927306492\n",
      "Validation loss: 1.4297654628753662\n",
      "mse 1.4297654816504095\n",
      "New best model found at epoch 144 with validation loss 1.4297654628753662\n",
      "Starting Epoch 145\n",
      "1.4818437149127324\n",
      "Validation loss: 1.4292384386062622\n",
      "mse 1.4292385559944796\n",
      "New best model found at epoch 145 with validation loss 1.4292384386062622\n",
      "Starting Epoch 146\n",
      "1.4809799244006474\n",
      "Validation loss: 1.4286491870880127\n",
      "mse 1.4286492093513004\n",
      "New best model found at epoch 146 with validation loss 1.4286491870880127\n",
      "Starting Epoch 147\n",
      "1.480076899131139\n",
      "Validation loss: 1.4280880689620972\n",
      "mse 1.4280880895285826\n",
      "New best model found at epoch 147 with validation loss 1.4280880689620972\n",
      "Starting Epoch 148\n",
      "1.4792184780041377\n",
      "Validation loss: 1.427558183670044\n",
      "mse 1.4275581692308594\n",
      "New best model found at epoch 148 with validation loss 1.427558183670044\n",
      "Starting Epoch 149\n",
      "1.478393519918124\n",
      "Validation loss: 1.4269940853118896\n",
      "mse 1.4269942175151815\n",
      "New best model found at epoch 149 with validation loss 1.4269940853118896\n",
      "Starting Epoch 150\n",
      "1.4775209079186122\n",
      "Validation loss: 1.4264928102493286\n",
      "mse 1.4264928686170129\n",
      "New best model found at epoch 150 with validation loss 1.4264928102493286\n",
      "Starting Epoch 151\n",
      "1.4767270982265472\n",
      "Validation loss: 1.4259532690048218\n",
      "mse 1.42595318566092\n",
      "New best model found at epoch 151 with validation loss 1.4259532690048218\n",
      "Starting Epoch 152\n",
      "1.4758739322423935\n",
      "Validation loss: 1.4253876209259033\n",
      "mse 1.4253876867268525\n",
      "New best model found at epoch 152 with validation loss 1.4253876209259033\n",
      "Starting Epoch 153\n",
      "1.4751028617223103\n",
      "Validation loss: 1.4248640537261963\n",
      "mse 1.4248639243767334\n",
      "New best model found at epoch 153 with validation loss 1.4248640537261963\n",
      "Starting Epoch 154\n",
      "1.474266345302264\n",
      "Validation loss: 1.4243853092193604\n",
      "mse 1.424385349563882\n",
      "New best model found at epoch 154 with validation loss 1.4243853092193604\n",
      "Starting Epoch 155\n",
      "1.4734722673892975\n",
      "Validation loss: 1.4239579439163208\n",
      "mse 1.4239580009440331\n",
      "New best model found at epoch 155 with validation loss 1.4239579439163208\n",
      "Starting Epoch 156\n",
      "1.472733587026596\n",
      "Validation loss: 1.4233026504516602\n",
      "mse 1.4233027813593622\n",
      "New best model found at epoch 156 with validation loss 1.4233026504516602\n",
      "Starting Epoch 157\n",
      "1.4718760500351589\n",
      "Validation loss: 1.4229806661605835\n",
      "mse 1.4229806481493217\n",
      "New best model found at epoch 157 with validation loss 1.4229806661605835\n",
      "Starting Epoch 158\n",
      "1.4711744636297226\n",
      "Validation loss: 1.4225685596466064\n",
      "mse 1.4225685320266637\n",
      "New best model found at epoch 158 with validation loss 1.4225685596466064\n",
      "Starting Epoch 159\n",
      "1.470418855547905\n",
      "Validation loss: 1.4220340251922607\n",
      "mse 1.422034030926399\n",
      "New best model found at epoch 159 with validation loss 1.4220340251922607\n",
      "Starting Epoch 160\n",
      "1.4696739514668782\n",
      "Validation loss: 1.4215588569641113\n",
      "mse 1.421558898452879\n",
      "New best model found at epoch 160 with validation loss 1.4215588569641113\n",
      "Starting Epoch 161\n",
      "1.4689381370941799\n",
      "Validation loss: 1.4210976362228394\n",
      "mse 1.4210975972282158\n",
      "New best model found at epoch 161 with validation loss 1.4210976362228394\n",
      "Starting Epoch 162\n",
      "1.468182161450386\n",
      "Validation loss: 1.420727014541626\n",
      "mse 1.4207270713454596\n",
      "New best model found at epoch 162 with validation loss 1.420727014541626\n",
      "Starting Epoch 163\n",
      "1.4674782902002335\n",
      "Validation loss: 1.4203765392303467\n",
      "mse 1.4203766503178918\n",
      "New best model found at epoch 163 with validation loss 1.4203765392303467\n",
      "Starting Epoch 164\n",
      "1.466828351219495\n",
      "Validation loss: 1.4197076559066772\n",
      "mse 1.4197077608285043\n",
      "New best model found at epoch 164 with validation loss 1.4197076559066772\n",
      "Starting Epoch 165\n",
      "1.4660606533288956\n",
      "Validation loss: 1.4193819761276245\n",
      "mse 1.4193819201131532\n",
      "New best model found at epoch 165 with validation loss 1.4193819761276245\n",
      "Starting Epoch 166\n",
      "1.4653903394937515\n",
      "Validation loss: 1.4188069105148315\n",
      "mse 1.418806847027537\n",
      "New best model found at epoch 166 with validation loss 1.4188069105148315\n",
      "Starting Epoch 167\n",
      "1.4647183418273926\n",
      "Validation loss: 1.418312907218933\n",
      "mse 1.418312830403678\n",
      "New best model found at epoch 167 with validation loss 1.418312907218933\n",
      "Starting Epoch 168\n",
      "1.4639627436796825\n",
      "Validation loss: 1.4179518222808838\n",
      "mse 1.4179518347315412\n",
      "New best model found at epoch 168 with validation loss 1.4179518222808838\n",
      "Starting Epoch 169\n",
      "1.4633387476205826\n",
      "Validation loss: 1.417407512664795\n",
      "mse 1.4174074929101124\n",
      "New best model found at epoch 169 with validation loss 1.417407512664795\n",
      "Starting Epoch 170\n",
      "1.4626149584849675\n",
      "Validation loss: 1.4170364141464233\n",
      "mse 1.4170365022952396\n",
      "New best model found at epoch 170 with validation loss 1.4170364141464233\n",
      "Starting Epoch 171\n",
      "1.4619591385126114\n",
      "Validation loss: 1.4165445566177368\n",
      "mse 1.416544477517495\n",
      "New best model found at epoch 171 with validation loss 1.4165445566177368\n",
      "Starting Epoch 172\n",
      "1.4612849255402882\n",
      "Validation loss: 1.4160767793655396\n",
      "mse 1.4160768708967562\n",
      "New best model found at epoch 172 with validation loss 1.4160767793655396\n",
      "Starting Epoch 173\n",
      "1.4606050451596577\n",
      "Validation loss: 1.4155967235565186\n",
      "mse 1.4155967214171084\n",
      "New best model found at epoch 173 with validation loss 1.4155967235565186\n",
      "Starting Epoch 174\n",
      "1.4599896917740505\n",
      "Validation loss: 1.4151318073272705\n",
      "mse 1.4151317343160663\n",
      "New best model found at epoch 174 with validation loss 1.4151318073272705\n",
      "Starting Epoch 175\n",
      "1.4593426088492076\n",
      "Validation loss: 1.4147027730941772\n",
      "mse 1.4147026988234543\n",
      "New best model found at epoch 175 with validation loss 1.4147027730941772\n",
      "Starting Epoch 176\n",
      "1.4587321728467941\n",
      "Validation loss: 1.4142776727676392\n",
      "mse 1.4142777141644212\n",
      "New best model found at epoch 176 with validation loss 1.4142776727676392\n",
      "Starting Epoch 177\n",
      "1.4580871264139812\n",
      "Validation loss: 1.4138407707214355\n",
      "mse 1.4138407576138234\n",
      "New best model found at epoch 177 with validation loss 1.4138407707214355\n",
      "Starting Epoch 178\n",
      "1.4574619382619858\n",
      "Validation loss: 1.4134891033172607\n",
      "mse 1.4134892125864547\n",
      "New best model found at epoch 178 with validation loss 1.4134891033172607\n",
      "Starting Epoch 179\n",
      "1.4568491925795872\n",
      "Validation loss: 1.4131208658218384\n",
      "mse 1.413120755097545\n",
      "New best model found at epoch 179 with validation loss 1.4131208658218384\n",
      "Starting Epoch 180\n",
      "1.4562328457832336\n",
      "Validation loss: 1.4126893281936646\n",
      "mse 1.412689384770421\n",
      "New best model found at epoch 180 with validation loss 1.4126893281936646\n",
      "Starting Epoch 181\n",
      "1.455641731619835\n",
      "Validation loss: 1.4122520685195923\n",
      "mse 1.4122521416605596\n",
      "New best model found at epoch 181 with validation loss 1.4122520685195923\n",
      "Starting Epoch 182\n",
      "1.4550907711188\n",
      "Validation loss: 1.4118646383285522\n",
      "mse 1.4118646784404134\n",
      "New best model found at epoch 182 with validation loss 1.4118646383285522\n",
      "Starting Epoch 183\n",
      "1.4544739574193954\n",
      "Validation loss: 1.4114375114440918\n",
      "mse 1.4114373720029505\n",
      "New best model found at epoch 183 with validation loss 1.4114375114440918\n",
      "Starting Epoch 184\n",
      "1.453907772898674\n",
      "Validation loss: 1.4109001159667969\n",
      "mse 1.4109001322979369\n",
      "New best model found at epoch 184 with validation loss 1.4109001159667969\n",
      "Starting Epoch 185\n",
      "1.453322301308314\n",
      "Validation loss: 1.4104570150375366\n",
      "mse 1.4104569293158375\n",
      "New best model found at epoch 185 with validation loss 1.4104570150375366\n",
      "Starting Epoch 186\n",
      "1.4527674714724224\n",
      "Validation loss: 1.4101749658584595\n",
      "mse 1.4101750565182323\n",
      "New best model found at epoch 186 with validation loss 1.4101749658584595\n",
      "Starting Epoch 187\n",
      "1.452140177289645\n",
      "Validation loss: 1.4096770286560059\n",
      "mse 1.409676965566098\n",
      "New best model found at epoch 187 with validation loss 1.4096770286560059\n",
      "Starting Epoch 188\n",
      "1.4515612224737804\n",
      "Validation loss: 1.4092572927474976\n",
      "mse 1.4092572747075813\n",
      "New best model found at epoch 188 with validation loss 1.4092572927474976\n",
      "Starting Epoch 189\n",
      "1.4510057518879573\n",
      "Validation loss: 1.408769130706787\n",
      "mse 1.408768984114794\n",
      "New best model found at epoch 189 with validation loss 1.408769130706787\n",
      "Starting Epoch 190\n",
      "1.4504686693350475\n",
      "Validation loss: 1.4084275960922241\n",
      "mse 1.4084275967526292\n",
      "New best model found at epoch 190 with validation loss 1.4084275960922241\n",
      "Starting Epoch 191\n",
      "1.449893668293953\n",
      "Validation loss: 1.4080431461334229\n",
      "mse 1.4080431441140113\n",
      "New best model found at epoch 191 with validation loss 1.4080431461334229\n",
      "Starting Epoch 192\n",
      "1.4493409097194672\n",
      "Validation loss: 1.4076240062713623\n",
      "mse 1.4076240895815417\n",
      "New best model found at epoch 192 with validation loss 1.4076240062713623\n",
      "Starting Epoch 193\n",
      "1.4487399111191432\n",
      "Validation loss: 1.4072201251983643\n",
      "mse 1.4072201017489678\n",
      "New best model found at epoch 193 with validation loss 1.4072201251983643\n",
      "Starting Epoch 194\n",
      "1.4481452852487564\n",
      "Validation loss: 1.4067634344100952\n",
      "mse 1.4067634441080796\n",
      "New best model found at epoch 194 with validation loss 1.4067634344100952\n",
      "Starting Epoch 195\n",
      "1.4475212742884953\n",
      "Validation loss: 1.4062505960464478\n",
      "mse 1.4062506310520777\n",
      "New best model found at epoch 195 with validation loss 1.4062505960464478\n",
      "Starting Epoch 196\n",
      "1.446971818804741\n",
      "Validation loss: 1.405857801437378\n",
      "mse 1.4058578456164366\n",
      "New best model found at epoch 196 with validation loss 1.405857801437378\n",
      "Starting Epoch 197\n",
      "1.4463880360126495\n",
      "Validation loss: 1.4053434133529663\n",
      "mse 1.40534325254074\n",
      "New best model found at epoch 197 with validation loss 1.4053434133529663\n",
      "Starting Epoch 198\n",
      "1.4457797606786091\n",
      "Validation loss: 1.4047168493270874\n",
      "mse 1.404716778812873\n",
      "New best model found at epoch 198 with validation loss 1.4047168493270874\n",
      "Starting Epoch 199\n",
      "1.4451996088027954\n",
      "Validation loss: 1.4042267799377441\n",
      "mse 1.4042267142575173\n",
      "New best model found at epoch 199 with validation loss 1.4042267799377441\n",
      "Starting Epoch 200\n",
      "1.4447053968906403\n",
      "Validation loss: 1.403735876083374\n",
      "mse 1.403736009027482\n",
      "New best model found at epoch 200 with validation loss 1.403735876083374\n",
      "Starting Epoch 201\n",
      "1.4440415501594543\n",
      "Validation loss: 1.4032596349716187\n",
      "mse 1.4032595388302005\n",
      "New best model found at epoch 201 with validation loss 1.4032596349716187\n",
      "Starting Epoch 202\n",
      "1.4435545802116394\n",
      "Validation loss: 1.4027704000473022\n",
      "mse 1.4027704953880087\n",
      "New best model found at epoch 202 with validation loss 1.4027704000473022\n",
      "Starting Epoch 203\n",
      "1.4429516394933064\n",
      "Validation loss: 1.402137279510498\n",
      "mse 1.4021373600116112\n",
      "New best model found at epoch 203 with validation loss 1.402137279510498\n",
      "Starting Epoch 204\n",
      "1.442347452044487\n",
      "Validation loss: 1.4015361070632935\n",
      "mse 1.401536074519206\n",
      "New best model found at epoch 204 with validation loss 1.4015361070632935\n",
      "Starting Epoch 205\n",
      "1.4417309015989304\n",
      "Validation loss: 1.4009476900100708\n",
      "mse 1.400947727388634\n",
      "New best model found at epoch 205 with validation loss 1.4009476900100708\n",
      "Starting Epoch 206\n",
      "1.441127101580302\n",
      "Validation loss: 1.400357723236084\n",
      "mse 1.4003577906014129\n",
      "New best model found at epoch 206 with validation loss 1.400357723236084\n",
      "Starting Epoch 207\n",
      "1.4404869228601456\n",
      "Validation loss: 1.3997383117675781\n",
      "mse 1.3997382333910127\n",
      "New best model found at epoch 207 with validation loss 1.3997383117675781\n",
      "Starting Epoch 208\n",
      "1.439898858467738\n",
      "Validation loss: 1.3991961479187012\n",
      "mse 1.3991960407873472\n",
      "New best model found at epoch 208 with validation loss 1.3991961479187012\n",
      "Starting Epoch 209\n",
      "1.4392857402563095\n",
      "Validation loss: 1.398625135421753\n",
      "mse 1.3986251778215215\n",
      "New best model found at epoch 209 with validation loss 1.398625135421753\n",
      "Starting Epoch 210\n",
      "1.4387047737836838\n",
      "Validation loss: 1.3980956077575684\n",
      "mse 1.3980954995188881\n",
      "New best model found at epoch 210 with validation loss 1.3980956077575684\n",
      "Starting Epoch 211\n",
      "1.4381840775410335\n",
      "Validation loss: 1.3975298404693604\n",
      "mse 1.3975299206597744\n",
      "New best model found at epoch 211 with validation loss 1.3975298404693604\n",
      "Starting Epoch 212\n",
      "1.4375305771827698\n",
      "Validation loss: 1.397003412246704\n",
      "mse 1.3970034262344861\n",
      "New best model found at epoch 212 with validation loss 1.397003412246704\n",
      "Starting Epoch 213\n",
      "1.4368963912129402\n",
      "Validation loss: 1.3962746858596802\n",
      "mse 1.396274664994185\n",
      "New best model found at epoch 213 with validation loss 1.3962746858596802\n",
      "Starting Epoch 214\n",
      "1.4362401366233826\n",
      "Validation loss: 1.395621418952942\n",
      "mse 1.395621426530287\n",
      "New best model found at epoch 214 with validation loss 1.395621418952942\n",
      "Starting Epoch 215\n",
      "1.435583730538686\n",
      "Validation loss: 1.3951716423034668\n",
      "mse 1.3951717203676102\n",
      "New best model found at epoch 215 with validation loss 1.3951716423034668\n",
      "Starting Epoch 216\n",
      "1.4349962895115216\n",
      "Validation loss: 1.394569754600525\n",
      "mse 1.3945697534141068\n",
      "New best model found at epoch 216 with validation loss 1.394569754600525\n",
      "Starting Epoch 217\n",
      "1.4342948173483212\n",
      "Validation loss: 1.3940788507461548\n",
      "mse 1.3940788089126381\n",
      "New best model found at epoch 217 with validation loss 1.3940788507461548\n",
      "Starting Epoch 218\n",
      "1.4337029879291852\n",
      "Validation loss: 1.3935487270355225\n",
      "mse 1.3935487452069002\n",
      "New best model found at epoch 218 with validation loss 1.3935487270355225\n",
      "Starting Epoch 219\n",
      "1.4331238741676013\n",
      "Validation loss: 1.3929991722106934\n",
      "mse 1.3929990610718974\n",
      "New best model found at epoch 219 with validation loss 1.3929991722106934\n",
      "Starting Epoch 220\n",
      "1.4324807996551197\n",
      "Validation loss: 1.3925608396530151\n",
      "mse 1.3925608836900494\n",
      "New best model found at epoch 220 with validation loss 1.3925608396530151\n",
      "Starting Epoch 221\n",
      "1.4319228678941727\n",
      "Validation loss: 1.391983985900879\n",
      "mse 1.3919841127893509\n",
      "New best model found at epoch 221 with validation loss 1.391983985900879\n",
      "Starting Epoch 222\n",
      "1.431290050347646\n",
      "Validation loss: 1.391538143157959\n",
      "mse 1.3915379641427466\n",
      "New best model found at epoch 222 with validation loss 1.391538143157959\n",
      "Starting Epoch 223\n",
      "1.4306982606649399\n",
      "Validation loss: 1.3910415172576904\n",
      "mse 1.3910415443713455\n",
      "New best model found at epoch 223 with validation loss 1.3910415172576904\n",
      "Starting Epoch 224\n",
      "1.4301482513546944\n",
      "Validation loss: 1.3904876708984375\n",
      "mse 1.3904877613888635\n",
      "New best model found at epoch 224 with validation loss 1.3904876708984375\n",
      "Starting Epoch 225\n",
      "1.4295223007599513\n",
      "Validation loss: 1.3900526762008667\n",
      "mse 1.3900527005124146\n",
      "New best model found at epoch 225 with validation loss 1.3900526762008667\n",
      "Starting Epoch 226\n",
      "1.428933451573054\n",
      "Validation loss: 1.3895748853683472\n",
      "mse 1.3895749181064776\n",
      "New best model found at epoch 226 with validation loss 1.3895748853683472\n",
      "Starting Epoch 227\n",
      "1.4282800381382306\n",
      "Validation loss: 1.3891355991363525\n",
      "mse 1.3891356121173477\n",
      "New best model found at epoch 227 with validation loss 1.3891355991363525\n",
      "Starting Epoch 228\n",
      "1.4277632435162861\n",
      "Validation loss: 1.388627529144287\n",
      "mse 1.3886275378611443\n",
      "New best model found at epoch 228 with validation loss 1.388627529144287\n",
      "Starting Epoch 229\n",
      "1.4271621430913608\n",
      "Validation loss: 1.3881568908691406\n",
      "mse 1.3881569331979358\n",
      "New best model found at epoch 229 with validation loss 1.3881568908691406\n",
      "Starting Epoch 230\n",
      "1.4265464097261429\n",
      "Validation loss: 1.3877811431884766\n",
      "mse 1.38778113295129\n",
      "New best model found at epoch 230 with validation loss 1.3877811431884766\n",
      "Starting Epoch 231\n",
      "1.425985909998417\n",
      "Validation loss: 1.387362003326416\n",
      "mse 1.387362099592237\n",
      "New best model found at epoch 231 with validation loss 1.387362003326416\n",
      "Starting Epoch 232\n",
      "1.4254596307873726\n",
      "Validation loss: 1.3868297338485718\n",
      "mse 1.3868299159456128\n",
      "New best model found at epoch 232 with validation loss 1.3868297338485718\n",
      "Starting Epoch 233\n",
      "1.424832823375861\n",
      "Validation loss: 1.3864737749099731\n",
      "mse 1.3864737970114098\n",
      "New best model found at epoch 233 with validation loss 1.3864737749099731\n",
      "Starting Epoch 234\n",
      "1.4243112529317539\n",
      "Validation loss: 1.3860337734222412\n",
      "mse 1.3860338522397393\n",
      "New best model found at epoch 234 with validation loss 1.3860337734222412\n",
      "Starting Epoch 235\n",
      "1.4237399622797966\n",
      "Validation loss: 1.3855825662612915\n",
      "mse 1.3855824797658196\n",
      "New best model found at epoch 235 with validation loss 1.3855825662612915\n",
      "Starting Epoch 236\n",
      "1.4232094883918762\n",
      "Validation loss: 1.3851728439331055\n",
      "mse 1.3851728755396364\n",
      "New best model found at epoch 236 with validation loss 1.3851728439331055\n",
      "Starting Epoch 237\n",
      "1.4226458072662354\n",
      "Validation loss: 1.3847211599349976\n",
      "mse 1.3847211687997811\n",
      "New best model found at epoch 237 with validation loss 1.3847211599349976\n",
      "Starting Epoch 238\n",
      "1.422154498596986\n",
      "Validation loss: 1.3841928243637085\n",
      "mse 1.3841929392248358\n",
      "New best model found at epoch 238 with validation loss 1.3841928243637085\n",
      "Starting Epoch 239\n",
      "1.4215515727798145\n",
      "Validation loss: 1.3838359117507935\n",
      "mse 1.383835742951534\n",
      "New best model found at epoch 239 with validation loss 1.3838359117507935\n",
      "Starting Epoch 240\n",
      "1.4210327168305714\n",
      "Validation loss: 1.383405327796936\n",
      "mse 1.3834053901332415\n",
      "New best model found at epoch 240 with validation loss 1.383405327796936\n",
      "Starting Epoch 241\n",
      "1.4205207775036495\n",
      "Validation loss: 1.3830064535140991\n",
      "mse 1.3830063917337065\n",
      "New best model found at epoch 241 with validation loss 1.3830064535140991\n",
      "Starting Epoch 242\n",
      "1.419974684715271\n",
      "Validation loss: 1.3825739622116089\n",
      "mse 1.3825740046610837\n",
      "New best model found at epoch 242 with validation loss 1.3825739622116089\n",
      "Starting Epoch 243\n",
      "1.4194825291633606\n",
      "Validation loss: 1.382053017616272\n",
      "mse 1.3820529820944227\n",
      "New best model found at epoch 243 with validation loss 1.382053017616272\n",
      "Starting Epoch 244\n",
      "1.4189228937029839\n",
      "Validation loss: 1.3817410469055176\n",
      "mse 1.3817409092483905\n",
      "New best model found at epoch 244 with validation loss 1.3817410469055176\n",
      "Starting Epoch 245\n",
      "1.4184170762697856\n",
      "Validation loss: 1.3813238143920898\n",
      "mse 1.381323731063504\n",
      "New best model found at epoch 245 with validation loss 1.3813238143920898\n",
      "Starting Epoch 246\n",
      "1.4179236615697544\n",
      "Validation loss: 1.3808104991912842\n",
      "mse 1.3808105141626135\n",
      "New best model found at epoch 246 with validation loss 1.3808104991912842\n",
      "Starting Epoch 247\n",
      "1.417366437613964\n",
      "Validation loss: 1.3804306983947754\n",
      "mse 1.3804305338371539\n",
      "New best model found at epoch 247 with validation loss 1.3804306983947754\n",
      "Starting Epoch 248\n",
      "1.4168370713790257\n",
      "Validation loss: 1.3799901008605957\n",
      "mse 1.3799900391082598\n",
      "New best model found at epoch 248 with validation loss 1.3799901008605957\n",
      "Starting Epoch 249\n",
      "1.4163450449705124\n",
      "Validation loss: 1.3795156478881836\n",
      "mse 1.3795156797509822\n",
      "New best model found at epoch 249 with validation loss 1.3795156478881836\n",
      "Starting Epoch 250\n",
      "1.415786251425743\n",
      "Validation loss: 1.379189133644104\n",
      "mse 1.3791891499534488\n",
      "New best model found at epoch 250 with validation loss 1.379189133644104\n",
      "Starting Epoch 251\n",
      "1.415278822183609\n",
      "Validation loss: 1.3787708282470703\n",
      "mse 1.3787709102662717\n",
      "New best model found at epoch 251 with validation loss 1.3787708282470703\n",
      "Starting Epoch 252\n",
      "1.4148317947983742\n",
      "Validation loss: 1.3782691955566406\n",
      "mse 1.3782692684357842\n",
      "New best model found at epoch 252 with validation loss 1.3782691955566406\n",
      "Starting Epoch 253\n",
      "1.4143152385950089\n",
      "Validation loss: 1.3779845237731934\n",
      "mse 1.3779846640271147\n",
      "New best model found at epoch 253 with validation loss 1.3779845237731934\n",
      "Starting Epoch 254\n",
      "1.4138299847642581\n",
      "Validation loss: 1.3775711059570312\n",
      "mse 1.3775710562306949\n",
      "New best model found at epoch 254 with validation loss 1.3775711059570312\n",
      "Starting Epoch 255\n",
      "1.4133315806587536\n",
      "Validation loss: 1.3773691654205322\n",
      "mse 1.377369147588179\n",
      "New best model found at epoch 255 with validation loss 1.3773691654205322\n",
      "Starting Epoch 256\n",
      "1.4129398067792256\n",
      "Validation loss: 1.3767553567886353\n",
      "mse 1.3767553049260814\n",
      "New best model found at epoch 256 with validation loss 1.3767553567886353\n",
      "Starting Epoch 257\n",
      "1.4124125987291336\n",
      "Validation loss: 1.3764104843139648\n",
      "mse 1.3764104630252054\n",
      "New best model found at epoch 257 with validation loss 1.3764104843139648\n",
      "Starting Epoch 258\n",
      "1.4119477570056915\n",
      "Validation loss: 1.3761073350906372\n",
      "mse 1.3761072579209546\n",
      "New best model found at epoch 258 with validation loss 1.3761073350906372\n",
      "Starting Epoch 259\n",
      "1.411495288213094\n",
      "Validation loss: 1.3756945133209229\n",
      "mse 1.3756946114085862\n",
      "New best model found at epoch 259 with validation loss 1.3756945133209229\n",
      "Starting Epoch 260\n",
      "1.4110462243358295\n",
      "Validation loss: 1.3751713037490845\n",
      "mse 1.375171292904321\n",
      "New best model found at epoch 260 with validation loss 1.3751713037490845\n",
      "Starting Epoch 261\n",
      "1.4105363140503566\n",
      "Validation loss: 1.375043511390686\n",
      "mse 1.3750434114261059\n",
      "New best model found at epoch 261 with validation loss 1.375043511390686\n",
      "Starting Epoch 262\n",
      "1.4101358105738957\n",
      "Validation loss: 1.3744337558746338\n",
      "mse 1.374433679667835\n",
      "New best model found at epoch 262 with validation loss 1.3744337558746338\n",
      "Starting Epoch 263\n",
      "1.4096429298321407\n",
      "Validation loss: 1.374128818511963\n",
      "mse 1.3741289194662536\n",
      "New best model found at epoch 263 with validation loss 1.374128818511963\n",
      "Starting Epoch 264\n",
      "1.409167304635048\n",
      "Validation loss: 1.3739348649978638\n",
      "mse 1.3739348449273583\n",
      "New best model found at epoch 264 with validation loss 1.3739348649978638\n",
      "Starting Epoch 265\n",
      "1.408762479821841\n",
      "Validation loss: 1.3733869791030884\n",
      "mse 1.3733868940292566\n",
      "New best model found at epoch 265 with validation loss 1.3733869791030884\n",
      "Starting Epoch 266\n",
      "1.4083153208096821\n",
      "Validation loss: 1.3731247186660767\n",
      "mse 1.3731247248616276\n",
      "New best model found at epoch 266 with validation loss 1.3731247186660767\n",
      "Starting Epoch 267\n",
      "1.4078480054934819\n",
      "Validation loss: 1.3726831674575806\n",
      "mse 1.372683151992879\n",
      "New best model found at epoch 267 with validation loss 1.3726831674575806\n",
      "Starting Epoch 268\n",
      "1.4074250260988872\n",
      "Validation loss: 1.3723872900009155\n",
      "mse 1.3723872201998177\n",
      "New best model found at epoch 268 with validation loss 1.3723872900009155\n",
      "Starting Epoch 269\n",
      "1.4069708387056987\n",
      "Validation loss: 1.3719552755355835\n",
      "mse 1.3719554052165104\n",
      "New best model found at epoch 269 with validation loss 1.3719552755355835\n",
      "Starting Epoch 270\n",
      "1.4065537477533023\n",
      "Validation loss: 1.371673822402954\n",
      "mse 1.3716737688031075\n",
      "New best model found at epoch 270 with validation loss 1.371673822402954\n",
      "Starting Epoch 271\n",
      "1.4061081483960152\n",
      "Validation loss: 1.3712725639343262\n",
      "mse 1.371272642590623\n",
      "New best model found at epoch 271 with validation loss 1.3712725639343262\n",
      "Starting Epoch 272\n",
      "1.405682307978471\n",
      "Validation loss: 1.3709716796875\n",
      "mse 1.370971764302709\n",
      "New best model found at epoch 272 with validation loss 1.3709716796875\n",
      "Starting Epoch 273\n",
      "1.4052297001083691\n",
      "Validation loss: 1.3705365657806396\n",
      "mse 1.3705365311753925\n",
      "New best model found at epoch 273 with validation loss 1.3705365657806396\n",
      "Starting Epoch 274\n",
      "1.4048152690132458\n",
      "Validation loss: 1.3701963424682617\n",
      "mse 1.370196324635878\n",
      "New best model found at epoch 274 with validation loss 1.3701963424682617\n",
      "Starting Epoch 275\n",
      "1.4043350766102474\n",
      "Validation loss: 1.369898796081543\n",
      "mse 1.3698988021628664\n",
      "New best model found at epoch 275 with validation loss 1.369898796081543\n",
      "Starting Epoch 276\n",
      "1.4039253716667492\n",
      "Validation loss: 1.3694263696670532\n",
      "mse 1.3694264036176862\n",
      "New best model found at epoch 276 with validation loss 1.3694263696670532\n",
      "Starting Epoch 277\n",
      "1.4034511571129162\n",
      "Validation loss: 1.369155764579773\n",
      "mse 1.3691557369220748\n",
      "New best model found at epoch 277 with validation loss 1.369155764579773\n",
      "Starting Epoch 278\n",
      "1.4030392294128735\n",
      "Validation loss: 1.3686820268630981\n",
      "mse 1.368682085289532\n",
      "New best model found at epoch 278 with validation loss 1.3686820268630981\n",
      "Starting Epoch 279\n",
      "1.4026258910695713\n",
      "Validation loss: 1.3683170080184937\n",
      "mse 1.3683170549703614\n",
      "New best model found at epoch 279 with validation loss 1.3683170080184937\n",
      "Starting Epoch 280\n",
      "1.4021368697285652\n",
      "Validation loss: 1.367991328239441\n",
      "mse 1.367991270775849\n",
      "New best model found at epoch 280 with validation loss 1.367991328239441\n",
      "Starting Epoch 281\n",
      "1.4017394756277402\n",
      "Validation loss: 1.3675392866134644\n",
      "mse 1.3675391285552982\n",
      "New best model found at epoch 281 with validation loss 1.3675392866134644\n",
      "Starting Epoch 282\n",
      "1.4012867286801338\n",
      "Validation loss: 1.3671592473983765\n",
      "mse 1.3671592447811223\n",
      "New best model found at epoch 282 with validation loss 1.3671592473983765\n",
      "Starting Epoch 283\n",
      "1.4008691708246868\n",
      "Validation loss: 1.3667771816253662\n",
      "mse 1.3667771743325636\n",
      "New best model found at epoch 283 with validation loss 1.3667771816253662\n",
      "Starting Epoch 284\n",
      "1.4004438444972038\n",
      "Validation loss: 1.366397738456726\n",
      "mse 1.3663977469617614\n",
      "New best model found at epoch 284 with validation loss 1.366397738456726\n",
      "Starting Epoch 285\n",
      "1.400008112192154\n",
      "Validation loss: 1.366023302078247\n",
      "mse 1.3660231881179177\n",
      "New best model found at epoch 285 with validation loss 1.366023302078247\n",
      "Starting Epoch 286\n",
      "1.3995872288942337\n",
      "Validation loss: 1.3656386137008667\n",
      "mse 1.3656385782112872\n",
      "New best model found at epoch 286 with validation loss 1.3656386137008667\n",
      "Starting Epoch 287\n",
      "1.3991677438219388\n",
      "Validation loss: 1.3652222156524658\n",
      "mse 1.3652222108499996\n",
      "New best model found at epoch 287 with validation loss 1.3652222156524658\n",
      "Starting Epoch 288\n",
      "1.3987431898713112\n",
      "Validation loss: 1.3648325204849243\n",
      "mse 1.3648324940302672\n",
      "New best model found at epoch 288 with validation loss 1.3648325204849243\n",
      "Starting Epoch 289\n",
      "1.3982994904120762\n",
      "Validation loss: 1.3644517660140991\n",
      "mse 1.364451864010768\n",
      "New best model found at epoch 289 with validation loss 1.3644517660140991\n",
      "Starting Epoch 290\n",
      "1.3978925471504529\n",
      "Validation loss: 1.364084243774414\n",
      "mse 1.3640842361291408\n",
      "New best model found at epoch 290 with validation loss 1.364084243774414\n",
      "Starting Epoch 291\n",
      "1.3974650974075\n",
      "Validation loss: 1.3636541366577148\n",
      "mse 1.3636542410790238\n",
      "New best model found at epoch 291 with validation loss 1.3636541366577148\n",
      "Starting Epoch 292\n",
      "1.3970380425453186\n",
      "Validation loss: 1.3633426427841187\n",
      "mse 1.3633425528778227\n",
      "New best model found at epoch 292 with validation loss 1.3633426427841187\n",
      "Starting Epoch 293\n",
      "1.396630346775055\n",
      "Validation loss: 1.3629612922668457\n",
      "mse 1.3629613355328598\n",
      "New best model found at epoch 293 with validation loss 1.3629612922668457\n",
      "Starting Epoch 294\n",
      "1.3962027455369632\n",
      "Validation loss: 1.3625400066375732\n",
      "mse 1.3625399833937455\n",
      "New best model found at epoch 294 with validation loss 1.3625400066375732\n",
      "Starting Epoch 295\n",
      "1.395791433751583\n",
      "Validation loss: 1.3621715307235718\n",
      "mse 1.3621714874994697\n",
      "New best model found at epoch 295 with validation loss 1.3621715307235718\n",
      "Starting Epoch 296\n",
      "1.3953620096047719\n",
      "Validation loss: 1.3618342876434326\n",
      "mse 1.3618341599820034\n",
      "New best model found at epoch 296 with validation loss 1.3618342876434326\n",
      "Starting Epoch 297\n",
      "1.394954390823841\n",
      "Validation loss: 1.3614164590835571\n",
      "mse 1.3614164922928587\n",
      "New best model found at epoch 297 with validation loss 1.3614164590835571\n",
      "Starting Epoch 298\n",
      "1.3945375109712284\n",
      "Validation loss: 1.3610366582870483\n",
      "mse 1.3610366931437485\n",
      "New best model found at epoch 298 with validation loss 1.3610366582870483\n",
      "Starting Epoch 299\n",
      "1.3941389694809914\n",
      "Validation loss: 1.360630750656128\n",
      "mse 1.3606305059182398\n",
      "New best model found at epoch 299 with validation loss 1.360630750656128\n",
      "Starting Epoch 300\n",
      "1.3937182798981667\n",
      "Validation loss: 1.3602286577224731\n",
      "mse 1.3602285968818204\n",
      "New best model found at epoch 300 with validation loss 1.3602286577224731\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-10-5-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41228e1",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 20 - 10 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "368b2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0a27d32a-a2f4-48fb-b65f-3f08994d609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.527958422899246\n",
      "Validation loss: 2.2715487480163574\n",
      "mse 2.2715487778038903\n",
      "New best model found at epoch 1 with validation loss 2.2715487480163574\n",
      "Starting Epoch 2\n",
      "2.164583280682564\n",
      "Validation loss: 2.0885262489318848\n",
      "mse 2.088526347147082\n",
      "New best model found at epoch 2 with validation loss 2.0885262489318848\n",
      "Starting Epoch 3\n",
      "2.0638521760702133\n",
      "Validation loss: 1.9887784719467163\n",
      "mse 1.9887784121494694\n",
      "New best model found at epoch 3 with validation loss 1.9887784719467163\n",
      "Starting Epoch 4\n",
      "1.9834604064623516\n",
      "Validation loss: 1.907597303390503\n",
      "mse 1.907597296959202\n",
      "New best model found at epoch 4 with validation loss 1.907597303390503\n",
      "Starting Epoch 5\n",
      "1.9397961050271988\n",
      "Validation loss: 1.8730589151382446\n",
      "mse 1.8730587717261227\n",
      "New best model found at epoch 5 with validation loss 1.8730589151382446\n",
      "Starting Epoch 6\n",
      "1.9127491861581802\n",
      "Validation loss: 1.8482211828231812\n",
      "mse 1.8482212324136356\n",
      "New best model found at epoch 6 with validation loss 1.8482211828231812\n",
      "Starting Epoch 7\n",
      "1.8917827357848485\n",
      "Validation loss: 1.8235453367233276\n",
      "mse 1.8235453863262172\n",
      "New best model found at epoch 7 with validation loss 1.8235453367233276\n",
      "Starting Epoch 8\n",
      "1.87258742749691\n",
      "Validation loss: 1.8024848699569702\n",
      "mse 1.8024849497151352\n",
      "New best model found at epoch 8 with validation loss 1.8024848699569702\n",
      "Starting Epoch 9\n",
      "1.854240705569585\n",
      "Validation loss: 1.7828667163848877\n",
      "mse 1.7828668690094611\n",
      "New best model found at epoch 9 with validation loss 1.7828667163848877\n",
      "Starting Epoch 10\n",
      "1.8367355714241664\n",
      "Validation loss: 1.761935830116272\n",
      "mse 1.7619357065906378\n",
      "New best model found at epoch 10 with validation loss 1.761935830116272\n",
      "Starting Epoch 11\n",
      "1.8197222650051117\n",
      "Validation loss: 1.741664171218872\n",
      "mse 1.7416641568442008\n",
      "New best model found at epoch 11 with validation loss 1.741664171218872\n",
      "Starting Epoch 12\n",
      "1.8032252043485641\n",
      "Validation loss: 1.7222802639007568\n",
      "mse 1.7222801293655472\n",
      "New best model found at epoch 12 with validation loss 1.7222802639007568\n",
      "Starting Epoch 13\n",
      "1.7871688952048619\n",
      "Validation loss: 1.7040174007415771\n",
      "mse 1.704017288713986\n",
      "New best model found at epoch 13 with validation loss 1.7040174007415771\n",
      "Starting Epoch 14\n",
      "1.7717874497175217\n",
      "Validation loss: 1.6850570440292358\n",
      "mse 1.6850570108316218\n",
      "New best model found at epoch 14 with validation loss 1.6850570440292358\n",
      "Starting Epoch 15\n",
      "1.7572498619556427\n",
      "Validation loss: 1.6689696311950684\n",
      "mse 1.6689696127805898\n",
      "New best model found at epoch 15 with validation loss 1.6689696311950684\n",
      "Starting Epoch 16\n",
      "1.7435816725095112\n",
      "Validation loss: 1.6543668508529663\n",
      "mse 1.6543670016686154\n",
      "New best model found at epoch 16 with validation loss 1.6543668508529663\n",
      "Starting Epoch 17\n",
      "1.73092120885849\n",
      "Validation loss: 1.6403619050979614\n",
      "mse 1.6403617882030532\n",
      "New best model found at epoch 17 with validation loss 1.6403619050979614\n",
      "Starting Epoch 18\n",
      "1.7189145187536876\n",
      "Validation loss: 1.6269155740737915\n",
      "mse 1.626915782760422\n",
      "New best model found at epoch 18 with validation loss 1.6269155740737915\n",
      "Starting Epoch 19\n",
      "1.7074533551931381\n",
      "Validation loss: 1.6150881052017212\n",
      "mse 1.6150881526781238\n",
      "New best model found at epoch 19 with validation loss 1.6150881052017212\n",
      "Starting Epoch 20\n",
      "1.696895455320676\n",
      "Validation loss: 1.6033517122268677\n",
      "mse 1.6033517535953457\n",
      "New best model found at epoch 20 with validation loss 1.6033517122268677\n",
      "Starting Epoch 21\n",
      "1.6871370524168015\n",
      "Validation loss: 1.5922821760177612\n",
      "mse 1.592282158974512\n",
      "New best model found at epoch 21 with validation loss 1.5922821760177612\n",
      "Starting Epoch 22\n",
      "1.6781409631172817\n",
      "Validation loss: 1.5829678773880005\n",
      "mse 1.582967913381434\n",
      "New best model found at epoch 22 with validation loss 1.5829678773880005\n",
      "Starting Epoch 23\n",
      "1.6697864184776943\n",
      "Validation loss: 1.5745892524719238\n",
      "mse 1.574589160105558\n",
      "New best model found at epoch 23 with validation loss 1.5745892524719238\n",
      "Starting Epoch 24\n",
      "1.6619061628977458\n",
      "Validation loss: 1.5672576427459717\n",
      "mse 1.5672575118691692\n",
      "New best model found at epoch 24 with validation loss 1.5672576427459717\n",
      "Starting Epoch 25\n",
      "1.654955307642619\n",
      "Validation loss: 1.5608158111572266\n",
      "mse 1.5608158496615514\n",
      "New best model found at epoch 25 with validation loss 1.5608158111572266\n",
      "Starting Epoch 26\n",
      "1.6482894271612167\n",
      "Validation loss: 1.554308533668518\n",
      "mse 1.5543085402200938\n",
      "New best model found at epoch 26 with validation loss 1.554308533668518\n",
      "Starting Epoch 27\n",
      "1.642184595266978\n",
      "Validation loss: 1.5483330488204956\n",
      "mse 1.5483331243527578\n",
      "New best model found at epoch 27 with validation loss 1.5483330488204956\n",
      "Starting Epoch 28\n",
      "1.6368214935064316\n",
      "Validation loss: 1.542801022529602\n",
      "mse 1.5428011036738856\n",
      "New best model found at epoch 28 with validation loss 1.542801022529602\n",
      "Starting Epoch 29\n",
      "1.631673887372017\n",
      "Validation loss: 1.537797451019287\n",
      "mse 1.5377974338063372\n",
      "New best model found at epoch 29 with validation loss 1.537797451019287\n",
      "Starting Epoch 30\n",
      "1.6270575821399689\n",
      "Validation loss: 1.5332837104797363\n",
      "mse 1.533283897545982\n",
      "New best model found at epoch 30 with validation loss 1.5332837104797363\n",
      "Starting Epoch 31\n",
      "1.6226132363080978\n",
      "Validation loss: 1.5297770500183105\n",
      "mse 1.5297770956145267\n",
      "New best model found at epoch 31 with validation loss 1.5297770500183105\n",
      "Starting Epoch 32\n",
      "1.618717963496844\n",
      "Validation loss: 1.5253102779388428\n",
      "mse 1.5253103447949494\n",
      "New best model found at epoch 32 with validation loss 1.5253102779388428\n",
      "Starting Epoch 33\n",
      "1.614957590897878\n",
      "Validation loss: 1.5219306945800781\n",
      "mse 1.5219306748182493\n",
      "New best model found at epoch 33 with validation loss 1.5219306945800781\n",
      "Starting Epoch 34\n",
      "1.6113418936729431\n",
      "Validation loss: 1.5185277462005615\n",
      "mse 1.5185276802716956\n",
      "New best model found at epoch 34 with validation loss 1.5185277462005615\n",
      "Starting Epoch 35\n",
      "1.6076521972815196\n",
      "Validation loss: 1.5153392553329468\n",
      "mse 1.5153390444041446\n",
      "New best model found at epoch 35 with validation loss 1.5153392553329468\n",
      "Starting Epoch 36\n",
      "1.6035865445931752\n",
      "Validation loss: 1.5111910104751587\n",
      "mse 1.5111907896077288\n",
      "New best model found at epoch 36 with validation loss 1.5111910104751587\n",
      "Starting Epoch 37\n",
      "1.5990102241436641\n",
      "Validation loss: 1.5071842670440674\n",
      "mse 1.5071842753145015\n",
      "New best model found at epoch 37 with validation loss 1.5071842670440674\n",
      "Starting Epoch 38\n",
      "1.59422068297863\n",
      "Validation loss: 1.5038448572158813\n",
      "mse 1.5038446541783785\n",
      "New best model found at epoch 38 with validation loss 1.5038448572158813\n",
      "Starting Epoch 39\n",
      "1.589793140689532\n",
      "Validation loss: 1.5003249645233154\n",
      "mse 1.5003248527560256\n",
      "New best model found at epoch 39 with validation loss 1.5003249645233154\n",
      "Starting Epoch 40\n",
      "1.5848329116900761\n",
      "Validation loss: 1.4962565898895264\n",
      "mse 1.4962565823499847\n",
      "New best model found at epoch 40 with validation loss 1.4962565898895264\n",
      "Starting Epoch 41\n",
      "1.5802399615446727\n",
      "Validation loss: 1.492419958114624\n",
      "mse 1.4924198957410417\n",
      "New best model found at epoch 41 with validation loss 1.492419958114624\n",
      "Starting Epoch 42\n",
      "1.5758645782868068\n",
      "Validation loss: 1.4886438846588135\n",
      "mse 1.4886439301268588\n",
      "New best model found at epoch 42 with validation loss 1.4886438846588135\n",
      "Starting Epoch 43\n",
      "1.571811283628146\n",
      "Validation loss: 1.4845874309539795\n",
      "mse 1.4845875105281088\n",
      "New best model found at epoch 43 with validation loss 1.4845874309539795\n",
      "Starting Epoch 44\n",
      "1.5682206352551777\n",
      "Validation loss: 1.4823404550552368\n",
      "mse 1.4823402634820557\n",
      "New best model found at epoch 44 with validation loss 1.4823404550552368\n",
      "Starting Epoch 45\n",
      "1.5649374177058537\n",
      "Validation loss: 1.4797790050506592\n",
      "mse 1.4797790573595597\n",
      "New best model found at epoch 45 with validation loss 1.4797790050506592\n",
      "Starting Epoch 46\n",
      "1.5617114553848903\n",
      "Validation loss: 1.477460265159607\n",
      "mse 1.4774602529705751\n",
      "New best model found at epoch 46 with validation loss 1.477460265159607\n",
      "Starting Epoch 47\n",
      "1.558635026216507\n",
      "Validation loss: 1.475329041481018\n",
      "mse 1.475329128756141\n",
      "New best model found at epoch 47 with validation loss 1.475329041481018\n",
      "Starting Epoch 48\n",
      "1.5554830431938171\n",
      "Validation loss: 1.472051739692688\n",
      "mse 1.4720517110379892\n",
      "New best model found at epoch 48 with validation loss 1.472051739692688\n",
      "Starting Epoch 49\n",
      "1.552650585770607\n",
      "Validation loss: 1.4702601432800293\n",
      "mse 1.4702601818144991\n",
      "New best model found at epoch 49 with validation loss 1.4702601432800293\n",
      "Starting Epoch 50\n",
      "1.5498911490043004\n",
      "Validation loss: 1.4683327674865723\n",
      "mse 1.4683327948131695\n",
      "New best model found at epoch 50 with validation loss 1.4683327674865723\n",
      "Starting Epoch 51\n",
      "1.5472501168648403\n",
      "Validation loss: 1.4663277864456177\n",
      "mse 1.4663276165173749\n",
      "New best model found at epoch 51 with validation loss 1.4663277864456177\n",
      "Starting Epoch 52\n",
      "1.5446672439575195\n",
      "Validation loss: 1.4642325639724731\n",
      "mse 1.4642324586367843\n",
      "New best model found at epoch 52 with validation loss 1.4642325639724731\n",
      "Starting Epoch 53\n",
      "1.5422886063655217\n",
      "Validation loss: 1.4624806642532349\n",
      "mse 1.4624808278607286\n",
      "New best model found at epoch 53 with validation loss 1.4624806642532349\n",
      "Starting Epoch 54\n",
      "1.5399368802706401\n",
      "Validation loss: 1.4606560468673706\n",
      "mse 1.4606560292384863\n",
      "New best model found at epoch 54 with validation loss 1.4606560468673706\n",
      "Starting Epoch 55\n",
      "1.5375935584306717\n",
      "Validation loss: 1.458268165588379\n",
      "mse 1.4582683161297885\n",
      "New best model found at epoch 55 with validation loss 1.458268165588379\n",
      "Starting Epoch 56\n",
      "1.535404200355212\n",
      "Validation loss: 1.4567288160324097\n",
      "mse 1.4567286817886171\n",
      "New best model found at epoch 56 with validation loss 1.4567288160324097\n",
      "Starting Epoch 57\n",
      "1.5331720064083736\n",
      "Validation loss: 1.4546587467193604\n",
      "mse 1.4546587286913293\n",
      "New best model found at epoch 57 with validation loss 1.4546587467193604\n",
      "Starting Epoch 58\n",
      "1.5308245718479156\n",
      "Validation loss: 1.4532585144042969\n",
      "mse 1.4532585114618488\n",
      "New best model found at epoch 58 with validation loss 1.4532585144042969\n",
      "Starting Epoch 59\n",
      "1.5285645226637523\n",
      "Validation loss: 1.4513076543807983\n",
      "mse 1.451307699177387\n",
      "New best model found at epoch 59 with validation loss 1.4513076543807983\n",
      "Starting Epoch 60\n",
      "1.5263547947009404\n",
      "Validation loss: 1.4495505094528198\n",
      "mse 1.4495505047989266\n",
      "New best model found at epoch 60 with validation loss 1.4495505094528198\n",
      "Starting Epoch 61\n",
      "1.5242054710785549\n",
      "Validation loss: 1.447779893875122\n",
      "mse 1.44777994411701\n",
      "New best model found at epoch 61 with validation loss 1.447779893875122\n",
      "Starting Epoch 62\n",
      "1.5220029056072235\n",
      "Validation loss: 1.4456614255905151\n",
      "mse 1.4456612974816305\n",
      "New best model found at epoch 62 with validation loss 1.4456614255905151\n",
      "Starting Epoch 63\n",
      "1.5197430451711018\n",
      "Validation loss: 1.4435412883758545\n",
      "mse 1.4435412860820036\n",
      "New best model found at epoch 63 with validation loss 1.4435412883758545\n",
      "Starting Epoch 64\n",
      "1.5174258599678676\n",
      "Validation loss: 1.4412870407104492\n",
      "mse 1.4412869254186431\n",
      "New best model found at epoch 64 with validation loss 1.4412870407104492\n",
      "Starting Epoch 65\n",
      "1.515081192056338\n",
      "Validation loss: 1.439093828201294\n",
      "mse 1.4390938822391606\n",
      "New best model found at epoch 65 with validation loss 1.439093828201294\n",
      "Starting Epoch 66\n",
      "1.5128036141395569\n",
      "Validation loss: 1.4373743534088135\n",
      "mse 1.4373743742568579\n",
      "New best model found at epoch 66 with validation loss 1.4373743534088135\n",
      "Starting Epoch 67\n",
      "1.510573277870814\n",
      "Validation loss: 1.4356489181518555\n",
      "mse 1.4356489633159752\n",
      "New best model found at epoch 67 with validation loss 1.4356489181518555\n",
      "Starting Epoch 68\n",
      "1.508388082186381\n",
      "Validation loss: 1.4341018199920654\n",
      "mse 1.4341017609823654\n",
      "New best model found at epoch 68 with validation loss 1.4341018199920654\n",
      "Starting Epoch 69\n",
      "1.506298025449117\n",
      "Validation loss: 1.4323445558547974\n",
      "mse 1.4323445809469122\n",
      "New best model found at epoch 69 with validation loss 1.4323445558547974\n",
      "Starting Epoch 70\n",
      "1.5042562534411748\n",
      "Validation loss: 1.4308056831359863\n",
      "mse 1.4308056773936926\n",
      "New best model found at epoch 70 with validation loss 1.4308056831359863\n",
      "Starting Epoch 71\n",
      "1.5023324588934581\n",
      "Validation loss: 1.4291666746139526\n",
      "mse 1.4291665550846238\n",
      "New best model found at epoch 71 with validation loss 1.4291666746139526\n",
      "Starting Epoch 72\n",
      "1.5003928641478221\n",
      "Validation loss: 1.4276812076568604\n",
      "mse 1.4276810339830277\n",
      "New best model found at epoch 72 with validation loss 1.4276812076568604\n",
      "Starting Epoch 73\n",
      "1.4985028554995854\n",
      "Validation loss: 1.426033616065979\n",
      "mse 1.4260336772818254\n",
      "New best model found at epoch 73 with validation loss 1.426033616065979\n",
      "Starting Epoch 74\n",
      "1.4966096381346385\n",
      "Validation loss: 1.4244844913482666\n",
      "mse 1.424484529386634\n",
      "New best model found at epoch 74 with validation loss 1.4244844913482666\n",
      "Starting Epoch 75\n",
      "1.4947097599506378\n",
      "Validation loss: 1.4228116273880005\n",
      "mse 1.422811607518764\n",
      "New best model found at epoch 75 with validation loss 1.4228116273880005\n",
      "Starting Epoch 76\n",
      "1.4928344041109085\n",
      "Validation loss: 1.4212546348571777\n",
      "mse 1.421254517799525\n",
      "New best model found at epoch 76 with validation loss 1.4212546348571777\n",
      "Starting Epoch 77\n",
      "1.4909638911485672\n",
      "Validation loss: 1.4198105335235596\n",
      "mse 1.4198105456830776\n",
      "New best model found at epoch 77 with validation loss 1.4198105335235596\n",
      "Starting Epoch 78\n",
      "1.489155227939288\n",
      "Validation loss: 1.418280005455017\n",
      "mse 1.4182799983706031\n",
      "New best model found at epoch 78 with validation loss 1.418280005455017\n",
      "Starting Epoch 79\n",
      "1.4873886108398438\n",
      "Validation loss: 1.4168555736541748\n",
      "mse 1.4168555653939987\n",
      "New best model found at epoch 79 with validation loss 1.4168555736541748\n",
      "Starting Epoch 80\n",
      "1.4856430391470592\n",
      "Validation loss: 1.415360927581787\n",
      "mse 1.4153609462714862\n",
      "New best model found at epoch 80 with validation loss 1.415360927581787\n",
      "Starting Epoch 81\n",
      "1.483873059352239\n",
      "Validation loss: 1.4138591289520264\n",
      "mse 1.4138590630154961\n",
      "New best model found at epoch 81 with validation loss 1.4138591289520264\n",
      "Starting Epoch 82\n",
      "1.482149710257848\n",
      "Validation loss: 1.4127047061920166\n",
      "mse 1.412704706250459\n",
      "New best model found at epoch 82 with validation loss 1.4127047061920166\n",
      "Starting Epoch 83\n",
      "1.4804297635952632\n",
      "Validation loss: 1.4113075733184814\n",
      "mse 1.4113075560376942\n",
      "New best model found at epoch 83 with validation loss 1.4113075733184814\n",
      "Starting Epoch 84\n",
      "1.4787089973688126\n",
      "Validation loss: 1.409912347793579\n",
      "mse 1.4099123858078029\n",
      "New best model found at epoch 84 with validation loss 1.409912347793579\n",
      "Starting Epoch 85\n",
      "1.4770256678263347\n",
      "Validation loss: 1.4085854291915894\n",
      "mse 1.4085853930172358\n",
      "New best model found at epoch 85 with validation loss 1.4085854291915894\n",
      "Starting Epoch 86\n",
      "1.475383574763934\n",
      "Validation loss: 1.4074686765670776\n",
      "mse 1.4074685139178762\n",
      "New best model found at epoch 86 with validation loss 1.4074686765670776\n",
      "Starting Epoch 87\n",
      "1.4737075169881184\n",
      "Validation loss: 1.406019926071167\n",
      "mse 1.4060199888700111\n",
      "New best model found at epoch 87 with validation loss 1.406019926071167\n",
      "Starting Epoch 88\n",
      "1.4721228182315826\n",
      "Validation loss: 1.4045168161392212\n",
      "mse 1.4045168825693632\n",
      "New best model found at epoch 88 with validation loss 1.4045168161392212\n",
      "Starting Epoch 89\n",
      "1.4704744319121044\n",
      "Validation loss: 1.4031795263290405\n",
      "mse 1.40317947195636\n",
      "New best model found at epoch 89 with validation loss 1.4031795263290405\n",
      "Starting Epoch 90\n",
      "1.4689000050226848\n",
      "Validation loss: 1.4018476009368896\n",
      "mse 1.4018476198272598\n",
      "New best model found at epoch 90 with validation loss 1.4018476009368896\n",
      "Starting Epoch 91\n",
      "1.467293565471967\n",
      "Validation loss: 1.400506615638733\n",
      "mse 1.4005065813039612\n",
      "New best model found at epoch 91 with validation loss 1.400506615638733\n",
      "Starting Epoch 92\n",
      "1.4657332052787144\n",
      "Validation loss: 1.3990845680236816\n",
      "mse 1.3990846757328115\n",
      "New best model found at epoch 92 with validation loss 1.3990845680236816\n",
      "Starting Epoch 93\n",
      "1.4641533344984055\n",
      "Validation loss: 1.3977687358856201\n",
      "mse 1.3977687345786036\n",
      "New best model found at epoch 93 with validation loss 1.3977687358856201\n",
      "Starting Epoch 94\n",
      "1.4626210232575734\n",
      "Validation loss: 1.396083116531372\n",
      "mse 1.3960831513175447\n",
      "New best model found at epoch 94 with validation loss 1.396083116531372\n",
      "Starting Epoch 95\n",
      "1.4611253837744396\n",
      "Validation loss: 1.3948397636413574\n",
      "mse 1.3948398028037565\n",
      "New best model found at epoch 95 with validation loss 1.3948397636413574\n",
      "Starting Epoch 96\n",
      "1.4595637172460556\n",
      "Validation loss: 1.393450379371643\n",
      "mse 1.3934503840084747\n",
      "New best model found at epoch 96 with validation loss 1.393450379371643\n",
      "Starting Epoch 97\n",
      "1.4581241259972255\n",
      "Validation loss: 1.392143726348877\n",
      "mse 1.3921436806406395\n",
      "New best model found at epoch 97 with validation loss 1.392143726348877\n",
      "Starting Epoch 98\n",
      "1.456578180193901\n",
      "Validation loss: 1.3907722234725952\n",
      "mse 1.3907721024823085\n",
      "New best model found at epoch 98 with validation loss 1.3907722234725952\n",
      "Starting Epoch 99\n",
      "1.4551758617162704\n",
      "Validation loss: 1.390224575996399\n",
      "mse 1.3902245092502878\n",
      "New best model found at epoch 99 with validation loss 1.390224575996399\n",
      "Starting Epoch 100\n",
      "1.4537408749262493\n",
      "Validation loss: 1.3890478610992432\n",
      "mse 1.3890480058457362\n",
      "New best model found at epoch 100 with validation loss 1.3890478610992432\n",
      "Starting Epoch 101\n",
      "1.4523292829593022\n",
      "Validation loss: 1.3870809078216553\n",
      "mse 1.3870808687688476\n",
      "New best model found at epoch 101 with validation loss 1.3870809078216553\n",
      "Starting Epoch 102\n",
      "1.4508538295825322\n",
      "Validation loss: 1.386248230934143\n",
      "mse 1.3862483177525964\n",
      "New best model found at epoch 102 with validation loss 1.386248230934143\n",
      "Starting Epoch 103\n",
      "1.4494861215353012\n",
      "Validation loss: 1.3852378129959106\n",
      "mse 1.3852377981706057\n",
      "New best model found at epoch 103 with validation loss 1.3852378129959106\n",
      "Starting Epoch 104\n",
      "1.4481040736039479\n",
      "Validation loss: 1.3838698863983154\n",
      "mse 1.383869973612137\n",
      "New best model found at epoch 104 with validation loss 1.3838698863983154\n",
      "Starting Epoch 105\n",
      "1.4467505713303883\n",
      "Validation loss: 1.3825732469558716\n",
      "mse 1.3825733376175329\n",
      "New best model found at epoch 105 with validation loss 1.3825732469558716\n",
      "Starting Epoch 106\n",
      "1.4453798582156498\n",
      "Validation loss: 1.381436824798584\n",
      "mse 1.3814367529420337\n",
      "New best model found at epoch 106 with validation loss 1.381436824798584\n",
      "Starting Epoch 107\n",
      "1.4440197696288426\n",
      "Validation loss: 1.3803924322128296\n",
      "mse 1.3803925114715534\n",
      "New best model found at epoch 107 with validation loss 1.3803924322128296\n",
      "Starting Epoch 108\n",
      "1.4427249083916347\n",
      "Validation loss: 1.3792517185211182\n",
      "mse 1.379251664190567\n",
      "New best model found at epoch 108 with validation loss 1.3792517185211182\n",
      "Starting Epoch 109\n",
      "1.4414117087920506\n",
      "Validation loss: 1.3781590461730957\n",
      "mse 1.378159085200042\n",
      "New best model found at epoch 109 with validation loss 1.3781590461730957\n",
      "Starting Epoch 110\n",
      "1.4401284555594127\n",
      "Validation loss: 1.3770177364349365\n",
      "mse 1.377017743810802\n",
      "New best model found at epoch 110 with validation loss 1.3770177364349365\n",
      "Starting Epoch 111\n",
      "1.438841034968694\n",
      "Validation loss: 1.37588632106781\n",
      "mse 1.375886266502055\n",
      "New best model found at epoch 111 with validation loss 1.37588632106781\n",
      "Starting Epoch 112\n",
      "1.4376134524742763\n",
      "Validation loss: 1.3746311664581299\n",
      "mse 1.3746312690909006\n",
      "New best model found at epoch 112 with validation loss 1.3746311664581299\n",
      "Starting Epoch 113\n",
      "1.4363149801890056\n",
      "Validation loss: 1.373523235321045\n",
      "mse 1.3735233564971498\n",
      "New best model found at epoch 113 with validation loss 1.373523235321045\n",
      "Starting Epoch 114\n",
      "1.4351073453823726\n",
      "Validation loss: 1.3722671270370483\n",
      "mse 1.3722671406194349\n",
      "New best model found at epoch 114 with validation loss 1.3722671270370483\n",
      "Starting Epoch 115\n",
      "1.4338367531696956\n",
      "Validation loss: 1.3712966442108154\n",
      "mse 1.371296605566301\n",
      "New best model found at epoch 115 with validation loss 1.3712966442108154\n",
      "Starting Epoch 116\n",
      "1.4326816722750664\n",
      "Validation loss: 1.3700019121170044\n",
      "mse 1.3700018805356153\n",
      "New best model found at epoch 116 with validation loss 1.3700019121170044\n",
      "Starting Epoch 117\n",
      "1.4314134418964386\n",
      "Validation loss: 1.3690637350082397\n",
      "mse 1.3690637700182686\n",
      "New best model found at epoch 117 with validation loss 1.3690637350082397\n",
      "Starting Epoch 118\n",
      "1.4302614455421765\n",
      "Validation loss: 1.3677541017532349\n",
      "mse 1.3677540445160283\n",
      "New best model found at epoch 118 with validation loss 1.3677541017532349\n",
      "Starting Epoch 119\n",
      "1.4290541832645733\n",
      "Validation loss: 1.366620421409607\n",
      "mse 1.3666204715282821\n",
      "New best model found at epoch 119 with validation loss 1.366620421409607\n",
      "Starting Epoch 120\n",
      "1.4278040404121082\n",
      "Validation loss: 1.3657362461090088\n",
      "mse 1.3657363796250293\n",
      "New best model found at epoch 120 with validation loss 1.3657362461090088\n",
      "Starting Epoch 121\n",
      "1.4266933500766754\n",
      "Validation loss: 1.3644517660140991\n",
      "mse 1.3644517851127476\n",
      "New best model found at epoch 121 with validation loss 1.3644517660140991\n",
      "Starting Epoch 122\n",
      "1.425514002641042\n",
      "Validation loss: 1.3634364604949951\n",
      "mse 1.3634364534497116\n",
      "New best model found at epoch 122 with validation loss 1.3634364604949951\n",
      "Starting Epoch 123\n",
      "1.4243207424879074\n",
      "Validation loss: 1.362568974494934\n",
      "mse 1.3625691010075867\n",
      "New best model found at epoch 123 with validation loss 1.362568974494934\n",
      "Starting Epoch 124\n",
      "1.4232357169191043\n",
      "Validation loss: 1.3614559173583984\n",
      "mse 1.3614560085929202\n",
      "New best model found at epoch 124 with validation loss 1.3614559173583984\n",
      "Starting Epoch 125\n",
      "1.4220250596602757\n",
      "Validation loss: 1.3606936931610107\n",
      "mse 1.3606938010262106\n",
      "New best model found at epoch 125 with validation loss 1.3606936931610107\n",
      "Starting Epoch 126\n",
      "1.420982003211975\n",
      "Validation loss: 1.3595284223556519\n",
      "mse 1.3595283640540097\n",
      "New best model found at epoch 126 with validation loss 1.3595284223556519\n",
      "Starting Epoch 127\n",
      "1.4198856751124065\n",
      "Validation loss: 1.3585084676742554\n",
      "mse 1.35850836845804\n",
      "New best model found at epoch 127 with validation loss 1.3585084676742554\n",
      "Starting Epoch 128\n",
      "1.4187368551890056\n",
      "Validation loss: 1.3576457500457764\n",
      "mse 1.3576457871470717\n",
      "New best model found at epoch 128 with validation loss 1.3576457500457764\n",
      "Starting Epoch 129\n",
      "1.417701209584872\n",
      "Validation loss: 1.3567187786102295\n",
      "mse 1.3567187581044655\n",
      "New best model found at epoch 129 with validation loss 1.3567187786102295\n",
      "Starting Epoch 130\n",
      "1.4166479632258415\n",
      "Validation loss: 1.3555773496627808\n",
      "mse 1.3555771822381537\n",
      "New best model found at epoch 130 with validation loss 1.3555773496627808\n",
      "Starting Epoch 131\n",
      "1.415506196518739\n",
      "Validation loss: 1.3547395467758179\n",
      "mse 1.3547394968354975\n",
      "New best model found at epoch 131 with validation loss 1.3547395467758179\n",
      "Starting Epoch 132\n",
      "1.4144168893496196\n",
      "Validation loss: 1.3539386987686157\n",
      "mse 1.3539386520062255\n",
      "New best model found at epoch 132 with validation loss 1.3539386987686157\n",
      "Starting Epoch 133\n",
      "1.4134846404194832\n",
      "Validation loss: 1.3527567386627197\n",
      "mse 1.3527569442999223\n",
      "New best model found at epoch 133 with validation loss 1.3527567386627197\n",
      "Starting Epoch 134\n",
      "1.4123693058888118\n",
      "Validation loss: 1.3520009517669678\n",
      "mse 1.3520009985292645\n",
      "New best model found at epoch 134 with validation loss 1.3520009517669678\n",
      "Starting Epoch 135\n",
      "1.4113042950630188\n",
      "Validation loss: 1.3511766195297241\n",
      "mse 1.3511767272861372\n",
      "New best model found at epoch 135 with validation loss 1.3511766195297241\n",
      "Starting Epoch 136\n",
      "1.410255951186021\n",
      "Validation loss: 1.3502460718154907\n",
      "mse 1.3502459865646579\n",
      "New best model found at epoch 136 with validation loss 1.3502460718154907\n",
      "Starting Epoch 137\n",
      "1.4091604426503181\n",
      "Validation loss: 1.3494362831115723\n",
      "mse 1.3494363476756426\n",
      "New best model found at epoch 137 with validation loss 1.3494362831115723\n",
      "Starting Epoch 138\n",
      "1.408106952905655\n",
      "Validation loss: 1.3486878871917725\n",
      "mse 1.3486879425961673\n",
      "New best model found at epoch 138 with validation loss 1.3486878871917725\n",
      "Starting Epoch 139\n",
      "1.4070591454704602\n",
      "Validation loss: 1.347873568534851\n",
      "mse 1.3478735688699601\n",
      "New best model found at epoch 139 with validation loss 1.347873568534851\n",
      "Starting Epoch 140\n",
      "1.406026430428028\n",
      "Validation loss: 1.3469668626785278\n",
      "mse 1.346966849215018\n",
      "New best model found at epoch 140 with validation loss 1.3469668626785278\n",
      "Starting Epoch 141\n",
      "1.4050068085392315\n",
      "Validation loss: 1.3461437225341797\n",
      "mse 1.3461437119773492\n",
      "New best model found at epoch 141 with validation loss 1.3461437225341797\n",
      "Starting Epoch 142\n",
      "1.4040510281920433\n",
      "Validation loss: 1.345146656036377\n",
      "mse 1.3451467072262806\n",
      "New best model found at epoch 142 with validation loss 1.345146656036377\n",
      "Starting Epoch 143\n",
      "1.4030153304338455\n",
      "Validation loss: 1.3444308042526245\n",
      "mse 1.3444307345060817\n",
      "New best model found at epoch 143 with validation loss 1.3444308042526245\n",
      "Starting Epoch 144\n",
      "1.402120145658652\n",
      "Validation loss: 1.3433924913406372\n",
      "mse 1.343392479673184\n",
      "New best model found at epoch 144 with validation loss 1.3433924913406372\n",
      "Starting Epoch 145\n",
      "1.4010729938745499\n",
      "Validation loss: 1.3426705598831177\n",
      "mse 1.3426705116344737\n",
      "New best model found at epoch 145 with validation loss 1.3426705598831177\n",
      "Starting Epoch 146\n",
      "1.4001687616109848\n",
      "Validation loss: 1.3416908979415894\n",
      "mse 1.3416908121692255\n",
      "New best model found at epoch 146 with validation loss 1.3416908979415894\n",
      "Starting Epoch 147\n",
      "1.3992085705200832\n",
      "Validation loss: 1.3408012390136719\n",
      "mse 1.3408012450107036\n",
      "New best model found at epoch 147 with validation loss 1.3408012390136719\n",
      "Starting Epoch 148\n",
      "1.3981925398111343\n",
      "Validation loss: 1.3402268886566162\n",
      "mse 1.3402269415227352\n",
      "New best model found at epoch 148 with validation loss 1.3402268886566162\n",
      "Starting Epoch 149\n",
      "1.3973276565472286\n",
      "Validation loss: 1.3394122123718262\n",
      "mse 1.339412212972538\n",
      "New best model found at epoch 149 with validation loss 1.3394122123718262\n",
      "Starting Epoch 150\n",
      "1.396419420838356\n",
      "Validation loss: 1.3386421203613281\n",
      "mse 1.3386421027703919\n",
      "New best model found at epoch 150 with validation loss 1.3386421203613281\n",
      "Starting Epoch 151\n",
      "1.39552790671587\n",
      "Validation loss: 1.3377734422683716\n",
      "mse 1.3377733295450258\n",
      "New best model found at epoch 151 with validation loss 1.3377734422683716\n",
      "Starting Epoch 152\n",
      "1.394607350230217\n",
      "Validation loss: 1.3371540307998657\n",
      "mse 1.337154100769885\n",
      "New best model found at epoch 152 with validation loss 1.3371540307998657\n",
      "Starting Epoch 153\n",
      "1.3937585378686588\n",
      "Validation loss: 1.336294174194336\n",
      "mse 1.3362941223272926\n",
      "New best model found at epoch 153 with validation loss 1.336294174194336\n",
      "Starting Epoch 154\n",
      "1.3928702374299367\n",
      "Validation loss: 1.3354063034057617\n",
      "mse 1.3354063568534655\n",
      "New best model found at epoch 154 with validation loss 1.3354063034057617\n",
      "Starting Epoch 155\n",
      "1.3919469937682152\n",
      "Validation loss: 1.3345680236816406\n",
      "mse 1.334568137185117\n",
      "New best model found at epoch 155 with validation loss 1.3345680236816406\n",
      "Starting Epoch 156\n",
      "1.3911038065950077\n",
      "Validation loss: 1.333735704421997\n",
      "mse 1.3337358411362228\n",
      "New best model found at epoch 156 with validation loss 1.333735704421997\n",
      "Starting Epoch 157\n",
      "1.3901790380477905\n",
      "Validation loss: 1.3331230878829956\n",
      "mse 1.333123056077449\n",
      "New best model found at epoch 157 with validation loss 1.3331230878829956\n",
      "Starting Epoch 158\n",
      "1.389350302517414\n",
      "Validation loss: 1.3323382139205933\n",
      "mse 1.3323383056840876\n",
      "New best model found at epoch 158 with validation loss 1.3323382139205933\n",
      "Starting Epoch 159\n",
      "1.3884760563572247\n",
      "Validation loss: 1.33163321018219\n",
      "mse 1.3316332188014008\n",
      "New best model found at epoch 159 with validation loss 1.33163321018219\n",
      "Starting Epoch 160\n",
      "1.3876250262061756\n",
      "Validation loss: 1.32980215549469\n",
      "mse 1.3298021423616702\n",
      "New best model found at epoch 160 with validation loss 1.32980215549469\n",
      "Starting Epoch 161\n",
      "1.3867417474587758\n",
      "Validation loss: 1.3301823139190674\n",
      "mse 1.3301822059592772\n",
      "Starting Epoch 162\n",
      "1.3860225901007652\n",
      "Validation loss: 1.3294340372085571\n",
      "mse 1.3294340333037677\n",
      "New best model found at epoch 162 with validation loss 1.3294340372085571\n",
      "Starting Epoch 163\n",
      "1.3851004913449287\n",
      "Validation loss: 1.3286492824554443\n",
      "mse 1.3286493060178928\n",
      "New best model found at epoch 163 with validation loss 1.3286492824554443\n",
      "Starting Epoch 164\n",
      "1.3842575177550316\n",
      "Validation loss: 1.3267617225646973\n",
      "mse 1.326761656882585\n",
      "New best model found at epoch 164 with validation loss 1.3267617225646973\n",
      "Starting Epoch 165\n",
      "1.3833146790663402\n",
      "Validation loss: 1.3271193504333496\n",
      "mse 1.3271193808054682\n",
      "Starting Epoch 166\n",
      "1.382606141269207\n",
      "Validation loss: 1.3264758586883545\n",
      "mse 1.326475932865944\n",
      "New best model found at epoch 166 with validation loss 1.3264758586883545\n",
      "Starting Epoch 167\n",
      "1.3817773660024006\n",
      "Validation loss: 1.324689269065857\n",
      "mse 1.3246892914802586\n",
      "New best model found at epoch 167 with validation loss 1.324689269065857\n",
      "Starting Epoch 168\n",
      "1.3808439746499062\n",
      "Validation loss: 1.324903964996338\n",
      "mse 1.3249038970065616\n",
      "Starting Epoch 169\n",
      "1.3801080385843914\n",
      "Validation loss: 1.3232176303863525\n",
      "mse 1.3232176706231764\n",
      "New best model found at epoch 169 with validation loss 1.3232176303863525\n",
      "Starting Epoch 170\n",
      "1.3792136013507843\n",
      "Validation loss: 1.3234144449234009\n",
      "mse 1.323414447548821\n",
      "Starting Epoch 171\n",
      "1.3783416748046875\n",
      "Validation loss: 1.3219122886657715\n",
      "mse 1.321912310794495\n",
      "New best model found at epoch 171 with validation loss 1.3219122886657715\n",
      "Starting Epoch 172\n",
      "1.3775161306063335\n",
      "Validation loss: 1.3221814632415771\n",
      "mse 1.3221814999105692\n",
      "Starting Epoch 173\n",
      "1.376741814116637\n",
      "Validation loss: 1.321730375289917\n",
      "mse 1.3217304658904112\n",
      "New best model found at epoch 173 with validation loss 1.321730375289917\n",
      "Starting Epoch 174\n",
      "1.3759361480673153\n",
      "Validation loss: 1.3202906847000122\n",
      "mse 1.320290769234744\n",
      "New best model found at epoch 174 with validation loss 1.3202906847000122\n",
      "Starting Epoch 175\n",
      "1.3750975256164868\n",
      "Validation loss: 1.32049560546875\n",
      "mse 1.3204955903356899\n",
      "Starting Epoch 176\n",
      "1.3743392651279767\n",
      "Validation loss: 1.3191161155700684\n",
      "mse 1.3191160752689488\n",
      "New best model found at epoch 176 with validation loss 1.3191161155700684\n",
      "Starting Epoch 177\n",
      "1.3734903583923976\n",
      "Validation loss: 1.3194870948791504\n",
      "mse 1.3194870570078827\n",
      "Starting Epoch 178\n",
      "1.3727662563323975\n",
      "Validation loss: 1.3180915117263794\n",
      "mse 1.3180915409884486\n",
      "New best model found at epoch 178 with validation loss 1.3180915117263794\n",
      "Starting Epoch 179\n",
      "1.371916726231575\n",
      "Validation loss: 1.3175232410430908\n",
      "mse 1.317523114660242\n",
      "New best model found at epoch 179 with validation loss 1.3175232410430908\n",
      "Starting Epoch 180\n",
      "1.3712324276566505\n",
      "Validation loss: 1.3177138566970825\n",
      "mse 1.3177138437385694\n",
      "Starting Epoch 181\n",
      "1.370439698298772\n",
      "Validation loss: 1.316535234451294\n",
      "mse 1.3165352826635708\n",
      "New best model found at epoch 181 with validation loss 1.316535234451294\n",
      "Starting Epoch 182\n",
      "1.3697632228334744\n",
      "Validation loss: 1.316663384437561\n",
      "mse 1.3166634790086333\n",
      "Starting Epoch 183\n",
      "1.3690845370292664\n",
      "Validation loss: 1.3162375688552856\n",
      "mse 1.3162376213419569\n",
      "New best model found at epoch 183 with validation loss 1.3162375688552856\n",
      "Starting Epoch 184\n",
      "1.368327942987283\n",
      "Validation loss: 1.3150485754013062\n",
      "mse 1.3150486306338365\n",
      "New best model found at epoch 184 with validation loss 1.3150485754013062\n",
      "Starting Epoch 185\n",
      "1.3676075687011082\n",
      "Validation loss: 1.3153270483016968\n",
      "mse 1.315326877122106\n",
      "Starting Epoch 186\n",
      "1.3669823283950489\n",
      "Validation loss: 1.3140147924423218\n",
      "mse 1.314014927246723\n",
      "New best model found at epoch 186 with validation loss 1.3140147924423218\n",
      "Starting Epoch 187\n",
      "1.3662765497962635\n",
      "Validation loss: 1.3141745328903198\n",
      "mse 1.3141744944124027\n",
      "Starting Epoch 188\n",
      "1.365743450820446\n",
      "Validation loss: 1.312848448753357\n",
      "mse 1.3128484928427127\n",
      "New best model found at epoch 188 with validation loss 1.312848448753357\n",
      "Starting Epoch 189\n",
      "1.364900956551234\n",
      "Validation loss: 1.3133492469787598\n",
      "mse 1.3133493255513755\n",
      "Starting Epoch 190\n",
      "1.364360769589742\n",
      "Validation loss: 1.311922311782837\n",
      "mse 1.3119224129534628\n",
      "New best model found at epoch 190 with validation loss 1.311922311782837\n",
      "Starting Epoch 191\n",
      "1.3635932182272275\n",
      "Validation loss: 1.312371850013733\n",
      "mse 1.3123718729559002\n",
      "Starting Epoch 192\n",
      "1.3630406161149342\n",
      "Validation loss: 1.311000108718872\n",
      "mse 1.311000222376644\n",
      "New best model found at epoch 192 with validation loss 1.311000108718872\n",
      "Starting Epoch 193\n",
      "1.362372135122617\n",
      "Validation loss: 1.3113069534301758\n",
      "mse 1.311306954436217\n",
      "Starting Epoch 194\n",
      "1.3618421827753384\n",
      "Validation loss: 1.3108078241348267\n",
      "mse 1.3108078089266426\n",
      "New best model found at epoch 194 with validation loss 1.3108078241348267\n",
      "Starting Epoch 195\n",
      "1.361115574836731\n",
      "Validation loss: 1.309347152709961\n",
      "mse 1.3093471557770417\n",
      "New best model found at epoch 195 with validation loss 1.309347152709961\n",
      "Starting Epoch 196\n",
      "1.3604741618037224\n",
      "Validation loss: 1.308767318725586\n",
      "mse 1.30876743906959\n",
      "New best model found at epoch 196 with validation loss 1.308767318725586\n",
      "Starting Epoch 197\n",
      "1.3600172052780788\n",
      "Validation loss: 1.309325098991394\n",
      "mse 1.30932509550415\n",
      "Starting Epoch 198\n",
      "1.3593727151552837\n",
      "Validation loss: 1.3078340291976929\n",
      "mse 1.3078340153648875\n",
      "New best model found at epoch 198 with validation loss 1.3078340291976929\n",
      "Starting Epoch 199\n",
      "1.3587723697225254\n",
      "Validation loss: 1.3079787492752075\n",
      "mse 1.3079786733856686\n",
      "Starting Epoch 200\n",
      "1.3582097614804904\n",
      "Validation loss: 1.3067234754562378\n",
      "mse 1.3067235313817818\n",
      "New best model found at epoch 200 with validation loss 1.3067234754562378\n",
      "Starting Epoch 201\n",
      "1.3576517676313717\n",
      "Validation loss: 1.3071404695510864\n",
      "mse 1.3071403793165117\n",
      "Starting Epoch 202\n",
      "1.3570922488967578\n",
      "Validation loss: 1.305942177772522\n",
      "mse 1.3059421169803502\n",
      "New best model found at epoch 202 with validation loss 1.305942177772522\n",
      "Starting Epoch 203\n",
      "1.356520190834999\n",
      "Validation loss: 1.3065533638000488\n",
      "mse 1.3065532491337644\n",
      "Starting Epoch 204\n",
      "1.3559372449914615\n",
      "Validation loss: 1.3049885034561157\n",
      "mse 1.3049886656746565\n",
      "New best model found at epoch 204 with validation loss 1.3049885034561157\n",
      "Starting Epoch 205\n",
      "1.3554116562008858\n",
      "Validation loss: 1.3051435947418213\n",
      "mse 1.3051435579587771\n",
      "Starting Epoch 206\n",
      "1.3549611642956734\n",
      "Validation loss: 1.304003357887268\n",
      "mse 1.3040032282875342\n",
      "New best model found at epoch 206 with validation loss 1.304003357887268\n",
      "Starting Epoch 207\n",
      "1.3542430649201076\n",
      "Validation loss: 1.3036588430404663\n",
      "mse 1.3036589549815145\n",
      "New best model found at epoch 207 with validation loss 1.3036588430404663\n",
      "Starting Epoch 208\n",
      "1.3538257429997127\n",
      "Validation loss: 1.303856372833252\n",
      "mse 1.3038562790839068\n",
      "Starting Epoch 209\n",
      "1.3532177458206813\n",
      "Validation loss: 1.3028879165649414\n",
      "mse 1.3028879678195413\n",
      "New best model found at epoch 209 with validation loss 1.3028879165649414\n",
      "Starting Epoch 210\n",
      "1.3527213012178738\n",
      "Validation loss: 1.3023661375045776\n",
      "mse 1.3023662307906867\n",
      "New best model found at epoch 210 with validation loss 1.3023661375045776\n",
      "Starting Epoch 211\n",
      "1.3522049238284428\n",
      "Validation loss: 1.3025318384170532\n",
      "mse 1.3025318964761659\n",
      "Starting Epoch 212\n",
      "1.3517005890607834\n",
      "Validation loss: 1.3015437126159668\n",
      "mse 1.3015435892201277\n",
      "New best model found at epoch 212 with validation loss 1.3015437126159668\n",
      "Starting Epoch 213\n",
      "1.3511231169104576\n",
      "Validation loss: 1.3017160892486572\n",
      "mse 1.3017160141083555\n",
      "Starting Epoch 214\n",
      "1.3505762666463852\n",
      "Validation loss: 1.3005390167236328\n",
      "mse 1.3005389309146522\n",
      "New best model found at epoch 214 with validation loss 1.3005390167236328\n",
      "Starting Epoch 215\n",
      "1.3501053998867671\n",
      "Validation loss: 1.3001296520233154\n",
      "mse 1.3001296268693172\n",
      "New best model found at epoch 215 with validation loss 1.3001296520233154\n",
      "Starting Epoch 216\n",
      "1.3494823301831882\n",
      "Validation loss: 1.2996516227722168\n",
      "mse 1.2996513572941646\n",
      "New best model found at epoch 216 with validation loss 1.2996516227722168\n",
      "Starting Epoch 217\n",
      "1.349136879046758\n",
      "Validation loss: 1.2999403476715088\n",
      "mse 1.299940330812694\n",
      "Starting Epoch 218\n",
      "1.3485434005657833\n",
      "Validation loss: 1.2988783121109009\n",
      "mse 1.298878372510082\n",
      "New best model found at epoch 218 with validation loss 1.2988783121109009\n",
      "Starting Epoch 219\n",
      "1.3481275911132495\n",
      "Validation loss: 1.2989912033081055\n",
      "mse 1.2989912300101056\n",
      "Starting Epoch 220\n",
      "1.3475841581821442\n",
      "Validation loss: 1.298019289970398\n",
      "mse 1.2980191241072352\n",
      "New best model found at epoch 220 with validation loss 1.298019289970398\n",
      "Starting Epoch 221\n",
      "1.3471371258298557\n",
      "Validation loss: 1.2974119186401367\n",
      "mse 1.2974120209148274\n",
      "New best model found at epoch 221 with validation loss 1.2974119186401367\n",
      "Starting Epoch 222\n",
      "1.3465084557731946\n",
      "Validation loss: 1.2969683408737183\n",
      "mse 1.2969683187404422\n",
      "New best model found at epoch 222 with validation loss 1.2969683408737183\n",
      "Starting Epoch 223\n",
      "1.3460622330506642\n",
      "Validation loss: 1.2974437475204468\n",
      "mse 1.2974436490458714\n",
      "Starting Epoch 224\n",
      "1.345710036655267\n",
      "Validation loss: 1.2963547706604004\n",
      "mse 1.2963547027789781\n",
      "New best model found at epoch 224 with validation loss 1.2963547706604004\n",
      "Starting Epoch 225\n",
      "1.345157320300738\n",
      "Validation loss: 1.2967723608016968\n",
      "mse 1.2967724063818264\n",
      "Starting Epoch 226\n",
      "1.3447398642698924\n",
      "Validation loss: 1.2956734895706177\n",
      "mse 1.2956733572611325\n",
      "New best model found at epoch 226 with validation loss 1.2956734895706177\n",
      "Starting Epoch 227\n",
      "1.3442117323478062\n",
      "Validation loss: 1.2951551675796509\n",
      "mse 1.2951551503583707\n",
      "New best model found at epoch 227 with validation loss 1.2951551675796509\n",
      "Starting Epoch 228\n",
      "1.3438196902473767\n",
      "Validation loss: 1.2946479320526123\n",
      "mse 1.2946478875595888\n",
      "New best model found at epoch 228 with validation loss 1.2946479320526123\n",
      "Starting Epoch 229\n",
      "1.3432656178871791\n",
      "Validation loss: 1.2942631244659424\n",
      "mse 1.2942631500004131\n",
      "New best model found at epoch 229 with validation loss 1.2942631244659424\n",
      "Starting Epoch 230\n",
      "1.3428893238306046\n",
      "Validation loss: 1.2936726808547974\n",
      "mse 1.2936726499847473\n",
      "New best model found at epoch 230 with validation loss 1.2936726808547974\n",
      "Starting Epoch 231\n",
      "1.3424505566557248\n",
      "Validation loss: 1.294258713722229\n",
      "mse 1.2942586898515493\n",
      "Starting Epoch 232\n",
      "1.3419185156623523\n",
      "Validation loss: 1.2931431531906128\n",
      "mse 1.2931430875465193\n",
      "New best model found at epoch 232 with validation loss 1.2931431531906128\n",
      "Starting Epoch 233\n",
      "1.3415288502971332\n",
      "Validation loss: 1.2924388647079468\n",
      "mse 1.2924388433905232\n",
      "New best model found at epoch 233 with validation loss 1.2924388647079468\n",
      "Starting Epoch 234\n",
      "1.3410658563176792\n",
      "Validation loss: 1.2930134534835815\n",
      "mse 1.2930134450982038\n",
      "Starting Epoch 235\n",
      "1.3406899223725002\n",
      "Validation loss: 1.2926359176635742\n",
      "mse 1.292635904319207\n",
      "Starting Epoch 236\n",
      "1.3403183942039807\n",
      "Validation loss: 1.2915334701538086\n",
      "mse 1.291533485525253\n",
      "New best model found at epoch 236 with validation loss 1.2915334701538086\n",
      "Starting Epoch 237\n",
      "1.3397856975595157\n",
      "Validation loss: 1.2910329103469849\n",
      "mse 1.2910330083147998\n",
      "New best model found at epoch 237 with validation loss 1.2910329103469849\n",
      "Starting Epoch 238\n",
      "1.339372456073761\n",
      "Validation loss: 1.2913628816604614\n",
      "mse 1.2913628137477136\n",
      "Starting Epoch 239\n",
      "1.339044027030468\n",
      "Validation loss: 1.2904517650604248\n",
      "mse 1.2904517807108398\n",
      "New best model found at epoch 239 with validation loss 1.2904517650604248\n",
      "Starting Epoch 240\n",
      "1.3385304734110832\n",
      "Validation loss: 1.2906253337860107\n",
      "mse 1.2906253325809018\n",
      "Starting Epoch 241\n",
      "1.3382167344292004\n",
      "Validation loss: 1.2905387878417969\n",
      "mse 1.2905386758827628\n",
      "Starting Epoch 242\n",
      "1.337767854332924\n",
      "Validation loss: 1.2895506620407104\n",
      "mse 1.289550692527187\n",
      "New best model found at epoch 242 with validation loss 1.2895506620407104\n",
      "Starting Epoch 243\n",
      "1.3372990960876148\n",
      "Validation loss: 1.289703607559204\n",
      "mse 1.2897035328636872\n",
      "Starting Epoch 244\n",
      "1.336951993405819\n",
      "Validation loss: 1.2894519567489624\n",
      "mse 1.2894518943496003\n",
      "New best model found at epoch 244 with validation loss 1.2894519567489624\n",
      "Starting Epoch 245\n",
      "1.3365688994526863\n",
      "Validation loss: 1.288367509841919\n",
      "mse 1.2883674086473762\n",
      "New best model found at epoch 245 with validation loss 1.288367509841919\n",
      "Starting Epoch 246\n",
      "1.3360721568266551\n",
      "Validation loss: 1.2887455224990845\n",
      "mse 1.288745555406819\n",
      "Starting Epoch 247\n",
      "1.3357305725415547\n",
      "Validation loss: 1.2884159088134766\n",
      "mse 1.2884158717956635\n",
      "Starting Epoch 248\n",
      "1.3352922375003498\n",
      "Validation loss: 1.2873231172561646\n",
      "mse 1.2873229530113683\n",
      "New best model found at epoch 248 with validation loss 1.2873231172561646\n",
      "Starting Epoch 249\n",
      "1.334809072315693\n",
      "Validation loss: 1.2877449989318848\n",
      "mse 1.287744954444547\n",
      "Starting Epoch 250\n",
      "1.334484467903773\n",
      "Validation loss: 1.2873706817626953\n",
      "mse 1.287370613549367\n",
      "Starting Epoch 251\n",
      "1.3340803310275078\n",
      "Validation loss: 1.286449670791626\n",
      "mse 1.2864496227596494\n",
      "New best model found at epoch 251 with validation loss 1.286449670791626\n",
      "Starting Epoch 252\n",
      "1.3336052397886913\n",
      "Validation loss: 1.2868455648422241\n",
      "mse 1.286845592538446\n",
      "Starting Epoch 253\n",
      "1.3333093424638112\n",
      "Validation loss: 1.2865712642669678\n",
      "mse 1.2865712969208145\n",
      "Starting Epoch 254\n",
      "1.332851655781269\n",
      "Validation loss: 1.2853167057037354\n",
      "mse 1.285316743282349\n",
      "New best model found at epoch 254 with validation loss 1.2853167057037354\n",
      "Starting Epoch 255\n",
      "1.3324494237701099\n",
      "Validation loss: 1.2856861352920532\n",
      "mse 1.2856861928305332\n",
      "Starting Epoch 256\n",
      "1.332124650478363\n",
      "Validation loss: 1.2855247259140015\n",
      "mse 1.2855248911425776\n",
      "Starting Epoch 257\n",
      "1.3316834717988968\n",
      "Validation loss: 1.2851768732070923\n",
      "mse 1.285176908611391\n",
      "New best model found at epoch 257 with validation loss 1.2851768732070923\n",
      "Starting Epoch 258\n",
      "1.3312889461716015\n",
      "Validation loss: 1.284256100654602\n",
      "mse 1.2842561906672474\n",
      "New best model found at epoch 258 with validation loss 1.284256100654602\n",
      "Starting Epoch 259\n",
      "1.3308645635843277\n",
      "Validation loss: 1.2843552827835083\n",
      "mse 1.2843553383774398\n",
      "Starting Epoch 260\n",
      "1.3305181165536244\n",
      "Validation loss: 1.2843413352966309\n",
      "mse 1.2843413285836343\n",
      "Starting Epoch 261\n",
      "1.3300574123859406\n",
      "Validation loss: 1.283060073852539\n",
      "mse 1.2830600920116921\n",
      "New best model found at epoch 261 with validation loss 1.283060073852539\n",
      "Starting Epoch 262\n",
      "1.329728404680888\n",
      "Validation loss: 1.283373236656189\n",
      "mse 1.2833731312298944\n",
      "Starting Epoch 263\n",
      "1.3293280626336734\n",
      "Validation loss: 1.28316068649292\n",
      "mse 1.2831607169546633\n",
      "Starting Epoch 264\n",
      "1.3289738694826763\n",
      "Validation loss: 1.2828656435012817\n",
      "mse 1.2828655109824874\n",
      "New best model found at epoch 264 with validation loss 1.2828656435012817\n",
      "Starting Epoch 265\n",
      "1.3285916695992153\n",
      "Validation loss: 1.281977891921997\n",
      "mse 1.2819777294243693\n",
      "New best model found at epoch 265 with validation loss 1.281977891921997\n",
      "Starting Epoch 266\n",
      "1.3282684534788132\n",
      "Validation loss: 1.2817116975784302\n",
      "mse 1.2817117823749056\n",
      "New best model found at epoch 266 with validation loss 1.2817116975784302\n",
      "Starting Epoch 267\n",
      "1.3277684847513835\n",
      "Validation loss: 1.2810838222503662\n",
      "mse 1.281083882520347\n",
      "New best model found at epoch 267 with validation loss 1.2810838222503662\n",
      "Starting Epoch 268\n",
      "1.3273972769578297\n",
      "Validation loss: 1.2814464569091797\n",
      "mse 1.2814463208537605\n",
      "Starting Epoch 269\n",
      "1.3272010882695515\n",
      "Validation loss: 1.2810285091400146\n",
      "mse 1.2810284495633795\n",
      "New best model found at epoch 269 with validation loss 1.2810285091400146\n",
      "Starting Epoch 270\n",
      "1.3267022942503293\n",
      "Validation loss: 1.2803045511245728\n",
      "mse 1.2803045125369226\n",
      "New best model found at epoch 270 with validation loss 1.2803045511245728\n",
      "Starting Epoch 271\n",
      "1.326396721104781\n",
      "Validation loss: 1.280321717262268\n",
      "mse 1.2803216586914639\n",
      "Starting Epoch 272\n",
      "1.3259688367446263\n",
      "Validation loss: 1.279629111289978\n",
      "mse 1.2796291486460372\n",
      "New best model found at epoch 272 with validation loss 1.279629111289978\n",
      "Starting Epoch 273\n",
      "1.325706238547961\n",
      "Validation loss: 1.2798922061920166\n",
      "mse 1.2798921497991378\n",
      "Starting Epoch 274\n",
      "1.3253433605035145\n",
      "Validation loss: 1.2791669368743896\n",
      "mse 1.2791668319644593\n",
      "New best model found at epoch 274 with validation loss 1.2791669368743896\n",
      "Starting Epoch 275\n",
      "1.3248708347479503\n",
      "Validation loss: 1.2787880897521973\n",
      "mse 1.2787881354111783\n",
      "New best model found at epoch 275 with validation loss 1.2787880897521973\n",
      "Starting Epoch 276\n",
      "1.3246306454141934\n",
      "Validation loss: 1.2788249254226685\n",
      "mse 1.2788249359205488\n",
      "Starting Epoch 277\n",
      "1.3242317686478298\n",
      "Validation loss: 1.2782784700393677\n",
      "mse 1.2782784432375873\n",
      "New best model found at epoch 277 with validation loss 1.2782784700393677\n",
      "Starting Epoch 278\n",
      "1.3238491366306941\n",
      "Validation loss: 1.2779369354248047\n",
      "mse 1.2779369997871433\n",
      "New best model found at epoch 278 with validation loss 1.2779369354248047\n",
      "Starting Epoch 279\n",
      "1.3236111303170521\n",
      "Validation loss: 1.278085708618164\n",
      "mse 1.2780856613470886\n",
      "Starting Epoch 280\n",
      "1.3231986289223034\n",
      "Validation loss: 1.2778937816619873\n",
      "mse 1.2778938353834985\n",
      "New best model found at epoch 280 with validation loss 1.2778937816619873\n",
      "Starting Epoch 281\n",
      "1.322803574303786\n",
      "Validation loss: 1.2779114246368408\n",
      "mse 1.2779112930493466\n",
      "Starting Epoch 282\n",
      "1.3224179198344548\n",
      "Validation loss: 1.277547836303711\n",
      "mse 1.2775477595014737\n",
      "New best model found at epoch 282 with validation loss 1.277547836303711\n",
      "Starting Epoch 283\n",
      "1.3220383922259014\n",
      "Validation loss: 1.276965618133545\n",
      "mse 1.276965611513494\n",
      "New best model found at epoch 283 with validation loss 1.276965618133545\n",
      "Starting Epoch 284\n",
      "1.3215808992584546\n",
      "Validation loss: 1.2767366170883179\n",
      "mse 1.2767367200800783\n",
      "New best model found at epoch 284 with validation loss 1.2767366170883179\n",
      "Starting Epoch 285\n",
      "1.3211833263436954\n",
      "Validation loss: 1.276713252067566\n",
      "mse 1.2767131932531284\n",
      "New best model found at epoch 285 with validation loss 1.276713252067566\n",
      "Starting Epoch 286\n",
      "1.3208224723736446\n",
      "Validation loss: 1.2764393091201782\n",
      "mse 1.2764393511181071\n",
      "New best model found at epoch 286 with validation loss 1.2764393091201782\n",
      "Starting Epoch 287\n",
      "1.320463481048743\n",
      "Validation loss: 1.276027798652649\n",
      "mse 1.2760277228960772\n",
      "New best model found at epoch 287 with validation loss 1.276027798652649\n",
      "Starting Epoch 288\n",
      "1.3201385910312335\n",
      "Validation loss: 1.2764689922332764\n",
      "mse 1.2764690266230474\n",
      "Starting Epoch 289\n",
      "1.3197317247589428\n",
      "Validation loss: 1.276074767112732\n",
      "mse 1.2760748172331744\n",
      "Starting Epoch 290\n",
      "1.3193660974502563\n",
      "Validation loss: 1.2754701375961304\n",
      "mse 1.2754702451503905\n",
      "New best model found at epoch 290 with validation loss 1.2754701375961304\n",
      "Starting Epoch 291\n",
      "1.3189836988846462\n",
      "Validation loss: 1.2753617763519287\n",
      "mse 1.275361715760528\n",
      "New best model found at epoch 291 with validation loss 1.2753617763519287\n",
      "Starting Epoch 292\n",
      "1.3185523077845573\n",
      "Validation loss: 1.2753961086273193\n",
      "mse 1.275396235605094\n",
      "Starting Epoch 293\n",
      "1.3182498117287953\n",
      "Validation loss: 1.2751046419143677\n",
      "mse 1.2751045234304101\n",
      "New best model found at epoch 293 with validation loss 1.2751046419143677\n",
      "Starting Epoch 294\n",
      "1.3179737652341526\n",
      "Validation loss: 1.2744386196136475\n",
      "mse 1.274438542336412\n",
      "New best model found at epoch 294 with validation loss 1.2744386196136475\n",
      "Starting Epoch 295\n",
      "1.3175129070878029\n",
      "Validation loss: 1.2746022939682007\n",
      "mse 1.274602232413442\n",
      "Starting Epoch 296\n",
      "1.3171762824058533\n",
      "Validation loss: 1.274395227432251\n",
      "mse 1.2743952911906595\n",
      "New best model found at epoch 296 with validation loss 1.274395227432251\n",
      "Starting Epoch 297\n",
      "1.3168398638566334\n",
      "Validation loss: 1.2740572690963745\n",
      "mse 1.274057356832449\n",
      "New best model found at epoch 297 with validation loss 1.2740572690963745\n",
      "Starting Epoch 298\n",
      "1.3165411452452342\n",
      "Validation loss: 1.2739672660827637\n",
      "mse 1.2739672635258819\n",
      "New best model found at epoch 298 with validation loss 1.2739672660827637\n",
      "Starting Epoch 299\n",
      "1.3160847102602322\n",
      "Validation loss: 1.2739331722259521\n",
      "mse 1.2739331603514288\n",
      "New best model found at epoch 299 with validation loss 1.2739331722259521\n",
      "Starting Epoch 300\n",
      "1.3158411880334218\n",
      "Validation loss: 1.2734261751174927\n",
      "mse 1.2734261957781345\n",
      "New best model found at epoch 300 with validation loss 1.2734261751174927\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-20-10-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ece4c4",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 3\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 20 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "80d3e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "218b5f3b-d9b6-4add-a26c-8a439e7e3d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.648886129260063\n",
      "Validation loss: 2.4550955295562744\n",
      "mse 2.4550952972069475\n",
      "New best model found at epoch 1 with validation loss 2.4550955295562744\n",
      "Starting Epoch 2\n",
      "2.326302950580915\n",
      "Validation loss: 2.278740167617798\n",
      "mse 2.2787402679028963\n",
      "New best model found at epoch 2 with validation loss 2.278740167617798\n",
      "Starting Epoch 3\n",
      "2.1662920067707696\n",
      "Validation loss: 2.1061437129974365\n",
      "mse 2.106143621083117\n",
      "New best model found at epoch 3 with validation loss 2.1061437129974365\n",
      "Starting Epoch 4\n",
      "2.054077391823133\n",
      "Validation loss: 1.9957244396209717\n",
      "mse 1.9957244988149578\n",
      "New best model found at epoch 4 with validation loss 1.9957244396209717\n",
      "Starting Epoch 5\n",
      "1.9789185871680577\n",
      "Validation loss: 1.9149857759475708\n",
      "mse 1.914985942857469\n",
      "New best model found at epoch 5 with validation loss 1.9149857759475708\n",
      "Starting Epoch 6\n",
      "1.9199161330858867\n",
      "Validation loss: 1.8517818450927734\n",
      "mse 1.8517818431283661\n",
      "New best model found at epoch 6 with validation loss 1.8517818450927734\n",
      "Starting Epoch 7\n",
      "1.8724055389563243\n",
      "Validation loss: 1.801343321800232\n",
      "mse 1.801343111271574\n",
      "New best model found at epoch 7 with validation loss 1.801343321800232\n",
      "Starting Epoch 8\n",
      "1.8335890372594197\n",
      "Validation loss: 1.7589844465255737\n",
      "mse 1.758984511970155\n",
      "New best model found at epoch 8 with validation loss 1.7589844465255737\n",
      "Starting Epoch 9\n",
      "1.8014124035835266\n",
      "Validation loss: 1.7242494821548462\n",
      "mse 1.724249424332988\n",
      "New best model found at epoch 9 with validation loss 1.7242494821548462\n",
      "Starting Epoch 10\n",
      "1.7738713969786961\n",
      "Validation loss: 1.6954399347305298\n",
      "mse 1.6954400245881764\n",
      "New best model found at epoch 10 with validation loss 1.6954399347305298\n",
      "Starting Epoch 11\n",
      "1.750362957517306\n",
      "Validation loss: 1.6699726581573486\n",
      "mse 1.6699727777146618\n",
      "New best model found at epoch 11 with validation loss 1.6699726581573486\n",
      "Starting Epoch 12\n",
      "1.7283904453118641\n",
      "Validation loss: 1.646590232849121\n",
      "mse 1.646590122641417\n",
      "New best model found at epoch 12 with validation loss 1.646590232849121\n",
      "Starting Epoch 13\n",
      "1.7081298977136612\n",
      "Validation loss: 1.6291426420211792\n",
      "mse 1.6291427493103585\n",
      "New best model found at epoch 13 with validation loss 1.6291426420211792\n",
      "Starting Epoch 14\n",
      "1.6914910425742467\n",
      "Validation loss: 1.6134326457977295\n",
      "mse 1.6134325485725458\n",
      "New best model found at epoch 14 with validation loss 1.6134326457977295\n",
      "Starting Epoch 15\n",
      "1.6771783431371052\n",
      "Validation loss: 1.598932147026062\n",
      "mse 1.5989320842950716\n",
      "New best model found at epoch 15 with validation loss 1.598932147026062\n",
      "Starting Epoch 16\n",
      "1.6645972033341725\n",
      "Validation loss: 1.5849696397781372\n",
      "mse 1.5849696728158709\n",
      "New best model found at epoch 16 with validation loss 1.5849696397781372\n",
      "Starting Epoch 17\n",
      "1.6534457604090373\n",
      "Validation loss: 1.5737313032150269\n",
      "mse 1.5737312627651294\n",
      "New best model found at epoch 17 with validation loss 1.5737313032150269\n",
      "Starting Epoch 18\n",
      "1.6434332231680553\n",
      "Validation loss: 1.563679575920105\n",
      "mse 1.5636795412469635\n",
      "New best model found at epoch 18 with validation loss 1.563679575920105\n",
      "Starting Epoch 19\n",
      "1.634401982029279\n",
      "Validation loss: 1.5555644035339355\n",
      "mse 1.5555643136626482\n",
      "New best model found at epoch 19 with validation loss 1.5555644035339355\n",
      "Starting Epoch 20\n",
      "1.6261911590894063\n",
      "Validation loss: 1.546683430671692\n",
      "mse 1.5466834209063605\n",
      "New best model found at epoch 20 with validation loss 1.546683430671692\n",
      "Starting Epoch 21\n",
      "1.6183737864096959\n",
      "Validation loss: 1.5393260717391968\n",
      "mse 1.5393260333796766\n",
      "New best model found at epoch 21 with validation loss 1.5393260717391968\n",
      "Starting Epoch 22\n",
      "1.6112265487511952\n",
      "Validation loss: 1.532862901687622\n",
      "mse 1.5328629411260009\n",
      "New best model found at epoch 22 with validation loss 1.532862901687622\n",
      "Starting Epoch 23\n",
      "1.6046136021614075\n",
      "Validation loss: 1.5269670486450195\n",
      "mse 1.526966944038543\n",
      "New best model found at epoch 23 with validation loss 1.5269670486450195\n",
      "Starting Epoch 24\n",
      "1.5984355509281158\n",
      "Validation loss: 1.521011471748352\n",
      "mse 1.5210113483506442\n",
      "New best model found at epoch 24 with validation loss 1.521011471748352\n",
      "Starting Epoch 25\n",
      "1.59251968562603\n",
      "Validation loss: 1.516020655632019\n",
      "mse 1.5160206008862247\n",
      "New best model found at epoch 25 with validation loss 1.516020655632019\n",
      "Starting Epoch 26\n",
      "1.5877507279316585\n",
      "Validation loss: 1.515372395515442\n",
      "mse 1.5153723315294279\n",
      "New best model found at epoch 26 with validation loss 1.515372395515442\n",
      "Starting Epoch 27\n",
      "1.5826919476191204\n",
      "Validation loss: 1.5056190490722656\n",
      "mse 1.5056191296170574\n",
      "New best model found at epoch 27 with validation loss 1.5056190490722656\n",
      "Starting Epoch 28\n",
      "1.5768695573012035\n",
      "Validation loss: 1.5012640953063965\n",
      "mse 1.5012640189274116\n",
      "New best model found at epoch 28 with validation loss 1.5012640953063965\n",
      "Starting Epoch 29\n",
      "1.5722671796878178\n",
      "Validation loss: 1.4978845119476318\n",
      "mse 1.4978844826745974\n",
      "New best model found at epoch 29 with validation loss 1.4978845119476318\n",
      "Starting Epoch 30\n",
      "1.5678358177344005\n",
      "Validation loss: 1.4948557615280151\n",
      "mse 1.4948556501382233\n",
      "New best model found at epoch 30 with validation loss 1.4948557615280151\n",
      "Starting Epoch 31\n",
      "1.563656245668729\n",
      "Validation loss: 1.491637110710144\n",
      "mse 1.4916370804718795\n",
      "New best model found at epoch 31 with validation loss 1.491637110710144\n",
      "Starting Epoch 32\n",
      "1.5597014129161835\n",
      "Validation loss: 1.487733244895935\n",
      "mse 1.487733220327617\n",
      "New best model found at epoch 32 with validation loss 1.487733244895935\n",
      "Starting Epoch 33\n",
      "1.5557868927717209\n",
      "Validation loss: 1.4845017194747925\n",
      "mse 1.4845016903062827\n",
      "New best model found at epoch 33 with validation loss 1.4845017194747925\n",
      "Starting Epoch 34\n",
      "1.5520382821559906\n",
      "Validation loss: 1.4814821481704712\n",
      "mse 1.4814821112821512\n",
      "New best model found at epoch 34 with validation loss 1.4814821481704712\n",
      "Starting Epoch 35\n",
      "1.5484113991260529\n",
      "Validation loss: 1.4787983894348145\n",
      "mse 1.4787984865402464\n",
      "New best model found at epoch 35 with validation loss 1.4787983894348145\n",
      "Starting Epoch 36\n",
      "1.5449568927288055\n",
      "Validation loss: 1.4755724668502808\n",
      "mse 1.4755724407380681\n",
      "New best model found at epoch 36 with validation loss 1.4755724668502808\n",
      "Starting Epoch 37\n",
      "1.5415253788232803\n",
      "Validation loss: 1.4727426767349243\n",
      "mse 1.4727427620692712\n",
      "New best model found at epoch 37 with validation loss 1.4727426767349243\n",
      "Starting Epoch 38\n",
      "1.5381895005702972\n",
      "Validation loss: 1.4701322317123413\n",
      "mse 1.470132201547776\n",
      "New best model found at epoch 38 with validation loss 1.4701322317123413\n",
      "Starting Epoch 39\n",
      "1.5346757471561432\n",
      "Validation loss: 1.4679216146469116\n",
      "mse 1.4679215990496952\n",
      "New best model found at epoch 39 with validation loss 1.4679216146469116\n",
      "Starting Epoch 40\n",
      "1.5315107504526775\n",
      "Validation loss: 1.465397834777832\n",
      "mse 1.4653978053381447\n",
      "New best model found at epoch 40 with validation loss 1.465397834777832\n",
      "Starting Epoch 41\n",
      "1.52872800330321\n",
      "Validation loss: 1.4622173309326172\n",
      "mse 1.46221732283485\n",
      "New best model found at epoch 41 with validation loss 1.4622173309326172\n",
      "Starting Epoch 42\n",
      "1.5256516635417938\n",
      "Validation loss: 1.4599244594573975\n",
      "mse 1.4599244375579616\n",
      "New best model found at epoch 42 with validation loss 1.4599244594573975\n",
      "Starting Epoch 43\n",
      "1.5227459420760472\n",
      "Validation loss: 1.457678198814392\n",
      "mse 1.4576781939752226\n",
      "New best model found at epoch 43 with validation loss 1.457678198814392\n",
      "Starting Epoch 44\n",
      "1.5197414358456929\n",
      "Validation loss: 1.4550873041152954\n",
      "mse 1.4550873312225308\n",
      "New best model found at epoch 44 with validation loss 1.4550873041152954\n",
      "Starting Epoch 45\n",
      "1.5169330636660259\n",
      "Validation loss: 1.4532570838928223\n",
      "mse 1.453256939882375\n",
      "New best model found at epoch 45 with validation loss 1.4532570838928223\n",
      "Starting Epoch 46\n",
      "1.5143306801716487\n",
      "Validation loss: 1.4507458209991455\n",
      "mse 1.4507457755642574\n",
      "New best model found at epoch 46 with validation loss 1.4507458209991455\n",
      "Starting Epoch 47\n",
      "1.5117347190777461\n",
      "Validation loss: 1.448578953742981\n",
      "mse 1.4485789519855483\n",
      "New best model found at epoch 47 with validation loss 1.448578953742981\n",
      "Starting Epoch 48\n",
      "1.5091417580842972\n",
      "Validation loss: 1.4464259147644043\n",
      "mse 1.446425980066656\n",
      "New best model found at epoch 48 with validation loss 1.4464259147644043\n",
      "Starting Epoch 49\n",
      "1.5065551151831944\n",
      "Validation loss: 1.4448896646499634\n",
      "mse 1.4448898104724575\n",
      "New best model found at epoch 49 with validation loss 1.4448896646499634\n",
      "Starting Epoch 50\n",
      "1.504205231865247\n",
      "Validation loss: 1.442352533340454\n",
      "mse 1.4423524449570666\n",
      "New best model found at epoch 50 with validation loss 1.442352533340454\n",
      "Starting Epoch 51\n",
      "1.5017160971959431\n",
      "Validation loss: 1.4405019283294678\n",
      "mse 1.4405019247128237\n",
      "New best model found at epoch 51 with validation loss 1.4405019283294678\n",
      "Starting Epoch 52\n",
      "1.4990620166063309\n",
      "Validation loss: 1.4371161460876465\n",
      "mse 1.4371162430072322\n",
      "New best model found at epoch 52 with validation loss 1.4371161460876465\n",
      "Starting Epoch 53\n",
      "1.4957851072152455\n",
      "Validation loss: 1.4345617294311523\n",
      "mse 1.4345617196487948\n",
      "New best model found at epoch 53 with validation loss 1.4345617294311523\n",
      "Starting Epoch 54\n",
      "1.4927651484807332\n",
      "Validation loss: 1.4322391748428345\n",
      "mse 1.4322392912437745\n",
      "New best model found at epoch 54 with validation loss 1.4322391748428345\n",
      "Starting Epoch 55\n",
      "1.4899771958589554\n",
      "Validation loss: 1.430573582649231\n",
      "mse 1.4305735441346854\n",
      "New best model found at epoch 55 with validation loss 1.430573582649231\n",
      "Starting Epoch 56\n",
      "1.4874200473229091\n",
      "Validation loss: 1.4291565418243408\n",
      "mse 1.429156533721841\n",
      "New best model found at epoch 56 with validation loss 1.4291565418243408\n",
      "Starting Epoch 57\n",
      "1.4850169519583385\n",
      "Validation loss: 1.4277702569961548\n",
      "mse 1.427770233367813\n",
      "New best model found at epoch 57 with validation loss 1.4277702569961548\n",
      "Starting Epoch 58\n",
      "1.4828110535939534\n",
      "Validation loss: 1.426242709159851\n",
      "mse 1.4262427079863704\n",
      "New best model found at epoch 58 with validation loss 1.426242709159851\n",
      "Starting Epoch 59\n",
      "1.48060139020284\n",
      "Validation loss: 1.4246495962142944\n",
      "mse 1.4246496645321822\n",
      "New best model found at epoch 59 with validation loss 1.4246495962142944\n",
      "Starting Epoch 60\n",
      "1.478455126285553\n",
      "Validation loss: 1.42318856716156\n",
      "mse 1.4231887056034482\n",
      "New best model found at epoch 60 with validation loss 1.42318856716156\n",
      "Starting Epoch 61\n",
      "1.4764889180660248\n",
      "Validation loss: 1.4216268062591553\n",
      "mse 1.4216267210440388\n",
      "New best model found at epoch 61 with validation loss 1.4216268062591553\n",
      "Starting Epoch 62\n",
      "1.4744059989849727\n",
      "Validation loss: 1.4196979999542236\n",
      "mse 1.4196977590596143\n",
      "New best model found at epoch 62 with validation loss 1.4196979999542236\n",
      "Starting Epoch 63\n",
      "1.4724895308415096\n",
      "Validation loss: 1.4177542924880981\n",
      "mse 1.4177542126464366\n",
      "New best model found at epoch 63 with validation loss 1.4177542924880981\n",
      "Starting Epoch 64\n",
      "1.4702864686648052\n",
      "Validation loss: 1.4172998666763306\n",
      "mse 1.4172997237819172\n",
      "New best model found at epoch 64 with validation loss 1.4172998666763306\n",
      "Starting Epoch 65\n",
      "1.468590870499611\n",
      "Validation loss: 1.4149086475372314\n",
      "mse 1.4149087245377958\n",
      "New best model found at epoch 65 with validation loss 1.4149086475372314\n",
      "Starting Epoch 66\n",
      "1.466718077659607\n",
      "Validation loss: 1.4136790037155151\n",
      "mse 1.4136790261662893\n",
      "New best model found at epoch 66 with validation loss 1.4136790037155151\n",
      "Starting Epoch 67\n",
      "1.4648059258858364\n",
      "Validation loss: 1.4128395318984985\n",
      "mse 1.412839467635791\n",
      "New best model found at epoch 67 with validation loss 1.4128395318984985\n",
      "Starting Epoch 68\n",
      "1.4630715250968933\n",
      "Validation loss: 1.4110280275344849\n",
      "mse 1.411027989153549\n",
      "New best model found at epoch 68 with validation loss 1.4110280275344849\n",
      "Starting Epoch 69\n",
      "1.4611895829439163\n",
      "Validation loss: 1.4102898836135864\n",
      "mse 1.4102897519303406\n",
      "New best model found at epoch 69 with validation loss 1.4102898836135864\n",
      "Starting Epoch 70\n",
      "1.4595197836558025\n",
      "Validation loss: 1.4084569215774536\n",
      "mse 1.4084569176326378\n",
      "New best model found at epoch 70 with validation loss 1.4084569215774536\n",
      "Starting Epoch 71\n",
      "1.4577116668224335\n",
      "Validation loss: 1.4071910381317139\n",
      "mse 1.4071911189873185\n",
      "New best model found at epoch 71 with validation loss 1.4071910381317139\n",
      "Starting Epoch 72\n",
      "1.4560087323188782\n",
      "Validation loss: 1.4058899879455566\n",
      "mse 1.405889901342178\n",
      "New best model found at epoch 72 with validation loss 1.4058899879455566\n",
      "Starting Epoch 73\n",
      "1.4543465624252956\n",
      "Validation loss: 1.4045785665512085\n",
      "mse 1.4045784447478125\n",
      "New best model found at epoch 73 with validation loss 1.4045785665512085\n",
      "Starting Epoch 74\n",
      "1.452522873878479\n",
      "Validation loss: 1.4046505689620972\n",
      "mse 1.4046506894356265\n",
      "Starting Epoch 75\n",
      "1.4511029173930485\n",
      "Validation loss: 1.4025201797485352\n",
      "mse 1.4025200832993086\n",
      "New best model found at epoch 75 with validation loss 1.4025201797485352\n",
      "Starting Epoch 76\n",
      "1.4493722468614578\n",
      "Validation loss: 1.4008265733718872\n",
      "mse 1.4008265559681061\n",
      "New best model found at epoch 76 with validation loss 1.4008265733718872\n",
      "Starting Epoch 77\n",
      "1.447662780682246\n",
      "Validation loss: 1.4005789756774902\n",
      "mse 1.4005788974261493\n",
      "New best model found at epoch 77 with validation loss 1.4005789756774902\n",
      "Starting Epoch 78\n",
      "1.446189984679222\n",
      "Validation loss: 1.3983196020126343\n",
      "mse 1.398319561286099\n",
      "New best model found at epoch 78 with validation loss 1.3983196020126343\n",
      "Starting Epoch 79\n",
      "1.444391888876756\n",
      "Validation loss: 1.396701693534851\n",
      "mse 1.3967016895013176\n",
      "New best model found at epoch 79 with validation loss 1.396701693534851\n",
      "Starting Epoch 80\n",
      "1.4426716988285382\n",
      "Validation loss: 1.3965998888015747\n",
      "mse 1.39659986642093\n",
      "New best model found at epoch 80 with validation loss 1.3965998888015747\n",
      "Starting Epoch 81\n",
      "1.4412040039896965\n",
      "Validation loss: 1.394995093345642\n",
      "mse 1.3949950372840683\n",
      "New best model found at epoch 81 with validation loss 1.394995093345642\n",
      "Starting Epoch 82\n",
      "1.4396197572350502\n",
      "Validation loss: 1.392975926399231\n",
      "mse 1.392975888820525\n",
      "New best model found at epoch 82 with validation loss 1.392975926399231\n",
      "Starting Epoch 83\n",
      "1.437987707555294\n",
      "Validation loss: 1.391835331916809\n",
      "mse 1.3918353681378481\n",
      "New best model found at epoch 83 with validation loss 1.391835331916809\n",
      "Starting Epoch 84\n",
      "1.4365243713061016\n",
      "Validation loss: 1.390560507774353\n",
      "mse 1.3905605322243535\n",
      "New best model found at epoch 84 with validation loss 1.390560507774353\n",
      "Starting Epoch 85\n",
      "1.4349886079629262\n",
      "Validation loss: 1.3895611763000488\n",
      "mse 1.3895611630606965\n",
      "New best model found at epoch 85 with validation loss 1.3895611763000488\n",
      "Starting Epoch 86\n",
      "1.4336349094907443\n",
      "Validation loss: 1.3883401155471802\n",
      "mse 1.388340099696256\n",
      "New best model found at epoch 86 with validation loss 1.3883401155471802\n",
      "Starting Epoch 87\n",
      "1.4321355024973552\n",
      "Validation loss: 1.3884018659591675\n",
      "mse 1.3884018887144585\n",
      "Starting Epoch 88\n",
      "1.430935171743234\n",
      "Validation loss: 1.3872851133346558\n",
      "mse 1.3872852184842712\n",
      "New best model found at epoch 88 with validation loss 1.3872851133346558\n",
      "Starting Epoch 89\n",
      "1.4296035741766293\n",
      "Validation loss: 1.3853994607925415\n",
      "mse 1.385399402829625\n",
      "New best model found at epoch 89 with validation loss 1.3853994607925415\n",
      "Starting Epoch 90\n",
      "1.428183637559414\n",
      "Validation loss: 1.3845531940460205\n",
      "mse 1.3845532362880009\n",
      "New best model found at epoch 90 with validation loss 1.3845531940460205\n",
      "Starting Epoch 91\n",
      "1.426915851732095\n",
      "Validation loss: 1.3835312128067017\n",
      "mse 1.3835312494621193\n",
      "New best model found at epoch 91 with validation loss 1.3835312128067017\n",
      "Starting Epoch 92\n",
      "1.425625150402387\n",
      "Validation loss: 1.3826366662979126\n",
      "mse 1.3826366624407787\n",
      "New best model found at epoch 92 with validation loss 1.3826366662979126\n",
      "Starting Epoch 93\n",
      "1.4243513941764832\n",
      "Validation loss: 1.3813010454177856\n",
      "mse 1.381301189369106\n",
      "New best model found at epoch 93 with validation loss 1.3813010454177856\n",
      "Starting Epoch 94\n",
      "1.4230880389610927\n",
      "Validation loss: 1.3805521726608276\n",
      "mse 1.3805521450050615\n",
      "New best model found at epoch 94 with validation loss 1.3805521726608276\n",
      "Starting Epoch 95\n",
      "1.4218788196643193\n",
      "Validation loss: 1.3797742128372192\n",
      "mse 1.379774173321966\n",
      "New best model found at epoch 95 with validation loss 1.3797742128372192\n",
      "Starting Epoch 96\n",
      "1.4206633145610492\n",
      "Validation loss: 1.3789092302322388\n",
      "mse 1.3789092732352841\n",
      "New best model found at epoch 96 with validation loss 1.3789092302322388\n",
      "Starting Epoch 97\n",
      "1.4194604729612668\n",
      "Validation loss: 1.3780282735824585\n",
      "mse 1.3780283218704807\n",
      "New best model found at epoch 97 with validation loss 1.3780282735824585\n",
      "Starting Epoch 98\n",
      "1.4183135703206062\n",
      "Validation loss: 1.3771684169769287\n",
      "mse 1.3771684700932867\n",
      "New best model found at epoch 98 with validation loss 1.3771684169769287\n",
      "Starting Epoch 99\n",
      "1.4171724592645962\n",
      "Validation loss: 1.376341462135315\n",
      "mse 1.3763413869434118\n",
      "New best model found at epoch 99 with validation loss 1.376341462135315\n",
      "Starting Epoch 100\n",
      "1.4160423278808594\n",
      "Validation loss: 1.3755983114242554\n",
      "mse 1.375598268194636\n",
      "New best model found at epoch 100 with validation loss 1.3755983114242554\n",
      "Starting Epoch 101\n",
      "1.4148795381188393\n",
      "Validation loss: 1.3747807741165161\n",
      "mse 1.3747807406538897\n",
      "New best model found at epoch 101 with validation loss 1.3747807741165161\n",
      "Starting Epoch 102\n",
      "1.4137785509228706\n",
      "Validation loss: 1.374000906944275\n",
      "mse 1.3740008536018389\n",
      "New best model found at epoch 102 with validation loss 1.374000906944275\n",
      "Starting Epoch 103\n",
      "1.4127004121740658\n",
      "Validation loss: 1.3732796907424927\n",
      "mse 1.3732796685814983\n",
      "New best model found at epoch 103 with validation loss 1.3732796907424927\n",
      "Starting Epoch 104\n",
      "1.4115889941652615\n",
      "Validation loss: 1.3724461793899536\n",
      "mse 1.3724461621520052\n",
      "New best model found at epoch 104 with validation loss 1.3724461793899536\n",
      "Starting Epoch 105\n",
      "1.4104795729120572\n",
      "Validation loss: 1.371711015701294\n",
      "mse 1.3717108304940429\n",
      "New best model found at epoch 105 with validation loss 1.371711015701294\n",
      "Starting Epoch 106\n",
      "1.4094515442848206\n",
      "Validation loss: 1.3709362745285034\n",
      "mse 1.3709361952017183\n",
      "New best model found at epoch 106 with validation loss 1.3709362745285034\n",
      "Starting Epoch 107\n",
      "1.4083604340751965\n",
      "Validation loss: 1.3702105283737183\n",
      "mse 1.3702103529107243\n",
      "New best model found at epoch 107 with validation loss 1.3702105283737183\n",
      "Starting Epoch 108\n",
      "1.407352643708388\n",
      "Validation loss: 1.3693767786026\n",
      "mse 1.3693766667200602\n",
      "New best model found at epoch 108 with validation loss 1.3693767786026\n",
      "Starting Epoch 109\n",
      "1.4062637016177177\n",
      "Validation loss: 1.3692827224731445\n",
      "mse 1.3692828186596988\n",
      "New best model found at epoch 109 with validation loss 1.3692827224731445\n",
      "Starting Epoch 110\n",
      "1.405329888065656\n",
      "Validation loss: 1.3678284883499146\n",
      "mse 1.367828484213677\n",
      "New best model found at epoch 110 with validation loss 1.3678284883499146\n",
      "Starting Epoch 111\n",
      "1.404267484943072\n",
      "Validation loss: 1.367112159729004\n",
      "mse 1.367112166697671\n",
      "New best model found at epoch 111 with validation loss 1.367112159729004\n",
      "Starting Epoch 112\n",
      "1.4032571762800217\n",
      "Validation loss: 1.3663426637649536\n",
      "mse 1.36634273459783\n",
      "New best model found at epoch 112 with validation loss 1.3663426637649536\n",
      "Starting Epoch 113\n",
      "1.4022621860106785\n",
      "Validation loss: 1.3655375242233276\n",
      "mse 1.3655373862725408\n",
      "New best model found at epoch 113 with validation loss 1.3655375242233276\n",
      "Starting Epoch 114\n",
      "1.4013027970989544\n",
      "Validation loss: 1.3647844791412354\n",
      "mse 1.364784339603438\n",
      "New best model found at epoch 114 with validation loss 1.3647844791412354\n",
      "Starting Epoch 115\n",
      "1.4003366480271022\n",
      "Validation loss: 1.3640779256820679\n",
      "mse 1.3640778643817484\n",
      "New best model found at epoch 115 with validation loss 1.3640779256820679\n",
      "Starting Epoch 116\n",
      "1.3993563974897067\n",
      "Validation loss: 1.3633029460906982\n",
      "mse 1.3633029488415593\n",
      "New best model found at epoch 116 with validation loss 1.3633029460906982\n",
      "Starting Epoch 117\n",
      "1.3984014615416527\n",
      "Validation loss: 1.3626294136047363\n",
      "mse 1.3626293951938142\n",
      "New best model found at epoch 117 with validation loss 1.3626294136047363\n",
      "Starting Epoch 118\n",
      "1.3974306906263034\n",
      "Validation loss: 1.36178719997406\n",
      "mse 1.3617873636422981\n",
      "New best model found at epoch 118 with validation loss 1.36178719997406\n",
      "Starting Epoch 119\n",
      "1.3964841440320015\n",
      "Validation loss: 1.3610142469406128\n",
      "mse 1.3610143699874815\n",
      "New best model found at epoch 119 with validation loss 1.3610142469406128\n",
      "Starting Epoch 120\n",
      "1.3955731118718784\n",
      "Validation loss: 1.3602094650268555\n",
      "mse 1.3602095436003867\n",
      "New best model found at epoch 120 with validation loss 1.3602094650268555\n",
      "Starting Epoch 121\n",
      "1.3946213002006214\n",
      "Validation loss: 1.3595670461654663\n",
      "mse 1.3595670941220317\n",
      "New best model found at epoch 121 with validation loss 1.3595670461654663\n",
      "Starting Epoch 122\n",
      "1.393722636004289\n",
      "Validation loss: 1.3588379621505737\n",
      "mse 1.3588379088908196\n",
      "New best model found at epoch 122 with validation loss 1.3588379621505737\n",
      "Starting Epoch 123\n",
      "1.3927754337588947\n",
      "Validation loss: 1.358121633529663\n",
      "mse 1.3581214988202392\n",
      "New best model found at epoch 123 with validation loss 1.358121633529663\n",
      "Starting Epoch 124\n",
      "1.3919069891174634\n",
      "Validation loss: 1.3573789596557617\n",
      "mse 1.3573789965157563\n",
      "New best model found at epoch 124 with validation loss 1.3573789596557617\n",
      "Starting Epoch 125\n",
      "1.390985021988551\n",
      "Validation loss: 1.3569051027297974\n",
      "mse 1.3569051046600356\n",
      "New best model found at epoch 125 with validation loss 1.3569051027297974\n",
      "Starting Epoch 126\n",
      "1.3901056945323944\n",
      "Validation loss: 1.3561800718307495\n",
      "mse 1.3561800847230345\n",
      "New best model found at epoch 126 with validation loss 1.3561800718307495\n",
      "Starting Epoch 127\n",
      "1.3892247925202053\n",
      "Validation loss: 1.3554832935333252\n",
      "mse 1.3554832967492438\n",
      "New best model found at epoch 127 with validation loss 1.3554832935333252\n",
      "Starting Epoch 128\n",
      "1.3883973037203152\n",
      "Validation loss: 1.3548475503921509\n",
      "mse 1.3548475547751604\n",
      "New best model found at epoch 128 with validation loss 1.3548475503921509\n",
      "Starting Epoch 129\n",
      "1.3874677916367848\n",
      "Validation loss: 1.3546127080917358\n",
      "mse 1.354612788789516\n",
      "New best model found at epoch 129 with validation loss 1.3546127080917358\n",
      "Starting Epoch 130\n",
      "1.386624736090501\n",
      "Validation loss: 1.353860855102539\n",
      "mse 1.3538607901830906\n",
      "New best model found at epoch 130 with validation loss 1.353860855102539\n",
      "Starting Epoch 131\n",
      "1.3858137006560962\n",
      "Validation loss: 1.3531830310821533\n",
      "mse 1.3531830902938402\n",
      "New best model found at epoch 131 with validation loss 1.3531830310821533\n",
      "Starting Epoch 132\n",
      "1.3849355652928352\n",
      "Validation loss: 1.35251784324646\n",
      "mse 1.3525176887973094\n",
      "New best model found at epoch 132 with validation loss 1.35251784324646\n",
      "Starting Epoch 133\n",
      "1.3841113621989887\n",
      "Validation loss: 1.3519258499145508\n",
      "mse 1.351925954780119\n",
      "New best model found at epoch 133 with validation loss 1.3519258499145508\n",
      "Starting Epoch 134\n",
      "1.3832844992478688\n",
      "Validation loss: 1.3514788150787354\n",
      "mse 1.351478838229425\n",
      "New best model found at epoch 134 with validation loss 1.3514788150787354\n",
      "Starting Epoch 135\n",
      "1.382490371664365\n",
      "Validation loss: 1.350820541381836\n",
      "mse 1.3508205437560463\n",
      "New best model found at epoch 135 with validation loss 1.350820541381836\n",
      "Starting Epoch 136\n",
      "1.3816651478409767\n",
      "Validation loss: 1.3501001596450806\n",
      "mse 1.3501002446117847\n",
      "New best model found at epoch 136 with validation loss 1.3501001596450806\n",
      "Starting Epoch 137\n",
      "1.3808086936672528\n",
      "Validation loss: 1.349460244178772\n",
      "mse 1.3494601557671977\n",
      "New best model found at epoch 137 with validation loss 1.349460244178772\n",
      "Starting Epoch 138\n",
      "1.3800634294748306\n",
      "Validation loss: 1.3488103151321411\n",
      "mse 1.3488103804612508\n",
      "New best model found at epoch 138 with validation loss 1.3488103151321411\n",
      "Starting Epoch 139\n",
      "1.3793058494726818\n",
      "Validation loss: 1.3481053113937378\n",
      "mse 1.3481052571793224\n",
      "New best model found at epoch 139 with validation loss 1.3481053113937378\n",
      "Starting Epoch 140\n",
      "1.3784875323375065\n",
      "Validation loss: 1.347313404083252\n",
      "mse 1.3473133848592176\n",
      "New best model found at epoch 140 with validation loss 1.347313404083252\n",
      "Starting Epoch 141\n",
      "1.3777293612559636\n",
      "Validation loss: 1.3471119403839111\n",
      "mse 1.3471118859430118\n",
      "New best model found at epoch 141 with validation loss 1.3471119403839111\n",
      "Starting Epoch 142\n",
      "1.3769734998544056\n",
      "Validation loss: 1.3463377952575684\n",
      "mse 1.3463378802301003\n",
      "New best model found at epoch 142 with validation loss 1.3463377952575684\n",
      "Starting Epoch 143\n",
      "1.3761858716607094\n",
      "Validation loss: 1.3456952571868896\n",
      "mse 1.3456952171899899\n",
      "New best model found at epoch 143 with validation loss 1.3456952571868896\n",
      "Starting Epoch 144\n",
      "1.3753615493575733\n",
      "Validation loss: 1.345076084136963\n",
      "mse 1.3450761567775487\n",
      "New best model found at epoch 144 with validation loss 1.345076084136963\n",
      "Starting Epoch 145\n",
      "1.374544121325016\n",
      "Validation loss: 1.3449498414993286\n",
      "mse 1.344949841446942\n",
      "New best model found at epoch 145 with validation loss 1.3449498414993286\n",
      "Starting Epoch 146\n",
      "1.3737503613034885\n",
      "Validation loss: 1.3446879386901855\n",
      "mse 1.3446879399205023\n",
      "New best model found at epoch 146 with validation loss 1.3446879386901855\n",
      "Starting Epoch 147\n",
      "1.372976114352544\n",
      "Validation loss: 1.3442821502685547\n",
      "mse 1.3442820139903564\n",
      "New best model found at epoch 147 with validation loss 1.3442821502685547\n",
      "Starting Epoch 148\n",
      "1.3722026521960895\n",
      "Validation loss: 1.343679428100586\n",
      "mse 1.3436794268547245\n",
      "New best model found at epoch 148 with validation loss 1.343679428100586\n",
      "Starting Epoch 149\n",
      "1.371460181971391\n",
      "Validation loss: 1.3428822755813599\n",
      "mse 1.3428823208374314\n",
      "New best model found at epoch 149 with validation loss 1.3428822755813599\n",
      "Starting Epoch 150\n",
      "1.370655747751395\n",
      "Validation loss: 1.342204213142395\n",
      "mse 1.342204305190461\n",
      "New best model found at epoch 150 with validation loss 1.342204213142395\n",
      "Starting Epoch 151\n",
      "1.3699318543076515\n",
      "Validation loss: 1.3416545391082764\n",
      "mse 1.3416546195645758\n",
      "New best model found at epoch 151 with validation loss 1.3416545391082764\n",
      "Starting Epoch 152\n",
      "1.3691914603114128\n",
      "Validation loss: 1.3408117294311523\n",
      "mse 1.340811719916826\n",
      "New best model found at epoch 152 with validation loss 1.3408117294311523\n",
      "Starting Epoch 153\n",
      "1.3684821153680484\n",
      "Validation loss: 1.3399970531463623\n",
      "mse 1.3399970574401077\n",
      "New best model found at epoch 153 with validation loss 1.3399970531463623\n",
      "Starting Epoch 154\n",
      "1.3676913728316624\n",
      "Validation loss: 1.3395851850509644\n",
      "mse 1.3395852784050055\n",
      "New best model found at epoch 154 with validation loss 1.3395851850509644\n",
      "Starting Epoch 155\n",
      "1.3670130148530006\n",
      "Validation loss: 1.3386958837509155\n",
      "mse 1.3386958671214615\n",
      "New best model found at epoch 155 with validation loss 1.3386958837509155\n",
      "Starting Epoch 156\n",
      "1.3662277484933536\n",
      "Validation loss: 1.3379513025283813\n",
      "mse 1.3379513004088648\n",
      "New best model found at epoch 156 with validation loss 1.3379513025283813\n",
      "Starting Epoch 157\n",
      "1.3655014062921207\n",
      "Validation loss: 1.3372704982757568\n",
      "mse 1.3372704689874537\n",
      "New best model found at epoch 157 with validation loss 1.3372704982757568\n",
      "Starting Epoch 158\n",
      "1.364731289446354\n",
      "Validation loss: 1.3368480205535889\n",
      "mse 1.336847980373212\n",
      "New best model found at epoch 158 with validation loss 1.3368480205535889\n",
      "Starting Epoch 159\n",
      "1.3640226324399312\n",
      "Validation loss: 1.336126446723938\n",
      "mse 1.3361264492272718\n",
      "New best model found at epoch 159 with validation loss 1.336126446723938\n",
      "Starting Epoch 160\n",
      "1.3632735535502434\n",
      "Validation loss: 1.3354809284210205\n",
      "mse 1.3354808899161306\n",
      "New best model found at epoch 160 with validation loss 1.3354809284210205\n",
      "Starting Epoch 161\n",
      "1.362538071970145\n",
      "Validation loss: 1.3350558280944824\n",
      "mse 1.3350558081229542\n",
      "New best model found at epoch 161 with validation loss 1.3350558280944824\n",
      "Starting Epoch 162\n",
      "1.3618467077612877\n",
      "Validation loss: 1.3343353271484375\n",
      "mse 1.3343353491980714\n",
      "New best model found at epoch 162 with validation loss 1.3343353271484375\n",
      "Starting Epoch 163\n",
      "1.3610644812385242\n",
      "Validation loss: 1.3337723016738892\n",
      "mse 1.333772317441819\n",
      "New best model found at epoch 163 with validation loss 1.3337723016738892\n",
      "Starting Epoch 164\n",
      "1.3603983422120411\n",
      "Validation loss: 1.332953691482544\n",
      "mse 1.332953735422797\n",
      "New best model found at epoch 164 with validation loss 1.332953691482544\n",
      "Starting Epoch 165\n",
      "1.3597053190072377\n",
      "Validation loss: 1.332632064819336\n",
      "mse 1.3326321602811317\n",
      "New best model found at epoch 165 with validation loss 1.332632064819336\n",
      "Starting Epoch 166\n",
      "1.3590382958451908\n",
      "Validation loss: 1.332058310508728\n",
      "mse 1.3320585340381175\n",
      "New best model found at epoch 166 with validation loss 1.332058310508728\n",
      "Starting Epoch 167\n",
      "1.3583784649769466\n",
      "Validation loss: 1.3315305709838867\n",
      "mse 1.3315304940525525\n",
      "New best model found at epoch 167 with validation loss 1.3315305709838867\n",
      "Starting Epoch 168\n",
      "1.3576750084757805\n",
      "Validation loss: 1.331201434135437\n",
      "mse 1.3312014681752626\n",
      "New best model found at epoch 168 with validation loss 1.331201434135437\n",
      "Starting Epoch 169\n",
      "1.3570530737439792\n",
      "Validation loss: 1.330579161643982\n",
      "mse 1.330579186648104\n",
      "New best model found at epoch 169 with validation loss 1.330579161643982\n",
      "Starting Epoch 170\n",
      "1.356385091940562\n",
      "Validation loss: 1.330273151397705\n",
      "mse 1.3302731389116622\n",
      "New best model found at epoch 170 with validation loss 1.330273151397705\n",
      "Starting Epoch 171\n",
      "1.3557170530160267\n",
      "Validation loss: 1.3298243284225464\n",
      "mse 1.3298243247948685\n",
      "New best model found at epoch 171 with validation loss 1.3298243284225464\n",
      "Starting Epoch 172\n",
      "1.3550700172781944\n",
      "Validation loss: 1.32917320728302\n",
      "mse 1.3291732292660945\n",
      "New best model found at epoch 172 with validation loss 1.32917320728302\n",
      "Starting Epoch 173\n",
      "1.3544300297896068\n",
      "Validation loss: 1.328713297843933\n",
      "mse 1.3287132586262802\n",
      "New best model found at epoch 173 with validation loss 1.328713297843933\n",
      "Starting Epoch 174\n",
      "1.3537990922729175\n",
      "Validation loss: 1.3282591104507446\n",
      "mse 1.3282591888967095\n",
      "New best model found at epoch 174 with validation loss 1.3282591104507446\n",
      "Starting Epoch 175\n",
      "1.3531641513109207\n",
      "Validation loss: 1.3277592658996582\n",
      "mse 1.3277593172546618\n",
      "New best model found at epoch 175 with validation loss 1.3277592658996582\n",
      "Starting Epoch 176\n",
      "1.352517731487751\n",
      "Validation loss: 1.327593207359314\n",
      "mse 1.327593094202353\n",
      "New best model found at epoch 176 with validation loss 1.327593207359314\n",
      "Starting Epoch 177\n",
      "1.3519338741898537\n",
      "Validation loss: 1.3269444704055786\n",
      "mse 1.3269445203519636\n",
      "New best model found at epoch 177 with validation loss 1.3269444704055786\n",
      "Starting Epoch 178\n",
      "1.351285308599472\n",
      "Validation loss: 1.3266059160232544\n",
      "mse 1.3266058940760725\n",
      "New best model found at epoch 178 with validation loss 1.3266059160232544\n",
      "Starting Epoch 179\n",
      "1.3506678541501362\n",
      "Validation loss: 1.3261626958847046\n",
      "mse 1.326162713831221\n",
      "New best model found at epoch 179 with validation loss 1.3261626958847046\n",
      "Starting Epoch 180\n",
      "1.350063644349575\n",
      "Validation loss: 1.3256810903549194\n",
      "mse 1.325681052168934\n",
      "New best model found at epoch 180 with validation loss 1.3256810903549194\n",
      "Starting Epoch 181\n",
      "1.3494173561533291\n",
      "Validation loss: 1.324995994567871\n",
      "mse 1.32499597099921\n",
      "New best model found at epoch 181 with validation loss 1.324995994567871\n",
      "Starting Epoch 182\n",
      "1.3488395710786183\n",
      "Validation loss: 1.324695110321045\n",
      "mse 1.3246950112059355\n",
      "New best model found at epoch 182 with validation loss 1.324695110321045\n",
      "Starting Epoch 183\n",
      "1.34825653086106\n",
      "Validation loss: 1.3243350982666016\n",
      "mse 1.3243351104927743\n",
      "New best model found at epoch 183 with validation loss 1.3243350982666016\n",
      "Starting Epoch 184\n",
      "1.347635952134927\n",
      "Validation loss: 1.3239662647247314\n",
      "mse 1.3239663257642706\n",
      "New best model found at epoch 184 with validation loss 1.3239662647247314\n",
      "Starting Epoch 185\n",
      "1.347081184387207\n",
      "Validation loss: 1.3233882188796997\n",
      "mse 1.3233882465808335\n",
      "New best model found at epoch 185 with validation loss 1.3233882188796997\n",
      "Starting Epoch 186\n",
      "1.346467877427737\n",
      "Validation loss: 1.3230128288269043\n",
      "mse 1.3230127589907077\n",
      "New best model found at epoch 186 with validation loss 1.3230128288269043\n",
      "Starting Epoch 187\n",
      "1.3459237292408943\n",
      "Validation loss: 1.3224411010742188\n",
      "mse 1.3224411513072754\n",
      "New best model found at epoch 187 with validation loss 1.3224411010742188\n",
      "Starting Epoch 188\n",
      "1.3453188488880794\n",
      "Validation loss: 1.3221412897109985\n",
      "mse 1.3221412722247625\n",
      "New best model found at epoch 188 with validation loss 1.3221412897109985\n",
      "Starting Epoch 189\n",
      "1.3447092448671658\n",
      "Validation loss: 1.321744680404663\n",
      "mse 1.3217446888373408\n",
      "New best model found at epoch 189 with validation loss 1.321744680404663\n",
      "Starting Epoch 190\n",
      "1.3441360717018445\n",
      "Validation loss: 1.3212376832962036\n",
      "mse 1.321237810730649\n",
      "New best model found at epoch 190 with validation loss 1.3212376832962036\n",
      "Starting Epoch 191\n",
      "1.3435197820266087\n",
      "Validation loss: 1.320866346359253\n",
      "mse 1.320866348867144\n",
      "New best model found at epoch 191 with validation loss 1.320866346359253\n",
      "Starting Epoch 192\n",
      "1.3429225732882817\n",
      "Validation loss: 1.3204420804977417\n",
      "mse 1.3204420809658957\n",
      "New best model found at epoch 192 with validation loss 1.3204420804977417\n",
      "Starting Epoch 193\n",
      "1.342449004451434\n",
      "Validation loss: 1.320054531097412\n",
      "mse 1.3200544856888696\n",
      "New best model found at epoch 193 with validation loss 1.320054531097412\n",
      "Starting Epoch 194\n",
      "1.3418820053339005\n",
      "Validation loss: 1.319658875465393\n",
      "mse 1.3196589088014672\n",
      "New best model found at epoch 194 with validation loss 1.319658875465393\n",
      "Starting Epoch 195\n",
      "1.3413432364662488\n",
      "Validation loss: 1.3193129301071167\n",
      "mse 1.319312921971162\n",
      "New best model found at epoch 195 with validation loss 1.3193129301071167\n",
      "Starting Epoch 196\n",
      "1.3407883296410243\n",
      "Validation loss: 1.318760633468628\n",
      "mse 1.3187606897866118\n",
      "New best model found at epoch 196 with validation loss 1.318760633468628\n",
      "Starting Epoch 197\n",
      "1.340245706339677\n",
      "Validation loss: 1.3183637857437134\n",
      "mse 1.3183637640501016\n",
      "New best model found at epoch 197 with validation loss 1.3183637857437134\n",
      "Starting Epoch 198\n",
      "1.3396889666716258\n",
      "Validation loss: 1.318068504333496\n",
      "mse 1.3180684425494584\n",
      "New best model found at epoch 198 with validation loss 1.318068504333496\n",
      "Starting Epoch 199\n",
      "1.3391729642947514\n",
      "Validation loss: 1.3177162408828735\n",
      "mse 1.3177162324858178\n",
      "New best model found at epoch 199 with validation loss 1.3177162408828735\n",
      "Starting Epoch 200\n",
      "1.3385508134961128\n",
      "Validation loss: 1.3172576427459717\n",
      "mse 1.3172574750549997\n",
      "New best model found at epoch 200 with validation loss 1.3172576427459717\n",
      "Starting Epoch 201\n",
      "1.3380908394853275\n",
      "Validation loss: 1.3169139623641968\n",
      "mse 1.3169140630675467\n",
      "New best model found at epoch 201 with validation loss 1.3169139623641968\n",
      "Starting Epoch 202\n",
      "1.3375489537914593\n",
      "Validation loss: 1.316532015800476\n",
      "mse 1.316531969053363\n",
      "New best model found at epoch 202 with validation loss 1.316532015800476\n",
      "Starting Epoch 203\n",
      "1.3370015397667885\n",
      "Validation loss: 1.3163155317306519\n",
      "mse 1.3163155346492768\n",
      "New best model found at epoch 203 with validation loss 1.3163155317306519\n",
      "Starting Epoch 204\n",
      "1.336533876756827\n",
      "Validation loss: 1.3158890008926392\n",
      "mse 1.3158889134605505\n",
      "New best model found at epoch 204 with validation loss 1.3158890008926392\n",
      "Starting Epoch 205\n",
      "1.3359482660889626\n",
      "Validation loss: 1.3155744075775146\n",
      "mse 1.3155744345389162\n",
      "New best model found at epoch 205 with validation loss 1.3155744075775146\n",
      "Starting Epoch 206\n",
      "1.3354777594407399\n",
      "Validation loss: 1.3152670860290527\n",
      "mse 1.3152671678500516\n",
      "New best model found at epoch 206 with validation loss 1.3152670860290527\n",
      "Starting Epoch 207\n",
      "1.3349268610278766\n",
      "Validation loss: 1.314887523651123\n",
      "mse 1.3148875260096788\n",
      "New best model found at epoch 207 with validation loss 1.314887523651123\n",
      "Starting Epoch 208\n",
      "1.3344593221942584\n",
      "Validation loss: 1.314513087272644\n",
      "mse 1.3145131001742325\n",
      "New best model found at epoch 208 with validation loss 1.314513087272644\n",
      "Starting Epoch 209\n",
      "1.3339455450574558\n",
      "Validation loss: 1.3143965005874634\n",
      "mse 1.3143963127598517\n",
      "New best model found at epoch 209 with validation loss 1.3143965005874634\n",
      "Starting Epoch 210\n",
      "1.3334326073527336\n",
      "Validation loss: 1.3140116930007935\n",
      "mse 1.3140116057331752\n",
      "New best model found at epoch 210 with validation loss 1.3140116930007935\n",
      "Starting Epoch 211\n",
      "1.3329735149939854\n",
      "Validation loss: 1.3135000467300415\n",
      "mse 1.3135000674492765\n",
      "New best model found at epoch 211 with validation loss 1.3135000467300415\n",
      "Starting Epoch 212\n",
      "1.3324458003044128\n",
      "Validation loss: 1.31325101852417\n",
      "mse 1.3132510289996524\n",
      "New best model found at epoch 212 with validation loss 1.31325101852417\n",
      "Starting Epoch 213\n",
      "1.3319190169374149\n",
      "Validation loss: 1.3129719495773315\n",
      "mse 1.3129719552928234\n",
      "New best model found at epoch 213 with validation loss 1.3129719495773315\n",
      "Starting Epoch 214\n",
      "1.3314338326454163\n",
      "Validation loss: 1.312861442565918\n",
      "mse 1.3128614112763324\n",
      "New best model found at epoch 214 with validation loss 1.312861442565918\n",
      "Starting Epoch 215\n",
      "1.3309784084558487\n",
      "Validation loss: 1.3124418258666992\n",
      "mse 1.3124418698997473\n",
      "New best model found at epoch 215 with validation loss 1.3124418258666992\n",
      "Starting Epoch 216\n",
      "1.3304282501339912\n",
      "Validation loss: 1.3121943473815918\n",
      "mse 1.3121942902010184\n",
      "New best model found at epoch 216 with validation loss 1.3121943473815918\n",
      "Starting Epoch 217\n",
      "1.3299168323477109\n",
      "Validation loss: 1.3119345903396606\n",
      "mse 1.3119345674910514\n",
      "New best model found at epoch 217 with validation loss 1.3119345903396606\n",
      "Starting Epoch 218\n",
      "1.3294319584965706\n",
      "Validation loss: 1.3115403652191162\n",
      "mse 1.3115404017654846\n",
      "New best model found at epoch 218 with validation loss 1.3115403652191162\n",
      "Starting Epoch 219\n",
      "1.3289219910899799\n",
      "Validation loss: 1.3113590478897095\n",
      "mse 1.311359052698577\n",
      "New best model found at epoch 219 with validation loss 1.3113590478897095\n",
      "Starting Epoch 220\n",
      "1.3284779166181881\n",
      "Validation loss: 1.3110498189926147\n",
      "mse 1.3110498024372064\n",
      "New best model found at epoch 220 with validation loss 1.3110498189926147\n",
      "Starting Epoch 221\n",
      "1.327902575333913\n",
      "Validation loss: 1.310792088508606\n",
      "mse 1.3107920553306909\n",
      "New best model found at epoch 221 with validation loss 1.310792088508606\n",
      "Starting Epoch 222\n",
      "1.327359529832999\n",
      "Validation loss: 1.3105932474136353\n",
      "mse 1.3105931390363652\n",
      "New best model found at epoch 222 with validation loss 1.3105932474136353\n",
      "Starting Epoch 223\n",
      "1.3268490110834439\n",
      "Validation loss: 1.3104276657104492\n",
      "mse 1.3104275569991992\n",
      "New best model found at epoch 223 with validation loss 1.3104276657104492\n",
      "Starting Epoch 224\n",
      "1.3262636040647824\n",
      "Validation loss: 1.3101954460144043\n",
      "mse 1.3101955782902588\n",
      "New best model found at epoch 224 with validation loss 1.3101954460144043\n",
      "Starting Epoch 225\n",
      "1.325704316298167\n",
      "Validation loss: 1.3101532459259033\n",
      "mse 1.3101532999181018\n",
      "New best model found at epoch 225 with validation loss 1.3101532459259033\n",
      "Starting Epoch 226\n",
      "1.3251860067248344\n",
      "Validation loss: 1.3098288774490356\n",
      "mse 1.3098289069088724\n",
      "New best model found at epoch 226 with validation loss 1.3098288774490356\n",
      "Starting Epoch 227\n",
      "1.3246054475506146\n",
      "Validation loss: 1.3096473217010498\n",
      "mse 1.3096471446563023\n",
      "New best model found at epoch 227 with validation loss 1.3096473217010498\n",
      "Starting Epoch 228\n",
      "1.3240879426399867\n",
      "Validation loss: 1.3093066215515137\n",
      "mse 1.3093065967556101\n",
      "New best model found at epoch 228 with validation loss 1.3093066215515137\n",
      "Starting Epoch 229\n",
      "1.3235502516229947\n",
      "Validation loss: 1.308742642402649\n",
      "mse 1.3087425545322877\n",
      "New best model found at epoch 229 with validation loss 1.308742642402649\n",
      "Starting Epoch 230\n",
      "1.3230347856879234\n",
      "Validation loss: 1.308404803276062\n",
      "mse 1.3084048213552983\n",
      "New best model found at epoch 230 with validation loss 1.308404803276062\n",
      "Starting Epoch 231\n",
      "1.3225256552298863\n",
      "Validation loss: 1.3082208633422852\n",
      "mse 1.3082208710354344\n",
      "New best model found at epoch 231 with validation loss 1.3082208633422852\n",
      "Starting Epoch 232\n",
      "1.3220144957304\n",
      "Validation loss: 1.3077489137649536\n",
      "mse 1.3077490399896414\n",
      "New best model found at epoch 232 with validation loss 1.3077489137649536\n",
      "Starting Epoch 233\n",
      "1.3215239470203717\n",
      "Validation loss: 1.307369589805603\n",
      "mse 1.3073695763614228\n",
      "New best model found at epoch 233 with validation loss 1.307369589805603\n",
      "Starting Epoch 234\n",
      "1.320982130865256\n",
      "Validation loss: 1.3069547414779663\n",
      "mse 1.3069548019977963\n",
      "New best model found at epoch 234 with validation loss 1.3069547414779663\n",
      "Starting Epoch 235\n",
      "1.3205138395229976\n",
      "Validation loss: 1.306803822517395\n",
      "mse 1.3068038876980455\n",
      "New best model found at epoch 235 with validation loss 1.306803822517395\n",
      "Starting Epoch 236\n",
      "1.3200203751524289\n",
      "Validation loss: 1.3062152862548828\n",
      "mse 1.3062151766395371\n",
      "New best model found at epoch 236 with validation loss 1.3062152862548828\n",
      "Starting Epoch 237\n",
      "1.3195582752426465\n",
      "Validation loss: 1.305873990058899\n",
      "mse 1.305873881487172\n",
      "New best model found at epoch 237 with validation loss 1.305873990058899\n",
      "Starting Epoch 238\n",
      "1.3189857254425685\n",
      "Validation loss: 1.3055659532546997\n",
      "mse 1.3055659258863435\n",
      "New best model found at epoch 238 with validation loss 1.3055659532546997\n",
      "Starting Epoch 239\n",
      "1.3186016976833344\n",
      "Validation loss: 1.3050546646118164\n",
      "mse 1.3050545735279722\n",
      "New best model found at epoch 239 with validation loss 1.3050546646118164\n",
      "Starting Epoch 240\n",
      "1.3180617640415828\n",
      "Validation loss: 1.3049873113632202\n",
      "mse 1.304987536142038\n",
      "New best model found at epoch 240 with validation loss 1.3049873113632202\n",
      "Starting Epoch 241\n",
      "1.3175814573963482\n",
      "Validation loss: 1.3045989274978638\n",
      "mse 1.3045990526753815\n",
      "New best model found at epoch 241 with validation loss 1.3045989274978638\n",
      "Starting Epoch 242\n",
      "1.3171216795841854\n",
      "Validation loss: 1.3043582439422607\n",
      "mse 1.3043582070901085\n",
      "New best model found at epoch 242 with validation loss 1.3043582439422607\n",
      "Starting Epoch 243\n",
      "1.3166436900695164\n",
      "Validation loss: 1.303898572921753\n",
      "mse 1.3038986808123225\n",
      "New best model found at epoch 243 with validation loss 1.303898572921753\n",
      "Starting Epoch 244\n",
      "1.3161579072475433\n",
      "Validation loss: 1.3035905361175537\n",
      "mse 1.3035905238284786\n",
      "New best model found at epoch 244 with validation loss 1.3035905361175537\n",
      "Starting Epoch 245\n",
      "1.3156974837183952\n",
      "Validation loss: 1.3032841682434082\n",
      "mse 1.3032842505210223\n",
      "New best model found at epoch 245 with validation loss 1.3032841682434082\n",
      "Starting Epoch 246\n",
      "1.3152715687950451\n",
      "Validation loss: 1.3028048276901245\n",
      "mse 1.3028048665957253\n",
      "New best model found at epoch 246 with validation loss 1.3028048276901245\n",
      "Starting Epoch 247\n",
      "1.3148325756192207\n",
      "Validation loss: 1.302695631980896\n",
      "mse 1.3026956670927996\n",
      "New best model found at epoch 247 with validation loss 1.302695631980896\n",
      "Starting Epoch 248\n",
      "1.314302717645963\n",
      "Validation loss: 1.302384853363037\n",
      "mse 1.3023848254909167\n",
      "New best model found at epoch 248 with validation loss 1.302384853363037\n",
      "Starting Epoch 249\n",
      "1.3139001528422039\n",
      "Validation loss: 1.3018827438354492\n",
      "mse 1.3018827707158585\n",
      "New best model found at epoch 249 with validation loss 1.3018827438354492\n",
      "Starting Epoch 250\n",
      "1.313415989279747\n",
      "Validation loss: 1.3017657995224\n",
      "mse 1.3017658131512717\n",
      "New best model found at epoch 250 with validation loss 1.3017657995224\n",
      "Starting Epoch 251\n",
      "1.3129525929689407\n",
      "Validation loss: 1.3015153408050537\n",
      "mse 1.3015154122601076\n",
      "New best model found at epoch 251 with validation loss 1.3015153408050537\n",
      "Starting Epoch 252\n",
      "1.312560220559438\n",
      "Validation loss: 1.301059365272522\n",
      "mse 1.3010593992579944\n",
      "New best model found at epoch 252 with validation loss 1.301059365272522\n",
      "Starting Epoch 253\n",
      "1.312050347526868\n",
      "Validation loss: 1.300972819328308\n",
      "mse 1.3009728298076362\n",
      "New best model found at epoch 253 with validation loss 1.300972819328308\n",
      "Starting Epoch 254\n",
      "1.3116127500931423\n",
      "Validation loss: 1.300586223602295\n",
      "mse 1.3005862787488034\n",
      "New best model found at epoch 254 with validation loss 1.300586223602295\n",
      "Starting Epoch 255\n",
      "1.3111421838402748\n",
      "Validation loss: 1.3005214929580688\n",
      "mse 1.3005215728957098\n",
      "New best model found at epoch 255 with validation loss 1.3005214929580688\n",
      "Starting Epoch 256\n",
      "1.3107014099756877\n",
      "Validation loss: 1.3002617359161377\n",
      "mse 1.3002617419581817\n",
      "New best model found at epoch 256 with validation loss 1.3002617359161377\n",
      "Starting Epoch 257\n",
      "1.3102297733227413\n",
      "Validation loss: 1.2999283075332642\n",
      "mse 1.2999283503846375\n",
      "New best model found at epoch 257 with validation loss 1.2999283075332642\n",
      "Starting Epoch 258\n",
      "1.3097955013314884\n",
      "Validation loss: 1.2996503114700317\n",
      "mse 1.299650284923024\n",
      "New best model found at epoch 258 with validation loss 1.2996503114700317\n",
      "Starting Epoch 259\n",
      "1.3093369255463283\n",
      "Validation loss: 1.2992883920669556\n",
      "mse 1.2992884985418944\n",
      "New best model found at epoch 259 with validation loss 1.2992883920669556\n",
      "Starting Epoch 260\n",
      "1.308863915503025\n",
      "Validation loss: 1.2991551160812378\n",
      "mse 1.2991552228060192\n",
      "New best model found at epoch 260 with validation loss 1.2991551160812378\n",
      "Starting Epoch 261\n",
      "1.3084595575928688\n",
      "Validation loss: 1.2985464334487915\n",
      "mse 1.2985464415499055\n",
      "New best model found at epoch 261 with validation loss 1.2985464334487915\n",
      "Starting Epoch 262\n",
      "1.3079980139931042\n",
      "Validation loss: 1.2983064651489258\n",
      "mse 1.2983066532533927\n",
      "New best model found at epoch 262 with validation loss 1.2983064651489258\n",
      "Starting Epoch 263\n",
      "1.3075025429328282\n",
      "Validation loss: 1.2980711460113525\n",
      "mse 1.298071264934344\n",
      "New best model found at epoch 263 with validation loss 1.2980711460113525\n",
      "Starting Epoch 264\n",
      "1.3070231179396312\n",
      "Validation loss: 1.2977604866027832\n",
      "mse 1.297760627585598\n",
      "New best model found at epoch 264 with validation loss 1.2977604866027832\n",
      "Starting Epoch 265\n",
      "1.3065838366746902\n",
      "Validation loss: 1.2975194454193115\n",
      "mse 1.2975193676166177\n",
      "New best model found at epoch 265 with validation loss 1.2975194454193115\n",
      "Starting Epoch 266\n",
      "1.3060337826609612\n",
      "Validation loss: 1.2975678443908691\n",
      "mse 1.2975677779772503\n",
      "Starting Epoch 267\n",
      "1.3055733665823936\n",
      "Validation loss: 1.2972028255462646\n",
      "mse 1.297202794365474\n",
      "New best model found at epoch 267 with validation loss 1.2972028255462646\n",
      "Starting Epoch 268\n",
      "1.3051429366072018\n",
      "Validation loss: 1.296647548675537\n",
      "mse 1.2966474992262926\n",
      "New best model found at epoch 268 with validation loss 1.296647548675537\n",
      "Starting Epoch 269\n",
      "1.3046331455310185\n",
      "Validation loss: 1.2964951992034912\n",
      "mse 1.29649516346138\n",
      "New best model found at epoch 269 with validation loss 1.2964951992034912\n",
      "Starting Epoch 270\n",
      "1.3041236326098442\n",
      "Validation loss: 1.2962254285812378\n",
      "mse 1.2962254266132567\n",
      "New best model found at epoch 270 with validation loss 1.2962254285812378\n",
      "Starting Epoch 271\n",
      "1.3036180064082146\n",
      "Validation loss: 1.2962675094604492\n",
      "mse 1.2962674950804793\n",
      "Starting Epoch 272\n",
      "1.303089181582133\n",
      "Validation loss: 1.2959742546081543\n",
      "mse 1.295974308956351\n",
      "New best model found at epoch 272 with validation loss 1.2959742546081543\n",
      "Starting Epoch 273\n",
      "1.3025355363885562\n",
      "Validation loss: 1.2956715822219849\n",
      "mse 1.2956715442574516\n",
      "New best model found at epoch 273 with validation loss 1.2956715822219849\n",
      "Starting Epoch 274\n",
      "1.3019016658266385\n",
      "Validation loss: 1.2953832149505615\n",
      "mse 1.295383217627199\n",
      "New best model found at epoch 274 with validation loss 1.2953832149505615\n",
      "Starting Epoch 275\n",
      "1.3012919922669728\n",
      "Validation loss: 1.2948544025421143\n",
      "mse 1.2948543970257986\n",
      "New best model found at epoch 275 with validation loss 1.2948544025421143\n",
      "Starting Epoch 276\n",
      "1.3005571514368057\n",
      "Validation loss: 1.294334053993225\n",
      "mse 1.2943338549603716\n",
      "New best model found at epoch 276 with validation loss 1.294334053993225\n",
      "Starting Epoch 277\n",
      "1.2999133293827374\n",
      "Validation loss: 1.2937241792678833\n",
      "mse 1.2937241413589715\n",
      "New best model found at epoch 277 with validation loss 1.2937241792678833\n",
      "Starting Epoch 278\n",
      "1.2993416363994281\n",
      "Validation loss: 1.2932193279266357\n",
      "mse 1.29321929818543\n",
      "New best model found at epoch 278 with validation loss 1.2932193279266357\n",
      "Starting Epoch 279\n",
      "1.298783337076505\n",
      "Validation loss: 1.292856216430664\n",
      "mse 1.2928561918266546\n",
      "New best model found at epoch 279 with validation loss 1.292856216430664\n",
      "Starting Epoch 280\n",
      "1.2982164894541104\n",
      "Validation loss: 1.2923368215560913\n",
      "mse 1.2923367887249428\n",
      "New best model found at epoch 280 with validation loss 1.2923368215560913\n",
      "Starting Epoch 281\n",
      "1.2976781005660694\n",
      "Validation loss: 1.2919172048568726\n",
      "mse 1.2919171275458474\n",
      "New best model found at epoch 281 with validation loss 1.2919172048568726\n",
      "Starting Epoch 282\n",
      "1.2971394211053848\n",
      "Validation loss: 1.2915966510772705\n",
      "mse 1.2915965717411504\n",
      "New best model found at epoch 282 with validation loss 1.2915966510772705\n",
      "Starting Epoch 283\n",
      "1.296664983034134\n",
      "Validation loss: 1.291050672531128\n",
      "mse 1.2910505172551832\n",
      "New best model found at epoch 283 with validation loss 1.291050672531128\n",
      "Starting Epoch 284\n",
      "1.296161564687888\n",
      "Validation loss: 1.2903804779052734\n",
      "mse 1.290380422999674\n",
      "New best model found at epoch 284 with validation loss 1.2903804779052734\n",
      "Starting Epoch 285\n",
      "1.2955510144432385\n",
      "Validation loss: 1.2901248931884766\n",
      "mse 1.2901248694965346\n",
      "New best model found at epoch 285 with validation loss 1.2901248931884766\n",
      "Starting Epoch 286\n",
      "1.29500462859869\n",
      "Validation loss: 1.289888620376587\n",
      "mse 1.289888795034014\n",
      "New best model found at epoch 286 with validation loss 1.289888620376587\n",
      "Starting Epoch 287\n",
      "1.2945445130268733\n",
      "Validation loss: 1.2894407510757446\n",
      "mse 1.289440821999064\n",
      "New best model found at epoch 287 with validation loss 1.2894407510757446\n",
      "Starting Epoch 288\n",
      "1.293978489935398\n",
      "Validation loss: 1.289427399635315\n",
      "mse 1.2894274610643208\n",
      "New best model found at epoch 288 with validation loss 1.289427399635315\n",
      "Starting Epoch 289\n",
      "1.2935797944664955\n",
      "Validation loss: 1.288970947265625\n",
      "mse 1.2889710672334618\n",
      "New best model found at epoch 289 with validation loss 1.288970947265625\n",
      "Starting Epoch 290\n",
      "1.2931252419948578\n",
      "Validation loss: 1.288491129875183\n",
      "mse 1.2884911147627571\n",
      "New best model found at epoch 290 with validation loss 1.288491129875183\n",
      "Starting Epoch 291\n",
      "1.2926076700290043\n",
      "Validation loss: 1.2883362770080566\n",
      "mse 1.2883363846963458\n",
      "New best model found at epoch 291 with validation loss 1.2883362770080566\n",
      "Starting Epoch 292\n",
      "1.2921897719303768\n",
      "Validation loss: 1.2878568172454834\n",
      "mse 1.287856681402571\n",
      "New best model found at epoch 292 with validation loss 1.2878568172454834\n",
      "Starting Epoch 293\n",
      "1.291667677462101\n",
      "Validation loss: 1.2879719734191895\n",
      "mse 1.2879718494563925\n",
      "Starting Epoch 294\n",
      "1.2912466923395793\n",
      "Validation loss: 1.287795066833496\n",
      "mse 1.2877949219319882\n",
      "New best model found at epoch 294 with validation loss 1.287795066833496\n",
      "Starting Epoch 295\n",
      "1.2908486972252529\n",
      "Validation loss: 1.2873172760009766\n",
      "mse 1.2873172447088548\n",
      "New best model found at epoch 295 with validation loss 1.2873172760009766\n",
      "Starting Epoch 296\n",
      "1.2903691033522289\n",
      "Validation loss: 1.2871603965759277\n",
      "mse 1.2871604353490946\n",
      "New best model found at epoch 296 with validation loss 1.2871603965759277\n",
      "Starting Epoch 297\n",
      "1.28998248030742\n",
      "Validation loss: 1.2868057489395142\n",
      "mse 1.2868057234601022\n",
      "New best model found at epoch 297 with validation loss 1.2868057489395142\n",
      "Starting Epoch 298\n",
      "1.289493702352047\n",
      "Validation loss: 1.286696195602417\n",
      "mse 1.2866961100193528\n",
      "New best model found at epoch 298 with validation loss 1.286696195602417\n",
      "Starting Epoch 299\n",
      "1.2890944331884384\n",
      "Validation loss: 1.2862781286239624\n",
      "mse 1.28627805987594\n",
      "New best model found at epoch 299 with validation loss 1.2862781286239624\n",
      "Starting Epoch 300\n",
      "1.2886662557721138\n",
      "Validation loss: 1.2858861684799194\n",
      "mse 1.2858862474009487\n",
      "New best model found at epoch 300 with validation loss 1.2858861684799194\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-40-20-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2d0b9",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 10 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e52b392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "77e0e072-0b83-4222-894c-632f1789ba0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.8293984284003577\n",
      "Validation loss: 2.484739065170288\n",
      "mse 2.4847393097337256\n",
      "New best model found at epoch 1 with validation loss 2.484739065170288\n",
      "Starting Epoch 2\n",
      "2.3175525466601052\n",
      "Validation loss: 2.2651994228363037\n",
      "mse 2.265199487265224\n",
      "New best model found at epoch 2 with validation loss 2.2651994228363037\n",
      "Starting Epoch 3\n",
      "2.191296880443891\n",
      "Validation loss: 2.1542093753814697\n",
      "mse 2.15420910992754\n",
      "New best model found at epoch 3 with validation loss 2.1542093753814697\n",
      "Starting Epoch 4\n",
      "2.112940475344658\n",
      "Validation loss: 2.071883201599121\n",
      "mse 2.0718831131217508\n",
      "New best model found at epoch 4 with validation loss 2.071883201599121\n",
      "Starting Epoch 5\n",
      "2.0524430871009827\n",
      "Validation loss: 2.0060386657714844\n",
      "mse 2.006038742055569\n",
      "New best model found at epoch 5 with validation loss 2.0060386657714844\n",
      "Starting Epoch 6\n",
      "2.0013895481824875\n",
      "Validation loss: 1.949317455291748\n",
      "mse 1.9493174347794457\n",
      "New best model found at epoch 6 with validation loss 1.949317455291748\n",
      "Starting Epoch 7\n",
      "1.9574987441301346\n",
      "Validation loss: 1.9008324146270752\n",
      "mse 1.9008325714639147\n",
      "New best model found at epoch 7 with validation loss 1.9008324146270752\n",
      "Starting Epoch 8\n",
      "1.9193909366925557\n",
      "Validation loss: 1.8581721782684326\n",
      "mse 1.8581722676061214\n",
      "New best model found at epoch 8 with validation loss 1.8581721782684326\n",
      "Starting Epoch 9\n",
      "1.886315832535426\n",
      "Validation loss: 1.8216625452041626\n",
      "mse 1.8216624880227081\n",
      "New best model found at epoch 9 with validation loss 1.8216625452041626\n",
      "Starting Epoch 10\n",
      "1.8577512850364049\n",
      "Validation loss: 1.7891157865524292\n",
      "mse 1.789115917199099\n",
      "New best model found at epoch 10 with validation loss 1.7891157865524292\n",
      "Starting Epoch 11\n",
      "1.8328426331281662\n",
      "Validation loss: 1.7603946924209595\n",
      "mse 1.76039485112142\n",
      "New best model found at epoch 11 with validation loss 1.7603946924209595\n",
      "Starting Epoch 12\n",
      "1.8112055410941441\n",
      "Validation loss: 1.7367616891860962\n",
      "mse 1.7367617882507733\n",
      "New best model found at epoch 12 with validation loss 1.7367616891860962\n",
      "Starting Epoch 13\n",
      "1.792423278093338\n",
      "Validation loss: 1.7150471210479736\n",
      "mse 1.7150470522444683\n",
      "New best model found at epoch 13 with validation loss 1.7150471210479736\n",
      "Starting Epoch 14\n",
      "1.7759365389744441\n",
      "Validation loss: 1.6967511177062988\n",
      "mse 1.69675103344561\n",
      "New best model found at epoch 14 with validation loss 1.6967511177062988\n",
      "Starting Epoch 15\n",
      "1.7613679766654968\n",
      "Validation loss: 1.6806674003601074\n",
      "mse 1.680667281646172\n",
      "New best model found at epoch 15 with validation loss 1.6806674003601074\n",
      "Starting Epoch 16\n",
      "1.7484312256177266\n",
      "Validation loss: 1.6660069227218628\n",
      "mse 1.6660069009039244\n",
      "New best model found at epoch 16 with validation loss 1.6660069227218628\n",
      "Starting Epoch 17\n",
      "1.73662372926871\n",
      "Validation loss: 1.653071403503418\n",
      "mse 1.6530713844448928\n",
      "New best model found at epoch 17 with validation loss 1.653071403503418\n",
      "Starting Epoch 18\n",
      "1.7261768629153569\n",
      "Validation loss: 1.6416211128234863\n",
      "mse 1.641621067445706\n",
      "New best model found at epoch 18 with validation loss 1.6416211128234863\n",
      "Starting Epoch 19\n",
      "1.7166409939527512\n",
      "Validation loss: 1.6313393115997314\n",
      "mse 1.6313393235035307\n",
      "New best model found at epoch 19 with validation loss 1.6313393115997314\n",
      "Starting Epoch 20\n",
      "1.7079682995875676\n",
      "Validation loss: 1.6225963830947876\n",
      "mse 1.6225963616874133\n",
      "New best model found at epoch 20 with validation loss 1.6225963830947876\n",
      "Starting Epoch 21\n",
      "1.6999811331431072\n",
      "Validation loss: 1.6138280630111694\n",
      "mse 1.613827984044541\n",
      "New best model found at epoch 21 with validation loss 1.6138280630111694\n",
      "Starting Epoch 22\n",
      "1.6926070948441823\n",
      "Validation loss: 1.6063145399093628\n",
      "mse 1.606314621154953\n",
      "New best model found at epoch 22 with validation loss 1.6063145399093628\n",
      "Starting Epoch 23\n",
      "1.685307651758194\n",
      "Validation loss: 1.5988566875457764\n",
      "mse 1.5988566574583507\n",
      "New best model found at epoch 23 with validation loss 1.5988566875457764\n",
      "Starting Epoch 24\n",
      "1.678386504451434\n",
      "Validation loss: 1.5931521654129028\n",
      "mse 1.5931521380186482\n",
      "New best model found at epoch 24 with validation loss 1.5931521654129028\n",
      "Starting Epoch 25\n",
      "1.6720848282178242\n",
      "Validation loss: 1.5872128009796143\n",
      "mse 1.5872129889537272\n",
      "New best model found at epoch 25 with validation loss 1.5872128009796143\n",
      "Starting Epoch 26\n",
      "1.665921375155449\n",
      "Validation loss: 1.5817787647247314\n",
      "mse 1.5817787698411365\n",
      "New best model found at epoch 26 with validation loss 1.5817787647247314\n",
      "Starting Epoch 27\n",
      "1.6601004749536514\n",
      "Validation loss: 1.5764529705047607\n",
      "mse 1.576452983723357\n",
      "New best model found at epoch 27 with validation loss 1.5764529705047607\n",
      "Starting Epoch 28\n",
      "1.6545541882514954\n",
      "Validation loss: 1.5717370510101318\n",
      "mse 1.5717369478674892\n",
      "New best model found at epoch 28 with validation loss 1.5717370510101318\n",
      "Starting Epoch 29\n",
      "1.6493520140647888\n",
      "Validation loss: 1.5674833059310913\n",
      "mse 1.5674833247832496\n",
      "New best model found at epoch 29 with validation loss 1.5674833059310913\n",
      "Starting Epoch 30\n",
      "1.644369934995969\n",
      "Validation loss: 1.5630419254302979\n",
      "mse 1.5630419012320496\n",
      "New best model found at epoch 30 with validation loss 1.5630419254302979\n",
      "Starting Epoch 31\n",
      "1.6397602359453838\n",
      "Validation loss: 1.5587587356567383\n",
      "mse 1.5587587077753033\n",
      "New best model found at epoch 31 with validation loss 1.5587587356567383\n",
      "Starting Epoch 32\n",
      "1.635262722770373\n",
      "Validation loss: 1.5542172193527222\n",
      "mse 1.5542172901023337\n",
      "New best model found at epoch 32 with validation loss 1.5542172193527222\n",
      "Starting Epoch 33\n",
      "1.6309105108181636\n",
      "Validation loss: 1.5496528148651123\n",
      "mse 1.5496526869934444\n",
      "New best model found at epoch 33 with validation loss 1.5496528148651123\n",
      "Starting Epoch 34\n",
      "1.6266808708508809\n",
      "Validation loss: 1.5454691648483276\n",
      "mse 1.5454692365235285\n",
      "New best model found at epoch 34 with validation loss 1.5454691648483276\n",
      "Starting Epoch 35\n",
      "1.6225411693255107\n",
      "Validation loss: 1.5416369438171387\n",
      "mse 1.5416369956293492\n",
      "New best model found at epoch 35 with validation loss 1.5416369438171387\n",
      "Starting Epoch 36\n",
      "1.6186469743649166\n",
      "Validation loss: 1.5378209352493286\n",
      "mse 1.5378210219921038\n",
      "New best model found at epoch 36 with validation loss 1.5378209352493286\n",
      "Starting Epoch 37\n",
      "1.6148192038138707\n",
      "Validation loss: 1.534207820892334\n",
      "mse 1.5342077718498595\n",
      "New best model found at epoch 37 with validation loss 1.534207820892334\n",
      "Starting Epoch 38\n",
      "1.6111719757318497\n",
      "Validation loss: 1.5306644439697266\n",
      "mse 1.5306644702132124\n",
      "New best model found at epoch 38 with validation loss 1.5306644439697266\n",
      "Starting Epoch 39\n",
      "1.607655867934227\n",
      "Validation loss: 1.5271955728530884\n",
      "mse 1.5271955388096183\n",
      "New best model found at epoch 39 with validation loss 1.5271955728530884\n",
      "Starting Epoch 40\n",
      "1.604208156466484\n",
      "Validation loss: 1.523877739906311\n",
      "mse 1.5238776407712964\n",
      "New best model found at epoch 40 with validation loss 1.523877739906311\n",
      "Starting Epoch 41\n",
      "1.6008680661519368\n",
      "Validation loss: 1.5208079814910889\n",
      "mse 1.5208080230717869\n",
      "New best model found at epoch 41 with validation loss 1.5208079814910889\n",
      "Starting Epoch 42\n",
      "1.5976605862379074\n",
      "Validation loss: 1.5177483558654785\n",
      "mse 1.5177481676825963\n",
      "New best model found at epoch 42 with validation loss 1.5177483558654785\n",
      "Starting Epoch 43\n",
      "1.5945976575215657\n",
      "Validation loss: 1.5147135257720947\n",
      "mse 1.514713564627903\n",
      "New best model found at epoch 43 with validation loss 1.5147135257720947\n",
      "Starting Epoch 44\n",
      "1.5915182928244274\n",
      "Validation loss: 1.511805534362793\n",
      "mse 1.5118055189851272\n",
      "New best model found at epoch 44 with validation loss 1.511805534362793\n",
      "Starting Epoch 45\n",
      "1.5882736990849178\n",
      "Validation loss: 1.5084213018417358\n",
      "mse 1.508421385000843\n",
      "New best model found at epoch 45 with validation loss 1.5084213018417358\n",
      "Starting Epoch 46\n",
      "1.5841319312651951\n",
      "Validation loss: 1.5026557445526123\n",
      "mse 1.5026558017414466\n",
      "New best model found at epoch 46 with validation loss 1.5026557445526123\n",
      "Starting Epoch 47\n",
      "1.5769783556461334\n",
      "Validation loss: 1.4954432249069214\n",
      "mse 1.4954433164372638\n",
      "New best model found at epoch 47 with validation loss 1.4954432249069214\n",
      "Starting Epoch 48\n",
      "1.5701705465714137\n",
      "Validation loss: 1.4896858930587769\n",
      "mse 1.4896860119987843\n",
      "New best model found at epoch 48 with validation loss 1.4896858930587769\n",
      "Starting Epoch 49\n",
      "1.5648431926965714\n",
      "Validation loss: 1.4857693910598755\n",
      "mse 1.485769397965633\n",
      "New best model found at epoch 49 with validation loss 1.4857693910598755\n",
      "Starting Epoch 50\n",
      "1.5608468800783157\n",
      "Validation loss: 1.4819532632827759\n",
      "mse 1.481953216768457\n",
      "New best model found at epoch 50 with validation loss 1.4819532632827759\n",
      "Starting Epoch 51\n",
      "1.5574989914894104\n",
      "Validation loss: 1.4793059825897217\n",
      "mse 1.479306037309822\n",
      "New best model found at epoch 51 with validation loss 1.4793059825897217\n",
      "Starting Epoch 52\n",
      "1.5541962335507076\n",
      "Validation loss: 1.4761767387390137\n",
      "mse 1.4761767798509065\n",
      "New best model found at epoch 52 with validation loss 1.4761767387390137\n",
      "Starting Epoch 53\n",
      "1.550974542895953\n",
      "Validation loss: 1.4738333225250244\n",
      "mse 1.4738334194310465\n",
      "New best model found at epoch 53 with validation loss 1.4738333225250244\n",
      "Starting Epoch 54\n",
      "1.5477883418401082\n",
      "Validation loss: 1.4716328382492065\n",
      "mse 1.4716328968677879\n",
      "New best model found at epoch 54 with validation loss 1.4716328382492065\n",
      "Starting Epoch 55\n",
      "1.5447284330924351\n",
      "Validation loss: 1.4695428609848022\n",
      "mse 1.4695429440449992\n",
      "New best model found at epoch 55 with validation loss 1.4695428609848022\n",
      "Starting Epoch 56\n",
      "1.5417886674404144\n",
      "Validation loss: 1.467397928237915\n",
      "mse 1.4673980236848214\n",
      "New best model found at epoch 56 with validation loss 1.467397928237915\n",
      "Starting Epoch 57\n",
      "1.5390760799249013\n",
      "Validation loss: 1.465287446975708\n",
      "mse 1.4652875123935931\n",
      "New best model found at epoch 57 with validation loss 1.465287446975708\n",
      "Starting Epoch 58\n",
      "1.5364211549361546\n",
      "Validation loss: 1.4635756015777588\n",
      "mse 1.4635756643486282\n",
      "New best model found at epoch 58 with validation loss 1.4635756015777588\n",
      "Starting Epoch 59\n",
      "1.5338269074757893\n",
      "Validation loss: 1.4615657329559326\n",
      "mse 1.4615658368282063\n",
      "New best model found at epoch 59 with validation loss 1.4615657329559326\n",
      "Starting Epoch 60\n",
      "1.531251663963\n",
      "Validation loss: 1.4596071243286133\n",
      "mse 1.4596070661179883\n",
      "New best model found at epoch 60 with validation loss 1.4596071243286133\n",
      "Starting Epoch 61\n",
      "1.5288853893677394\n",
      "Validation loss: 1.4577323198318481\n",
      "mse 1.4577323474145263\n",
      "New best model found at epoch 61 with validation loss 1.4577323198318481\n",
      "Starting Epoch 62\n",
      "1.5263911137978237\n",
      "Validation loss: 1.4560142755508423\n",
      "mse 1.4560143434238442\n",
      "New best model found at epoch 62 with validation loss 1.4560142755508423\n",
      "Starting Epoch 63\n",
      "1.524119421839714\n",
      "Validation loss: 1.4541394710540771\n",
      "mse 1.4541394509702807\n",
      "New best model found at epoch 63 with validation loss 1.4541394710540771\n",
      "Starting Epoch 64\n",
      "1.5218390623728435\n",
      "Validation loss: 1.4524400234222412\n",
      "mse 1.4524400448070478\n",
      "New best model found at epoch 64 with validation loss 1.4524400234222412\n",
      "Starting Epoch 65\n",
      "1.5195363362630208\n",
      "Validation loss: 1.4508349895477295\n",
      "mse 1.4508348783618048\n",
      "New best model found at epoch 65 with validation loss 1.4508349895477295\n",
      "Starting Epoch 66\n",
      "1.5172822227080662\n",
      "Validation loss: 1.4490249156951904\n",
      "mse 1.4490249394822918\n",
      "New best model found at epoch 66 with validation loss 1.4490249156951904\n",
      "Starting Epoch 67\n",
      "1.5150264203548431\n",
      "Validation loss: 1.4472379684448242\n",
      "mse 1.4472378204575078\n",
      "New best model found at epoch 67 with validation loss 1.4472379684448242\n",
      "Starting Epoch 68\n",
      "1.5129050463438034\n",
      "Validation loss: 1.445556640625\n",
      "mse 1.4455566988104347\n",
      "New best model found at epoch 68 with validation loss 1.445556640625\n",
      "Starting Epoch 69\n",
      "1.5106275926033657\n",
      "Validation loss: 1.4437905550003052\n",
      "mse 1.443790476508544\n",
      "New best model found at epoch 69 with validation loss 1.4437905550003052\n",
      "Starting Epoch 70\n",
      "1.5085905144611995\n",
      "Validation loss: 1.442219614982605\n",
      "mse 1.4422195887112557\n",
      "New best model found at epoch 70 with validation loss 1.442219614982605\n",
      "Starting Epoch 71\n",
      "1.5065285215775173\n",
      "Validation loss: 1.440634846687317\n",
      "mse 1.4406348813721643\n",
      "New best model found at epoch 71 with validation loss 1.440634846687317\n",
      "Starting Epoch 72\n",
      "1.5045086095730464\n",
      "Validation loss: 1.438921570777893\n",
      "mse 1.4389216560845939\n",
      "New best model found at epoch 72 with validation loss 1.438921570777893\n",
      "Starting Epoch 73\n",
      "1.5025035242239635\n",
      "Validation loss: 1.4373637437820435\n",
      "mse 1.4373637014326235\n",
      "New best model found at epoch 73 with validation loss 1.4373637437820435\n",
      "Starting Epoch 74\n",
      "1.5005735407272975\n",
      "Validation loss: 1.4357483386993408\n",
      "mse 1.4357482498385103\n",
      "New best model found at epoch 74 with validation loss 1.4357483386993408\n",
      "Starting Epoch 75\n",
      "1.4985647996266682\n",
      "Validation loss: 1.4343785047531128\n",
      "mse 1.434378383745654\n",
      "New best model found at epoch 75 with validation loss 1.4343785047531128\n",
      "Starting Epoch 76\n",
      "1.4967037985722225\n",
      "Validation loss: 1.4327270984649658\n",
      "mse 1.432727167129131\n",
      "New best model found at epoch 76 with validation loss 1.4327270984649658\n",
      "Starting Epoch 77\n",
      "1.49482166270415\n",
      "Validation loss: 1.4313421249389648\n",
      "mse 1.4313420970196011\n",
      "New best model found at epoch 77 with validation loss 1.4313421249389648\n",
      "Starting Epoch 78\n",
      "1.4930289785067241\n",
      "Validation loss: 1.4296786785125732\n",
      "mse 1.4296786024010104\n",
      "New best model found at epoch 78 with validation loss 1.4296786785125732\n",
      "Starting Epoch 79\n",
      "1.49112302561601\n",
      "Validation loss: 1.4281232357025146\n",
      "mse 1.4281231710753306\n",
      "New best model found at epoch 79 with validation loss 1.4281232357025146\n",
      "Starting Epoch 80\n",
      "1.4893284142017365\n",
      "Validation loss: 1.4268052577972412\n",
      "mse 1.4268053162777536\n",
      "New best model found at epoch 80 with validation loss 1.4268052577972412\n",
      "Starting Epoch 81\n",
      "1.487646649281184\n",
      "Validation loss: 1.4252864122390747\n",
      "mse 1.425286430845955\n",
      "New best model found at epoch 81 with validation loss 1.4252864122390747\n",
      "Starting Epoch 82\n",
      "1.4858694821596146\n",
      "Validation loss: 1.423895001411438\n",
      "mse 1.4238949238630088\n",
      "New best model found at epoch 82 with validation loss 1.423895001411438\n",
      "Starting Epoch 83\n",
      "1.4842040340105693\n",
      "Validation loss: 1.4225037097930908\n",
      "mse 1.4225037834875047\n",
      "New best model found at epoch 83 with validation loss 1.4225037097930908\n",
      "Starting Epoch 84\n",
      "1.4825838506221771\n",
      "Validation loss: 1.4210814237594604\n",
      "mse 1.4210813864339644\n",
      "New best model found at epoch 84 with validation loss 1.4210814237594604\n",
      "Starting Epoch 85\n",
      "1.4809049119551976\n",
      "Validation loss: 1.4197642803192139\n",
      "mse 1.4197642694117172\n",
      "New best model found at epoch 85 with validation loss 1.4197642803192139\n",
      "Starting Epoch 86\n",
      "1.4793341060479481\n",
      "Validation loss: 1.4183472394943237\n",
      "mse 1.4183471650043948\n",
      "New best model found at epoch 86 with validation loss 1.4183472394943237\n",
      "Starting Epoch 87\n",
      "1.477602481842041\n",
      "Validation loss: 1.4170383214950562\n",
      "mse 1.4170382429303938\n",
      "New best model found at epoch 87 with validation loss 1.4170383214950562\n",
      "Starting Epoch 88\n",
      "1.4761192202568054\n",
      "Validation loss: 1.4155606031417847\n",
      "mse 1.4155605733043772\n",
      "New best model found at epoch 88 with validation loss 1.4155606031417847\n",
      "Starting Epoch 89\n",
      "1.4744871258735657\n",
      "Validation loss: 1.414154052734375\n",
      "mse 1.4141539500563316\n",
      "New best model found at epoch 89 with validation loss 1.414154052734375\n",
      "Starting Epoch 90\n",
      "1.4726322342952092\n",
      "Validation loss: 1.4120745658874512\n",
      "mse 1.4120746643153292\n",
      "New best model found at epoch 90 with validation loss 1.4120745658874512\n",
      "Starting Epoch 91\n",
      "1.4707254419724147\n",
      "Validation loss: 1.4103072881698608\n",
      "mse 1.4103071832873113\n",
      "New best model found at epoch 91 with validation loss 1.4103072881698608\n",
      "Starting Epoch 92\n",
      "1.4690713385740917\n",
      "Validation loss: 1.4087896347045898\n",
      "mse 1.408789631988998\n",
      "New best model found at epoch 92 with validation loss 1.4087896347045898\n",
      "Starting Epoch 93\n",
      "1.4673768728971481\n",
      "Validation loss: 1.407330870628357\n",
      "mse 1.4073308437816587\n",
      "New best model found at epoch 93 with validation loss 1.407330870628357\n",
      "Starting Epoch 94\n",
      "1.4658356755971909\n",
      "Validation loss: 1.4061945676803589\n",
      "mse 1.4061945654292276\n",
      "New best model found at epoch 94 with validation loss 1.4061945676803589\n",
      "Starting Epoch 95\n",
      "1.4643516441186268\n",
      "Validation loss: 1.4049584865570068\n",
      "mse 1.404958647543067\n",
      "New best model found at epoch 95 with validation loss 1.4049584865570068\n",
      "Starting Epoch 96\n",
      "1.4628374725580215\n",
      "Validation loss: 1.403630256652832\n",
      "mse 1.4036302671504228\n",
      "New best model found at epoch 96 with validation loss 1.403630256652832\n",
      "Starting Epoch 97\n",
      "1.4614006007711093\n",
      "Validation loss: 1.4023741483688354\n",
      "mse 1.4023740815166252\n",
      "New best model found at epoch 97 with validation loss 1.4023741483688354\n",
      "Starting Epoch 98\n",
      "1.4599675983190536\n",
      "Validation loss: 1.4014219045639038\n",
      "mse 1.4014218011151542\n",
      "New best model found at epoch 98 with validation loss 1.4014219045639038\n",
      "Starting Epoch 99\n",
      "1.4585427393515904\n",
      "Validation loss: 1.4003769159317017\n",
      "mse 1.4003769140175297\n",
      "New best model found at epoch 99 with validation loss 1.4003769159317017\n",
      "Starting Epoch 100\n",
      "1.4571630954742432\n",
      "Validation loss: 1.3992644548416138\n",
      "mse 1.3992645433850266\n",
      "New best model found at epoch 100 with validation loss 1.3992644548416138\n",
      "Starting Epoch 101\n",
      "1.455736483136813\n",
      "Validation loss: 1.398145079612732\n",
      "mse 1.3981451974049144\n",
      "New best model found at epoch 101 with validation loss 1.398145079612732\n",
      "Starting Epoch 102\n",
      "1.454382638136546\n",
      "Validation loss: 1.3970998525619507\n",
      "mse 1.397099817598809\n",
      "New best model found at epoch 102 with validation loss 1.3970998525619507\n",
      "Starting Epoch 103\n",
      "1.453039010365804\n",
      "Validation loss: 1.395729660987854\n",
      "mse 1.3957295694552487\n",
      "New best model found at epoch 103 with validation loss 1.395729660987854\n",
      "Starting Epoch 104\n",
      "1.451765815416972\n",
      "Validation loss: 1.3947997093200684\n",
      "mse 1.3947996247507595\n",
      "New best model found at epoch 104 with validation loss 1.3947997093200684\n",
      "Starting Epoch 105\n",
      "1.4504946271578472\n",
      "Validation loss: 1.3935832977294922\n",
      "mse 1.3935833615669502\n",
      "New best model found at epoch 105 with validation loss 1.3935832977294922\n",
      "Starting Epoch 106\n",
      "1.4492199743787448\n",
      "Validation loss: 1.39211905002594\n",
      "mse 1.392118898990425\n",
      "New best model found at epoch 106 with validation loss 1.39211905002594\n",
      "Starting Epoch 107\n",
      "1.4478737066189449\n",
      "Validation loss: 1.3910166025161743\n",
      "mse 1.3910165873829377\n",
      "New best model found at epoch 107 with validation loss 1.3910166025161743\n",
      "Starting Epoch 108\n",
      "1.4467043032248814\n",
      "Validation loss: 1.3899744749069214\n",
      "mse 1.3899744966394463\n",
      "New best model found at epoch 108 with validation loss 1.3899744749069214\n",
      "Starting Epoch 109\n",
      "1.445391225318114\n",
      "Validation loss: 1.3886139392852783\n",
      "mse 1.3886139396852077\n",
      "New best model found at epoch 109 with validation loss 1.3886139392852783\n",
      "Starting Epoch 110\n",
      "1.4441361625989277\n",
      "Validation loss: 1.3874493837356567\n",
      "mse 1.3874493350678863\n",
      "New best model found at epoch 110 with validation loss 1.3874493837356567\n",
      "Starting Epoch 111\n",
      "1.4429724887013435\n",
      "Validation loss: 1.3863945007324219\n",
      "mse 1.3863945135133466\n",
      "New best model found at epoch 111 with validation loss 1.3863945007324219\n",
      "Starting Epoch 112\n",
      "1.4417701959609985\n",
      "Validation loss: 1.3850584030151367\n",
      "mse 1.3850582976058987\n",
      "New best model found at epoch 112 with validation loss 1.3850584030151367\n",
      "Starting Epoch 113\n",
      "1.440557097395261\n",
      "Validation loss: 1.384137511253357\n",
      "mse 1.3841374742010017\n",
      "New best model found at epoch 113 with validation loss 1.384137511253357\n",
      "Starting Epoch 114\n",
      "1.4393756811817486\n",
      "Validation loss: 1.3829017877578735\n",
      "mse 1.3829017904110636\n",
      "New best model found at epoch 114 with validation loss 1.3829017877578735\n",
      "Starting Epoch 115\n",
      "1.4382211913665135\n",
      "Validation loss: 1.3821099996566772\n",
      "mse 1.3821100196568956\n",
      "New best model found at epoch 115 with validation loss 1.3821099996566772\n",
      "Starting Epoch 116\n",
      "1.437061257660389\n",
      "Validation loss: 1.380953311920166\n",
      "mse 1.380953379704442\n",
      "New best model found at epoch 116 with validation loss 1.380953311920166\n",
      "Starting Epoch 117\n",
      "1.4359070286154747\n",
      "Validation loss: 1.3798859119415283\n",
      "mse 1.3798858698632241\n",
      "New best model found at epoch 117 with validation loss 1.3798859119415283\n",
      "Starting Epoch 118\n",
      "1.4347451453407605\n",
      "Validation loss: 1.3789455890655518\n",
      "mse 1.3789456915288663\n",
      "New best model found at epoch 118 with validation loss 1.3789455890655518\n",
      "Starting Epoch 119\n",
      "1.433583324154218\n",
      "Validation loss: 1.37788987159729\n",
      "mse 1.3778897984222556\n",
      "New best model found at epoch 119 with validation loss 1.37788987159729\n",
      "Starting Epoch 120\n",
      "1.4325505246718724\n",
      "Validation loss: 1.377105474472046\n",
      "mse 1.3771056436849773\n",
      "New best model found at epoch 120 with validation loss 1.377105474472046\n",
      "Starting Epoch 121\n",
      "1.4314070418477058\n",
      "Validation loss: 1.3759812116622925\n",
      "mse 1.3759813264851186\n",
      "New best model found at epoch 121 with validation loss 1.3759812116622925\n",
      "Starting Epoch 122\n",
      "1.4303987522919972\n",
      "Validation loss: 1.3751499652862549\n",
      "mse 1.375150009137147\n",
      "New best model found at epoch 122 with validation loss 1.3751499652862549\n",
      "Starting Epoch 123\n",
      "1.4292780831456184\n",
      "Validation loss: 1.3739802837371826\n",
      "mse 1.3739803770697119\n",
      "New best model found at epoch 123 with validation loss 1.3739802837371826\n",
      "Starting Epoch 124\n",
      "1.4282706404725711\n",
      "Validation loss: 1.373103380203247\n",
      "mse 1.3731033523148446\n",
      "New best model found at epoch 124 with validation loss 1.373103380203247\n",
      "Starting Epoch 125\n",
      "1.427227350572745\n",
      "Validation loss: 1.37204110622406\n",
      "mse 1.3720411888503767\n",
      "New best model found at epoch 125 with validation loss 1.37204110622406\n",
      "Starting Epoch 126\n",
      "1.4261161809166272\n",
      "Validation loss: 1.371120572090149\n",
      "mse 1.371120621113263\n",
      "New best model found at epoch 126 with validation loss 1.371120572090149\n",
      "Starting Epoch 127\n",
      "1.425103058417638\n",
      "Validation loss: 1.3701306581497192\n",
      "mse 1.3701305465764937\n",
      "New best model found at epoch 127 with validation loss 1.3701306581497192\n",
      "Starting Epoch 128\n",
      "1.4240560034910839\n",
      "Validation loss: 1.3692870140075684\n",
      "mse 1.3692869522846574\n",
      "New best model found at epoch 128 with validation loss 1.3692870140075684\n",
      "Starting Epoch 129\n",
      "1.4231301546096802\n",
      "Validation loss: 1.3682438135147095\n",
      "mse 1.3682439342806285\n",
      "New best model found at epoch 129 with validation loss 1.3682438135147095\n",
      "Starting Epoch 130\n",
      "1.4221159517765045\n",
      "Validation loss: 1.3673641681671143\n",
      "mse 1.367364110040691\n",
      "New best model found at epoch 130 with validation loss 1.3673641681671143\n",
      "Starting Epoch 131\n",
      "1.4211297829945881\n",
      "Validation loss: 1.366500735282898\n",
      "mse 1.3665005805290051\n",
      "New best model found at epoch 131 with validation loss 1.366500735282898\n",
      "Starting Epoch 132\n",
      "1.4201705157756805\n",
      "Validation loss: 1.365488052368164\n",
      "mse 1.3654879997488818\n",
      "New best model found at epoch 132 with validation loss 1.365488052368164\n",
      "Starting Epoch 133\n",
      "1.419228158891201\n",
      "Validation loss: 1.3646270036697388\n",
      "mse 1.3646270477939246\n",
      "New best model found at epoch 133 with validation loss 1.3646270036697388\n",
      "Starting Epoch 134\n",
      "1.4182664056619008\n",
      "Validation loss: 1.3636057376861572\n",
      "mse 1.3636055784525802\n",
      "New best model found at epoch 134 with validation loss 1.3636057376861572\n",
      "Starting Epoch 135\n",
      "1.4172453085581462\n",
      "Validation loss: 1.3627541065216064\n",
      "mse 1.3627542124659495\n",
      "New best model found at epoch 135 with validation loss 1.3627541065216064\n",
      "Starting Epoch 136\n",
      "1.4162875811258953\n",
      "Validation loss: 1.3616306781768799\n",
      "mse 1.3616306747293323\n",
      "New best model found at epoch 136 with validation loss 1.3616306781768799\n",
      "Starting Epoch 137\n",
      "1.4154114052653313\n",
      "Validation loss: 1.3607338666915894\n",
      "mse 1.3607337318167751\n",
      "New best model found at epoch 137 with validation loss 1.3607338666915894\n",
      "Starting Epoch 138\n",
      "1.4144576340913773\n",
      "Validation loss: 1.359876036643982\n",
      "mse 1.3598761786363256\n",
      "New best model found at epoch 138 with validation loss 1.359876036643982\n",
      "Starting Epoch 139\n",
      "1.4135149146119754\n",
      "Validation loss: 1.3589985370635986\n",
      "mse 1.3589984507963986\n",
      "New best model found at epoch 139 with validation loss 1.3589985370635986\n",
      "Starting Epoch 140\n",
      "1.4125902379552524\n",
      "Validation loss: 1.358327031135559\n",
      "mse 1.3583270193343477\n",
      "New best model found at epoch 140 with validation loss 1.358327031135559\n",
      "Starting Epoch 141\n",
      "1.4115589037537575\n",
      "Validation loss: 1.357389211654663\n",
      "mse 1.3573892389574245\n",
      "New best model found at epoch 141 with validation loss 1.357389211654663\n",
      "Starting Epoch 142\n",
      "1.410643105705579\n",
      "Validation loss: 1.356628179550171\n",
      "mse 1.356628182105682\n",
      "New best model found at epoch 142 with validation loss 1.356628179550171\n",
      "Starting Epoch 143\n",
      "1.4096458132068317\n",
      "Validation loss: 1.3555079698562622\n",
      "mse 1.355507888056185\n",
      "New best model found at epoch 143 with validation loss 1.3555079698562622\n",
      "Starting Epoch 144\n",
      "1.4086791202425957\n",
      "Validation loss: 1.3545929193496704\n",
      "mse 1.3545928843021466\n",
      "New best model found at epoch 144 with validation loss 1.3545929193496704\n",
      "Starting Epoch 145\n",
      "1.4078192164500554\n",
      "Validation loss: 1.3538814783096313\n",
      "mse 1.3538813469173503\n",
      "New best model found at epoch 145 with validation loss 1.3538814783096313\n",
      "Starting Epoch 146\n",
      "1.4068605452775955\n",
      "Validation loss: 1.3530179262161255\n",
      "mse 1.3530179292611122\n",
      "New best model found at epoch 146 with validation loss 1.3530179262161255\n",
      "Starting Epoch 147\n",
      "1.4058675269285839\n",
      "Validation loss: 1.3517718315124512\n",
      "mse 1.351771819075571\n",
      "New best model found at epoch 147 with validation loss 1.3517718315124512\n",
      "Starting Epoch 148\n",
      "1.4050172045826912\n",
      "Validation loss: 1.351252555847168\n",
      "mse 1.351252645561411\n",
      "New best model found at epoch 148 with validation loss 1.351252555847168\n",
      "Starting Epoch 149\n",
      "1.4041456133127213\n",
      "Validation loss: 1.3503777980804443\n",
      "mse 1.3503777416236962\n",
      "New best model found at epoch 149 with validation loss 1.3503777980804443\n",
      "Starting Epoch 150\n",
      "1.4031795759995778\n",
      "Validation loss: 1.3493565320968628\n",
      "mse 1.3493565599689508\n",
      "New best model found at epoch 150 with validation loss 1.3493565320968628\n",
      "Starting Epoch 151\n",
      "1.4022006342808406\n",
      "Validation loss: 1.3482365608215332\n",
      "mse 1.3482365961757086\n",
      "New best model found at epoch 151 with validation loss 1.3482365608215332\n",
      "Starting Epoch 152\n",
      "1.4012757167220116\n",
      "Validation loss: 1.3475183248519897\n",
      "mse 1.3475183354259033\n",
      "New best model found at epoch 152 with validation loss 1.3475183248519897\n",
      "Starting Epoch 153\n",
      "1.4004866480827332\n",
      "Validation loss: 1.3466447591781616\n",
      "mse 1.346644740001729\n",
      "New best model found at epoch 153 with validation loss 1.3466447591781616\n",
      "Starting Epoch 154\n",
      "1.3995390633742015\n",
      "Validation loss: 1.3457595109939575\n",
      "mse 1.345759568401207\n",
      "New best model found at epoch 154 with validation loss 1.3457595109939575\n",
      "Starting Epoch 155\n",
      "1.3985598882039387\n",
      "Validation loss: 1.344722032546997\n",
      "mse 1.3447220101430626\n",
      "New best model found at epoch 155 with validation loss 1.344722032546997\n",
      "Starting Epoch 156\n",
      "1.3976896032691002\n",
      "Validation loss: 1.3440295457839966\n",
      "mse 1.3440296599378447\n",
      "New best model found at epoch 156 with validation loss 1.3440295457839966\n",
      "Starting Epoch 157\n",
      "1.3966843485832214\n",
      "Validation loss: 1.3431777954101562\n",
      "mse 1.3431777768815636\n",
      "New best model found at epoch 157 with validation loss 1.3431777954101562\n",
      "Starting Epoch 158\n",
      "1.3957999249299367\n",
      "Validation loss: 1.342358112335205\n",
      "mse 1.3423580933638477\n",
      "New best model found at epoch 158 with validation loss 1.342358112335205\n",
      "Starting Epoch 159\n",
      "1.394920917848746\n",
      "Validation loss: 1.3415343761444092\n",
      "mse 1.3415343820942534\n",
      "New best model found at epoch 159 with validation loss 1.3415343761444092\n",
      "Starting Epoch 160\n",
      "1.393997808297475\n",
      "Validation loss: 1.3406915664672852\n",
      "mse 1.340691565816695\n",
      "New best model found at epoch 160 with validation loss 1.3406915664672852\n",
      "Starting Epoch 161\n",
      "1.3931733816862106\n",
      "Validation loss: 1.3402293920516968\n",
      "mse 1.340229476137454\n",
      "New best model found at epoch 161 with validation loss 1.3402293920516968\n",
      "Starting Epoch 162\n",
      "1.392235778272152\n",
      "Validation loss: 1.339211106300354\n",
      "mse 1.3392111585501554\n",
      "New best model found at epoch 162 with validation loss 1.339211106300354\n",
      "Starting Epoch 163\n",
      "1.3914627060294151\n",
      "Validation loss: 1.3388546705245972\n",
      "mse 1.3388547662089543\n",
      "New best model found at epoch 163 with validation loss 1.3388546705245972\n",
      "Starting Epoch 164\n",
      "1.3907158623139064\n",
      "Validation loss: 1.337900161743164\n",
      "mse 1.3379000686244722\n",
      "New best model found at epoch 164 with validation loss 1.337900161743164\n",
      "Starting Epoch 165\n",
      "1.3897936046123505\n",
      "Validation loss: 1.3368394374847412\n",
      "mse 1.3368394418421892\n",
      "New best model found at epoch 165 with validation loss 1.3368394374847412\n",
      "Starting Epoch 166\n",
      "1.3888952011863391\n",
      "Validation loss: 1.335315465927124\n",
      "mse 1.3353155077674652\n",
      "New best model found at epoch 166 with validation loss 1.335315465927124\n",
      "Starting Epoch 167\n",
      "1.387856123348077\n",
      "Validation loss: 1.3335331678390503\n",
      "mse 1.3335332064303074\n",
      "New best model found at epoch 167 with validation loss 1.3335331678390503\n",
      "Starting Epoch 168\n",
      "1.3866099094351132\n",
      "Validation loss: 1.3320318460464478\n",
      "mse 1.3320319739233875\n",
      "New best model found at epoch 168 with validation loss 1.3320318460464478\n",
      "Starting Epoch 169\n",
      "1.3857937256495159\n",
      "Validation loss: 1.330937147140503\n",
      "mse 1.3309370354819836\n",
      "New best model found at epoch 169 with validation loss 1.330937147140503\n",
      "Starting Epoch 170\n",
      "1.3847640802462895\n",
      "Validation loss: 1.329777479171753\n",
      "mse 1.329777659845229\n",
      "New best model found at epoch 170 with validation loss 1.329777479171753\n",
      "Starting Epoch 171\n",
      "1.3837872048219044\n",
      "Validation loss: 1.3288732767105103\n",
      "mse 1.3288732131598193\n",
      "New best model found at epoch 171 with validation loss 1.3288732767105103\n",
      "Starting Epoch 172\n",
      "1.3830396309494972\n",
      "Validation loss: 1.3280874490737915\n",
      "mse 1.3280874397624831\n",
      "New best model found at epoch 172 with validation loss 1.3280874490737915\n",
      "Starting Epoch 173\n",
      "1.3822013512253761\n",
      "Validation loss: 1.3271507024765015\n",
      "mse 1.3271506301334604\n",
      "New best model found at epoch 173 with validation loss 1.3271507024765015\n",
      "Starting Epoch 174\n",
      "1.3813248847921689\n",
      "Validation loss: 1.3264540433883667\n",
      "mse 1.326453985775644\n",
      "New best model found at epoch 174 with validation loss 1.3264540433883667\n",
      "Starting Epoch 175\n",
      "1.3805619478225708\n",
      "Validation loss: 1.325474500656128\n",
      "mse 1.3254743881849027\n",
      "New best model found at epoch 175 with validation loss 1.325474500656128\n",
      "Starting Epoch 176\n",
      "1.3798269207278888\n",
      "Validation loss: 1.3247429132461548\n",
      "mse 1.324742797602659\n",
      "New best model found at epoch 176 with validation loss 1.3247429132461548\n",
      "Starting Epoch 177\n",
      "1.3790682156880696\n",
      "Validation loss: 1.3240748643875122\n",
      "mse 1.3240748716940416\n",
      "New best model found at epoch 177 with validation loss 1.3240748643875122\n",
      "Starting Epoch 178\n",
      "1.3782540907462437\n",
      "Validation loss: 1.3232605457305908\n",
      "mse 1.3232605502616324\n",
      "New best model found at epoch 178 with validation loss 1.3232605457305908\n",
      "Starting Epoch 179\n",
      "1.3775211522976558\n",
      "Validation loss: 1.3226432800292969\n",
      "mse 1.3226432179643632\n",
      "New best model found at epoch 179 with validation loss 1.3226432800292969\n",
      "Starting Epoch 180\n",
      "1.3767436295747757\n",
      "Validation loss: 1.3217359781265259\n",
      "mse 1.3217359385805172\n",
      "New best model found at epoch 180 with validation loss 1.3217359781265259\n",
      "Starting Epoch 181\n",
      "1.3760136092702548\n",
      "Validation loss: 1.3211592435836792\n",
      "mse 1.3211593188379824\n",
      "New best model found at epoch 181 with validation loss 1.3211592435836792\n",
      "Starting Epoch 182\n",
      "1.3752830525239308\n",
      "Validation loss: 1.320340871810913\n",
      "mse 1.3203409635424235\n",
      "New best model found at epoch 182 with validation loss 1.320340871810913\n",
      "Starting Epoch 183\n",
      "1.374461700518926\n",
      "Validation loss: 1.3195469379425049\n",
      "mse 1.3195469263801491\n",
      "New best model found at epoch 183 with validation loss 1.3195469379425049\n",
      "Starting Epoch 184\n",
      "1.3737080494562786\n",
      "Validation loss: 1.3187472820281982\n",
      "mse 1.3187472881063222\n",
      "New best model found at epoch 184 with validation loss 1.3187472820281982\n",
      "Starting Epoch 185\n",
      "1.372998793919881\n",
      "Validation loss: 1.318131923675537\n",
      "mse 1.3181318552357146\n",
      "New best model found at epoch 185 with validation loss 1.318131923675537\n",
      "Starting Epoch 186\n",
      "1.3722877924640973\n",
      "Validation loss: 1.3175429105758667\n",
      "mse 1.317542904656681\n",
      "New best model found at epoch 186 with validation loss 1.3175429105758667\n",
      "Starting Epoch 187\n",
      "1.3715591231981914\n",
      "Validation loss: 1.316693663597107\n",
      "mse 1.316693695668044\n",
      "New best model found at epoch 187 with validation loss 1.316693663597107\n",
      "Starting Epoch 188\n",
      "1.370859923462073\n",
      "Validation loss: 1.3161150217056274\n",
      "mse 1.3161149211440066\n",
      "New best model found at epoch 188 with validation loss 1.3161150217056274\n",
      "Starting Epoch 189\n",
      "1.3700669954220455\n",
      "Validation loss: 1.315366268157959\n",
      "mse 1.3153661709307498\n",
      "New best model found at epoch 189 with validation loss 1.315366268157959\n",
      "Starting Epoch 190\n",
      "1.369402825832367\n",
      "Validation loss: 1.3148161172866821\n",
      "mse 1.3148160863494083\n",
      "New best model found at epoch 190 with validation loss 1.3148161172866821\n",
      "Starting Epoch 191\n",
      "1.368666206796964\n",
      "Validation loss: 1.3141435384750366\n",
      "mse 1.3141435154341858\n",
      "New best model found at epoch 191 with validation loss 1.3141435384750366\n",
      "Starting Epoch 192\n",
      "1.3679852584997814\n",
      "Validation loss: 1.3134255409240723\n",
      "mse 1.3134255867250904\n",
      "New best model found at epoch 192 with validation loss 1.3134255409240723\n",
      "Starting Epoch 193\n",
      "1.3672987272342045\n",
      "Validation loss: 1.3128201961517334\n",
      "mse 1.3128201589907014\n",
      "New best model found at epoch 193 with validation loss 1.3128201961517334\n",
      "Starting Epoch 194\n",
      "1.3666031112273533\n",
      "Validation loss: 1.3121200799942017\n",
      "mse 1.312120000007089\n",
      "New best model found at epoch 194 with validation loss 1.3121200799942017\n",
      "Starting Epoch 195\n",
      "1.3659449368715286\n",
      "Validation loss: 1.31163489818573\n",
      "mse 1.3116349435310084\n",
      "New best model found at epoch 195 with validation loss 1.31163489818573\n",
      "Starting Epoch 196\n",
      "1.3651761437455814\n",
      "Validation loss: 1.3107693195343018\n",
      "mse 1.3107692961057646\n",
      "New best model found at epoch 196 with validation loss 1.3107693195343018\n",
      "Starting Epoch 197\n",
      "1.364538088440895\n",
      "Validation loss: 1.3101319074630737\n",
      "mse 1.3101320031047254\n",
      "New best model found at epoch 197 with validation loss 1.3101319074630737\n",
      "Starting Epoch 198\n",
      "1.3638015513618786\n",
      "Validation loss: 1.3094780445098877\n",
      "mse 1.3094779922998736\n",
      "New best model found at epoch 198 with validation loss 1.3094780445098877\n",
      "Starting Epoch 199\n",
      "1.3631437569856644\n",
      "Validation loss: 1.3087735176086426\n",
      "mse 1.3087735962996918\n",
      "New best model found at epoch 199 with validation loss 1.3087735176086426\n",
      "Starting Epoch 200\n",
      "1.3624838938315709\n",
      "Validation loss: 1.3082010746002197\n",
      "mse 1.3082010833472355\n",
      "New best model found at epoch 200 with validation loss 1.3082010746002197\n",
      "Starting Epoch 201\n",
      "1.3618281334638596\n",
      "Validation loss: 1.3075796365737915\n",
      "mse 1.3075797173587804\n",
      "New best model found at epoch 201 with validation loss 1.3075796365737915\n",
      "Starting Epoch 202\n",
      "1.3611336027582486\n",
      "Validation loss: 1.3069524765014648\n",
      "mse 1.3069525694079194\n",
      "New best model found at epoch 202 with validation loss 1.3069524765014648\n",
      "Starting Epoch 203\n",
      "1.3604812994599342\n",
      "Validation loss: 1.3062710762023926\n",
      "mse 1.306271145990223\n",
      "New best model found at epoch 203 with validation loss 1.3062710762023926\n",
      "Starting Epoch 204\n",
      "1.3597699602444966\n",
      "Validation loss: 1.3056122064590454\n",
      "mse 1.3056122687201899\n",
      "New best model found at epoch 204 with validation loss 1.3056122064590454\n",
      "Starting Epoch 205\n",
      "1.3591536581516266\n",
      "Validation loss: 1.3049532175064087\n",
      "mse 1.3049531079907297\n",
      "New best model found at epoch 205 with validation loss 1.3049532175064087\n",
      "Starting Epoch 206\n",
      "1.3585326944788296\n",
      "Validation loss: 1.3043439388275146\n",
      "mse 1.3043440111866826\n",
      "New best model found at epoch 206 with validation loss 1.3043439388275146\n",
      "Starting Epoch 207\n",
      "1.3578586727380753\n",
      "Validation loss: 1.3036589622497559\n",
      "mse 1.3036589045652986\n",
      "New best model found at epoch 207 with validation loss 1.3036589622497559\n",
      "Starting Epoch 208\n",
      "1.357196715970834\n",
      "Validation loss: 1.3030599355697632\n",
      "mse 1.3030598775590903\n",
      "New best model found at epoch 208 with validation loss 1.3030599355697632\n",
      "Starting Epoch 209\n",
      "1.3565913066267967\n",
      "Validation loss: 1.3024173974990845\n",
      "mse 1.3024173787953441\n",
      "New best model found at epoch 209 with validation loss 1.3024173974990845\n",
      "Starting Epoch 210\n",
      "1.3558981120586395\n",
      "Validation loss: 1.3017879724502563\n",
      "mse 1.3017879040471902\n",
      "New best model found at epoch 210 with validation loss 1.3017879724502563\n",
      "Starting Epoch 211\n",
      "1.3552727748950322\n",
      "Validation loss: 1.301152229309082\n",
      "mse 1.3011521921158673\n",
      "New best model found at epoch 211 with validation loss 1.301152229309082\n",
      "Starting Epoch 212\n",
      "1.3546941752235095\n",
      "Validation loss: 1.3005584478378296\n",
      "mse 1.3005584014186249\n",
      "New best model found at epoch 212 with validation loss 1.3005584478378296\n",
      "Starting Epoch 213\n",
      "1.3540274600187938\n",
      "Validation loss: 1.2999958992004395\n",
      "mse 1.2999960068618936\n",
      "New best model found at epoch 213 with validation loss 1.2999958992004395\n",
      "Starting Epoch 214\n",
      "1.353436345855395\n",
      "Validation loss: 1.299356460571289\n",
      "mse 1.299356209302248\n",
      "New best model found at epoch 214 with validation loss 1.299356460571289\n",
      "Starting Epoch 215\n",
      "1.3527630294362705\n",
      "Validation loss: 1.2988004684448242\n",
      "mse 1.298800419388163\n",
      "New best model found at epoch 215 with validation loss 1.2988004684448242\n",
      "Starting Epoch 216\n",
      "1.3521916667620342\n",
      "Validation loss: 1.298142671585083\n",
      "mse 1.2981426291345934\n",
      "New best model found at epoch 216 with validation loss 1.298142671585083\n",
      "Starting Epoch 217\n",
      "1.3515597780545552\n",
      "Validation loss: 1.2976889610290527\n",
      "mse 1.2976890640670355\n",
      "New best model found at epoch 217 with validation loss 1.2976889610290527\n",
      "Starting Epoch 218\n",
      "1.3509155462185543\n",
      "Validation loss: 1.2969765663146973\n",
      "mse 1.2969766489142491\n",
      "New best model found at epoch 218 with validation loss 1.2969765663146973\n",
      "Starting Epoch 219\n",
      "1.3503261730074883\n",
      "Validation loss: 1.296591877937317\n",
      "mse 1.2965918763191127\n",
      "New best model found at epoch 219 with validation loss 1.296591877937317\n",
      "Starting Epoch 220\n",
      "1.3497211535771687\n",
      "Validation loss: 1.2959539890289307\n",
      "mse 1.295953887909624\n",
      "New best model found at epoch 220 with validation loss 1.2959539890289307\n",
      "Starting Epoch 221\n",
      "1.349164217710495\n",
      "Validation loss: 1.2954310178756714\n",
      "mse 1.295431027113568\n",
      "New best model found at epoch 221 with validation loss 1.2954310178756714\n",
      "Starting Epoch 222\n",
      "1.3485172142585118\n",
      "Validation loss: 1.2948145866394043\n",
      "mse 1.2948146134897336\n",
      "New best model found at epoch 222 with validation loss 1.2948145866394043\n",
      "Starting Epoch 223\n",
      "1.347926417986552\n",
      "Validation loss: 1.2942842245101929\n",
      "mse 1.2942844287091182\n",
      "New best model found at epoch 223 with validation loss 1.2942842245101929\n",
      "Starting Epoch 224\n",
      "1.3473171119888623\n",
      "Validation loss: 1.2937098741531372\n",
      "mse 1.2937097339735935\n",
      "New best model found at epoch 224 with validation loss 1.2937098741531372\n",
      "Starting Epoch 225\n",
      "1.3466298480828602\n",
      "Validation loss: 1.2931303977966309\n",
      "mse 1.2931304036091866\n",
      "New best model found at epoch 225 with validation loss 1.2931303977966309\n",
      "Starting Epoch 226\n",
      "1.3460823198159535\n",
      "Validation loss: 1.292601466178894\n",
      "mse 1.292601451856244\n",
      "New best model found at epoch 226 with validation loss 1.292601466178894\n",
      "Starting Epoch 227\n",
      "1.3454288318753242\n",
      "Validation loss: 1.2921650409698486\n",
      "mse 1.292164924663989\n",
      "New best model found at epoch 227 with validation loss 1.2921650409698486\n",
      "Starting Epoch 228\n",
      "1.344856545329094\n",
      "Validation loss: 1.2914623022079468\n",
      "mse 1.2914624190677393\n",
      "New best model found at epoch 228 with validation loss 1.2914623022079468\n",
      "Starting Epoch 229\n",
      "1.3442343150575955\n",
      "Validation loss: 1.2910428047180176\n",
      "mse 1.2910429249417852\n",
      "New best model found at epoch 229 with validation loss 1.2910428047180176\n",
      "Starting Epoch 230\n",
      "1.343695268034935\n",
      "Validation loss: 1.2905137538909912\n",
      "mse 1.2905137391275905\n",
      "New best model found at epoch 230 with validation loss 1.2905137538909912\n",
      "Starting Epoch 231\n",
      "1.3430859347184498\n",
      "Validation loss: 1.2900727987289429\n",
      "mse 1.2900727844369493\n",
      "New best model found at epoch 231 with validation loss 1.2900727987289429\n",
      "Starting Epoch 232\n",
      "1.342441404859225\n",
      "Validation loss: 1.2894604206085205\n",
      "mse 1.2894603658501598\n",
      "New best model found at epoch 232 with validation loss 1.2894604206085205\n",
      "Starting Epoch 233\n",
      "1.3419566104809444\n",
      "Validation loss: 1.2889773845672607\n",
      "mse 1.2889772979839726\n",
      "New best model found at epoch 233 with validation loss 1.2889773845672607\n",
      "Starting Epoch 234\n",
      "1.3413425385951996\n",
      "Validation loss: 1.2884820699691772\n",
      "mse 1.2884819447622675\n",
      "New best model found at epoch 234 with validation loss 1.2884820699691772\n",
      "Starting Epoch 235\n",
      "1.340804951886336\n",
      "Validation loss: 1.2878050804138184\n",
      "mse 1.287805041707737\n",
      "New best model found at epoch 235 with validation loss 1.2878050804138184\n",
      "Starting Epoch 236\n",
      "1.340258739888668\n",
      "Validation loss: 1.2872862815856934\n",
      "mse 1.2872863948560795\n",
      "New best model found at epoch 236 with validation loss 1.2872862815856934\n",
      "Starting Epoch 237\n",
      "1.3396648466587067\n",
      "Validation loss: 1.2868129014968872\n",
      "mse 1.28681277355975\n",
      "New best model found at epoch 237 with validation loss 1.2868129014968872\n",
      "Starting Epoch 238\n",
      "1.3391222779949505\n",
      "Validation loss: 1.2862164974212646\n",
      "mse 1.2862163093043972\n",
      "New best model found at epoch 238 with validation loss 1.2862164974212646\n",
      "Starting Epoch 239\n",
      "1.338594858845075\n",
      "Validation loss: 1.2856082916259766\n",
      "mse 1.2856082269050162\n",
      "New best model found at epoch 239 with validation loss 1.2856082916259766\n",
      "Starting Epoch 240\n",
      "1.337974138557911\n",
      "Validation loss: 1.2851550579071045\n",
      "mse 1.2851550514608405\n",
      "New best model found at epoch 240 with validation loss 1.2851550579071045\n",
      "Starting Epoch 241\n",
      "1.3374326278765996\n",
      "Validation loss: 1.284523844718933\n",
      "mse 1.2845236331070085\n",
      "New best model found at epoch 241 with validation loss 1.284523844718933\n",
      "Starting Epoch 242\n",
      "1.3369137768944104\n",
      "Validation loss: 1.28397798538208\n",
      "mse 1.2839778611759607\n",
      "New best model found at epoch 242 with validation loss 1.28397798538208\n",
      "Starting Epoch 243\n",
      "1.336321197450161\n",
      "Validation loss: 1.2835168838500977\n",
      "mse 1.2835168650513844\n",
      "New best model found at epoch 243 with validation loss 1.2835168838500977\n",
      "Starting Epoch 244\n",
      "1.3357791751623154\n",
      "Validation loss: 1.2828773260116577\n",
      "mse 1.2828774238125664\n",
      "New best model found at epoch 244 with validation loss 1.2828773260116577\n",
      "Starting Epoch 245\n",
      "1.3352386405070622\n",
      "Validation loss: 1.2822962999343872\n",
      "mse 1.2822963537496355\n",
      "New best model found at epoch 245 with validation loss 1.2822962999343872\n",
      "Starting Epoch 246\n",
      "1.3346421793103218\n",
      "Validation loss: 1.2816137075424194\n",
      "mse 1.2816137154531353\n",
      "New best model found at epoch 246 with validation loss 1.2816137075424194\n",
      "Starting Epoch 247\n",
      "1.3341315761208534\n",
      "Validation loss: 1.2809998989105225\n",
      "mse 1.280999844103629\n",
      "New best model found at epoch 247 with validation loss 1.2809998989105225\n",
      "Starting Epoch 248\n",
      "1.3335298548142116\n",
      "Validation loss: 1.2803313732147217\n",
      "mse 1.2803314142012598\n",
      "New best model found at epoch 248 with validation loss 1.2803313732147217\n",
      "Starting Epoch 249\n",
      "1.3329394683241844\n",
      "Validation loss: 1.2797143459320068\n",
      "mse 1.2797143332344676\n",
      "New best model found at epoch 249 with validation loss 1.2797143459320068\n",
      "Starting Epoch 250\n",
      "1.3323289106289546\n",
      "Validation loss: 1.2791073322296143\n",
      "mse 1.2791072673421415\n",
      "New best model found at epoch 250 with validation loss 1.2791073322296143\n",
      "Starting Epoch 251\n",
      "1.3317253291606903\n",
      "Validation loss: 1.278389573097229\n",
      "mse 1.2783895601368596\n",
      "New best model found at epoch 251 with validation loss 1.278389573097229\n",
      "Starting Epoch 252\n",
      "1.3311389808853467\n",
      "Validation loss: 1.2777540683746338\n",
      "mse 1.2777539560784799\n",
      "New best model found at epoch 252 with validation loss 1.2777540683746338\n",
      "Starting Epoch 253\n",
      "1.3305098588267963\n",
      "Validation loss: 1.277156949043274\n",
      "mse 1.2771568433631428\n",
      "New best model found at epoch 253 with validation loss 1.277156949043274\n",
      "Starting Epoch 254\n",
      "1.3299284254511197\n",
      "Validation loss: 1.2766120433807373\n",
      "mse 1.2766120457733359\n",
      "New best model found at epoch 254 with validation loss 1.2766120433807373\n",
      "Starting Epoch 255\n",
      "1.329332284629345\n",
      "Validation loss: 1.2759917974472046\n",
      "mse 1.2759918767071268\n",
      "New best model found at epoch 255 with validation loss 1.2759917974472046\n",
      "Starting Epoch 256\n",
      "1.3287349020441372\n",
      "Validation loss: 1.2754698991775513\n",
      "mse 1.275469943382667\n",
      "New best model found at epoch 256 with validation loss 1.2754698991775513\n",
      "Starting Epoch 257\n",
      "1.3282263899842899\n",
      "Validation loss: 1.2746927738189697\n",
      "mse 1.2746928162005964\n",
      "New best model found at epoch 257 with validation loss 1.2746927738189697\n",
      "Starting Epoch 258\n",
      "1.3275472993652027\n",
      "Validation loss: 1.2739368677139282\n",
      "mse 1.2739369355210057\n",
      "New best model found at epoch 258 with validation loss 1.2739368677139282\n",
      "Starting Epoch 259\n",
      "1.3267814045151074\n",
      "Validation loss: 1.2730633020401\n",
      "mse 1.273063304048279\n",
      "New best model found at epoch 259 with validation loss 1.2730633020401\n",
      "Starting Epoch 260\n",
      "1.3260359913110733\n",
      "Validation loss: 1.272300362586975\n",
      "mse 1.2723003921217715\n",
      "New best model found at epoch 260 with validation loss 1.272300362586975\n",
      "Starting Epoch 261\n",
      "1.3252758060892422\n",
      "Validation loss: 1.2715048789978027\n",
      "mse 1.2715048602725874\n",
      "New best model found at epoch 261 with validation loss 1.2715048789978027\n",
      "Starting Epoch 262\n",
      "1.3245083043972652\n",
      "Validation loss: 1.2706366777420044\n",
      "mse 1.2706366628330663\n",
      "New best model found at epoch 262 with validation loss 1.2706366777420044\n",
      "Starting Epoch 263\n",
      "1.3237875998020172\n",
      "Validation loss: 1.2698060274124146\n",
      "mse 1.2698060110443272\n",
      "New best model found at epoch 263 with validation loss 1.2698060274124146\n",
      "Starting Epoch 264\n",
      "1.3231123288472493\n",
      "Validation loss: 1.269079327583313\n",
      "mse 1.2690792135610796\n",
      "New best model found at epoch 264 with validation loss 1.269079327583313\n",
      "Starting Epoch 265\n",
      "1.322399119536082\n",
      "Validation loss: 1.2682971954345703\n",
      "mse 1.2682972435901643\n",
      "New best model found at epoch 265 with validation loss 1.2682971954345703\n",
      "Starting Epoch 266\n",
      "1.3217903524637222\n",
      "Validation loss: 1.267733097076416\n",
      "mse 1.2677329819064773\n",
      "New best model found at epoch 266 with validation loss 1.267733097076416\n",
      "Starting Epoch 267\n",
      "1.321214680870374\n",
      "Validation loss: 1.2673574686050415\n",
      "mse 1.2673574901197433\n",
      "New best model found at epoch 267 with validation loss 1.2673574686050415\n",
      "Starting Epoch 268\n",
      "1.3206935202081997\n",
      "Validation loss: 1.2669349908828735\n",
      "mse 1.2669349098205145\n",
      "New best model found at epoch 268 with validation loss 1.2669349908828735\n",
      "Starting Epoch 269\n",
      "1.3201972916722298\n",
      "Validation loss: 1.2665992975234985\n",
      "mse 1.2665992704298272\n",
      "New best model found at epoch 269 with validation loss 1.2665992975234985\n",
      "Starting Epoch 270\n",
      "1.3196686804294586\n",
      "Validation loss: 1.2661546468734741\n",
      "mse 1.266154636311507\n",
      "New best model found at epoch 270 with validation loss 1.2661546468734741\n",
      "Starting Epoch 271\n",
      "1.3191591252883275\n",
      "Validation loss: 1.2655829191207886\n",
      "mse 1.2655829193287027\n",
      "New best model found at epoch 271 with validation loss 1.2655829191207886\n",
      "Starting Epoch 272\n",
      "1.3186533500750859\n",
      "Validation loss: 1.2652130126953125\n",
      "mse 1.2652128947622898\n",
      "New best model found at epoch 272 with validation loss 1.2652130126953125\n",
      "Starting Epoch 273\n",
      "1.318102126320203\n",
      "Validation loss: 1.2646640539169312\n",
      "mse 1.2646640775944022\n",
      "New best model found at epoch 273 with validation loss 1.2646640539169312\n",
      "Starting Epoch 274\n",
      "1.3175626968344052\n",
      "Validation loss: 1.2641407251358032\n",
      "mse 1.264140661758426\n",
      "New best model found at epoch 274 with validation loss 1.2641407251358032\n",
      "Starting Epoch 275\n",
      "1.317077433069547\n",
      "Validation loss: 1.2637696266174316\n",
      "mse 1.263769629359985\n",
      "New best model found at epoch 275 with validation loss 1.2637696266174316\n",
      "Starting Epoch 276\n",
      "1.3165518840154011\n",
      "Validation loss: 1.2633028030395508\n",
      "mse 1.2633027202389888\n",
      "New best model found at epoch 276 with validation loss 1.2633028030395508\n",
      "Starting Epoch 277\n",
      "1.3159764409065247\n",
      "Validation loss: 1.2628822326660156\n",
      "mse 1.2628822441613448\n",
      "New best model found at epoch 277 with validation loss 1.2628822326660156\n",
      "Starting Epoch 278\n",
      "1.3155686780810356\n",
      "Validation loss: 1.262623906135559\n",
      "mse 1.2626238451458074\n",
      "New best model found at epoch 278 with validation loss 1.262623906135559\n",
      "Starting Epoch 279\n",
      "1.315082016090552\n",
      "Validation loss: 1.262156367301941\n",
      "mse 1.2621563696666276\n",
      "New best model found at epoch 279 with validation loss 1.262156367301941\n",
      "Starting Epoch 280\n",
      "1.3145317807793617\n",
      "Validation loss: 1.2617400884628296\n",
      "mse 1.2617401574240465\n",
      "New best model found at epoch 280 with validation loss 1.2617400884628296\n",
      "Starting Epoch 281\n",
      "1.3140251984198887\n",
      "Validation loss: 1.2615164518356323\n",
      "mse 1.2615164702761177\n",
      "New best model found at epoch 281 with validation loss 1.2615164518356323\n",
      "Starting Epoch 282\n",
      "1.313476634522279\n",
      "Validation loss: 1.2611404657363892\n",
      "mse 1.2611406389793813\n",
      "New best model found at epoch 282 with validation loss 1.2611404657363892\n",
      "Starting Epoch 283\n",
      "1.3129445165395737\n",
      "Validation loss: 1.2609323263168335\n",
      "mse 1.260932191086951\n",
      "New best model found at epoch 283 with validation loss 1.2609323263168335\n",
      "Starting Epoch 284\n",
      "1.3122990081707637\n",
      "Validation loss: 1.2605562210083008\n",
      "mse 1.2605561776272372\n",
      "New best model found at epoch 284 with validation loss 1.2605562210083008\n",
      "Starting Epoch 285\n",
      "1.3117519567410152\n",
      "Validation loss: 1.260297179222107\n",
      "mse 1.2602973248830687\n",
      "New best model found at epoch 285 with validation loss 1.260297179222107\n",
      "Starting Epoch 286\n",
      "1.311188151439031\n",
      "Validation loss: 1.2599222660064697\n",
      "mse 1.2599222034984805\n",
      "New best model found at epoch 286 with validation loss 1.2599222660064697\n",
      "Starting Epoch 287\n",
      "1.3106693054238956\n",
      "Validation loss: 1.2596005201339722\n",
      "mse 1.259600474264195\n",
      "New best model found at epoch 287 with validation loss 1.2596005201339722\n",
      "Starting Epoch 288\n",
      "1.31002626568079\n",
      "Validation loss: 1.2593307495117188\n",
      "mse 1.2593308592691914\n",
      "New best model found at epoch 288 with validation loss 1.2593307495117188\n",
      "Starting Epoch 289\n",
      "1.3095316514372826\n",
      "Validation loss: 1.2591092586517334\n",
      "mse 1.259109289839955\n",
      "New best model found at epoch 289 with validation loss 1.2591092586517334\n",
      "Starting Epoch 290\n",
      "1.3090448478857677\n",
      "Validation loss: 1.2587801218032837\n",
      "mse 1.2587800823797928\n",
      "New best model found at epoch 290 with validation loss 1.2587801218032837\n",
      "Starting Epoch 291\n",
      "1.308496395746867\n",
      "Validation loss: 1.2584389448165894\n",
      "mse 1.258438970594062\n",
      "New best model found at epoch 291 with validation loss 1.2584389448165894\n",
      "Starting Epoch 292\n",
      "1.3080493981639545\n",
      "Validation loss: 1.2580232620239258\n",
      "mse 1.2580231710399483\n",
      "New best model found at epoch 292 with validation loss 1.2580232620239258\n",
      "Starting Epoch 293\n",
      "1.307609702150027\n",
      "Validation loss: 1.2578009366989136\n",
      "mse 1.2578009332301667\n",
      "New best model found at epoch 293 with validation loss 1.2578009366989136\n",
      "Starting Epoch 294\n",
      "1.3070427551865578\n",
      "Validation loss: 1.2575160264968872\n",
      "mse 1.2575159356653787\n",
      "New best model found at epoch 294 with validation loss 1.2575160264968872\n",
      "Starting Epoch 295\n",
      "1.3066394651929538\n",
      "Validation loss: 1.2572484016418457\n",
      "mse 1.2572484057181725\n",
      "New best model found at epoch 295 with validation loss 1.2572484016418457\n",
      "Starting Epoch 296\n",
      "1.306118480861187\n",
      "Validation loss: 1.2568542957305908\n",
      "mse 1.2568542532888107\n",
      "New best model found at epoch 296 with validation loss 1.2568542957305908\n",
      "Starting Epoch 297\n",
      "1.3056618198752403\n",
      "Validation loss: 1.2564610242843628\n",
      "mse 1.2564609061284977\n",
      "New best model found at epoch 297 with validation loss 1.2564610242843628\n",
      "Starting Epoch 298\n",
      "1.3051861102382343\n",
      "Validation loss: 1.2562665939331055\n",
      "mse 1.2562666654152788\n",
      "New best model found at epoch 298 with validation loss 1.2562665939331055\n",
      "Starting Epoch 299\n",
      "1.3047161400318146\n",
      "Validation loss: 1.2558786869049072\n",
      "mse 1.2558786388433518\n",
      "New best model found at epoch 299 with validation loss 1.2558786869049072\n",
      "Starting Epoch 300\n",
      "1.3042986566821735\n",
      "Validation loss: 1.2556333541870117\n",
      "mse 1.255633409216984\n",
      "New best model found at epoch 300 with validation loss 1.2556333541870117\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-40-10-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a754cc",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 40 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "085b77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "dcac8c7e-3107-4876-8178-dd7727dea88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.6575487007697425\n",
      "Validation loss: 2.225450277328491\n",
      "mse 2.2254502978443793\n",
      "New best model found at epoch 1 with validation loss 2.225450277328491\n",
      "Starting Epoch 2\n",
      "2.103057344754537\n",
      "Validation loss: 1.9523524045944214\n",
      "mse 1.952352527331554\n",
      "New best model found at epoch 2 with validation loss 1.9523524045944214\n",
      "Starting Epoch 3\n",
      "1.9371623645226161\n",
      "Validation loss: 1.8182958364486694\n",
      "mse 1.8182957410999812\n",
      "New best model found at epoch 3 with validation loss 1.8182958364486694\n",
      "Starting Epoch 4\n",
      "1.8315458744764328\n",
      "Validation loss: 1.7203048467636108\n",
      "mse 1.7203049126818872\n",
      "New best model found at epoch 4 with validation loss 1.7203048467636108\n",
      "Starting Epoch 5\n",
      "1.7522055208683014\n",
      "Validation loss: 1.65043044090271\n",
      "mse 1.6504304612650769\n",
      "New best model found at epoch 5 with validation loss 1.65043044090271\n",
      "Starting Epoch 6\n",
      "1.6942177812258403\n",
      "Validation loss: 1.6010029315948486\n",
      "mse 1.6010029872652736\n",
      "New best model found at epoch 6 with validation loss 1.6010029315948486\n",
      "Starting Epoch 7\n",
      "1.6515130052963893\n",
      "Validation loss: 1.5674879550933838\n",
      "mse 1.5674879092181533\n",
      "New best model found at epoch 7 with validation loss 1.5674879550933838\n",
      "Starting Epoch 8\n",
      "1.6196560859680176\n",
      "Validation loss: 1.5427443981170654\n",
      "mse 1.5427444543192406\n",
      "New best model found at epoch 8 with validation loss 1.5427443981170654\n",
      "Starting Epoch 9\n",
      "1.5950664977232616\n",
      "Validation loss: 1.5245612859725952\n",
      "mse 1.5245612389112633\n",
      "New best model found at epoch 9 with validation loss 1.5245612859725952\n",
      "Starting Epoch 10\n",
      "1.5746950954198837\n",
      "Validation loss: 1.5104836225509644\n",
      "mse 1.5104836243103765\n",
      "New best model found at epoch 10 with validation loss 1.5104836225509644\n",
      "Starting Epoch 11\n",
      "1.5583333323399227\n",
      "Validation loss: 1.4992629289627075\n",
      "mse 1.4992629037521492\n",
      "New best model found at epoch 11 with validation loss 1.4992629289627075\n",
      "Starting Epoch 12\n",
      "1.544989248116811\n",
      "Validation loss: 1.4882065057754517\n",
      "mse 1.4882063074960252\n",
      "New best model found at epoch 12 with validation loss 1.4882065057754517\n",
      "Starting Epoch 13\n",
      "1.5335102428992589\n",
      "Validation loss: 1.480972409248352\n",
      "mse 1.4809724558940354\n",
      "New best model found at epoch 13 with validation loss 1.480972409248352\n",
      "Starting Epoch 14\n",
      "1.5238986959060032\n",
      "Validation loss: 1.4741096496582031\n",
      "mse 1.4741096389157553\n",
      "New best model found at epoch 14 with validation loss 1.4741096496582031\n",
      "Starting Epoch 15\n",
      "1.5149742464224498\n",
      "Validation loss: 1.4685444831848145\n",
      "mse 1.4685443951973483\n",
      "New best model found at epoch 15 with validation loss 1.4685444831848145\n",
      "Starting Epoch 16\n",
      "1.5071724901596706\n",
      "Validation loss: 1.463050127029419\n",
      "mse 1.463050072287406\n",
      "New best model found at epoch 16 with validation loss 1.463050127029419\n",
      "Starting Epoch 17\n",
      "1.4997674226760864\n",
      "Validation loss: 1.458178997039795\n",
      "mse 1.4581790452441379\n",
      "New best model found at epoch 17 with validation loss 1.458178997039795\n",
      "Starting Epoch 18\n",
      "1.4931324621041615\n",
      "Validation loss: 1.453850507736206\n",
      "mse 1.453850647541977\n",
      "New best model found at epoch 18 with validation loss 1.453850507736206\n",
      "Starting Epoch 19\n",
      "1.486929749449094\n",
      "Validation loss: 1.4494118690490723\n",
      "mse 1.4494119480785228\n",
      "New best model found at epoch 19 with validation loss 1.4494118690490723\n",
      "Starting Epoch 20\n",
      "1.480858748157819\n",
      "Validation loss: 1.4452546834945679\n",
      "mse 1.4452547744304185\n",
      "New best model found at epoch 20 with validation loss 1.4452546834945679\n",
      "Starting Epoch 21\n",
      "1.4753351658582687\n",
      "Validation loss: 1.4409058094024658\n",
      "mse 1.4409057373332252\n",
      "New best model found at epoch 21 with validation loss 1.4409058094024658\n",
      "Starting Epoch 22\n",
      "1.4698315809170406\n",
      "Validation loss: 1.438011884689331\n",
      "mse 1.4380120337996032\n",
      "New best model found at epoch 22 with validation loss 1.438011884689331\n",
      "Starting Epoch 23\n",
      "1.4648857812086742\n",
      "Validation loss: 1.4341970682144165\n",
      "mse 1.4341970409272702\n",
      "New best model found at epoch 23 with validation loss 1.4341970682144165\n",
      "Starting Epoch 24\n",
      "1.4600078066190083\n",
      "Validation loss: 1.4299366474151611\n",
      "mse 1.4299367321071168\n",
      "New best model found at epoch 24 with validation loss 1.4299366474151611\n",
      "Starting Epoch 25\n",
      "1.4551217158635457\n",
      "Validation loss: 1.4268630743026733\n",
      "mse 1.4268631954594464\n",
      "New best model found at epoch 25 with validation loss 1.4268630743026733\n",
      "Starting Epoch 26\n",
      "1.4505810141563416\n",
      "Validation loss: 1.422763705253601\n",
      "mse 1.4227636464903748\n",
      "New best model found at epoch 26 with validation loss 1.422763705253601\n",
      "Starting Epoch 27\n",
      "1.4461153994003932\n",
      "Validation loss: 1.4192014932632446\n",
      "mse 1.4192015983643471\n",
      "New best model found at epoch 27 with validation loss 1.4192014932632446\n",
      "Starting Epoch 28\n",
      "1.4414628247419994\n",
      "Validation loss: 1.4156725406646729\n",
      "mse 1.4156725997063457\n",
      "New best model found at epoch 28 with validation loss 1.4156725406646729\n",
      "Starting Epoch 29\n",
      "1.4372753749291103\n",
      "Validation loss: 1.4128391742706299\n",
      "mse 1.4128393008384141\n",
      "New best model found at epoch 29 with validation loss 1.4128391742706299\n",
      "Starting Epoch 30\n",
      "1.4329866617918015\n",
      "Validation loss: 1.4096766710281372\n",
      "mse 1.4096767083056168\n",
      "New best model found at epoch 30 with validation loss 1.4096766710281372\n",
      "Starting Epoch 31\n",
      "1.428808997074763\n",
      "Validation loss: 1.4055625200271606\n",
      "mse 1.4055625261827112\n",
      "New best model found at epoch 31 with validation loss 1.4055625200271606\n",
      "Starting Epoch 32\n",
      "1.4244596511125565\n",
      "Validation loss: 1.4034161567687988\n",
      "mse 1.4034160891797867\n",
      "New best model found at epoch 32 with validation loss 1.4034161567687988\n",
      "Starting Epoch 33\n",
      "1.4206804484128952\n",
      "Validation loss: 1.3998569250106812\n",
      "mse 1.3998569240211796\n",
      "New best model found at epoch 33 with validation loss 1.3998569250106812\n",
      "Starting Epoch 34\n",
      "1.4163939505815506\n",
      "Validation loss: 1.3958017826080322\n",
      "mse 1.3958017645680443\n",
      "New best model found at epoch 34 with validation loss 1.3958017826080322\n",
      "Starting Epoch 35\n",
      "1.412410760919253\n",
      "Validation loss: 1.3929036855697632\n",
      "mse 1.3929035828477758\n",
      "New best model found at epoch 35 with validation loss 1.3929036855697632\n",
      "Starting Epoch 36\n",
      "1.408177341024081\n",
      "Validation loss: 1.3892136812210083\n",
      "mse 1.3892137581099078\n",
      "New best model found at epoch 36 with validation loss 1.3892136812210083\n",
      "Starting Epoch 37\n",
      "1.4029943297306697\n",
      "Validation loss: 1.3835968971252441\n",
      "mse 1.3835970239027031\n",
      "New best model found at epoch 37 with validation loss 1.3835968971252441\n",
      "Starting Epoch 38\n",
      "1.3989425400892894\n",
      "Validation loss: 1.3818814754486084\n",
      "mse 1.381881504166969\n",
      "New best model found at epoch 38 with validation loss 1.3818814754486084\n",
      "Starting Epoch 39\n",
      "1.3952941248814266\n",
      "Validation loss: 1.3783929347991943\n",
      "mse 1.3783929639153119\n",
      "New best model found at epoch 39 with validation loss 1.3783929347991943\n",
      "Starting Epoch 40\n",
      "1.3917625894149144\n",
      "Validation loss: 1.3761801719665527\n",
      "mse 1.3761802465985902\n",
      "New best model found at epoch 40 with validation loss 1.3761801719665527\n",
      "Starting Epoch 41\n",
      "1.3884371643265088\n",
      "Validation loss: 1.3726186752319336\n",
      "mse 1.372618728954197\n",
      "New best model found at epoch 41 with validation loss 1.3726186752319336\n",
      "Starting Epoch 42\n",
      "1.384826086461544\n",
      "Validation loss: 1.3702226877212524\n",
      "mse 1.3702226919451355\n",
      "New best model found at epoch 42 with validation loss 1.3702226877212524\n",
      "Starting Epoch 43\n",
      "1.3814073503017426\n",
      "Validation loss: 1.3697247505187988\n",
      "mse 1.3697247063846125\n",
      "New best model found at epoch 43 with validation loss 1.3697247505187988\n",
      "Starting Epoch 44\n",
      "1.3783935382962227\n",
      "Validation loss: 1.364635944366455\n",
      "mse 1.3646358877829847\n",
      "New best model found at epoch 44 with validation loss 1.364635944366455\n",
      "Starting Epoch 45\n",
      "1.3750494097669919\n",
      "Validation loss: 1.363076090812683\n",
      "mse 1.3630759602789495\n",
      "New best model found at epoch 45 with validation loss 1.363076090812683\n",
      "Starting Epoch 46\n",
      "1.3719256470600765\n",
      "Validation loss: 1.3612414598464966\n",
      "mse 1.36124145234859\n",
      "New best model found at epoch 46 with validation loss 1.3612414598464966\n",
      "Starting Epoch 47\n",
      "1.3690717220306396\n",
      "Validation loss: 1.3579952716827393\n",
      "mse 1.3579952622290912\n",
      "New best model found at epoch 47 with validation loss 1.3579952716827393\n",
      "Starting Epoch 48\n",
      "1.3660640542705853\n",
      "Validation loss: 1.3553768396377563\n",
      "mse 1.3553769642733582\n",
      "New best model found at epoch 48 with validation loss 1.3553768396377563\n",
      "Starting Epoch 49\n",
      "1.3630880763133366\n",
      "Validation loss: 1.3541463613510132\n",
      "mse 1.3541464385257675\n",
      "New best model found at epoch 49 with validation loss 1.3541463613510132\n",
      "Starting Epoch 50\n",
      "1.3601859857638676\n",
      "Validation loss: 1.3506873846054077\n",
      "mse 1.3506874028924079\n",
      "New best model found at epoch 50 with validation loss 1.3506873846054077\n",
      "Starting Epoch 51\n",
      "1.3573080102602642\n",
      "Validation loss: 1.3489044904708862\n",
      "mse 1.3489044950016393\n",
      "New best model found at epoch 51 with validation loss 1.3489044904708862\n",
      "Starting Epoch 52\n",
      "1.3545295347770054\n",
      "Validation loss: 1.3463122844696045\n",
      "mse 1.3463123512544986\n",
      "New best model found at epoch 52 with validation loss 1.3463122844696045\n",
      "Starting Epoch 53\n",
      "1.351661577820778\n",
      "Validation loss: 1.343876838684082\n",
      "mse 1.3438768442708\n",
      "New best model found at epoch 53 with validation loss 1.343876838684082\n",
      "Starting Epoch 54\n",
      "1.3491063763697941\n",
      "Validation loss: 1.3406596183776855\n",
      "mse 1.3406595946678572\n",
      "New best model found at epoch 54 with validation loss 1.3406596183776855\n",
      "Starting Epoch 55\n",
      "1.346370669702689\n",
      "Validation loss: 1.338526964187622\n",
      "mse 1.338526938376284\n",
      "New best model found at epoch 55 with validation loss 1.338526964187622\n",
      "Starting Epoch 56\n",
      "1.3437298859159152\n",
      "Validation loss: 1.3376106023788452\n",
      "mse 1.3376104597569158\n",
      "New best model found at epoch 56 with validation loss 1.3376106023788452\n",
      "Starting Epoch 57\n",
      "1.3413423871000607\n",
      "Validation loss: 1.3365124464035034\n",
      "mse 1.336512527481098\n",
      "New best model found at epoch 57 with validation loss 1.3365124464035034\n",
      "Starting Epoch 58\n",
      "1.3389201958974202\n",
      "Validation loss: 1.3346624374389648\n",
      "mse 1.3346624570981533\n",
      "New best model found at epoch 58 with validation loss 1.3346624374389648\n",
      "Starting Epoch 59\n",
      "1.3365164175629616\n",
      "Validation loss: 1.3324027061462402\n",
      "mse 1.3324026610484447\n",
      "New best model found at epoch 59 with validation loss 1.3324027061462402\n",
      "Starting Epoch 60\n",
      "1.3340600033601124\n",
      "Validation loss: 1.3308709859848022\n",
      "mse 1.330871081367356\n",
      "New best model found at epoch 60 with validation loss 1.3308709859848022\n",
      "Starting Epoch 61\n",
      "1.3318252836664517\n",
      "Validation loss: 1.3286426067352295\n",
      "mse 1.3286424407224646\n",
      "New best model found at epoch 61 with validation loss 1.3286426067352295\n",
      "Starting Epoch 62\n",
      "1.3294830123583476\n",
      "Validation loss: 1.326969861984253\n",
      "mse 1.3269699819694556\n",
      "New best model found at epoch 62 with validation loss 1.326969861984253\n",
      "Starting Epoch 63\n",
      "1.3272990435361862\n",
      "Validation loss: 1.32502281665802\n",
      "mse 1.3250229204362134\n",
      "New best model found at epoch 63 with validation loss 1.32502281665802\n",
      "Starting Epoch 64\n",
      "1.3250043069322903\n",
      "Validation loss: 1.3228973150253296\n",
      "mse 1.3228973305467828\n",
      "New best model found at epoch 64 with validation loss 1.3228973150253296\n",
      "Starting Epoch 65\n",
      "1.3228280966480572\n",
      "Validation loss: 1.3209174871444702\n",
      "mse 1.320917469838377\n",
      "New best model found at epoch 65 with validation loss 1.3209174871444702\n",
      "Starting Epoch 66\n",
      "1.320704109966755\n",
      "Validation loss: 1.319055438041687\n",
      "mse 1.3190554188517423\n",
      "New best model found at epoch 66 with validation loss 1.319055438041687\n",
      "Starting Epoch 67\n",
      "1.3183790345986683\n",
      "Validation loss: 1.3175300359725952\n",
      "mse 1.317530118507657\n",
      "New best model found at epoch 67 with validation loss 1.3175300359725952\n",
      "Starting Epoch 68\n",
      "1.316218415896098\n",
      "Validation loss: 1.3143203258514404\n",
      "mse 1.3143203272232096\n",
      "New best model found at epoch 68 with validation loss 1.3143203258514404\n",
      "Starting Epoch 69\n",
      "1.3136100843548775\n",
      "Validation loss: 1.3133383989334106\n",
      "mse 1.313338423927228\n",
      "New best model found at epoch 69 with validation loss 1.3133383989334106\n",
      "Starting Epoch 70\n",
      "1.3107585832476616\n",
      "Validation loss: 1.3119434118270874\n",
      "mse 1.311943472803936\n",
      "New best model found at epoch 70 with validation loss 1.3119434118270874\n",
      "Starting Epoch 71\n",
      "1.3075998822848003\n",
      "Validation loss: 1.3112373352050781\n",
      "mse 1.3112374665738171\n",
      "New best model found at epoch 71 with validation loss 1.3112373352050781\n",
      "Starting Epoch 72\n",
      "1.3048905258377392\n",
      "Validation loss: 1.3103771209716797\n",
      "mse 1.310377065356976\n",
      "New best model found at epoch 72 with validation loss 1.3103771209716797\n",
      "Starting Epoch 73\n",
      "1.3024146830042203\n",
      "Validation loss: 1.3094934225082397\n",
      "mse 1.3094934254073398\n",
      "New best model found at epoch 73 with validation loss 1.3094934225082397\n",
      "Starting Epoch 74\n",
      "1.300103209912777\n",
      "Validation loss: 1.3066191673278809\n",
      "mse 1.3066191947721035\n",
      "New best model found at epoch 74 with validation loss 1.3066191673278809\n",
      "Starting Epoch 75\n",
      "1.2976153368751209\n",
      "Validation loss: 1.3057861328125\n",
      "mse 1.3057860215856814\n",
      "New best model found at epoch 75 with validation loss 1.3057861328125\n",
      "Starting Epoch 76\n",
      "1.2953849708040555\n",
      "Validation loss: 1.3031501770019531\n",
      "mse 1.3031501387734186\n",
      "New best model found at epoch 76 with validation loss 1.3031501770019531\n",
      "Starting Epoch 77\n",
      "1.2931756327549617\n",
      "Validation loss: 1.300696849822998\n",
      "mse 1.3006969593828348\n",
      "New best model found at epoch 77 with validation loss 1.300696849822998\n",
      "Starting Epoch 78\n",
      "1.2910221964120865\n",
      "Validation loss: 1.2987490892410278\n",
      "mse 1.298749070336652\n",
      "New best model found at epoch 78 with validation loss 1.2987490892410278\n",
      "Starting Epoch 79\n",
      "1.2891099527478218\n",
      "Validation loss: 1.2973092794418335\n",
      "mse 1.29730935080629\n",
      "New best model found at epoch 79 with validation loss 1.2973092794418335\n",
      "Starting Epoch 80\n",
      "1.286944958070914\n",
      "Validation loss: 1.295488953590393\n",
      "mse 1.2954889536379732\n",
      "New best model found at epoch 80 with validation loss 1.295488953590393\n",
      "Starting Epoch 81\n",
      "1.2850053409735362\n",
      "Validation loss: 1.2938504219055176\n",
      "mse 1.293850481704847\n",
      "New best model found at epoch 81 with validation loss 1.2938504219055176\n",
      "Starting Epoch 82\n",
      "1.28293393800656\n",
      "Validation loss: 1.291425347328186\n",
      "mse 1.2914254294713754\n",
      "New best model found at epoch 82 with validation loss 1.291425347328186\n",
      "Starting Epoch 83\n",
      "1.280918759604295\n",
      "Validation loss: 1.2900484800338745\n",
      "mse 1.2900484768209697\n",
      "New best model found at epoch 83 with validation loss 1.2900484800338745\n",
      "Starting Epoch 84\n",
      "1.2790214369694393\n",
      "Validation loss: 1.2882599830627441\n",
      "mse 1.2882599564907327\n",
      "New best model found at epoch 84 with validation loss 1.2882599830627441\n",
      "Starting Epoch 85\n",
      "1.277096189558506\n",
      "Validation loss: 1.2880171537399292\n",
      "mse 1.2880171479914273\n",
      "New best model found at epoch 85 with validation loss 1.2880171537399292\n",
      "Starting Epoch 86\n",
      "1.2754236658414204\n",
      "Validation loss: 1.2856091260910034\n",
      "mse 1.285609044500794\n",
      "New best model found at epoch 86 with validation loss 1.2856091260910034\n",
      "Starting Epoch 87\n",
      "1.273649198313554\n",
      "Validation loss: 1.2835590839385986\n",
      "mse 1.2835591154048138\n",
      "New best model found at epoch 87 with validation loss 1.2835590839385986\n",
      "Starting Epoch 88\n",
      "1.2716102773944538\n",
      "Validation loss: 1.2820916175842285\n",
      "mse 1.2820915593856825\n",
      "New best model found at epoch 88 with validation loss 1.2820916175842285\n",
      "Starting Epoch 89\n",
      "1.2696968540549278\n",
      "Validation loss: 1.2805696725845337\n",
      "mse 1.2805697103804392\n",
      "New best model found at epoch 89 with validation loss 1.2805696725845337\n",
      "Starting Epoch 90\n",
      "1.2679287840922673\n",
      "Validation loss: 1.279712438583374\n",
      "mse 1.2797125486076844\n",
      "New best model found at epoch 90 with validation loss 1.279712438583374\n",
      "Starting Epoch 91\n",
      "1.266332636276881\n",
      "Validation loss: 1.2777202129364014\n",
      "mse 1.2777201502012812\n",
      "New best model found at epoch 91 with validation loss 1.2777202129364014\n",
      "Starting Epoch 92\n",
      "1.2644600868225098\n",
      "Validation loss: 1.2768816947937012\n",
      "mse 1.2768817075145031\n",
      "New best model found at epoch 92 with validation loss 1.2768816947937012\n",
      "Starting Epoch 93\n",
      "1.2628182818492253\n",
      "Validation loss: 1.275017499923706\n",
      "mse 1.2750175815143583\n",
      "New best model found at epoch 93 with validation loss 1.275017499923706\n",
      "Starting Epoch 94\n",
      "1.2610864788293839\n",
      "Validation loss: 1.2735137939453125\n",
      "mse 1.273513782129055\n",
      "New best model found at epoch 94 with validation loss 1.2735137939453125\n",
      "Starting Epoch 95\n",
      "1.2594428484638531\n",
      "Validation loss: 1.2719776630401611\n",
      "mse 1.2719777019150358\n",
      "New best model found at epoch 95 with validation loss 1.2719776630401611\n",
      "Starting Epoch 96\n",
      "1.2577232271432877\n",
      "Validation loss: 1.2707871198654175\n",
      "mse 1.2707870577738902\n",
      "New best model found at epoch 96 with validation loss 1.2707871198654175\n",
      "Starting Epoch 97\n",
      "1.2560433770219486\n",
      "Validation loss: 1.2691341638565063\n",
      "mse 1.269134080842072\n",
      "New best model found at epoch 97 with validation loss 1.2691341638565063\n",
      "Starting Epoch 98\n",
      "1.2542945941289265\n",
      "Validation loss: 1.2680119276046753\n",
      "mse 1.268011790009195\n",
      "New best model found at epoch 98 with validation loss 1.2680119276046753\n",
      "Starting Epoch 99\n",
      "1.2525973642865817\n",
      "Validation loss: 1.2664003372192383\n",
      "mse 1.2664003518725\n",
      "New best model found at epoch 99 with validation loss 1.2664003372192383\n",
      "Starting Epoch 100\n",
      "1.2509377648433049\n",
      "Validation loss: 1.2664886713027954\n",
      "mse 1.2664886599232676\n",
      "Starting Epoch 101\n",
      "1.248617097735405\n",
      "Validation loss: 1.2657502889633179\n",
      "mse 1.2657502395854916\n",
      "New best model found at epoch 101 with validation loss 1.2657502889633179\n",
      "Starting Epoch 102\n",
      "1.2465238968531291\n",
      "Validation loss: 1.2650867700576782\n",
      "mse 1.2650868229420045\n",
      "New best model found at epoch 102 with validation loss 1.2650867700576782\n",
      "Starting Epoch 103\n",
      "1.2447429150342941\n",
      "Validation loss: 1.263664960861206\n",
      "mse 1.2636648601895693\n",
      "New best model found at epoch 103 with validation loss 1.263664960861206\n",
      "Starting Epoch 104\n",
      "1.2431995297471683\n",
      "Validation loss: 1.2628003358840942\n",
      "mse 1.2628003402105594\n",
      "New best model found at epoch 104 with validation loss 1.2628003358840942\n",
      "Starting Epoch 105\n",
      "1.2416494091351826\n",
      "Validation loss: 1.261842966079712\n",
      "mse 1.2618429858878872\n",
      "New best model found at epoch 105 with validation loss 1.261842966079712\n",
      "Starting Epoch 106\n",
      "1.2399752363562584\n",
      "Validation loss: 1.2598211765289307\n",
      "mse 1.259821270613842\n",
      "New best model found at epoch 106 with validation loss 1.2598211765289307\n",
      "Starting Epoch 107\n",
      "1.2381127774715424\n",
      "Validation loss: 1.2588567733764648\n",
      "mse 1.2588567222388622\n",
      "New best model found at epoch 107 with validation loss 1.2588567733764648\n",
      "Starting Epoch 108\n",
      "1.236545741558075\n",
      "Validation loss: 1.2573548555374146\n",
      "mse 1.257354740942768\n",
      "New best model found at epoch 108 with validation loss 1.2573548555374146\n",
      "Starting Epoch 109\n",
      "1.234820306301117\n",
      "Validation loss: 1.2563326358795166\n",
      "mse 1.2563327012374643\n",
      "New best model found at epoch 109 with validation loss 1.2563326358795166\n",
      "Starting Epoch 110\n",
      "1.2333212817708652\n",
      "Validation loss: 1.2548730373382568\n",
      "mse 1.2548730373275967\n",
      "New best model found at epoch 110 with validation loss 1.2548730373382568\n",
      "Starting Epoch 111\n",
      "1.2316265081365902\n",
      "Validation loss: 1.2536510229110718\n",
      "mse 1.2536510156911347\n",
      "New best model found at epoch 111 with validation loss 1.2536510229110718\n",
      "Starting Epoch 112\n",
      "1.2301140626271565\n",
      "Validation loss: 1.2525975704193115\n",
      "mse 1.2525974518001035\n",
      "New best model found at epoch 112 with validation loss 1.2525975704193115\n",
      "Starting Epoch 113\n",
      "1.2285046676794689\n",
      "Validation loss: 1.2516471147537231\n",
      "mse 1.2516471064224368\n",
      "New best model found at epoch 113 with validation loss 1.2516471147537231\n",
      "Starting Epoch 114\n",
      "1.2270908951759338\n",
      "Validation loss: 1.2506064176559448\n",
      "mse 1.250606468759126\n",
      "New best model found at epoch 114 with validation loss 1.2506064176559448\n",
      "Starting Epoch 115\n",
      "1.225375235080719\n",
      "Validation loss: 1.2489861249923706\n",
      "mse 1.2489860909355763\n",
      "New best model found at epoch 115 with validation loss 1.2489861249923706\n",
      "Starting Epoch 116\n",
      "1.2238903492689133\n",
      "Validation loss: 1.2485603094100952\n",
      "mse 1.2485603417629814\n",
      "New best model found at epoch 116 with validation loss 1.2485603094100952\n",
      "Starting Epoch 117\n",
      "1.2223792945345242\n",
      "Validation loss: 1.2474400997161865\n",
      "mse 1.2474400497755886\n",
      "New best model found at epoch 117 with validation loss 1.2474400997161865\n",
      "Starting Epoch 118\n",
      "1.2208926851550739\n",
      "Validation loss: 1.2466977834701538\n",
      "mse 1.2466977945834534\n",
      "New best model found at epoch 118 with validation loss 1.2466977834701538\n",
      "Starting Epoch 119\n",
      "1.2193825766444206\n",
      "Validation loss: 1.2446538209915161\n",
      "mse 1.244653818844129\n",
      "New best model found at epoch 119 with validation loss 1.2446538209915161\n",
      "Starting Epoch 120\n",
      "1.217897097269694\n",
      "Validation loss: 1.244147777557373\n",
      "mse 1.244147730402285\n",
      "New best model found at epoch 120 with validation loss 1.244147777557373\n",
      "Starting Epoch 121\n",
      "1.2165846576293309\n",
      "Validation loss: 1.2435590028762817\n",
      "mse 1.2435590775079852\n",
      "New best model found at epoch 121 with validation loss 1.2435590028762817\n",
      "Starting Epoch 122\n",
      "1.2151294946670532\n",
      "Validation loss: 1.241861343383789\n",
      "mse 1.2418612673880318\n",
      "New best model found at epoch 122 with validation loss 1.241861343383789\n",
      "Starting Epoch 123\n",
      "1.2136110762755077\n",
      "Validation loss: 1.2414143085479736\n",
      "mse 1.2414143145078695\n",
      "New best model found at epoch 123 with validation loss 1.2414143085479736\n",
      "Starting Epoch 124\n",
      "1.2122409790754318\n",
      "Validation loss: 1.240411639213562\n",
      "mse 1.2404116048500966\n",
      "New best model found at epoch 124 with validation loss 1.240411639213562\n",
      "Starting Epoch 125\n",
      "1.2107546081145604\n",
      "Validation loss: 1.2389297485351562\n",
      "mse 1.2389298373817081\n",
      "New best model found at epoch 125 with validation loss 1.2389297485351562\n",
      "Starting Epoch 126\n",
      "1.209331179658572\n",
      "Validation loss: 1.2383959293365479\n",
      "mse 1.2383960593496535\n",
      "New best model found at epoch 126 with validation loss 1.2383959293365479\n",
      "Starting Epoch 127\n",
      "1.2078853696584702\n",
      "Validation loss: 1.2369635105133057\n",
      "mse 1.236963527127647\n",
      "New best model found at epoch 127 with validation loss 1.2369635105133057\n",
      "Starting Epoch 128\n",
      "1.2065483207503955\n",
      "Validation loss: 1.2365933656692505\n",
      "mse 1.236593343873017\n",
      "New best model found at epoch 128 with validation loss 1.2365933656692505\n",
      "Starting Epoch 129\n",
      "1.20515143374602\n",
      "Validation loss: 1.2348649501800537\n",
      "mse 1.234864911365842\n",
      "New best model found at epoch 129 with validation loss 1.2348649501800537\n",
      "Starting Epoch 130\n",
      "1.2037278537948926\n",
      "Validation loss: 1.2346572875976562\n",
      "mse 1.2346571899170653\n",
      "New best model found at epoch 130 with validation loss 1.2346572875976562\n",
      "Starting Epoch 131\n",
      "1.2023241743445396\n",
      "Validation loss: 1.232988953590393\n",
      "mse 1.2329889120629258\n",
      "New best model found at epoch 131 with validation loss 1.232988953590393\n",
      "Starting Epoch 132\n",
      "1.2010662431518238\n",
      "Validation loss: 1.2328075170516968\n",
      "mse 1.232807443580849\n",
      "New best model found at epoch 132 with validation loss 1.2328075170516968\n",
      "Starting Epoch 133\n",
      "1.1996569111943245\n",
      "Validation loss: 1.2313411235809326\n",
      "mse 1.2313412295277315\n",
      "New best model found at epoch 133 with validation loss 1.2313411235809326\n",
      "Starting Epoch 134\n",
      "1.1984138414263725\n",
      "Validation loss: 1.2307392358779907\n",
      "mse 1.2307391947379853\n",
      "New best model found at epoch 134 with validation loss 1.2307392358779907\n",
      "Starting Epoch 135\n",
      "1.1971568862597148\n",
      "Validation loss: 1.2297163009643555\n",
      "mse 1.2297162296644228\n",
      "New best model found at epoch 135 with validation loss 1.2297163009643555\n",
      "Starting Epoch 136\n",
      "1.19587196658055\n",
      "Validation loss: 1.2291769981384277\n",
      "mse 1.2291769997251314\n",
      "New best model found at epoch 136 with validation loss 1.2291769981384277\n",
      "Starting Epoch 137\n",
      "1.1947083895405133\n",
      "Validation loss: 1.2282702922821045\n",
      "mse 1.2282702574436115\n",
      "New best model found at epoch 137 with validation loss 1.2282702922821045\n",
      "Starting Epoch 138\n",
      "1.1934185350934665\n",
      "Validation loss: 1.2264554500579834\n",
      "mse 1.2264554724222176\n",
      "New best model found at epoch 138 with validation loss 1.2264554500579834\n",
      "Starting Epoch 139\n",
      "1.191803400715192\n",
      "Validation loss: 1.2268640995025635\n",
      "mse 1.226864177035106\n",
      "Starting Epoch 140\n",
      "1.1905860056479771\n",
      "Validation loss: 1.224961280822754\n",
      "mse 1.224961407294353\n",
      "New best model found at epoch 140 with validation loss 1.224961280822754\n",
      "Starting Epoch 141\n",
      "1.18927513808012\n",
      "Validation loss: 1.2252217531204224\n",
      "mse 1.2252217149995268\n",
      "Starting Epoch 142\n",
      "1.1881931275129318\n",
      "Validation loss: 1.2234811782836914\n",
      "mse 1.223481122490618\n",
      "New best model found at epoch 142 with validation loss 1.2234811782836914\n",
      "Starting Epoch 143\n",
      "1.1872067227959633\n",
      "Validation loss: 1.2231730222702026\n",
      "mse 1.2231729378660383\n",
      "New best model found at epoch 143 with validation loss 1.2231730222702026\n",
      "Starting Epoch 144\n",
      "1.185958427687486\n",
      "Validation loss: 1.222678303718567\n",
      "mse 1.2226782457402126\n",
      "New best model found at epoch 144 with validation loss 1.222678303718567\n",
      "Starting Epoch 145\n",
      "1.1845686833063762\n",
      "Validation loss: 1.2215995788574219\n",
      "mse 1.2215996250622312\n",
      "New best model found at epoch 145 with validation loss 1.2215995788574219\n",
      "Starting Epoch 146\n",
      "1.18308042238156\n",
      "Validation loss: 1.2214367389678955\n",
      "mse 1.22143669358779\n",
      "New best model found at epoch 146 with validation loss 1.2214367389678955\n",
      "Starting Epoch 147\n",
      "1.1815392151474953\n",
      "Validation loss: 1.2201746702194214\n",
      "mse 1.220174727166055\n",
      "New best model found at epoch 147 with validation loss 1.2201746702194214\n",
      "Starting Epoch 148\n",
      "1.1803107634186745\n",
      "Validation loss: 1.2202504873275757\n",
      "mse 1.2202505015160372\n",
      "Starting Epoch 149\n",
      "1.1790697251756985\n",
      "Validation loss: 1.2186869382858276\n",
      "mse 1.218686774905837\n",
      "New best model found at epoch 149 with validation loss 1.2186869382858276\n",
      "Starting Epoch 150\n",
      "1.177762138346831\n",
      "Validation loss: 1.2185215950012207\n",
      "mse 1.218521565341322\n",
      "New best model found at epoch 150 with validation loss 1.2185215950012207\n",
      "Starting Epoch 151\n",
      "1.1765654782454174\n",
      "Validation loss: 1.217552661895752\n",
      "mse 1.2175526371809338\n",
      "New best model found at epoch 151 with validation loss 1.217552661895752\n",
      "Starting Epoch 152\n",
      "1.175369622806708\n",
      "Validation loss: 1.2174407243728638\n",
      "mse 1.2174407452133142\n",
      "New best model found at epoch 152 with validation loss 1.2174407243728638\n",
      "Starting Epoch 153\n",
      "1.1741555854678154\n",
      "Validation loss: 1.216321349143982\n",
      "mse 1.2163213366730012\n",
      "New best model found at epoch 153 with validation loss 1.216321349143982\n",
      "Starting Epoch 154\n",
      "1.172876700758934\n",
      "Validation loss: 1.216109037399292\n",
      "mse 1.216108984574718\n",
      "New best model found at epoch 154 with validation loss 1.216109037399292\n",
      "Starting Epoch 155\n",
      "1.1719075193007786\n",
      "Validation loss: 1.2157572507858276\n",
      "mse 1.2157572247813608\n",
      "New best model found at epoch 155 with validation loss 1.2157572507858276\n",
      "Starting Epoch 156\n",
      "1.170607713361581\n",
      "Validation loss: 1.2150706052780151\n",
      "mse 1.2150705872791343\n",
      "New best model found at epoch 156 with validation loss 1.2150706052780151\n",
      "Starting Epoch 157\n",
      "1.1693118909994762\n",
      "Validation loss: 1.2148741483688354\n",
      "mse 1.214874204507832\n",
      "New best model found at epoch 157 with validation loss 1.2148741483688354\n",
      "Starting Epoch 158\n",
      "1.1682342886924744\n",
      "Validation loss: 1.2145556211471558\n",
      "mse 1.214555596663593\n",
      "New best model found at epoch 158 with validation loss 1.2145556211471558\n",
      "Starting Epoch 159\n",
      "1.166989542543888\n",
      "Validation loss: 1.2134153842926025\n",
      "mse 1.213415323030946\n",
      "New best model found at epoch 159 with validation loss 1.2134153842926025\n",
      "Starting Epoch 160\n",
      "1.1659962659080823\n",
      "Validation loss: 1.2131072282791138\n",
      "mse 1.2131072626597899\n",
      "New best model found at epoch 160 with validation loss 1.2131072282791138\n",
      "Starting Epoch 161\n",
      "1.1647678092122078\n",
      "Validation loss: 1.2122799158096313\n",
      "mse 1.21227988884944\n",
      "New best model found at epoch 161 with validation loss 1.2122799158096313\n",
      "Starting Epoch 162\n",
      "1.1636142979065578\n",
      "Validation loss: 1.2122058868408203\n",
      "mse 1.2122058866318988\n",
      "New best model found at epoch 162 with validation loss 1.2122058868408203\n",
      "Starting Epoch 163\n",
      "1.1623591308792431\n",
      "Validation loss: 1.211238980293274\n",
      "mse 1.2112389192934598\n",
      "New best model found at epoch 163 with validation loss 1.211238980293274\n",
      "Starting Epoch 164\n",
      "1.1614103491107624\n",
      "Validation loss: 1.210855484008789\n",
      "mse 1.2108554893904084\n",
      "New best model found at epoch 164 with validation loss 1.210855484008789\n",
      "Starting Epoch 165\n",
      "1.1601350928346317\n",
      "Validation loss: 1.2105836868286133\n",
      "mse 1.2105836829375978\n",
      "New best model found at epoch 165 with validation loss 1.2105836868286133\n",
      "Starting Epoch 166\n",
      "1.1592205266157787\n",
      "Validation loss: 1.2102488279342651\n",
      "mse 1.21024889130746\n",
      "New best model found at epoch 166 with validation loss 1.2102488279342651\n",
      "Starting Epoch 167\n",
      "1.1582431743542354\n",
      "Validation loss: 1.2091714143753052\n",
      "mse 1.2091712874998073\n",
      "New best model found at epoch 167 with validation loss 1.2091714143753052\n",
      "Starting Epoch 168\n",
      "1.1570199603835742\n",
      "Validation loss: 1.2091476917266846\n",
      "mse 1.2091477336954817\n",
      "New best model found at epoch 168 with validation loss 1.2091476917266846\n",
      "Starting Epoch 169\n",
      "1.1560143008828163\n",
      "Validation loss: 1.2076237201690674\n",
      "mse 1.207623590067748\n",
      "New best model found at epoch 169 with validation loss 1.2076237201690674\n",
      "Starting Epoch 170\n",
      "1.1548718214035034\n",
      "Validation loss: 1.2080607414245605\n",
      "mse 1.2080606523924524\n",
      "Starting Epoch 171\n",
      "1.1540090143680573\n",
      "Validation loss: 1.2066582441329956\n",
      "mse 1.2066583481411521\n",
      "New best model found at epoch 171 with validation loss 1.2066582441329956\n",
      "Starting Epoch 172\n",
      "1.1528889785210292\n",
      "Validation loss: 1.206531047821045\n",
      "mse 1.2065310014003685\n",
      "New best model found at epoch 172 with validation loss 1.206531047821045\n",
      "Starting Epoch 173\n",
      "1.1518654574950535\n",
      "Validation loss: 1.2060493230819702\n",
      "mse 1.206049218603678\n",
      "New best model found at epoch 173 with validation loss 1.2060493230819702\n",
      "Starting Epoch 174\n",
      "1.1509048988421757\n",
      "Validation loss: 1.2056143283843994\n",
      "mse 1.2056144503498074\n",
      "New best model found at epoch 174 with validation loss 1.2056143283843994\n",
      "Starting Epoch 175\n",
      "1.1497893904646237\n",
      "Validation loss: 1.2044509649276733\n",
      "mse 1.2044509204778713\n",
      "New best model found at epoch 175 with validation loss 1.2044509649276733\n",
      "Starting Epoch 176\n",
      "1.148948758840561\n",
      "Validation loss: 1.204593300819397\n",
      "mse 1.2045931989685574\n",
      "Starting Epoch 177\n",
      "1.1478758081793785\n",
      "Validation loss: 1.203931450843811\n",
      "mse 1.2039313311752953\n",
      "New best model found at epoch 177 with validation loss 1.203931450843811\n",
      "Starting Epoch 178\n",
      "1.1470822741587956\n",
      "Validation loss: 1.2025877237319946\n",
      "mse 1.2025876161227271\n",
      "New best model found at epoch 178 with validation loss 1.2025877237319946\n",
      "Starting Epoch 179\n",
      "1.1458297471205394\n",
      "Validation loss: 1.2028002738952637\n",
      "mse 1.2028001480120742\n",
      "Starting Epoch 180\n",
      "1.144895541171233\n",
      "Validation loss: 1.201989769935608\n",
      "mse 1.2019898157305848\n",
      "New best model found at epoch 180 with validation loss 1.201989769935608\n",
      "Starting Epoch 181\n",
      "1.1439776768287022\n",
      "Validation loss: 1.2016198635101318\n",
      "mse 1.2016198482733589\n",
      "New best model found at epoch 181 with validation loss 1.2016198635101318\n",
      "Starting Epoch 182\n",
      "1.1431389699379604\n",
      "Validation loss: 1.2012367248535156\n",
      "mse 1.201236724427052\n",
      "New best model found at epoch 182 with validation loss 1.2012367248535156\n",
      "Starting Epoch 183\n",
      "1.1421561365326245\n",
      "Validation loss: 1.200161099433899\n",
      "mse 1.2001610897835198\n",
      "New best model found at epoch 183 with validation loss 1.200161099433899\n",
      "Starting Epoch 184\n",
      "1.1412462890148163\n",
      "Validation loss: 1.1998628377914429\n",
      "mse 1.199862838160898\n",
      "New best model found at epoch 184 with validation loss 1.1998628377914429\n",
      "Starting Epoch 185\n",
      "1.1402583594123523\n",
      "Validation loss: 1.1993287801742554\n",
      "mse 1.1993287410504305\n",
      "New best model found at epoch 185 with validation loss 1.1993287801742554\n",
      "Starting Epoch 186\n",
      "1.139492116868496\n",
      "Validation loss: 1.1988602876663208\n",
      "mse 1.1988603734737484\n",
      "New best model found at epoch 186 with validation loss 1.1988602876663208\n",
      "Starting Epoch 187\n",
      "1.1387198095520337\n",
      "Validation loss: 1.1985070705413818\n",
      "mse 1.1985071454056828\n",
      "New best model found at epoch 187 with validation loss 1.1985070705413818\n",
      "Starting Epoch 188\n",
      "1.13776250431935\n",
      "Validation loss: 1.1981089115142822\n",
      "mse 1.1981089096102602\n",
      "New best model found at epoch 188 with validation loss 1.1981089115142822\n",
      "Starting Epoch 189\n",
      "1.1368922243515651\n",
      "Validation loss: 1.1974636316299438\n",
      "mse 1.1974636371160594\n",
      "New best model found at epoch 189 with validation loss 1.1974636316299438\n",
      "Starting Epoch 190\n",
      "1.1360590234398842\n",
      "Validation loss: 1.1962714195251465\n",
      "mse 1.196271486546799\n",
      "New best model found at epoch 190 with validation loss 1.1962714195251465\n",
      "Starting Epoch 191\n",
      "1.135129342476527\n",
      "Validation loss: 1.1961687803268433\n",
      "mse 1.1961688966876356\n",
      "New best model found at epoch 191 with validation loss 1.1961687803268433\n",
      "Starting Epoch 192\n",
      "1.134313163657983\n",
      "Validation loss: 1.1959744691848755\n",
      "mse 1.1959745025717807\n",
      "New best model found at epoch 192 with validation loss 1.1959744691848755\n",
      "Starting Epoch 193\n",
      "1.1334747970104218\n",
      "Validation loss: 1.1952141523361206\n",
      "mse 1.195214104825104\n",
      "New best model found at epoch 193 with validation loss 1.1952141523361206\n",
      "Starting Epoch 194\n",
      "1.1327340031663578\n",
      "Validation loss: 1.1950833797454834\n",
      "mse 1.19508332753529\n",
      "New best model found at epoch 194 with validation loss 1.1950833797454834\n",
      "Starting Epoch 195\n",
      "1.1318535854419072\n",
      "Validation loss: 1.1947593688964844\n",
      "mse 1.1947593472867921\n",
      "New best model found at epoch 195 with validation loss 1.1947593688964844\n",
      "Starting Epoch 196\n",
      "1.1313070083657901\n",
      "Validation loss: 1.193752646446228\n",
      "mse 1.1937527293680394\n",
      "New best model found at epoch 196 with validation loss 1.193752646446228\n",
      "Starting Epoch 197\n",
      "1.1303455779949825\n",
      "Validation loss: 1.1935229301452637\n",
      "mse 1.1935230325949082\n",
      "New best model found at epoch 197 with validation loss 1.1935229301452637\n",
      "Starting Epoch 198\n",
      "1.1295224651694298\n",
      "Validation loss: 1.1926217079162598\n",
      "mse 1.1926217752736081\n",
      "New best model found at epoch 198 with validation loss 1.1926217079162598\n",
      "Starting Epoch 199\n",
      "1.1298181240757306\n",
      "Validation loss: 1.190548062324524\n",
      "mse 1.1905480367219008\n",
      "New best model found at epoch 199 with validation loss 1.190548062324524\n",
      "Starting Epoch 200\n",
      "1.1294310167431831\n",
      "Validation loss: 1.1905314922332764\n",
      "mse 1.1905315140691566\n",
      "New best model found at epoch 200 with validation loss 1.1905314922332764\n",
      "Starting Epoch 201\n",
      "1.1278191457192104\n",
      "Validation loss: 1.1903294324874878\n",
      "mse 1.1903294669590647\n",
      "New best model found at epoch 201 with validation loss 1.1903294324874878\n",
      "Starting Epoch 202\n",
      "1.1268470138311386\n",
      "Validation loss: 1.189745545387268\n",
      "mse 1.189745541761944\n",
      "New best model found at epoch 202 with validation loss 1.189745545387268\n",
      "Starting Epoch 203\n",
      "1.1259913096825283\n",
      "Validation loss: 1.1886664628982544\n",
      "mse 1.1886664427361258\n",
      "New best model found at epoch 203 with validation loss 1.1886664628982544\n",
      "Starting Epoch 204\n",
      "1.1251285473505657\n",
      "Validation loss: 1.1887096166610718\n",
      "mse 1.1887096882644763\n",
      "Starting Epoch 205\n",
      "1.124413366119067\n",
      "Validation loss: 1.1875990629196167\n",
      "mse 1.187599056771662\n",
      "New best model found at epoch 205 with validation loss 1.1875990629196167\n",
      "Starting Epoch 206\n",
      "1.123573660850525\n",
      "Validation loss: 1.1873118877410889\n",
      "mse 1.1873118997915142\n",
      "New best model found at epoch 206 with validation loss 1.1873118877410889\n",
      "Starting Epoch 207\n",
      "1.1227160717050235\n",
      "Validation loss: 1.1866923570632935\n",
      "mse 1.1866923853646643\n",
      "New best model found at epoch 207 with validation loss 1.1866923570632935\n",
      "Starting Epoch 208\n",
      "1.121836689611276\n",
      "Validation loss: 1.1859662532806396\n",
      "mse 1.1859663233569928\n",
      "New best model found at epoch 208 with validation loss 1.1859662532806396\n",
      "Starting Epoch 209\n",
      "1.1211683079600334\n",
      "Validation loss: 1.185380458831787\n",
      "mse 1.185380458825497\n",
      "New best model found at epoch 209 with validation loss 1.185380458831787\n",
      "Starting Epoch 210\n",
      "1.1203942621747653\n",
      "Validation loss: 1.1853135824203491\n",
      "mse 1.1853135454138606\n",
      "New best model found at epoch 210 with validation loss 1.1853135824203491\n",
      "Starting Epoch 211\n",
      "1.1196305826306343\n",
      "Validation loss: 1.1847410202026367\n",
      "mse 1.184740980139465\n",
      "New best model found at epoch 211 with validation loss 1.1847410202026367\n",
      "Starting Epoch 212\n",
      "1.1188719272613525\n",
      "Validation loss: 1.1848634481430054\n",
      "mse 1.1848632810204651\n",
      "Starting Epoch 213\n",
      "1.1182027558485668\n",
      "Validation loss: 1.1837559938430786\n",
      "mse 1.183756045041152\n",
      "New best model found at epoch 213 with validation loss 1.1837559938430786\n",
      "Starting Epoch 214\n",
      "1.1175372501214345\n",
      "Validation loss: 1.1835497617721558\n",
      "mse 1.1835499661213134\n",
      "New best model found at epoch 214 with validation loss 1.1835497617721558\n",
      "Starting Epoch 215\n",
      "1.1166941598057747\n",
      "Validation loss: 1.183500051498413\n",
      "mse 1.1835000587435756\n",
      "New best model found at epoch 215 with validation loss 1.183500051498413\n",
      "Starting Epoch 216\n",
      "1.1160999263326328\n",
      "Validation loss: 1.1832568645477295\n",
      "mse 1.1832570403070286\n",
      "New best model found at epoch 216 with validation loss 1.1832568645477295\n",
      "Starting Epoch 217\n",
      "1.1153718456625938\n",
      "Validation loss: 1.1828545331954956\n",
      "mse 1.1828545394678622\n",
      "New best model found at epoch 217 with validation loss 1.1828545331954956\n",
      "Starting Epoch 218\n",
      "1.1145965283115704\n",
      "Validation loss: 1.182222843170166\n",
      "mse 1.1822227187694843\n",
      "New best model found at epoch 218 with validation loss 1.182222843170166\n",
      "Starting Epoch 219\n",
      "1.1139763221144676\n",
      "Validation loss: 1.181857943534851\n",
      "mse 1.181858062104788\n",
      "New best model found at epoch 219 with validation loss 1.181857943534851\n",
      "Starting Epoch 220\n",
      "1.1132369861006737\n",
      "Validation loss: 1.1818722486495972\n",
      "mse 1.1818723236233066\n",
      "Starting Epoch 221\n",
      "1.112539403140545\n",
      "Validation loss: 1.181649088859558\n",
      "mse 1.1816491299482899\n",
      "New best model found at epoch 221 with validation loss 1.181649088859558\n",
      "Starting Epoch 222\n",
      "1.1113710577289264\n",
      "Validation loss: 1.1815648078918457\n",
      "mse 1.1815646707051577\n",
      "New best model found at epoch 222 with validation loss 1.1815648078918457\n",
      "Starting Epoch 223\n",
      "1.110723537703355\n",
      "Validation loss: 1.1808393001556396\n",
      "mse 1.1808393192520967\n",
      "New best model found at epoch 223 with validation loss 1.1808393001556396\n",
      "Starting Epoch 224\n",
      "1.1099352141221364\n",
      "Validation loss: 1.180675745010376\n",
      "mse 1.1806756485409005\n",
      "New best model found at epoch 224 with validation loss 1.180675745010376\n",
      "Starting Epoch 225\n",
      "1.1092150857051213\n",
      "Validation loss: 1.1799547672271729\n",
      "mse 1.1799547808154933\n",
      "New best model found at epoch 225 with validation loss 1.1799547672271729\n",
      "Starting Epoch 226\n",
      "1.1086479624112446\n",
      "Validation loss: 1.180145025253296\n",
      "mse 1.180145056203723\n",
      "Starting Epoch 227\n",
      "1.1079624071717262\n",
      "Validation loss: 1.1794381141662598\n",
      "mse 1.1794381372139413\n",
      "New best model found at epoch 227 with validation loss 1.1794381141662598\n",
      "Starting Epoch 228\n",
      "1.1073398689428966\n",
      "Validation loss: 1.1789703369140625\n",
      "mse 1.1789703258585014\n",
      "New best model found at epoch 228 with validation loss 1.1789703369140625\n",
      "Starting Epoch 229\n",
      "1.1065480907758076\n",
      "Validation loss: 1.178715467453003\n",
      "mse 1.1787154320099644\n",
      "New best model found at epoch 229 with validation loss 1.178715467453003\n",
      "Starting Epoch 230\n",
      "1.1060094634691875\n",
      "Validation loss: 1.1786048412322998\n",
      "mse 1.1786047992216435\n",
      "New best model found at epoch 230 with validation loss 1.1786048412322998\n",
      "Starting Epoch 231\n",
      "1.1054103896021843\n",
      "Validation loss: 1.1782361268997192\n",
      "mse 1.1782360858951115\n",
      "New best model found at epoch 231 with validation loss 1.1782361268997192\n",
      "Starting Epoch 232\n",
      "1.1047657305995624\n",
      "Validation loss: 1.1777235269546509\n",
      "mse 1.1777236009867766\n",
      "New best model found at epoch 232 with validation loss 1.1777235269546509\n",
      "Starting Epoch 233\n",
      "1.1041096250216167\n",
      "Validation loss: 1.1776862144470215\n",
      "mse 1.1776862462511413\n",
      "New best model found at epoch 233 with validation loss 1.1776862144470215\n",
      "Starting Epoch 234\n",
      "1.1035620446006458\n",
      "Validation loss: 1.177098035812378\n",
      "mse 1.177097819043454\n",
      "New best model found at epoch 234 with validation loss 1.177098035812378\n",
      "Starting Epoch 235\n",
      "1.102906587223212\n",
      "Validation loss: 1.1768467426300049\n",
      "mse 1.1768468706620732\n",
      "New best model found at epoch 235 with validation loss 1.1768467426300049\n",
      "Starting Epoch 236\n",
      "1.102326271434625\n",
      "Validation loss: 1.1766560077667236\n",
      "mse 1.17665606381003\n",
      "New best model found at epoch 236 with validation loss 1.1766560077667236\n",
      "Starting Epoch 237\n",
      "1.101642628510793\n",
      "Validation loss: 1.1759512424468994\n",
      "mse 1.1759512767918225\n",
      "New best model found at epoch 237 with validation loss 1.1759512424468994\n",
      "Starting Epoch 238\n",
      "1.1010884195566177\n",
      "Validation loss: 1.176255702972412\n",
      "mse 1.1762557373561027\n",
      "Starting Epoch 239\n",
      "1.100488230586052\n",
      "Validation loss: 1.1756583452224731\n",
      "mse 1.1756583548987996\n",
      "New best model found at epoch 239 with validation loss 1.1756583452224731\n",
      "Starting Epoch 240\n",
      "1.0998567913969357\n",
      "Validation loss: 1.1755753755569458\n",
      "mse 1.175575373704496\n",
      "New best model found at epoch 240 with validation loss 1.1755753755569458\n",
      "Starting Epoch 241\n",
      "1.0992513969540596\n",
      "Validation loss: 1.174902081489563\n",
      "mse 1.174902141012536\n",
      "New best model found at epoch 241 with validation loss 1.174902081489563\n",
      "Starting Epoch 242\n",
      "1.0986996293067932\n",
      "Validation loss: 1.1743988990783691\n",
      "mse 1.1743988645661043\n",
      "New best model found at epoch 242 with validation loss 1.1743988990783691\n",
      "Starting Epoch 243\n",
      "1.098089372118314\n",
      "Validation loss: 1.17433762550354\n",
      "mse 1.1743377032586597\n",
      "New best model found at epoch 243 with validation loss 1.17433762550354\n",
      "Starting Epoch 244\n",
      "1.0974485551317532\n",
      "Validation loss: 1.173926591873169\n",
      "mse 1.1739265321074033\n",
      "New best model found at epoch 244 with validation loss 1.173926591873169\n",
      "Starting Epoch 245\n",
      "1.096840833624204\n",
      "Validation loss: 1.173877239227295\n",
      "mse 1.173877088401188\n",
      "New best model found at epoch 245 with validation loss 1.173877239227295\n",
      "Starting Epoch 246\n",
      "1.0965165371696155\n",
      "Validation loss: 1.17379891872406\n",
      "mse 1.1737989447175048\n",
      "New best model found at epoch 246 with validation loss 1.17379891872406\n",
      "Starting Epoch 247\n",
      "1.0956501613060634\n",
      "Validation loss: 1.1736294031143188\n",
      "mse 1.1736294494465491\n",
      "New best model found at epoch 247 with validation loss 1.1736294031143188\n",
      "Starting Epoch 248\n",
      "1.0954197719693184\n",
      "Validation loss: 1.1731315851211548\n",
      "mse 1.1731316253907986\n",
      "New best model found at epoch 248 with validation loss 1.1731315851211548\n",
      "Starting Epoch 249\n",
      "1.0946976815660794\n",
      "Validation loss: 1.1730875968933105\n",
      "mse 1.1730875746936333\n",
      "New best model found at epoch 249 with validation loss 1.1730875968933105\n",
      "Starting Epoch 250\n",
      "1.0941995506485303\n",
      "Validation loss: 1.1727421283721924\n",
      "mse 1.1727420771693944\n",
      "New best model found at epoch 250 with validation loss 1.1727421283721924\n",
      "Starting Epoch 251\n",
      "1.0937579224507015\n",
      "Validation loss: 1.172661542892456\n",
      "mse 1.1726616272298036\n",
      "New best model found at epoch 251 with validation loss 1.172661542892456\n",
      "Starting Epoch 252\n",
      "1.0931252017617226\n",
      "Validation loss: 1.1720165014266968\n",
      "mse 1.1720163719752097\n",
      "New best model found at epoch 252 with validation loss 1.1720165014266968\n",
      "Starting Epoch 253\n",
      "1.0924789706865947\n",
      "Validation loss: 1.1715971231460571\n",
      "mse 1.1715971224280008\n",
      "New best model found at epoch 253 with validation loss 1.1715971231460571\n",
      "Starting Epoch 254\n",
      "1.0919307321310043\n",
      "Validation loss: 1.1719423532485962\n",
      "mse 1.171942330145117\n",
      "Starting Epoch 255\n",
      "1.0917699088652928\n",
      "Validation loss: 1.1712498664855957\n",
      "mse 1.1712498518243328\n",
      "New best model found at epoch 255 with validation loss 1.1712498664855957\n",
      "Starting Epoch 256\n",
      "1.0910413588086765\n",
      "Validation loss: 1.1709400415420532\n",
      "mse 1.1709400345070848\n",
      "New best model found at epoch 256 with validation loss 1.1709400415420532\n",
      "Starting Epoch 257\n",
      "1.0905980244278908\n",
      "Validation loss: 1.1706836223602295\n",
      "mse 1.1706835506067272\n",
      "New best model found at epoch 257 with validation loss 1.1706836223602295\n",
      "Starting Epoch 258\n",
      "1.0900365685423214\n",
      "Validation loss: 1.1707878112792969\n",
      "mse 1.1707878014275697\n",
      "Starting Epoch 259\n",
      "1.0895089656114578\n",
      "Validation loss: 1.1707781553268433\n",
      "mse 1.1707780855040368\n",
      "Starting Epoch 260\n",
      "1.0891858264803886\n",
      "Validation loss: 1.170136570930481\n",
      "mse 1.1701365598839542\n",
      "New best model found at epoch 260 with validation loss 1.170136570930481\n",
      "Starting Epoch 261\n",
      "1.088506539662679\n",
      "Validation loss: 1.1697295904159546\n",
      "mse 1.1697295488604909\n",
      "New best model found at epoch 261 with validation loss 1.1697295904159546\n",
      "Starting Epoch 262\n",
      "1.088175465663274\n",
      "Validation loss: 1.1691960096359253\n",
      "mse 1.1691960563476773\n",
      "New best model found at epoch 262 with validation loss 1.1691960096359253\n",
      "Starting Epoch 263\n",
      "1.0875468874971073\n",
      "Validation loss: 1.1692167520523071\n",
      "mse 1.169216810596019\n",
      "Starting Epoch 264\n",
      "1.0871848116318386\n",
      "Validation loss: 1.16964852809906\n",
      "mse 1.1696486011224152\n",
      "Starting Epoch 265\n",
      "1.086685262620449\n",
      "Validation loss: 1.1690417528152466\n",
      "mse 1.1690416714197986\n",
      "New best model found at epoch 265 with validation loss 1.1690417528152466\n",
      "Starting Epoch 266\n",
      "1.0862816274166107\n",
      "Validation loss: 1.1686389446258545\n",
      "mse 1.1686389006102431\n",
      "New best model found at epoch 266 with validation loss 1.1686389446258545\n",
      "Starting Epoch 267\n",
      "1.0857654189070065\n",
      "Validation loss: 1.1681877374649048\n",
      "mse 1.1681876911938935\n",
      "New best model found at epoch 267 with validation loss 1.1681877374649048\n",
      "Starting Epoch 268\n",
      "1.0854601884881656\n",
      "Validation loss: 1.1681149005889893\n",
      "mse 1.1681147910901\n",
      "New best model found at epoch 268 with validation loss 1.1681149005889893\n",
      "Starting Epoch 269\n",
      "1.0849008808533351\n",
      "Validation loss: 1.1681976318359375\n",
      "mse 1.1681976067336775\n",
      "Starting Epoch 270\n",
      "1.0843884696563084\n",
      "Validation loss: 1.167741060256958\n",
      "mse 1.1677410275060989\n",
      "New best model found at epoch 270 with validation loss 1.167741060256958\n",
      "Starting Epoch 271\n",
      "1.0840657701094945\n",
      "Validation loss: 1.1672958135604858\n",
      "mse 1.1672957774000754\n",
      "New best model found at epoch 271 with validation loss 1.1672958135604858\n",
      "Starting Epoch 272\n",
      "1.0835776329040527\n",
      "Validation loss: 1.1672444343566895\n",
      "mse 1.1672445174563424\n",
      "New best model found at epoch 272 with validation loss 1.1672444343566895\n",
      "Starting Epoch 273\n",
      "1.08296071489652\n",
      "Validation loss: 1.1670849323272705\n",
      "mse 1.1670850069827308\n",
      "New best model found at epoch 273 with validation loss 1.1670849323272705\n",
      "Starting Epoch 274\n",
      "1.0826927175124486\n",
      "Validation loss: 1.1673444509506226\n",
      "mse 1.1673445852166882\n",
      "Starting Epoch 275\n",
      "1.0824555108944576\n",
      "Validation loss: 1.1667413711547852\n",
      "mse 1.1667413330260392\n",
      "New best model found at epoch 275 with validation loss 1.1667413711547852\n",
      "Starting Epoch 276\n",
      "1.0818306853373845\n",
      "Validation loss: 1.1664751768112183\n",
      "mse 1.1664750893604041\n",
      "New best model found at epoch 276 with validation loss 1.1664751768112183\n",
      "Starting Epoch 277\n",
      "1.0815187369783719\n",
      "Validation loss: 1.1662791967391968\n",
      "mse 1.166279115218634\n",
      "New best model found at epoch 277 with validation loss 1.1662791967391968\n",
      "Starting Epoch 278\n",
      "1.080985223253568\n",
      "Validation loss: 1.1664388179779053\n",
      "mse 1.1664387470547857\n",
      "Starting Epoch 279\n",
      "1.0807018702228863\n",
      "Validation loss: 1.1661226749420166\n",
      "mse 1.1661226788952745\n",
      "New best model found at epoch 279 with validation loss 1.1661226749420166\n",
      "Starting Epoch 280\n",
      "1.0802825838327408\n",
      "Validation loss: 1.1660834550857544\n",
      "mse 1.1660834745695694\n",
      "New best model found at epoch 280 with validation loss 1.1660834550857544\n",
      "Starting Epoch 281\n",
      "1.079871028661728\n",
      "Validation loss: 1.1658246517181396\n",
      "mse 1.1658245637614533\n",
      "New best model found at epoch 281 with validation loss 1.1658246517181396\n",
      "Starting Epoch 282\n",
      "1.0794926409920056\n",
      "Validation loss: 1.1657825708389282\n",
      "mse 1.165782675610491\n",
      "New best model found at epoch 282 with validation loss 1.1657825708389282\n",
      "Starting Epoch 283\n",
      "1.0790738239884377\n",
      "Validation loss: 1.165360927581787\n",
      "mse 1.165360859541297\n",
      "New best model found at epoch 283 with validation loss 1.165360927581787\n",
      "Starting Epoch 284\n",
      "1.0786782105763753\n",
      "Validation loss: 1.1653990745544434\n",
      "mse 1.1653989760083538\n",
      "Starting Epoch 285\n",
      "1.0781850914160411\n",
      "Validation loss: 1.1648681163787842\n",
      "mse 1.1648681904064395\n",
      "New best model found at epoch 285 with validation loss 1.1648681163787842\n",
      "Starting Epoch 286\n",
      "1.0779353628555934\n",
      "Validation loss: 1.1652151346206665\n",
      "mse 1.1652150060278508\n",
      "Starting Epoch 287\n",
      "1.0776621997356415\n",
      "Validation loss: 1.1647731065750122\n",
      "mse 1.1647730177065052\n",
      "New best model found at epoch 287 with validation loss 1.1647731065750122\n",
      "Starting Epoch 288\n",
      "1.0771171698967617\n",
      "Validation loss: 1.164738416671753\n",
      "mse 1.1647382294390138\n",
      "New best model found at epoch 288 with validation loss 1.164738416671753\n",
      "Starting Epoch 289\n",
      "1.0767614245414734\n",
      "Validation loss: 1.164357304573059\n",
      "mse 1.1643572532420297\n",
      "New best model found at epoch 289 with validation loss 1.164357304573059\n",
      "Starting Epoch 290\n",
      "1.0763823663194974\n",
      "Validation loss: 1.163867473602295\n",
      "mse 1.1638673774290413\n",
      "New best model found at epoch 290 with validation loss 1.163867473602295\n",
      "Starting Epoch 291\n",
      "1.0758771449327469\n",
      "Validation loss: 1.1638802289962769\n",
      "mse 1.163880240031932\n",
      "Starting Epoch 292\n",
      "1.0756991803646088\n",
      "Validation loss: 1.1641852855682373\n",
      "mse 1.1641852499918808\n",
      "Starting Epoch 293\n",
      "1.075229172905286\n",
      "Validation loss: 1.1634113788604736\n",
      "mse 1.1634114401544036\n",
      "New best model found at epoch 293 with validation loss 1.1634113788604736\n",
      "Starting Epoch 294\n",
      "1.074840672314167\n",
      "Validation loss: 1.1633704900741577\n",
      "mse 1.163370511004561\n",
      "New best model found at epoch 294 with validation loss 1.1633704900741577\n",
      "Starting Epoch 295\n",
      "1.0744783903161685\n",
      "Validation loss: 1.1634658575057983\n",
      "mse 1.1634658868936991\n",
      "Starting Epoch 296\n",
      "1.0740783388415973\n",
      "Validation loss: 1.1629608869552612\n",
      "mse 1.1629607437325844\n",
      "New best model found at epoch 296 with validation loss 1.1629608869552612\n",
      "Starting Epoch 297\n",
      "1.0737626353899639\n",
      "Validation loss: 1.1632519960403442\n",
      "mse 1.1632519492036086\n",
      "Starting Epoch 298\n",
      "1.0735304579138756\n",
      "Validation loss: 1.1631897687911987\n",
      "mse 1.163189737413885\n",
      "Starting Epoch 299\n",
      "1.0732687016328175\n",
      "Validation loss: 1.1626451015472412\n",
      "mse 1.1626449847241187\n",
      "New best model found at epoch 299 with validation loss 1.1626451015472412\n",
      "Starting Epoch 300\n",
      "1.0727725798885028\n",
      "Validation loss: 1.1626529693603516\n",
      "mse 1.1626529583658938\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-60-40-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdceb04",
   "metadata": {},
   "source": [
    "##### 4-layers MLP: Version 6\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 20 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "e817cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "b93d3d48-66ed-4ed7-bbaa-32b70f7d8760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.5703761130571365\n",
      "Validation loss: 2.1508822441101074\n",
      "mse 2.150882406645222\n",
      "New best model found at epoch 1 with validation loss 2.1508822441101074\n",
      "Starting Epoch 2\n",
      "2.054278095563253\n",
      "Validation loss: 1.8977900743484497\n",
      "mse 1.8977899918433294\n",
      "New best model found at epoch 2 with validation loss 1.8977900743484497\n",
      "Starting Epoch 3\n",
      "1.9144298036893208\n",
      "Validation loss: 1.7945648431777954\n",
      "mse 1.7945648977168287\n",
      "New best model found at epoch 3 with validation loss 1.7945648431777954\n",
      "Starting Epoch 4\n",
      "1.8374659270048141\n",
      "Validation loss: 1.722249984741211\n",
      "mse 1.7222499980545232\n",
      "New best model found at epoch 4 with validation loss 1.722249984741211\n",
      "Starting Epoch 5\n",
      "1.7799610048532486\n",
      "Validation loss: 1.6689726114273071\n",
      "mse 1.668972519251003\n",
      "New best model found at epoch 5 with validation loss 1.6689726114273071\n",
      "Starting Epoch 6\n",
      "1.7368521591027577\n",
      "Validation loss: 1.6293009519577026\n",
      "mse 1.6293008324746268\n",
      "New best model found at epoch 6 with validation loss 1.6293009519577026\n",
      "Starting Epoch 7\n",
      "1.7010855327049892\n",
      "Validation loss: 1.59697425365448\n",
      "mse 1.5969741415947551\n",
      "New best model found at epoch 7 with validation loss 1.59697425365448\n",
      "Starting Epoch 8\n",
      "1.6713064461946487\n",
      "Validation loss: 1.572806715965271\n",
      "mse 1.5728066845819961\n",
      "New best model found at epoch 8 with validation loss 1.572806715965271\n",
      "Starting Epoch 9\n",
      "1.646625245610873\n",
      "Validation loss: 1.552539348602295\n",
      "mse 1.5525394951854474\n",
      "New best model found at epoch 9 with validation loss 1.552539348602295\n",
      "Starting Epoch 10\n",
      "1.6263861705859501\n",
      "Validation loss: 1.5355886220932007\n",
      "mse 1.5355886411298811\n",
      "New best model found at epoch 10 with validation loss 1.5355886220932007\n",
      "Starting Epoch 11\n",
      "1.6087532391150792\n",
      "Validation loss: 1.5230717658996582\n",
      "mse 1.5230718862300978\n",
      "New best model found at epoch 11 with validation loss 1.5230717658996582\n",
      "Starting Epoch 12\n",
      "1.5939047584931056\n",
      "Validation loss: 1.5088826417922974\n",
      "mse 1.5088826284457975\n",
      "New best model found at epoch 12 with validation loss 1.5088826417922974\n",
      "Starting Epoch 13\n",
      "1.579382653037707\n",
      "Validation loss: 1.4972771406173706\n",
      "mse 1.4972771526964792\n",
      "New best model found at epoch 13 with validation loss 1.4972771406173706\n",
      "Starting Epoch 14\n",
      "1.5673405478398006\n",
      "Validation loss: 1.4882838726043701\n",
      "mse 1.4882838187117584\n",
      "New best model found at epoch 14 with validation loss 1.4882838726043701\n",
      "Starting Epoch 15\n",
      "1.55589526395003\n",
      "Validation loss: 1.478424072265625\n",
      "mse 1.4784240173584855\n",
      "New best model found at epoch 15 with validation loss 1.478424072265625\n",
      "Starting Epoch 16\n",
      "1.5452119658390682\n",
      "Validation loss: 1.4712611436843872\n",
      "mse 1.4712612780599459\n",
      "New best model found at epoch 16 with validation loss 1.4712611436843872\n",
      "Starting Epoch 17\n",
      "1.5356579472621281\n",
      "Validation loss: 1.4647377729415894\n",
      "mse 1.4647377559049846\n",
      "New best model found at epoch 17 with validation loss 1.4647377729415894\n",
      "Starting Epoch 18\n",
      "1.5271399567524593\n",
      "Validation loss: 1.4592301845550537\n",
      "mse 1.4592302555151466\n",
      "New best model found at epoch 18 with validation loss 1.4592301845550537\n",
      "Starting Epoch 19\n",
      "1.5196935137112935\n",
      "Validation loss: 1.4543133974075317\n",
      "mse 1.4543134101380126\n",
      "New best model found at epoch 19 with validation loss 1.4543133974075317\n",
      "Starting Epoch 20\n",
      "1.512344812353452\n",
      "Validation loss: 1.4477945566177368\n",
      "mse 1.4477946013571446\n",
      "New best model found at epoch 20 with validation loss 1.4477945566177368\n",
      "Starting Epoch 21\n",
      "1.5053771088520687\n",
      "Validation loss: 1.4431962966918945\n",
      "mse 1.4431961300736385\n",
      "New best model found at epoch 21 with validation loss 1.4431962966918945\n",
      "Starting Epoch 22\n",
      "1.4989024649063747\n",
      "Validation loss: 1.4378618001937866\n",
      "mse 1.4378616750421238\n",
      "New best model found at epoch 22 with validation loss 1.4378618001937866\n",
      "Starting Epoch 23\n",
      "1.4927521049976349\n",
      "Validation loss: 1.4351004362106323\n",
      "mse 1.4351004443071314\n",
      "New best model found at epoch 23 with validation loss 1.4351004362106323\n",
      "Starting Epoch 24\n",
      "1.486970067024231\n",
      "Validation loss: 1.4301562309265137\n",
      "mse 1.4301560906070905\n",
      "New best model found at epoch 24 with validation loss 1.4301562309265137\n",
      "Starting Epoch 25\n",
      "1.4813547035058339\n",
      "Validation loss: 1.4264577627182007\n",
      "mse 1.42645776634811\n",
      "New best model found at epoch 25 with validation loss 1.4264577627182007\n",
      "Starting Epoch 26\n",
      "1.476175919175148\n",
      "Validation loss: 1.4231258630752563\n",
      "mse 1.423125882937343\n",
      "New best model found at epoch 26 with validation loss 1.4231258630752563\n",
      "Starting Epoch 27\n",
      "1.4712402522563934\n",
      "Validation loss: 1.4199504852294922\n",
      "mse 1.4199505705190778\n",
      "New best model found at epoch 27 with validation loss 1.4199504852294922\n",
      "Starting Epoch 28\n",
      "1.4664201140403748\n",
      "Validation loss: 1.4159280061721802\n",
      "mse 1.4159280141261377\n",
      "New best model found at epoch 28 with validation loss 1.4159280061721802\n",
      "Starting Epoch 29\n",
      "1.4619277467330296\n",
      "Validation loss: 1.4125466346740723\n",
      "mse 1.4125466970018246\n",
      "New best model found at epoch 29 with validation loss 1.4125466346740723\n",
      "Starting Epoch 30\n",
      "1.457335814833641\n",
      "Validation loss: 1.4097734689712524\n",
      "mse 1.4097734699050994\n",
      "New best model found at epoch 30 with validation loss 1.4097734689712524\n",
      "Starting Epoch 31\n",
      "1.4531538238128026\n",
      "Validation loss: 1.406464695930481\n",
      "mse 1.4064645377951919\n",
      "New best model found at epoch 31 with validation loss 1.406464695930481\n",
      "Starting Epoch 32\n",
      "1.4489144285519917\n",
      "Validation loss: 1.4038912057876587\n",
      "mse 1.4038911709685846\n",
      "New best model found at epoch 32 with validation loss 1.4038912057876587\n",
      "Starting Epoch 33\n",
      "1.4449898302555084\n",
      "Validation loss: 1.40018892288208\n",
      "mse 1.4001888586152689\n",
      "New best model found at epoch 33 with validation loss 1.40018892288208\n",
      "Starting Epoch 34\n",
      "1.4410124868154526\n",
      "Validation loss: 1.3974084854125977\n",
      "mse 1.397408402996587\n",
      "New best model found at epoch 34 with validation loss 1.3974084854125977\n",
      "Starting Epoch 35\n",
      "1.437197506427765\n",
      "Validation loss: 1.394568681716919\n",
      "mse 1.3945686803042379\n",
      "New best model found at epoch 35 with validation loss 1.394568681716919\n",
      "Starting Epoch 36\n",
      "1.4333172291517258\n",
      "Validation loss: 1.3916852474212646\n",
      "mse 1.3916852669083304\n",
      "New best model found at epoch 36 with validation loss 1.3916852474212646\n",
      "Starting Epoch 37\n",
      "1.4296714514493942\n",
      "Validation loss: 1.3888238668441772\n",
      "mse 1.388823706315746\n",
      "New best model found at epoch 37 with validation loss 1.3888238668441772\n",
      "Starting Epoch 38\n",
      "1.4260311623414357\n",
      "Validation loss: 1.386087417602539\n",
      "mse 1.386087453884178\n",
      "New best model found at epoch 38 with validation loss 1.386087417602539\n",
      "Starting Epoch 39\n",
      "1.422669346133868\n",
      "Validation loss: 1.3834428787231445\n",
      "mse 1.383442873547441\n",
      "New best model found at epoch 39 with validation loss 1.3834428787231445\n",
      "Starting Epoch 40\n",
      "1.4193759163220723\n",
      "Validation loss: 1.3808190822601318\n",
      "mse 1.380818862415456\n",
      "New best model found at epoch 40 with validation loss 1.3808190822601318\n",
      "Starting Epoch 41\n",
      "1.4159302761157353\n",
      "Validation loss: 1.3781694173812866\n",
      "mse 1.3781694710103016\n",
      "New best model found at epoch 41 with validation loss 1.3781694173812866\n",
      "Starting Epoch 42\n",
      "1.4127792070309322\n",
      "Validation loss: 1.3756725788116455\n",
      "mse 1.3756725818817046\n",
      "New best model found at epoch 42 with validation loss 1.3756725788116455\n",
      "Starting Epoch 43\n",
      "1.4094705482323964\n",
      "Validation loss: 1.373523473739624\n",
      "mse 1.3735234717339742\n",
      "New best model found at epoch 43 with validation loss 1.373523473739624\n",
      "Starting Epoch 44\n",
      "1.4063715090354283\n",
      "Validation loss: 1.3708232641220093\n",
      "mse 1.3708232231974324\n",
      "New best model found at epoch 44 with validation loss 1.3708232641220093\n",
      "Starting Epoch 45\n",
      "1.4029337565104167\n",
      "Validation loss: 1.3682920932769775\n",
      "mse 1.3682921134976875\n",
      "New best model found at epoch 45 with validation loss 1.3682920932769775\n",
      "Starting Epoch 46\n",
      "1.3993398422996204\n",
      "Validation loss: 1.3653864860534668\n",
      "mse 1.3653864972749226\n",
      "New best model found at epoch 46 with validation loss 1.3653864860534668\n",
      "Starting Epoch 47\n",
      "1.3958288778861363\n",
      "Validation loss: 1.3637131452560425\n",
      "mse 1.3637132750023864\n",
      "New best model found at epoch 47 with validation loss 1.3637131452560425\n",
      "Starting Epoch 48\n",
      "1.3927058726549149\n",
      "Validation loss: 1.3608373403549194\n",
      "mse 1.3608374011153197\n",
      "New best model found at epoch 48 with validation loss 1.3608373403549194\n",
      "Starting Epoch 49\n",
      "1.3893893485267956\n",
      "Validation loss: 1.359138011932373\n",
      "mse 1.3591380142713423\n",
      "New best model found at epoch 49 with validation loss 1.359138011932373\n",
      "Starting Epoch 50\n",
      "1.3861370359857876\n",
      "Validation loss: 1.3565394878387451\n",
      "mse 1.3565394756964\n",
      "New best model found at epoch 50 with validation loss 1.3565394878387451\n",
      "Starting Epoch 51\n",
      "1.3829431732495625\n",
      "Validation loss: 1.3540576696395874\n",
      "mse 1.3540577330673014\n",
      "New best model found at epoch 51 with validation loss 1.3540576696395874\n",
      "Starting Epoch 52\n",
      "1.3795944303274155\n",
      "Validation loss: 1.35115385055542\n",
      "mse 1.3511536701471643\n",
      "New best model found at epoch 52 with validation loss 1.35115385055542\n",
      "Starting Epoch 53\n",
      "1.3766756008068721\n",
      "Validation loss: 1.3485585451126099\n",
      "mse 1.3485586999454124\n",
      "New best model found at epoch 53 with validation loss 1.3485585451126099\n",
      "Starting Epoch 54\n",
      "1.3741066331664722\n",
      "Validation loss: 1.3466237783432007\n",
      "mse 1.3466237255283295\n",
      "New best model found at epoch 54 with validation loss 1.3466237783432007\n",
      "Starting Epoch 55\n",
      "1.3713516220450401\n",
      "Validation loss: 1.3446526527404785\n",
      "mse 1.3446525420589486\n",
      "New best model found at epoch 55 with validation loss 1.3446526527404785\n",
      "Starting Epoch 56\n",
      "1.3689471979935963\n",
      "Validation loss: 1.3423964977264404\n",
      "mse 1.3423964781319502\n",
      "New best model found at epoch 56 with validation loss 1.3423964977264404\n",
      "Starting Epoch 57\n",
      "1.366446706155936\n",
      "Validation loss: 1.3398501873016357\n",
      "mse 1.3398503133580026\n",
      "New best model found at epoch 57 with validation loss 1.3398501873016357\n",
      "Starting Epoch 58\n",
      "1.363829178114732\n",
      "Validation loss: 1.3367420434951782\n",
      "mse 1.3367419001117833\n",
      "New best model found at epoch 58 with validation loss 1.3367420434951782\n",
      "Starting Epoch 59\n",
      "1.3611856177449226\n",
      "Validation loss: 1.335062861442566\n",
      "mse 1.3350628338837216\n",
      "New best model found at epoch 59 with validation loss 1.335062861442566\n",
      "Starting Epoch 60\n",
      "1.358078271150589\n",
      "Validation loss: 1.3333650827407837\n",
      "mse 1.3333650151911136\n",
      "New best model found at epoch 60 with validation loss 1.3333650827407837\n",
      "Starting Epoch 61\n",
      "1.3552916819850604\n",
      "Validation loss: 1.3311622142791748\n",
      "mse 1.331162134837307\n",
      "New best model found at epoch 61 with validation loss 1.3311622142791748\n",
      "Starting Epoch 62\n",
      "1.3526231199502945\n",
      "Validation loss: 1.3291155099868774\n",
      "mse 1.3291154400453051\n",
      "New best model found at epoch 62 with validation loss 1.3291155099868774\n",
      "Starting Epoch 63\n",
      "1.3501404747366905\n",
      "Validation loss: 1.3277000188827515\n",
      "mse 1.327700135636819\n",
      "New best model found at epoch 63 with validation loss 1.3277000188827515\n",
      "Starting Epoch 64\n",
      "1.347650667031606\n",
      "Validation loss: 1.3254890441894531\n",
      "mse 1.3254890196905007\n",
      "New best model found at epoch 64 with validation loss 1.3254890441894531\n",
      "Starting Epoch 65\n",
      "1.34542312224706\n",
      "Validation loss: 1.323509931564331\n",
      "mse 1.3235099822030036\n",
      "New best model found at epoch 65 with validation loss 1.323509931564331\n",
      "Starting Epoch 66\n",
      "1.3430802474419277\n",
      "Validation loss: 1.3215439319610596\n",
      "mse 1.3215439615556932\n",
      "New best model found at epoch 66 with validation loss 1.3215439319610596\n",
      "Starting Epoch 67\n",
      "1.3408844297130902\n",
      "Validation loss: 1.3194292783737183\n",
      "mse 1.3194292306224884\n",
      "New best model found at epoch 67 with validation loss 1.3194292783737183\n",
      "Starting Epoch 68\n",
      "1.3386219665408134\n",
      "Validation loss: 1.317739486694336\n",
      "mse 1.3177395230676954\n",
      "New best model found at epoch 68 with validation loss 1.317739486694336\n",
      "Starting Epoch 69\n",
      "1.336465838054816\n",
      "Validation loss: 1.3157403469085693\n",
      "mse 1.3157403487248425\n",
      "New best model found at epoch 69 with validation loss 1.3157403469085693\n",
      "Starting Epoch 70\n",
      "1.3341559320688248\n",
      "Validation loss: 1.31419038772583\n",
      "mse 1.314190475073478\n",
      "New best model found at epoch 70 with validation loss 1.31419038772583\n",
      "Starting Epoch 71\n",
      "1.3320104653636615\n",
      "Validation loss: 1.3122931718826294\n",
      "mse 1.3122931029010902\n",
      "New best model found at epoch 71 with validation loss 1.3122931718826294\n",
      "Starting Epoch 72\n",
      "1.3300453474124272\n",
      "Validation loss: 1.3106825351715088\n",
      "mse 1.3106825973196223\n",
      "New best model found at epoch 72 with validation loss 1.3106825351715088\n",
      "Starting Epoch 73\n",
      "1.3279602527618408\n",
      "Validation loss: 1.3089884519577026\n",
      "mse 1.308988316696814\n",
      "New best model found at epoch 73 with validation loss 1.3089884519577026\n",
      "Starting Epoch 74\n",
      "1.3262262692054112\n",
      "Validation loss: 1.3071379661560059\n",
      "mse 1.30713800694257\n",
      "New best model found at epoch 74 with validation loss 1.3071379661560059\n",
      "Starting Epoch 75\n",
      "1.3241133317351341\n",
      "Validation loss: 1.3052949905395508\n",
      "mse 1.3052949878425786\n",
      "New best model found at epoch 75 with validation loss 1.3052949905395508\n",
      "Starting Epoch 76\n",
      "1.322112853328387\n",
      "Validation loss: 1.3039731979370117\n",
      "mse 1.3039731733798947\n",
      "New best model found at epoch 76 with validation loss 1.3039731979370117\n",
      "Starting Epoch 77\n",
      "1.3202698851625125\n",
      "Validation loss: 1.3022440671920776\n",
      "mse 1.3022440546702652\n",
      "New best model found at epoch 77 with validation loss 1.3022440671920776\n",
      "Starting Epoch 78\n",
      "1.3182920590043068\n",
      "Validation loss: 1.3005387783050537\n",
      "mse 1.3005386472213603\n",
      "New best model found at epoch 78 with validation loss 1.3005387783050537\n",
      "Starting Epoch 79\n",
      "1.3165388802687328\n",
      "Validation loss: 1.2988957166671753\n",
      "mse 1.2988956959125237\n",
      "New best model found at epoch 79 with validation loss 1.2988957166671753\n",
      "Starting Epoch 80\n",
      "1.3146254047751427\n",
      "Validation loss: 1.2977293729782104\n",
      "mse 1.2977295034140905\n",
      "New best model found at epoch 80 with validation loss 1.2977293729782104\n",
      "Starting Epoch 81\n",
      "1.3129722103476524\n",
      "Validation loss: 1.2962126731872559\n",
      "mse 1.2962126161312353\n",
      "New best model found at epoch 81 with validation loss 1.2962126731872559\n",
      "Starting Epoch 82\n",
      "1.3111931184927623\n",
      "Validation loss: 1.2947121858596802\n",
      "mse 1.2947122170106737\n",
      "New best model found at epoch 82 with validation loss 1.2947121858596802\n",
      "Starting Epoch 83\n",
      "1.3094461063543956\n",
      "Validation loss: 1.2933170795440674\n",
      "mse 1.2933169989354714\n",
      "New best model found at epoch 83 with validation loss 1.2933170795440674\n",
      "Starting Epoch 84\n",
      "1.3076791316270828\n",
      "Validation loss: 1.292601466178894\n",
      "mse 1.2926014185632078\n",
      "New best model found at epoch 84 with validation loss 1.292601466178894\n",
      "Starting Epoch 85\n",
      "1.3061087826887767\n",
      "Validation loss: 1.2908916473388672\n",
      "mse 1.2908917374488769\n",
      "New best model found at epoch 85 with validation loss 1.2908916473388672\n",
      "Starting Epoch 86\n",
      "1.3044152806202571\n",
      "Validation loss: 1.2897593975067139\n",
      "mse 1.2897593225090092\n",
      "New best model found at epoch 86 with validation loss 1.2897593975067139\n",
      "Starting Epoch 87\n",
      "1.3028866400321324\n",
      "Validation loss: 1.288045883178711\n",
      "mse 1.2880459648871263\n",
      "New best model found at epoch 87 with validation loss 1.288045883178711\n",
      "Starting Epoch 88\n",
      "1.3010273550947506\n",
      "Validation loss: 1.287066102027893\n",
      "mse 1.2870661073612522\n",
      "New best model found at epoch 88 with validation loss 1.287066102027893\n",
      "Starting Epoch 89\n",
      "1.299410010377566\n",
      "Validation loss: 1.2854329347610474\n",
      "mse 1.285432936933769\n",
      "New best model found at epoch 89 with validation loss 1.2854329347610474\n",
      "Starting Epoch 90\n",
      "1.2979674835999806\n",
      "Validation loss: 1.2843077182769775\n",
      "mse 1.2843078046029317\n",
      "New best model found at epoch 90 with validation loss 1.2843077182769775\n",
      "Starting Epoch 91\n",
      "1.2963967050115268\n",
      "Validation loss: 1.2825325727462769\n",
      "mse 1.282532507029578\n",
      "New best model found at epoch 91 with validation loss 1.2825325727462769\n",
      "Starting Epoch 92\n",
      "1.2947238609194756\n",
      "Validation loss: 1.2818173170089722\n",
      "mse 1.2818173338455532\n",
      "New best model found at epoch 92 with validation loss 1.2818173170089722\n",
      "Starting Epoch 93\n",
      "1.2932999258240063\n",
      "Validation loss: 1.2799803018569946\n",
      "mse 1.2799803270364927\n",
      "New best model found at epoch 93 with validation loss 1.2799803018569946\n",
      "Starting Epoch 94\n",
      "1.2917311266064644\n",
      "Validation loss: 1.279137134552002\n",
      "mse 1.2791372284910991\n",
      "New best model found at epoch 94 with validation loss 1.279137134552002\n",
      "Starting Epoch 95\n",
      "1.290340170264244\n",
      "Validation loss: 1.2777057886123657\n",
      "mse 1.2777057573670478\n",
      "New best model found at epoch 95 with validation loss 1.2777057886123657\n",
      "Starting Epoch 96\n",
      "1.2889416764179866\n",
      "Validation loss: 1.2762463092803955\n",
      "mse 1.276246346490518\n",
      "New best model found at epoch 96 with validation loss 1.2762463092803955\n",
      "Starting Epoch 97\n",
      "1.287380834420522\n",
      "Validation loss: 1.2752095460891724\n",
      "mse 1.275209498338731\n",
      "New best model found at epoch 97 with validation loss 1.2752095460891724\n",
      "Starting Epoch 98\n",
      "1.286013938486576\n",
      "Validation loss: 1.274048924446106\n",
      "mse 1.2740489122105088\n",
      "New best model found at epoch 98 with validation loss 1.274048924446106\n",
      "Starting Epoch 99\n",
      "1.2845911532640457\n",
      "Validation loss: 1.2730522155761719\n",
      "mse 1.2730523058699883\n",
      "New best model found at epoch 99 with validation loss 1.2730522155761719\n",
      "Starting Epoch 100\n",
      "1.283213014403979\n",
      "Validation loss: 1.2719063758850098\n",
      "mse 1.2719063310261538\n",
      "New best model found at epoch 100 with validation loss 1.2719063758850098\n",
      "Starting Epoch 101\n",
      "1.2818677152196567\n",
      "Validation loss: 1.2711000442504883\n",
      "mse 1.271100213762607\n",
      "New best model found at epoch 101 with validation loss 1.2711000442504883\n",
      "Starting Epoch 102\n",
      "1.280645566682021\n",
      "Validation loss: 1.2698500156402588\n",
      "mse 1.2698499603544098\n",
      "New best model found at epoch 102 with validation loss 1.2698500156402588\n",
      "Starting Epoch 103\n",
      "1.2793627257148426\n",
      "Validation loss: 1.2686641216278076\n",
      "mse 1.2686642413834892\n",
      "New best model found at epoch 103 with validation loss 1.2686641216278076\n",
      "Starting Epoch 104\n",
      "1.2778963098923366\n",
      "Validation loss: 1.2678741216659546\n",
      "mse 1.2678741920282657\n",
      "New best model found at epoch 104 with validation loss 1.2678741216659546\n",
      "Starting Epoch 105\n",
      "1.2766295050581296\n",
      "Validation loss: 1.266922950744629\n",
      "mse 1.26692303384623\n",
      "New best model found at epoch 105 with validation loss 1.266922950744629\n",
      "Starting Epoch 106\n",
      "1.2755520765980084\n",
      "Validation loss: 1.2658761739730835\n",
      "mse 1.265876135947613\n",
      "New best model found at epoch 106 with validation loss 1.2658761739730835\n",
      "Starting Epoch 107\n",
      "1.274125727514426\n",
      "Validation loss: 1.2649708986282349\n",
      "mse 1.2649707989493093\n",
      "New best model found at epoch 107 with validation loss 1.2649708986282349\n",
      "Starting Epoch 108\n",
      "1.273013214270274\n",
      "Validation loss: 1.2639681100845337\n",
      "mse 1.2639682126980545\n",
      "New best model found at epoch 108 with validation loss 1.2639681100845337\n",
      "Starting Epoch 109\n",
      "1.271683193743229\n",
      "Validation loss: 1.2633099555969238\n",
      "mse 1.2633100035116798\n",
      "New best model found at epoch 109 with validation loss 1.2633099555969238\n",
      "Starting Epoch 110\n",
      "1.2704672788580258\n",
      "Validation loss: 1.2623980045318604\n",
      "mse 1.2623978625860843\n",
      "New best model found at epoch 110 with validation loss 1.2623980045318604\n",
      "Starting Epoch 111\n",
      "1.269245023528735\n",
      "Validation loss: 1.2611433267593384\n",
      "mse 1.261143160153315\n",
      "New best model found at epoch 111 with validation loss 1.2611433267593384\n",
      "Starting Epoch 112\n",
      "1.2679302071531613\n",
      "Validation loss: 1.261157751083374\n",
      "mse 1.2611577068762352\n",
      "Starting Epoch 113\n",
      "1.2668305163582165\n",
      "Validation loss: 1.2596949338912964\n",
      "mse 1.2596948559677443\n",
      "New best model found at epoch 113 with validation loss 1.2596949338912964\n",
      "Starting Epoch 114\n",
      "1.2656712333361309\n",
      "Validation loss: 1.25948965549469\n",
      "mse 1.2594895402317825\n",
      "New best model found at epoch 114 with validation loss 1.25948965549469\n",
      "Starting Epoch 115\n",
      "1.2643736973404884\n",
      "Validation loss: 1.2588735818862915\n",
      "mse 1.2588735670600468\n",
      "New best model found at epoch 115 with validation loss 1.2588735818862915\n",
      "Starting Epoch 116\n",
      "1.263481726249059\n",
      "Validation loss: 1.258090853691101\n",
      "mse 1.258090789831372\n",
      "New best model found at epoch 116 with validation loss 1.258090853691101\n",
      "Starting Epoch 117\n",
      "1.262341635922591\n",
      "Validation loss: 1.2571133375167847\n",
      "mse 1.2571133454911647\n",
      "New best model found at epoch 117 with validation loss 1.2571133375167847\n",
      "Starting Epoch 118\n",
      "1.261083759367466\n",
      "Validation loss: 1.2560656070709229\n",
      "mse 1.2560657073976969\n",
      "New best model found at epoch 118 with validation loss 1.2560656070709229\n",
      "Starting Epoch 119\n",
      "1.2600697974363964\n",
      "Validation loss: 1.2557116746902466\n",
      "mse 1.2557116835719961\n",
      "New best model found at epoch 119 with validation loss 1.2557116746902466\n",
      "Starting Epoch 120\n",
      "1.2590017020702362\n",
      "Validation loss: 1.2547152042388916\n",
      "mse 1.254715193632262\n",
      "New best model found at epoch 120 with validation loss 1.2547152042388916\n",
      "Starting Epoch 121\n",
      "1.257920888562997\n",
      "Validation loss: 1.2539218664169312\n",
      "mse 1.2539220362013968\n",
      "New best model found at epoch 121 with validation loss 1.2539218664169312\n",
      "Starting Epoch 122\n",
      "1.256845439473788\n",
      "Validation loss: 1.2530312538146973\n",
      "mse 1.2530311744583624\n",
      "New best model found at epoch 122 with validation loss 1.2530312538146973\n",
      "Starting Epoch 123\n",
      "1.2559481014808018\n",
      "Validation loss: 1.2521545886993408\n",
      "mse 1.2521545576460968\n",
      "New best model found at epoch 123 with validation loss 1.2521545886993408\n",
      "Starting Epoch 124\n",
      "1.254908447464307\n",
      "Validation loss: 1.2516311407089233\n",
      "mse 1.2516311811736263\n",
      "New best model found at epoch 124 with validation loss 1.2516311407089233\n",
      "Starting Epoch 125\n",
      "1.2537509029110272\n",
      "Validation loss: 1.2502199411392212\n",
      "mse 1.2502200001749744\n",
      "New best model found at epoch 125 with validation loss 1.2502199411392212\n",
      "Starting Epoch 126\n",
      "1.2527706027030945\n",
      "Validation loss: 1.2495241165161133\n",
      "mse 1.2495241368424206\n",
      "New best model found at epoch 126 with validation loss 1.2495241165161133\n",
      "Starting Epoch 127\n",
      "1.2516861483454704\n",
      "Validation loss: 1.2490733861923218\n",
      "mse 1.2490735423233066\n",
      "New best model found at epoch 127 with validation loss 1.2490733861923218\n",
      "Starting Epoch 128\n",
      "1.250700203080972\n",
      "Validation loss: 1.2479310035705566\n",
      "mse 1.2479309777185525\n",
      "New best model found at epoch 128 with validation loss 1.2479310035705566\n",
      "Starting Epoch 129\n",
      "1.2495446080962818\n",
      "Validation loss: 1.2473257780075073\n",
      "mse 1.2473259799823038\n",
      "New best model found at epoch 129 with validation loss 1.2473257780075073\n",
      "Starting Epoch 130\n",
      "1.2486949513355892\n",
      "Validation loss: 1.246722936630249\n",
      "mse 1.2467229901745704\n",
      "New best model found at epoch 130 with validation loss 1.246722936630249\n",
      "Starting Epoch 131\n",
      "1.2475739692648251\n",
      "Validation loss: 1.24570894241333\n",
      "mse 1.245708852647961\n",
      "New best model found at epoch 131 with validation loss 1.24570894241333\n",
      "Starting Epoch 132\n",
      "1.246589702864488\n",
      "Validation loss: 1.2448091506958008\n",
      "mse 1.244809053914381\n",
      "New best model found at epoch 132 with validation loss 1.2448091506958008\n",
      "Starting Epoch 133\n",
      "1.2454983020822208\n",
      "Validation loss: 1.2442008256912231\n",
      "mse 1.2442008715134352\n",
      "New best model found at epoch 133 with validation loss 1.2442008256912231\n",
      "Starting Epoch 134\n",
      "1.2445173760255177\n",
      "Validation loss: 1.2435168027877808\n",
      "mse 1.2435166907382045\n",
      "New best model found at epoch 134 with validation loss 1.2435168027877808\n",
      "Starting Epoch 135\n",
      "1.2435982748866081\n",
      "Validation loss: 1.2424370050430298\n",
      "mse 1.2424371158534793\n",
      "New best model found at epoch 135 with validation loss 1.2424370050430298\n",
      "Starting Epoch 136\n",
      "1.242585450410843\n",
      "Validation loss: 1.2419484853744507\n",
      "mse 1.2419484135595125\n",
      "New best model found at epoch 136 with validation loss 1.2419484853744507\n",
      "Starting Epoch 137\n",
      "1.2416536286473274\n",
      "Validation loss: 1.2406387329101562\n",
      "mse 1.2406385151100208\n",
      "New best model found at epoch 137 with validation loss 1.2406387329101562\n",
      "Starting Epoch 138\n",
      "1.2406035736203194\n",
      "Validation loss: 1.2404567003250122\n",
      "mse 1.2404566909451689\n",
      "New best model found at epoch 138 with validation loss 1.2404567003250122\n",
      "Starting Epoch 139\n",
      "1.2396765425801277\n",
      "Validation loss: 1.2400449514389038\n",
      "mse 1.2400449963192348\n",
      "New best model found at epoch 139 with validation loss 1.2400449514389038\n",
      "Starting Epoch 140\n",
      "1.2387832428018253\n",
      "Validation loss: 1.2389479875564575\n",
      "mse 1.2389480282611893\n",
      "New best model found at epoch 140 with validation loss 1.2389479875564575\n",
      "Starting Epoch 141\n",
      "1.2378382707635562\n",
      "Validation loss: 1.238434076309204\n",
      "mse 1.2384340660867432\n",
      "New best model found at epoch 141 with validation loss 1.238434076309204\n",
      "Starting Epoch 142\n",
      "1.2368709569176037\n",
      "Validation loss: 1.2374926805496216\n",
      "mse 1.2374926828077624\n",
      "New best model found at epoch 142 with validation loss 1.2374926805496216\n",
      "Starting Epoch 143\n",
      "1.2360747456550598\n",
      "Validation loss: 1.2368788719177246\n",
      "mse 1.2368790144601702\n",
      "New best model found at epoch 143 with validation loss 1.2368788719177246\n",
      "Starting Epoch 144\n",
      "1.2350087662537892\n",
      "Validation loss: 1.235994577407837\n",
      "mse 1.235994640146842\n",
      "New best model found at epoch 144 with validation loss 1.235994577407837\n",
      "Starting Epoch 145\n",
      "1.2342091128230095\n",
      "Validation loss: 1.2356756925582886\n",
      "mse 1.235675669861846\n",
      "New best model found at epoch 145 with validation loss 1.2356756925582886\n",
      "Starting Epoch 146\n",
      "1.2332959473133087\n",
      "Validation loss: 1.2347147464752197\n",
      "mse 1.2347147649482189\n",
      "New best model found at epoch 146 with validation loss 1.2347147464752197\n",
      "Starting Epoch 147\n",
      "1.2326223626732826\n",
      "Validation loss: 1.2344191074371338\n",
      "mse 1.2344192093475566\n",
      "New best model found at epoch 147 with validation loss 1.2344191074371338\n",
      "Starting Epoch 148\n",
      "1.2315080513556798\n",
      "Validation loss: 1.233419418334961\n",
      "mse 1.2334193855417959\n",
      "New best model found at epoch 148 with validation loss 1.233419418334961\n",
      "Starting Epoch 149\n",
      "1.2308193842569988\n",
      "Validation loss: 1.2328341007232666\n",
      "mse 1.232834062775726\n",
      "New best model found at epoch 149 with validation loss 1.2328341007232666\n",
      "Starting Epoch 150\n",
      "1.2298361013333003\n",
      "Validation loss: 1.2319213151931763\n",
      "mse 1.2319212379527018\n",
      "New best model found at epoch 150 with validation loss 1.2319213151931763\n",
      "Starting Epoch 151\n",
      "1.2291597748796146\n",
      "Validation loss: 1.2317094802856445\n",
      "mse 1.231709559072077\n",
      "New best model found at epoch 151 with validation loss 1.2317094802856445\n",
      "Starting Epoch 152\n",
      "1.228271481891473\n",
      "Validation loss: 1.230812907218933\n",
      "mse 1.2308129430282988\n",
      "New best model found at epoch 152 with validation loss 1.230812907218933\n",
      "Starting Epoch 153\n",
      "1.2274207348624866\n",
      "Validation loss: 1.230395793914795\n",
      "mse 1.230395901213366\n",
      "New best model found at epoch 153 with validation loss 1.230395793914795\n",
      "Starting Epoch 154\n",
      "1.2265387152632077\n",
      "Validation loss: 1.229650855064392\n",
      "mse 1.2296509169917258\n",
      "New best model found at epoch 154 with validation loss 1.229650855064392\n",
      "Starting Epoch 155\n",
      "1.2257836138208706\n",
      "Validation loss: 1.2298333644866943\n",
      "mse 1.229833365131831\n",
      "Starting Epoch 156\n",
      "1.2247653603553772\n",
      "Validation loss: 1.2284698486328125\n",
      "mse 1.2284699861004518\n",
      "New best model found at epoch 156 with validation loss 1.2284698486328125\n",
      "Starting Epoch 157\n",
      "1.2234373862544696\n",
      "Validation loss: 1.2279640436172485\n",
      "mse 1.2279638922093878\n",
      "New best model found at epoch 157 with validation loss 1.2279640436172485\n",
      "Starting Epoch 158\n",
      "1.2216768885652225\n",
      "Validation loss: 1.2279242277145386\n",
      "mse 1.2279242250617706\n",
      "New best model found at epoch 158 with validation loss 1.2279242277145386\n",
      "Starting Epoch 159\n",
      "1.2198024168610573\n",
      "Validation loss: 1.228647232055664\n",
      "mse 1.2286472589238824\n",
      "Starting Epoch 160\n",
      "1.2180647030472755\n",
      "Validation loss: 1.2288199663162231\n",
      "mse 1.2288199981496162\n",
      "Starting Epoch 161\n",
      "1.2165635426839192\n",
      "Validation loss: 1.2281726598739624\n",
      "mse 1.228172686865153\n",
      "Starting Epoch 162\n",
      "1.2151005292932193\n",
      "Validation loss: 1.2277069091796875\n",
      "mse 1.2277069146434894\n",
      "New best model found at epoch 162 with validation loss 1.2277069091796875\n",
      "Starting Epoch 163\n",
      "1.2143883183598518\n",
      "Validation loss: 1.2273755073547363\n",
      "mse 1.2273755083555973\n",
      "New best model found at epoch 163 with validation loss 1.2273755073547363\n",
      "Starting Epoch 164\n",
      "1.2131743704279263\n",
      "Validation loss: 1.226448655128479\n",
      "mse 1.2264486377556552\n",
      "New best model found at epoch 164 with validation loss 1.226448655128479\n",
      "Starting Epoch 165\n",
      "1.2123040134708087\n",
      "Validation loss: 1.2261265516281128\n",
      "mse 1.2261265365848746\n",
      "New best model found at epoch 165 with validation loss 1.2261265516281128\n",
      "Starting Epoch 166\n",
      "1.2113029087583225\n",
      "Validation loss: 1.2251992225646973\n",
      "mse 1.2251992385080164\n",
      "New best model found at epoch 166 with validation loss 1.2251992225646973\n",
      "Starting Epoch 167\n",
      "1.2104276319344838\n",
      "Validation loss: 1.2246663570404053\n",
      "mse 1.2246663722068303\n",
      "New best model found at epoch 167 with validation loss 1.2246663570404053\n",
      "Starting Epoch 168\n",
      "1.2094196553031604\n",
      "Validation loss: 1.2241889238357544\n",
      "mse 1.2241889968922997\n",
      "New best model found at epoch 168 with validation loss 1.2241889238357544\n",
      "Starting Epoch 169\n",
      "1.208606633047263\n",
      "Validation loss: 1.2237950563430786\n",
      "mse 1.2237950066738932\n",
      "New best model found at epoch 169 with validation loss 1.2237950563430786\n",
      "Starting Epoch 170\n",
      "1.2076661214232445\n",
      "Validation loss: 1.2229676246643066\n",
      "mse 1.2229676465330106\n",
      "New best model found at epoch 170 with validation loss 1.2229676246643066\n",
      "Starting Epoch 171\n",
      "1.2068322027722995\n",
      "Validation loss: 1.222533941268921\n",
      "mse 1.222533947525972\n",
      "New best model found at epoch 171 with validation loss 1.222533941268921\n",
      "Starting Epoch 172\n",
      "1.2058453112840652\n",
      "Validation loss: 1.222198247909546\n",
      "mse 1.2221982709632753\n",
      "New best model found at epoch 172 with validation loss 1.222198247909546\n",
      "Starting Epoch 173\n",
      "1.2050739924112956\n",
      "Validation loss: 1.2219098806381226\n",
      "mse 1.2219099489486624\n",
      "New best model found at epoch 173 with validation loss 1.2219098806381226\n",
      "Starting Epoch 174\n",
      "1.204151061673959\n",
      "Validation loss: 1.2206367254257202\n",
      "mse 1.2206367358912373\n",
      "New best model found at epoch 174 with validation loss 1.2206367254257202\n",
      "Starting Epoch 175\n",
      "1.2032843455672264\n",
      "Validation loss: 1.2204842567443848\n",
      "mse 1.2204843001305057\n",
      "New best model found at epoch 175 with validation loss 1.2204842567443848\n",
      "Starting Epoch 176\n",
      "1.2025218630830448\n",
      "Validation loss: 1.2199969291687012\n",
      "mse 1.2199968061661461\n",
      "New best model found at epoch 176 with validation loss 1.2199969291687012\n",
      "Starting Epoch 177\n",
      "1.2016019001603127\n",
      "Validation loss: 1.2191914319992065\n",
      "mse 1.2191914084644557\n",
      "New best model found at epoch 177 with validation loss 1.2191914319992065\n",
      "Starting Epoch 178\n",
      "1.2006886849800746\n",
      "Validation loss: 1.218863606452942\n",
      "mse 1.2188635507008838\n",
      "New best model found at epoch 178 with validation loss 1.218863606452942\n",
      "Starting Epoch 179\n",
      "1.1999701857566833\n",
      "Validation loss: 1.2189205884933472\n",
      "mse 1.218920625760699\n",
      "Starting Epoch 180\n",
      "1.199084110558033\n",
      "Validation loss: 1.2182300090789795\n",
      "mse 1.218229984947476\n",
      "New best model found at epoch 180 with validation loss 1.2182300090789795\n",
      "Starting Epoch 181\n",
      "1.198463000357151\n",
      "Validation loss: 1.217822790145874\n",
      "mse 1.2178228118844872\n",
      "New best model found at epoch 181 with validation loss 1.217822790145874\n",
      "Starting Epoch 182\n",
      "1.197271928191185\n",
      "Validation loss: 1.2173441648483276\n",
      "mse 1.2173442128287626\n",
      "New best model found at epoch 182 with validation loss 1.2173441648483276\n",
      "Starting Epoch 183\n",
      "1.1968392804265022\n",
      "Validation loss: 1.2167001962661743\n",
      "mse 1.2167002508183276\n",
      "New best model found at epoch 183 with validation loss 1.2167001962661743\n",
      "Starting Epoch 184\n",
      "1.1958988159894943\n",
      "Validation loss: 1.2165870666503906\n",
      "mse 1.2165871007955424\n",
      "New best model found at epoch 184 with validation loss 1.2165870666503906\n",
      "Starting Epoch 185\n",
      "1.1951578557491302\n",
      "Validation loss: 1.2163372039794922\n",
      "mse 1.2163373487522702\n",
      "New best model found at epoch 185 with validation loss 1.2163372039794922\n",
      "Starting Epoch 186\n",
      "1.1943497732281685\n",
      "Validation loss: 1.2158797979354858\n",
      "mse 1.2158796960346518\n",
      "New best model found at epoch 186 with validation loss 1.2158797979354858\n",
      "Starting Epoch 187\n",
      "1.1934424142042797\n",
      "Validation loss: 1.2156541347503662\n",
      "mse 1.21565403529957\n",
      "New best model found at epoch 187 with validation loss 1.2156541347503662\n",
      "Starting Epoch 188\n",
      "1.1928819591800373\n",
      "Validation loss: 1.2147936820983887\n",
      "mse 1.2147935935543617\n",
      "New best model found at epoch 188 with validation loss 1.2147936820983887\n",
      "Starting Epoch 189\n",
      "1.1919000496466954\n",
      "Validation loss: 1.21444571018219\n",
      "mse 1.2144455099480704\n",
      "New best model found at epoch 189 with validation loss 1.21444571018219\n",
      "Starting Epoch 190\n",
      "1.1913417503237724\n",
      "Validation loss: 1.2144187688827515\n",
      "mse 1.2144187705912066\n",
      "New best model found at epoch 190 with validation loss 1.2144187688827515\n",
      "Starting Epoch 191\n",
      "1.1903805161515872\n",
      "Validation loss: 1.213388442993164\n",
      "mse 1.213388441744089\n",
      "New best model found at epoch 191 with validation loss 1.213388442993164\n",
      "Starting Epoch 192\n",
      "1.189745619893074\n",
      "Validation loss: 1.2132611274719238\n",
      "mse 1.2132610580847256\n",
      "New best model found at epoch 192 with validation loss 1.2132611274719238\n",
      "Starting Epoch 193\n",
      "1.1889547581473987\n",
      "Validation loss: 1.2131251096725464\n",
      "mse 1.2131249805096906\n",
      "New best model found at epoch 193 with validation loss 1.2131251096725464\n",
      "Starting Epoch 194\n",
      "1.1880899916092555\n",
      "Validation loss: 1.2126154899597168\n",
      "mse 1.2126154096180615\n",
      "New best model found at epoch 194 with validation loss 1.2126154899597168\n",
      "Starting Epoch 195\n",
      "1.1874255686998367\n",
      "Validation loss: 1.2121155261993408\n",
      "mse 1.2121155100137233\n",
      "New best model found at epoch 195 with validation loss 1.2121155261993408\n",
      "Starting Epoch 196\n",
      "1.186739794909954\n",
      "Validation loss: 1.212197184562683\n",
      "mse 1.2121972310543496\n",
      "Starting Epoch 197\n",
      "1.1858611827095349\n",
      "Validation loss: 1.211816668510437\n",
      "mse 1.2118167423108805\n",
      "New best model found at epoch 197 with validation loss 1.211816668510437\n",
      "Starting Epoch 198\n",
      "1.185242069264253\n",
      "Validation loss: 1.2107884883880615\n",
      "mse 1.2107884739602934\n",
      "New best model found at epoch 198 with validation loss 1.2107884883880615\n",
      "Starting Epoch 199\n",
      "1.1844495485226314\n",
      "Validation loss: 1.2110668420791626\n",
      "mse 1.2110668329170748\n",
      "Starting Epoch 200\n",
      "1.1836044788360596\n",
      "Validation loss: 1.2102503776550293\n",
      "mse 1.2102504173058093\n",
      "New best model found at epoch 200 with validation loss 1.2102503776550293\n",
      "Starting Epoch 201\n",
      "1.183003808061282\n",
      "Validation loss: 1.210000991821289\n",
      "mse 1.2100008132149538\n",
      "New best model found at epoch 201 with validation loss 1.210000991821289\n",
      "Starting Epoch 202\n",
      "1.1822561050454776\n",
      "Validation loss: 1.2099748849868774\n",
      "mse 1.2099749183241317\n",
      "New best model found at epoch 202 with validation loss 1.2099748849868774\n",
      "Starting Epoch 203\n",
      "1.1814794465899467\n",
      "Validation loss: 1.2093807458877563\n",
      "mse 1.2093808231707222\n",
      "New best model found at epoch 203 with validation loss 1.2093807458877563\n",
      "Starting Epoch 204\n",
      "1.1807980040709178\n",
      "Validation loss: 1.2088075876235962\n",
      "mse 1.2088075863539247\n",
      "New best model found at epoch 204 with validation loss 1.2088075876235962\n",
      "Starting Epoch 205\n",
      "1.1800944432616234\n",
      "Validation loss: 1.2083967924118042\n",
      "mse 1.208396860657325\n",
      "New best model found at epoch 205 with validation loss 1.2083967924118042\n",
      "Starting Epoch 206\n",
      "1.1792301883300145\n",
      "Validation loss: 1.2085822820663452\n",
      "mse 1.208582236477827\n",
      "Starting Epoch 207\n",
      "1.1786897381146748\n",
      "Validation loss: 1.2078908681869507\n",
      "mse 1.2078908418602043\n",
      "New best model found at epoch 207 with validation loss 1.2078908681869507\n",
      "Starting Epoch 208\n",
      "1.1780219400922458\n",
      "Validation loss: 1.2074497938156128\n",
      "mse 1.2074498421960953\n",
      "New best model found at epoch 208 with validation loss 1.2074497938156128\n",
      "Starting Epoch 209\n",
      "1.1773305634657543\n",
      "Validation loss: 1.2066307067871094\n",
      "mse 1.2066306098434494\n",
      "New best model found at epoch 209 with validation loss 1.2066307067871094\n",
      "Starting Epoch 210\n",
      "1.1765033304691315\n",
      "Validation loss: 1.2070810794830322\n",
      "mse 1.2070810055724681\n",
      "Starting Epoch 211\n",
      "1.1758881906668346\n",
      "Validation loss: 1.2063400745391846\n",
      "mse 1.2063400061931902\n",
      "New best model found at epoch 211 with validation loss 1.2063400745391846\n",
      "Starting Epoch 212\n",
      "1.1752669960260391\n",
      "Validation loss: 1.2057348489761353\n",
      "mse 1.205734763892283\n",
      "New best model found at epoch 212 with validation loss 1.2057348489761353\n",
      "Starting Epoch 213\n",
      "1.1745244984825451\n",
      "Validation loss: 1.2053793668746948\n",
      "mse 1.2053792681964333\n",
      "New best model found at epoch 213 with validation loss 1.2053793668746948\n",
      "Starting Epoch 214\n",
      "1.1738863810896873\n",
      "Validation loss: 1.2052617073059082\n",
      "mse 1.2052616749495595\n",
      "New best model found at epoch 214 with validation loss 1.2052617073059082\n",
      "Starting Epoch 215\n",
      "1.1731193711360295\n",
      "Validation loss: 1.2047642469406128\n",
      "mse 1.2047643030165525\n",
      "New best model found at epoch 215 with validation loss 1.2047642469406128\n",
      "Starting Epoch 216\n",
      "1.1723891869187355\n",
      "Validation loss: 1.2041963338851929\n",
      "mse 1.2041963314276733\n",
      "New best model found at epoch 216 with validation loss 1.2041963338851929\n",
      "Starting Epoch 217\n",
      "1.1718813280264537\n",
      "Validation loss: 1.2043514251708984\n",
      "mse 1.2043514423371637\n",
      "Starting Epoch 218\n",
      "1.1711324950059254\n",
      "Validation loss: 1.203892707824707\n",
      "mse 1.2038926652438096\n",
      "New best model found at epoch 218 with validation loss 1.203892707824707\n",
      "Starting Epoch 219\n",
      "1.1704755425453186\n",
      "Validation loss: 1.2033120393753052\n",
      "mse 1.2033120447467984\n",
      "New best model found at epoch 219 with validation loss 1.2033120393753052\n",
      "Starting Epoch 220\n",
      "1.1699079126119614\n",
      "Validation loss: 1.2033536434173584\n",
      "mse 1.203353677014357\n",
      "Starting Epoch 221\n",
      "1.1691685194770496\n",
      "Validation loss: 1.2027993202209473\n",
      "mse 1.2027993522658267\n",
      "New best model found at epoch 221 with validation loss 1.2027993202209473\n",
      "Starting Epoch 222\n",
      "1.1685662244757016\n",
      "Validation loss: 1.2020879983901978\n",
      "mse 1.202087975897611\n",
      "New best model found at epoch 222 with validation loss 1.2020879983901978\n",
      "Starting Epoch 223\n",
      "1.1679644882678986\n",
      "Validation loss: 1.2024153470993042\n",
      "mse 1.202415354457626\n",
      "Starting Epoch 224\n",
      "1.167204591135184\n",
      "Validation loss: 1.2018585205078125\n",
      "mse 1.2018585401527633\n",
      "New best model found at epoch 224 with validation loss 1.2018585205078125\n",
      "Starting Epoch 225\n",
      "1.1666496793429058\n",
      "Validation loss: 1.2014164924621582\n",
      "mse 1.2014164969127834\n",
      "New best model found at epoch 225 with validation loss 1.2014164924621582\n",
      "Starting Epoch 226\n",
      "1.166036568582058\n",
      "Validation loss: 1.2018944025039673\n",
      "mse 1.2018944032903938\n",
      "Starting Epoch 227\n",
      "1.1654075309634209\n",
      "Validation loss: 1.2012394666671753\n",
      "mse 1.2012393060408264\n",
      "New best model found at epoch 227 with validation loss 1.2012394666671753\n",
      "Starting Epoch 228\n",
      "1.1647830680012703\n",
      "Validation loss: 1.200627326965332\n",
      "mse 1.2006274130276584\n",
      "New best model found at epoch 228 with validation loss 1.200627326965332\n",
      "Starting Epoch 229\n",
      "1.1641183669368427\n",
      "Validation loss: 1.2015132904052734\n",
      "mse 1.20151326738864\n",
      "Starting Epoch 230\n",
      "1.163476159175237\n",
      "Validation loss: 1.2013163566589355\n",
      "mse 1.2013164183396743\n",
      "Starting Epoch 231\n",
      "1.1628887603680294\n",
      "Validation loss: 1.2012102603912354\n",
      "mse 1.201210343847355\n",
      "Starting Epoch 232\n",
      "1.1622855365276337\n",
      "Validation loss: 1.200427532196045\n",
      "mse 1.20042760536522\n",
      "New best model found at epoch 232 with validation loss 1.200427532196045\n",
      "Starting Epoch 233\n",
      "1.1616362209121387\n",
      "Validation loss: 1.2008476257324219\n",
      "mse 1.2008475916479944\n",
      "Starting Epoch 234\n",
      "1.1610220149159431\n",
      "Validation loss: 1.2007569074630737\n",
      "mse 1.2007568445331664\n",
      "Starting Epoch 235\n",
      "1.1604391659299533\n",
      "Validation loss: 1.1999963521957397\n",
      "mse 1.1999963832920286\n",
      "New best model found at epoch 235 with validation loss 1.1999963521957397\n",
      "Starting Epoch 236\n",
      "1.1598730583985646\n",
      "Validation loss: 1.1997836828231812\n",
      "mse 1.1997835910548451\n",
      "New best model found at epoch 236 with validation loss 1.1997836828231812\n",
      "Starting Epoch 237\n",
      "1.1590948353211086\n",
      "Validation loss: 1.1998789310455322\n",
      "mse 1.1998788792898074\n",
      "Starting Epoch 238\n",
      "1.1586745927731197\n",
      "Validation loss: 1.1992377042770386\n",
      "mse 1.1992375905723032\n",
      "New best model found at epoch 238 with validation loss 1.1992377042770386\n",
      "Starting Epoch 239\n",
      "1.157995693385601\n",
      "Validation loss: 1.1990628242492676\n",
      "mse 1.199062925129742\n",
      "New best model found at epoch 239 with validation loss 1.1990628242492676\n",
      "Starting Epoch 240\n",
      "1.1574084361394246\n",
      "Validation loss: 1.1985411643981934\n",
      "mse 1.1985411343216883\n",
      "New best model found at epoch 240 with validation loss 1.1985411643981934\n",
      "Starting Epoch 241\n",
      "1.1569291303555171\n",
      "Validation loss: 1.1989624500274658\n",
      "mse 1.1989623429695024\n",
      "Starting Epoch 242\n",
      "1.1562407289942105\n",
      "Validation loss: 1.1984443664550781\n",
      "mse 1.1984444655160111\n",
      "New best model found at epoch 242 with validation loss 1.1984443664550781\n",
      "Starting Epoch 243\n",
      "1.15565624833107\n",
      "Validation loss: 1.1977980136871338\n",
      "mse 1.1977981453803164\n",
      "New best model found at epoch 243 with validation loss 1.1977980136871338\n",
      "Starting Epoch 244\n",
      "1.1551348517338436\n",
      "Validation loss: 1.197553038597107\n",
      "mse 1.1975531027174662\n",
      "New best model found at epoch 244 with validation loss 1.197553038597107\n",
      "Starting Epoch 245\n",
      "1.154575193921725\n",
      "Validation loss: 1.1972883939743042\n",
      "mse 1.1972884718493302\n",
      "New best model found at epoch 245 with validation loss 1.1972883939743042\n",
      "Starting Epoch 246\n",
      "1.153912713130315\n",
      "Validation loss: 1.1968586444854736\n",
      "mse 1.1968585516630175\n",
      "New best model found at epoch 246 with validation loss 1.1968586444854736\n",
      "Starting Epoch 247\n",
      "1.1533813029527664\n",
      "Validation loss: 1.1966235637664795\n",
      "mse 1.196623633196653\n",
      "New best model found at epoch 247 with validation loss 1.1966235637664795\n",
      "Starting Epoch 248\n",
      "1.1527916143337886\n",
      "Validation loss: 1.196326732635498\n",
      "mse 1.1963267150468941\n",
      "New best model found at epoch 248 with validation loss 1.196326732635498\n",
      "Starting Epoch 249\n",
      "1.1522294307748477\n",
      "Validation loss: 1.1960809230804443\n",
      "mse 1.196081088730413\n",
      "New best model found at epoch 249 with validation loss 1.1960809230804443\n",
      "Starting Epoch 250\n",
      "1.1516348694761593\n",
      "Validation loss: 1.195926547050476\n",
      "mse 1.1959264959843732\n",
      "New best model found at epoch 250 with validation loss 1.195926547050476\n",
      "Starting Epoch 251\n",
      "1.1511251678069432\n",
      "Validation loss: 1.1955125331878662\n",
      "mse 1.1955124810375606\n",
      "New best model found at epoch 251 with validation loss 1.1955125331878662\n",
      "Starting Epoch 252\n",
      "1.1505064566930134\n",
      "Validation loss: 1.1953788995742798\n",
      "mse 1.195378916840328\n",
      "New best model found at epoch 252 with validation loss 1.1953788995742798\n",
      "Starting Epoch 253\n",
      "1.1499245017766953\n",
      "Validation loss: 1.1951751708984375\n",
      "mse 1.1951753333046342\n",
      "New best model found at epoch 253 with validation loss 1.1951751708984375\n",
      "Starting Epoch 254\n",
      "1.1493425120910008\n",
      "Validation loss: 1.1948072910308838\n",
      "mse 1.1948072523140403\n",
      "New best model found at epoch 254 with validation loss 1.1948072910308838\n",
      "Starting Epoch 255\n",
      "1.148822898666064\n",
      "Validation loss: 1.194812536239624\n",
      "mse 1.1948125276390427\n",
      "Starting Epoch 256\n",
      "1.1483500301837921\n",
      "Validation loss: 1.194234013557434\n",
      "mse 1.1942340515134984\n",
      "New best model found at epoch 256 with validation loss 1.194234013557434\n",
      "Starting Epoch 257\n",
      "1.1478161762158077\n",
      "Validation loss: 1.193632960319519\n",
      "mse 1.1936329648599744\n",
      "New best model found at epoch 257 with validation loss 1.193632960319519\n",
      "Starting Epoch 258\n",
      "1.1471937348445256\n",
      "Validation loss: 1.193647027015686\n",
      "mse 1.1936470457203208\n",
      "Starting Epoch 259\n",
      "1.1466278359293938\n",
      "Validation loss: 1.1933326721191406\n",
      "mse 1.1933326866853056\n",
      "New best model found at epoch 259 with validation loss 1.1933326721191406\n",
      "Starting Epoch 260\n",
      "1.1461507578690846\n",
      "Validation loss: 1.1930127143859863\n",
      "mse 1.1930128231237214\n",
      "New best model found at epoch 260 with validation loss 1.1930127143859863\n",
      "Starting Epoch 261\n",
      "1.1456249803304672\n",
      "Validation loss: 1.1928082704544067\n",
      "mse 1.192808182572414\n",
      "New best model found at epoch 261 with validation loss 1.1928082704544067\n",
      "Starting Epoch 262\n",
      "1.14507840325435\n",
      "Validation loss: 1.192470908164978\n",
      "mse 1.1924709458922054\n",
      "New best model found at epoch 262 with validation loss 1.192470908164978\n",
      "Starting Epoch 263\n",
      "1.1445148785909016\n",
      "Validation loss: 1.1923872232437134\n",
      "mse 1.1923872439972176\n",
      "New best model found at epoch 263 with validation loss 1.1923872232437134\n",
      "Starting Epoch 264\n",
      "1.1438807969292004\n",
      "Validation loss: 1.192058801651001\n",
      "mse 1.1920587699795033\n",
      "New best model found at epoch 264 with validation loss 1.192058801651001\n",
      "Starting Epoch 265\n",
      "1.1434302479028702\n",
      "Validation loss: 1.1918784379959106\n",
      "mse 1.191878426255169\n",
      "New best model found at epoch 265 with validation loss 1.1918784379959106\n",
      "Starting Epoch 266\n",
      "1.142905240257581\n",
      "Validation loss: 1.1916671991348267\n",
      "mse 1.1916671854187963\n",
      "New best model found at epoch 266 with validation loss 1.1916671991348267\n",
      "Starting Epoch 267\n",
      "1.1423895458380382\n",
      "Validation loss: 1.19143545627594\n",
      "mse 1.1914353845544876\n",
      "New best model found at epoch 267 with validation loss 1.19143545627594\n",
      "Starting Epoch 268\n",
      "1.1418792679905891\n",
      "Validation loss: 1.1910511255264282\n",
      "mse 1.1910513076249223\n",
      "New best model found at epoch 268 with validation loss 1.1910511255264282\n",
      "Starting Epoch 269\n",
      "1.1413524225354195\n",
      "Validation loss: 1.190813422203064\n",
      "mse 1.1908133684637976\n",
      "New best model found at epoch 269 with validation loss 1.190813422203064\n",
      "Starting Epoch 270\n",
      "1.1409546037515004\n",
      "Validation loss: 1.1901354789733887\n",
      "mse 1.1901354245069635\n",
      "New best model found at epoch 270 with validation loss 1.1901354789733887\n",
      "Starting Epoch 271\n",
      "1.1403066019217174\n",
      "Validation loss: 1.1903023719787598\n",
      "mse 1.19030242712503\n",
      "Starting Epoch 272\n",
      "1.1399343808492024\n",
      "Validation loss: 1.1899389028549194\n",
      "mse 1.189938948507618\n",
      "New best model found at epoch 272 with validation loss 1.1899389028549194\n",
      "Starting Epoch 273\n",
      "1.1393383940060933\n",
      "Validation loss: 1.189700961112976\n",
      "mse 1.1897010699270252\n",
      "New best model found at epoch 273 with validation loss 1.189700961112976\n",
      "Starting Epoch 274\n",
      "1.1389338374137878\n",
      "Validation loss: 1.189406156539917\n",
      "mse 1.189406082319644\n",
      "New best model found at epoch 274 with validation loss 1.189406156539917\n",
      "Starting Epoch 275\n",
      "1.138314274450143\n",
      "Validation loss: 1.1893672943115234\n",
      "mse 1.1893673996536098\n",
      "New best model found at epoch 275 with validation loss 1.1893672943115234\n",
      "Starting Epoch 276\n",
      "1.1378913298249245\n",
      "Validation loss: 1.1888598203659058\n",
      "mse 1.1888597877539275\n",
      "New best model found at epoch 276 with validation loss 1.1888598203659058\n",
      "Starting Epoch 277\n",
      "1.1373914604385693\n",
      "Validation loss: 1.1889089345932007\n",
      "mse 1.188908923191424\n",
      "Starting Epoch 278\n",
      "1.1368723412354786\n",
      "Validation loss: 1.1883134841918945\n",
      "mse 1.188313337588162\n",
      "New best model found at epoch 278 with validation loss 1.1883134841918945\n",
      "Starting Epoch 279\n",
      "1.1363905295729637\n",
      "Validation loss: 1.1882864236831665\n",
      "mse 1.1882864618509936\n",
      "New best model found at epoch 279 with validation loss 1.1882864236831665\n",
      "Starting Epoch 280\n",
      "1.1358953317006428\n",
      "Validation loss: 1.1880143880844116\n",
      "mse 1.188014405364095\n",
      "New best model found at epoch 280 with validation loss 1.1880143880844116\n",
      "Starting Epoch 281\n",
      "1.1353919977943103\n",
      "Validation loss: 1.1878149509429932\n",
      "mse 1.1878150222076582\n",
      "New best model found at epoch 281 with validation loss 1.1878149509429932\n",
      "Starting Epoch 282\n",
      "1.1348191450039546\n",
      "Validation loss: 1.1877784729003906\n",
      "mse 1.1877784784596654\n",
      "New best model found at epoch 282 with validation loss 1.1877784729003906\n",
      "Starting Epoch 283\n",
      "1.1344885577758153\n",
      "Validation loss: 1.1874382495880127\n",
      "mse 1.18743823359606\n",
      "New best model found at epoch 283 with validation loss 1.1874382495880127\n",
      "Starting Epoch 284\n",
      "1.1338993509610493\n",
      "Validation loss: 1.1872752904891968\n",
      "mse 1.1872750953347588\n",
      "New best model found at epoch 284 with validation loss 1.1872752904891968\n",
      "Starting Epoch 285\n",
      "1.133375806113084\n",
      "Validation loss: 1.186922311782837\n",
      "mse 1.1869223060812832\n",
      "New best model found at epoch 285 with validation loss 1.186922311782837\n",
      "Starting Epoch 286\n",
      "1.132936601837476\n",
      "Validation loss: 1.186872124671936\n",
      "mse 1.1868721220890532\n",
      "New best model found at epoch 286 with validation loss 1.186872124671936\n",
      "Starting Epoch 287\n",
      "1.1324318448702495\n",
      "Validation loss: 1.1866399049758911\n",
      "mse 1.1866397930270085\n",
      "New best model found at epoch 287 with validation loss 1.1866399049758911\n",
      "Starting Epoch 288\n",
      "1.1321699246764183\n",
      "Validation loss: 1.186144232749939\n",
      "mse 1.1861443192628955\n",
      "New best model found at epoch 288 with validation loss 1.186144232749939\n",
      "Starting Epoch 289\n",
      "1.1315414160490036\n",
      "Validation loss: 1.1861053705215454\n",
      "mse 1.1861054399611757\n",
      "New best model found at epoch 289 with validation loss 1.1861053705215454\n",
      "Starting Epoch 290\n",
      "1.1311971445878346\n",
      "Validation loss: 1.1853959560394287\n",
      "mse 1.185395963126375\n",
      "New best model found at epoch 290 with validation loss 1.1853959560394287\n",
      "Starting Epoch 291\n",
      "1.1306800171732903\n",
      "Validation loss: 1.1853196620941162\n",
      "mse 1.1853198744924005\n",
      "New best model found at epoch 291 with validation loss 1.1853196620941162\n",
      "Starting Epoch 292\n",
      "1.1303059657414753\n",
      "Validation loss: 1.1849340200424194\n",
      "mse 1.1849340127372132\n",
      "New best model found at epoch 292 with validation loss 1.1849340200424194\n",
      "Starting Epoch 293\n",
      "1.1296352818608284\n",
      "Validation loss: 1.1848647594451904\n",
      "mse 1.1848648679955043\n",
      "New best model found at epoch 293 with validation loss 1.1848647594451904\n",
      "Starting Epoch 294\n",
      "1.1294272964199383\n",
      "Validation loss: 1.1846009492874146\n",
      "mse 1.1846008750008332\n",
      "New best model found at epoch 294 with validation loss 1.1846009492874146\n",
      "Starting Epoch 295\n",
      "1.1288860241572063\n",
      "Validation loss: 1.1840819120407104\n",
      "mse 1.1840820020156873\n",
      "New best model found at epoch 295 with validation loss 1.1840819120407104\n",
      "Starting Epoch 296\n",
      "1.1283225292960803\n",
      "Validation loss: 1.1841639280319214\n",
      "mse 1.1841638712006604\n",
      "Starting Epoch 297\n",
      "1.12812985231479\n",
      "Validation loss: 1.18390691280365\n",
      "mse 1.1839068781217197\n",
      "New best model found at epoch 297 with validation loss 1.18390691280365\n",
      "Starting Epoch 298\n",
      "1.1275726134578388\n",
      "Validation loss: 1.1832449436187744\n",
      "mse 1.1832448921521108\n",
      "New best model found at epoch 298 with validation loss 1.1832449436187744\n",
      "Starting Epoch 299\n",
      "1.1272318810224533\n",
      "Validation loss: 1.183051347732544\n",
      "mse 1.1830513962503164\n",
      "New best model found at epoch 299 with validation loss 1.183051347732544\n",
      "Starting Epoch 300\n",
      "1.126757984360059\n",
      "Validation loss: 1.1830686330795288\n",
      "mse 1.18306862457138\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-60-20-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47165b85",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 7\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 80 - 50 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "0ec15841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "0db82fbb-346f-45db-9203-5034ec75d6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.6316646138827005\n",
      "Validation loss: 2.1943581104278564\n",
      "mse 2.194358197600399\n",
      "New best model found at epoch 1 with validation loss 2.1943581104278564\n",
      "Starting Epoch 2\n",
      "2.118984361489614\n",
      "Validation loss: 1.9713101387023926\n",
      "mse 1.9713101250123757\n",
      "New best model found at epoch 2 with validation loss 1.9713101387023926\n",
      "Starting Epoch 3\n",
      "1.9723920772473018\n",
      "Validation loss: 1.8420329093933105\n",
      "mse 1.842032863310854\n",
      "New best model found at epoch 3 with validation loss 1.8420329093933105\n",
      "Starting Epoch 4\n",
      "1.8797054092089336\n",
      "Validation loss: 1.7501471042633057\n",
      "mse 1.7501469418906128\n",
      "New best model found at epoch 4 with validation loss 1.7501471042633057\n",
      "Starting Epoch 5\n",
      "1.8111777404944103\n",
      "Validation loss: 1.6818289756774902\n",
      "mse 1.681829050121727\n",
      "New best model found at epoch 5 with validation loss 1.6818289756774902\n",
      "Starting Epoch 6\n",
      "1.7589323769013088\n",
      "Validation loss: 1.6360785961151123\n",
      "mse 1.6360785307164911\n",
      "New best model found at epoch 6 with validation loss 1.6360785961151123\n",
      "Starting Epoch 7\n",
      "1.718358685572942\n",
      "Validation loss: 1.6021260023117065\n",
      "mse 1.6021259636040575\n",
      "New best model found at epoch 7 with validation loss 1.6021260023117065\n",
      "Starting Epoch 8\n",
      "1.6851334869861603\n",
      "Validation loss: 1.5730197429656982\n",
      "mse 1.573019691999281\n",
      "New best model found at epoch 8 with validation loss 1.5730197429656982\n",
      "Starting Epoch 9\n",
      "1.655703643957774\n",
      "Validation loss: 1.5519696474075317\n",
      "mse 1.5519697467499858\n",
      "New best model found at epoch 9 with validation loss 1.5519696474075317\n",
      "Starting Epoch 10\n",
      "1.6300831486781437\n",
      "Validation loss: 1.5332539081573486\n",
      "mse 1.533253972800004\n",
      "New best model found at epoch 10 with validation loss 1.5332539081573486\n",
      "Starting Epoch 11\n",
      "1.6081028431653976\n",
      "Validation loss: 1.5177011489868164\n",
      "mse 1.5177010337354326\n",
      "New best model found at epoch 11 with validation loss 1.5177011489868164\n",
      "Starting Epoch 12\n",
      "1.5885866284370422\n",
      "Validation loss: 1.5053820610046387\n",
      "mse 1.5053821886258287\n",
      "New best model found at epoch 12 with validation loss 1.5053820610046387\n",
      "Starting Epoch 13\n",
      "1.5722798605759938\n",
      "Validation loss: 1.4916902780532837\n",
      "mse 1.4916902250046378\n",
      "New best model found at epoch 13 with validation loss 1.4916902780532837\n",
      "Starting Epoch 14\n",
      "1.5558261672655742\n",
      "Validation loss: 1.4822078943252563\n",
      "mse 1.4822079496936191\n",
      "New best model found at epoch 14 with validation loss 1.4822078943252563\n",
      "Starting Epoch 15\n",
      "1.5407955596844356\n",
      "Validation loss: 1.4729900360107422\n",
      "mse 1.4729901435354216\n",
      "New best model found at epoch 15 with validation loss 1.4729900360107422\n",
      "Starting Epoch 16\n",
      "1.527180607120196\n",
      "Validation loss: 1.4638843536376953\n",
      "mse 1.4638842827259941\n",
      "New best model found at epoch 16 with validation loss 1.4638843536376953\n",
      "Starting Epoch 17\n",
      "1.5140572289625804\n",
      "Validation loss: 1.455811619758606\n",
      "mse 1.4558115818270059\n",
      "New best model found at epoch 17 with validation loss 1.455811619758606\n",
      "Starting Epoch 18\n",
      "1.5021702100833256\n",
      "Validation loss: 1.448370337486267\n",
      "mse 1.448370207845118\n",
      "New best model found at epoch 18 with validation loss 1.448370337486267\n",
      "Starting Epoch 19\n",
      "1.4909617354472477\n",
      "Validation loss: 1.4405484199523926\n",
      "mse 1.4405482536263154\n",
      "New best model found at epoch 19 with validation loss 1.4405484199523926\n",
      "Starting Epoch 20\n",
      "1.479646881421407\n",
      "Validation loss: 1.4330271482467651\n",
      "mse 1.4330271420726017\n",
      "New best model found at epoch 20 with validation loss 1.4330271482467651\n",
      "Starting Epoch 21\n",
      "1.4685865888992946\n",
      "Validation loss: 1.424412488937378\n",
      "mse 1.42441257161238\n",
      "New best model found at epoch 21 with validation loss 1.424412488937378\n",
      "Starting Epoch 22\n",
      "1.4583450357119243\n",
      "Validation loss: 1.4184201955795288\n",
      "mse 1.4184200352643366\n",
      "New best model found at epoch 22 with validation loss 1.4184201955795288\n",
      "Starting Epoch 23\n",
      "1.4489261756340663\n",
      "Validation loss: 1.4123457670211792\n",
      "mse 1.4123457696693915\n",
      "New best model found at epoch 23 with validation loss 1.4123457670211792\n",
      "Starting Epoch 24\n",
      "1.4397096186876297\n",
      "Validation loss: 1.4070219993591309\n",
      "mse 1.4070219721196613\n",
      "New best model found at epoch 24 with validation loss 1.4070219993591309\n",
      "Starting Epoch 25\n",
      "1.4310771773258846\n",
      "Validation loss: 1.4024498462677002\n",
      "mse 1.4024499001461441\n",
      "New best model found at epoch 25 with validation loss 1.4024498462677002\n",
      "Starting Epoch 26\n",
      "1.4229031751553218\n",
      "Validation loss: 1.3971951007843018\n",
      "mse 1.3971951162059058\n",
      "New best model found at epoch 26 with validation loss 1.3971951007843018\n",
      "Starting Epoch 27\n",
      "1.4145036886135738\n",
      "Validation loss: 1.391143798828125\n",
      "mse 1.391143765316189\n",
      "New best model found at epoch 27 with validation loss 1.391143798828125\n",
      "Starting Epoch 28\n",
      "1.4066261698802311\n",
      "Validation loss: 1.3869578838348389\n",
      "mse 1.3869577793533938\n",
      "New best model found at epoch 28 with validation loss 1.3869578838348389\n",
      "Starting Epoch 29\n",
      "1.3998838514089584\n",
      "Validation loss: 1.3815553188323975\n",
      "mse 1.3815552458343618\n",
      "New best model found at epoch 29 with validation loss 1.3815553188323975\n",
      "Starting Epoch 30\n",
      "1.3933771799008052\n",
      "Validation loss: 1.3780704736709595\n",
      "mse 1.3780705175078924\n",
      "New best model found at epoch 30 with validation loss 1.3780704736709595\n",
      "Starting Epoch 31\n",
      "1.3877440144618352\n",
      "Validation loss: 1.372686505317688\n",
      "mse 1.3726864367412648\n",
      "New best model found at epoch 31 with validation loss 1.372686505317688\n",
      "Starting Epoch 32\n",
      "1.3818481266498566\n",
      "Validation loss: 1.3682708740234375\n",
      "mse 1.3682709180137238\n",
      "New best model found at epoch 32 with validation loss 1.3682708740234375\n",
      "Starting Epoch 33\n",
      "1.3755567570527394\n",
      "Validation loss: 1.363499402999878\n",
      "mse 1.3634993066821597\n",
      "New best model found at epoch 33 with validation loss 1.363499402999878\n",
      "Starting Epoch 34\n",
      "1.3704242582122486\n",
      "Validation loss: 1.3595415353775024\n",
      "mse 1.3595414303913185\n",
      "New best model found at epoch 34 with validation loss 1.3595415353775024\n",
      "Starting Epoch 35\n",
      "1.3651852210362752\n",
      "Validation loss: 1.3559752702713013\n",
      "mse 1.3559751802618023\n",
      "New best model found at epoch 35 with validation loss 1.3559752702713013\n",
      "Starting Epoch 36\n",
      "1.3600618814428647\n",
      "Validation loss: 1.3498696088790894\n",
      "mse 1.3498697124200314\n",
      "New best model found at epoch 36 with validation loss 1.3498696088790894\n",
      "Starting Epoch 37\n",
      "1.3544487381974857\n",
      "Validation loss: 1.3461061716079712\n",
      "mse 1.3461062079206145\n",
      "New best model found at epoch 37 with validation loss 1.3461061716079712\n",
      "Starting Epoch 38\n",
      "1.3497132112582524\n",
      "Validation loss: 1.3423367738723755\n",
      "mse 1.342336714531698\n",
      "New best model found at epoch 38 with validation loss 1.3423367738723755\n",
      "Starting Epoch 39\n",
      "1.3452778061230977\n",
      "Validation loss: 1.3379257917404175\n",
      "mse 1.3379258832718823\n",
      "New best model found at epoch 39 with validation loss 1.3379257917404175\n",
      "Starting Epoch 40\n",
      "1.3408244873086612\n",
      "Validation loss: 1.3346693515777588\n",
      "mse 1.3346692938794231\n",
      "New best model found at epoch 40 with validation loss 1.3346693515777588\n",
      "Starting Epoch 41\n",
      "1.3371079415082932\n",
      "Validation loss: 1.3309744596481323\n",
      "mse 1.330974510257353\n",
      "New best model found at epoch 41 with validation loss 1.3309744596481323\n",
      "Starting Epoch 42\n",
      "1.3331770772735279\n",
      "Validation loss: 1.3273718357086182\n",
      "mse 1.327371884695121\n",
      "New best model found at epoch 42 with validation loss 1.3273718357086182\n",
      "Starting Epoch 43\n",
      "1.3293271238605182\n",
      "Validation loss: 1.3242652416229248\n",
      "mse 1.3242651543118373\n",
      "New best model found at epoch 43 with validation loss 1.3242652416229248\n",
      "Starting Epoch 44\n",
      "1.3258181884884834\n",
      "Validation loss: 1.3230836391448975\n",
      "mse 1.32308355983108\n",
      "New best model found at epoch 44 with validation loss 1.3230836391448975\n",
      "Starting Epoch 45\n",
      "1.3223662301898003\n",
      "Validation loss: 1.3199011087417603\n",
      "mse 1.3199010814729755\n",
      "New best model found at epoch 45 with validation loss 1.3199011087417603\n",
      "Starting Epoch 46\n",
      "1.319214162727197\n",
      "Validation loss: 1.3149998188018799\n",
      "mse 1.3149998280643729\n",
      "New best model found at epoch 46 with validation loss 1.3149998188018799\n",
      "Starting Epoch 47\n",
      "1.315221130847931\n",
      "Validation loss: 1.3112632036209106\n",
      "mse 1.3112630861608265\n",
      "New best model found at epoch 47 with validation loss 1.3112632036209106\n",
      "Starting Epoch 48\n",
      "1.3121602659424145\n",
      "Validation loss: 1.3117471933364868\n",
      "mse 1.3117472521462965\n",
      "Starting Epoch 49\n",
      "1.3087331453959148\n",
      "Validation loss: 1.3071845769882202\n",
      "mse 1.3071845815653245\n",
      "New best model found at epoch 49 with validation loss 1.3071845769882202\n",
      "Starting Epoch 50\n",
      "1.3052354976534843\n",
      "Validation loss: 1.3059170246124268\n",
      "mse 1.3059169993380897\n",
      "New best model found at epoch 50 with validation loss 1.3059170246124268\n",
      "Starting Epoch 51\n",
      "1.3028144091367722\n",
      "Validation loss: 1.3017711639404297\n",
      "mse 1.301771176908097\n",
      "New best model found at epoch 51 with validation loss 1.3017711639404297\n",
      "Starting Epoch 52\n",
      "1.2995448435346286\n",
      "Validation loss: 1.2992746829986572\n",
      "mse 1.2992746255892118\n",
      "New best model found at epoch 52 with validation loss 1.2992746829986572\n",
      "Starting Epoch 53\n",
      "1.2965387130777042\n",
      "Validation loss: 1.2973158359527588\n",
      "mse 1.297315806551247\n",
      "New best model found at epoch 53 with validation loss 1.2973158359527588\n",
      "Starting Epoch 54\n",
      "1.293515498439471\n",
      "Validation loss: 1.293017864227295\n",
      "mse 1.2930179760545581\n",
      "New best model found at epoch 54 with validation loss 1.293017864227295\n",
      "Starting Epoch 55\n",
      "1.2909381613135338\n",
      "Validation loss: 1.2915219068527222\n",
      "mse 1.2915218541997349\n",
      "New best model found at epoch 55 with validation loss 1.2915219068527222\n",
      "Starting Epoch 56\n",
      "1.2882144078612328\n",
      "Validation loss: 1.289881944656372\n",
      "mse 1.289881920329748\n",
      "New best model found at epoch 56 with validation loss 1.289881944656372\n",
      "Starting Epoch 57\n",
      "1.28582547356685\n",
      "Validation loss: 1.2873822450637817\n",
      "mse 1.2873822191887971\n",
      "New best model found at epoch 57 with validation loss 1.2873822450637817\n",
      "Starting Epoch 58\n",
      "1.2831128612160683\n",
      "Validation loss: 1.2842692136764526\n",
      "mse 1.2842691810079003\n",
      "New best model found at epoch 58 with validation loss 1.2842692136764526\n",
      "Starting Epoch 59\n",
      "1.2801257396737735\n",
      "Validation loss: 1.2822121381759644\n",
      "mse 1.282212229531096\n",
      "New best model found at epoch 59 with validation loss 1.2822121381759644\n",
      "Starting Epoch 60\n",
      "1.2779433975617092\n",
      "Validation loss: 1.2805043458938599\n",
      "mse 1.2805044068158147\n",
      "New best model found at epoch 60 with validation loss 1.2805043458938599\n",
      "Starting Epoch 61\n",
      "1.2754327630003293\n",
      "Validation loss: 1.2795343399047852\n",
      "mse 1.2795343081257955\n",
      "New best model found at epoch 61 with validation loss 1.2795343399047852\n",
      "Starting Epoch 62\n",
      "1.2732440133889515\n",
      "Validation loss: 1.2782820463180542\n",
      "mse 1.2782820869098757\n",
      "New best model found at epoch 62 with validation loss 1.2782820463180542\n",
      "Starting Epoch 63\n",
      "1.2709240689873695\n",
      "Validation loss: 1.274493932723999\n",
      "mse 1.2744939982064494\n",
      "New best model found at epoch 63 with validation loss 1.274493932723999\n",
      "Starting Epoch 64\n",
      "1.2682380676269531\n",
      "Validation loss: 1.2737882137298584\n",
      "mse 1.2737882227508617\n",
      "New best model found at epoch 64 with validation loss 1.2737882137298584\n",
      "Starting Epoch 65\n",
      "1.2660330335299175\n",
      "Validation loss: 1.2712948322296143\n",
      "mse 1.2712948708787157\n",
      "New best model found at epoch 65 with validation loss 1.2712948322296143\n",
      "Starting Epoch 66\n",
      "1.2640771518150966\n",
      "Validation loss: 1.270911455154419\n",
      "mse 1.2709114106586308\n",
      "New best model found at epoch 66 with validation loss 1.270911455154419\n",
      "Starting Epoch 67\n",
      "1.261537993947665\n",
      "Validation loss: 1.2691161632537842\n",
      "mse 1.2691162406164294\n",
      "New best model found at epoch 67 with validation loss 1.2691161632537842\n",
      "Starting Epoch 68\n",
      "1.2594462931156158\n",
      "Validation loss: 1.267244815826416\n",
      "mse 1.2672449134879864\n",
      "New best model found at epoch 68 with validation loss 1.267244815826416\n",
      "Starting Epoch 69\n",
      "1.257379819949468\n",
      "Validation loss: 1.2648764848709106\n",
      "mse 1.2648766112561542\n",
      "New best model found at epoch 69 with validation loss 1.2648764848709106\n",
      "Starting Epoch 70\n",
      "1.2553951740264893\n",
      "Validation loss: 1.2626652717590332\n",
      "mse 1.262665289571762\n",
      "New best model found at epoch 70 with validation loss 1.2626652717590332\n",
      "Starting Epoch 71\n",
      "1.2529862473408382\n",
      "Validation loss: 1.2606213092803955\n",
      "mse 1.2606212852016148\n",
      "New best model found at epoch 71 with validation loss 1.2606213092803955\n",
      "Starting Epoch 72\n",
      "1.2509651109576225\n",
      "Validation loss: 1.258610486984253\n",
      "mse 1.2586104272770509\n",
      "New best model found at epoch 72 with validation loss 1.258610486984253\n",
      "Starting Epoch 73\n",
      "1.249151016275088\n",
      "Validation loss: 1.2560251951217651\n",
      "mse 1.25602518360198\n",
      "New best model found at epoch 73 with validation loss 1.2560251951217651\n",
      "Starting Epoch 74\n",
      "1.2468106622497241\n",
      "Validation loss: 1.2540724277496338\n",
      "mse 1.254072486171566\n",
      "New best model found at epoch 74 with validation loss 1.2540724277496338\n",
      "Starting Epoch 75\n",
      "1.2447813178102176\n",
      "Validation loss: 1.2535767555236816\n",
      "mse 1.25357673846701\n",
      "New best model found at epoch 75 with validation loss 1.2535767555236816\n",
      "Starting Epoch 76\n",
      "1.2429323469599087\n",
      "Validation loss: 1.2511640787124634\n",
      "mse 1.2511639696788082\n",
      "New best model found at epoch 76 with validation loss 1.2511640787124634\n",
      "Starting Epoch 77\n",
      "1.241141786177953\n",
      "Validation loss: 1.2496311664581299\n",
      "mse 1.2496311206012154\n",
      "New best model found at epoch 77 with validation loss 1.2496311664581299\n",
      "Starting Epoch 78\n",
      "1.2390121296048164\n",
      "Validation loss: 1.2490631341934204\n",
      "mse 1.2490632724583204\n",
      "New best model found at epoch 78 with validation loss 1.2490631341934204\n",
      "Starting Epoch 79\n",
      "1.2372128888964653\n",
      "Validation loss: 1.2474249601364136\n",
      "mse 1.247424850698018\n",
      "New best model found at epoch 79 with validation loss 1.2474249601364136\n",
      "Starting Epoch 80\n",
      "1.2357311621308327\n",
      "Validation loss: 1.2455064058303833\n",
      "mse 1.245506511032132\n",
      "New best model found at epoch 80 with validation loss 1.2455064058303833\n",
      "Starting Epoch 81\n",
      "1.234377461175124\n",
      "Validation loss: 1.2431190013885498\n",
      "mse 1.243118797747004\n",
      "New best model found at epoch 81 with validation loss 1.2431190013885498\n",
      "Starting Epoch 82\n",
      "1.232370028893153\n",
      "Validation loss: 1.242563247680664\n",
      "mse 1.2425631548424116\n",
      "New best model found at epoch 82 with validation loss 1.242563247680664\n",
      "Starting Epoch 83\n",
      "1.230702094733715\n",
      "Validation loss: 1.2402522563934326\n",
      "mse 1.2402523130135308\n",
      "New best model found at epoch 83 with validation loss 1.2402522563934326\n",
      "Starting Epoch 84\n",
      "1.2292045131325722\n",
      "Validation loss: 1.2393170595169067\n",
      "mse 1.2393172208561538\n",
      "New best model found at epoch 84 with validation loss 1.2393170595169067\n",
      "Starting Epoch 85\n",
      "1.227545162041982\n",
      "Validation loss: 1.2370315790176392\n",
      "mse 1.2370316505016283\n",
      "New best model found at epoch 85 with validation loss 1.2370315790176392\n",
      "Starting Epoch 86\n",
      "1.226273645957311\n",
      "Validation loss: 1.2356661558151245\n",
      "mse 1.2356661633753887\n",
      "New best model found at epoch 86 with validation loss 1.2356661558151245\n",
      "Starting Epoch 87\n",
      "1.2242186789711316\n",
      "Validation loss: 1.23403000831604\n",
      "mse 1.2340299562129642\n",
      "New best model found at epoch 87 with validation loss 1.23403000831604\n",
      "Starting Epoch 88\n",
      "1.2226635416348774\n",
      "Validation loss: 1.2324280738830566\n",
      "mse 1.2324279660255266\n",
      "New best model found at epoch 88 with validation loss 1.2324280738830566\n",
      "Starting Epoch 89\n",
      "1.2213499595721562\n",
      "Validation loss: 1.2312724590301514\n",
      "mse 1.2312724935448813\n",
      "New best model found at epoch 89 with validation loss 1.2312724590301514\n",
      "Starting Epoch 90\n",
      "1.2194351851940155\n",
      "Validation loss: 1.2300846576690674\n",
      "mse 1.2300845954595612\n",
      "New best model found at epoch 90 with validation loss 1.2300846576690674\n",
      "Starting Epoch 91\n",
      "1.2176531081398327\n",
      "Validation loss: 1.22866690158844\n",
      "mse 1.2286668783110262\n",
      "New best model found at epoch 91 with validation loss 1.22866690158844\n",
      "Starting Epoch 92\n",
      "1.21632669121027\n",
      "Validation loss: 1.228280782699585\n",
      "mse 1.22828065854192\n",
      "New best model found at epoch 92 with validation loss 1.228280782699585\n",
      "Starting Epoch 93\n",
      "1.214767222603162\n",
      "Validation loss: 1.2255609035491943\n",
      "mse 1.2255609664871046\n",
      "New best model found at epoch 93 with validation loss 1.2255609035491943\n",
      "Starting Epoch 94\n",
      "1.213384747505188\n",
      "Validation loss: 1.2250089645385742\n",
      "mse 1.2250088697936103\n",
      "New best model found at epoch 94 with validation loss 1.2250089645385742\n",
      "Starting Epoch 95\n",
      "1.2119630351662636\n",
      "Validation loss: 1.223340630531311\n",
      "mse 1.2233405748876471\n",
      "New best model found at epoch 95 with validation loss 1.223340630531311\n",
      "Starting Epoch 96\n",
      "1.2100235347946484\n",
      "Validation loss: 1.2226133346557617\n",
      "mse 1.2226132541749828\n",
      "New best model found at epoch 96 with validation loss 1.2226133346557617\n",
      "Starting Epoch 97\n",
      "1.208766038219134\n",
      "Validation loss: 1.2207045555114746\n",
      "mse 1.2207045575744402\n",
      "New best model found at epoch 97 with validation loss 1.2207045555114746\n",
      "Starting Epoch 98\n",
      "1.207021656135718\n",
      "Validation loss: 1.2191251516342163\n",
      "mse 1.2191252210691945\n",
      "New best model found at epoch 98 with validation loss 1.2191251516342163\n",
      "Starting Epoch 99\n",
      "1.2052151660124462\n",
      "Validation loss: 1.2173954248428345\n",
      "mse 1.2173953956786767\n",
      "New best model found at epoch 99 with validation loss 1.2173954248428345\n",
      "Starting Epoch 100\n",
      "1.2037482758363087\n",
      "Validation loss: 1.2158788442611694\n",
      "mse 1.2158788179994227\n",
      "New best model found at epoch 100 with validation loss 1.2158788442611694\n",
      "Starting Epoch 101\n",
      "1.2022868891557057\n",
      "Validation loss: 1.2146656513214111\n",
      "mse 1.2146656619988336\n",
      "New best model found at epoch 101 with validation loss 1.2146656513214111\n",
      "Starting Epoch 102\n",
      "1.2008404384056728\n",
      "Validation loss: 1.2124985456466675\n",
      "mse 1.2124985230396097\n",
      "New best model found at epoch 102 with validation loss 1.2124985456466675\n",
      "Starting Epoch 103\n",
      "1.198819746573766\n",
      "Validation loss: 1.21083664894104\n",
      "mse 1.210836683246572\n",
      "New best model found at epoch 103 with validation loss 1.21083664894104\n",
      "Starting Epoch 104\n",
      "1.1974896118044853\n",
      "Validation loss: 1.210124135017395\n",
      "mse 1.2101241748334284\n",
      "New best model found at epoch 104 with validation loss 1.210124135017395\n",
      "Starting Epoch 105\n",
      "1.1957862203319867\n",
      "Validation loss: 1.209224820137024\n",
      "mse 1.209224805695729\n",
      "New best model found at epoch 105 with validation loss 1.209224820137024\n",
      "Starting Epoch 106\n",
      "1.1944841295480728\n",
      "Validation loss: 1.207080364227295\n",
      "mse 1.2070805266041484\n",
      "New best model found at epoch 106 with validation loss 1.207080364227295\n",
      "Starting Epoch 107\n",
      "1.1931153188149135\n",
      "Validation loss: 1.2068828344345093\n",
      "mse 1.2068827299472478\n",
      "New best model found at epoch 107 with validation loss 1.2068828344345093\n",
      "Starting Epoch 108\n",
      "1.1916641667485237\n",
      "Validation loss: 1.205176591873169\n",
      "mse 1.205176475490429\n",
      "New best model found at epoch 108 with validation loss 1.205176591873169\n",
      "Starting Epoch 109\n",
      "1.1904343912998836\n",
      "Validation loss: 1.2037794589996338\n",
      "mse 1.2037793964069339\n",
      "New best model found at epoch 109 with validation loss 1.2037794589996338\n",
      "Starting Epoch 110\n",
      "1.1889475559194882\n",
      "Validation loss: 1.2027051448822021\n",
      "mse 1.202705165130053\n",
      "New best model found at epoch 110 with validation loss 1.2027051448822021\n",
      "Starting Epoch 111\n",
      "1.1879338522752125\n",
      "Validation loss: 1.2010889053344727\n",
      "mse 1.2010888813143148\n",
      "New best model found at epoch 111 with validation loss 1.2010889053344727\n",
      "Starting Epoch 112\n",
      "1.1860899130503337\n",
      "Validation loss: 1.2005475759506226\n",
      "mse 1.200547632235217\n",
      "New best model found at epoch 112 with validation loss 1.2005475759506226\n",
      "Starting Epoch 113\n",
      "1.1848377933104832\n",
      "Validation loss: 1.1984668970108032\n",
      "mse 1.1984669051416132\n",
      "New best model found at epoch 113 with validation loss 1.1984668970108032\n",
      "Starting Epoch 114\n",
      "1.183758094906807\n",
      "Validation loss: 1.19829261302948\n",
      "mse 1.1982925930749198\n",
      "New best model found at epoch 114 with validation loss 1.19829261302948\n",
      "Starting Epoch 115\n",
      "1.1822235857446988\n",
      "Validation loss: 1.1961052417755127\n",
      "mse 1.196105188335085\n",
      "New best model found at epoch 115 with validation loss 1.1961052417755127\n",
      "Starting Epoch 116\n",
      "1.1812297354141872\n",
      "Validation loss: 1.195418357849121\n",
      "mse 1.1954184130295464\n",
      "New best model found at epoch 116 with validation loss 1.195418357849121\n",
      "Starting Epoch 117\n",
      "1.1797111655275028\n",
      "Validation loss: 1.1939681768417358\n",
      "mse 1.19396811446045\n",
      "New best model found at epoch 117 with validation loss 1.1939681768417358\n",
      "Starting Epoch 118\n",
      "1.1781837219993274\n",
      "Validation loss: 1.1937611103057861\n",
      "mse 1.1937610452534906\n",
      "New best model found at epoch 118 with validation loss 1.1937611103057861\n",
      "Starting Epoch 119\n",
      "1.1772537703315418\n",
      "Validation loss: 1.1917340755462646\n",
      "mse 1.1917339999467307\n",
      "New best model found at epoch 119 with validation loss 1.1917340755462646\n",
      "Starting Epoch 120\n",
      "1.1759191031257312\n",
      "Validation loss: 1.1913962364196777\n",
      "mse 1.1913962463297465\n",
      "New best model found at epoch 120 with validation loss 1.1913962364196777\n",
      "Starting Epoch 121\n",
      "1.1747521286209424\n",
      "Validation loss: 1.1906932592391968\n",
      "mse 1.1906932684381646\n",
      "New best model found at epoch 121 with validation loss 1.1906932592391968\n",
      "Starting Epoch 122\n",
      "1.1738593205809593\n",
      "Validation loss: 1.1889235973358154\n",
      "mse 1.188923638921616\n",
      "New best model found at epoch 122 with validation loss 1.1889235973358154\n",
      "Starting Epoch 123\n",
      "1.1724913244446118\n",
      "Validation loss: 1.1878331899642944\n",
      "mse 1.187833050083776\n",
      "New best model found at epoch 123 with validation loss 1.1878331899642944\n",
      "Starting Epoch 124\n",
      "1.1716740404566128\n",
      "Validation loss: 1.1877881288528442\n",
      "mse 1.1877880952416497\n",
      "New best model found at epoch 124 with validation loss 1.1877881288528442\n",
      "Starting Epoch 125\n",
      "1.170040063560009\n",
      "Validation loss: 1.1865230798721313\n",
      "mse 1.1865230875470862\n",
      "New best model found at epoch 125 with validation loss 1.1865230798721313\n",
      "Starting Epoch 126\n",
      "1.169170819222927\n",
      "Validation loss: 1.1857892274856567\n",
      "mse 1.1857892074124294\n",
      "New best model found at epoch 126 with validation loss 1.1857892274856567\n",
      "Starting Epoch 127\n",
      "1.1680153384804726\n",
      "Validation loss: 1.1846991777420044\n",
      "mse 1.1846991264619282\n",
      "New best model found at epoch 127 with validation loss 1.1846991777420044\n",
      "Starting Epoch 128\n",
      "1.1668171087900798\n",
      "Validation loss: 1.1841566562652588\n",
      "mse 1.1841565665236693\n",
      "New best model found at epoch 128 with validation loss 1.1841566562652588\n",
      "Starting Epoch 129\n",
      "1.1656627158323924\n",
      "Validation loss: 1.18314790725708\n",
      "mse 1.1831479376720646\n",
      "New best model found at epoch 129 with validation loss 1.18314790725708\n",
      "Starting Epoch 130\n",
      "1.164868141214053\n",
      "Validation loss: 1.1820470094680786\n",
      "mse 1.1820470295205499\n",
      "New best model found at epoch 130 with validation loss 1.1820470094680786\n",
      "Starting Epoch 131\n",
      "1.1638014540076256\n",
      "Validation loss: 1.1817119121551514\n",
      "mse 1.1817120644968793\n",
      "New best model found at epoch 131 with validation loss 1.1817119121551514\n",
      "Starting Epoch 132\n",
      "1.162564940750599\n",
      "Validation loss: 1.1805317401885986\n",
      "mse 1.1805318646034586\n",
      "New best model found at epoch 132 with validation loss 1.1805317401885986\n",
      "Starting Epoch 133\n",
      "1.161535347501437\n",
      "Validation loss: 1.179786205291748\n",
      "mse 1.1797862882323298\n",
      "New best model found at epoch 133 with validation loss 1.179786205291748\n",
      "Starting Epoch 134\n",
      "1.1604155525565147\n",
      "Validation loss: 1.1786679029464722\n",
      "mse 1.1786679030920697\n",
      "New best model found at epoch 134 with validation loss 1.1786679029464722\n",
      "Starting Epoch 135\n",
      "1.1595116058985393\n",
      "Validation loss: 1.1778764724731445\n",
      "mse 1.1778764093740048\n",
      "New best model found at epoch 135 with validation loss 1.1778764724731445\n",
      "Starting Epoch 136\n",
      "1.158502921462059\n",
      "Validation loss: 1.17721426486969\n",
      "mse 1.1772142347820016\n",
      "New best model found at epoch 136 with validation loss 1.17721426486969\n",
      "Starting Epoch 137\n",
      "1.1575784385204315\n",
      "Validation loss: 1.1760547161102295\n",
      "mse 1.1760546684046818\n",
      "New best model found at epoch 137 with validation loss 1.1760547161102295\n",
      "Starting Epoch 138\n",
      "1.1564609905083973\n",
      "Validation loss: 1.1758549213409424\n",
      "mse 1.1758549831884624\n",
      "New best model found at epoch 138 with validation loss 1.1758549213409424\n",
      "Starting Epoch 139\n",
      "1.1555461684862773\n",
      "Validation loss: 1.1748069524765015\n",
      "mse 1.1748069146135713\n",
      "New best model found at epoch 139 with validation loss 1.1748069524765015\n",
      "Starting Epoch 140\n",
      "1.1545645048220952\n",
      "Validation loss: 1.1741938591003418\n",
      "mse 1.1741938773924545\n",
      "New best model found at epoch 140 with validation loss 1.1741938591003418\n",
      "Starting Epoch 141\n",
      "1.1534014269709587\n",
      "Validation loss: 1.1732310056686401\n",
      "mse 1.1732310399213557\n",
      "New best model found at epoch 141 with validation loss 1.1732310056686401\n",
      "Starting Epoch 142\n",
      "1.1526236186424892\n",
      "Validation loss: 1.1729272603988647\n",
      "mse 1.172927252886034\n",
      "New best model found at epoch 142 with validation loss 1.1729272603988647\n",
      "Starting Epoch 143\n",
      "1.151627649863561\n",
      "Validation loss: 1.1722716093063354\n",
      "mse 1.1722716965598443\n",
      "New best model found at epoch 143 with validation loss 1.1722716093063354\n",
      "Starting Epoch 144\n",
      "1.1506661127010982\n",
      "Validation loss: 1.1716935634613037\n",
      "mse 1.1716934420099243\n",
      "New best model found at epoch 144 with validation loss 1.1716935634613037\n",
      "Starting Epoch 145\n",
      "1.1496710578600566\n",
      "Validation loss: 1.171957015991211\n",
      "mse 1.1719571391869075\n",
      "Starting Epoch 146\n",
      "1.1490281994144123\n",
      "Validation loss: 1.1706650257110596\n",
      "mse 1.1706649385156753\n",
      "New best model found at epoch 146 with validation loss 1.1706650257110596\n",
      "Starting Epoch 147\n",
      "1.14803550640742\n",
      "Validation loss: 1.1697425842285156\n",
      "mse 1.169742575464352\n",
      "New best model found at epoch 147 with validation loss 1.1697425842285156\n",
      "Starting Epoch 148\n",
      "1.147176889081796\n",
      "Validation loss: 1.1695656776428223\n",
      "mse 1.1695658184130093\n",
      "New best model found at epoch 148 with validation loss 1.1695656776428223\n",
      "Starting Epoch 149\n",
      "1.146387626727422\n",
      "Validation loss: 1.169467568397522\n",
      "mse 1.16946762362818\n",
      "New best model found at epoch 149 with validation loss 1.169467568397522\n",
      "Starting Epoch 150\n",
      "1.145455315709114\n",
      "Validation loss: 1.1680110692977905\n",
      "mse 1.1680110757430318\n",
      "New best model found at epoch 150 with validation loss 1.1680110692977905\n",
      "Starting Epoch 151\n",
      "1.144500491519769\n",
      "Validation loss: 1.1681808233261108\n",
      "mse 1.1681808351570475\n",
      "Starting Epoch 152\n",
      "1.1436943337321281\n",
      "Validation loss: 1.1669628620147705\n",
      "mse 1.1669628146691016\n",
      "New best model found at epoch 152 with validation loss 1.1669628620147705\n",
      "Starting Epoch 153\n",
      "1.142856741944949\n",
      "Validation loss: 1.1672630310058594\n",
      "mse 1.1672628983101985\n",
      "Starting Epoch 154\n",
      "1.1422211527824402\n",
      "Validation loss: 1.1663329601287842\n",
      "mse 1.1663330754083718\n",
      "New best model found at epoch 154 with validation loss 1.1663329601287842\n",
      "Starting Epoch 155\n",
      "1.141130693256855\n",
      "Validation loss: 1.1650265455245972\n",
      "mse 1.1650265597277896\n",
      "New best model found at epoch 155 with validation loss 1.1650265455245972\n",
      "Starting Epoch 156\n",
      "1.1402339885632198\n",
      "Validation loss: 1.1646779775619507\n",
      "mse 1.1646778410514866\n",
      "New best model found at epoch 156 with validation loss 1.1646779775619507\n",
      "Starting Epoch 157\n",
      "1.1395934720834096\n",
      "Validation loss: 1.1648019552230835\n",
      "mse 1.164802099501278\n",
      "Starting Epoch 158\n",
      "1.1386752799153328\n",
      "Validation loss: 1.1641753911972046\n",
      "mse 1.1641753850085836\n",
      "New best model found at epoch 158 with validation loss 1.1641753911972046\n",
      "Starting Epoch 159\n",
      "1.137844276924928\n",
      "Validation loss: 1.1633285284042358\n",
      "mse 1.163328453416179\n",
      "New best model found at epoch 159 with validation loss 1.1633285284042358\n",
      "Starting Epoch 160\n",
      "1.1368478015065193\n",
      "Validation loss: 1.1629382371902466\n",
      "mse 1.1629383363366466\n",
      "New best model found at epoch 160 with validation loss 1.1629382371902466\n",
      "Starting Epoch 161\n",
      "1.136319416264693\n",
      "Validation loss: 1.1625386476516724\n",
      "mse 1.1625384453737746\n",
      "New best model found at epoch 161 with validation loss 1.1625386476516724\n",
      "Starting Epoch 162\n",
      "1.1355144505699475\n",
      "Validation loss: 1.1619336605072021\n",
      "mse 1.1619337128547063\n",
      "New best model found at epoch 162 with validation loss 1.1619336605072021\n",
      "Starting Epoch 163\n",
      "1.1346397151549656\n",
      "Validation loss: 1.1617988348007202\n",
      "mse 1.1617989255138972\n",
      "New best model found at epoch 163 with validation loss 1.1617988348007202\n",
      "Starting Epoch 164\n",
      "1.1339235827326775\n",
      "Validation loss: 1.1601210832595825\n",
      "mse 1.160120945837493\n",
      "New best model found at epoch 164 with validation loss 1.1601210832595825\n",
      "Starting Epoch 165\n",
      "1.1331627517938614\n",
      "Validation loss: 1.1603022813796997\n",
      "mse 1.1603022943032708\n",
      "Starting Epoch 166\n",
      "1.1325096487998962\n",
      "Validation loss: 1.1595160961151123\n",
      "mse 1.159516151728266\n",
      "New best model found at epoch 166 with validation loss 1.1595160961151123\n",
      "Starting Epoch 167\n",
      "1.1315761382381122\n",
      "Validation loss: 1.1594390869140625\n",
      "mse 1.1594390688086134\n",
      "New best model found at epoch 167 with validation loss 1.1594390869140625\n",
      "Starting Epoch 168\n",
      "1.1309717074036598\n",
      "Validation loss: 1.1587939262390137\n",
      "mse 1.1587939277479737\n",
      "New best model found at epoch 168 with validation loss 1.1587939262390137\n",
      "Starting Epoch 169\n",
      "1.1301333929101627\n",
      "Validation loss: 1.1583490371704102\n",
      "mse 1.1583491057181958\n",
      "New best model found at epoch 169 with validation loss 1.1583490371704102\n",
      "Starting Epoch 170\n",
      "1.1292342990636826\n",
      "Validation loss: 1.1578959226608276\n",
      "mse 1.1578957763058424\n",
      "New best model found at epoch 170 with validation loss 1.1578959226608276\n",
      "Starting Epoch 171\n",
      "1.1284799178441365\n",
      "Validation loss: 1.157410979270935\n",
      "mse 1.1574111154031987\n",
      "New best model found at epoch 171 with validation loss 1.157410979270935\n",
      "Starting Epoch 172\n",
      "1.1279649436473846\n",
      "Validation loss: 1.1567482948303223\n",
      "mse 1.156748322947373\n",
      "New best model found at epoch 172 with validation loss 1.1567482948303223\n",
      "Starting Epoch 173\n",
      "1.127076116700967\n",
      "Validation loss: 1.1562553644180298\n",
      "mse 1.1562553553725343\n",
      "New best model found at epoch 173 with validation loss 1.1562553644180298\n",
      "Starting Epoch 174\n",
      "1.1263616184393566\n",
      "Validation loss: 1.1559845209121704\n",
      "mse 1.1559845280256202\n",
      "New best model found at epoch 174 with validation loss 1.1559845209121704\n",
      "Starting Epoch 175\n",
      "1.1257275566458702\n",
      "Validation loss: 1.1569302082061768\n",
      "mse 1.156930236983554\n",
      "Starting Epoch 176\n",
      "1.12496713300546\n",
      "Validation loss: 1.1564009189605713\n",
      "mse 1.1564009003355769\n",
      "Starting Epoch 177\n",
      "1.1243513400355976\n",
      "Validation loss: 1.1546263694763184\n",
      "mse 1.1546265770455322\n",
      "New best model found at epoch 177 with validation loss 1.1546263694763184\n",
      "Starting Epoch 178\n",
      "1.1234801312287648\n",
      "Validation loss: 1.1553502082824707\n",
      "mse 1.1553502174680514\n",
      "Starting Epoch 179\n",
      "1.1227574621637662\n",
      "Validation loss: 1.1551529169082642\n",
      "mse 1.155152941922672\n",
      "Starting Epoch 180\n",
      "1.1222747787833214\n",
      "Validation loss: 1.1533094644546509\n",
      "mse 1.153309505833591\n",
      "New best model found at epoch 180 with validation loss 1.1533094644546509\n",
      "Starting Epoch 181\n",
      "1.121418130894502\n",
      "Validation loss: 1.1535459756851196\n",
      "mse 1.1535460543270466\n",
      "Starting Epoch 182\n",
      "1.1209080666303635\n",
      "Validation loss: 1.1537190675735474\n",
      "mse 1.1537189110112709\n",
      "Starting Epoch 183\n",
      "1.1201512937744458\n",
      "Validation loss: 1.152093768119812\n",
      "mse 1.152093692992345\n",
      "New best model found at epoch 183 with validation loss 1.152093768119812\n",
      "Starting Epoch 184\n",
      "1.119293436408043\n",
      "Validation loss: 1.151728868484497\n",
      "mse 1.151728993001997\n",
      "New best model found at epoch 184 with validation loss 1.151728868484497\n",
      "Starting Epoch 185\n",
      "1.1185353845357895\n",
      "Validation loss: 1.1512428522109985\n",
      "mse 1.1512429139233098\n",
      "New best model found at epoch 185 with validation loss 1.1512428522109985\n",
      "Starting Epoch 186\n",
      "1.117810805638631\n",
      "Validation loss: 1.1518577337265015\n",
      "mse 1.151857780148291\n",
      "Starting Epoch 187\n",
      "1.1172069286306698\n",
      "Validation loss: 1.1503500938415527\n",
      "mse 1.1503500885728644\n",
      "New best model found at epoch 187 with validation loss 1.1503500938415527\n",
      "Starting Epoch 188\n",
      "1.11653886983792\n",
      "Validation loss: 1.1497172117233276\n",
      "mse 1.149717160677519\n",
      "New best model found at epoch 188 with validation loss 1.1497172117233276\n",
      "Starting Epoch 189\n",
      "1.1158058196306229\n",
      "Validation loss: 1.1505835056304932\n",
      "mse 1.1505834361176983\n",
      "Starting Epoch 190\n",
      "1.1151415506998699\n",
      "Validation loss: 1.1495425701141357\n",
      "mse 1.149542649849101\n",
      "New best model found at epoch 190 with validation loss 1.1495425701141357\n",
      "Starting Epoch 191\n",
      "1.1144882043202717\n",
      "Validation loss: 1.1489553451538086\n",
      "mse 1.148955368429952\n",
      "New best model found at epoch 191 with validation loss 1.1489553451538086\n",
      "Starting Epoch 192\n",
      "1.1139295225342114\n",
      "Validation loss: 1.1495684385299683\n",
      "mse 1.1495683374931116\n",
      "Starting Epoch 193\n",
      "1.1131905689835548\n",
      "Validation loss: 1.1488263607025146\n",
      "mse 1.1488265042331876\n",
      "New best model found at epoch 193 with validation loss 1.1488263607025146\n",
      "Starting Epoch 194\n",
      "1.112706795334816\n",
      "Validation loss: 1.14913010597229\n",
      "mse 1.149130084032246\n",
      "Starting Epoch 195\n",
      "1.112021766602993\n",
      "Validation loss: 1.1477714776992798\n",
      "mse 1.1477714298255453\n",
      "New best model found at epoch 195 with validation loss 1.1477714776992798\n",
      "Starting Epoch 196\n",
      "1.1114276473720868\n",
      "Validation loss: 1.1482661962509155\n",
      "mse 1.1482661910530048\n",
      "Starting Epoch 197\n",
      "1.1107125257452328\n",
      "Validation loss: 1.1481059789657593\n",
      "mse 1.1481060585643335\n",
      "Starting Epoch 198\n",
      "1.1101543307304382\n",
      "Validation loss: 1.1474852561950684\n",
      "mse 1.1474852428647893\n",
      "New best model found at epoch 198 with validation loss 1.1474852561950684\n",
      "Starting Epoch 199\n",
      "1.109573855996132\n",
      "Validation loss: 1.1466021537780762\n",
      "mse 1.146602126012765\n",
      "New best model found at epoch 199 with validation loss 1.1466021537780762\n",
      "Starting Epoch 200\n",
      "1.1090669482946396\n",
      "Validation loss: 1.1470378637313843\n",
      "mse 1.1470379787580498\n",
      "Starting Epoch 201\n",
      "1.1084069733818371\n",
      "Validation loss: 1.14658784866333\n",
      "mse 1.1465880333878544\n",
      "New best model found at epoch 201 with validation loss 1.14658784866333\n",
      "Starting Epoch 202\n",
      "1.1076634178558986\n",
      "Validation loss: 1.146539330482483\n",
      "mse 1.146539290240656\n",
      "New best model found at epoch 202 with validation loss 1.146539330482483\n",
      "Starting Epoch 203\n",
      "1.1072360003987949\n",
      "Validation loss: 1.1458520889282227\n",
      "mse 1.1458522026139748\n",
      "New best model found at epoch 203 with validation loss 1.1458520889282227\n",
      "Starting Epoch 204\n",
      "1.1063933794697125\n",
      "Validation loss: 1.1445351839065552\n",
      "mse 1.144535141593448\n",
      "New best model found at epoch 204 with validation loss 1.1445351839065552\n",
      "Starting Epoch 205\n",
      "1.1061219225327175\n",
      "Validation loss: 1.1451606750488281\n",
      "mse 1.1451607431377266\n",
      "Starting Epoch 206\n",
      "1.1052938501040142\n",
      "Validation loss: 1.1447268724441528\n",
      "mse 1.144726827465811\n",
      "Starting Epoch 207\n",
      "1.1047295033931732\n",
      "Validation loss: 1.1446949243545532\n",
      "mse 1.1446950378751062\n",
      "Starting Epoch 208\n",
      "1.1043485254049301\n",
      "Validation loss: 1.144099473953247\n",
      "mse 1.144099504221005\n",
      "New best model found at epoch 208 with validation loss 1.144099473953247\n",
      "Starting Epoch 209\n",
      "1.1038227031628292\n",
      "Validation loss: 1.1438584327697754\n",
      "mse 1.1438584076542608\n",
      "New best model found at epoch 209 with validation loss 1.1438584327697754\n",
      "Starting Epoch 210\n",
      "1.1029319639007251\n",
      "Validation loss: 1.143850326538086\n",
      "mse 1.1438504172328752\n",
      "New best model found at epoch 210 with validation loss 1.143850326538086\n",
      "Starting Epoch 211\n",
      "1.1026804993549983\n",
      "Validation loss: 1.1432291269302368\n",
      "mse 1.1432290908272107\n",
      "New best model found at epoch 211 with validation loss 1.1432291269302368\n",
      "Starting Epoch 212\n",
      "1.1017420689264934\n",
      "Validation loss: 1.1418651342391968\n",
      "mse 1.1418651325914344\n",
      "New best model found at epoch 212 with validation loss 1.1418651342391968\n",
      "Starting Epoch 213\n",
      "1.1013896663983662\n",
      "Validation loss: 1.1421059370040894\n",
      "mse 1.1421058912853277\n",
      "Starting Epoch 214\n",
      "1.1009127621849377\n",
      "Validation loss: 1.1420254707336426\n",
      "mse 1.1420254450872063\n",
      "Starting Epoch 215\n",
      "1.1003902206818263\n",
      "Validation loss: 1.1420722007751465\n",
      "mse 1.142072143796\n",
      "Starting Epoch 216\n",
      "1.0996661360065143\n",
      "Validation loss: 1.141530156135559\n",
      "mse 1.1415301135919877\n",
      "New best model found at epoch 216 with validation loss 1.141530156135559\n",
      "Starting Epoch 217\n",
      "1.0991046552856762\n",
      "Validation loss: 1.1418983936309814\n",
      "mse 1.1418984774447583\n",
      "Starting Epoch 218\n",
      "1.098594402273496\n",
      "Validation loss: 1.1402618885040283\n",
      "mse 1.1402618889647784\n",
      "New best model found at epoch 218 with validation loss 1.1402618885040283\n",
      "Starting Epoch 219\n",
      "1.0981568892796834\n",
      "Validation loss: 1.1406702995300293\n",
      "mse 1.1406702879452462\n",
      "Starting Epoch 220\n",
      "1.0976679623126984\n",
      "Validation loss: 1.1407922506332397\n",
      "mse 1.1407923016694976\n",
      "Starting Epoch 221\n",
      "1.0971174587806065\n",
      "Validation loss: 1.1401008367538452\n",
      "mse 1.1401009314492074\n",
      "New best model found at epoch 221 with validation loss 1.1401008367538452\n",
      "Starting Epoch 222\n",
      "1.0964086229602497\n",
      "Validation loss: 1.1403415203094482\n",
      "mse 1.1403414661945874\n",
      "Starting Epoch 223\n",
      "1.095847487449646\n",
      "Validation loss: 1.1399773359298706\n",
      "mse 1.1399773390861416\n",
      "New best model found at epoch 223 with validation loss 1.1399773359298706\n",
      "Starting Epoch 224\n",
      "1.0953608627120655\n",
      "Validation loss: 1.1400465965270996\n",
      "mse 1.1400466459569265\n",
      "Starting Epoch 225\n",
      "1.0953065132101376\n",
      "Validation loss: 1.1388322114944458\n",
      "mse 1.1388321340618373\n",
      "New best model found at epoch 225 with validation loss 1.1388322114944458\n",
      "Starting Epoch 226\n",
      "1.094439114133517\n",
      "Validation loss: 1.1393686532974243\n",
      "mse 1.1393687784949222\n",
      "Starting Epoch 227\n",
      "1.0937486191590626\n",
      "Validation loss: 1.1389679908752441\n",
      "mse 1.1389679457087718\n",
      "Starting Epoch 228\n",
      "1.09360425422589\n",
      "Validation loss: 1.1391371488571167\n",
      "mse 1.1391370829553529\n",
      "Starting Epoch 229\n",
      "1.092969576517741\n",
      "Validation loss: 1.1388392448425293\n",
      "mse 1.1388392146648998\n",
      "Starting Epoch 230\n",
      "1.0925380364060402\n",
      "Validation loss: 1.1378666162490845\n",
      "mse 1.137866686816603\n",
      "New best model found at epoch 230 with validation loss 1.1378666162490845\n",
      "Starting Epoch 231\n",
      "1.0919594019651413\n",
      "Validation loss: 1.1375703811645508\n",
      "mse 1.1375703206606453\n",
      "New best model found at epoch 231 with validation loss 1.1375703811645508\n",
      "Starting Epoch 232\n",
      "1.091411180794239\n",
      "Validation loss: 1.1383123397827148\n",
      "mse 1.1383123500341341\n",
      "Starting Epoch 233\n",
      "1.0911154374480247\n",
      "Validation loss: 1.137743353843689\n",
      "mse 1.1377432646400594\n",
      "Starting Epoch 234\n",
      "1.090407947699229\n",
      "Validation loss: 1.136614441871643\n",
      "mse 1.136614383962327\n",
      "New best model found at epoch 234 with validation loss 1.136614441871643\n",
      "Starting Epoch 235\n",
      "1.0899082273244858\n",
      "Validation loss: 1.1369513273239136\n",
      "mse 1.1369513708914083\n",
      "Starting Epoch 236\n",
      "1.0892527426282566\n",
      "Validation loss: 1.1376211643218994\n",
      "mse 1.1376211739404303\n",
      "Starting Epoch 237\n",
      "1.089055987695853\n",
      "Validation loss: 1.136339545249939\n",
      "mse 1.136339491634096\n",
      "New best model found at epoch 237 with validation loss 1.136339545249939\n",
      "Starting Epoch 238\n",
      "1.0883942171931267\n",
      "Validation loss: 1.1362929344177246\n",
      "mse 1.1362930115858494\n",
      "New best model found at epoch 238 with validation loss 1.1362929344177246\n",
      "Starting Epoch 239\n",
      "1.0880515625079472\n",
      "Validation loss: 1.1353853940963745\n",
      "mse 1.13538536636743\n",
      "New best model found at epoch 239 with validation loss 1.1353853940963745\n",
      "Starting Epoch 240\n",
      "1.0873402630289395\n",
      "Validation loss: 1.1350961923599243\n",
      "mse 1.1350961471294925\n",
      "New best model found at epoch 240 with validation loss 1.1350961923599243\n",
      "Starting Epoch 241\n",
      "1.0867979948719342\n",
      "Validation loss: 1.1352818012237549\n",
      "mse 1.135281820324293\n",
      "Starting Epoch 242\n",
      "1.0863815049330394\n",
      "Validation loss: 1.1347455978393555\n",
      "mse 1.1347456529314155\n",
      "New best model found at epoch 242 with validation loss 1.1347455978393555\n",
      "Starting Epoch 243\n",
      "1.0858870148658752\n",
      "Validation loss: 1.1338050365447998\n",
      "mse 1.1338050194691236\n",
      "New best model found at epoch 243 with validation loss 1.1338050365447998\n",
      "Starting Epoch 244\n",
      "1.0854176332553227\n",
      "Validation loss: 1.13458251953125\n",
      "mse 1.134582433010283\n",
      "Starting Epoch 245\n",
      "1.0848733484745026\n",
      "Validation loss: 1.134037971496582\n",
      "mse 1.1340379677878816\n",
      "Starting Epoch 246\n",
      "1.0845228855808575\n",
      "Validation loss: 1.1347379684448242\n",
      "mse 1.134737789740921\n",
      "Starting Epoch 247\n",
      "1.0839469134807587\n",
      "Validation loss: 1.1343721151351929\n",
      "mse 1.1343721309591481\n",
      "Starting Epoch 248\n",
      "1.0837674960494041\n",
      "Validation loss: 1.1331839561462402\n",
      "mse 1.1331839716352963\n",
      "New best model found at epoch 248 with validation loss 1.1331839561462402\n",
      "Starting Epoch 249\n",
      "1.0831776683529217\n",
      "Validation loss: 1.1334221363067627\n",
      "mse 1.133422122847654\n",
      "Starting Epoch 250\n",
      "1.0826312204202015\n",
      "Validation loss: 1.1330840587615967\n",
      "mse 1.1330839135425141\n",
      "New best model found at epoch 250 with validation loss 1.1330840587615967\n",
      "Starting Epoch 251\n",
      "1.0821225196123123\n",
      "Validation loss: 1.133209228515625\n",
      "mse 1.1332092921355694\n",
      "Starting Epoch 252\n",
      "1.081901880602042\n",
      "Validation loss: 1.132810115814209\n",
      "mse 1.132810131126163\n",
      "New best model found at epoch 252 with validation loss 1.132810115814209\n",
      "Starting Epoch 253\n",
      "1.0811849211653073\n",
      "Validation loss: 1.1326444149017334\n",
      "mse 1.132644460735729\n",
      "New best model found at epoch 253 with validation loss 1.1326444149017334\n",
      "Starting Epoch 254\n",
      "1.0807707384228706\n",
      "Validation loss: 1.1331313848495483\n",
      "mse 1.1331313777108498\n",
      "Starting Epoch 255\n",
      "1.0804327105482419\n",
      "Validation loss: 1.1323432922363281\n",
      "mse 1.1323432677874614\n",
      "New best model found at epoch 255 with validation loss 1.1323432922363281\n",
      "Starting Epoch 256\n",
      "1.0799852659304936\n",
      "Validation loss: 1.1323983669281006\n",
      "mse 1.1323984711811743\n",
      "Starting Epoch 257\n",
      "1.0794579063852627\n",
      "Validation loss: 1.1319527626037598\n",
      "mse 1.131952790477393\n",
      "New best model found at epoch 257 with validation loss 1.1319527626037598\n",
      "Starting Epoch 258\n",
      "1.0789808208743732\n",
      "Validation loss: 1.1317102909088135\n",
      "mse 1.1317102784716708\n",
      "New best model found at epoch 258 with validation loss 1.1317102909088135\n",
      "Starting Epoch 259\n",
      "1.0787133574485779\n",
      "Validation loss: 1.1306445598602295\n",
      "mse 1.130644682673774\n",
      "New best model found at epoch 259 with validation loss 1.1306445598602295\n",
      "Starting Epoch 260\n",
      "1.0781853000322978\n",
      "Validation loss: 1.1311213970184326\n",
      "mse 1.1311214095087005\n",
      "Starting Epoch 261\n",
      "1.0778624067703884\n",
      "Validation loss: 1.1299797296524048\n",
      "mse 1.1299796646523903\n",
      "New best model found at epoch 261 with validation loss 1.1299797296524048\n",
      "Starting Epoch 262\n",
      "1.0772720923026402\n",
      "Validation loss: 1.1305207014083862\n",
      "mse 1.1305207395317622\n",
      "Starting Epoch 263\n",
      "1.0768503149350483\n",
      "Validation loss: 1.130792498588562\n",
      "mse 1.1307925049303982\n",
      "Starting Epoch 264\n",
      "1.0766089409589767\n",
      "Validation loss: 1.1301190853118896\n",
      "mse 1.1301190115427373\n",
      "Starting Epoch 265\n",
      "1.0761483137806256\n",
      "Validation loss: 1.1304768323898315\n",
      "mse 1.130476826303227\n",
      "Starting Epoch 266\n",
      "1.0759908283750217\n",
      "Validation loss: 1.129061222076416\n",
      "mse 1.1290612135486247\n",
      "New best model found at epoch 266 with validation loss 1.129061222076416\n",
      "Starting Epoch 267\n",
      "1.0754155566294987\n",
      "Validation loss: 1.1297985315322876\n",
      "mse 1.1297984696947254\n",
      "Starting Epoch 268\n",
      "1.0750061050057411\n",
      "Validation loss: 1.1294159889221191\n",
      "mse 1.1294159515907318\n",
      "Starting Epoch 269\n",
      "1.0744884063800175\n",
      "Validation loss: 1.1299272775650024\n",
      "mse 1.1299272784588814\n",
      "Starting Epoch 270\n",
      "1.0743363449970882\n",
      "Validation loss: 1.1286773681640625\n",
      "mse 1.1286774723362651\n",
      "New best model found at epoch 270 with validation loss 1.1286773681640625\n",
      "Starting Epoch 271\n",
      "1.0738886917630832\n",
      "Validation loss: 1.128990650177002\n",
      "mse 1.1289906034312778\n",
      "Starting Epoch 272\n",
      "1.0735442787408829\n",
      "Validation loss: 1.128755807876587\n",
      "mse 1.1287557562311572\n",
      "Starting Epoch 273\n",
      "1.0731775015592575\n",
      "Validation loss: 1.1277261972427368\n",
      "mse 1.1277262188170214\n",
      "New best model found at epoch 273 with validation loss 1.1277261972427368\n",
      "Starting Epoch 274\n",
      "1.0727465152740479\n",
      "Validation loss: 1.1274080276489258\n",
      "mse 1.1274080470286747\n",
      "New best model found at epoch 274 with validation loss 1.1274080276489258\n",
      "Starting Epoch 275\n",
      "1.0723154470324516\n",
      "Validation loss: 1.127703309059143\n",
      "mse 1.1277033227861004\n",
      "Starting Epoch 276\n",
      "1.071821577847004\n",
      "Validation loss: 1.1278706789016724\n",
      "mse 1.1278707581270528\n",
      "Starting Epoch 277\n",
      "1.0715183317661285\n",
      "Validation loss: 1.1282345056533813\n",
      "mse 1.1282344445492813\n",
      "Starting Epoch 278\n",
      "1.0711337501804035\n",
      "Validation loss: 1.1277122497558594\n",
      "mse 1.1277120850163176\n",
      "Starting Epoch 279\n",
      "1.070667398472627\n",
      "Validation loss: 1.1273705959320068\n",
      "mse 1.1273705732239026\n",
      "New best model found at epoch 279 with validation loss 1.1273705959320068\n",
      "Starting Epoch 280\n",
      "1.0701245069503784\n",
      "Validation loss: 1.1274194717407227\n",
      "mse 1.127419421467085\n",
      "Starting Epoch 281\n",
      "1.070022573073705\n",
      "Validation loss: 1.1272693872451782\n",
      "mse 1.127269438928436\n",
      "New best model found at epoch 281 with validation loss 1.1272693872451782\n",
      "Starting Epoch 282\n",
      "1.0697368408242862\n",
      "Validation loss: 1.1269828081130981\n",
      "mse 1.126982733786768\n",
      "New best model found at epoch 282 with validation loss 1.1269828081130981\n",
      "Starting Epoch 283\n",
      "1.0691446339090664\n",
      "Validation loss: 1.1268820762634277\n",
      "mse 1.1268820655820864\n",
      "New best model found at epoch 283 with validation loss 1.1268820762634277\n",
      "Starting Epoch 284\n",
      "1.068964918454488\n",
      "Validation loss: 1.1266676187515259\n",
      "mse 1.126667628236737\n",
      "New best model found at epoch 284 with validation loss 1.1266676187515259\n",
      "Starting Epoch 285\n",
      "1.0684583360950153\n",
      "Validation loss: 1.1258528232574463\n",
      "mse 1.1258528884989665\n",
      "New best model found at epoch 285 with validation loss 1.1258528232574463\n",
      "Starting Epoch 286\n",
      "1.0681541487574577\n",
      "Validation loss: 1.1256362199783325\n",
      "mse 1.1256362243225697\n",
      "New best model found at epoch 286 with validation loss 1.1256362199783325\n",
      "Starting Epoch 287\n",
      "1.0678195084134738\n",
      "Validation loss: 1.1261956691741943\n",
      "mse 1.1261957471446935\n",
      "Starting Epoch 288\n",
      "1.067401446402073\n",
      "Validation loss: 1.1265071630477905\n",
      "mse 1.1265071578415475\n",
      "Starting Epoch 289\n",
      "1.067026508351167\n",
      "Validation loss: 1.1260310411453247\n",
      "mse 1.1260310089354817\n",
      "Starting Epoch 290\n",
      "1.0666753898064296\n",
      "Validation loss: 1.1262673139572144\n",
      "mse 1.1262673036898403\n",
      "Starting Epoch 291\n",
      "1.0662752389907837\n",
      "Validation loss: 1.1256341934204102\n",
      "mse 1.1256341627045023\n",
      "New best model found at epoch 291 with validation loss 1.1256341934204102\n",
      "Starting Epoch 292\n",
      "1.065897802511851\n",
      "Validation loss: 1.125311255455017\n",
      "mse 1.125311220212601\n",
      "New best model found at epoch 292 with validation loss 1.125311255455017\n",
      "Starting Epoch 293\n",
      "1.0655041088660557\n",
      "Validation loss: 1.1248303651809692\n",
      "mse 1.1248303862519862\n",
      "New best model found at epoch 293 with validation loss 1.1248303651809692\n",
      "Starting Epoch 294\n",
      "1.0651448518037796\n",
      "Validation loss: 1.125868320465088\n",
      "mse 1.1258683520055983\n",
      "Starting Epoch 295\n",
      "1.0649516358971596\n",
      "Validation loss: 1.125164270401001\n",
      "mse 1.1251642607766033\n",
      "Starting Epoch 296\n",
      "1.0643616194526355\n",
      "Validation loss: 1.1246658563613892\n",
      "mse 1.1246659402499115\n",
      "New best model found at epoch 296 with validation loss 1.1246658563613892\n",
      "Starting Epoch 297\n",
      "1.0640271628896396\n",
      "Validation loss: 1.124808430671692\n",
      "mse 1.1248084928200572\n",
      "Starting Epoch 298\n",
      "1.0638026247421901\n",
      "Validation loss: 1.1245379447937012\n",
      "mse 1.1245379035406977\n",
      "New best model found at epoch 298 with validation loss 1.1245379447937012\n",
      "Starting Epoch 299\n",
      "1.063540096084277\n",
      "Validation loss: 1.1250362396240234\n",
      "mse 1.1250362932043239\n",
      "Starting Epoch 300\n",
      "1.0632278472185135\n",
      "Validation loss: 1.1241343021392822\n",
      "mse 1.1241342054648833\n",
      "New best model found at epoch 300 with validation loss 1.1241343021392822\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-80-50-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "fe5c918e-67e8-48b7-a9f6-90073cee2768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.789418</td>\n",
       "      <td>0.730049</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.579022</td>\n",
       "      <td>0.390659</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>0.612816</td>\n",
       "      <td>0.433778</td>\n",
       "      <td>0.79668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.584555</td>\n",
       "      <td>0.392098</td>\n",
       "      <td>0.817131</td>\n",
       "      <td>0.61371</td>\n",
       "      <td>0.435071</td>\n",
       "      <td>0.796384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>2.323296</td>\n",
       "      <td>0.907326</td>\n",
       "      <td>0.273192</td>\n",
       "      <td>2.371142</td>\n",
       "      <td>0.929039</td>\n",
       "      <td>0.213305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.778288</td>\n",
       "      <td>0.719919</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>1.81521</td>\n",
       "      <td>0.749433</td>\n",
       "      <td>0.397751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.612341</td>\n",
       "      <td>0.692069</td>\n",
       "      <td>0.495604</td>\n",
       "      <td>1.666438</td>\n",
       "      <td>0.727603</td>\n",
       "      <td>0.447111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-1</th>\n",
       "      <td>1.386030</td>\n",
       "      <td>0.840528</td>\n",
       "      <td>0.566402</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-1</th>\n",
       "      <td>1.511389</td>\n",
       "      <td>0.875163</td>\n",
       "      <td>0.527185</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-1</th>\n",
       "      <td>1.442876</td>\n",
       "      <td>0.859189</td>\n",
       "      <td>0.548618</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-1</th>\n",
       "      <td>1.343067</td>\n",
       "      <td>0.821639</td>\n",
       "      <td>0.579842</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-1</th>\n",
       "      <td>1.347905</td>\n",
       "      <td>0.820918</td>\n",
       "      <td>0.578329</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-1</th>\n",
       "      <td>1.388511</td>\n",
       "      <td>0.829501</td>\n",
       "      <td>0.565625</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-1</th>\n",
       "      <td>1.360229</td>\n",
       "      <td>0.822960</td>\n",
       "      <td>0.574473</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-1</th>\n",
       "      <td>1.273426</td>\n",
       "      <td>0.791052</td>\n",
       "      <td>0.601628</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-1</th>\n",
       "      <td>1.285886</td>\n",
       "      <td>0.801589</td>\n",
       "      <td>0.597730</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-1</th>\n",
       "      <td>1.255633</td>\n",
       "      <td>0.796268</td>\n",
       "      <td>0.607194</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-1</th>\n",
       "      <td>1.162645</td>\n",
       "      <td>0.744006</td>\n",
       "      <td>0.636284</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-1</th>\n",
       "      <td>1.183051</td>\n",
       "      <td>0.745964</td>\n",
       "      <td>0.629900</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-1</th>\n",
       "      <td>1.124134</td>\n",
       "      <td>0.712487</td>\n",
       "      <td>0.648332</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN             0.673141  0.442646  0.789418  0.730049  0.478475  0.757785\n",
       "Decision tree    0.579022  0.390659  0.818862  0.612816  0.433778   0.79668\n",
       "Random forest    0.584555  0.392098  0.817131   0.61371  0.435071  0.796384\n",
       "SVM linear       2.323296  0.907326  0.273192  2.371142  0.929039  0.213305\n",
       "SVM poly         1.778288  0.719919  0.443690   1.81521  0.749433  0.397751\n",
       "SVM rbf          1.612341  0.692069  0.495604  1.666438  0.727603  0.447111\n",
       "MLP: 17-5-1      1.386030  0.840528  0.566402         -         -         -\n",
       "MLP: 17-10-1     1.511389  0.875163  0.527185         -         -         -\n",
       "MLP: 17-20-1     1.442876  0.859189  0.548618         -         -         -\n",
       "MLP: 17-25-1     1.343067  0.821639  0.579842         -         -         -\n",
       "MLP: 17-40-1     1.347905  0.820918  0.578329         -         -         -\n",
       "MLP: 17-60-1     1.388511  0.829501  0.565625         -         -         -\n",
       "MLP: 17-10-5-1   1.360229  0.822960  0.574473         -         -         -\n",
       "MLP: 17-20-10-1  1.273426  0.791052  0.601628         -         -         -\n",
       "MLP: 17-40-20-1  1.285886  0.801589  0.597730         -         -         -\n",
       "MLP: 17-40-10-1  1.255633  0.796268  0.607194         -         -         -\n",
       "MLP: 17-60-40-1  1.162645  0.744006  0.636284         -         -         -\n",
       "MLP: 17-60-20-1  1.183051  0.745964  0.629900         -         -         -\n",
       "MLP: 17-80-50-1  1.124134  0.712487  0.648332         -         -         -"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc2ad6-88d6-488d-a023-cf626d9e4cc7",
   "metadata": {},
   "source": [
    "best performing model until now: 4 layers, 17-80-50-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2d146-889f-477a-a40e-52cf1fd0e002",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "09470076-34c0-4851-9342-98074d61b0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "89b6c3a3-866b-4b4d-8b35-39fd55a271fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,9,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9bb38635-730a-4728-92fd-6beb6b6ed92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'median(container counts)', 'median(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "5acc06e5-d693-4287-9b6b-1097338ccce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "774cb0f4-1718-4ff1-8d44-32fd9d0551f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.6472993989785514\n",
      "Validation loss: 1.9968913793563843\n",
      "mse 1.9968914136754483\n",
      "New best model found at epoch 1 with validation loss 1.9968913793563843\n",
      "Starting Epoch 2\n",
      "1.9894902010758717\n",
      "Validation loss: 1.8401508331298828\n",
      "mse 1.8401510075798675\n",
      "New best model found at epoch 2 with validation loss 1.8401508331298828\n",
      "Starting Epoch 3\n",
      "1.8970474700133007\n",
      "Validation loss: 1.7730885744094849\n",
      "mse 1.7730885820326259\n",
      "New best model found at epoch 3 with validation loss 1.7730885744094849\n",
      "Starting Epoch 4\n",
      "1.8472682336966197\n",
      "Validation loss: 1.7346312999725342\n",
      "mse 1.734631379787103\n",
      "New best model found at epoch 4 with validation loss 1.7346312999725342\n",
      "Starting Epoch 5\n",
      "1.8147960503896077\n",
      "Validation loss: 1.7114273309707642\n",
      "mse 1.7114274478902336\n",
      "New best model found at epoch 5 with validation loss 1.7114273309707642\n",
      "Starting Epoch 6\n",
      "1.789401352405548\n",
      "Validation loss: 1.6940410137176514\n",
      "mse 1.69404093761719\n",
      "New best model found at epoch 6 with validation loss 1.6940410137176514\n",
      "Starting Epoch 7\n",
      "1.7685555269320805\n",
      "Validation loss: 1.6782459020614624\n",
      "mse 1.678245770693929\n",
      "New best model found at epoch 7 with validation loss 1.6782459020614624\n",
      "Starting Epoch 8\n",
      "1.7509291569391887\n",
      "Validation loss: 1.6655497550964355\n",
      "mse 1.665549675087697\n",
      "New best model found at epoch 8 with validation loss 1.6655497550964355\n",
      "Starting Epoch 9\n",
      "1.7363001704216003\n",
      "Validation loss: 1.6560285091400146\n",
      "mse 1.6560285510545036\n",
      "New best model found at epoch 9 with validation loss 1.6560285091400146\n",
      "Starting Epoch 10\n",
      "1.7242063681284587\n",
      "Validation loss: 1.6478114128112793\n",
      "mse 1.647811469450768\n",
      "New best model found at epoch 10 with validation loss 1.6478114128112793\n",
      "Starting Epoch 11\n",
      "1.7137409150600433\n",
      "Validation loss: 1.639586091041565\n",
      "mse 1.6395861050210432\n",
      "New best model found at epoch 11 with validation loss 1.639586091041565\n",
      "Starting Epoch 12\n",
      "1.7040703296661377\n",
      "Validation loss: 1.6335011720657349\n",
      "mse 1.6335012659829622\n",
      "New best model found at epoch 12 with validation loss 1.6335011720657349\n",
      "Starting Epoch 13\n",
      "1.6949013322591782\n",
      "Validation loss: 1.6269625425338745\n",
      "mse 1.6269625778467642\n",
      "New best model found at epoch 13 with validation loss 1.6269625425338745\n",
      "Starting Epoch 14\n",
      "1.686502456665039\n",
      "Validation loss: 1.6209224462509155\n",
      "mse 1.620922455152167\n",
      "New best model found at epoch 14 with validation loss 1.6209224462509155\n",
      "Starting Epoch 15\n",
      "1.678547700246175\n",
      "Validation loss: 1.6158406734466553\n",
      "mse 1.615840596518693\n",
      "New best model found at epoch 15 with validation loss 1.6158406734466553\n",
      "Starting Epoch 16\n",
      "1.6708299865325291\n",
      "Validation loss: 1.6098101139068604\n",
      "mse 1.6098101252243728\n",
      "New best model found at epoch 16 with validation loss 1.6098101139068604\n",
      "Starting Epoch 17\n",
      "1.6635034034649532\n",
      "Validation loss: 1.6047313213348389\n",
      "mse 1.6047314135356467\n",
      "New best model found at epoch 17 with validation loss 1.6047313213348389\n",
      "Starting Epoch 18\n",
      "1.656449134151141\n",
      "Validation loss: 1.5989302396774292\n",
      "mse 1.5989303439443567\n",
      "New best model found at epoch 18 with validation loss 1.5989302396774292\n",
      "Starting Epoch 19\n",
      "1.6494835019111633\n",
      "Validation loss: 1.595228672027588\n",
      "mse 1.595228762482921\n",
      "New best model found at epoch 19 with validation loss 1.595228672027588\n",
      "Starting Epoch 20\n",
      "1.6424932877222698\n",
      "Validation loss: 1.590105652809143\n",
      "mse 1.5901055965114599\n",
      "New best model found at epoch 20 with validation loss 1.590105652809143\n",
      "Starting Epoch 21\n",
      "1.6360716074705124\n",
      "Validation loss: 1.5865851640701294\n",
      "mse 1.5865852226279762\n",
      "New best model found at epoch 21 with validation loss 1.5865851640701294\n",
      "Starting Epoch 22\n",
      "1.6296282708644867\n",
      "Validation loss: 1.582872986793518\n",
      "mse 1.5828728963506742\n",
      "New best model found at epoch 22 with validation loss 1.582872986793518\n",
      "Starting Epoch 23\n",
      "1.6237636903921764\n",
      "Validation loss: 1.578754186630249\n",
      "mse 1.5787543307820524\n",
      "New best model found at epoch 23 with validation loss 1.578754186630249\n",
      "Starting Epoch 24\n",
      "1.6179399092992146\n",
      "Validation loss: 1.5753809213638306\n",
      "mse 1.5753808325492238\n",
      "New best model found at epoch 24 with validation loss 1.5753809213638306\n",
      "Starting Epoch 25\n",
      "1.6122800260782242\n",
      "Validation loss: 1.5711688995361328\n",
      "mse 1.571168888218509\n",
      "New best model found at epoch 25 with validation loss 1.5711688995361328\n",
      "Starting Epoch 26\n",
      "1.6055851876735687\n",
      "Validation loss: 1.5667555332183838\n",
      "mse 1.5667554019139307\n",
      "New best model found at epoch 26 with validation loss 1.5667555332183838\n",
      "Starting Epoch 27\n",
      "1.5999113619327545\n",
      "Validation loss: 1.5628516674041748\n",
      "mse 1.5628514962516717\n",
      "New best model found at epoch 27 with validation loss 1.5628516674041748\n",
      "Starting Epoch 28\n",
      "1.5945511261622112\n",
      "Validation loss: 1.5582714080810547\n",
      "mse 1.5582712958718379\n",
      "New best model found at epoch 28 with validation loss 1.5582714080810547\n",
      "Starting Epoch 29\n",
      "1.5890445510546367\n",
      "Validation loss: 1.5554453134536743\n",
      "mse 1.5554452122823474\n",
      "New best model found at epoch 29 with validation loss 1.5554453134536743\n",
      "Starting Epoch 30\n",
      "1.583944524327914\n",
      "Validation loss: 1.5520931482315063\n",
      "mse 1.552093027166931\n",
      "New best model found at epoch 30 with validation loss 1.5520931482315063\n",
      "Starting Epoch 31\n",
      "1.5786351710557938\n",
      "Validation loss: 1.5482527017593384\n",
      "mse 1.548252757177469\n",
      "New best model found at epoch 31 with validation loss 1.5482527017593384\n",
      "Starting Epoch 32\n",
      "1.5737753063440323\n",
      "Validation loss: 1.545277714729309\n",
      "mse 1.5452778210145797\n",
      "New best model found at epoch 32 with validation loss 1.545277714729309\n",
      "Starting Epoch 33\n",
      "1.5690133422613144\n",
      "Validation loss: 1.541327953338623\n",
      "mse 1.5413278788948606\n",
      "New best model found at epoch 33 with validation loss 1.541327953338623\n",
      "Starting Epoch 34\n",
      "1.5642241835594177\n",
      "Validation loss: 1.5387102365493774\n",
      "mse 1.5387102347969135\n",
      "New best model found at epoch 34 with validation loss 1.5387102365493774\n",
      "Starting Epoch 35\n",
      "1.5598694185415904\n",
      "Validation loss: 1.5343513488769531\n",
      "mse 1.534351358455021\n",
      "New best model found at epoch 35 with validation loss 1.5343513488769531\n",
      "Starting Epoch 36\n",
      "1.5551184167464573\n",
      "Validation loss: 1.5320569276809692\n",
      "mse 1.532056910711407\n",
      "New best model found at epoch 36 with validation loss 1.5320569276809692\n",
      "Starting Epoch 37\n",
      "1.5507553120454152\n",
      "Validation loss: 1.5291414260864258\n",
      "mse 1.5291414127356577\n",
      "New best model found at epoch 37 with validation loss 1.5291414260864258\n",
      "Starting Epoch 38\n",
      "1.5468267401059468\n",
      "Validation loss: 1.5259795188903809\n",
      "mse 1.5259795498032704\n",
      "New best model found at epoch 38 with validation loss 1.5259795188903809\n",
      "Starting Epoch 39\n",
      "1.5428054680426915\n",
      "Validation loss: 1.5231355428695679\n",
      "mse 1.523135660255764\n",
      "New best model found at epoch 39 with validation loss 1.5231355428695679\n",
      "Starting Epoch 40\n",
      "1.538785681128502\n",
      "Validation loss: 1.519521713256836\n",
      "mse 1.5195217247452537\n",
      "New best model found at epoch 40 with validation loss 1.519521713256836\n",
      "Starting Epoch 41\n",
      "1.5348057945569356\n",
      "Validation loss: 1.5176385641098022\n",
      "mse 1.5176385136504347\n",
      "New best model found at epoch 41 with validation loss 1.5176385641098022\n",
      "Starting Epoch 42\n",
      "1.531003435452779\n",
      "Validation loss: 1.5146538019180298\n",
      "mse 1.5146537980513015\n",
      "New best model found at epoch 42 with validation loss 1.5146538019180298\n",
      "Starting Epoch 43\n",
      "1.5276366074879963\n",
      "Validation loss: 1.511474370956421\n",
      "mse 1.5114744442185541\n",
      "New best model found at epoch 43 with validation loss 1.511474370956421\n",
      "Starting Epoch 44\n",
      "1.5240816126267116\n",
      "Validation loss: 1.508636236190796\n",
      "mse 1.508636232120442\n",
      "New best model found at epoch 44 with validation loss 1.508636236190796\n",
      "Starting Epoch 45\n",
      "1.520650178194046\n",
      "Validation loss: 1.5060726404190063\n",
      "mse 1.5060726221421041\n",
      "New best model found at epoch 45 with validation loss 1.5060726404190063\n",
      "Starting Epoch 46\n",
      "1.5172164837519329\n",
      "Validation loss: 1.5035618543624878\n",
      "mse 1.5035619442557835\n",
      "New best model found at epoch 46 with validation loss 1.5035618543624878\n",
      "Starting Epoch 47\n",
      "1.5139216681321461\n",
      "Validation loss: 1.500836730003357\n",
      "mse 1.5008368311804523\n",
      "New best model found at epoch 47 with validation loss 1.500836730003357\n",
      "Starting Epoch 48\n",
      "1.5106817732254665\n",
      "Validation loss: 1.4980159997940063\n",
      "mse 1.4980158803796633\n",
      "New best model found at epoch 48 with validation loss 1.4980159997940063\n",
      "Starting Epoch 49\n",
      "1.5074548870325089\n",
      "Validation loss: 1.4946776628494263\n",
      "mse 1.4946777837598526\n",
      "New best model found at epoch 49 with validation loss 1.4946776628494263\n",
      "Starting Epoch 50\n",
      "1.5042994270722072\n",
      "Validation loss: 1.4924581050872803\n",
      "mse 1.492458159714437\n",
      "New best model found at epoch 50 with validation loss 1.4924581050872803\n",
      "Starting Epoch 51\n",
      "1.5014328807592392\n",
      "Validation loss: 1.489367127418518\n",
      "mse 1.4893671336249086\n",
      "New best model found at epoch 51 with validation loss 1.489367127418518\n",
      "Starting Epoch 52\n",
      "1.4982350965340931\n",
      "Validation loss: 1.4870606660842896\n",
      "mse 1.487060594610256\n",
      "New best model found at epoch 52 with validation loss 1.4870606660842896\n",
      "Starting Epoch 53\n",
      "1.4951859762271245\n",
      "Validation loss: 1.4845263957977295\n",
      "mse 1.4845263667340944\n",
      "New best model found at epoch 53 with validation loss 1.4845263957977295\n",
      "Starting Epoch 54\n",
      "1.4923856208721797\n",
      "Validation loss: 1.4821995496749878\n",
      "mse 1.4821995525242015\n",
      "New best model found at epoch 54 with validation loss 1.4821995496749878\n",
      "Starting Epoch 55\n",
      "1.489534189303716\n",
      "Validation loss: 1.4791803359985352\n",
      "mse 1.479180346524983\n",
      "New best model found at epoch 55 with validation loss 1.4791803359985352\n",
      "Starting Epoch 56\n",
      "1.486629992723465\n",
      "Validation loss: 1.477343201637268\n",
      "mse 1.4773433311213673\n",
      "New best model found at epoch 56 with validation loss 1.477343201637268\n",
      "Starting Epoch 57\n",
      "1.4839284370342891\n",
      "Validation loss: 1.475024700164795\n",
      "mse 1.475024745755326\n",
      "New best model found at epoch 57 with validation loss 1.475024700164795\n",
      "Starting Epoch 58\n",
      "1.4812057663997014\n",
      "Validation loss: 1.4729455709457397\n",
      "mse 1.4729455335459358\n",
      "New best model found at epoch 58 with validation loss 1.4729455709457397\n",
      "Starting Epoch 59\n",
      "1.4786810924609501\n",
      "Validation loss: 1.4705777168273926\n",
      "mse 1.4705777012123684\n",
      "New best model found at epoch 59 with validation loss 1.4705777168273926\n",
      "Starting Epoch 60\n",
      "1.4761450241009395\n",
      "Validation loss: 1.4680896997451782\n",
      "mse 1.4680897502713603\n",
      "New best model found at epoch 60 with validation loss 1.4680896997451782\n",
      "Starting Epoch 61\n",
      "1.473712166150411\n",
      "Validation loss: 1.4652860164642334\n",
      "mse 1.4652860046505345\n",
      "New best model found at epoch 61 with validation loss 1.4652860164642334\n",
      "Starting Epoch 62\n",
      "1.4712123423814774\n",
      "Validation loss: 1.4621940851211548\n",
      "mse 1.4621940396633706\n",
      "New best model found at epoch 62 with validation loss 1.4621940851211548\n",
      "Starting Epoch 63\n",
      "1.4686320076386135\n",
      "Validation loss: 1.4607752561569214\n",
      "mse 1.4607752459731083\n",
      "New best model found at epoch 63 with validation loss 1.4607752561569214\n",
      "Starting Epoch 64\n",
      "1.4663718342781067\n",
      "Validation loss: 1.459235429763794\n",
      "mse 1.4592354222148538\n",
      "New best model found at epoch 64 with validation loss 1.459235429763794\n",
      "Starting Epoch 65\n",
      "1.4641851584116619\n",
      "Validation loss: 1.4562416076660156\n",
      "mse 1.4562416671983223\n",
      "New best model found at epoch 65 with validation loss 1.4562416076660156\n",
      "Starting Epoch 66\n",
      "1.4617099861303966\n",
      "Validation loss: 1.4548766613006592\n",
      "mse 1.454876600865948\n",
      "New best model found at epoch 66 with validation loss 1.4548766613006592\n",
      "Starting Epoch 67\n",
      "1.4595125714937847\n",
      "Validation loss: 1.452964425086975\n",
      "mse 1.4529642881288207\n",
      "New best model found at epoch 67 with validation loss 1.452964425086975\n",
      "Starting Epoch 68\n",
      "1.4571881542603176\n",
      "Validation loss: 1.4508811235427856\n",
      "mse 1.45088114725237\n",
      "New best model found at epoch 68 with validation loss 1.4508811235427856\n",
      "Starting Epoch 69\n",
      "1.4551783551772435\n",
      "Validation loss: 1.4480823278427124\n",
      "mse 1.4480823036155448\n",
      "New best model found at epoch 69 with validation loss 1.4480823278427124\n",
      "Starting Epoch 70\n",
      "1.45310111840566\n",
      "Validation loss: 1.446617603302002\n",
      "mse 1.4466175346661094\n",
      "New best model found at epoch 70 with validation loss 1.446617603302002\n",
      "Starting Epoch 71\n",
      "1.4507585068543751\n",
      "Validation loss: 1.4448785781860352\n",
      "mse 1.4448785918790257\n",
      "New best model found at epoch 71 with validation loss 1.4448785781860352\n",
      "Starting Epoch 72\n",
      "1.448922023177147\n",
      "Validation loss: 1.4423811435699463\n",
      "mse 1.4423810585452495\n",
      "New best model found at epoch 72 with validation loss 1.4423811435699463\n",
      "Starting Epoch 73\n",
      "1.4466474652290344\n",
      "Validation loss: 1.440735936164856\n",
      "mse 1.4407357991330585\n",
      "New best model found at epoch 73 with validation loss 1.440735936164856\n",
      "Starting Epoch 74\n",
      "1.444684440890948\n",
      "Validation loss: 1.4392468929290771\n",
      "mse 1.4392468752489203\n",
      "New best model found at epoch 74 with validation loss 1.4392468929290771\n",
      "Starting Epoch 75\n",
      "1.4427316685517628\n",
      "Validation loss: 1.4377899169921875\n",
      "mse 1.4377900840003317\n",
      "New best model found at epoch 75 with validation loss 1.4377899169921875\n",
      "Starting Epoch 76\n",
      "1.440874030192693\n",
      "Validation loss: 1.4364076852798462\n",
      "mse 1.4364076429707133\n",
      "New best model found at epoch 76 with validation loss 1.4364076852798462\n",
      "Starting Epoch 77\n",
      "1.439111848672231\n",
      "Validation loss: 1.4347354173660278\n",
      "mse 1.4347354160040517\n",
      "New best model found at epoch 77 with validation loss 1.4347354173660278\n",
      "Starting Epoch 78\n",
      "1.4372677927215893\n",
      "Validation loss: 1.432852864265442\n",
      "mse 1.4328527355244605\n",
      "New best model found at epoch 78 with validation loss 1.432852864265442\n",
      "Starting Epoch 79\n",
      "1.4352024793624878\n",
      "Validation loss: 1.431287407875061\n",
      "mse 1.4312873036207576\n",
      "New best model found at epoch 79 with validation loss 1.431287407875061\n",
      "Starting Epoch 80\n",
      "1.4334262212117512\n",
      "Validation loss: 1.4292593002319336\n",
      "mse 1.4292593394863962\n",
      "New best model found at epoch 80 with validation loss 1.4292593002319336\n",
      "Starting Epoch 81\n",
      "1.4314219032724698\n",
      "Validation loss: 1.4282140731811523\n",
      "mse 1.4282141351820623\n",
      "New best model found at epoch 81 with validation loss 1.4282140731811523\n",
      "Starting Epoch 82\n",
      "1.4300067623456318\n",
      "Validation loss: 1.4257386922836304\n",
      "mse 1.4257385744276978\n",
      "New best model found at epoch 82 with validation loss 1.4257386922836304\n",
      "Starting Epoch 83\n",
      "1.4281198754906654\n",
      "Validation loss: 1.4241664409637451\n",
      "mse 1.4241662353441882\n",
      "New best model found at epoch 83 with validation loss 1.4241664409637451\n",
      "Starting Epoch 84\n",
      "1.4266266425450642\n",
      "Validation loss: 1.423740029335022\n",
      "mse 1.4237401463425692\n",
      "New best model found at epoch 84 with validation loss 1.423740029335022\n",
      "Starting Epoch 85\n",
      "1.4252218802769978\n",
      "Validation loss: 1.4214012622833252\n",
      "mse 1.421401252566108\n",
      "New best model found at epoch 85 with validation loss 1.4214012622833252\n",
      "Starting Epoch 86\n",
      "1.423481027285258\n",
      "Validation loss: 1.4201563596725464\n",
      "mse 1.420156438041585\n",
      "New best model found at epoch 86 with validation loss 1.4201563596725464\n",
      "Starting Epoch 87\n",
      "1.421818733215332\n",
      "Validation loss: 1.4195395708084106\n",
      "mse 1.4195395381554758\n",
      "New best model found at epoch 87 with validation loss 1.4195395708084106\n",
      "Starting Epoch 88\n",
      "1.4204371521870296\n",
      "Validation loss: 1.4176431894302368\n",
      "mse 1.417643218044088\n",
      "New best model found at epoch 88 with validation loss 1.4176431894302368\n",
      "Starting Epoch 89\n",
      "1.4189497232437134\n",
      "Validation loss: 1.4164886474609375\n",
      "mse 1.4164885702439949\n",
      "New best model found at epoch 89 with validation loss 1.4164886474609375\n",
      "Starting Epoch 90\n",
      "1.4173268303275108\n",
      "Validation loss: 1.4152225255966187\n",
      "mse 1.4152224538145002\n",
      "New best model found at epoch 90 with validation loss 1.4152225255966187\n",
      "Starting Epoch 91\n",
      "1.4159709339340527\n",
      "Validation loss: 1.4134495258331299\n",
      "mse 1.4134495734637627\n",
      "New best model found at epoch 91 with validation loss 1.4134495258331299\n",
      "Starting Epoch 92\n",
      "1.4144572615623474\n",
      "Validation loss: 1.4123212099075317\n",
      "mse 1.4123211578664743\n",
      "New best model found at epoch 92 with validation loss 1.4123212099075317\n",
      "Starting Epoch 93\n",
      "1.41301429271698\n",
      "Validation loss: 1.4112021923065186\n",
      "mse 1.4112023095791757\n",
      "New best model found at epoch 93 with validation loss 1.4112021923065186\n",
      "Starting Epoch 94\n",
      "1.4115232552091281\n",
      "Validation loss: 1.4101148843765259\n",
      "mse 1.4101149280089507\n",
      "New best model found at epoch 94 with validation loss 1.4101148843765259\n",
      "Starting Epoch 95\n",
      "1.409968229631583\n",
      "Validation loss: 1.408275842666626\n",
      "mse 1.4082757768087248\n",
      "New best model found at epoch 95 with validation loss 1.408275842666626\n",
      "Starting Epoch 96\n",
      "1.4085552940766017\n",
      "Validation loss: 1.4076653718948364\n",
      "mse 1.4076653234302563\n",
      "New best model found at epoch 96 with validation loss 1.4076653718948364\n",
      "Starting Epoch 97\n",
      "1.4072482238213222\n",
      "Validation loss: 1.4064925909042358\n",
      "mse 1.406492591549836\n",
      "New best model found at epoch 97 with validation loss 1.4064925909042358\n",
      "Starting Epoch 98\n",
      "1.4060298229257266\n",
      "Validation loss: 1.4051477909088135\n",
      "mse 1.4051477368277945\n",
      "New best model found at epoch 98 with validation loss 1.4051477909088135\n",
      "Starting Epoch 99\n",
      "1.4048094550768535\n",
      "Validation loss: 1.4039560556411743\n",
      "mse 1.4039561237400333\n",
      "New best model found at epoch 99 with validation loss 1.4039560556411743\n",
      "Starting Epoch 100\n",
      "1.4035788774490356\n",
      "Validation loss: 1.4020957946777344\n",
      "mse 1.402095641744583\n",
      "New best model found at epoch 100 with validation loss 1.4020957946777344\n",
      "Starting Epoch 101\n",
      "1.4023824632167816\n",
      "Validation loss: 1.4014537334442139\n",
      "mse 1.4014537252726338\n",
      "New best model found at epoch 101 with validation loss 1.4014537334442139\n",
      "Starting Epoch 102\n",
      "1.4010825504859288\n",
      "Validation loss: 1.400012731552124\n",
      "mse 1.4000127303583918\n",
      "New best model found at epoch 102 with validation loss 1.400012731552124\n",
      "Starting Epoch 103\n",
      "1.3999482095241547\n",
      "Validation loss: 1.399132490158081\n",
      "mse 1.3991326217823077\n",
      "New best model found at epoch 103 with validation loss 1.399132490158081\n",
      "Starting Epoch 104\n",
      "1.398807128270467\n",
      "Validation loss: 1.3979109525680542\n",
      "mse 1.3979110080592496\n",
      "New best model found at epoch 104 with validation loss 1.3979109525680542\n",
      "Starting Epoch 105\n",
      "1.397749255100886\n",
      "Validation loss: 1.3971017599105835\n",
      "mse 1.3971015537682792\n",
      "New best model found at epoch 105 with validation loss 1.3971017599105835\n",
      "Starting Epoch 106\n",
      "1.396656649808089\n",
      "Validation loss: 1.395864486694336\n",
      "mse 1.3958644744202424\n",
      "New best model found at epoch 106 with validation loss 1.395864486694336\n",
      "Starting Epoch 107\n",
      "1.3955510209004085\n",
      "Validation loss: 1.3951945304870605\n",
      "mse 1.3951945906070777\n",
      "New best model found at epoch 107 with validation loss 1.3951945304870605\n",
      "Starting Epoch 108\n",
      "1.39433137824138\n",
      "Validation loss: 1.393910527229309\n",
      "mse 1.3939104288807935\n",
      "New best model found at epoch 108 with validation loss 1.393910527229309\n",
      "Starting Epoch 109\n",
      "1.3933495605985324\n",
      "Validation loss: 1.392835021018982\n",
      "mse 1.3928349973585006\n",
      "New best model found at epoch 109 with validation loss 1.392835021018982\n",
      "Starting Epoch 110\n",
      "1.3921549593408902\n",
      "Validation loss: 1.3918814659118652\n",
      "mse 1.3918814642215518\n",
      "New best model found at epoch 110 with validation loss 1.3918814659118652\n",
      "Starting Epoch 111\n",
      "1.391032598912716\n",
      "Validation loss: 1.391177773475647\n",
      "mse 1.391177794722892\n",
      "New best model found at epoch 111 with validation loss 1.391177773475647\n",
      "Starting Epoch 112\n",
      "1.38997316857179\n",
      "Validation loss: 1.3897796869277954\n",
      "mse 1.3897795178898278\n",
      "New best model found at epoch 112 with validation loss 1.3897796869277954\n",
      "Starting Epoch 113\n",
      "1.389146938920021\n",
      "Validation loss: 1.3885258436203003\n",
      "mse 1.3885258709460842\n",
      "New best model found at epoch 113 with validation loss 1.3885258436203003\n",
      "Starting Epoch 114\n",
      "1.3881107966105144\n",
      "Validation loss: 1.3873573541641235\n",
      "mse 1.3873572889233463\n",
      "New best model found at epoch 114 with validation loss 1.3873573541641235\n",
      "Starting Epoch 115\n",
      "1.3869512006640434\n",
      "Validation loss: 1.3867672681808472\n",
      "mse 1.3867671884147703\n",
      "New best model found at epoch 115 with validation loss 1.3867672681808472\n",
      "Starting Epoch 116\n",
      "1.3859531333049138\n",
      "Validation loss: 1.3852689266204834\n",
      "mse 1.3852689506377291\n",
      "New best model found at epoch 116 with validation loss 1.3852689266204834\n",
      "Starting Epoch 117\n",
      "1.3848914032181103\n",
      "Validation loss: 1.3843698501586914\n",
      "mse 1.3843698338392314\n",
      "New best model found at epoch 117 with validation loss 1.3843698501586914\n",
      "Starting Epoch 118\n",
      "1.3838387951254845\n",
      "Validation loss: 1.3836153745651245\n",
      "mse 1.3836153888136025\n",
      "New best model found at epoch 118 with validation loss 1.3836153745651245\n",
      "Starting Epoch 119\n",
      "1.3828143998980522\n",
      "Validation loss: 1.3821152448654175\n",
      "mse 1.3821152358981261\n",
      "New best model found at epoch 119 with validation loss 1.3821152448654175\n",
      "Starting Epoch 120\n",
      "1.3816901023189228\n",
      "Validation loss: 1.3820080757141113\n",
      "mse 1.3820080704492725\n",
      "New best model found at epoch 120 with validation loss 1.3820080757141113\n",
      "Starting Epoch 121\n",
      "1.3808611631393433\n",
      "Validation loss: 1.3803995847702026\n",
      "mse 1.3803994746311818\n",
      "New best model found at epoch 121 with validation loss 1.3803995847702026\n",
      "Starting Epoch 122\n",
      "1.3798355733354886\n",
      "Validation loss: 1.3795232772827148\n",
      "mse 1.3795232413777276\n",
      "New best model found at epoch 122 with validation loss 1.3795232772827148\n",
      "Starting Epoch 123\n",
      "1.378821738064289\n",
      "Validation loss: 1.3782546520233154\n",
      "mse 1.3782545478544566\n",
      "New best model found at epoch 123 with validation loss 1.3782546520233154\n",
      "Starting Epoch 124\n",
      "1.377826268474261\n",
      "Validation loss: 1.3775213956832886\n",
      "mse 1.377521384709672\n",
      "New best model found at epoch 124 with validation loss 1.3775213956832886\n",
      "Starting Epoch 125\n",
      "1.3769900972644489\n",
      "Validation loss: 1.3765778541564941\n",
      "mse 1.3765779421673354\n",
      "New best model found at epoch 125 with validation loss 1.3765778541564941\n",
      "Starting Epoch 126\n",
      "1.3760082423686981\n",
      "Validation loss: 1.3767250776290894\n",
      "mse 1.3767250034291847\n",
      "Starting Epoch 127\n",
      "1.3751223559180896\n",
      "Validation loss: 1.3755496740341187\n",
      "mse 1.3755497284855565\n",
      "New best model found at epoch 127 with validation loss 1.3755496740341187\n",
      "Starting Epoch 128\n",
      "1.3743855580687523\n",
      "Validation loss: 1.3751134872436523\n",
      "mse 1.375113591064726\n",
      "New best model found at epoch 128 with validation loss 1.3751134872436523\n",
      "Starting Epoch 129\n",
      "1.3734239960710208\n",
      "Validation loss: 1.3746535778045654\n",
      "mse 1.374653469626369\n",
      "New best model found at epoch 129 with validation loss 1.3746535778045654\n",
      "Starting Epoch 130\n",
      "1.3725777765115101\n",
      "Validation loss: 1.3737629652023315\n",
      "mse 1.373762917569519\n",
      "New best model found at epoch 130 with validation loss 1.3737629652023315\n",
      "Starting Epoch 131\n",
      "1.3716985036929448\n",
      "Validation loss: 1.3735688924789429\n",
      "mse 1.373568763336811\n",
      "New best model found at epoch 131 with validation loss 1.3735688924789429\n",
      "Starting Epoch 132\n",
      "1.370935653646787\n",
      "Validation loss: 1.3723115921020508\n",
      "mse 1.3723115557376717\n",
      "New best model found at epoch 132 with validation loss 1.3723115921020508\n",
      "Starting Epoch 133\n",
      "1.3700743193427722\n",
      "Validation loss: 1.3715370893478394\n",
      "mse 1.371537128400606\n",
      "New best model found at epoch 133 with validation loss 1.3715370893478394\n",
      "Starting Epoch 134\n",
      "1.3694443454345067\n",
      "Validation loss: 1.3713903427124023\n",
      "mse 1.3713903600593604\n",
      "New best model found at epoch 134 with validation loss 1.3713903427124023\n",
      "Starting Epoch 135\n",
      "1.3685936629772186\n",
      "Validation loss: 1.3701045513153076\n",
      "mse 1.370104540216968\n",
      "New best model found at epoch 135 with validation loss 1.3701045513153076\n",
      "Starting Epoch 136\n",
      "1.3679050331314404\n",
      "Validation loss: 1.3695071935653687\n",
      "mse 1.3695072529438774\n",
      "New best model found at epoch 136 with validation loss 1.3695071935653687\n",
      "Starting Epoch 137\n",
      "1.367083343366782\n",
      "Validation loss: 1.369210958480835\n",
      "mse 1.3692108443109172\n",
      "New best model found at epoch 137 with validation loss 1.369210958480835\n",
      "Starting Epoch 138\n",
      "1.3664182052016258\n",
      "Validation loss: 1.3679189682006836\n",
      "mse 1.3679189668734488\n",
      "New best model found at epoch 138 with validation loss 1.3679189682006836\n",
      "Starting Epoch 139\n",
      "1.3656899506847064\n",
      "Validation loss: 1.367231845855713\n",
      "mse 1.3672318936334225\n",
      "New best model found at epoch 139 with validation loss 1.367231845855713\n",
      "Starting Epoch 140\n",
      "1.3649061744411786\n",
      "Validation loss: 1.366695523262024\n",
      "mse 1.366695520829602\n",
      "New best model found at epoch 140 with validation loss 1.366695523262024\n",
      "Starting Epoch 141\n",
      "1.364177073041598\n",
      "Validation loss: 1.366095781326294\n",
      "mse 1.3660958569693629\n",
      "New best model found at epoch 141 with validation loss 1.366095781326294\n",
      "Starting Epoch 142\n",
      "1.363582710425059\n",
      "Validation loss: 1.3657972812652588\n",
      "mse 1.3657971134990128\n",
      "New best model found at epoch 142 with validation loss 1.3657972812652588\n",
      "Starting Epoch 143\n",
      "1.3628772422671318\n",
      "Validation loss: 1.3649311065673828\n",
      "mse 1.3649311425258275\n",
      "New best model found at epoch 143 with validation loss 1.3649311065673828\n",
      "Starting Epoch 144\n",
      "1.3621392821272214\n",
      "Validation loss: 1.3650615215301514\n",
      "mse 1.3650614933019956\n",
      "Starting Epoch 145\n",
      "1.3615785936514537\n",
      "Validation loss: 1.3638805150985718\n",
      "mse 1.3638804489175398\n",
      "New best model found at epoch 145 with validation loss 1.3638805150985718\n",
      "Starting Epoch 146\n",
      "1.3608077789346378\n",
      "Validation loss: 1.3634676933288574\n",
      "mse 1.3634675777348042\n",
      "New best model found at epoch 146 with validation loss 1.3634676933288574\n",
      "Starting Epoch 147\n",
      "1.3603009780248005\n",
      "Validation loss: 1.3629285097122192\n",
      "mse 1.3629284832627102\n",
      "New best model found at epoch 147 with validation loss 1.3629285097122192\n",
      "Starting Epoch 148\n",
      "1.359514442582925\n",
      "Validation loss: 1.362337350845337\n",
      "mse 1.3623374448658974\n",
      "New best model found at epoch 148 with validation loss 1.362337350845337\n",
      "Starting Epoch 149\n",
      "1.358795481423537\n",
      "Validation loss: 1.361649990081787\n",
      "mse 1.3616498438074827\n",
      "New best model found at epoch 149 with validation loss 1.361649990081787\n",
      "Starting Epoch 150\n",
      "1.3581434711813927\n",
      "Validation loss: 1.3609254360198975\n",
      "mse 1.3609255702615588\n",
      "New best model found at epoch 150 with validation loss 1.3609254360198975\n",
      "Starting Epoch 151\n",
      "1.3573844532171886\n",
      "Validation loss: 1.3602629899978638\n",
      "mse 1.3602630238915838\n",
      "New best model found at epoch 151 with validation loss 1.3602629899978638\n",
      "Starting Epoch 152\n",
      "1.356953077018261\n",
      "Validation loss: 1.3598734140396118\n",
      "mse 1.3598733090855517\n",
      "New best model found at epoch 152 with validation loss 1.3598734140396118\n",
      "Starting Epoch 153\n",
      "1.3562737256288528\n",
      "Validation loss: 1.3592662811279297\n",
      "mse 1.3592662453955424\n",
      "New best model found at epoch 153 with validation loss 1.3592662811279297\n",
      "Starting Epoch 154\n",
      "1.3556454951564472\n",
      "Validation loss: 1.3588937520980835\n",
      "mse 1.3588939327879919\n",
      "New best model found at epoch 154 with validation loss 1.3588937520980835\n",
      "Starting Epoch 155\n",
      "1.355043848355611\n",
      "Validation loss: 1.3583906888961792\n",
      "mse 1.3583907203523746\n",
      "New best model found at epoch 155 with validation loss 1.3583906888961792\n",
      "Starting Epoch 156\n",
      "1.3545484418670337\n",
      "Validation loss: 1.3575245141983032\n",
      "mse 1.357524414909725\n",
      "New best model found at epoch 156 with validation loss 1.3575245141983032\n",
      "Starting Epoch 157\n",
      "1.353854887187481\n",
      "Validation loss: 1.357334017753601\n",
      "mse 1.3573340583586104\n",
      "New best model found at epoch 157 with validation loss 1.357334017753601\n",
      "Starting Epoch 158\n",
      "1.3532660851875942\n",
      "Validation loss: 1.3571540117263794\n",
      "mse 1.3571538603934485\n",
      "New best model found at epoch 158 with validation loss 1.3571540117263794\n",
      "Starting Epoch 159\n",
      "1.352641721566518\n",
      "Validation loss: 1.355867624282837\n",
      "mse 1.3558677735229443\n",
      "New best model found at epoch 159 with validation loss 1.355867624282837\n",
      "Starting Epoch 160\n",
      "1.3518587698539097\n",
      "Validation loss: 1.3550145626068115\n",
      "mse 1.3550145558206814\n",
      "New best model found at epoch 160 with validation loss 1.3550145626068115\n",
      "Starting Epoch 161\n",
      "1.351060229043166\n",
      "Validation loss: 1.3536368608474731\n",
      "mse 1.3536367425768712\n",
      "New best model found at epoch 161 with validation loss 1.3536368608474731\n",
      "Starting Epoch 162\n",
      "1.35033983985583\n",
      "Validation loss: 1.352998971939087\n",
      "mse 1.352999054886298\n",
      "New best model found at epoch 162 with validation loss 1.352998971939087\n",
      "Starting Epoch 163\n",
      "1.3496551215648651\n",
      "Validation loss: 1.352994441986084\n",
      "mse 1.3529944496781656\n",
      "New best model found at epoch 163 with validation loss 1.352994441986084\n",
      "Starting Epoch 164\n",
      "1.349321263531844\n",
      "Validation loss: 1.3526986837387085\n",
      "mse 1.352698788068238\n",
      "New best model found at epoch 164 with validation loss 1.3526986837387085\n",
      "Starting Epoch 165\n",
      "1.3487423708041508\n",
      "Validation loss: 1.3527324199676514\n",
      "mse 1.3527323675330254\n",
      "Starting Epoch 166\n",
      "1.3480258708198865\n",
      "Validation loss: 1.3518906831741333\n",
      "mse 1.3518906587058153\n",
      "New best model found at epoch 166 with validation loss 1.3518906831741333\n",
      "Starting Epoch 167\n",
      "1.3476158330837886\n",
      "Validation loss: 1.351630449295044\n",
      "mse 1.3516305283607786\n",
      "New best model found at epoch 167 with validation loss 1.351630449295044\n",
      "Starting Epoch 168\n",
      "1.3469188064336777\n",
      "Validation loss: 1.3509905338287354\n",
      "mse 1.350990518472723\n",
      "New best model found at epoch 168 with validation loss 1.3509905338287354\n",
      "Starting Epoch 169\n",
      "1.3463944469889004\n",
      "Validation loss: 1.3504019975662231\n",
      "mse 1.3504021268671014\n",
      "New best model found at epoch 169 with validation loss 1.3504019975662231\n",
      "Starting Epoch 170\n",
      "1.3458666776617367\n",
      "Validation loss: 1.3505340814590454\n",
      "mse 1.3505340112623017\n",
      "Starting Epoch 171\n",
      "1.3452750990788143\n",
      "Validation loss: 1.3505046367645264\n",
      "mse 1.350504710359615\n",
      "Starting Epoch 172\n",
      "1.3447558879852295\n",
      "Validation loss: 1.3497220277786255\n",
      "mse 1.3497221069828342\n",
      "New best model found at epoch 172 with validation loss 1.3497220277786255\n",
      "Starting Epoch 173\n",
      "1.3442805310090382\n",
      "Validation loss: 1.3488013744354248\n",
      "mse 1.348801249838635\n",
      "New best model found at epoch 173 with validation loss 1.3488013744354248\n",
      "Starting Epoch 174\n",
      "1.3437308544913928\n",
      "Validation loss: 1.348716378211975\n",
      "mse 1.3487164158655427\n",
      "New best model found at epoch 174 with validation loss 1.348716378211975\n",
      "Starting Epoch 175\n",
      "1.343195987244447\n",
      "Validation loss: 1.3480594158172607\n",
      "mse 1.3480595177916568\n",
      "New best model found at epoch 175 with validation loss 1.3480594158172607\n",
      "Starting Epoch 176\n",
      "1.3426623493432999\n",
      "Validation loss: 1.3477932214736938\n",
      "mse 1.3477933787479124\n",
      "New best model found at epoch 176 with validation loss 1.3477932214736938\n",
      "Starting Epoch 177\n",
      "1.342227265238762\n",
      "Validation loss: 1.3473875522613525\n",
      "mse 1.3473875172127736\n",
      "New best model found at epoch 177 with validation loss 1.3473875522613525\n",
      "Starting Epoch 178\n",
      "1.3417415122191112\n",
      "Validation loss: 1.3469277620315552\n",
      "mse 1.3469276987693175\n",
      "New best model found at epoch 178 with validation loss 1.3469277620315552\n",
      "Starting Epoch 179\n",
      "1.3411987324555714\n",
      "Validation loss: 1.3467590808868408\n",
      "mse 1.3467589960683828\n",
      "New best model found at epoch 179 with validation loss 1.3467590808868408\n",
      "Starting Epoch 180\n",
      "1.3407495766878128\n",
      "Validation loss: 1.3460909128189087\n",
      "mse 1.346090824857094\n",
      "New best model found at epoch 180 with validation loss 1.3460909128189087\n",
      "Starting Epoch 181\n",
      "1.3402032107114792\n",
      "Validation loss: 1.3461734056472778\n",
      "mse 1.346173242164202\n",
      "Starting Epoch 182\n",
      "1.3397776583830516\n",
      "Validation loss: 1.3456332683563232\n",
      "mse 1.3456331628260998\n",
      "New best model found at epoch 182 with validation loss 1.3456332683563232\n",
      "Starting Epoch 183\n",
      "1.339323990046978\n",
      "Validation loss: 1.3453198671340942\n",
      "mse 1.345319925814719\n",
      "New best model found at epoch 183 with validation loss 1.3453198671340942\n",
      "Starting Epoch 184\n",
      "1.3388559371232986\n",
      "Validation loss: 1.344693660736084\n",
      "mse 1.344693695399\n",
      "New best model found at epoch 184 with validation loss 1.344693660736084\n",
      "Starting Epoch 185\n",
      "1.3383759756882985\n",
      "Validation loss: 1.3442574739456177\n",
      "mse 1.3442576116708458\n",
      "New best model found at epoch 185 with validation loss 1.3442574739456177\n",
      "Starting Epoch 186\n",
      "1.3378522197405498\n",
      "Validation loss: 1.3441672325134277\n",
      "mse 1.3441671684666547\n",
      "New best model found at epoch 186 with validation loss 1.3441672325134277\n",
      "Starting Epoch 187\n",
      "1.3375295301278431\n",
      "Validation loss: 1.3436918258666992\n",
      "mse 1.3436918848544173\n",
      "New best model found at epoch 187 with validation loss 1.3436918258666992\n",
      "Starting Epoch 188\n",
      "1.3370433847109477\n",
      "Validation loss: 1.3431411981582642\n",
      "mse 1.343141267996211\n",
      "New best model found at epoch 188 with validation loss 1.3431411981582642\n",
      "Starting Epoch 189\n",
      "1.33654938886563\n",
      "Validation loss: 1.3433607816696167\n",
      "mse 1.343360792010071\n",
      "Starting Epoch 190\n",
      "1.3362079709768295\n",
      "Validation loss: 1.3427506685256958\n",
      "mse 1.3427507444341706\n",
      "New best model found at epoch 190 with validation loss 1.3427506685256958\n",
      "Starting Epoch 191\n",
      "1.335719108581543\n",
      "Validation loss: 1.3420764207839966\n",
      "mse 1.3420763886820128\n",
      "New best model found at epoch 191 with validation loss 1.3420764207839966\n",
      "Starting Epoch 192\n",
      "1.3352070872982342\n",
      "Validation loss: 1.3419824838638306\n",
      "mse 1.3419825833843029\n",
      "New best model found at epoch 192 with validation loss 1.3419824838638306\n",
      "Starting Epoch 193\n",
      "1.334835944076379\n",
      "Validation loss: 1.3418525457382202\n",
      "mse 1.3418523574864931\n",
      "New best model found at epoch 193 with validation loss 1.3418525457382202\n",
      "Starting Epoch 194\n",
      "1.3343754932284355\n",
      "Validation loss: 1.3415597677230835\n",
      "mse 1.3415597192591133\n",
      "New best model found at epoch 194 with validation loss 1.3415597677230835\n",
      "Starting Epoch 195\n",
      "1.3340104296803474\n",
      "Validation loss: 1.3408644199371338\n",
      "mse 1.340864363022058\n",
      "New best model found at epoch 195 with validation loss 1.3408644199371338\n",
      "Starting Epoch 196\n",
      "1.3335481236378353\n",
      "Validation loss: 1.34083890914917\n",
      "mse 1.3408387871535108\n",
      "New best model found at epoch 196 with validation loss 1.34083890914917\n",
      "Starting Epoch 197\n",
      "1.333039457599322\n",
      "Validation loss: 1.3407135009765625\n",
      "mse 1.34071340276167\n",
      "New best model found at epoch 197 with validation loss 1.3407135009765625\n",
      "Starting Epoch 198\n",
      "1.3327458997567494\n",
      "Validation loss: 1.340091586112976\n",
      "mse 1.3400916638087152\n",
      "New best model found at epoch 198 with validation loss 1.340091586112976\n",
      "Starting Epoch 199\n",
      "1.3322598437468212\n",
      "Validation loss: 1.3395187854766846\n",
      "mse 1.3395188208716695\n",
      "New best model found at epoch 199 with validation loss 1.3395187854766846\n",
      "Starting Epoch 200\n",
      "1.3318208654721577\n",
      "Validation loss: 1.339583158493042\n",
      "mse 1.3395832200105628\n",
      "Starting Epoch 201\n",
      "1.3314294641216595\n",
      "Validation loss: 1.3389767408370972\n",
      "mse 1.3389767923530616\n",
      "New best model found at epoch 201 with validation loss 1.3389767408370972\n",
      "Starting Epoch 202\n",
      "1.330961840848128\n",
      "Validation loss: 1.3389112949371338\n",
      "mse 1.338911116828191\n",
      "New best model found at epoch 202 with validation loss 1.3389112949371338\n",
      "Starting Epoch 203\n",
      "1.3306217044591904\n",
      "Validation loss: 1.3386014699935913\n",
      "mse 1.338601619887099\n",
      "New best model found at epoch 203 with validation loss 1.3386014699935913\n",
      "Starting Epoch 204\n",
      "1.3301484485467274\n",
      "Validation loss: 1.3384337425231934\n",
      "mse 1.338433908160762\n",
      "New best model found at epoch 204 with validation loss 1.3384337425231934\n",
      "Starting Epoch 205\n",
      "1.329741584757964\n",
      "Validation loss: 1.3376288414001465\n",
      "mse 1.3376287904214463\n",
      "New best model found at epoch 205 with validation loss 1.3376288414001465\n",
      "Starting Epoch 206\n",
      "1.3292994300524394\n",
      "Validation loss: 1.338013768196106\n",
      "mse 1.338013641433194\n",
      "Starting Epoch 207\n",
      "1.3290143708388011\n",
      "Validation loss: 1.3370860815048218\n",
      "mse 1.3370861164865846\n",
      "New best model found at epoch 207 with validation loss 1.3370860815048218\n",
      "Starting Epoch 208\n",
      "1.328488568464915\n",
      "Validation loss: 1.3365812301635742\n",
      "mse 1.336581207281079\n",
      "New best model found at epoch 208 with validation loss 1.3365812301635742\n",
      "Starting Epoch 209\n",
      "1.3281558752059937\n",
      "Validation loss: 1.3365981578826904\n",
      "mse 1.3365982608001798\n",
      "Starting Epoch 210\n",
      "1.3276897594332695\n",
      "Validation loss: 1.3360557556152344\n",
      "mse 1.3360557821344201\n",
      "New best model found at epoch 210 with validation loss 1.3360557556152344\n",
      "Starting Epoch 211\n",
      "1.3273409282167752\n",
      "Validation loss: 1.335744857788086\n",
      "mse 1.3357449761432312\n",
      "New best model found at epoch 211 with validation loss 1.335744857788086\n",
      "Starting Epoch 212\n",
      "1.3269907161593437\n",
      "Validation loss: 1.335641860961914\n",
      "mse 1.3356417655064023\n",
      "New best model found at epoch 212 with validation loss 1.335641860961914\n",
      "Starting Epoch 213\n",
      "1.326636679470539\n",
      "Validation loss: 1.3354381322860718\n",
      "mse 1.3354381571751495\n",
      "New best model found at epoch 213 with validation loss 1.3354381322860718\n",
      "Starting Epoch 214\n",
      "1.3261085773507755\n",
      "Validation loss: 1.3349708318710327\n",
      "mse 1.33497085195734\n",
      "New best model found at epoch 214 with validation loss 1.3349708318710327\n",
      "Starting Epoch 215\n",
      "1.3257672563195229\n",
      "Validation loss: 1.3346595764160156\n",
      "mse 1.3346597020372049\n",
      "New best model found at epoch 215 with validation loss 1.3346595764160156\n",
      "Starting Epoch 216\n",
      "1.3254331449667613\n",
      "Validation loss: 1.3342338800430298\n",
      "mse 1.3342337974368472\n",
      "New best model found at epoch 216 with validation loss 1.3342338800430298\n",
      "Starting Epoch 217\n",
      "1.3250449026624362\n",
      "Validation loss: 1.334227442741394\n",
      "mse 1.3342276632549195\n",
      "New best model found at epoch 217 with validation loss 1.334227442741394\n",
      "Starting Epoch 218\n",
      "1.3244963760177295\n",
      "Validation loss: 1.3336551189422607\n",
      "mse 1.3336551745829313\n",
      "New best model found at epoch 218 with validation loss 1.3336551189422607\n",
      "Starting Epoch 219\n",
      "1.3242320716381073\n",
      "Validation loss: 1.3336049318313599\n",
      "mse 1.3336049231131226\n",
      "New best model found at epoch 219 with validation loss 1.3336049318313599\n",
      "Starting Epoch 220\n",
      "1.323790284494559\n",
      "Validation loss: 1.3335460424423218\n",
      "mse 1.3335459907769958\n",
      "New best model found at epoch 220 with validation loss 1.3335460424423218\n",
      "Starting Epoch 221\n",
      "1.3235246911644936\n",
      "Validation loss: 1.3332690000534058\n",
      "mse 1.333268956232513\n",
      "New best model found at epoch 221 with validation loss 1.3332690000534058\n",
      "Starting Epoch 222\n",
      "1.3230632469058037\n",
      "Validation loss: 1.33266019821167\n",
      "mse 1.332660220842872\n",
      "New best model found at epoch 222 with validation loss 1.33266019821167\n",
      "Starting Epoch 223\n",
      "1.3227659910917282\n",
      "Validation loss: 1.3324799537658691\n",
      "mse 1.3324799280290411\n",
      "New best model found at epoch 223 with validation loss 1.3324799537658691\n",
      "Starting Epoch 224\n",
      "1.322419670720895\n",
      "Validation loss: 1.3322230577468872\n",
      "mse 1.3322230522658378\n",
      "New best model found at epoch 224 with validation loss 1.3322230577468872\n",
      "Starting Epoch 225\n",
      "1.3219542776544888\n",
      "Validation loss: 1.3318053483963013\n",
      "mse 1.331805293028009\n",
      "New best model found at epoch 225 with validation loss 1.3318053483963013\n",
      "Starting Epoch 226\n",
      "1.3214792038003604\n",
      "Validation loss: 1.3314887285232544\n",
      "mse 1.3314886925895284\n",
      "New best model found at epoch 226 with validation loss 1.3314887285232544\n",
      "Starting Epoch 227\n",
      "1.3211959327260654\n",
      "Validation loss: 1.3311980962753296\n",
      "mse 1.331197986327514\n",
      "New best model found at epoch 227 with validation loss 1.3311980962753296\n",
      "Starting Epoch 228\n",
      "1.3208416774868965\n",
      "Validation loss: 1.3305586576461792\n",
      "mse 1.3305587627147293\n",
      "New best model found at epoch 228 with validation loss 1.3305586576461792\n",
      "Starting Epoch 229\n",
      "1.3204292903343837\n",
      "Validation loss: 1.3305575847625732\n",
      "mse 1.3305575188060121\n",
      "New best model found at epoch 229 with validation loss 1.3305575847625732\n",
      "Starting Epoch 230\n",
      "1.3200442393620808\n",
      "Validation loss: 1.330104947090149\n",
      "mse 1.3301049412381114\n",
      "New best model found at epoch 230 with validation loss 1.330104947090149\n",
      "Starting Epoch 231\n",
      "1.3196849649151166\n",
      "Validation loss: 1.3297979831695557\n",
      "mse 1.329797987286332\n",
      "New best model found at epoch 231 with validation loss 1.3297979831695557\n",
      "Starting Epoch 232\n",
      "1.3194124326109886\n",
      "Validation loss: 1.3297239542007446\n",
      "mse 1.3297240247379476\n",
      "New best model found at epoch 232 with validation loss 1.3297239542007446\n",
      "Starting Epoch 233\n",
      "1.3190495669841766\n",
      "Validation loss: 1.3292452096939087\n",
      "mse 1.329245171309268\n",
      "New best model found at epoch 233 with validation loss 1.3292452096939087\n",
      "Starting Epoch 234\n",
      "1.318658468623956\n",
      "Validation loss: 1.328896403312683\n",
      "mse 1.3288963255877668\n",
      "New best model found at epoch 234 with validation loss 1.328896403312683\n",
      "Starting Epoch 235\n",
      "1.3183411632974942\n",
      "Validation loss: 1.3288615942001343\n",
      "mse 1.3288617374972502\n",
      "New best model found at epoch 235 with validation loss 1.3288615942001343\n",
      "Starting Epoch 236\n",
      "1.3180003215869267\n",
      "Validation loss: 1.3283122777938843\n",
      "mse 1.3283123466384932\n",
      "New best model found at epoch 236 with validation loss 1.3283122777938843\n",
      "Starting Epoch 237\n",
      "1.3176218941807747\n",
      "Validation loss: 1.3277292251586914\n",
      "mse 1.3277292282466826\n",
      "New best model found at epoch 237 with validation loss 1.3277292251586914\n",
      "Starting Epoch 238\n",
      "1.3172280763586361\n",
      "Validation loss: 1.3275625705718994\n",
      "mse 1.327562430042786\n",
      "New best model found at epoch 238 with validation loss 1.3275625705718994\n",
      "Starting Epoch 239\n",
      "1.3168738782405853\n",
      "Validation loss: 1.3277966976165771\n",
      "mse 1.3277967460237357\n",
      "Starting Epoch 240\n",
      "1.3166056697567303\n",
      "Validation loss: 1.327014446258545\n",
      "mse 1.3270145370713728\n",
      "New best model found at epoch 240 with validation loss 1.327014446258545\n",
      "Starting Epoch 241\n",
      "1.3161603609720867\n",
      "Validation loss: 1.326797604560852\n",
      "mse 1.3267975471880413\n",
      "New best model found at epoch 241 with validation loss 1.326797604560852\n",
      "Starting Epoch 242\n",
      "1.3158684819936752\n",
      "Validation loss: 1.3266173601150513\n",
      "mse 1.3266172638739537\n",
      "New best model found at epoch 242 with validation loss 1.3266173601150513\n",
      "Starting Epoch 243\n",
      "1.3155209968487422\n",
      "Validation loss: 1.3267189264297485\n",
      "mse 1.3267189593607762\n",
      "Starting Epoch 244\n",
      "1.315185785293579\n",
      "Validation loss: 1.325740933418274\n",
      "mse 1.325740778029577\n",
      "New best model found at epoch 244 with validation loss 1.325740933418274\n",
      "Starting Epoch 245\n",
      "1.3147941107551258\n",
      "Validation loss: 1.3258308172225952\n",
      "mse 1.3258309712006857\n",
      "Starting Epoch 246\n",
      "1.314415954053402\n",
      "Validation loss: 1.3255376815795898\n",
      "mse 1.3255376991721182\n",
      "New best model found at epoch 246 with validation loss 1.3255376815795898\n",
      "Starting Epoch 247\n",
      "1.3141498814026515\n",
      "Validation loss: 1.3251311779022217\n",
      "mse 1.3251311286336946\n",
      "New best model found at epoch 247 with validation loss 1.3251311779022217\n",
      "Starting Epoch 248\n",
      "1.3137409562865894\n",
      "Validation loss: 1.3248311281204224\n",
      "mse 1.3248312877814843\n",
      "New best model found at epoch 248 with validation loss 1.3248311281204224\n",
      "Starting Epoch 249\n",
      "1.3134411722421646\n",
      "Validation loss: 1.3248438835144043\n",
      "mse 1.3248438414339367\n",
      "Starting Epoch 250\n",
      "1.3131623392303784\n",
      "Validation loss: 1.324202299118042\n",
      "mse 1.324202275051112\n",
      "New best model found at epoch 250 with validation loss 1.324202299118042\n",
      "Starting Epoch 251\n",
      "1.3127521847685177\n",
      "Validation loss: 1.3239001035690308\n",
      "mse 1.3239002181772603\n",
      "New best model found at epoch 251 with validation loss 1.3239001035690308\n",
      "Starting Epoch 252\n",
      "1.3123618339498837\n",
      "Validation loss: 1.3234785795211792\n",
      "mse 1.3234786397799705\n",
      "New best model found at epoch 252 with validation loss 1.3234785795211792\n",
      "Starting Epoch 253\n",
      "1.3120624373356502\n",
      "Validation loss: 1.323291540145874\n",
      "mse 1.3232915501025844\n",
      "New best model found at epoch 253 with validation loss 1.323291540145874\n",
      "Starting Epoch 254\n",
      "1.3117956543962161\n",
      "Validation loss: 1.3228135108947754\n",
      "mse 1.3228134499968276\n",
      "New best model found at epoch 254 with validation loss 1.3228135108947754\n",
      "Starting Epoch 255\n",
      "1.3113890662789345\n",
      "Validation loss: 1.3225146532058716\n",
      "mse 1.3225147460706088\n",
      "New best model found at epoch 255 with validation loss 1.3225146532058716\n",
      "Starting Epoch 256\n",
      "1.3109818771481514\n",
      "Validation loss: 1.322371482849121\n",
      "mse 1.3223714840268523\n",
      "New best model found at epoch 256 with validation loss 1.322371482849121\n",
      "Starting Epoch 257\n",
      "1.3107518951098125\n",
      "Validation loss: 1.3216532468795776\n",
      "mse 1.321653241597333\n",
      "New best model found at epoch 257 with validation loss 1.3216532468795776\n",
      "Starting Epoch 258\n",
      "1.3103459104895592\n",
      "Validation loss: 1.3216423988342285\n",
      "mse 1.3216422477981682\n",
      "New best model found at epoch 258 with validation loss 1.3216423988342285\n",
      "Starting Epoch 259\n",
      "1.310066044330597\n",
      "Validation loss: 1.3214643001556396\n",
      "mse 1.3214642463627355\n",
      "New best model found at epoch 259 with validation loss 1.3214643001556396\n",
      "Starting Epoch 260\n",
      "1.3097160110870998\n",
      "Validation loss: 1.320981502532959\n",
      "mse 1.3209815959069302\n",
      "New best model found at epoch 260 with validation loss 1.320981502532959\n",
      "Starting Epoch 261\n",
      "1.3092851663629215\n",
      "Validation loss: 1.3210394382476807\n",
      "mse 1.321039350243564\n",
      "Starting Epoch 262\n",
      "1.3090661317110062\n",
      "Validation loss: 1.320413589477539\n",
      "mse 1.3204136254742351\n",
      "New best model found at epoch 262 with validation loss 1.320413589477539\n",
      "Starting Epoch 263\n",
      "1.3086674585938454\n",
      "Validation loss: 1.3205283880233765\n",
      "mse 1.3205283216288142\n",
      "Starting Epoch 264\n",
      "1.3083143110076587\n",
      "Validation loss: 1.3202345371246338\n",
      "mse 1.32023462515863\n",
      "New best model found at epoch 264 with validation loss 1.3202345371246338\n",
      "Starting Epoch 265\n",
      "1.3080226133267085\n",
      "Validation loss: 1.320427656173706\n",
      "mse 1.3204276442662353\n",
      "Starting Epoch 266\n",
      "1.3077573850750923\n",
      "Validation loss: 1.3198096752166748\n",
      "mse 1.3198096224534772\n",
      "New best model found at epoch 266 with validation loss 1.3198096752166748\n",
      "Starting Epoch 267\n",
      "1.307340328892072\n",
      "Validation loss: 1.3196479082107544\n",
      "mse 1.3196478752687764\n",
      "New best model found at epoch 267 with validation loss 1.3196479082107544\n",
      "Starting Epoch 268\n",
      "1.3070097888509433\n",
      "Validation loss: 1.3194553852081299\n",
      "mse 1.3194553685249861\n",
      "New best model found at epoch 268 with validation loss 1.3194553852081299\n",
      "Starting Epoch 269\n",
      "1.3066801006595294\n",
      "Validation loss: 1.319283366203308\n",
      "mse 1.3192833187300927\n",
      "New best model found at epoch 269 with validation loss 1.319283366203308\n",
      "Starting Epoch 270\n",
      "1.3064101884762447\n",
      "Validation loss: 1.3188233375549316\n",
      "mse 1.3188233064058732\n",
      "New best model found at epoch 270 with validation loss 1.3188233375549316\n",
      "Starting Epoch 271\n",
      "1.3060662026206653\n",
      "Validation loss: 1.3188281059265137\n",
      "mse 1.3188280625444517\n",
      "Starting Epoch 272\n",
      "1.3057534744342167\n",
      "Validation loss: 1.3186448812484741\n",
      "mse 1.3186448195662508\n",
      "New best model found at epoch 272 with validation loss 1.3186448812484741\n",
      "Starting Epoch 273\n",
      "1.305466614663601\n",
      "Validation loss: 1.3182954788208008\n",
      "mse 1.3182953841814553\n",
      "New best model found at epoch 273 with validation loss 1.3182954788208008\n",
      "Starting Epoch 274\n",
      "1.3051211809118588\n",
      "Validation loss: 1.3178900480270386\n",
      "mse 1.317890015736644\n",
      "New best model found at epoch 274 with validation loss 1.3178900480270386\n",
      "Starting Epoch 275\n",
      "1.3048361266652744\n",
      "Validation loss: 1.3178476095199585\n",
      "mse 1.317847662855764\n",
      "New best model found at epoch 275 with validation loss 1.3178476095199585\n",
      "Starting Epoch 276\n",
      "1.3045257727305095\n",
      "Validation loss: 1.3172727823257446\n",
      "mse 1.3172729457210115\n",
      "New best model found at epoch 276 with validation loss 1.3172727823257446\n",
      "Starting Epoch 277\n",
      "1.3042238752047222\n",
      "Validation loss: 1.317795991897583\n",
      "mse 1.3177959661882643\n",
      "Starting Epoch 278\n",
      "1.3039157514770825\n",
      "Validation loss: 1.316866159439087\n",
      "mse 1.3168663087455987\n",
      "New best model found at epoch 278 with validation loss 1.316866159439087\n",
      "Starting Epoch 279\n",
      "1.3035735090573628\n",
      "Validation loss: 1.3167974948883057\n",
      "mse 1.316797493098048\n",
      "New best model found at epoch 279 with validation loss 1.3167974948883057\n",
      "Starting Epoch 280\n",
      "1.3032567078868549\n",
      "Validation loss: 1.3168020248413086\n",
      "mse 1.316802097667494\n",
      "Starting Epoch 281\n",
      "1.3029372990131378\n",
      "Validation loss: 1.3165687322616577\n",
      "mse 1.316568707279814\n",
      "New best model found at epoch 281 with validation loss 1.3165687322616577\n",
      "Starting Epoch 282\n",
      "1.3026237313946087\n",
      "Validation loss: 1.3166553974151611\n",
      "mse 1.3166554121793919\n",
      "Starting Epoch 283\n",
      "1.3023870959877968\n",
      "Validation loss: 1.3159208297729492\n",
      "mse 1.315920784787383\n",
      "New best model found at epoch 283 with validation loss 1.3159208297729492\n",
      "Starting Epoch 284\n",
      "1.3020437980691593\n",
      "Validation loss: 1.3157097101211548\n",
      "mse 1.3157097034225609\n",
      "New best model found at epoch 284 with validation loss 1.3157097101211548\n",
      "Starting Epoch 285\n",
      "1.3017576436201732\n",
      "Validation loss: 1.316062569618225\n",
      "mse 1.3160624890739094\n",
      "Starting Epoch 286\n",
      "1.301448442041874\n",
      "Validation loss: 1.315665602684021\n",
      "mse 1.3156656741208117\n",
      "New best model found at epoch 286 with validation loss 1.315665602684021\n",
      "Starting Epoch 287\n",
      "1.3010778004924457\n",
      "Validation loss: 1.3152186870574951\n",
      "mse 1.3152186547221494\n",
      "New best model found at epoch 287 with validation loss 1.3152186870574951\n",
      "Starting Epoch 288\n",
      "1.3008370498816173\n",
      "Validation loss: 1.315085530281067\n",
      "mse 1.3150855958225354\n",
      "New best model found at epoch 288 with validation loss 1.315085530281067\n",
      "Starting Epoch 289\n",
      "1.3004724010825157\n",
      "Validation loss: 1.3151991367340088\n",
      "mse 1.315199180481295\n",
      "Starting Epoch 290\n",
      "1.3002449472745259\n",
      "Validation loss: 1.3146921396255493\n",
      "mse 1.3146921389974409\n",
      "New best model found at epoch 290 with validation loss 1.3146921396255493\n",
      "Starting Epoch 291\n",
      "1.2998976930975914\n",
      "Validation loss: 1.3146251440048218\n",
      "mse 1.3146251488533167\n",
      "New best model found at epoch 291 with validation loss 1.3146251440048218\n",
      "Starting Epoch 292\n",
      "1.299635834991932\n",
      "Validation loss: 1.3147119283676147\n",
      "mse 1.3147119289932827\n",
      "Starting Epoch 293\n",
      "1.2993590906262398\n",
      "Validation loss: 1.3140610456466675\n",
      "mse 1.3140609440591549\n",
      "New best model found at epoch 293 with validation loss 1.3140610456466675\n",
      "Starting Epoch 294\n",
      "1.2990565846363704\n",
      "Validation loss: 1.3139561414718628\n",
      "mse 1.3139562638047788\n",
      "New best model found at epoch 294 with validation loss 1.3139561414718628\n",
      "Starting Epoch 295\n",
      "1.298766851425171\n",
      "Validation loss: 1.3139395713806152\n",
      "mse 1.3139395757122627\n",
      "New best model found at epoch 295 with validation loss 1.3139395713806152\n",
      "Starting Epoch 296\n",
      "1.2983759293953578\n",
      "Validation loss: 1.313362956047058\n",
      "mse 1.313362896054666\n",
      "New best model found at epoch 296 with validation loss 1.313362956047058\n",
      "Starting Epoch 297\n",
      "1.2981215740243595\n",
      "Validation loss: 1.3135193586349487\n",
      "mse 1.313519330417985\n",
      "Starting Epoch 298\n",
      "1.2979045286774635\n",
      "Validation loss: 1.313114881515503\n",
      "mse 1.3131147804014554\n",
      "New best model found at epoch 298 with validation loss 1.313114881515503\n",
      "Starting Epoch 299\n",
      "1.2976006294290225\n",
      "Validation loss: 1.3131117820739746\n",
      "mse 1.3131118787862577\n",
      "New best model found at epoch 299 with validation loss 1.3131117820739746\n",
      "Starting Epoch 300\n",
      "1.297254631916682\n",
      "Validation loss: 1.31339693069458\n",
      "mse 1.3133968296990086\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-median: 7-80-50-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b278b7",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "1afd1a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "d63f6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,7,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "0d637fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'mean(container counts)', 'mean(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ba2e7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "8a02cc2c-039c-4b0c-a142-bdd9b4541fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.627548043926557\n",
      "Validation loss: 1.9655922651290894\n",
      "mse 1.965592207881156\n",
      "New best model found at epoch 1 with validation loss 1.9655922651290894\n",
      "Starting Epoch 2\n",
      "1.9757496267557144\n",
      "Validation loss: 1.8293046951293945\n",
      "mse 1.8293047284468122\n",
      "New best model found at epoch 2 with validation loss 1.8293046951293945\n",
      "Starting Epoch 3\n",
      "1.8914619088172913\n",
      "Validation loss: 1.7693285942077637\n",
      "mse 1.769328557096388\n",
      "New best model found at epoch 3 with validation loss 1.7693285942077637\n",
      "Starting Epoch 4\n",
      "1.8481308966875076\n",
      "Validation loss: 1.7364952564239502\n",
      "mse 1.736495318441865\n",
      "New best model found at epoch 4 with validation loss 1.7364952564239502\n",
      "Starting Epoch 5\n",
      "1.8166903406381607\n",
      "Validation loss: 1.7143551111221313\n",
      "mse 1.7143551542395277\n",
      "New best model found at epoch 5 with validation loss 1.7143551111221313\n",
      "Starting Epoch 6\n",
      "1.7923451115687687\n",
      "Validation loss: 1.698380470275879\n",
      "mse 1.6983806191349806\n",
      "New best model found at epoch 6 with validation loss 1.698380470275879\n",
      "Starting Epoch 7\n",
      "1.7703021466732025\n",
      "Validation loss: 1.6832021474838257\n",
      "mse 1.6832020873285847\n",
      "New best model found at epoch 7 with validation loss 1.6832021474838257\n",
      "Starting Epoch 8\n",
      "1.7513036827246349\n",
      "Validation loss: 1.6697663068771362\n",
      "mse 1.6697662238948536\n",
      "New best model found at epoch 8 with validation loss 1.6697663068771362\n",
      "Starting Epoch 9\n",
      "1.7351729323466618\n",
      "Validation loss: 1.6595215797424316\n",
      "mse 1.6595215407278139\n",
      "New best model found at epoch 9 with validation loss 1.6595215797424316\n",
      "Starting Epoch 10\n",
      "1.720893199245135\n",
      "Validation loss: 1.6469848155975342\n",
      "mse 1.6469847568782428\n",
      "New best model found at epoch 10 with validation loss 1.6469848155975342\n",
      "Starting Epoch 11\n",
      "1.708400050799052\n",
      "Validation loss: 1.6384881734848022\n",
      "mse 1.6384881016104649\n",
      "New best model found at epoch 11 with validation loss 1.6384881734848022\n",
      "Starting Epoch 12\n",
      "1.6977184067169826\n",
      "Validation loss: 1.6304508447647095\n",
      "mse 1.630450883687535\n",
      "New best model found at epoch 12 with validation loss 1.6304508447647095\n",
      "Starting Epoch 13\n",
      "1.6878079722325008\n",
      "Validation loss: 1.6234034299850464\n",
      "mse 1.6234034156575712\n",
      "New best model found at epoch 13 with validation loss 1.6234034299850464\n",
      "Starting Epoch 14\n",
      "1.6788807660341263\n",
      "Validation loss: 1.6154038906097412\n",
      "mse 1.615404001818617\n",
      "New best model found at epoch 14 with validation loss 1.6154038906097412\n",
      "Starting Epoch 15\n",
      "1.669507493575414\n",
      "Validation loss: 1.6081684827804565\n",
      "mse 1.608168386721039\n",
      "New best model found at epoch 15 with validation loss 1.6081684827804565\n",
      "Starting Epoch 16\n",
      "1.6608092536528904\n",
      "Validation loss: 1.6025335788726807\n",
      "mse 1.602533603965886\n",
      "New best model found at epoch 16 with validation loss 1.6025335788726807\n",
      "Starting Epoch 17\n",
      "1.6517128646373749\n",
      "Validation loss: 1.596960186958313\n",
      "mse 1.5969601932092068\n",
      "New best model found at epoch 17 with validation loss 1.596960186958313\n",
      "Starting Epoch 18\n",
      "1.6435299863417943\n",
      "Validation loss: 1.59165620803833\n",
      "mse 1.5916563341190961\n",
      "New best model found at epoch 18 with validation loss 1.59165620803833\n",
      "Starting Epoch 19\n",
      "1.635847384730975\n",
      "Validation loss: 1.584708333015442\n",
      "mse 1.5847082076583054\n",
      "New best model found at epoch 19 with validation loss 1.584708333015442\n",
      "Starting Epoch 20\n",
      "1.6278936167558034\n",
      "Validation loss: 1.5786588191986084\n",
      "mse 1.5786587818936075\n",
      "New best model found at epoch 20 with validation loss 1.5786588191986084\n",
      "Starting Epoch 21\n",
      "1.6203305075565975\n",
      "Validation loss: 1.5732229948043823\n",
      "mse 1.5732228999437488\n",
      "New best model found at epoch 21 with validation loss 1.5732229948043823\n",
      "Starting Epoch 22\n",
      "1.6128989060719807\n",
      "Validation loss: 1.5678343772888184\n",
      "mse 1.5678344078034834\n",
      "New best model found at epoch 22 with validation loss 1.5678343772888184\n",
      "Starting Epoch 23\n",
      "1.6057044913371403\n",
      "Validation loss: 1.565425157546997\n",
      "mse 1.5654251912961443\n",
      "New best model found at epoch 23 with validation loss 1.565425157546997\n",
      "Starting Epoch 24\n",
      "1.5985454271237056\n",
      "Validation loss: 1.5595885515213013\n",
      "mse 1.5595886425072936\n",
      "New best model found at epoch 24 with validation loss 1.5595885515213013\n",
      "Starting Epoch 25\n",
      "1.591338574886322\n",
      "Validation loss: 1.5526031255722046\n",
      "mse 1.552603095261398\n",
      "New best model found at epoch 25 with validation loss 1.5526031255722046\n",
      "Starting Epoch 26\n",
      "1.5840831100940704\n",
      "Validation loss: 1.547946572303772\n",
      "mse 1.547946493422336\n",
      "New best model found at epoch 26 with validation loss 1.547946572303772\n",
      "Starting Epoch 27\n",
      "1.5767446259657543\n",
      "Validation loss: 1.5424450635910034\n",
      "mse 1.5424451377909665\n",
      "New best model found at epoch 27 with validation loss 1.5424450635910034\n",
      "Starting Epoch 28\n",
      "1.5701916714509327\n",
      "Validation loss: 1.5380311012268066\n",
      "mse 1.5380312789004034\n",
      "New best model found at epoch 28 with validation loss 1.5380311012268066\n",
      "Starting Epoch 29\n",
      "1.563653623064359\n",
      "Validation loss: 1.5288329124450684\n",
      "mse 1.5288327849982384\n",
      "New best model found at epoch 29 with validation loss 1.5288329124450684\n",
      "Starting Epoch 30\n",
      "1.5567310353120167\n",
      "Validation loss: 1.525941014289856\n",
      "mse 1.5259410180786506\n",
      "New best model found at epoch 30 with validation loss 1.525941014289856\n",
      "Starting Epoch 31\n",
      "1.5505911459525425\n",
      "Validation loss: 1.519304871559143\n",
      "mse 1.5193047846281145\n",
      "New best model found at epoch 31 with validation loss 1.519304871559143\n",
      "Starting Epoch 32\n",
      "1.5442612618207932\n",
      "Validation loss: 1.5142415761947632\n",
      "mse 1.514241680342861\n",
      "New best model found at epoch 32 with validation loss 1.5142415761947632\n",
      "Starting Epoch 33\n",
      "1.538539007306099\n",
      "Validation loss: 1.5111522674560547\n",
      "mse 1.5111522285985903\n",
      "New best model found at epoch 33 with validation loss 1.5111522674560547\n",
      "Starting Epoch 34\n",
      "1.5325027356545131\n",
      "Validation loss: 1.5059831142425537\n",
      "mse 1.5059830237793013\n",
      "New best model found at epoch 34 with validation loss 1.5059831142425537\n",
      "Starting Epoch 35\n",
      "1.5267223070065181\n",
      "Validation loss: 1.5008461475372314\n",
      "mse 1.5008461720126929\n",
      "New best model found at epoch 35 with validation loss 1.5008461475372314\n",
      "Starting Epoch 36\n",
      "1.5209376364946365\n",
      "Validation loss: 1.4947545528411865\n",
      "mse 1.4947544274899538\n",
      "New best model found at epoch 36 with validation loss 1.4947545528411865\n",
      "Starting Epoch 37\n",
      "1.5154731820027034\n",
      "Validation loss: 1.4916919469833374\n",
      "mse 1.4916919415289525\n",
      "New best model found at epoch 37 with validation loss 1.4916919469833374\n",
      "Starting Epoch 38\n",
      "1.5100880612929661\n",
      "Validation loss: 1.4849356412887573\n",
      "mse 1.4849357774551093\n",
      "New best model found at epoch 38 with validation loss 1.4849356412887573\n",
      "Starting Epoch 39\n",
      "1.5047601163387299\n",
      "Validation loss: 1.4799083471298218\n",
      "mse 1.4799083287597394\n",
      "New best model found at epoch 39 with validation loss 1.4799083471298218\n",
      "Starting Epoch 40\n",
      "1.4993952562411625\n",
      "Validation loss: 1.4772980213165283\n",
      "mse 1.4772981246548156\n",
      "New best model found at epoch 40 with validation loss 1.4772980213165283\n",
      "Starting Epoch 41\n",
      "1.494249626994133\n",
      "Validation loss: 1.4731032848358154\n",
      "mse 1.473103182750015\n",
      "New best model found at epoch 41 with validation loss 1.4731032848358154\n",
      "Starting Epoch 42\n",
      "1.489210233092308\n",
      "Validation loss: 1.4672685861587524\n",
      "mse 1.4672686527505732\n",
      "New best model found at epoch 42 with validation loss 1.4672685861587524\n",
      "Starting Epoch 43\n",
      "1.4842070490121841\n",
      "Validation loss: 1.465283751487732\n",
      "mse 1.4652837546967494\n",
      "New best model found at epoch 43 with validation loss 1.465283751487732\n",
      "Starting Epoch 44\n",
      "1.4798057576020558\n",
      "Validation loss: 1.4621425867080688\n",
      "mse 1.462142496674069\n",
      "New best model found at epoch 44 with validation loss 1.4621425867080688\n",
      "Starting Epoch 45\n",
      "1.4753708293040593\n",
      "Validation loss: 1.4571664333343506\n",
      "mse 1.4571663418225722\n",
      "New best model found at epoch 45 with validation loss 1.4571664333343506\n",
      "Starting Epoch 46\n",
      "1.4710751225550969\n",
      "Validation loss: 1.451804518699646\n",
      "mse 1.4518045689382748\n",
      "New best model found at epoch 46 with validation loss 1.451804518699646\n",
      "Starting Epoch 47\n",
      "1.466706911722819\n",
      "Validation loss: 1.4458422660827637\n",
      "mse 1.4458423055954646\n",
      "New best model found at epoch 47 with validation loss 1.4458422660827637\n",
      "Starting Epoch 48\n",
      "1.4622774471839268\n",
      "Validation loss: 1.443337082862854\n",
      "mse 1.443337032122375\n",
      "New best model found at epoch 48 with validation loss 1.443337082862854\n",
      "Starting Epoch 49\n",
      "1.4581455091635387\n",
      "Validation loss: 1.4402635097503662\n",
      "mse 1.4402634244914518\n",
      "New best model found at epoch 49 with validation loss 1.4402635097503662\n",
      "Starting Epoch 50\n",
      "1.4542864312728245\n",
      "Validation loss: 1.4364111423492432\n",
      "mse 1.4364109813127406\n",
      "New best model found at epoch 50 with validation loss 1.4364111423492432\n",
      "Starting Epoch 51\n",
      "1.4502900342146556\n",
      "Validation loss: 1.4331499338150024\n",
      "mse 1.4331499724909442\n",
      "New best model found at epoch 51 with validation loss 1.4331499338150024\n",
      "Starting Epoch 52\n",
      "1.4465147455533345\n",
      "Validation loss: 1.4291491508483887\n",
      "mse 1.4291490990142093\n",
      "New best model found at epoch 52 with validation loss 1.4291491508483887\n",
      "Starting Epoch 53\n",
      "1.4426890015602112\n",
      "Validation loss: 1.426013469696045\n",
      "mse 1.4260134487631655\n",
      "New best model found at epoch 53 with validation loss 1.426013469696045\n",
      "Starting Epoch 54\n",
      "1.439296379685402\n",
      "Validation loss: 1.4228636026382446\n",
      "mse 1.4228635104756704\n",
      "New best model found at epoch 54 with validation loss 1.4228636026382446\n",
      "Starting Epoch 55\n",
      "1.435850739479065\n",
      "Validation loss: 1.4196462631225586\n",
      "mse 1.4196461092321107\n",
      "New best model found at epoch 55 with validation loss 1.4196462631225586\n",
      "Starting Epoch 56\n",
      "1.4324512978394826\n",
      "Validation loss: 1.4171257019042969\n",
      "mse 1.4171257141150322\n",
      "New best model found at epoch 56 with validation loss 1.4171257019042969\n",
      "Starting Epoch 57\n",
      "1.4291849732398987\n",
      "Validation loss: 1.414290189743042\n",
      "mse 1.4142902442036707\n",
      "New best model found at epoch 57 with validation loss 1.414290189743042\n",
      "Starting Epoch 58\n",
      "1.4262107387185097\n",
      "Validation loss: 1.411146879196167\n",
      "mse 1.4111469445152507\n",
      "New best model found at epoch 58 with validation loss 1.411146879196167\n",
      "Starting Epoch 59\n",
      "1.4230226427316666\n",
      "Validation loss: 1.408766746520996\n",
      "mse 1.408766543183416\n",
      "New best model found at epoch 59 with validation loss 1.408766746520996\n",
      "Starting Epoch 60\n",
      "1.420001044869423\n",
      "Validation loss: 1.4047781229019165\n",
      "mse 1.4047783209411635\n",
      "New best model found at epoch 60 with validation loss 1.4047781229019165\n",
      "Starting Epoch 61\n",
      "1.4170660277207692\n",
      "Validation loss: 1.402741551399231\n",
      "mse 1.4027414844075552\n",
      "New best model found at epoch 61 with validation loss 1.402741551399231\n",
      "Starting Epoch 62\n",
      "1.414427210887273\n",
      "Validation loss: 1.4000312089920044\n",
      "mse 1.4000310675613226\n",
      "New best model found at epoch 62 with validation loss 1.4000312089920044\n",
      "Starting Epoch 63\n",
      "1.4115025599797566\n",
      "Validation loss: 1.3980419635772705\n",
      "mse 1.398041942093149\n",
      "New best model found at epoch 63 with validation loss 1.3980419635772705\n",
      "Starting Epoch 64\n",
      "1.4089803049961727\n",
      "Validation loss: 1.3950080871582031\n",
      "mse 1.3950081784600623\n",
      "New best model found at epoch 64 with validation loss 1.3950080871582031\n",
      "Starting Epoch 65\n",
      "1.4061698913574219\n",
      "Validation loss: 1.3916341066360474\n",
      "mse 1.391634240218371\n",
      "New best model found at epoch 65 with validation loss 1.3916341066360474\n",
      "Starting Epoch 66\n",
      "1.4038023129105568\n",
      "Validation loss: 1.389753818511963\n",
      "mse 1.3897538512303256\n",
      "New best model found at epoch 66 with validation loss 1.389753818511963\n",
      "Starting Epoch 67\n",
      "1.401278741657734\n",
      "Validation loss: 1.3874537944793701\n",
      "mse 1.387453823932043\n",
      "New best model found at epoch 67 with validation loss 1.3874537944793701\n",
      "Starting Epoch 68\n",
      "1.398823377986749\n",
      "Validation loss: 1.3854432106018066\n",
      "mse 1.3854430818668255\n",
      "New best model found at epoch 68 with validation loss 1.3854432106018066\n",
      "Starting Epoch 69\n",
      "1.396275334060192\n",
      "Validation loss: 1.383019208908081\n",
      "mse 1.3830193138923226\n",
      "New best model found at epoch 69 with validation loss 1.383019208908081\n",
      "Starting Epoch 70\n",
      "1.39402324706316\n",
      "Validation loss: 1.3812631368637085\n",
      "mse 1.3812631588653494\n",
      "New best model found at epoch 70 with validation loss 1.3812631368637085\n",
      "Starting Epoch 71\n",
      "1.3919563839832942\n",
      "Validation loss: 1.379360556602478\n",
      "mse 1.379360494658226\n",
      "New best model found at epoch 71 with validation loss 1.379360556602478\n",
      "Starting Epoch 72\n",
      "1.3898103162646294\n",
      "Validation loss: 1.3776684999465942\n",
      "mse 1.3776684062846918\n",
      "New best model found at epoch 72 with validation loss 1.3776684999465942\n",
      "Starting Epoch 73\n",
      "1.3876854131619136\n",
      "Validation loss: 1.375791072845459\n",
      "mse 1.3757909605573015\n",
      "New best model found at epoch 73 with validation loss 1.375791072845459\n",
      "Starting Epoch 74\n",
      "1.3857153356075287\n",
      "Validation loss: 1.3732110261917114\n",
      "mse 1.3732109308692455\n",
      "New best model found at epoch 74 with validation loss 1.3732110261917114\n",
      "Starting Epoch 75\n",
      "1.383732666571935\n",
      "Validation loss: 1.3729904890060425\n",
      "mse 1.3729905016052752\n",
      "New best model found at epoch 75 with validation loss 1.3729904890060425\n",
      "Starting Epoch 76\n",
      "1.3819930031895638\n",
      "Validation loss: 1.3704334497451782\n",
      "mse 1.3704335515439172\n",
      "New best model found at epoch 76 with validation loss 1.3704334497451782\n",
      "Starting Epoch 77\n",
      "1.3800902739167213\n",
      "Validation loss: 1.3688572645187378\n",
      "mse 1.368857243225883\n",
      "New best model found at epoch 77 with validation loss 1.3688572645187378\n",
      "Starting Epoch 78\n",
      "1.3780736575524013\n",
      "Validation loss: 1.3672326803207397\n",
      "mse 1.367232751096592\n",
      "New best model found at epoch 78 with validation loss 1.3672326803207397\n",
      "Starting Epoch 79\n",
      "1.3763988291223843\n",
      "Validation loss: 1.3656268119812012\n",
      "mse 1.365626794413195\n",
      "New best model found at epoch 79 with validation loss 1.3656268119812012\n",
      "Starting Epoch 80\n",
      "1.374714011947314\n",
      "Validation loss: 1.364234447479248\n",
      "mse 1.3642345920800696\n",
      "New best model found at epoch 80 with validation loss 1.364234447479248\n",
      "Starting Epoch 81\n",
      "1.3730699717998505\n",
      "Validation loss: 1.362419843673706\n",
      "mse 1.3624198940735173\n",
      "New best model found at epoch 81 with validation loss 1.362419843673706\n",
      "Starting Epoch 82\n",
      "1.371316318710645\n",
      "Validation loss: 1.3607829809188843\n",
      "mse 1.3607830258548135\n",
      "New best model found at epoch 82 with validation loss 1.3607829809188843\n",
      "Starting Epoch 83\n",
      "1.3698011388381321\n",
      "Validation loss: 1.3596633672714233\n",
      "mse 1.3596635060925721\n",
      "New best model found at epoch 83 with validation loss 1.3596633672714233\n",
      "Starting Epoch 84\n",
      "1.3682120194037755\n",
      "Validation loss: 1.3574779033660889\n",
      "mse 1.3574778738725812\n",
      "New best model found at epoch 84 with validation loss 1.3574779033660889\n",
      "Starting Epoch 85\n",
      "1.3666442409157753\n",
      "Validation loss: 1.3562859296798706\n",
      "mse 1.3562860023372834\n",
      "New best model found at epoch 85 with validation loss 1.3562859296798706\n",
      "Starting Epoch 86\n",
      "1.3650469730297725\n",
      "Validation loss: 1.3546971082687378\n",
      "mse 1.3546970696285916\n",
      "New best model found at epoch 86 with validation loss 1.3546971082687378\n",
      "Starting Epoch 87\n",
      "1.3636507565776508\n",
      "Validation loss: 1.3533859252929688\n",
      "mse 1.35338598232894\n",
      "New best model found at epoch 87 with validation loss 1.3533859252929688\n",
      "Starting Epoch 88\n",
      "1.3621794680754344\n",
      "Validation loss: 1.3518146276474\n",
      "mse 1.351814591269352\n",
      "New best model found at epoch 88 with validation loss 1.3518146276474\n",
      "Starting Epoch 89\n",
      "1.3608412618438404\n",
      "Validation loss: 1.350813627243042\n",
      "mse 1.3508135919481539\n",
      "New best model found at epoch 89 with validation loss 1.350813627243042\n",
      "Starting Epoch 90\n",
      "1.359387529393037\n",
      "Validation loss: 1.3490902185440063\n",
      "mse 1.349090217785861\n",
      "New best model found at epoch 90 with validation loss 1.3490902185440063\n",
      "Starting Epoch 91\n",
      "1.3580060675740242\n",
      "Validation loss: 1.3475810289382935\n",
      "mse 1.3475809585551095\n",
      "New best model found at epoch 91 with validation loss 1.3475810289382935\n",
      "Starting Epoch 92\n",
      "1.3566480154792468\n",
      "Validation loss: 1.3466813564300537\n",
      "mse 1.346681446151291\n",
      "New best model found at epoch 92 with validation loss 1.3466813564300537\n",
      "Starting Epoch 93\n",
      "1.3553424303730328\n",
      "Validation loss: 1.3454313278198242\n",
      "mse 1.3454313003742784\n",
      "New best model found at epoch 93 with validation loss 1.3454313278198242\n",
      "Starting Epoch 94\n",
      "1.3540527348717053\n",
      "Validation loss: 1.3440253734588623\n",
      "mse 1.344025286459774\n",
      "New best model found at epoch 94 with validation loss 1.3440253734588623\n",
      "Starting Epoch 95\n",
      "1.3526372388005257\n",
      "Validation loss: 1.3426880836486816\n",
      "mse 1.3426880757401602\n",
      "New best model found at epoch 95 with validation loss 1.3426880836486816\n",
      "Starting Epoch 96\n",
      "1.3513835022846858\n",
      "Validation loss: 1.3412753343582153\n",
      "mse 1.3412753459348472\n",
      "New best model found at epoch 96 with validation loss 1.3412753343582153\n",
      "Starting Epoch 97\n",
      "1.3499718929330509\n",
      "Validation loss: 1.340248942375183\n",
      "mse 1.340248872950138\n",
      "New best model found at epoch 97 with validation loss 1.340248942375183\n",
      "Starting Epoch 98\n",
      "1.3487342943747838\n",
      "Validation loss: 1.339368224143982\n",
      "mse 1.3393683747963776\n",
      "New best model found at epoch 98 with validation loss 1.339368224143982\n",
      "Starting Epoch 99\n",
      "1.347580961883068\n",
      "Validation loss: 1.3385592699050903\n",
      "mse 1.3385591416221798\n",
      "New best model found at epoch 99 with validation loss 1.3385592699050903\n",
      "Starting Epoch 100\n",
      "1.346199909845988\n",
      "Validation loss: 1.337204098701477\n",
      "mse 1.3372040499469566\n",
      "New best model found at epoch 100 with validation loss 1.337204098701477\n",
      "Starting Epoch 101\n",
      "1.3450367152690887\n",
      "Validation loss: 1.3363679647445679\n",
      "mse 1.3363679266710875\n",
      "New best model found at epoch 101 with validation loss 1.3363679647445679\n",
      "Starting Epoch 102\n",
      "1.3437183847030003\n",
      "Validation loss: 1.3347865343093872\n",
      "mse 1.33478634583442\n",
      "New best model found at epoch 102 with validation loss 1.3347865343093872\n",
      "Starting Epoch 103\n",
      "1.342566763361295\n",
      "Validation loss: 1.33412504196167\n",
      "mse 1.3341249031250777\n",
      "New best model found at epoch 103 with validation loss 1.33412504196167\n",
      "Starting Epoch 104\n",
      "1.3414061466852825\n",
      "Validation loss: 1.3327962160110474\n",
      "mse 1.3327961364232128\n",
      "New best model found at epoch 104 with validation loss 1.3327962160110474\n",
      "Starting Epoch 105\n",
      "1.3403017297387123\n",
      "Validation loss: 1.3319354057312012\n",
      "mse 1.331935509829856\n",
      "New best model found at epoch 105 with validation loss 1.3319354057312012\n",
      "Starting Epoch 106\n",
      "1.3392878870169322\n",
      "Validation loss: 1.3307462930679321\n",
      "mse 1.3307461658185396\n",
      "New best model found at epoch 106 with validation loss 1.3307462930679321\n",
      "Starting Epoch 107\n",
      "1.338226579129696\n",
      "Validation loss: 1.329940915107727\n",
      "mse 1.3299410124609992\n",
      "New best model found at epoch 107 with validation loss 1.329940915107727\n",
      "Starting Epoch 108\n",
      "1.3370301872491837\n",
      "Validation loss: 1.3283662796020508\n",
      "mse 1.3283662932812186\n",
      "New best model found at epoch 108 with validation loss 1.3283662796020508\n",
      "Starting Epoch 109\n",
      "1.3361073955893517\n",
      "Validation loss: 1.32831871509552\n",
      "mse 1.3283187158771954\n",
      "New best model found at epoch 109 with validation loss 1.32831871509552\n",
      "Starting Epoch 110\n",
      "1.335094538827737\n",
      "Validation loss: 1.3271726369857788\n",
      "mse 1.3271726392939363\n",
      "New best model found at epoch 110 with validation loss 1.3271726369857788\n",
      "Starting Epoch 111\n",
      "1.334062673151493\n",
      "Validation loss: 1.3263837099075317\n",
      "mse 1.3263837340489988\n",
      "New best model found at epoch 111 with validation loss 1.3263837099075317\n",
      "Starting Epoch 112\n",
      "1.333043249944846\n",
      "Validation loss: 1.3253321647644043\n",
      "mse 1.325332096789384\n",
      "New best model found at epoch 112 with validation loss 1.3253321647644043\n",
      "Starting Epoch 113\n",
      "1.3320603196819623\n",
      "Validation loss: 1.3241766691207886\n",
      "mse 1.3241766158907484\n",
      "New best model found at epoch 113 with validation loss 1.3241766691207886\n",
      "Starting Epoch 114\n",
      "1.33101341376702\n",
      "Validation loss: 1.3236429691314697\n",
      "mse 1.323642978432545\n",
      "New best model found at epoch 114 with validation loss 1.3236429691314697\n",
      "Starting Epoch 115\n",
      "1.3301374812920888\n",
      "Validation loss: 1.3228445053100586\n",
      "mse 1.3228445177142731\n",
      "New best model found at epoch 115 with validation loss 1.3228445053100586\n",
      "Starting Epoch 116\n",
      "1.3290990864237149\n",
      "Validation loss: 1.321907877922058\n",
      "mse 1.321907774583159\n",
      "New best model found at epoch 116 with validation loss 1.321907877922058\n",
      "Starting Epoch 117\n",
      "1.3282454187671344\n",
      "Validation loss: 1.3213839530944824\n",
      "mse 1.3213840304113267\n",
      "New best model found at epoch 117 with validation loss 1.3213839530944824\n",
      "Starting Epoch 118\n",
      "1.3272618874907494\n",
      "Validation loss: 1.3203002214431763\n",
      "mse 1.320300190122015\n",
      "New best model found at epoch 118 with validation loss 1.3203002214431763\n",
      "Starting Epoch 119\n",
      "1.3263743966817856\n",
      "Validation loss: 1.3198586702346802\n",
      "mse 1.3198586337614757\n",
      "New best model found at epoch 119 with validation loss 1.3198586702346802\n",
      "Starting Epoch 120\n",
      "1.3255506778756778\n",
      "Validation loss: 1.3192583322525024\n",
      "mse 1.3192582908118125\n",
      "New best model found at epoch 120 with validation loss 1.3192583322525024\n",
      "Starting Epoch 121\n",
      "1.3246918469667435\n",
      "Validation loss: 1.3184539079666138\n",
      "mse 1.3184538886445747\n",
      "New best model found at epoch 121 with validation loss 1.3184539079666138\n",
      "Starting Epoch 122\n",
      "1.3239232748746872\n",
      "Validation loss: 1.3177986145019531\n",
      "mse 1.3177986232232646\n",
      "New best model found at epoch 122 with validation loss 1.3177986145019531\n",
      "Starting Epoch 123\n",
      "1.3230570803085964\n",
      "Validation loss: 1.3173037767410278\n",
      "mse 1.317303683297734\n",
      "New best model found at epoch 123 with validation loss 1.3173037767410278\n",
      "Starting Epoch 124\n",
      "1.322113923728466\n",
      "Validation loss: 1.3163784742355347\n",
      "mse 1.3163783139990892\n",
      "New best model found at epoch 124 with validation loss 1.3163784742355347\n",
      "Starting Epoch 125\n",
      "1.321414368848006\n",
      "Validation loss: 1.3158036470413208\n",
      "mse 1.3158035734319182\n",
      "New best model found at epoch 125 with validation loss 1.3158036470413208\n",
      "Starting Epoch 126\n",
      "1.3206144447127979\n",
      "Validation loss: 1.3151382207870483\n",
      "mse 1.3151381603264665\n",
      "New best model found at epoch 126 with validation loss 1.3151382207870483\n",
      "Starting Epoch 127\n",
      "1.319715330998103\n",
      "Validation loss: 1.3148646354675293\n",
      "mse 1.3148647186352351\n",
      "New best model found at epoch 127 with validation loss 1.3148646354675293\n",
      "Starting Epoch 128\n",
      "1.318918913602829\n",
      "Validation loss: 1.3139221668243408\n",
      "mse 1.3139220397382967\n",
      "New best model found at epoch 128 with validation loss 1.3139221668243408\n",
      "Starting Epoch 129\n",
      "1.3182569940884907\n",
      "Validation loss: 1.313435673713684\n",
      "mse 1.3134356463959969\n",
      "New best model found at epoch 129 with validation loss 1.313435673713684\n",
      "Starting Epoch 130\n",
      "1.3175032089153926\n",
      "Validation loss: 1.3129870891571045\n",
      "mse 1.312987110634792\n",
      "New best model found at epoch 130 with validation loss 1.3129870891571045\n",
      "Starting Epoch 131\n",
      "1.31661818921566\n",
      "Validation loss: 1.3122811317443848\n",
      "mse 1.3122811259311076\n",
      "New best model found at epoch 131 with validation loss 1.3122811317443848\n",
      "Starting Epoch 132\n",
      "1.3159183313449223\n",
      "Validation loss: 1.3117246627807617\n",
      "mse 1.3117246109769958\n",
      "New best model found at epoch 132 with validation loss 1.3117246627807617\n",
      "Starting Epoch 133\n",
      "1.3150884062051773\n",
      "Validation loss: 1.3112350702285767\n",
      "mse 1.3112351129739226\n",
      "New best model found at epoch 133 with validation loss 1.3112350702285767\n",
      "Starting Epoch 134\n",
      "1.3144240379333496\n",
      "Validation loss: 1.3108948469161987\n",
      "mse 1.3108947998792602\n",
      "New best model found at epoch 134 with validation loss 1.3108948469161987\n",
      "Starting Epoch 135\n",
      "1.3136250575383503\n",
      "Validation loss: 1.3101176023483276\n",
      "mse 1.3101176895311355\n",
      "New best model found at epoch 135 with validation loss 1.3101176023483276\n",
      "Starting Epoch 136\n",
      "1.313012587527434\n",
      "Validation loss: 1.3094098567962646\n",
      "mse 1.309409796645068\n",
      "New best model found at epoch 136 with validation loss 1.3094098567962646\n",
      "Starting Epoch 137\n",
      "1.3122179607550304\n",
      "Validation loss: 1.3089905977249146\n",
      "mse 1.308990642290044\n",
      "New best model found at epoch 137 with validation loss 1.3089905977249146\n",
      "Starting Epoch 138\n",
      "1.3115394363800685\n",
      "Validation loss: 1.3083696365356445\n",
      "mse 1.308369705536669\n",
      "New best model found at epoch 138 with validation loss 1.3083696365356445\n",
      "Starting Epoch 139\n",
      "1.3108182152112324\n",
      "Validation loss: 1.3080511093139648\n",
      "mse 1.3080511271272275\n",
      "New best model found at epoch 139 with validation loss 1.3080511093139648\n",
      "Starting Epoch 140\n",
      "1.3102306127548218\n",
      "Validation loss: 1.307227611541748\n",
      "mse 1.307227640022723\n",
      "New best model found at epoch 140 with validation loss 1.307227611541748\n",
      "Starting Epoch 141\n",
      "1.3095575844248135\n",
      "Validation loss: 1.3069422245025635\n",
      "mse 1.3069422989372053\n",
      "New best model found at epoch 141 with validation loss 1.3069422245025635\n",
      "Starting Epoch 142\n",
      "1.308791697025299\n",
      "Validation loss: 1.3063976764678955\n",
      "mse 1.306397731616737\n",
      "New best model found at epoch 142 with validation loss 1.3063976764678955\n",
      "Starting Epoch 143\n",
      "1.308253715435664\n",
      "Validation loss: 1.3058604001998901\n",
      "mse 1.3058604053749112\n",
      "New best model found at epoch 143 with validation loss 1.3058604001998901\n",
      "Starting Epoch 144\n",
      "1.3074801216522853\n",
      "Validation loss: 1.3056881427764893\n",
      "mse 1.3056881317142366\n",
      "New best model found at epoch 144 with validation loss 1.3056881427764893\n",
      "Starting Epoch 145\n",
      "1.306878072520097\n",
      "Validation loss: 1.305144190788269\n",
      "mse 1.3051442688086725\n",
      "New best model found at epoch 145 with validation loss 1.305144190788269\n",
      "Starting Epoch 146\n",
      "1.3061955745021503\n",
      "Validation loss: 1.3044474124908447\n",
      "mse 1.3044474516316475\n",
      "New best model found at epoch 146 with validation loss 1.3044474124908447\n",
      "Starting Epoch 147\n",
      "1.3054869621992111\n",
      "Validation loss: 1.3042768239974976\n",
      "mse 1.304276746110795\n",
      "New best model found at epoch 147 with validation loss 1.3042768239974976\n",
      "Starting Epoch 148\n",
      "1.3048306827743847\n",
      "Validation loss: 1.3037102222442627\n",
      "mse 1.3037102241279817\n",
      "New best model found at epoch 148 with validation loss 1.3037102222442627\n",
      "Starting Epoch 149\n",
      "1.3043218453725178\n",
      "Validation loss: 1.3031103610992432\n",
      "mse 1.3031103697267727\n",
      "New best model found at epoch 149 with validation loss 1.3031103610992432\n",
      "Starting Epoch 150\n",
      "1.3036519785722096\n",
      "Validation loss: 1.3027007579803467\n",
      "mse 1.3027006848216423\n",
      "New best model found at epoch 150 with validation loss 1.3027007579803467\n",
      "Starting Epoch 151\n",
      "1.3030095944801967\n",
      "Validation loss: 1.3025307655334473\n",
      "mse 1.302530804319383\n",
      "New best model found at epoch 151 with validation loss 1.3025307655334473\n",
      "Starting Epoch 152\n",
      "1.302481879790624\n",
      "Validation loss: 1.302286148071289\n",
      "mse 1.3022861481592336\n",
      "New best model found at epoch 152 with validation loss 1.302286148071289\n",
      "Starting Epoch 153\n",
      "1.3017906273404758\n",
      "Validation loss: 1.3016823530197144\n",
      "mse 1.3016823845393548\n",
      "New best model found at epoch 153 with validation loss 1.3016823530197144\n",
      "Starting Epoch 154\n",
      "1.3012412190437317\n",
      "Validation loss: 1.3016337156295776\n",
      "mse 1.3016337622281766\n",
      "New best model found at epoch 154 with validation loss 1.3016337156295776\n",
      "Starting Epoch 155\n",
      "1.3005987455447514\n",
      "Validation loss: 1.300827980041504\n",
      "mse 1.3008280208992142\n",
      "New best model found at epoch 155 with validation loss 1.300827980041504\n",
      "Starting Epoch 156\n",
      "1.3001336703697841\n",
      "Validation loss: 1.300453782081604\n",
      "mse 1.3004536742706194\n",
      "New best model found at epoch 156 with validation loss 1.300453782081604\n",
      "Starting Epoch 157\n",
      "1.299497477710247\n",
      "Validation loss: 1.300296425819397\n",
      "mse 1.3002963509347443\n",
      "New best model found at epoch 157 with validation loss 1.300296425819397\n",
      "Starting Epoch 158\n",
      "1.2988896320263545\n",
      "Validation loss: 1.30008065700531\n",
      "mse 1.3000808461115596\n",
      "New best model found at epoch 158 with validation loss 1.30008065700531\n",
      "Starting Epoch 159\n",
      "1.2983828236659367\n",
      "Validation loss: 1.2999485731124878\n",
      "mse 1.2999485963462625\n",
      "New best model found at epoch 159 with validation loss 1.2999485731124878\n",
      "Starting Epoch 160\n",
      "1.2978199323018391\n",
      "Validation loss: 1.2991163730621338\n",
      "mse 1.2991163116231792\n",
      "New best model found at epoch 160 with validation loss 1.2991163730621338\n",
      "Starting Epoch 161\n",
      "1.297260008752346\n",
      "Validation loss: 1.2988808155059814\n",
      "mse 1.298880891960996\n",
      "New best model found at epoch 161 with validation loss 1.2988808155059814\n",
      "Starting Epoch 162\n",
      "1.2966993848482768\n",
      "Validation loss: 1.2987873554229736\n",
      "mse 1.2987872775374347\n",
      "New best model found at epoch 162 with validation loss 1.2987873554229736\n",
      "Starting Epoch 163\n",
      "1.2961413885156314\n",
      "Validation loss: 1.2983638048171997\n",
      "mse 1.2983637706595332\n",
      "New best model found at epoch 163 with validation loss 1.2983638048171997\n",
      "Starting Epoch 164\n",
      "1.2955925340453784\n",
      "Validation loss: 1.2980296611785889\n",
      "mse 1.29802960562354\n",
      "New best model found at epoch 164 with validation loss 1.2980296611785889\n",
      "Starting Epoch 165\n",
      "1.2950876653194427\n",
      "Validation loss: 1.2977988719940186\n",
      "mse 1.2977987517581053\n",
      "New best model found at epoch 165 with validation loss 1.2977988719940186\n",
      "Starting Epoch 166\n",
      "1.2944394797086716\n",
      "Validation loss: 1.297441840171814\n",
      "mse 1.2974419096541336\n",
      "New best model found at epoch 166 with validation loss 1.297441840171814\n",
      "Starting Epoch 167\n",
      "1.2939998507499695\n",
      "Validation loss: 1.297224998474121\n",
      "mse 1.297225047768456\n",
      "New best model found at epoch 167 with validation loss 1.297224998474121\n",
      "Starting Epoch 168\n",
      "1.2935199563701947\n",
      "Validation loss: 1.2970620393753052\n",
      "mse 1.297062130875799\n",
      "New best model found at epoch 168 with validation loss 1.2970620393753052\n",
      "Starting Epoch 169\n",
      "1.2929017742474873\n",
      "Validation loss: 1.296919584274292\n",
      "mse 1.296919575796082\n",
      "New best model found at epoch 169 with validation loss 1.296919584274292\n",
      "Starting Epoch 170\n",
      "1.292439100642999\n",
      "Validation loss: 1.296168565750122\n",
      "mse 1.2961684944491028\n",
      "New best model found at epoch 170 with validation loss 1.296168565750122\n",
      "Starting Epoch 171\n",
      "1.2918592691421509\n",
      "Validation loss: 1.2962872982025146\n",
      "mse 1.2962872773085676\n",
      "Starting Epoch 172\n",
      "1.291349433362484\n",
      "Validation loss: 1.2957504987716675\n",
      "mse 1.2957504938459992\n",
      "New best model found at epoch 172 with validation loss 1.2957504987716675\n",
      "Starting Epoch 173\n",
      "1.2909016857544582\n",
      "Validation loss: 1.29582679271698\n",
      "mse 1.2958267121685734\n",
      "Starting Epoch 174\n",
      "1.2902164707581203\n",
      "Validation loss: 1.2949550151824951\n",
      "mse 1.2949550118401916\n",
      "New best model found at epoch 174 with validation loss 1.2949550151824951\n",
      "Starting Epoch 175\n",
      "1.2899016638596852\n",
      "Validation loss: 1.2945888042449951\n",
      "mse 1.294588732538488\n",
      "New best model found at epoch 175 with validation loss 1.2945888042449951\n",
      "Starting Epoch 176\n",
      "1.2893237868944805\n",
      "Validation loss: 1.2948309183120728\n",
      "mse 1.2948308048331034\n",
      "Starting Epoch 177\n",
      "1.2889117648204167\n",
      "Validation loss: 1.2943658828735352\n",
      "mse 1.294365851385126\n",
      "New best model found at epoch 177 with validation loss 1.2943658828735352\n",
      "Starting Epoch 178\n",
      "1.288341224193573\n",
      "Validation loss: 1.2941019535064697\n",
      "mse 1.2941018982072001\n",
      "New best model found at epoch 178 with validation loss 1.2941019535064697\n",
      "Starting Epoch 179\n",
      "1.2877922753492992\n",
      "Validation loss: 1.2942718267440796\n",
      "mse 1.2942717805883068\n",
      "Starting Epoch 180\n",
      "1.2873803700009983\n",
      "Validation loss: 1.2936807870864868\n",
      "mse 1.2936807095745144\n",
      "New best model found at epoch 180 with validation loss 1.2936807870864868\n",
      "Starting Epoch 181\n",
      "1.2869460756580036\n",
      "Validation loss: 1.2936158180236816\n",
      "mse 1.2936158458006335\n",
      "New best model found at epoch 181 with validation loss 1.2936158180236816\n",
      "Starting Epoch 182\n",
      "1.2865164826313655\n",
      "Validation loss: 1.2933385372161865\n",
      "mse 1.2933384290765446\n",
      "New best model found at epoch 182 with validation loss 1.2933385372161865\n",
      "Starting Epoch 183\n",
      "1.28606974085172\n",
      "Validation loss: 1.2933199405670166\n",
      "mse 1.293319969409504\n",
      "New best model found at epoch 183 with validation loss 1.2933199405670166\n",
      "Starting Epoch 184\n",
      "1.285566784441471\n",
      "Validation loss: 1.292963981628418\n",
      "mse 1.292964011364626\n",
      "New best model found at epoch 184 with validation loss 1.292963981628418\n",
      "Starting Epoch 185\n",
      "1.2850431725382805\n",
      "Validation loss: 1.2927449941635132\n",
      "mse 1.2927451377191277\n",
      "New best model found at epoch 185 with validation loss 1.2927449941635132\n",
      "Starting Epoch 186\n",
      "1.2845972677071889\n",
      "Validation loss: 1.29258394241333\n",
      "mse 1.2925838332188089\n",
      "New best model found at epoch 186 with validation loss 1.29258394241333\n",
      "Starting Epoch 187\n",
      "1.2841895446181297\n",
      "Validation loss: 1.2928320169448853\n",
      "mse 1.2928318447631628\n",
      "Starting Epoch 188\n",
      "1.2837167978286743\n",
      "Validation loss: 1.2923494577407837\n",
      "mse 1.2923493964626527\n",
      "New best model found at epoch 188 with validation loss 1.2923494577407837\n",
      "Starting Epoch 189\n",
      "1.2832405442992847\n",
      "Validation loss: 1.2919224500656128\n",
      "mse 1.2919225143988242\n",
      "New best model found at epoch 189 with validation loss 1.2919224500656128\n",
      "Starting Epoch 190\n",
      "1.2827754641572635\n",
      "Validation loss: 1.2918071746826172\n",
      "mse 1.2918071447731811\n",
      "New best model found at epoch 190 with validation loss 1.2918071746826172\n",
      "Starting Epoch 191\n",
      "1.282296173274517\n",
      "Validation loss: 1.2921608686447144\n",
      "mse 1.292160845166866\n",
      "Starting Epoch 192\n",
      "1.2819413567582767\n",
      "Validation loss: 1.291446328163147\n",
      "mse 1.2914463467117898\n",
      "New best model found at epoch 192 with validation loss 1.291446328163147\n",
      "Starting Epoch 193\n",
      "1.2814521292845409\n",
      "Validation loss: 1.2913304567337036\n",
      "mse 1.291330485150661\n",
      "New best model found at epoch 193 with validation loss 1.2913304567337036\n",
      "Starting Epoch 194\n",
      "1.2809701884786289\n",
      "Validation loss: 1.2910679578781128\n",
      "mse 1.2910680045557659\n",
      "New best model found at epoch 194 with validation loss 1.2910679578781128\n",
      "Starting Epoch 195\n",
      "1.2804994583129883\n",
      "Validation loss: 1.2911784648895264\n",
      "mse 1.2911784164043112\n",
      "Starting Epoch 196\n",
      "1.2800637831290562\n",
      "Validation loss: 1.2907391786575317\n",
      "mse 1.2907390708235114\n",
      "New best model found at epoch 196 with validation loss 1.2907391786575317\n",
      "Starting Epoch 197\n",
      "1.2795691216985385\n",
      "Validation loss: 1.2911174297332764\n",
      "mse 1.2911175693588683\n",
      "Starting Epoch 198\n",
      "1.2791440139214199\n",
      "Validation loss: 1.290501356124878\n",
      "mse 1.290501212918443\n",
      "New best model found at epoch 198 with validation loss 1.290501356124878\n",
      "Starting Epoch 199\n",
      "1.278674530486266\n",
      "Validation loss: 1.2899044752120972\n",
      "mse 1.2899045894030852\n",
      "New best model found at epoch 199 with validation loss 1.2899044752120972\n",
      "Starting Epoch 200\n",
      "1.2782432089249294\n",
      "Validation loss: 1.2901779413223267\n",
      "mse 1.2901779260226194\n",
      "Starting Epoch 201\n",
      "1.2777783994873364\n",
      "Validation loss: 1.2895699739456177\n",
      "mse 1.2895699766434272\n",
      "New best model found at epoch 201 with validation loss 1.2895699739456177\n",
      "Starting Epoch 202\n",
      "1.2772347355882328\n",
      "Validation loss: 1.2892581224441528\n",
      "mse 1.2892581757618162\n",
      "New best model found at epoch 202 with validation loss 1.2892581224441528\n",
      "Starting Epoch 203\n",
      "1.276856169104576\n",
      "Validation loss: 1.2898792028427124\n",
      "mse 1.2898791061098769\n",
      "Starting Epoch 204\n",
      "1.276483530799548\n",
      "Validation loss: 1.2891649007797241\n",
      "mse 1.289164970547353\n",
      "New best model found at epoch 204 with validation loss 1.2891649007797241\n",
      "Starting Epoch 205\n",
      "1.276051012178262\n",
      "Validation loss: 1.289408802986145\n",
      "mse 1.2894089369071602\n",
      "Starting Epoch 206\n",
      "1.2755555013815563\n",
      "Validation loss: 1.2887492179870605\n",
      "mse 1.2887492094161994\n",
      "New best model found at epoch 206 with validation loss 1.2887492179870605\n",
      "Starting Epoch 207\n",
      "1.275286391377449\n",
      "Validation loss: 1.2891383171081543\n",
      "mse 1.2891385154521173\n",
      "Starting Epoch 208\n",
      "1.2748383258779843\n",
      "Validation loss: 1.2880566120147705\n",
      "mse 1.2880567412762207\n",
      "New best model found at epoch 208 with validation loss 1.2880566120147705\n",
      "Starting Epoch 209\n",
      "1.274376779794693\n",
      "Validation loss: 1.2887272834777832\n",
      "mse 1.288727321987709\n",
      "Starting Epoch 210\n",
      "1.2739985113342602\n",
      "Validation loss: 1.2880316972732544\n",
      "mse 1.2880316986582332\n",
      "New best model found at epoch 210 with validation loss 1.2880316972732544\n",
      "Starting Epoch 211\n",
      "1.2735199928283691\n",
      "Validation loss: 1.2875560522079468\n",
      "mse 1.2875558886105187\n",
      "New best model found at epoch 211 with validation loss 1.2875560522079468\n",
      "Starting Epoch 212\n",
      "1.273062340915203\n",
      "Validation loss: 1.28814697265625\n",
      "mse 1.2881470413091434\n",
      "Starting Epoch 213\n",
      "1.2728054746985435\n",
      "Validation loss: 1.287317156791687\n",
      "mse 1.2873172426311053\n",
      "New best model found at epoch 213 with validation loss 1.287317156791687\n",
      "Starting Epoch 214\n",
      "1.272288255393505\n",
      "Validation loss: 1.2871112823486328\n",
      "mse 1.2871111913176483\n",
      "New best model found at epoch 214 with validation loss 1.2871112823486328\n",
      "Starting Epoch 215\n",
      "1.2718644415338833\n",
      "Validation loss: 1.2877702713012695\n",
      "mse 1.2877703225245958\n",
      "Starting Epoch 216\n",
      "1.2715262522300084\n",
      "Validation loss: 1.2868804931640625\n",
      "mse 1.2868804181842677\n",
      "New best model found at epoch 216 with validation loss 1.2868804931640625\n",
      "Starting Epoch 217\n",
      "1.2710633352398872\n",
      "Validation loss: 1.2867684364318848\n",
      "mse 1.2867685489321876\n",
      "New best model found at epoch 217 with validation loss 1.2867684364318848\n",
      "Starting Epoch 218\n",
      "1.2703421513239543\n",
      "Validation loss: 1.2875295877456665\n",
      "mse 1.2875296741680038\n",
      "Starting Epoch 219\n",
      "1.2699121882518132\n",
      "Validation loss: 1.2866846323013306\n",
      "mse 1.2866846863730015\n",
      "New best model found at epoch 219 with validation loss 1.2866846323013306\n",
      "Starting Epoch 220\n",
      "1.2691469142834346\n",
      "Validation loss: 1.2868573665618896\n",
      "mse 1.286857203272098\n",
      "Starting Epoch 221\n",
      "1.2685374493400257\n",
      "Validation loss: 1.287497639656067\n",
      "mse 1.2874976554127193\n",
      "Starting Epoch 222\n",
      "1.268060142795245\n",
      "Validation loss: 1.286849021911621\n",
      "mse 1.2868488723911267\n",
      "Starting Epoch 223\n",
      "1.2674043625593185\n",
      "Validation loss: 1.2869048118591309\n",
      "mse 1.2869048160391825\n",
      "Starting Epoch 224\n",
      "1.2668107375502586\n",
      "Validation loss: 1.2875291109085083\n",
      "mse 1.2875291466298155\n",
      "Starting Epoch 225\n",
      "1.266393321255843\n",
      "Validation loss: 1.2865571975708008\n",
      "mse 1.2865571469427335\n",
      "New best model found at epoch 225 with validation loss 1.2865571975708008\n",
      "Starting Epoch 226\n",
      "1.2657369797428448\n",
      "Validation loss: 1.2865852117538452\n",
      "mse 1.2865852518294005\n",
      "Starting Epoch 227\n",
      "1.2652171105146408\n",
      "Validation loss: 1.2870749235153198\n",
      "mse 1.2870749802003731\n",
      "Starting Epoch 228\n",
      "1.2646132931113243\n",
      "Validation loss: 1.2866144180297852\n",
      "mse 1.2866144580528167\n",
      "Starting Epoch 229\n",
      "1.2641885330279667\n",
      "Validation loss: 1.286672592163086\n",
      "mse 1.2866726006271603\n",
      "Starting Epoch 230\n",
      "1.2636639599998791\n",
      "Validation loss: 1.2860115766525269\n",
      "mse 1.2860116445505796\n",
      "New best model found at epoch 230 with validation loss 1.2860115766525269\n",
      "Starting Epoch 231\n",
      "1.263204850256443\n",
      "Validation loss: 1.286344051361084\n",
      "mse 1.2863440563683664\n",
      "Starting Epoch 232\n",
      "1.2628977646430333\n",
      "Validation loss: 1.2857130765914917\n",
      "mse 1.2857130743008507\n",
      "New best model found at epoch 232 with validation loss 1.2857130765914917\n",
      "Starting Epoch 233\n",
      "1.2624911864598591\n",
      "Validation loss: 1.2852387428283691\n",
      "mse 1.2852387270681982\n",
      "New best model found at epoch 233 with validation loss 1.2852387428283691\n",
      "Starting Epoch 234\n",
      "1.2619743446509044\n",
      "Validation loss: 1.2857909202575684\n",
      "mse 1.2857908071219897\n",
      "Starting Epoch 235\n",
      "1.2616781815886497\n",
      "Validation loss: 1.2852553129196167\n",
      "mse 1.2852553129248894\n",
      "Starting Epoch 236\n",
      "1.261353110273679\n",
      "Validation loss: 1.2845749855041504\n",
      "mse 1.284574958063514\n",
      "New best model found at epoch 236 with validation loss 1.2845749855041504\n",
      "Starting Epoch 237\n",
      "1.2608703871568043\n",
      "Validation loss: 1.2846119403839111\n",
      "mse 1.2846119013007584\n",
      "Starting Epoch 238\n",
      "1.2604754120111465\n",
      "Validation loss: 1.284927487373352\n",
      "mse 1.284927471468759\n",
      "Starting Epoch 239\n",
      "1.2601468563079834\n",
      "Validation loss: 1.284792184829712\n",
      "mse 1.2847922249116905\n",
      "Starting Epoch 240\n",
      "1.2597465192278225\n",
      "Validation loss: 1.28436279296875\n",
      "mse 1.2843627277589271\n",
      "New best model found at epoch 240 with validation loss 1.28436279296875\n",
      "Starting Epoch 241\n",
      "1.2594659825166066\n",
      "Validation loss: 1.2844438552856445\n",
      "mse 1.2844439137400991\n",
      "Starting Epoch 242\n",
      "1.2589419707655907\n",
      "Validation loss: 1.2840855121612549\n",
      "mse 1.284085692557912\n",
      "New best model found at epoch 242 with validation loss 1.2840855121612549\n",
      "Starting Epoch 243\n",
      "1.2587807203332584\n",
      "Validation loss: 1.2841215133666992\n",
      "mse 1.2841214908531644\n",
      "Starting Epoch 244\n",
      "1.2583246851960819\n",
      "Validation loss: 1.283647060394287\n",
      "mse 1.283646873156034\n",
      "New best model found at epoch 244 with validation loss 1.283647060394287\n",
      "Starting Epoch 245\n",
      "1.2579137235879898\n",
      "Validation loss: 1.2832390069961548\n",
      "mse 1.2832389112560982\n",
      "New best model found at epoch 245 with validation loss 1.2832390069961548\n",
      "Starting Epoch 246\n",
      "1.2575141067306201\n",
      "Validation loss: 1.2833226919174194\n",
      "mse 1.2833226335397068\n",
      "Starting Epoch 247\n",
      "1.2571583141883214\n",
      "Validation loss: 1.2833645343780518\n",
      "mse 1.2833645946193533\n",
      "Starting Epoch 248\n",
      "1.2568719163537025\n",
      "Validation loss: 1.2831364870071411\n",
      "mse 1.2831364508852692\n",
      "New best model found at epoch 248 with validation loss 1.2831364870071411\n",
      "Starting Epoch 249\n",
      "1.256399152179559\n",
      "Validation loss: 1.2828025817871094\n",
      "mse 1.2828024633315298\n",
      "New best model found at epoch 249 with validation loss 1.2828025817871094\n",
      "Starting Epoch 250\n",
      "1.2561033243934314\n",
      "Validation loss: 1.282497525215149\n",
      "mse 1.2824976293775758\n",
      "New best model found at epoch 250 with validation loss 1.282497525215149\n",
      "Starting Epoch 251\n",
      "1.2556551819046338\n",
      "Validation loss: 1.2825195789337158\n",
      "mse 1.2825194930353643\n",
      "Starting Epoch 252\n",
      "1.2554046486814816\n",
      "Validation loss: 1.2822948694229126\n",
      "mse 1.2822947900518054\n",
      "New best model found at epoch 252 with validation loss 1.2822948694229126\n",
      "Starting Epoch 253\n",
      "1.2549911439418793\n",
      "Validation loss: 1.2819398641586304\n",
      "mse 1.2819398955412766\n",
      "New best model found at epoch 253 with validation loss 1.2819398641586304\n",
      "Starting Epoch 254\n",
      "1.2546755174795787\n",
      "Validation loss: 1.281908631324768\n",
      "mse 1.281908592771275\n",
      "New best model found at epoch 254 with validation loss 1.281908631324768\n",
      "Starting Epoch 255\n",
      "1.2541983798146248\n",
      "Validation loss: 1.2823636531829834\n",
      "mse 1.2823637211426493\n",
      "Starting Epoch 256\n",
      "1.2540161708990734\n",
      "Validation loss: 1.2814191579818726\n",
      "mse 1.2814192065693626\n",
      "New best model found at epoch 256 with validation loss 1.2814191579818726\n",
      "Starting Epoch 257\n",
      "1.2536294261614482\n",
      "Validation loss: 1.2815769910812378\n",
      "mse 1.2815767871839985\n",
      "Starting Epoch 258\n",
      "1.2533440242211025\n",
      "Validation loss: 1.281253695487976\n",
      "mse 1.2812536979808071\n",
      "New best model found at epoch 258 with validation loss 1.281253695487976\n",
      "Starting Epoch 259\n",
      "1.2528584773341815\n",
      "Validation loss: 1.2812058925628662\n",
      "mse 1.2812058797554147\n",
      "New best model found at epoch 259 with validation loss 1.2812058925628662\n",
      "Starting Epoch 260\n",
      "1.2526414518555005\n",
      "Validation loss: 1.2807159423828125\n",
      "mse 1.2807159168193227\n",
      "New best model found at epoch 260 with validation loss 1.2807159423828125\n",
      "Starting Epoch 261\n",
      "1.252221184472243\n",
      "Validation loss: 1.2809230089187622\n",
      "mse 1.2809228742269347\n",
      "Starting Epoch 262\n",
      "1.2519386063019435\n",
      "Validation loss: 1.280816912651062\n",
      "mse 1.2808169377221836\n",
      "Starting Epoch 263\n",
      "1.2515862360596657\n",
      "Validation loss: 1.2808492183685303\n",
      "mse 1.2808492739865933\n",
      "Starting Epoch 264\n",
      "1.2512502421935399\n",
      "Validation loss: 1.2801694869995117\n",
      "mse 1.2801694695244417\n",
      "New best model found at epoch 264 with validation loss 1.2801694869995117\n",
      "Starting Epoch 265\n",
      "1.2508656879266102\n",
      "Validation loss: 1.2803272008895874\n",
      "mse 1.2803272114858895\n",
      "Starting Epoch 266\n",
      "1.2505797644456227\n",
      "Validation loss: 1.279952883720398\n",
      "mse 1.2799528133515652\n",
      "New best model found at epoch 266 with validation loss 1.279952883720398\n",
      "Starting Epoch 267\n",
      "1.2502194792032242\n",
      "Validation loss: 1.280017375946045\n",
      "mse 1.2800172856989713\n",
      "Starting Epoch 268\n",
      "1.2498957738280296\n",
      "Validation loss: 1.2797112464904785\n",
      "mse 1.279711109042357\n",
      "New best model found at epoch 268 with validation loss 1.2797112464904785\n",
      "Starting Epoch 269\n",
      "1.24955269942681\n",
      "Validation loss: 1.279831886291504\n",
      "mse 1.2798319493100803\n",
      "Starting Epoch 270\n",
      "1.2491922577222188\n",
      "Validation loss: 1.2795640230178833\n",
      "mse 1.279564056251783\n",
      "New best model found at epoch 270 with validation loss 1.2795640230178833\n",
      "Starting Epoch 271\n",
      "1.2489511221647263\n",
      "Validation loss: 1.2792779207229614\n",
      "mse 1.279277995152621\n",
      "New best model found at epoch 271 with validation loss 1.2792779207229614\n",
      "Starting Epoch 272\n",
      "1.2486239771048229\n",
      "Validation loss: 1.2792800664901733\n",
      "mse 1.2792801578555462\n",
      "Starting Epoch 273\n",
      "1.2482265084981918\n",
      "Validation loss: 1.2790307998657227\n",
      "mse 1.2790307740502398\n",
      "New best model found at epoch 273 with validation loss 1.2790307998657227\n",
      "Starting Epoch 274\n",
      "1.2479505216081936\n",
      "Validation loss: 1.2790220975875854\n",
      "mse 1.2790220919977449\n",
      "New best model found at epoch 274 with validation loss 1.2790220975875854\n",
      "Starting Epoch 275\n",
      "1.2475793808698654\n",
      "Validation loss: 1.2789876461029053\n",
      "mse 1.2789876261374418\n",
      "New best model found at epoch 275 with validation loss 1.2789876461029053\n",
      "Starting Epoch 276\n",
      "1.2473152875900269\n",
      "Validation loss: 1.2787705659866333\n",
      "mse 1.2787704655880898\n",
      "New best model found at epoch 276 with validation loss 1.2787705659866333\n",
      "Starting Epoch 277\n",
      "1.2470683380961418\n",
      "Validation loss: 1.278516173362732\n",
      "mse 1.2785161263785336\n",
      "New best model found at epoch 277 with validation loss 1.278516173362732\n",
      "Starting Epoch 278\n",
      "1.2466852044065793\n",
      "Validation loss: 1.2785018682479858\n",
      "mse 1.2785018215185415\n",
      "New best model found at epoch 278 with validation loss 1.2785018682479858\n",
      "Starting Epoch 279\n",
      "1.2464061975479126\n",
      "Validation loss: 1.278275966644287\n",
      "mse 1.2782760346164685\n",
      "New best model found at epoch 279 with validation loss 1.278275966644287\n",
      "Starting Epoch 280\n",
      "1.2460993255178134\n",
      "Validation loss: 1.278302550315857\n",
      "mse 1.2783024961933382\n",
      "Starting Epoch 281\n",
      "1.2458128432432811\n",
      "Validation loss: 1.2780474424362183\n",
      "mse 1.2780474611093882\n",
      "New best model found at epoch 281 with validation loss 1.2780474424362183\n",
      "Starting Epoch 282\n",
      "1.245377503335476\n",
      "Validation loss: 1.2783182859420776\n",
      "mse 1.278318319077127\n",
      "Starting Epoch 283\n",
      "1.24516478429238\n",
      "Validation loss: 1.277805209159851\n",
      "mse 1.2778051600985938\n",
      "New best model found at epoch 283 with validation loss 1.277805209159851\n",
      "Starting Epoch 284\n",
      "1.2449022208650906\n",
      "Validation loss: 1.2777085304260254\n",
      "mse 1.2777085007937756\n",
      "New best model found at epoch 284 with validation loss 1.2777085304260254\n",
      "Starting Epoch 285\n",
      "1.2445476924379666\n",
      "Validation loss: 1.2770981788635254\n",
      "mse 1.2770982502548025\n",
      "New best model found at epoch 285 with validation loss 1.2770981788635254\n",
      "Starting Epoch 286\n",
      "1.2443576181928317\n",
      "Validation loss: 1.2771894931793213\n",
      "mse 1.277189432879097\n",
      "Starting Epoch 287\n",
      "1.244032507141431\n",
      "Validation loss: 1.2764948606491089\n",
      "mse 1.2764949260941014\n",
      "New best model found at epoch 287 with validation loss 1.2764948606491089\n",
      "Starting Epoch 288\n",
      "1.2435846080382664\n",
      "Validation loss: 1.2769927978515625\n",
      "mse 1.2769928701579703\n",
      "Starting Epoch 289\n",
      "1.2433284396926563\n",
      "Validation loss: 1.2771544456481934\n",
      "mse 1.2771542984842132\n",
      "Starting Epoch 290\n",
      "1.243094563484192\n",
      "Validation loss: 1.2767759561538696\n",
      "mse 1.2767759809207113\n",
      "Starting Epoch 291\n",
      "1.2427878181139629\n",
      "Validation loss: 1.27666175365448\n",
      "mse 1.2766617702479466\n",
      "Starting Epoch 292\n",
      "1.2425380821029346\n",
      "Validation loss: 1.276179313659668\n",
      "mse 1.276179322831515\n",
      "New best model found at epoch 292 with validation loss 1.276179313659668\n",
      "Starting Epoch 293\n",
      "1.2421182294686635\n",
      "Validation loss: 1.2764332294464111\n",
      "mse 1.2764333606456104\n",
      "Starting Epoch 294\n",
      "1.2417735556761424\n",
      "Validation loss: 1.2764770984649658\n",
      "mse 1.2764771414517635\n",
      "Starting Epoch 295\n",
      "1.241517926255862\n",
      "Validation loss: 1.2760480642318726\n",
      "mse 1.2760480833552426\n",
      "New best model found at epoch 295 with validation loss 1.2760480642318726\n",
      "Starting Epoch 296\n",
      "1.2412921686967213\n",
      "Validation loss: 1.275894284248352\n",
      "mse 1.2758943282746003\n",
      "New best model found at epoch 296 with validation loss 1.275894284248352\n",
      "Starting Epoch 297\n",
      "1.2409893696506817\n",
      "Validation loss: 1.2759180068969727\n",
      "mse 1.2759178347989861\n",
      "Starting Epoch 298\n",
      "1.240657592813174\n",
      "Validation loss: 1.2749590873718262\n",
      "mse 1.274959135742983\n",
      "New best model found at epoch 298 with validation loss 1.2749590873718262\n",
      "Starting Epoch 299\n",
      "1.2404541199405987\n",
      "Validation loss: 1.2746589183807373\n",
      "mse 1.2746588664675333\n",
      "New best model found at epoch 299 with validation loss 1.2746589183807373\n",
      "Starting Epoch 300\n",
      "1.2400137434403102\n",
      "Validation loss: 1.2746754884719849\n",
      "mse 1.2746754708123278\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-mean: 7-80-50-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9575f",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 3\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d8079886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d2f91dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,5,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "18b29c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'min(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f4318012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "7933b17d-1062-4d9c-9f89-30fca214822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.6243223498264947\n",
      "Validation loss: 1.9803472757339478\n",
      "mse 1.980347275152778\n",
      "New best model found at epoch 1 with validation loss 1.9803472757339478\n",
      "Starting Epoch 2\n",
      "1.9762608657280605\n",
      "Validation loss: 1.842280626296997\n",
      "mse 1.8422805205086255\n",
      "New best model found at epoch 2 with validation loss 1.842280626296997\n",
      "Starting Epoch 3\n",
      "1.89744238058726\n",
      "Validation loss: 1.7814147472381592\n",
      "mse 1.7814148042110296\n",
      "New best model found at epoch 3 with validation loss 1.7814147472381592\n",
      "Starting Epoch 4\n",
      "1.8554145594437916\n",
      "Validation loss: 1.7517324686050415\n",
      "mse 1.7517325596792084\n",
      "New best model found at epoch 4 with validation loss 1.7517324686050415\n",
      "Starting Epoch 5\n",
      "1.8266811122496922\n",
      "Validation loss: 1.7310782670974731\n",
      "mse 1.731078210203953\n",
      "New best model found at epoch 5 with validation loss 1.7310782670974731\n",
      "Starting Epoch 6\n",
      "1.8057951827843983\n",
      "Validation loss: 1.7163267135620117\n",
      "mse 1.7163268495083122\n",
      "New best model found at epoch 6 with validation loss 1.7163267135620117\n",
      "Starting Epoch 7\n",
      "1.7897357791662216\n",
      "Validation loss: 1.7058570384979248\n",
      "mse 1.7058570840133498\n",
      "New best model found at epoch 7 with validation loss 1.7058570384979248\n",
      "Starting Epoch 8\n",
      "1.7760567516088486\n",
      "Validation loss: 1.6964722871780396\n",
      "mse 1.6964724517530763\n",
      "New best model found at epoch 8 with validation loss 1.6964722871780396\n",
      "Starting Epoch 9\n",
      "1.7645315180222194\n",
      "Validation loss: 1.6898255348205566\n",
      "mse 1.6898256237209273\n",
      "New best model found at epoch 9 with validation loss 1.6898255348205566\n",
      "Starting Epoch 10\n",
      "1.7545695553223293\n",
      "Validation loss: 1.68338143825531\n",
      "mse 1.6833814392946471\n",
      "New best model found at epoch 10 with validation loss 1.68338143825531\n",
      "Starting Epoch 11\n",
      "1.7454570680856705\n",
      "Validation loss: 1.678110957145691\n",
      "mse 1.6781110714981748\n",
      "New best model found at epoch 11 with validation loss 1.678110957145691\n",
      "Starting Epoch 12\n",
      "1.7373218536376953\n",
      "Validation loss: 1.6733790636062622\n",
      "mse 1.6733791661579585\n",
      "New best model found at epoch 12 with validation loss 1.6733790636062622\n",
      "Starting Epoch 13\n",
      "1.7294592310984929\n",
      "Validation loss: 1.6684231758117676\n",
      "mse 1.6684231893089114\n",
      "New best model found at epoch 13 with validation loss 1.6684231758117676\n",
      "Starting Epoch 14\n",
      "1.7220250219106674\n",
      "Validation loss: 1.6649028062820435\n",
      "mse 1.6649027089554997\n",
      "New best model found at epoch 14 with validation loss 1.6649028062820435\n",
      "Starting Epoch 15\n",
      "1.7151140173276265\n",
      "Validation loss: 1.6601600646972656\n",
      "mse 1.6601600907870018\n",
      "New best model found at epoch 15 with validation loss 1.6601600646972656\n",
      "Starting Epoch 16\n",
      "1.708324561516444\n",
      "Validation loss: 1.656247615814209\n",
      "mse 1.6562476024416297\n",
      "New best model found at epoch 16 with validation loss 1.656247615814209\n",
      "Starting Epoch 17\n",
      "1.7018138418594997\n",
      "Validation loss: 1.651968240737915\n",
      "mse 1.6519683635394353\n",
      "New best model found at epoch 17 with validation loss 1.651968240737915\n",
      "Starting Epoch 18\n",
      "1.6956407527128856\n",
      "Validation loss: 1.6467622518539429\n",
      "mse 1.646762369078012\n",
      "New best model found at epoch 18 with validation loss 1.6467622518539429\n",
      "Starting Epoch 19\n",
      "1.6895543783903122\n",
      "Validation loss: 1.6432284116744995\n",
      "mse 1.6432284427145436\n",
      "New best model found at epoch 19 with validation loss 1.6432284116744995\n",
      "Starting Epoch 20\n",
      "1.6836656580368679\n",
      "Validation loss: 1.6388357877731323\n",
      "mse 1.6388357274732663\n",
      "New best model found at epoch 20 with validation loss 1.6388357877731323\n",
      "Starting Epoch 21\n",
      "1.678104226787885\n",
      "Validation loss: 1.6337904930114746\n",
      "mse 1.6337905560450174\n",
      "New best model found at epoch 21 with validation loss 1.6337904930114746\n",
      "Starting Epoch 22\n",
      "1.6730050295591354\n",
      "Validation loss: 1.6313425302505493\n",
      "mse 1.6313424597756814\n",
      "New best model found at epoch 22 with validation loss 1.6313425302505493\n",
      "Starting Epoch 23\n",
      "1.667731339732806\n",
      "Validation loss: 1.6282800436019897\n",
      "mse 1.6282801269867553\n",
      "New best model found at epoch 23 with validation loss 1.6282800436019897\n",
      "Starting Epoch 24\n",
      "1.6629022657871246\n",
      "Validation loss: 1.625083565711975\n",
      "mse 1.6250834933237968\n",
      "New best model found at epoch 24 with validation loss 1.625083565711975\n",
      "Starting Epoch 25\n",
      "1.6581164747476578\n",
      "Validation loss: 1.6217584609985352\n",
      "mse 1.621758555541614\n",
      "New best model found at epoch 25 with validation loss 1.6217584609985352\n",
      "Starting Epoch 26\n",
      "1.6533370713392894\n",
      "Validation loss: 1.6191484928131104\n",
      "mse 1.6191484501187323\n",
      "New best model found at epoch 26 with validation loss 1.6191484928131104\n",
      "Starting Epoch 27\n",
      "1.6488827069600422\n",
      "Validation loss: 1.6161236763000488\n",
      "mse 1.6161237914008715\n",
      "New best model found at epoch 27 with validation loss 1.6161236763000488\n",
      "Starting Epoch 28\n",
      "1.6442771355311077\n",
      "Validation loss: 1.6126564741134644\n",
      "mse 1.6126567043975686\n",
      "New best model found at epoch 28 with validation loss 1.6126564741134644\n",
      "Starting Epoch 29\n",
      "1.6400175939003627\n",
      "Validation loss: 1.6093218326568604\n",
      "mse 1.6093219465860538\n",
      "New best model found at epoch 29 with validation loss 1.6093218326568604\n",
      "Starting Epoch 30\n",
      "1.635433961947759\n",
      "Validation loss: 1.6059768199920654\n",
      "mse 1.6059767711838737\n",
      "New best model found at epoch 30 with validation loss 1.6059768199920654\n",
      "Starting Epoch 31\n",
      "1.6309977074464161\n",
      "Validation loss: 1.6039196252822876\n",
      "mse 1.6039196670459281\n",
      "New best model found at epoch 31 with validation loss 1.6039196252822876\n",
      "Starting Epoch 32\n",
      "1.6268203655878704\n",
      "Validation loss: 1.601236343383789\n",
      "mse 1.6012364594565502\n",
      "New best model found at epoch 32 with validation loss 1.601236343383789\n",
      "Starting Epoch 33\n",
      "1.6225569893916447\n",
      "Validation loss: 1.5984907150268555\n",
      "mse 1.5984906938045758\n",
      "New best model found at epoch 33 with validation loss 1.5984907150268555\n",
      "Starting Epoch 34\n",
      "1.6186984032392502\n",
      "Validation loss: 1.5954551696777344\n",
      "mse 1.5954551100913827\n",
      "New best model found at epoch 34 with validation loss 1.5954551696777344\n",
      "Starting Epoch 35\n",
      "1.614549254377683\n",
      "Validation loss: 1.5926883220672607\n",
      "mse 1.592688390896337\n",
      "New best model found at epoch 35 with validation loss 1.5926883220672607\n",
      "Starting Epoch 36\n",
      "1.6106115380922954\n",
      "Validation loss: 1.5901130437850952\n",
      "mse 1.5901130047546568\n",
      "New best model found at epoch 36 with validation loss 1.5901130437850952\n",
      "Starting Epoch 37\n",
      "1.6068837990363438\n",
      "Validation loss: 1.5874851942062378\n",
      "mse 1.5874852802565935\n",
      "New best model found at epoch 37 with validation loss 1.5874851942062378\n",
      "Starting Epoch 38\n",
      "1.602882261077563\n",
      "Validation loss: 1.5859296321868896\n",
      "mse 1.5859296290461937\n",
      "New best model found at epoch 38 with validation loss 1.5859296321868896\n",
      "Starting Epoch 39\n",
      "1.5993195921182632\n",
      "Validation loss: 1.5819159746170044\n",
      "mse 1.5819159779867544\n",
      "New best model found at epoch 39 with validation loss 1.5819159746170044\n",
      "Starting Epoch 40\n",
      "1.5954163670539856\n",
      "Validation loss: 1.580206274986267\n",
      "mse 1.5802062293820662\n",
      "New best model found at epoch 40 with validation loss 1.580206274986267\n",
      "Starting Epoch 41\n",
      "1.591849644978841\n",
      "Validation loss: 1.576453685760498\n",
      "mse 1.5764535785594507\n",
      "New best model found at epoch 41 with validation loss 1.576453685760498\n",
      "Starting Epoch 42\n",
      "1.5882106920083363\n",
      "Validation loss: 1.573991060256958\n",
      "mse 1.573991185324881\n",
      "New best model found at epoch 42 with validation loss 1.573991060256958\n",
      "Starting Epoch 43\n",
      "1.5846088031927745\n",
      "Validation loss: 1.5715619325637817\n",
      "mse 1.5715618870461479\n",
      "New best model found at epoch 43 with validation loss 1.5715619325637817\n",
      "Starting Epoch 44\n",
      "1.5812542488177617\n",
      "Validation loss: 1.5683659315109253\n",
      "mse 1.5683658937687477\n",
      "New best model found at epoch 44 with validation loss 1.5683659315109253\n",
      "Starting Epoch 45\n",
      "1.5777568072080612\n",
      "Validation loss: 1.5669106245040894\n",
      "mse 1.5669107024713527\n",
      "New best model found at epoch 45 with validation loss 1.5669106245040894\n",
      "Starting Epoch 46\n",
      "1.5744093259175618\n",
      "Validation loss: 1.5633620023727417\n",
      "mse 1.5633620127055112\n",
      "New best model found at epoch 46 with validation loss 1.5633620023727417\n",
      "Starting Epoch 47\n",
      "1.5709514270226161\n",
      "Validation loss: 1.5614216327667236\n",
      "mse 1.5614215812187868\n",
      "New best model found at epoch 47 with validation loss 1.5614216327667236\n",
      "Starting Epoch 48\n",
      "1.5677423427502315\n",
      "Validation loss: 1.5590766668319702\n",
      "mse 1.5590766892066377\n",
      "New best model found at epoch 48 with validation loss 1.5590766668319702\n",
      "Starting Epoch 49\n",
      "1.564467544356982\n",
      "Validation loss: 1.556317925453186\n",
      "mse 1.556317882477807\n",
      "New best model found at epoch 49 with validation loss 1.556317925453186\n",
      "Starting Epoch 50\n",
      "1.5613079518079758\n",
      "Validation loss: 1.5540974140167236\n",
      "mse 1.5540973258590434\n",
      "New best model found at epoch 50 with validation loss 1.5540974140167236\n",
      "Starting Epoch 51\n",
      "1.5579098959763844\n",
      "Validation loss: 1.5506336688995361\n",
      "mse 1.5506337615052386\n",
      "New best model found at epoch 51 with validation loss 1.5506336688995361\n",
      "Starting Epoch 52\n",
      "1.554799680908521\n",
      "Validation loss: 1.549075961112976\n",
      "mse 1.5490760188457209\n",
      "New best model found at epoch 52 with validation loss 1.549075961112976\n",
      "Starting Epoch 53\n",
      "1.5515543570121129\n",
      "Validation loss: 1.5477938652038574\n",
      "mse 1.547793842116799\n",
      "New best model found at epoch 53 with validation loss 1.5477938652038574\n",
      "Starting Epoch 54\n",
      "1.5483785271644592\n",
      "Validation loss: 1.5435988903045654\n",
      "mse 1.5435989701350479\n",
      "New best model found at epoch 54 with validation loss 1.5435988903045654\n",
      "Starting Epoch 55\n",
      "1.5452448974053066\n",
      "Validation loss: 1.5433533191680908\n",
      "mse 1.5433533283841436\n",
      "New best model found at epoch 55 with validation loss 1.5433533191680908\n",
      "Starting Epoch 56\n",
      "1.542169118920962\n",
      "Validation loss: 1.539557933807373\n",
      "mse 1.5395580204051038\n",
      "New best model found at epoch 56 with validation loss 1.539557933807373\n",
      "Starting Epoch 57\n",
      "1.538810004790624\n",
      "Validation loss: 1.5368105173110962\n",
      "mse 1.536810602335665\n",
      "New best model found at epoch 57 with validation loss 1.5368105173110962\n",
      "Starting Epoch 58\n",
      "1.5354985296726227\n",
      "Validation loss: 1.534292459487915\n",
      "mse 1.534292540597886\n",
      "New best model found at epoch 58 with validation loss 1.534292459487915\n",
      "Starting Epoch 59\n",
      "1.5324389040470123\n",
      "Validation loss: 1.53203547000885\n",
      "mse 1.5320353016487527\n",
      "New best model found at epoch 59 with validation loss 1.53203547000885\n",
      "Starting Epoch 60\n",
      "1.5291965703169506\n",
      "Validation loss: 1.530688762664795\n",
      "mse 1.5306887368482416\n",
      "New best model found at epoch 60 with validation loss 1.530688762664795\n",
      "Starting Epoch 61\n",
      "1.5258459746837616\n",
      "Validation loss: 1.528784155845642\n",
      "mse 1.52878418050012\n",
      "New best model found at epoch 61 with validation loss 1.528784155845642\n",
      "Starting Epoch 62\n",
      "1.5226217210292816\n",
      "Validation loss: 1.5260684490203857\n",
      "mse 1.526068481492065\n",
      "New best model found at epoch 62 with validation loss 1.5260684490203857\n",
      "Starting Epoch 63\n",
      "1.5193566332260768\n",
      "Validation loss: 1.5239919424057007\n",
      "mse 1.5239918722189547\n",
      "New best model found at epoch 63 with validation loss 1.5239919424057007\n",
      "Starting Epoch 64\n",
      "1.5163942376772563\n",
      "Validation loss: 1.521105408668518\n",
      "mse 1.5211053922141091\n",
      "New best model found at epoch 64 with validation loss 1.521105408668518\n",
      "Starting Epoch 65\n",
      "1.513668378194173\n",
      "Validation loss: 1.5190178155899048\n",
      "mse 1.5190178143538744\n",
      "New best model found at epoch 65 with validation loss 1.5190178155899048\n",
      "Starting Epoch 66\n",
      "1.5108153571685154\n",
      "Validation loss: 1.5168696641921997\n",
      "mse 1.51686963733061\n",
      "New best model found at epoch 66 with validation loss 1.5168696641921997\n",
      "Starting Epoch 67\n",
      "1.5082775453726451\n",
      "Validation loss: 1.5149811506271362\n",
      "mse 1.5149811371812334\n",
      "New best model found at epoch 67 with validation loss 1.5149811506271362\n",
      "Starting Epoch 68\n",
      "1.5055759747823079\n",
      "Validation loss: 1.5126413106918335\n",
      "mse 1.5126414344270362\n",
      "New best model found at epoch 68 with validation loss 1.5126413106918335\n",
      "Starting Epoch 69\n",
      "1.5028904279073079\n",
      "Validation loss: 1.5105985403060913\n",
      "mse 1.5105985445788184\n",
      "New best model found at epoch 69 with validation loss 1.5105985403060913\n",
      "Starting Epoch 70\n",
      "1.5006518612305324\n",
      "Validation loss: 1.508188247680664\n",
      "mse 1.5081882078764697\n",
      "New best model found at epoch 70 with validation loss 1.508188247680664\n",
      "Starting Epoch 71\n",
      "1.4981776823600133\n",
      "Validation loss: 1.5058977603912354\n",
      "mse 1.5058976234580108\n",
      "New best model found at epoch 71 with validation loss 1.5058977603912354\n",
      "Starting Epoch 72\n",
      "1.495662361383438\n",
      "Validation loss: 1.504105806350708\n",
      "mse 1.504105838841587\n",
      "New best model found at epoch 72 with validation loss 1.504105806350708\n",
      "Starting Epoch 73\n",
      "1.4933232615391414\n",
      "Validation loss: 1.5019402503967285\n",
      "mse 1.501940220912206\n",
      "New best model found at epoch 73 with validation loss 1.5019402503967285\n",
      "Starting Epoch 74\n",
      "1.4909867246945698\n",
      "Validation loss: 1.500431776046753\n",
      "mse 1.5004318227536053\n",
      "New best model found at epoch 74 with validation loss 1.500431776046753\n",
      "Starting Epoch 75\n",
      "1.4887099067370098\n",
      "Validation loss: 1.4984767436981201\n",
      "mse 1.4984766892697154\n",
      "New best model found at epoch 75 with validation loss 1.4984767436981201\n",
      "Starting Epoch 76\n",
      "1.486650635798772\n",
      "Validation loss: 1.4960931539535522\n",
      "mse 1.4960930649628454\n",
      "New best model found at epoch 76 with validation loss 1.4960931539535522\n",
      "Starting Epoch 77\n",
      "1.4844146023193996\n",
      "Validation loss: 1.4946274757385254\n",
      "mse 1.494627480074799\n",
      "New best model found at epoch 77 with validation loss 1.4946274757385254\n",
      "Starting Epoch 78\n",
      "1.4823725918928783\n",
      "Validation loss: 1.4921479225158691\n",
      "mse 1.4921478175583096\n",
      "New best model found at epoch 78 with validation loss 1.4921479225158691\n",
      "Starting Epoch 79\n",
      "1.4803715695937474\n",
      "Validation loss: 1.4909881353378296\n",
      "mse 1.490988194376683\n",
      "New best model found at epoch 79 with validation loss 1.4909881353378296\n",
      "Starting Epoch 80\n",
      "1.4780763188997905\n",
      "Validation loss: 1.4887633323669434\n",
      "mse 1.4887634782514645\n",
      "New best model found at epoch 80 with validation loss 1.4887633323669434\n",
      "Starting Epoch 81\n",
      "1.4761398981014888\n",
      "Validation loss: 1.488412857055664\n",
      "mse 1.4884128811331543\n",
      "New best model found at epoch 81 with validation loss 1.488412857055664\n",
      "Starting Epoch 82\n",
      "1.4741918245951335\n",
      "Validation loss: 1.485463261604309\n",
      "mse 1.4854632230429925\n",
      "New best model found at epoch 82 with validation loss 1.485463261604309\n",
      "Starting Epoch 83\n",
      "1.4721833169460297\n",
      "Validation loss: 1.4846932888031006\n",
      "mse 1.4846933637394768\n",
      "New best model found at epoch 83 with validation loss 1.4846932888031006\n",
      "Starting Epoch 84\n",
      "1.4704590737819672\n",
      "Validation loss: 1.4833351373672485\n",
      "mse 1.483335080822687\n",
      "New best model found at epoch 84 with validation loss 1.4833351373672485\n",
      "Starting Epoch 85\n",
      "1.4684155186017354\n",
      "Validation loss: 1.4815224409103394\n",
      "mse 1.4815224217394343\n",
      "New best model found at epoch 85 with validation loss 1.4815224409103394\n",
      "Starting Epoch 86\n",
      "1.4665269205967586\n",
      "Validation loss: 1.4798297882080078\n",
      "mse 1.4798297989328257\n",
      "New best model found at epoch 86 with validation loss 1.4798297882080078\n",
      "Starting Epoch 87\n",
      "1.4647093216578166\n",
      "Validation loss: 1.4779052734375\n",
      "mse 1.4779051402452614\n",
      "New best model found at epoch 87 with validation loss 1.4779052734375\n",
      "Starting Epoch 88\n",
      "1.4627967725197475\n",
      "Validation loss: 1.4776349067687988\n",
      "mse 1.4776349667656918\n",
      "New best model found at epoch 88 with validation loss 1.4776349067687988\n",
      "Starting Epoch 89\n",
      "1.461300864815712\n",
      "Validation loss: 1.4756710529327393\n",
      "mse 1.4756709623627442\n",
      "New best model found at epoch 89 with validation loss 1.4756710529327393\n",
      "Starting Epoch 90\n",
      "1.459441641966502\n",
      "Validation loss: 1.474469542503357\n",
      "mse 1.4744695845191662\n",
      "New best model found at epoch 90 with validation loss 1.474469542503357\n",
      "Starting Epoch 91\n",
      "1.4578193376461666\n",
      "Validation loss: 1.4723128080368042\n",
      "mse 1.4723127935823943\n",
      "New best model found at epoch 91 with validation loss 1.4723128080368042\n",
      "Starting Epoch 92\n",
      "1.4560509373744328\n",
      "Validation loss: 1.472211480140686\n",
      "mse 1.4722115288482545\n",
      "New best model found at epoch 92 with validation loss 1.472211480140686\n",
      "Starting Epoch 93\n",
      "1.4544301082690556\n",
      "Validation loss: 1.4709125757217407\n",
      "mse 1.4709126129111902\n",
      "New best model found at epoch 93 with validation loss 1.4709125757217407\n",
      "Starting Epoch 94\n",
      "1.4529203077157338\n",
      "Validation loss: 1.4693968296051025\n",
      "mse 1.469396775445518\n",
      "New best model found at epoch 94 with validation loss 1.4693968296051025\n",
      "Starting Epoch 95\n",
      "1.4512114723523457\n",
      "Validation loss: 1.4677629470825195\n",
      "mse 1.4677628234768914\n",
      "New best model found at epoch 95 with validation loss 1.4677629470825195\n",
      "Starting Epoch 96\n",
      "1.4498005360364914\n",
      "Validation loss: 1.465211272239685\n",
      "mse 1.4652112248133051\n",
      "New best model found at epoch 96 with validation loss 1.465211272239685\n",
      "Starting Epoch 97\n",
      "1.4482180923223495\n",
      "Validation loss: 1.4655917882919312\n",
      "mse 1.4655917442550626\n",
      "Starting Epoch 98\n",
      "1.4466423640648525\n",
      "Validation loss: 1.4626553058624268\n",
      "mse 1.4626554652515198\n",
      "New best model found at epoch 98 with validation loss 1.4626553058624268\n",
      "Starting Epoch 99\n",
      "1.4451339840888977\n",
      "Validation loss: 1.4621800184249878\n",
      "mse 1.4621799773332826\n",
      "New best model found at epoch 99 with validation loss 1.4621800184249878\n",
      "Starting Epoch 100\n",
      "1.4432998895645142\n",
      "Validation loss: 1.4599978923797607\n",
      "mse 1.4599978741231217\n",
      "New best model found at epoch 100 with validation loss 1.4599978923797607\n",
      "Starting Epoch 101\n",
      "1.441888650258382\n",
      "Validation loss: 1.4585317373275757\n",
      "mse 1.4585316347609023\n",
      "New best model found at epoch 101 with validation loss 1.4585317373275757\n",
      "Starting Epoch 102\n",
      "1.4400611172119777\n",
      "Validation loss: 1.4573898315429688\n",
      "mse 1.4573897867742445\n",
      "New best model found at epoch 102 with validation loss 1.4573898315429688\n",
      "Starting Epoch 103\n",
      "1.438429057598114\n",
      "Validation loss: 1.455944538116455\n",
      "mse 1.4559446302071477\n",
      "New best model found at epoch 103 with validation loss 1.455944538116455\n",
      "Starting Epoch 104\n",
      "1.4366988291343052\n",
      "Validation loss: 1.4554431438446045\n",
      "mse 1.455443071842937\n",
      "New best model found at epoch 104 with validation loss 1.4554431438446045\n",
      "Starting Epoch 105\n",
      "1.4350702315568924\n",
      "Validation loss: 1.4530620574951172\n",
      "mse 1.453062133716525\n",
      "New best model found at epoch 105 with validation loss 1.4530620574951172\n",
      "Starting Epoch 106\n",
      "1.4334359814723332\n",
      "Validation loss: 1.451616644859314\n",
      "mse 1.4516165319414769\n",
      "New best model found at epoch 106 with validation loss 1.451616644859314\n",
      "Starting Epoch 107\n",
      "1.4321139057477315\n",
      "Validation loss: 1.451454520225525\n",
      "mse 1.4514544869050916\n",
      "New best model found at epoch 107 with validation loss 1.451454520225525\n",
      "Starting Epoch 108\n",
      "1.430679718653361\n",
      "Validation loss: 1.449535608291626\n",
      "mse 1.4495355584648286\n",
      "New best model found at epoch 108 with validation loss 1.449535608291626\n",
      "Starting Epoch 109\n",
      "1.4292641182740529\n",
      "Validation loss: 1.44854736328125\n",
      "mse 1.4485473961736197\n",
      "New best model found at epoch 109 with validation loss 1.44854736328125\n",
      "Starting Epoch 110\n",
      "1.4279213796059291\n",
      "Validation loss: 1.446874976158142\n",
      "mse 1.4468750247269349\n",
      "New best model found at epoch 110 with validation loss 1.446874976158142\n",
      "Starting Epoch 111\n",
      "1.426613340775172\n",
      "Validation loss: 1.4459953308105469\n",
      "mse 1.4459953178420202\n",
      "New best model found at epoch 111 with validation loss 1.4459953308105469\n",
      "Starting Epoch 112\n",
      "1.4252507736285527\n",
      "Validation loss: 1.4438917636871338\n",
      "mse 1.4438918532820357\n",
      "New best model found at epoch 112 with validation loss 1.4438917636871338\n",
      "Starting Epoch 113\n",
      "1.4238458573818207\n",
      "Validation loss: 1.443221926689148\n",
      "mse 1.443221940152271\n",
      "New best model found at epoch 113 with validation loss 1.443221926689148\n",
      "Starting Epoch 114\n",
      "1.4225547462701797\n",
      "Validation loss: 1.4423646926879883\n",
      "mse 1.4423648587975963\n",
      "New best model found at epoch 114 with validation loss 1.4423646926879883\n",
      "Starting Epoch 115\n",
      "1.421268458167712\n",
      "Validation loss: 1.4401100873947144\n",
      "mse 1.440110010353061\n",
      "New best model found at epoch 115 with validation loss 1.4401100873947144\n",
      "Starting Epoch 116\n",
      "1.4198992153008778\n",
      "Validation loss: 1.4389519691467285\n",
      "mse 1.4389519925529959\n",
      "New best model found at epoch 116 with validation loss 1.4389519691467285\n",
      "Starting Epoch 117\n",
      "1.4186806281407673\n",
      "Validation loss: 1.4379266500473022\n",
      "mse 1.4379266743440793\n",
      "New best model found at epoch 117 with validation loss 1.4379266500473022\n",
      "Starting Epoch 118\n",
      "1.41747651497523\n",
      "Validation loss: 1.4359180927276611\n",
      "mse 1.4359180956351065\n",
      "New best model found at epoch 118 with validation loss 1.4359180927276611\n",
      "Starting Epoch 119\n",
      "1.416114906469981\n",
      "Validation loss: 1.4357203245162964\n",
      "mse 1.435720287394212\n",
      "New best model found at epoch 119 with validation loss 1.4357203245162964\n",
      "Starting Epoch 120\n",
      "1.414991555114587\n",
      "Validation loss: 1.434165358543396\n",
      "mse 1.4341652417142727\n",
      "New best model found at epoch 120 with validation loss 1.434165358543396\n",
      "Starting Epoch 121\n",
      "1.4137760177254677\n",
      "Validation loss: 1.4324945211410522\n",
      "mse 1.4324945210823514\n",
      "New best model found at epoch 121 with validation loss 1.4324945211410522\n",
      "Starting Epoch 122\n",
      "1.4125904813408852\n",
      "Validation loss: 1.4314502477645874\n",
      "mse 1.431450340498956\n",
      "New best model found at epoch 122 with validation loss 1.4314502477645874\n",
      "Starting Epoch 123\n",
      "1.4113510896762211\n",
      "Validation loss: 1.4303468465805054\n",
      "mse 1.4303467763738211\n",
      "New best model found at epoch 123 with validation loss 1.4303468465805054\n",
      "Starting Epoch 124\n",
      "1.4102906808257103\n",
      "Validation loss: 1.4295337200164795\n",
      "mse 1.4295338772886441\n",
      "New best model found at epoch 124 with validation loss 1.4295337200164795\n",
      "Starting Epoch 125\n",
      "1.4091934859752655\n",
      "Validation loss: 1.428316354751587\n",
      "mse 1.4283163822326403\n",
      "New best model found at epoch 125 with validation loss 1.428316354751587\n",
      "Starting Epoch 126\n",
      "1.4081151311596234\n",
      "Validation loss: 1.4266430139541626\n",
      "mse 1.4266429635120814\n",
      "New best model found at epoch 126 with validation loss 1.4266430139541626\n",
      "Starting Epoch 127\n",
      "1.4069659585754077\n",
      "Validation loss: 1.4260540008544922\n",
      "mse 1.4260539824194332\n",
      "New best model found at epoch 127 with validation loss 1.4260540008544922\n",
      "Starting Epoch 128\n",
      "1.405914140244325\n",
      "Validation loss: 1.424767255783081\n",
      "mse 1.4247672315962843\n",
      "New best model found at epoch 128 with validation loss 1.424767255783081\n",
      "Starting Epoch 129\n",
      "1.4048573076725006\n",
      "Validation loss: 1.4235401153564453\n",
      "mse 1.4235402264763266\n",
      "New best model found at epoch 129 with validation loss 1.4235401153564453\n",
      "Starting Epoch 130\n",
      "1.403712935745716\n",
      "Validation loss: 1.4219906330108643\n",
      "mse 1.4219906341190391\n",
      "New best model found at epoch 130 with validation loss 1.4219906330108643\n",
      "Starting Epoch 131\n",
      "1.4027494862675667\n",
      "Validation loss: 1.4211188554763794\n",
      "mse 1.421118733212352\n",
      "New best model found at epoch 131 with validation loss 1.4211188554763794\n",
      "Starting Epoch 132\n",
      "1.4016234651207924\n",
      "Validation loss: 1.4201810359954834\n",
      "mse 1.4201811777447078\n",
      "New best model found at epoch 132 with validation loss 1.4201810359954834\n",
      "Starting Epoch 133\n",
      "1.4006345470746357\n",
      "Validation loss: 1.418925166130066\n",
      "mse 1.418925024296347\n",
      "New best model found at epoch 133 with validation loss 1.418925166130066\n",
      "Starting Epoch 134\n",
      "1.3995718881487846\n",
      "Validation loss: 1.4179221391677856\n",
      "mse 1.4179221107516886\n",
      "New best model found at epoch 134 with validation loss 1.4179221391677856\n",
      "Starting Epoch 135\n",
      "1.3987235004703205\n",
      "Validation loss: 1.417262315750122\n",
      "mse 1.417262253253893\n",
      "New best model found at epoch 135 with validation loss 1.417262315750122\n",
      "Starting Epoch 136\n",
      "1.397719773153464\n",
      "Validation loss: 1.415770173072815\n",
      "mse 1.4157700343129789\n",
      "New best model found at epoch 136 with validation loss 1.415770173072815\n",
      "Starting Epoch 137\n",
      "1.3968053807814915\n",
      "Validation loss: 1.4155720472335815\n",
      "mse 1.4155720397353508\n",
      "New best model found at epoch 137 with validation loss 1.4155720472335815\n",
      "Starting Epoch 138\n",
      "1.395769976079464\n",
      "Validation loss: 1.4144572019577026\n",
      "mse 1.4144571139888833\n",
      "New best model found at epoch 138 with validation loss 1.4144572019577026\n",
      "Starting Epoch 139\n",
      "1.3949424127737682\n",
      "Validation loss: 1.413815975189209\n",
      "mse 1.4138158974782835\n",
      "New best model found at epoch 139 with validation loss 1.413815975189209\n",
      "Starting Epoch 140\n",
      "1.3939840992291768\n",
      "Validation loss: 1.4124130010604858\n",
      "mse 1.4124129585335499\n",
      "New best model found at epoch 140 with validation loss 1.4124130010604858\n",
      "Starting Epoch 141\n",
      "1.3931758925318718\n",
      "Validation loss: 1.4116460084915161\n",
      "mse 1.41164600566268\n",
      "New best model found at epoch 141 with validation loss 1.4116460084915161\n",
      "Starting Epoch 142\n",
      "1.3922999526063602\n",
      "Validation loss: 1.411332368850708\n",
      "mse 1.4113324753544838\n",
      "New best model found at epoch 142 with validation loss 1.411332368850708\n",
      "Starting Epoch 143\n",
      "1.391540303826332\n",
      "Validation loss: 1.4098341464996338\n",
      "mse 1.4098342166026256\n",
      "New best model found at epoch 143 with validation loss 1.4098341464996338\n",
      "Starting Epoch 144\n",
      "1.390645518898964\n",
      "Validation loss: 1.4097964763641357\n",
      "mse 1.4097965585919703\n",
      "New best model found at epoch 144 with validation loss 1.4097964763641357\n",
      "Starting Epoch 145\n",
      "1.3896550411979358\n",
      "Validation loss: 1.4090662002563477\n",
      "mse 1.4090663180734095\n",
      "New best model found at epoch 145 with validation loss 1.4090662002563477\n",
      "Starting Epoch 146\n",
      "1.3888545483350754\n",
      "Validation loss: 1.4083560705184937\n",
      "mse 1.4083560062726095\n",
      "New best model found at epoch 146 with validation loss 1.4083560705184937\n",
      "Starting Epoch 147\n",
      "1.3881577675541241\n",
      "Validation loss: 1.407512903213501\n",
      "mse 1.4075129083864635\n",
      "New best model found at epoch 147 with validation loss 1.407512903213501\n",
      "Starting Epoch 148\n",
      "1.3872312903404236\n",
      "Validation loss: 1.4069645404815674\n",
      "mse 1.4069646356023104\n",
      "New best model found at epoch 148 with validation loss 1.4069645404815674\n",
      "Starting Epoch 149\n",
      "1.3865143309036891\n",
      "Validation loss: 1.4061983823776245\n",
      "mse 1.4061983358678476\n",
      "New best model found at epoch 149 with validation loss 1.4061983823776245\n",
      "Starting Epoch 150\n",
      "1.3858483632405598\n",
      "Validation loss: 1.4057666063308716\n",
      "mse 1.4057665223693177\n",
      "New best model found at epoch 150 with validation loss 1.4057666063308716\n",
      "Starting Epoch 151\n",
      "1.3849272181590397\n",
      "Validation loss: 1.4049128293991089\n",
      "mse 1.4049126684084141\n",
      "New best model found at epoch 151 with validation loss 1.4049128293991089\n",
      "Starting Epoch 152\n",
      "1.384258637825648\n",
      "Validation loss: 1.4034640789031982\n",
      "mse 1.4034639165342326\n",
      "New best model found at epoch 152 with validation loss 1.4034640789031982\n",
      "Starting Epoch 153\n",
      "1.3833802690108616\n",
      "Validation loss: 1.4033528566360474\n",
      "mse 1.40335274036338\n",
      "New best model found at epoch 153 with validation loss 1.4033528566360474\n",
      "Starting Epoch 154\n",
      "1.3826997702320416\n",
      "Validation loss: 1.4017359018325806\n",
      "mse 1.401735935738765\n",
      "New best model found at epoch 154 with validation loss 1.4017359018325806\n",
      "Starting Epoch 155\n",
      "1.38190658390522\n",
      "Validation loss: 1.4018069505691528\n",
      "mse 1.401806756509338\n",
      "Starting Epoch 156\n",
      "1.3811903968453407\n",
      "Validation loss: 1.4007993936538696\n",
      "mse 1.4007995898134527\n",
      "New best model found at epoch 156 with validation loss 1.4007993936538696\n",
      "Starting Epoch 157\n",
      "1.3804084012905757\n",
      "Validation loss: 1.4007638692855835\n",
      "mse 1.4007636670981531\n",
      "New best model found at epoch 157 with validation loss 1.4007638692855835\n",
      "Starting Epoch 158\n",
      "1.3798650254805882\n",
      "Validation loss: 1.3994053602218628\n",
      "mse 1.3994053906205441\n",
      "New best model found at epoch 158 with validation loss 1.3994053602218628\n",
      "Starting Epoch 159\n",
      "1.3791215072075527\n",
      "Validation loss: 1.398808240890503\n",
      "mse 1.3988082643664383\n",
      "New best model found at epoch 159 with validation loss 1.398808240890503\n",
      "Starting Epoch 160\n",
      "1.378401793539524\n",
      "Validation loss: 1.398001790046692\n",
      "mse 1.3980017648472616\n",
      "New best model found at epoch 160 with validation loss 1.398001790046692\n",
      "Starting Epoch 161\n",
      "1.3777320037285488\n",
      "Validation loss: 1.3975327014923096\n",
      "mse 1.3975327158804336\n",
      "New best model found at epoch 161 with validation loss 1.3975327014923096\n",
      "Starting Epoch 162\n",
      "1.3771951297918956\n",
      "Validation loss: 1.3977158069610596\n",
      "mse 1.3977157579307644\n",
      "Starting Epoch 163\n",
      "1.3765339230497677\n",
      "Validation loss: 1.3965744972229004\n",
      "mse 1.3965744760794787\n",
      "New best model found at epoch 163 with validation loss 1.3965744972229004\n",
      "Starting Epoch 164\n",
      "1.3757491434613864\n",
      "Validation loss: 1.3954007625579834\n",
      "mse 1.3954006996041752\n",
      "New best model found at epoch 164 with validation loss 1.3954007625579834\n",
      "Starting Epoch 165\n",
      "1.3749702672163646\n",
      "Validation loss: 1.3952707052230835\n",
      "mse 1.3952706808554125\n",
      "New best model found at epoch 165 with validation loss 1.3952707052230835\n",
      "Starting Epoch 166\n",
      "1.3744766041636467\n",
      "Validation loss: 1.3943510055541992\n",
      "mse 1.3943511529353911\n",
      "New best model found at epoch 166 with validation loss 1.3943510055541992\n",
      "Starting Epoch 167\n",
      "1.3738835702339809\n",
      "Validation loss: 1.3940445184707642\n",
      "mse 1.3940444548456552\n",
      "New best model found at epoch 167 with validation loss 1.3940445184707642\n",
      "Starting Epoch 168\n",
      "1.3731933310627937\n",
      "Validation loss: 1.393216848373413\n",
      "mse 1.3932168786428585\n",
      "New best model found at epoch 168 with validation loss 1.393216848373413\n",
      "Starting Epoch 169\n",
      "1.3724638770023982\n",
      "Validation loss: 1.3927205801010132\n",
      "mse 1.3927206498775038\n",
      "New best model found at epoch 169 with validation loss 1.3927205801010132\n",
      "Starting Epoch 170\n",
      "1.371918390194575\n",
      "Validation loss: 1.3915122747421265\n",
      "mse 1.391512361410125\n",
      "New best model found at epoch 170 with validation loss 1.3915122747421265\n",
      "Starting Epoch 171\n",
      "1.3713506882389386\n",
      "Validation loss: 1.3913909196853638\n",
      "mse 1.3913910153497913\n",
      "New best model found at epoch 171 with validation loss 1.3913909196853638\n",
      "Starting Epoch 172\n",
      "1.3707063893477123\n",
      "Validation loss: 1.3911798000335693\n",
      "mse 1.3911799630660773\n",
      "New best model found at epoch 172 with validation loss 1.3911798000335693\n",
      "Starting Epoch 173\n",
      "1.3702061548829079\n",
      "Validation loss: 1.3901593685150146\n",
      "mse 1.390159457315742\n",
      "New best model found at epoch 173 with validation loss 1.3901593685150146\n",
      "Starting Epoch 174\n",
      "1.369507151345412\n",
      "Validation loss: 1.388883352279663\n",
      "mse 1.3888832559790423\n",
      "New best model found at epoch 174 with validation loss 1.388883352279663\n",
      "Starting Epoch 175\n",
      "1.3688458353281021\n",
      "Validation loss: 1.3885879516601562\n",
      "mse 1.388587983539862\n",
      "New best model found at epoch 175 with validation loss 1.3885879516601562\n",
      "Starting Epoch 176\n",
      "1.3683771739403408\n",
      "Validation loss: 1.3878158330917358\n",
      "mse 1.3878158118885784\n",
      "New best model found at epoch 176 with validation loss 1.3878158330917358\n",
      "Starting Epoch 177\n",
      "1.3677117998401325\n",
      "Validation loss: 1.387123465538025\n",
      "mse 1.3871235484817404\n",
      "New best model found at epoch 177 with validation loss 1.387123465538025\n",
      "Starting Epoch 178\n",
      "1.3671986336509387\n",
      "Validation loss: 1.3863059282302856\n",
      "mse 1.3863060575045298\n",
      "New best model found at epoch 178 with validation loss 1.3863059282302856\n",
      "Starting Epoch 179\n",
      "1.3665486375490825\n",
      "Validation loss: 1.3867868185043335\n",
      "mse 1.3867870447542106\n",
      "Starting Epoch 180\n",
      "1.3662078479925792\n",
      "Validation loss: 1.3859905004501343\n",
      "mse 1.3859905593645132\n",
      "New best model found at epoch 180 with validation loss 1.3859905004501343\n",
      "Starting Epoch 181\n",
      "1.3656088039278984\n",
      "Validation loss: 1.3851186037063599\n",
      "mse 1.3851185866355573\n",
      "New best model found at epoch 181 with validation loss 1.3851186037063599\n",
      "Starting Epoch 182\n",
      "1.3650188619891803\n",
      "Validation loss: 1.3835153579711914\n",
      "mse 1.3835154337501985\n",
      "New best model found at epoch 182 with validation loss 1.3835153579711914\n",
      "Starting Epoch 183\n",
      "1.3644185960292816\n",
      "Validation loss: 1.3834483623504639\n",
      "mse 1.3834482892710274\n",
      "New best model found at epoch 183 with validation loss 1.3834483623504639\n",
      "Starting Epoch 184\n",
      "1.3639313007394473\n",
      "Validation loss: 1.3819890022277832\n",
      "mse 1.3819890593632076\n",
      "New best model found at epoch 184 with validation loss 1.3819890022277832\n",
      "Starting Epoch 185\n",
      "1.3633766646186511\n",
      "Validation loss: 1.3817663192749023\n",
      "mse 1.3817662985528405\n",
      "New best model found at epoch 185 with validation loss 1.3817663192749023\n",
      "Starting Epoch 186\n",
      "1.3627318640549977\n",
      "Validation loss: 1.380886435508728\n",
      "mse 1.3808862363667949\n",
      "New best model found at epoch 186 with validation loss 1.380886435508728\n",
      "Starting Epoch 187\n",
      "1.3623227203885715\n",
      "Validation loss: 1.3805019855499268\n",
      "mse 1.3805019845162632\n",
      "New best model found at epoch 187 with validation loss 1.3805019855499268\n",
      "Starting Epoch 188\n",
      "1.361951395869255\n",
      "Validation loss: 1.379518747329712\n",
      "mse 1.3795188176380602\n",
      "New best model found at epoch 188 with validation loss 1.379518747329712\n",
      "Starting Epoch 189\n",
      "1.3612433522939682\n",
      "Validation loss: 1.3793474435806274\n",
      "mse 1.3793474396816567\n",
      "New best model found at epoch 189 with validation loss 1.3793474435806274\n",
      "Starting Epoch 190\n",
      "1.3607667684555054\n",
      "Validation loss: 1.378666877746582\n",
      "mse 1.378666961387796\n",
      "New best model found at epoch 190 with validation loss 1.378666877746582\n",
      "Starting Epoch 191\n",
      "1.360445536673069\n",
      "Validation loss: 1.3779561519622803\n",
      "mse 1.377956183246089\n",
      "New best model found at epoch 191 with validation loss 1.3779561519622803\n",
      "Starting Epoch 192\n",
      "1.359819583594799\n",
      "Validation loss: 1.377762794494629\n",
      "mse 1.377762822095249\n",
      "New best model found at epoch 192 with validation loss 1.377762794494629\n",
      "Starting Epoch 193\n",
      "1.3593374838431675\n",
      "Validation loss: 1.3772215843200684\n",
      "mse 1.3772214868074741\n",
      "New best model found at epoch 193 with validation loss 1.3772215843200684\n",
      "Starting Epoch 194\n",
      "1.359005980193615\n",
      "Validation loss: 1.3773642778396606\n",
      "mse 1.3773642742962326\n",
      "Starting Epoch 195\n",
      "1.3584481701254845\n",
      "Validation loss: 1.3762952089309692\n",
      "mse 1.3762952019365107\n",
      "New best model found at epoch 195 with validation loss 1.3762952089309692\n",
      "Starting Epoch 196\n",
      "1.3580136224627495\n",
      "Validation loss: 1.3755022287368774\n",
      "mse 1.3755022157568728\n",
      "New best model found at epoch 196 with validation loss 1.3755022287368774\n",
      "Starting Epoch 197\n",
      "1.357637417813142\n",
      "Validation loss: 1.375678300857544\n",
      "mse 1.3756783894768485\n",
      "Starting Epoch 198\n",
      "1.3570611129204433\n",
      "Validation loss: 1.3744494915008545\n",
      "mse 1.3744493646119107\n",
      "New best model found at epoch 198 with validation loss 1.3744494915008545\n",
      "Starting Epoch 199\n",
      "1.356549064318339\n",
      "Validation loss: 1.374067783355713\n",
      "mse 1.3740678796922805\n",
      "New best model found at epoch 199 with validation loss 1.374067783355713\n",
      "Starting Epoch 200\n",
      "1.3562026843428612\n",
      "Validation loss: 1.3730065822601318\n",
      "mse 1.373006520532618\n",
      "New best model found at epoch 200 with validation loss 1.3730065822601318\n",
      "Starting Epoch 201\n",
      "1.3557637085517247\n",
      "Validation loss: 1.372813105583191\n",
      "mse 1.3728131617841557\n",
      "New best model found at epoch 201 with validation loss 1.372813105583191\n",
      "Starting Epoch 202\n",
      "1.3552400022745132\n",
      "Validation loss: 1.3725273609161377\n",
      "mse 1.3725273784705456\n",
      "New best model found at epoch 202 with validation loss 1.3725273609161377\n",
      "Starting Epoch 203\n",
      "1.3547536606589954\n",
      "Validation loss: 1.3715022802352905\n",
      "mse 1.3715022946291915\n",
      "New best model found at epoch 203 with validation loss 1.3715022802352905\n",
      "Starting Epoch 204\n",
      "1.354420006275177\n",
      "Validation loss: 1.3717451095581055\n",
      "mse 1.3717452162319026\n",
      "Starting Epoch 205\n",
      "1.35399329662323\n",
      "Validation loss: 1.3712193965911865\n",
      "mse 1.3712193534849684\n",
      "New best model found at epoch 205 with validation loss 1.3712193965911865\n",
      "Starting Epoch 206\n",
      "1.353544682264328\n",
      "Validation loss: 1.370180606842041\n",
      "mse 1.3701806345194196\n",
      "New best model found at epoch 206 with validation loss 1.370180606842041\n",
      "Starting Epoch 207\n",
      "1.3532451465725899\n",
      "Validation loss: 1.3698792457580566\n",
      "mse 1.3698791645870656\n",
      "New best model found at epoch 207 with validation loss 1.3698792457580566\n",
      "Starting Epoch 208\n",
      "1.352803759276867\n",
      "Validation loss: 1.3698701858520508\n",
      "mse 1.369870224038234\n",
      "New best model found at epoch 208 with validation loss 1.3698701858520508\n",
      "Starting Epoch 209\n",
      "1.35233536362648\n",
      "Validation loss: 1.369392991065979\n",
      "mse 1.3693930110421701\n",
      "New best model found at epoch 209 with validation loss 1.369392991065979\n",
      "Starting Epoch 210\n",
      "1.3520581697424252\n",
      "Validation loss: 1.3693633079528809\n",
      "mse 1.3693633704025776\n",
      "New best model found at epoch 210 with validation loss 1.3693633079528809\n",
      "Starting Epoch 211\n",
      "1.3514717643459637\n",
      "Validation loss: 1.3680355548858643\n",
      "mse 1.3680355695005384\n",
      "New best model found at epoch 211 with validation loss 1.3680355548858643\n",
      "Starting Epoch 212\n",
      "1.3512352655331294\n",
      "Validation loss: 1.3673776388168335\n",
      "mse 1.3673776029741846\n",
      "New best model found at epoch 212 with validation loss 1.3673776388168335\n",
      "Starting Epoch 213\n",
      "1.3507367670536041\n",
      "Validation loss: 1.367304801940918\n",
      "mse 1.3673046548437917\n",
      "New best model found at epoch 213 with validation loss 1.367304801940918\n",
      "Starting Epoch 214\n",
      "1.3505669782559078\n",
      "Validation loss: 1.36685049533844\n",
      "mse 1.3668505810019773\n",
      "New best model found at epoch 214 with validation loss 1.36685049533844\n",
      "Starting Epoch 215\n",
      "1.3500813022255898\n",
      "Validation loss: 1.3666361570358276\n",
      "mse 1.3666360863211695\n",
      "New best model found at epoch 215 with validation loss 1.3666361570358276\n",
      "Starting Epoch 216\n",
      "1.3497488523523014\n",
      "Validation loss: 1.3674927949905396\n",
      "mse 1.3674926853620568\n",
      "Starting Epoch 217\n",
      "1.3494024003545444\n",
      "Validation loss: 1.3667327165603638\n",
      "mse 1.3667327467779717\n",
      "Starting Epoch 218\n",
      "1.3488920455177624\n",
      "Validation loss: 1.3657515048980713\n",
      "mse 1.365751562131479\n",
      "New best model found at epoch 218 with validation loss 1.3657515048980713\n",
      "Starting Epoch 219\n",
      "1.3487121413151424\n",
      "Validation loss: 1.36555814743042\n",
      "mse 1.365558135068541\n",
      "New best model found at epoch 219 with validation loss 1.36555814743042\n",
      "Starting Epoch 220\n",
      "1.3484460736314456\n",
      "Validation loss: 1.3659729957580566\n",
      "mse 1.3659731190265223\n",
      "Starting Epoch 221\n",
      "1.347863145172596\n",
      "Validation loss: 1.3663448095321655\n",
      "mse 1.3663448351138372\n",
      "Starting Epoch 222\n",
      "1.3476904978354771\n",
      "Validation loss: 1.3645178079605103\n",
      "mse 1.3645178165307426\n",
      "New best model found at epoch 222 with validation loss 1.3645178079605103\n",
      "Starting Epoch 223\n",
      "1.3474242761731148\n",
      "Validation loss: 1.3653600215911865\n",
      "mse 1.3653599481641219\n",
      "Starting Epoch 224\n",
      "1.3470348194241524\n",
      "Validation loss: 1.364258050918579\n",
      "mse 1.3642580746923085\n",
      "New best model found at epoch 224 with validation loss 1.364258050918579\n",
      "Starting Epoch 225\n",
      "1.34681136906147\n",
      "Validation loss: 1.3640207052230835\n",
      "mse 1.3640207030415774\n",
      "New best model found at epoch 225 with validation loss 1.3640207052230835\n",
      "Starting Epoch 226\n",
      "1.3465349301695824\n",
      "Validation loss: 1.3629145622253418\n",
      "mse 1.3629145092308708\n",
      "New best model found at epoch 226 with validation loss 1.3629145622253418\n",
      "Starting Epoch 227\n",
      "1.3461272567510605\n",
      "Validation loss: 1.3631519079208374\n",
      "mse 1.3631518620655918\n",
      "Starting Epoch 228\n",
      "1.3458501373728116\n",
      "Validation loss: 1.3632172346115112\n",
      "mse 1.3632170967467732\n",
      "Starting Epoch 229\n",
      "1.3453932081659634\n",
      "Validation loss: 1.3623838424682617\n",
      "mse 1.3623838030185413\n",
      "New best model found at epoch 229 with validation loss 1.3623838424682617\n",
      "Starting Epoch 230\n",
      "1.3451344097654026\n",
      "Validation loss: 1.3632606267929077\n",
      "mse 1.363260641980648\n",
      "Starting Epoch 231\n",
      "1.3449954837560654\n",
      "Validation loss: 1.3612122535705566\n",
      "mse 1.3612123332909882\n",
      "New best model found at epoch 231 with validation loss 1.3612122535705566\n",
      "Starting Epoch 232\n",
      "1.3445766866207123\n",
      "Validation loss: 1.3618407249450684\n",
      "mse 1.3618407515092164\n",
      "Starting Epoch 233\n",
      "1.344388855000337\n",
      "Validation loss: 1.3616353273391724\n",
      "mse 1.361635418756782\n",
      "Starting Epoch 234\n",
      "1.344066970050335\n",
      "Validation loss: 1.36038339138031\n",
      "mse 1.3603833724556633\n",
      "New best model found at epoch 234 with validation loss 1.36038339138031\n",
      "Starting Epoch 235\n",
      "1.343856041630109\n",
      "Validation loss: 1.3601455688476562\n",
      "mse 1.3601455957233546\n",
      "New best model found at epoch 235 with validation loss 1.3601455688476562\n",
      "Starting Epoch 236\n",
      "1.3434742788473766\n",
      "Validation loss: 1.3602546453475952\n",
      "mse 1.360254633123638\n",
      "Starting Epoch 237\n",
      "1.3432958200573921\n",
      "Validation loss: 1.3600690364837646\n",
      "mse 1.3600690693387287\n",
      "New best model found at epoch 237 with validation loss 1.3600690364837646\n",
      "Starting Epoch 238\n",
      "1.3430074279507\n",
      "Validation loss: 1.3600587844848633\n",
      "mse 1.3600588095181276\n",
      "New best model found at epoch 238 with validation loss 1.3600587844848633\n",
      "Starting Epoch 239\n",
      "1.3427546819051106\n",
      "Validation loss: 1.3603730201721191\n",
      "mse 1.3603728512456832\n",
      "Starting Epoch 240\n",
      "1.3423012296358745\n",
      "Validation loss: 1.3584246635437012\n",
      "mse 1.3584247841852852\n",
      "New best model found at epoch 240 with validation loss 1.3584246635437012\n",
      "Starting Epoch 241\n",
      "1.3419793173670769\n",
      "Validation loss: 1.3587098121643066\n",
      "mse 1.3587098653100589\n",
      "Starting Epoch 242\n",
      "1.3417797113458316\n",
      "Validation loss: 1.3581316471099854\n",
      "mse 1.3581317031156268\n",
      "New best model found at epoch 242 with validation loss 1.3581316471099854\n",
      "Starting Epoch 243\n",
      "1.3416957755883534\n",
      "Validation loss: 1.3579018115997314\n",
      "mse 1.3579018130628984\n",
      "New best model found at epoch 243 with validation loss 1.3579018115997314\n",
      "Starting Epoch 244\n",
      "1.3413191040356953\n",
      "Validation loss: 1.357751727104187\n",
      "mse 1.3577517647174695\n",
      "New best model found at epoch 244 with validation loss 1.357751727104187\n",
      "Starting Epoch 245\n",
      "1.341028484205405\n",
      "Validation loss: 1.3574408292770386\n",
      "mse 1.35744084692143\n",
      "New best model found at epoch 245 with validation loss 1.3574408292770386\n",
      "Starting Epoch 246\n",
      "1.3408671642343204\n",
      "Validation loss: 1.357187271118164\n",
      "mse 1.3571873803937922\n",
      "New best model found at epoch 246 with validation loss 1.357187271118164\n",
      "Starting Epoch 247\n",
      "1.3406465674440067\n",
      "Validation loss: 1.357130527496338\n",
      "mse 1.357130517051422\n",
      "New best model found at epoch 247 with validation loss 1.357130527496338\n",
      "Starting Epoch 248\n",
      "1.3403898030519485\n",
      "Validation loss: 1.356933355331421\n",
      "mse 1.3569334660218326\n",
      "New best model found at epoch 248 with validation loss 1.356933355331421\n",
      "Starting Epoch 249\n",
      "1.3400464604298274\n",
      "Validation loss: 1.3566521406173706\n",
      "mse 1.356652246134713\n",
      "New best model found at epoch 249 with validation loss 1.3566521406173706\n",
      "Starting Epoch 250\n",
      "1.3399324690302212\n",
      "Validation loss: 1.356408715248108\n",
      "mse 1.3564087075432627\n",
      "New best model found at epoch 250 with validation loss 1.356408715248108\n",
      "Starting Epoch 251\n",
      "1.339585267007351\n",
      "Validation loss: 1.3561497926712036\n",
      "mse 1.3561497682308892\n",
      "New best model found at epoch 251 with validation loss 1.3561497926712036\n",
      "Starting Epoch 252\n",
      "1.339399794737498\n",
      "Validation loss: 1.3559426069259644\n",
      "mse 1.355942482177563\n",
      "New best model found at epoch 252 with validation loss 1.3559426069259644\n",
      "Starting Epoch 253\n",
      "1.3391601343949635\n",
      "Validation loss: 1.3554668426513672\n",
      "mse 1.3554669933364685\n",
      "New best model found at epoch 253 with validation loss 1.3554668426513672\n",
      "Starting Epoch 254\n",
      "1.3389262532194455\n",
      "Validation loss: 1.3554328680038452\n",
      "mse 1.3554327966154558\n",
      "New best model found at epoch 254 with validation loss 1.3554328680038452\n",
      "Starting Epoch 255\n",
      "1.3386747961242993\n",
      "Validation loss: 1.35505211353302\n",
      "mse 1.3550521509386053\n",
      "New best model found at epoch 255 with validation loss 1.35505211353302\n",
      "Starting Epoch 256\n",
      "1.338484175503254\n",
      "Validation loss: 1.3558986186981201\n",
      "mse 1.3558985720449017\n",
      "Starting Epoch 257\n",
      "1.3382050171494484\n",
      "Validation loss: 1.3542695045471191\n",
      "mse 1.354269468341296\n",
      "New best model found at epoch 257 with validation loss 1.3542695045471191\n",
      "Starting Epoch 258\n",
      "1.3379255061348279\n",
      "Validation loss: 1.3541431427001953\n",
      "mse 1.354143301255271\n",
      "New best model found at epoch 258 with validation loss 1.3541431427001953\n",
      "Starting Epoch 259\n",
      "1.3376355121533077\n",
      "Validation loss: 1.3534824848175049\n",
      "mse 1.3534824715799778\n",
      "New best model found at epoch 259 with validation loss 1.3534824848175049\n",
      "Starting Epoch 260\n",
      "1.3375378623604774\n",
      "Validation loss: 1.3552714586257935\n",
      "mse 1.3552715521741476\n",
      "Starting Epoch 261\n",
      "1.3371821120381355\n",
      "Validation loss: 1.3532735109329224\n",
      "mse 1.3532734870154464\n",
      "New best model found at epoch 261 with validation loss 1.3532735109329224\n",
      "Starting Epoch 262\n",
      "1.337062306702137\n",
      "Validation loss: 1.3539806604385376\n",
      "mse 1.3539807053196837\n",
      "Starting Epoch 263\n",
      "1.33670923858881\n",
      "Validation loss: 1.352429747581482\n",
      "mse 1.3524298173045741\n",
      "New best model found at epoch 263 with validation loss 1.352429747581482\n",
      "Starting Epoch 264\n",
      "1.3365415434042613\n",
      "Validation loss: 1.3531709909439087\n",
      "mse 1.3531709798856404\n",
      "Starting Epoch 265\n",
      "1.3361666550238926\n",
      "Validation loss: 1.351572036743164\n",
      "mse 1.3515719961139074\n",
      "New best model found at epoch 265 with validation loss 1.351572036743164\n",
      "Starting Epoch 266\n",
      "1.3359512016177177\n",
      "Validation loss: 1.3531198501586914\n",
      "mse 1.3531196852701477\n",
      "Starting Epoch 267\n",
      "1.3359063044190407\n",
      "Validation loss: 1.3533300161361694\n",
      "mse 1.3533300275017612\n",
      "Starting Epoch 268\n",
      "1.3356488992770512\n",
      "Validation loss: 1.3509830236434937\n",
      "mse 1.3509829038288987\n",
      "New best model found at epoch 268 with validation loss 1.3509830236434937\n",
      "Starting Epoch 269\n",
      "1.3352956970532734\n",
      "Validation loss: 1.3512603044509888\n",
      "mse 1.3512604264000725\n",
      "Starting Epoch 270\n",
      "1.3350017741322517\n",
      "Validation loss: 1.3508626222610474\n",
      "mse 1.350862710311046\n",
      "New best model found at epoch 270 with validation loss 1.3508626222610474\n",
      "Starting Epoch 271\n",
      "1.3348459998766582\n",
      "Validation loss: 1.35007905960083\n",
      "mse 1.3500790802654017\n",
      "New best model found at epoch 271 with validation loss 1.35007905960083\n",
      "Starting Epoch 272\n",
      "1.3344998781879742\n",
      "Validation loss: 1.3516154289245605\n",
      "mse 1.35161543663045\n",
      "Starting Epoch 273\n",
      "1.334347940981388\n",
      "Validation loss: 1.3510667085647583\n",
      "mse 1.3510666474060564\n",
      "Starting Epoch 274\n",
      "1.3342049544056256\n",
      "Validation loss: 1.3511106967926025\n",
      "mse 1.3511105835286867\n",
      "Starting Epoch 275\n",
      "1.3339596514900525\n",
      "Validation loss: 1.3491212129592896\n",
      "mse 1.3491210629323103\n",
      "New best model found at epoch 275 with validation loss 1.3491212129592896\n",
      "Starting Epoch 276\n",
      "1.3335196649034817\n",
      "Validation loss: 1.3491309881210327\n",
      "mse 1.3491309823142579\n",
      "Starting Epoch 277\n",
      "1.3332867299516995\n",
      "Validation loss: 1.3503670692443848\n",
      "mse 1.3503671538014796\n",
      "Starting Epoch 278\n",
      "1.3332010333736737\n",
      "Validation loss: 1.3500124216079712\n",
      "mse 1.350012409285385\n",
      "Starting Epoch 279\n",
      "1.3328988055388133\n",
      "Validation loss: 1.349391222000122\n",
      "mse 1.3493912726840198\n",
      "Starting Epoch 280\n",
      "1.332650716106097\n",
      "Validation loss: 1.348021149635315\n",
      "mse 1.3480212371426674\n",
      "New best model found at epoch 280 with validation loss 1.348021149635315\n",
      "Starting Epoch 281\n",
      "1.332409846285979\n",
      "Validation loss: 1.3477259874343872\n",
      "mse 1.3477260556426849\n",
      "New best model found at epoch 281 with validation loss 1.3477259874343872\n",
      "Starting Epoch 282\n",
      "1.332275887330373\n",
      "Validation loss: 1.3494668006896973\n",
      "mse 1.3494668800090426\n",
      "Starting Epoch 283\n",
      "1.3321213374535243\n",
      "Validation loss: 1.3471033573150635\n",
      "mse 1.347103399752119\n",
      "New best model found at epoch 283 with validation loss 1.3471033573150635\n",
      "Starting Epoch 284\n",
      "1.3316487098733585\n",
      "Validation loss: 1.3469046354293823\n",
      "mse 1.3469047463480461\n",
      "New best model found at epoch 284 with validation loss 1.3469046354293823\n",
      "Starting Epoch 285\n",
      "1.3316218281785648\n",
      "Validation loss: 1.347048282623291\n",
      "mse 1.3470482338021723\n",
      "Starting Epoch 286\n",
      "1.3313276022672653\n",
      "Validation loss: 1.346664309501648\n",
      "mse 1.3466643386757287\n",
      "New best model found at epoch 286 with validation loss 1.346664309501648\n",
      "Starting Epoch 287\n",
      "1.3311148261030514\n",
      "Validation loss: 1.3464874029159546\n",
      "mse 1.3464874244615508\n",
      "New best model found at epoch 287 with validation loss 1.3464874029159546\n",
      "Starting Epoch 288\n",
      "1.3308320914705594\n",
      "Validation loss: 1.3480459451675415\n",
      "mse 1.3480459768284356\n",
      "Starting Epoch 289\n",
      "1.330793485045433\n",
      "Validation loss: 1.3464126586914062\n",
      "mse 1.3464126373468492\n",
      "New best model found at epoch 289 with validation loss 1.3464126586914062\n",
      "Starting Epoch 290\n",
      "1.330542077620824\n",
      "Validation loss: 1.3471647500991821\n",
      "mse 1.3471647886299825\n",
      "Starting Epoch 291\n",
      "1.330398827791214\n",
      "Validation loss: 1.3469897508621216\n",
      "mse 1.3469897993201199\n",
      "Starting Epoch 292\n",
      "1.3301315332452457\n",
      "Validation loss: 1.345241665840149\n",
      "mse 1.3452415802548718\n",
      "New best model found at epoch 292 with validation loss 1.345241665840149\n",
      "Starting Epoch 293\n",
      "1.32995509604613\n",
      "Validation loss: 1.34518563747406\n",
      "mse 1.3451856589739015\n",
      "New best model found at epoch 293 with validation loss 1.34518563747406\n",
      "Starting Epoch 294\n",
      "1.3297157113750775\n",
      "Validation loss: 1.3450151681900024\n",
      "mse 1.3450151514357884\n",
      "New best model found at epoch 294 with validation loss 1.3450151681900024\n",
      "Starting Epoch 295\n",
      "1.3295041918754578\n",
      "Validation loss: 1.3450392484664917\n",
      "mse 1.3450393388510329\n",
      "Starting Epoch 296\n",
      "1.3293003365397453\n",
      "Validation loss: 1.344639778137207\n",
      "mse 1.344639819933538\n",
      "New best model found at epoch 296 with validation loss 1.344639778137207\n",
      "Starting Epoch 297\n",
      "1.32901269197464\n",
      "Validation loss: 1.34480881690979\n",
      "mse 1.3448086737678924\n",
      "Starting Epoch 298\n",
      "1.3289757122596104\n",
      "Validation loss: 1.3447211980819702\n",
      "mse 1.344721310197313\n",
      "Starting Epoch 299\n",
      "1.3287693560123444\n",
      "Validation loss: 1.344109058380127\n",
      "mse 1.3441090543877685\n",
      "New best model found at epoch 299 with validation loss 1.344109058380127\n",
      "Starting Epoch 300\n",
      "1.3285855303208034\n",
      "Validation loss: 1.3442424535751343\n",
      "mse 1.3442423318859094\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-min: 7-80-50-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e4960",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "36dadd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "501b08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,6,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4e6125ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'max(container counts)', 'max(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "9bf7c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "bed40240-ff36-401d-9b7e-6ad4105ab158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.6156135946512222\n",
      "Validation loss: 1.905788779258728\n",
      "mse 1.90578898666099\n",
      "New best model found at epoch 1 with validation loss 1.905788779258728\n",
      "Starting Epoch 2\n",
      "1.9074756354093552\n",
      "Validation loss: 1.739980697631836\n",
      "mse 1.739980673240682\n",
      "New best model found at epoch 2 with validation loss 1.739980697631836\n",
      "Starting Epoch 3\n",
      "1.7986220220724742\n",
      "Validation loss: 1.666311264038086\n",
      "mse 1.6663113174630007\n",
      "New best model found at epoch 3 with validation loss 1.666311264038086\n",
      "Starting Epoch 4\n",
      "1.7403208017349243\n",
      "Validation loss: 1.6269384622573853\n",
      "mse 1.6269384807574228\n",
      "New best model found at epoch 4 with validation loss 1.6269384622573853\n",
      "Starting Epoch 5\n",
      "1.6988894542058308\n",
      "Validation loss: 1.6000159978866577\n",
      "mse 1.6000159839324544\n",
      "New best model found at epoch 5 with validation loss 1.6000159978866577\n",
      "Starting Epoch 6\n",
      "1.667750984430313\n",
      "Validation loss: 1.583130955696106\n",
      "mse 1.5831309558292224\n",
      "New best model found at epoch 6 with validation loss 1.583130955696106\n",
      "Starting Epoch 7\n",
      "1.6419481883446376\n",
      "Validation loss: 1.567480206489563\n",
      "mse 1.5674801252990755\n",
      "New best model found at epoch 7 with validation loss 1.567480206489563\n",
      "Starting Epoch 8\n",
      "1.6209118068218231\n",
      "Validation loss: 1.5550280809402466\n",
      "mse 1.5550280635082587\n",
      "New best model found at epoch 8 with validation loss 1.5550280809402466\n",
      "Starting Epoch 9\n",
      "1.6037427186965942\n",
      "Validation loss: 1.5449628829956055\n",
      "mse 1.5449629102421731\n",
      "New best model found at epoch 9 with validation loss 1.5449628829956055\n",
      "Starting Epoch 10\n",
      "1.5889293402433395\n",
      "Validation loss: 1.5358095169067383\n",
      "mse 1.5358095740002473\n",
      "New best model found at epoch 10 with validation loss 1.5358095169067383\n",
      "Starting Epoch 11\n",
      "1.5764221847057343\n",
      "Validation loss: 1.5275031328201294\n",
      "mse 1.5275030055566075\n",
      "New best model found at epoch 11 with validation loss 1.5275031328201294\n",
      "Starting Epoch 12\n",
      "1.5654368698596954\n",
      "Validation loss: 1.5214436054229736\n",
      "mse 1.5214436435925216\n",
      "New best model found at epoch 12 with validation loss 1.5214436054229736\n",
      "Starting Epoch 13\n",
      "1.55559404194355\n",
      "Validation loss: 1.5144819021224976\n",
      "mse 1.5144818845612544\n",
      "New best model found at epoch 13 with validation loss 1.5144819021224976\n",
      "Starting Epoch 14\n",
      "1.5465152511994045\n",
      "Validation loss: 1.5095523595809937\n",
      "mse 1.5095523008314833\n",
      "New best model found at epoch 14 with validation loss 1.5095523595809937\n",
      "Starting Epoch 15\n",
      "1.538260633746783\n",
      "Validation loss: 1.5039432048797607\n",
      "mse 1.503943214783025\n",
      "New best model found at epoch 15 with validation loss 1.5039432048797607\n",
      "Starting Epoch 16\n",
      "1.5303584684928258\n",
      "Validation loss: 1.497172236442566\n",
      "mse 1.4971722545375976\n",
      "New best model found at epoch 16 with validation loss 1.497172236442566\n",
      "Starting Epoch 17\n",
      "1.5227239082256954\n",
      "Validation loss: 1.493029236793518\n",
      "mse 1.493029293215695\n",
      "New best model found at epoch 17 with validation loss 1.493029236793518\n",
      "Starting Epoch 18\n",
      "1.5152636518081029\n",
      "Validation loss: 1.489140272140503\n",
      "mse 1.4891401761661396\n",
      "New best model found at epoch 18 with validation loss 1.489140272140503\n",
      "Starting Epoch 19\n",
      "1.5090199261903763\n",
      "Validation loss: 1.4834918975830078\n",
      "mse 1.4834919734216383\n",
      "New best model found at epoch 19 with validation loss 1.4834918975830078\n",
      "Starting Epoch 20\n",
      "1.5025320847829182\n",
      "Validation loss: 1.4796901941299438\n",
      "mse 1.4796901703912888\n",
      "New best model found at epoch 20 with validation loss 1.4796901941299438\n",
      "Starting Epoch 21\n",
      "1.4965486178795497\n",
      "Validation loss: 1.4749689102172852\n",
      "mse 1.4749688078787402\n",
      "New best model found at epoch 21 with validation loss 1.4749689102172852\n",
      "Starting Epoch 22\n",
      "1.4905256479978561\n",
      "Validation loss: 1.4729335308074951\n",
      "mse 1.4729335181937862\n",
      "New best model found at epoch 22 with validation loss 1.4729335308074951\n",
      "Starting Epoch 23\n",
      "1.4855314046144485\n",
      "Validation loss: 1.469895362854004\n",
      "mse 1.469895500481739\n",
      "New best model found at epoch 23 with validation loss 1.469895362854004\n",
      "Starting Epoch 24\n",
      "1.48021899163723\n",
      "Validation loss: 1.4664794206619263\n",
      "mse 1.4664794571732505\n",
      "New best model found at epoch 24 with validation loss 1.4664794206619263\n",
      "Starting Epoch 25\n",
      "1.4744490037361782\n",
      "Validation loss: 1.4629555940628052\n",
      "mse 1.4629555997537955\n",
      "New best model found at epoch 25 with validation loss 1.4629555940628052\n",
      "Starting Epoch 26\n",
      "1.4696564376354218\n",
      "Validation loss: 1.459614872932434\n",
      "mse 1.4596148558447517\n",
      "New best model found at epoch 26 with validation loss 1.459614872932434\n",
      "Starting Epoch 27\n",
      "1.465250050028165\n",
      "Validation loss: 1.4556454420089722\n",
      "mse 1.4556454407094994\n",
      "New best model found at epoch 27 with validation loss 1.4556454420089722\n",
      "Starting Epoch 28\n",
      "1.4605754812558491\n",
      "Validation loss: 1.4512498378753662\n",
      "mse 1.4512499636887035\n",
      "New best model found at epoch 28 with validation loss 1.4512498378753662\n",
      "Starting Epoch 29\n",
      "1.4560490300258\n",
      "Validation loss: 1.448407530784607\n",
      "mse 1.4484076266200574\n",
      "New best model found at epoch 29 with validation loss 1.448407530784607\n",
      "Starting Epoch 30\n",
      "1.451780413587888\n",
      "Validation loss: 1.4467390775680542\n",
      "mse 1.4467390678212846\n",
      "New best model found at epoch 30 with validation loss 1.4467390775680542\n",
      "Starting Epoch 31\n",
      "1.44795760512352\n",
      "Validation loss: 1.4427006244659424\n",
      "mse 1.442700649371901\n",
      "New best model found at epoch 31 with validation loss 1.4427006244659424\n",
      "Starting Epoch 32\n",
      "1.4437400847673416\n",
      "Validation loss: 1.4399281740188599\n",
      "mse 1.4399281187889854\n",
      "New best model found at epoch 32 with validation loss 1.4399281740188599\n",
      "Starting Epoch 33\n",
      "1.4401245067516963\n",
      "Validation loss: 1.438340187072754\n",
      "mse 1.4383403507928265\n",
      "New best model found at epoch 33 with validation loss 1.438340187072754\n",
      "Starting Epoch 34\n",
      "1.43626573185126\n",
      "Validation loss: 1.4365510940551758\n",
      "mse 1.4365513064004043\n",
      "New best model found at epoch 34 with validation loss 1.4365510940551758\n",
      "Starting Epoch 35\n",
      "1.4322722007830937\n",
      "Validation loss: 1.434290885925293\n",
      "mse 1.4342908560118401\n",
      "New best model found at epoch 35 with validation loss 1.434290885925293\n",
      "Starting Epoch 36\n",
      "1.4291192243496578\n",
      "Validation loss: 1.4306492805480957\n",
      "mse 1.4306492054521212\n",
      "New best model found at epoch 36 with validation loss 1.4306492805480957\n",
      "Starting Epoch 37\n",
      "1.425537849466006\n",
      "Validation loss: 1.428548812866211\n",
      "mse 1.4285487639715915\n",
      "New best model found at epoch 37 with validation loss 1.428548812866211\n",
      "Starting Epoch 38\n",
      "1.4220891048510869\n",
      "Validation loss: 1.4260014295578003\n",
      "mse 1.4260013290872926\n",
      "New best model found at epoch 38 with validation loss 1.4260014295578003\n",
      "Starting Epoch 39\n",
      "1.418993040919304\n",
      "Validation loss: 1.421923279762268\n",
      "mse 1.421923317892746\n",
      "New best model found at epoch 39 with validation loss 1.421923279762268\n",
      "Starting Epoch 40\n",
      "1.415979211529096\n",
      "Validation loss: 1.4193525314331055\n",
      "mse 1.4193525406545864\n",
      "New best model found at epoch 40 with validation loss 1.4193525314331055\n",
      "Starting Epoch 41\n",
      "1.413241336743037\n",
      "Validation loss: 1.4164127111434937\n",
      "mse 1.416412653742208\n",
      "New best model found at epoch 41 with validation loss 1.4164127111434937\n",
      "Starting Epoch 42\n",
      "1.4098785817623138\n",
      "Validation loss: 1.4145419597625732\n",
      "mse 1.414541815587984\n",
      "New best model found at epoch 42 with validation loss 1.4145419597625732\n",
      "Starting Epoch 43\n",
      "1.4069084723790486\n",
      "Validation loss: 1.4114011526107788\n",
      "mse 1.411401097746086\n",
      "New best model found at epoch 43 with validation loss 1.4114011526107788\n",
      "Starting Epoch 44\n",
      "1.4038645923137665\n",
      "Validation loss: 1.4097907543182373\n",
      "mse 1.409790773201286\n",
      "New best model found at epoch 44 with validation loss 1.4097907543182373\n",
      "Starting Epoch 45\n",
      "1.4013141145308812\n",
      "Validation loss: 1.4069515466690063\n",
      "mse 1.4069514895627144\n",
      "New best model found at epoch 45 with validation loss 1.4069515466690063\n",
      "Starting Epoch 46\n",
      "1.3981855337818463\n",
      "Validation loss: 1.4048383235931396\n",
      "mse 1.4048384076677412\n",
      "New best model found at epoch 46 with validation loss 1.4048383235931396\n",
      "Starting Epoch 47\n",
      "1.3959384833772976\n",
      "Validation loss: 1.4029130935668945\n",
      "mse 1.4029129436634558\n",
      "New best model found at epoch 47 with validation loss 1.4029130935668945\n",
      "Starting Epoch 48\n",
      "1.3930477052927017\n",
      "Validation loss: 1.3985615968704224\n",
      "mse 1.3985617251954428\n",
      "New best model found at epoch 48 with validation loss 1.3985615968704224\n",
      "Starting Epoch 49\n",
      "1.3901305918892224\n",
      "Validation loss: 1.397383689880371\n",
      "mse 1.3973837066331196\n",
      "New best model found at epoch 49 with validation loss 1.397383689880371\n",
      "Starting Epoch 50\n",
      "1.3875972802440326\n",
      "Validation loss: 1.3958208560943604\n",
      "mse 1.3958209614956851\n",
      "New best model found at epoch 50 with validation loss 1.3958208560943604\n",
      "Starting Epoch 51\n",
      "1.3854115257660549\n",
      "Validation loss: 1.3938325643539429\n",
      "mse 1.3938325752913583\n",
      "New best model found at epoch 51 with validation loss 1.3938325643539429\n",
      "Starting Epoch 52\n",
      "1.3828231617808342\n",
      "Validation loss: 1.391357421875\n",
      "mse 1.3913573431638788\n",
      "New best model found at epoch 52 with validation loss 1.391357421875\n",
      "Starting Epoch 53\n",
      "1.3801749249299367\n",
      "Validation loss: 1.3869346380233765\n",
      "mse 1.3869346349611418\n",
      "New best model found at epoch 53 with validation loss 1.3869346380233765\n",
      "Starting Epoch 54\n",
      "1.3773308868209522\n",
      "Validation loss: 1.3881196975708008\n",
      "mse 1.3881196197045125\n",
      "Starting Epoch 55\n",
      "1.3755112638076146\n",
      "Validation loss: 1.3864264488220215\n",
      "mse 1.3864265482656728\n",
      "New best model found at epoch 55 with validation loss 1.3864264488220215\n",
      "Starting Epoch 56\n",
      "1.3729829043149948\n",
      "Validation loss: 1.3858753442764282\n",
      "mse 1.3858754626756762\n",
      "New best model found at epoch 56 with validation loss 1.3858753442764282\n",
      "Starting Epoch 57\n",
      "1.370511529346307\n",
      "Validation loss: 1.3828920125961304\n",
      "mse 1.382891988881109\n",
      "New best model found at epoch 57 with validation loss 1.3828920125961304\n",
      "Starting Epoch 58\n",
      "1.3679696669181187\n",
      "Validation loss: 1.3810452222824097\n",
      "mse 1.3810452042383288\n",
      "New best model found at epoch 58 with validation loss 1.3810452222824097\n",
      "Starting Epoch 59\n",
      "1.3653810992836952\n",
      "Validation loss: 1.3792695999145508\n",
      "mse 1.3792695686334566\n",
      "New best model found at epoch 59 with validation loss 1.3792695999145508\n",
      "Starting Epoch 60\n",
      "1.3629050900538762\n",
      "Validation loss: 1.376619577407837\n",
      "mse 1.37661973967069\n",
      "New best model found at epoch 60 with validation loss 1.376619577407837\n",
      "Starting Epoch 61\n",
      "1.3607975989580154\n",
      "Validation loss: 1.3763599395751953\n",
      "mse 1.3763597915780132\n",
      "New best model found at epoch 61 with validation loss 1.3763599395751953\n",
      "Starting Epoch 62\n",
      "1.358525147040685\n",
      "Validation loss: 1.374436616897583\n",
      "mse 1.3744366470969773\n",
      "New best model found at epoch 62 with validation loss 1.374436616897583\n",
      "Starting Epoch 63\n",
      "1.3559754590193431\n",
      "Validation loss: 1.3726619482040405\n",
      "mse 1.3726619255330916\n",
      "New best model found at epoch 63 with validation loss 1.3726619482040405\n",
      "Starting Epoch 64\n",
      "1.3540028656522434\n",
      "Validation loss: 1.3714631795883179\n",
      "mse 1.3714631601435945\n",
      "New best model found at epoch 64 with validation loss 1.3714631795883179\n",
      "Starting Epoch 65\n",
      "1.3517190665006638\n",
      "Validation loss: 1.371781587600708\n",
      "mse 1.3717816033181554\n",
      "Starting Epoch 66\n",
      "1.3497563774387042\n",
      "Validation loss: 1.3698883056640625\n",
      "mse 1.3698882960138934\n",
      "New best model found at epoch 66 with validation loss 1.3698883056640625\n",
      "Starting Epoch 67\n",
      "1.3472538714607556\n",
      "Validation loss: 1.3683574199676514\n",
      "mse 1.3683574761432815\n",
      "New best model found at epoch 67 with validation loss 1.3683574199676514\n",
      "Starting Epoch 68\n",
      "1.3452509393294652\n",
      "Validation loss: 1.3667045831680298\n",
      "mse 1.3667045496535606\n",
      "New best model found at epoch 68 with validation loss 1.3667045831680298\n",
      "Starting Epoch 69\n",
      "1.3428226336836815\n",
      "Validation loss: 1.3650819063186646\n",
      "mse 1.3650819043776707\n",
      "New best model found at epoch 69 with validation loss 1.3650819063186646\n",
      "Starting Epoch 70\n",
      "1.3407010088364284\n",
      "Validation loss: 1.3620352745056152\n",
      "mse 1.362035304877896\n",
      "New best model found at epoch 70 with validation loss 1.3620352745056152\n",
      "Starting Epoch 71\n",
      "1.338366021712621\n",
      "Validation loss: 1.3615179061889648\n",
      "mse 1.36151796146618\n",
      "New best model found at epoch 71 with validation loss 1.3615179061889648\n",
      "Starting Epoch 72\n",
      "1.3363695641358693\n",
      "Validation loss: 1.3600538969039917\n",
      "mse 1.360053868964029\n",
      "New best model found at epoch 72 with validation loss 1.3600538969039917\n",
      "Starting Epoch 73\n",
      "1.3342143495877583\n",
      "Validation loss: 1.3586080074310303\n",
      "mse 1.3586079602899939\n",
      "New best model found at epoch 73 with validation loss 1.3586080074310303\n",
      "Starting Epoch 74\n",
      "1.332047109802564\n",
      "Validation loss: 1.3571559190750122\n",
      "mse 1.3571558961913737\n",
      "New best model found at epoch 74 with validation loss 1.3571559190750122\n",
      "Starting Epoch 75\n",
      "1.330157163242499\n",
      "Validation loss: 1.354495644569397\n",
      "mse 1.3544956890523847\n",
      "New best model found at epoch 75 with validation loss 1.354495644569397\n",
      "Starting Epoch 76\n",
      "1.3278490578134854\n",
      "Validation loss: 1.3534495830535889\n",
      "mse 1.3534497049975003\n",
      "New best model found at epoch 76 with validation loss 1.3534495830535889\n",
      "Starting Epoch 77\n",
      "1.3260296235481899\n",
      "Validation loss: 1.3514152765274048\n",
      "mse 1.3514154111830354\n",
      "New best model found at epoch 77 with validation loss 1.3514152765274048\n",
      "Starting Epoch 78\n",
      "1.324016456802686\n",
      "Validation loss: 1.3506578207015991\n",
      "mse 1.3506577200663417\n",
      "New best model found at epoch 78 with validation loss 1.3506578207015991\n",
      "Starting Epoch 79\n",
      "1.322147011756897\n",
      "Validation loss: 1.3508130311965942\n",
      "mse 1.3508129654684138\n",
      "Starting Epoch 80\n",
      "1.3204879437883694\n",
      "Validation loss: 1.3481507301330566\n",
      "mse 1.3481507229333558\n",
      "New best model found at epoch 80 with validation loss 1.3481507301330566\n",
      "Starting Epoch 81\n",
      "1.3185988118251164\n",
      "Validation loss: 1.3457764387130737\n",
      "mse 1.3457764635115903\n",
      "New best model found at epoch 81 with validation loss 1.3457764387130737\n",
      "Starting Epoch 82\n",
      "1.3164167602856953\n",
      "Validation loss: 1.3455371856689453\n",
      "mse 1.3455372409349895\n",
      "New best model found at epoch 82 with validation loss 1.3455371856689453\n",
      "Starting Epoch 83\n",
      "1.314821057021618\n",
      "Validation loss: 1.3436970710754395\n",
      "mse 1.343697197014533\n",
      "New best model found at epoch 83 with validation loss 1.3436970710754395\n",
      "Starting Epoch 84\n",
      "1.3125964924693108\n",
      "Validation loss: 1.3428984880447388\n",
      "mse 1.3428985065080163\n",
      "New best model found at epoch 84 with validation loss 1.3428984880447388\n",
      "Starting Epoch 85\n",
      "1.3107890412211418\n",
      "Validation loss: 1.3412975072860718\n",
      "mse 1.3412974669880637\n",
      "New best model found at epoch 85 with validation loss 1.3412975072860718\n",
      "Starting Epoch 86\n",
      "1.3088676085074742\n",
      "Validation loss: 1.3398501873016357\n",
      "mse 1.339850146593256\n",
      "New best model found at epoch 86 with validation loss 1.3398501873016357\n",
      "Starting Epoch 87\n",
      "1.3067729771137238\n",
      "Validation loss: 1.3383322954177856\n",
      "mse 1.3383322829533955\n",
      "New best model found at epoch 87 with validation loss 1.3383322954177856\n",
      "Starting Epoch 88\n",
      "1.3048260708649952\n",
      "Validation loss: 1.3374978303909302\n",
      "mse 1.3374978375290356\n",
      "New best model found at epoch 88 with validation loss 1.3374978303909302\n",
      "Starting Epoch 89\n",
      "1.3033680642644565\n",
      "Validation loss: 1.3351296186447144\n",
      "mse 1.3351295957032467\n",
      "New best model found at epoch 89 with validation loss 1.3351296186447144\n",
      "Starting Epoch 90\n",
      "1.301234891017278\n",
      "Validation loss: 1.3344841003417969\n",
      "mse 1.334484035276534\n",
      "New best model found at epoch 90 with validation loss 1.3344841003417969\n",
      "Starting Epoch 91\n",
      "1.2994361619154613\n",
      "Validation loss: 1.33371102809906\n",
      "mse 1.3337111019258379\n",
      "New best model found at epoch 91 with validation loss 1.33371102809906\n",
      "Starting Epoch 92\n",
      "1.297664334376653\n",
      "Validation loss: 1.3329179286956787\n",
      "mse 1.3329178754116324\n",
      "New best model found at epoch 92 with validation loss 1.3329179286956787\n",
      "Starting Epoch 93\n",
      "1.2957657178243\n",
      "Validation loss: 1.3314275741577148\n",
      "mse 1.3314274917425506\n",
      "New best model found at epoch 93 with validation loss 1.3314275741577148\n",
      "Starting Epoch 94\n",
      "1.294256071249644\n",
      "Validation loss: 1.3298027515411377\n",
      "mse 1.3298026820198139\n",
      "New best model found at epoch 94 with validation loss 1.3298027515411377\n",
      "Starting Epoch 95\n",
      "1.2919443572560947\n",
      "Validation loss: 1.3292502164840698\n",
      "mse 1.3292502216826045\n",
      "New best model found at epoch 95 with validation loss 1.3292502164840698\n",
      "Starting Epoch 96\n",
      "1.290571851034959\n",
      "Validation loss: 1.3277146816253662\n",
      "mse 1.327714757763903\n",
      "New best model found at epoch 96 with validation loss 1.3277146816253662\n",
      "Starting Epoch 97\n",
      "1.2888570825258892\n",
      "Validation loss: 1.3264292478561401\n",
      "mse 1.3264292428015938\n",
      "New best model found at epoch 97 with validation loss 1.3264292478561401\n",
      "Starting Epoch 98\n",
      "1.287250004708767\n",
      "Validation loss: 1.3255428075790405\n",
      "mse 1.325542731098139\n",
      "New best model found at epoch 98 with validation loss 1.3255428075790405\n",
      "Starting Epoch 99\n",
      "1.2855089604854584\n",
      "Validation loss: 1.3243604898452759\n",
      "mse 1.324360482896412\n",
      "New best model found at epoch 99 with validation loss 1.3243604898452759\n",
      "Starting Epoch 100\n",
      "1.2838507369160652\n",
      "Validation loss: 1.3223286867141724\n",
      "mse 1.3223287364890706\n",
      "New best model found at epoch 100 with validation loss 1.3223286867141724\n",
      "Starting Epoch 101\n",
      "1.2819931209087372\n",
      "Validation loss: 1.3221672773361206\n",
      "mse 1.322167226582233\n",
      "New best model found at epoch 101 with validation loss 1.3221672773361206\n",
      "Starting Epoch 102\n",
      "1.2804625084002812\n",
      "Validation loss: 1.3208184242248535\n",
      "mse 1.3208183675529812\n",
      "New best model found at epoch 102 with validation loss 1.3208184242248535\n",
      "Starting Epoch 103\n",
      "1.2787953540682793\n",
      "Validation loss: 1.3199177980422974\n",
      "mse 1.3199178393844504\n",
      "New best model found at epoch 103 with validation loss 1.3199177980422974\n",
      "Starting Epoch 104\n",
      "1.2771971722443898\n",
      "Validation loss: 1.3183848857879639\n",
      "mse 1.3183849609644154\n",
      "New best model found at epoch 104 with validation loss 1.3183848857879639\n",
      "Starting Epoch 105\n",
      "1.2760290851195653\n",
      "Validation loss: 1.3179266452789307\n",
      "mse 1.3179266420757094\n",
      "New best model found at epoch 105 with validation loss 1.3179266452789307\n",
      "Starting Epoch 106\n",
      "1.2740284750858943\n",
      "Validation loss: 1.3167518377304077\n",
      "mse 1.3167517986145119\n",
      "New best model found at epoch 106 with validation loss 1.3167518377304077\n",
      "Starting Epoch 107\n",
      "1.272530121107896\n",
      "Validation loss: 1.3162527084350586\n",
      "mse 1.3162528441005497\n",
      "New best model found at epoch 107 with validation loss 1.3162527084350586\n",
      "Starting Epoch 108\n",
      "1.2708735416332881\n",
      "Validation loss: 1.3142255544662476\n",
      "mse 1.3142256897318556\n",
      "New best model found at epoch 108 with validation loss 1.3142255544662476\n",
      "Starting Epoch 109\n",
      "1.2692097375790279\n",
      "Validation loss: 1.3133742809295654\n",
      "mse 1.313374391154716\n",
      "New best model found at epoch 109 with validation loss 1.3133742809295654\n",
      "Starting Epoch 110\n",
      "1.2678818504015605\n",
      "Validation loss: 1.3124566078186035\n",
      "mse 1.3124565661284648\n",
      "New best model found at epoch 110 with validation loss 1.3124566078186035\n",
      "Starting Epoch 111\n",
      "1.2662302354971569\n",
      "Validation loss: 1.3115510940551758\n",
      "mse 1.3115512851348883\n",
      "New best model found at epoch 111 with validation loss 1.3115510940551758\n",
      "Starting Epoch 112\n",
      "1.2647324378291767\n",
      "Validation loss: 1.3098844289779663\n",
      "mse 1.3098844248497035\n",
      "New best model found at epoch 112 with validation loss 1.3098844289779663\n",
      "Starting Epoch 113\n",
      "1.2632605855663617\n",
      "Validation loss: 1.3094401359558105\n",
      "mse 1.3094401096368444\n",
      "New best model found at epoch 113 with validation loss 1.3094401359558105\n",
      "Starting Epoch 114\n",
      "1.2619584922989209\n",
      "Validation loss: 1.3077268600463867\n",
      "mse 1.3077269670811267\n",
      "New best model found at epoch 114 with validation loss 1.3077268600463867\n",
      "Starting Epoch 115\n",
      "1.2602854172388713\n",
      "Validation loss: 1.3064419031143188\n",
      "mse 1.3064418711739647\n",
      "New best model found at epoch 115 with validation loss 1.3064419031143188\n",
      "Starting Epoch 116\n",
      "1.2590100814898808\n",
      "Validation loss: 1.3056308031082153\n",
      "mse 1.3056307754740395\n",
      "New best model found at epoch 116 with validation loss 1.3056308031082153\n",
      "Starting Epoch 117\n",
      "1.2573351586858432\n",
      "Validation loss: 1.3050953149795532\n",
      "mse 1.3050953231404052\n",
      "New best model found at epoch 117 with validation loss 1.3050953149795532\n",
      "Starting Epoch 118\n",
      "1.256137949724992\n",
      "Validation loss: 1.302972674369812\n",
      "mse 1.3029726954541074\n",
      "New best model found at epoch 118 with validation loss 1.302972674369812\n",
      "Starting Epoch 119\n",
      "1.2544494718313217\n",
      "Validation loss: 1.3026012182235718\n",
      "mse 1.302601185451172\n",
      "New best model found at epoch 119 with validation loss 1.3026012182235718\n",
      "Starting Epoch 120\n",
      "1.253061905503273\n",
      "Validation loss: 1.3014085292816162\n",
      "mse 1.301408598616129\n",
      "New best model found at epoch 120 with validation loss 1.3014085292816162\n",
      "Starting Epoch 121\n",
      "1.2515840431054432\n",
      "Validation loss: 1.3008002042770386\n",
      "mse 1.3008002980986368\n",
      "New best model found at epoch 121 with validation loss 1.3008002042770386\n",
      "Starting Epoch 122\n",
      "1.2501869748036067\n",
      "Validation loss: 1.2997108697891235\n",
      "mse 1.2997108842469154\n",
      "New best model found at epoch 122 with validation loss 1.2997108697891235\n",
      "Starting Epoch 123\n",
      "1.2489580462376277\n",
      "Validation loss: 1.2984976768493652\n",
      "mse 1.298497561178021\n",
      "New best model found at epoch 123 with validation loss 1.2984976768493652\n",
      "Starting Epoch 124\n",
      "1.2474279676874478\n",
      "Validation loss: 1.2976067066192627\n",
      "mse 1.2976065387268252\n",
      "New best model found at epoch 124 with validation loss 1.2976067066192627\n",
      "Starting Epoch 125\n",
      "1.2463937625288963\n",
      "Validation loss: 1.2970939874649048\n",
      "mse 1.2970940882983506\n",
      "New best model found at epoch 125 with validation loss 1.2970939874649048\n",
      "Starting Epoch 126\n",
      "1.2448955848813057\n",
      "Validation loss: 1.2954410314559937\n",
      "mse 1.2954411218429738\n",
      "New best model found at epoch 126 with validation loss 1.2954410314559937\n",
      "Starting Epoch 127\n",
      "1.2437725365161896\n",
      "Validation loss: 1.2947911024093628\n",
      "mse 1.2947912156416872\n",
      "New best model found at epoch 127 with validation loss 1.2947911024093628\n",
      "Starting Epoch 128\n",
      "1.2423502678672473\n",
      "Validation loss: 1.2933398485183716\n",
      "mse 1.2933399113399682\n",
      "New best model found at epoch 128 with validation loss 1.2933398485183716\n",
      "Starting Epoch 129\n",
      "1.2413888697822888\n",
      "Validation loss: 1.2928181886672974\n",
      "mse 1.2928181215485905\n",
      "New best model found at epoch 129 with validation loss 1.2928181886672974\n",
      "Starting Epoch 130\n",
      "1.2395688146352768\n",
      "Validation loss: 1.2912691831588745\n",
      "mse 1.2912692068273672\n",
      "New best model found at epoch 130 with validation loss 1.2912691831588745\n",
      "Starting Epoch 131\n",
      "1.238605593641599\n",
      "Validation loss: 1.290409803390503\n",
      "mse 1.2904098110016997\n",
      "New best model found at epoch 131 with validation loss 1.290409803390503\n",
      "Starting Epoch 132\n",
      "1.2373029788335164\n",
      "Validation loss: 1.289089560508728\n",
      "mse 1.2890895885839342\n",
      "New best model found at epoch 132 with validation loss 1.289089560508728\n",
      "Starting Epoch 133\n",
      "1.2357962081829708\n",
      "Validation loss: 1.288737416267395\n",
      "mse 1.2887374783775496\n",
      "New best model found at epoch 133 with validation loss 1.288737416267395\n",
      "Starting Epoch 134\n",
      "1.2349437723557155\n",
      "Validation loss: 1.2876673936843872\n",
      "mse 1.287667439929265\n",
      "New best model found at epoch 134 with validation loss 1.2876673936843872\n",
      "Starting Epoch 135\n",
      "1.2336114024122555\n",
      "Validation loss: 1.2867165803909302\n",
      "mse 1.286716674271008\n",
      "New best model found at epoch 135 with validation loss 1.2867165803909302\n",
      "Starting Epoch 136\n",
      "1.232390011350314\n",
      "Validation loss: 1.2857662439346313\n",
      "mse 1.2857661238833669\n",
      "New best model found at epoch 136 with validation loss 1.2857662439346313\n",
      "Starting Epoch 137\n",
      "1.2312250932057698\n",
      "Validation loss: 1.284209966659546\n",
      "mse 1.2842100165520633\n",
      "New best model found at epoch 137 with validation loss 1.284209966659546\n",
      "Starting Epoch 138\n",
      "1.2297463069359462\n",
      "Validation loss: 1.2839289903640747\n",
      "mse 1.2839289568165249\n",
      "New best model found at epoch 138 with validation loss 1.2839289903640747\n",
      "Starting Epoch 139\n",
      "1.2286164338390033\n",
      "Validation loss: 1.2821190357208252\n",
      "mse 1.2821190671540412\n",
      "New best model found at epoch 139 with validation loss 1.2821190357208252\n",
      "Starting Epoch 140\n",
      "1.2275581037004788\n",
      "Validation loss: 1.2813814878463745\n",
      "mse 1.2813814613801533\n",
      "New best model found at epoch 140 with validation loss 1.2813814878463745\n",
      "Starting Epoch 141\n",
      "1.2262553895513217\n",
      "Validation loss: 1.2804548740386963\n",
      "mse 1.2804548438023906\n",
      "New best model found at epoch 141 with validation loss 1.2804548740386963\n",
      "Starting Epoch 142\n",
      "1.2250751728812854\n",
      "Validation loss: 1.2792426347732544\n",
      "mse 1.2792427409635532\n",
      "New best model found at epoch 142 with validation loss 1.2792426347732544\n",
      "Starting Epoch 143\n",
      "1.2238250250617664\n",
      "Validation loss: 1.2782195806503296\n",
      "mse 1.278219531029784\n",
      "New best model found at epoch 143 with validation loss 1.2782195806503296\n",
      "Starting Epoch 144\n",
      "1.2226948216557503\n",
      "Validation loss: 1.2770615816116333\n",
      "mse 1.2770616424761096\n",
      "New best model found at epoch 144 with validation loss 1.2770615816116333\n",
      "Starting Epoch 145\n",
      "1.2215471267700195\n",
      "Validation loss: 1.2761346101760864\n",
      "mse 1.276134588992856\n",
      "New best model found at epoch 145 with validation loss 1.2761346101760864\n",
      "Starting Epoch 146\n",
      "1.2202427064379056\n",
      "Validation loss: 1.275315523147583\n",
      "mse 1.275315414728892\n",
      "New best model found at epoch 146 with validation loss 1.275315523147583\n",
      "Starting Epoch 147\n",
      "1.2190499653418858\n",
      "Validation loss: 1.2742353677749634\n",
      "mse 1.2742352080155568\n",
      "New best model found at epoch 147 with validation loss 1.2742353677749634\n",
      "Starting Epoch 148\n",
      "1.217910851041476\n",
      "Validation loss: 1.2733728885650635\n",
      "mse 1.2733729340379027\n",
      "New best model found at epoch 148 with validation loss 1.2733728885650635\n",
      "Starting Epoch 149\n",
      "1.2168589184681575\n",
      "Validation loss: 1.272350788116455\n",
      "mse 1.2723507819118047\n",
      "New best model found at epoch 149 with validation loss 1.272350788116455\n",
      "Starting Epoch 150\n",
      "1.2156272133191426\n",
      "Validation loss: 1.2716058492660522\n",
      "mse 1.2716058333046663\n",
      "New best model found at epoch 150 with validation loss 1.2716058492660522\n",
      "Starting Epoch 151\n",
      "1.2146856486797333\n",
      "Validation loss: 1.2707194089889526\n",
      "mse 1.2707194342931272\n",
      "New best model found at epoch 151 with validation loss 1.2707194089889526\n",
      "Starting Epoch 152\n",
      "1.2135213936368625\n",
      "Validation loss: 1.2698030471801758\n",
      "mse 1.2698029946556353\n",
      "New best model found at epoch 152 with validation loss 1.2698030471801758\n",
      "Starting Epoch 153\n",
      "1.2123939047257106\n",
      "Validation loss: 1.2697720527648926\n",
      "mse 1.2697719497641482\n",
      "New best model found at epoch 153 with validation loss 1.2697720527648926\n",
      "Starting Epoch 154\n",
      "1.211475819349289\n",
      "Validation loss: 1.2686312198638916\n",
      "mse 1.268631253396646\n",
      "New best model found at epoch 154 with validation loss 1.2686312198638916\n",
      "Starting Epoch 155\n",
      "1.2104606007536252\n",
      "Validation loss: 1.267175555229187\n",
      "mse 1.2671755356112027\n",
      "New best model found at epoch 155 with validation loss 1.267175555229187\n",
      "Starting Epoch 156\n",
      "1.2092662478486698\n",
      "Validation loss: 1.2669516801834106\n",
      "mse 1.2669517875210128\n",
      "New best model found at epoch 156 with validation loss 1.2669516801834106\n",
      "Starting Epoch 157\n",
      "1.2084577307105064\n",
      "Validation loss: 1.2657305002212524\n",
      "mse 1.2657305932389291\n",
      "New best model found at epoch 157 with validation loss 1.2657305002212524\n",
      "Starting Epoch 158\n",
      "1.2071842402219772\n",
      "Validation loss: 1.2647373676300049\n",
      "mse 1.2647372922737865\n",
      "New best model found at epoch 158 with validation loss 1.2647373676300049\n",
      "Starting Epoch 159\n",
      "1.2062936971584957\n",
      "Validation loss: 1.2645342350006104\n",
      "mse 1.2645340931001778\n",
      "New best model found at epoch 159 with validation loss 1.2645342350006104\n",
      "Starting Epoch 160\n",
      "1.2052296300729115\n",
      "Validation loss: 1.2636739015579224\n",
      "mse 1.263673813127084\n",
      "New best model found at epoch 160 with validation loss 1.2636739015579224\n",
      "Starting Epoch 161\n",
      "1.2042597606778145\n",
      "Validation loss: 1.2630714178085327\n",
      "mse 1.2630713818132535\n",
      "New best model found at epoch 161 with validation loss 1.2630714178085327\n",
      "Starting Epoch 162\n",
      "1.2034547204772632\n",
      "Validation loss: 1.2614290714263916\n",
      "mse 1.2614292034696157\n",
      "New best model found at epoch 162 with validation loss 1.2614290714263916\n",
      "Starting Epoch 163\n",
      "1.2022625307242076\n",
      "Validation loss: 1.261094331741333\n",
      "mse 1.2610942061555814\n",
      "New best model found at epoch 163 with validation loss 1.261094331741333\n",
      "Starting Epoch 164\n",
      "1.2013831287622452\n",
      "Validation loss: 1.2604562044143677\n",
      "mse 1.2604564102807163\n",
      "New best model found at epoch 164 with validation loss 1.2604562044143677\n",
      "Starting Epoch 165\n",
      "1.2004437868793805\n",
      "Validation loss: 1.2593297958374023\n",
      "mse 1.2593298089603018\n",
      "New best model found at epoch 165 with validation loss 1.2593297958374023\n",
      "Starting Epoch 166\n",
      "1.1993997270862262\n",
      "Validation loss: 1.258792757987976\n",
      "mse 1.2587926522777413\n",
      "New best model found at epoch 166 with validation loss 1.258792757987976\n",
      "Starting Epoch 167\n",
      "1.198531190554301\n",
      "Validation loss: 1.2583465576171875\n",
      "mse 1.258346524339972\n",
      "New best model found at epoch 167 with validation loss 1.2583465576171875\n",
      "Starting Epoch 168\n",
      "1.1975561852256458\n",
      "Validation loss: 1.257523775100708\n",
      "mse 1.257523846581633\n",
      "New best model found at epoch 168 with validation loss 1.257523775100708\n",
      "Starting Epoch 169\n",
      "1.1964731117089589\n",
      "Validation loss: 1.2560559511184692\n",
      "mse 1.2560558639462025\n",
      "New best model found at epoch 169 with validation loss 1.2560559511184692\n",
      "Starting Epoch 170\n",
      "1.1954779649774234\n",
      "Validation loss: 1.2560142278671265\n",
      "mse 1.256014237943085\n",
      "New best model found at epoch 170 with validation loss 1.2560142278671265\n",
      "Starting Epoch 171\n",
      "1.194448893268903\n",
      "Validation loss: 1.2550455331802368\n",
      "mse 1.2550456138608364\n",
      "New best model found at epoch 171 with validation loss 1.2550455331802368\n",
      "Starting Epoch 172\n",
      "1.1936087260643642\n",
      "Validation loss: 1.25432288646698\n",
      "mse 1.2543229025365514\n",
      "New best model found at epoch 172 with validation loss 1.25432288646698\n",
      "Starting Epoch 173\n",
      "1.1927356844147046\n",
      "Validation loss: 1.2534741163253784\n",
      "mse 1.253474154540743\n",
      "New best model found at epoch 173 with validation loss 1.2534741163253784\n",
      "Starting Epoch 174\n",
      "1.191731261710326\n",
      "Validation loss: 1.2530375719070435\n",
      "mse 1.2530375831312577\n",
      "New best model found at epoch 174 with validation loss 1.2530375719070435\n",
      "Starting Epoch 175\n",
      "1.190704107284546\n",
      "Validation loss: 1.2523436546325684\n",
      "mse 1.252343675728443\n",
      "New best model found at epoch 175 with validation loss 1.2523436546325684\n",
      "Starting Epoch 176\n",
      "1.1898220007618268\n",
      "Validation loss: 1.2505900859832764\n",
      "mse 1.2505901002845634\n",
      "New best model found at epoch 176 with validation loss 1.2505900859832764\n",
      "Starting Epoch 177\n",
      "1.1889743506908417\n",
      "Validation loss: 1.2506440877914429\n",
      "mse 1.2506440613708585\n",
      "Starting Epoch 178\n",
      "1.1880451068282127\n",
      "Validation loss: 1.250165343284607\n",
      "mse 1.2501653791336271\n",
      "New best model found at epoch 178 with validation loss 1.250165343284607\n",
      "Starting Epoch 179\n",
      "1.187166800101598\n",
      "Validation loss: 1.248944878578186\n",
      "mse 1.2489448668000096\n",
      "New best model found at epoch 179 with validation loss 1.248944878578186\n",
      "Starting Epoch 180\n",
      "1.186127210656802\n",
      "Validation loss: 1.2476129531860352\n",
      "mse 1.2476130619971477\n",
      "New best model found at epoch 180 with validation loss 1.2476129531860352\n",
      "Starting Epoch 181\n",
      "1.1853585665424664\n",
      "Validation loss: 1.2474396228790283\n",
      "mse 1.2474396926790372\n",
      "New best model found at epoch 181 with validation loss 1.2474396228790283\n",
      "Starting Epoch 182\n",
      "1.1844634339213371\n",
      "Validation loss: 1.2464457750320435\n",
      "mse 1.2464458221191326\n",
      "New best model found at epoch 182 with validation loss 1.2464457750320435\n",
      "Starting Epoch 183\n",
      "1.1834505846103032\n",
      "Validation loss: 1.2456676959991455\n",
      "mse 1.2456677838250225\n",
      "New best model found at epoch 183 with validation loss 1.2456676959991455\n",
      "Starting Epoch 184\n",
      "1.1826243201891582\n",
      "Validation loss: 1.2443311214447021\n",
      "mse 1.2443313049005797\n",
      "New best model found at epoch 184 with validation loss 1.2443311214447021\n",
      "Starting Epoch 185\n",
      "1.1814237733681996\n",
      "Validation loss: 1.2439767122268677\n",
      "mse 1.243976751996185\n",
      "New best model found at epoch 185 with validation loss 1.2439767122268677\n",
      "Starting Epoch 186\n",
      "1.1806319455305736\n",
      "Validation loss: 1.24287748336792\n",
      "mse 1.242877413702501\n",
      "New best model found at epoch 186 with validation loss 1.24287748336792\n",
      "Starting Epoch 187\n",
      "1.1794440150260925\n",
      "Validation loss: 1.242277979850769\n",
      "mse 1.2422780636586004\n",
      "New best model found at epoch 187 with validation loss 1.242277979850769\n",
      "Starting Epoch 188\n",
      "1.1782587269941966\n",
      "Validation loss: 1.241037130355835\n",
      "mse 1.241037174731476\n",
      "New best model found at epoch 188 with validation loss 1.241037130355835\n",
      "Starting Epoch 189\n",
      "1.177296628554662\n",
      "Validation loss: 1.2407528162002563\n",
      "mse 1.2407528562217334\n",
      "New best model found at epoch 189 with validation loss 1.2407528162002563\n",
      "Starting Epoch 190\n",
      "1.176459436615308\n",
      "Validation loss: 1.2390767335891724\n",
      "mse 1.2390767206469961\n",
      "New best model found at epoch 190 with validation loss 1.2390767335891724\n",
      "Starting Epoch 191\n",
      "1.1754588584105174\n",
      "Validation loss: 1.2388750314712524\n",
      "mse 1.2388750483242688\n",
      "New best model found at epoch 191 with validation loss 1.2388750314712524\n",
      "Starting Epoch 192\n",
      "1.174536796907584\n",
      "Validation loss: 1.238471269607544\n",
      "mse 1.2384710830820254\n",
      "New best model found at epoch 192 with validation loss 1.238471269607544\n",
      "Starting Epoch 193\n",
      "1.1736097161968548\n",
      "Validation loss: 1.2373195886611938\n",
      "mse 1.2373195778029267\n",
      "New best model found at epoch 193 with validation loss 1.2373195886611938\n",
      "Starting Epoch 194\n",
      "1.1727040509382884\n",
      "Validation loss: 1.236702561378479\n",
      "mse 1.2367027159782316\n",
      "New best model found at epoch 194 with validation loss 1.236702561378479\n",
      "Starting Epoch 195\n",
      "1.1719335590799649\n",
      "Validation loss: 1.2364089488983154\n",
      "mse 1.2364089572146404\n",
      "New best model found at epoch 195 with validation loss 1.2364089488983154\n",
      "Starting Epoch 196\n",
      "1.1708811670541763\n",
      "Validation loss: 1.234872579574585\n",
      "mse 1.2348724588746969\n",
      "New best model found at epoch 196 with validation loss 1.234872579574585\n",
      "Starting Epoch 197\n",
      "1.1697032327453296\n",
      "Validation loss: 1.235498070716858\n",
      "mse 1.2354981494298536\n",
      "Starting Epoch 198\n",
      "1.169421911239624\n",
      "Validation loss: 1.2344801425933838\n",
      "mse 1.2344802384037954\n",
      "New best model found at epoch 198 with validation loss 1.2344801425933838\n",
      "Starting Epoch 199\n",
      "1.1684826910495758\n",
      "Validation loss: 1.234363079071045\n",
      "mse 1.2343631438339828\n",
      "New best model found at epoch 199 with validation loss 1.234363079071045\n",
      "Starting Epoch 200\n",
      "1.167552299797535\n",
      "Validation loss: 1.2338870763778687\n",
      "mse 1.2338871935673377\n",
      "New best model found at epoch 200 with validation loss 1.2338870763778687\n",
      "Starting Epoch 201\n",
      "1.16676298280557\n",
      "Validation loss: 1.2324570417404175\n",
      "mse 1.2324570099424736\n",
      "New best model found at epoch 201 with validation loss 1.2324570417404175\n",
      "Starting Epoch 202\n",
      "1.1656952798366547\n",
      "Validation loss: 1.2324519157409668\n",
      "mse 1.2324519038350346\n",
      "New best model found at epoch 202 with validation loss 1.2324519157409668\n",
      "Starting Epoch 203\n",
      "1.1650499776005745\n",
      "Validation loss: 1.232126235961914\n",
      "mse 1.2321261909391614\n",
      "New best model found at epoch 203 with validation loss 1.232126235961914\n",
      "Starting Epoch 204\n",
      "1.1641672278443973\n",
      "Validation loss: 1.2323335409164429\n",
      "mse 1.2323334971910134\n",
      "Starting Epoch 205\n",
      "1.1634543016552925\n",
      "Validation loss: 1.2317700386047363\n",
      "mse 1.2317699981043344\n",
      "New best model found at epoch 205 with validation loss 1.2317700386047363\n",
      "Starting Epoch 206\n",
      "1.1625931411981583\n",
      "Validation loss: 1.2313965559005737\n",
      "mse 1.2313965785438232\n",
      "New best model found at epoch 206 with validation loss 1.2313965559005737\n",
      "Starting Epoch 207\n",
      "1.1620736916859944\n",
      "Validation loss: 1.230373501777649\n",
      "mse 1.2303735223010916\n",
      "New best model found at epoch 207 with validation loss 1.230373501777649\n",
      "Starting Epoch 208\n",
      "1.1612464015682538\n",
      "Validation loss: 1.2301188707351685\n",
      "mse 1.2301189157639576\n",
      "New best model found at epoch 208 with validation loss 1.2301188707351685\n",
      "Starting Epoch 209\n",
      "1.160323940217495\n",
      "Validation loss: 1.2301998138427734\n",
      "mse 1.230199849834924\n",
      "Starting Epoch 210\n",
      "1.159474345544974\n",
      "Validation loss: 1.229422926902771\n",
      "mse 1.229422976957067\n",
      "New best model found at epoch 210 with validation loss 1.229422926902771\n",
      "Starting Epoch 211\n",
      "1.1588178301850955\n",
      "Validation loss: 1.2296613454818726\n",
      "mse 1.2296614197384872\n",
      "Starting Epoch 212\n",
      "1.1581091061234474\n",
      "Validation loss: 1.2293763160705566\n",
      "mse 1.2293763865138627\n",
      "New best model found at epoch 212 with validation loss 1.2293763160705566\n",
      "Starting Epoch 213\n",
      "1.1571740930279095\n",
      "Validation loss: 1.2292828559875488\n",
      "mse 1.2292827626072305\n",
      "New best model found at epoch 213 with validation loss 1.2292828559875488\n",
      "Starting Epoch 214\n",
      "1.1564001490672429\n",
      "Validation loss: 1.228722095489502\n",
      "mse 1.2287220296865593\n",
      "New best model found at epoch 214 with validation loss 1.228722095489502\n",
      "Starting Epoch 215\n",
      "1.1557760735352833\n",
      "Validation loss: 1.2283754348754883\n",
      "mse 1.2283753767180892\n",
      "New best model found at epoch 215 with validation loss 1.2283754348754883\n",
      "Starting Epoch 216\n",
      "1.1547347952922185\n",
      "Validation loss: 1.2272827625274658\n",
      "mse 1.2272827167973073\n",
      "New best model found at epoch 216 with validation loss 1.2272827625274658\n",
      "Starting Epoch 217\n",
      "1.154168685277303\n",
      "Validation loss: 1.2263203859329224\n",
      "mse 1.2263204108054186\n",
      "New best model found at epoch 217 with validation loss 1.2263203859329224\n",
      "Starting Epoch 218\n",
      "1.1533040975530942\n",
      "Validation loss: 1.2262669801712036\n",
      "mse 1.2262670689488726\n",
      "New best model found at epoch 218 with validation loss 1.2262669801712036\n",
      "Starting Epoch 219\n",
      "1.1525499199827511\n",
      "Validation loss: 1.2258949279785156\n",
      "mse 1.225894937638478\n",
      "New best model found at epoch 219 with validation loss 1.2258949279785156\n",
      "Starting Epoch 220\n",
      "1.151665061712265\n",
      "Validation loss: 1.225724458694458\n",
      "mse 1.2257243741635582\n",
      "New best model found at epoch 220 with validation loss 1.225724458694458\n",
      "Starting Epoch 221\n",
      "1.1509906897942226\n",
      "Validation loss: 1.2258380651474\n",
      "mse 1.2258381646089271\n",
      "Starting Epoch 222\n",
      "1.1502422864238422\n",
      "Validation loss: 1.225914478302002\n",
      "mse 1.2259144309054877\n",
      "Starting Epoch 223\n",
      "1.1493686238924663\n",
      "Validation loss: 1.224627137184143\n",
      "mse 1.22462716408553\n",
      "New best model found at epoch 223 with validation loss 1.224627137184143\n",
      "Starting Epoch 224\n",
      "1.1484104171395302\n",
      "Validation loss: 1.2251832485198975\n",
      "mse 1.2251832386384836\n",
      "Starting Epoch 225\n",
      "1.1474491705497105\n",
      "Validation loss: 1.2244457006454468\n",
      "mse 1.224445630837374\n",
      "New best model found at epoch 225 with validation loss 1.2244457006454468\n",
      "Starting Epoch 226\n",
      "1.146900104979674\n",
      "Validation loss: 1.2244253158569336\n",
      "mse 1.2244252891899716\n",
      "New best model found at epoch 226 with validation loss 1.2244253158569336\n",
      "Starting Epoch 227\n",
      "1.1458326900998752\n",
      "Validation loss: 1.2245067358016968\n",
      "mse 1.2245067811541557\n",
      "Starting Epoch 228\n",
      "1.145315597454707\n",
      "Validation loss: 1.2234857082366943\n",
      "mse 1.223485649218628\n",
      "New best model found at epoch 228 with validation loss 1.2234857082366943\n",
      "Starting Epoch 229\n",
      "1.1447310323516529\n",
      "Validation loss: 1.223565936088562\n",
      "mse 1.2235659637979854\n",
      "Starting Epoch 230\n",
      "1.1440098782380421\n",
      "Validation loss: 1.2235844135284424\n",
      "mse 1.2235843908440482\n",
      "Starting Epoch 231\n",
      "1.1432375957568486\n",
      "Validation loss: 1.2231441736221313\n",
      "mse 1.2231442422231678\n",
      "New best model found at epoch 231 with validation loss 1.2231441736221313\n",
      "Starting Epoch 232\n",
      "1.1425220941503842\n",
      "Validation loss: 1.222781777381897\n",
      "mse 1.222781893481326\n",
      "New best model found at epoch 232 with validation loss 1.222781777381897\n",
      "Starting Epoch 233\n",
      "1.142001911997795\n",
      "Validation loss: 1.221323847770691\n",
      "mse 1.2213240023018257\n",
      "New best model found at epoch 233 with validation loss 1.221323847770691\n",
      "Starting Epoch 234\n",
      "1.141369437177976\n",
      "Validation loss: 1.2214252948760986\n",
      "mse 1.2214251536131635\n",
      "Starting Epoch 235\n",
      "1.1407252947489421\n",
      "Validation loss: 1.2203227281570435\n",
      "mse 1.220322729303433\n",
      "New best model found at epoch 235 with validation loss 1.2203227281570435\n",
      "Starting Epoch 236\n",
      "1.1401171907782555\n",
      "Validation loss: 1.21975839138031\n",
      "mse 1.219758543066424\n",
      "New best model found at epoch 236 with validation loss 1.21975839138031\n",
      "Starting Epoch 237\n",
      "1.139573685824871\n",
      "Validation loss: 1.2196764945983887\n",
      "mse 1.2196764963831106\n",
      "New best model found at epoch 237 with validation loss 1.2196764945983887\n",
      "Starting Epoch 238\n",
      "1.1390031352639198\n",
      "Validation loss: 1.2207152843475342\n",
      "mse 1.2207151940812901\n",
      "Starting Epoch 239\n",
      "1.138443723320961\n",
      "Validation loss: 1.2202435731887817\n",
      "mse 1.2202436151688627\n",
      "Starting Epoch 240\n",
      "1.137920727332433\n",
      "Validation loss: 1.219673752784729\n",
      "mse 1.2196737183699473\n",
      "New best model found at epoch 240 with validation loss 1.219673752784729\n",
      "Starting Epoch 241\n",
      "1.1372432733575504\n",
      "Validation loss: 1.2188093662261963\n",
      "mse 1.2188092804893422\n",
      "New best model found at epoch 241 with validation loss 1.2188093662261963\n",
      "Starting Epoch 242\n",
      "1.1366475348671277\n",
      "Validation loss: 1.2190688848495483\n",
      "mse 1.2190688376017538\n",
      "Starting Epoch 243\n",
      "1.136262873808543\n",
      "Validation loss: 1.2174266576766968\n",
      "mse 1.217426626338385\n",
      "New best model found at epoch 243 with validation loss 1.2174266576766968\n",
      "Starting Epoch 244\n",
      "1.1356223076581955\n",
      "Validation loss: 1.2179607152938843\n",
      "mse 1.2179607858534338\n",
      "Starting Epoch 245\n",
      "1.1351057837406795\n",
      "Validation loss: 1.2179282903671265\n",
      "mse 1.2179283501858043\n",
      "Starting Epoch 246\n",
      "1.1344026997685432\n",
      "Validation loss: 1.2170872688293457\n",
      "mse 1.2170873032699456\n",
      "New best model found at epoch 246 with validation loss 1.2170872688293457\n",
      "Starting Epoch 247\n",
      "1.1340358431140583\n",
      "Validation loss: 1.2169286012649536\n",
      "mse 1.2169286330821505\n",
      "New best model found at epoch 247 with validation loss 1.2169286012649536\n",
      "Starting Epoch 248\n",
      "1.1333905855814617\n",
      "Validation loss: 1.2171401977539062\n",
      "mse 1.2171401097933368\n",
      "Starting Epoch 249\n",
      "1.1328937684496243\n",
      "Validation loss: 1.2163060903549194\n",
      "mse 1.216306032570756\n",
      "New best model found at epoch 249 with validation loss 1.2163060903549194\n",
      "Starting Epoch 250\n",
      "1.132496898372968\n",
      "Validation loss: 1.2161363363265991\n",
      "mse 1.216136252055285\n",
      "New best model found at epoch 250 with validation loss 1.2161363363265991\n",
      "Starting Epoch 251\n",
      "1.1319123283028603\n",
      "Validation loss: 1.2158335447311401\n",
      "mse 1.2158334512500786\n",
      "New best model found at epoch 251 with validation loss 1.2158335447311401\n",
      "Starting Epoch 252\n",
      "1.1313474078973134\n",
      "Validation loss: 1.216009259223938\n",
      "mse 1.2160092928400685\n",
      "Starting Epoch 253\n",
      "1.1308733547727268\n",
      "Validation loss: 1.2155407667160034\n",
      "mse 1.2155407963038356\n",
      "New best model found at epoch 253 with validation loss 1.2155407667160034\n",
      "Starting Epoch 254\n",
      "1.1302539308865864\n",
      "Validation loss: 1.2154160737991333\n",
      "mse 1.2154159971097576\n",
      "New best model found at epoch 254 with validation loss 1.2154160737991333\n",
      "Starting Epoch 255\n",
      "1.1297391951084137\n",
      "Validation loss: 1.2146636247634888\n",
      "mse 1.2146636725300053\n",
      "New best model found at epoch 255 with validation loss 1.2146636247634888\n",
      "Starting Epoch 256\n",
      "1.1294537608822186\n",
      "Validation loss: 1.2144560813903809\n",
      "mse 1.214456139462803\n",
      "New best model found at epoch 256 with validation loss 1.2144560813903809\n",
      "Starting Epoch 257\n",
      "1.1288297101855278\n",
      "Validation loss: 1.2139780521392822\n",
      "mse 1.2139780292765736\n",
      "New best model found at epoch 257 with validation loss 1.2139780521392822\n",
      "Starting Epoch 258\n",
      "1.128394104540348\n",
      "Validation loss: 1.2142542600631714\n",
      "mse 1.2142542297213934\n",
      "Starting Epoch 259\n",
      "1.127822237710158\n",
      "Validation loss: 1.2134472131729126\n",
      "mse 1.2134472676491208\n",
      "New best model found at epoch 259 with validation loss 1.2134472131729126\n",
      "Starting Epoch 260\n",
      "1.1274814109007518\n",
      "Validation loss: 1.213636875152588\n",
      "mse 1.213636917790105\n",
      "Starting Epoch 261\n",
      "1.1269674971699715\n",
      "Validation loss: 1.2130471467971802\n",
      "mse 1.2130471600957982\n",
      "New best model found at epoch 261 with validation loss 1.2130471467971802\n",
      "Starting Epoch 262\n",
      "1.1264993250370026\n",
      "Validation loss: 1.212605595588684\n",
      "mse 1.2126054241618867\n",
      "New best model found at epoch 262 with validation loss 1.212605595588684\n",
      "Starting Epoch 263\n",
      "1.125942051410675\n",
      "Validation loss: 1.2119706869125366\n",
      "mse 1.2119706280814628\n",
      "New best model found at epoch 263 with validation loss 1.2119706869125366\n",
      "Starting Epoch 264\n",
      "1.1255885536472003\n",
      "Validation loss: 1.211431622505188\n",
      "mse 1.21143157267029\n",
      "New best model found at epoch 264 with validation loss 1.211431622505188\n",
      "Starting Epoch 265\n",
      "1.1250263080000877\n",
      "Validation loss: 1.2119102478027344\n",
      "mse 1.211910202210666\n",
      "Starting Epoch 266\n",
      "1.1246342783172925\n",
      "Validation loss: 1.2116588354110718\n",
      "mse 1.2116587812160486\n",
      "Starting Epoch 267\n",
      "1.124048297603925\n",
      "Validation loss: 1.2112078666687012\n",
      "mse 1.2112078730534472\n",
      "New best model found at epoch 267 with validation loss 1.2112078666687012\n",
      "Starting Epoch 268\n",
      "1.1236547206838925\n",
      "Validation loss: 1.2102617025375366\n",
      "mse 1.2102616923281622\n",
      "New best model found at epoch 268 with validation loss 1.2102617025375366\n",
      "Starting Epoch 269\n",
      "1.1230796352028847\n",
      "Validation loss: 1.2103396654129028\n",
      "mse 1.2103396649444875\n",
      "Starting Epoch 270\n",
      "1.1227260902523994\n",
      "Validation loss: 1.2106153964996338\n",
      "mse 1.210615373615293\n",
      "Starting Epoch 271\n",
      "1.122349274655183\n",
      "Validation loss: 1.2094850540161133\n",
      "mse 1.2094850405240618\n",
      "New best model found at epoch 271 with validation loss 1.2094850540161133\n",
      "Starting Epoch 272\n",
      "1.1217340379953384\n",
      "Validation loss: 1.2094813585281372\n",
      "mse 1.2094813346482238\n",
      "New best model found at epoch 272 with validation loss 1.2094813585281372\n",
      "Starting Epoch 273\n",
      "1.1213352233171463\n",
      "Validation loss: 1.209625482559204\n",
      "mse 1.209625448365925\n",
      "Starting Epoch 274\n",
      "1.1209673807024956\n",
      "Validation loss: 1.208095908164978\n",
      "mse 1.2080959482378544\n",
      "New best model found at epoch 274 with validation loss 1.208095908164978\n",
      "Starting Epoch 275\n",
      "1.1206181620558102\n",
      "Validation loss: 1.208234190940857\n",
      "mse 1.2082344495254447\n",
      "Starting Epoch 276\n",
      "1.1200417031844456\n",
      "Validation loss: 1.2078481912612915\n",
      "mse 1.207848144534231\n",
      "New best model found at epoch 276 with validation loss 1.2078481912612915\n",
      "Starting Epoch 277\n",
      "1.1196354925632477\n",
      "Validation loss: 1.2080104351043701\n",
      "mse 1.208010504517042\n",
      "Starting Epoch 278\n",
      "1.119178021947543\n",
      "Validation loss: 1.2075437307357788\n",
      "mse 1.2075437561196714\n",
      "New best model found at epoch 278 with validation loss 1.2075437307357788\n",
      "Starting Epoch 279\n",
      "1.1187100211779277\n",
      "Validation loss: 1.207675814628601\n",
      "mse 1.2076757759034298\n",
      "Starting Epoch 280\n",
      "1.1182110160589218\n",
      "Validation loss: 1.2067149877548218\n",
      "mse 1.2067148787788238\n",
      "New best model found at epoch 280 with validation loss 1.2067149877548218\n",
      "Starting Epoch 281\n",
      "1.1178781936566036\n",
      "Validation loss: 1.206553339958191\n",
      "mse 1.2065533516224245\n",
      "New best model found at epoch 281 with validation loss 1.206553339958191\n",
      "Starting Epoch 282\n",
      "1.1173700417081516\n",
      "Validation loss: 1.2062703371047974\n",
      "mse 1.2062705513714513\n",
      "New best model found at epoch 282 with validation loss 1.2062703371047974\n",
      "Starting Epoch 283\n",
      "1.1170525600512822\n",
      "Validation loss: 1.2056310176849365\n",
      "mse 1.20563095300404\n",
      "New best model found at epoch 283 with validation loss 1.2056310176849365\n",
      "Starting Epoch 284\n",
      "1.1165871247649193\n",
      "Validation loss: 1.2053688764572144\n",
      "mse 1.2053689372302707\n",
      "New best model found at epoch 284 with validation loss 1.2053688764572144\n",
      "Starting Epoch 285\n",
      "1.1161399309833844\n",
      "Validation loss: 1.205200433731079\n",
      "mse 1.2052003427527362\n",
      "New best model found at epoch 285 with validation loss 1.205200433731079\n",
      "Starting Epoch 286\n",
      "1.115701138973236\n",
      "Validation loss: 1.204676866531372\n",
      "mse 1.204676986261323\n",
      "New best model found at epoch 286 with validation loss 1.204676866531372\n",
      "Starting Epoch 287\n",
      "1.1154157270987828\n",
      "Validation loss: 1.2047019004821777\n",
      "mse 1.20470194670058\n",
      "Starting Epoch 288\n",
      "1.1150319402416546\n",
      "Validation loss: 1.2044391632080078\n",
      "mse 1.204439070867666\n",
      "New best model found at epoch 288 with validation loss 1.2044391632080078\n",
      "Starting Epoch 289\n",
      "1.1145404875278473\n",
      "Validation loss: 1.2048465013504028\n",
      "mse 1.2048465597226077\n",
      "Starting Epoch 290\n",
      "1.1142224843303363\n",
      "Validation loss: 1.204382300376892\n",
      "mse 1.2043821972143818\n",
      "New best model found at epoch 290 with validation loss 1.204382300376892\n",
      "Starting Epoch 291\n",
      "1.1137358918786049\n",
      "Validation loss: 1.2039891481399536\n",
      "mse 1.2039891414406017\n",
      "New best model found at epoch 291 with validation loss 1.2039891481399536\n",
      "Starting Epoch 292\n",
      "1.113368255396684\n",
      "Validation loss: 1.203547716140747\n",
      "mse 1.2035476953041804\n",
      "New best model found at epoch 292 with validation loss 1.203547716140747\n",
      "Starting Epoch 293\n",
      "1.1129487107197444\n",
      "Validation loss: 1.2032301425933838\n",
      "mse 1.2032300469587076\n",
      "New best model found at epoch 293 with validation loss 1.2032301425933838\n",
      "Starting Epoch 294\n",
      "1.11264156550169\n",
      "Validation loss: 1.2033785581588745\n",
      "mse 1.2033784918235984\n",
      "Starting Epoch 295\n",
      "1.1121220986048381\n",
      "Validation loss: 1.203070878982544\n",
      "mse 1.2030707895148172\n",
      "New best model found at epoch 295 with validation loss 1.203070878982544\n",
      "Starting Epoch 296\n",
      "1.1118394061923027\n",
      "Validation loss: 1.2033894062042236\n",
      "mse 1.2033893056738831\n",
      "Starting Epoch 297\n",
      "1.111440747976303\n",
      "Validation loss: 1.2032829523086548\n",
      "mse 1.2032831091688856\n",
      "Starting Epoch 298\n",
      "1.1110430384675662\n",
      "Validation loss: 1.202890396118164\n",
      "mse 1.2028904788372903\n",
      "New best model found at epoch 298 with validation loss 1.202890396118164\n",
      "Starting Epoch 299\n",
      "1.1107453977068265\n",
      "Validation loss: 1.2029390335083008\n",
      "mse 1.2029390429808775\n",
      "Starting Epoch 300\n",
      "1.1101570427417755\n",
      "Validation loss: 1.2027300596237183\n",
      "mse 1.202730023154227\n",
      "New best model found at epoch 300 with validation loss 1.2027300596237183\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-max: 7-80-50-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff9c4b9",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.25-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "41a2d11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "65b414a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,8,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "7f30f63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'q25(container counts)', 'q25(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "e1d1b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "58891e68-90b1-4410-b65f-62ef057535ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.636063272754351\n",
      "Validation loss: 1.98708176612854\n",
      "mse 1.9870818795185814\n",
      "New best model found at epoch 1 with validation loss 1.98708176612854\n",
      "Starting Epoch 2\n",
      "1.9817129870255787\n",
      "Validation loss: 1.840964674949646\n",
      "mse 1.8409645385215874\n",
      "New best model found at epoch 2 with validation loss 1.840964674949646\n",
      "Starting Epoch 3\n",
      "1.89666681488355\n",
      "Validation loss: 1.77755606174469\n",
      "mse 1.7775559303700263\n",
      "New best model found at epoch 3 with validation loss 1.77755606174469\n",
      "Starting Epoch 4\n",
      "1.85234401623408\n",
      "Validation loss: 1.7444783449172974\n",
      "mse 1.744478447526175\n",
      "New best model found at epoch 4 with validation loss 1.7444783449172974\n",
      "Starting Epoch 5\n",
      "1.8221900562445323\n",
      "Validation loss: 1.723644733428955\n",
      "mse 1.723644658418027\n",
      "New best model found at epoch 5 with validation loss 1.723644733428955\n",
      "Starting Epoch 6\n",
      "1.799769828716914\n",
      "Validation loss: 1.7079905271530151\n",
      "mse 1.7079905394495265\n",
      "New best model found at epoch 6 with validation loss 1.7079905271530151\n",
      "Starting Epoch 7\n",
      "1.7818659742673237\n",
      "Validation loss: 1.695907473564148\n",
      "mse 1.6959073650994765\n",
      "New best model found at epoch 7 with validation loss 1.695907473564148\n",
      "Starting Epoch 8\n",
      "1.766609827677409\n",
      "Validation loss: 1.686846375465393\n",
      "mse 1.686846457727302\n",
      "New best model found at epoch 8 with validation loss 1.686846375465393\n",
      "Starting Epoch 9\n",
      "1.754153033097585\n",
      "Validation loss: 1.6772984266281128\n",
      "mse 1.677298515697092\n",
      "New best model found at epoch 9 with validation loss 1.6772984266281128\n",
      "Starting Epoch 10\n",
      "1.7426764965057373\n",
      "Validation loss: 1.6708065271377563\n",
      "mse 1.6708064770692896\n",
      "New best model found at epoch 10 with validation loss 1.6708065271377563\n",
      "Starting Epoch 11\n",
      "1.7326201250155766\n",
      "Validation loss: 1.6639041900634766\n",
      "mse 1.6639039980558596\n",
      "New best model found at epoch 11 with validation loss 1.6639041900634766\n",
      "Starting Epoch 12\n",
      "1.723771795630455\n",
      "Validation loss: 1.6574419736862183\n",
      "mse 1.6574420204465714\n",
      "New best model found at epoch 12 with validation loss 1.6574419736862183\n",
      "Starting Epoch 13\n",
      "1.7153683950503666\n",
      "Validation loss: 1.6519250869750977\n",
      "mse 1.6519249852027842\n",
      "New best model found at epoch 13 with validation loss 1.6519250869750977\n",
      "Starting Epoch 14\n",
      "1.7075168987115223\n",
      "Validation loss: 1.6459006071090698\n",
      "mse 1.645900655759543\n",
      "New best model found at epoch 14 with validation loss 1.6459006071090698\n",
      "Starting Epoch 15\n",
      "1.6994327157735825\n",
      "Validation loss: 1.6395798921585083\n",
      "mse 1.6395798941919026\n",
      "New best model found at epoch 15 with validation loss 1.6395798921585083\n",
      "Starting Epoch 16\n",
      "1.6916704873243968\n",
      "Validation loss: 1.6338603496551514\n",
      "mse 1.633860472268392\n",
      "New best model found at epoch 16 with validation loss 1.6338603496551514\n",
      "Starting Epoch 17\n",
      "1.6844199697176616\n",
      "Validation loss: 1.6287323236465454\n",
      "mse 1.628732341211792\n",
      "New best model found at epoch 17 with validation loss 1.6287323236465454\n",
      "Starting Epoch 18\n",
      "1.677465796470642\n",
      "Validation loss: 1.6250145435333252\n",
      "mse 1.6250145186834635\n",
      "New best model found at epoch 18 with validation loss 1.6250145435333252\n",
      "Starting Epoch 19\n",
      "1.6713067044814427\n",
      "Validation loss: 1.6207590103149414\n",
      "mse 1.6207589892117091\n",
      "New best model found at epoch 19 with validation loss 1.6207590103149414\n",
      "Starting Epoch 20\n",
      "1.6653427829345067\n",
      "Validation loss: 1.6167936325073242\n",
      "mse 1.6167936197869086\n",
      "New best model found at epoch 20 with validation loss 1.6167936325073242\n",
      "Starting Epoch 21\n",
      "1.659287805358569\n",
      "Validation loss: 1.6133222579956055\n",
      "mse 1.6133223540744754\n",
      "New best model found at epoch 21 with validation loss 1.6133222579956055\n",
      "Starting Epoch 22\n",
      "1.6537388116121292\n",
      "Validation loss: 1.6093997955322266\n",
      "mse 1.6093999293419998\n",
      "New best model found at epoch 22 with validation loss 1.6093997955322266\n",
      "Starting Epoch 23\n",
      "1.648283690214157\n",
      "Validation loss: 1.6057007312774658\n",
      "mse 1.6057008111832278\n",
      "New best model found at epoch 23 with validation loss 1.6057007312774658\n",
      "Starting Epoch 24\n",
      "1.6428777277469635\n",
      "Validation loss: 1.6021814346313477\n",
      "mse 1.602181539266676\n",
      "New best model found at epoch 24 with validation loss 1.6021814346313477\n",
      "Starting Epoch 25\n",
      "1.637491802374522\n",
      "Validation loss: 1.5989758968353271\n",
      "mse 1.5989758593993488\n",
      "New best model found at epoch 25 with validation loss 1.5989758968353271\n",
      "Starting Epoch 26\n",
      "1.6323776592810948\n",
      "Validation loss: 1.595760703086853\n",
      "mse 1.5957607050403344\n",
      "New best model found at epoch 26 with validation loss 1.595760703086853\n",
      "Starting Epoch 27\n",
      "1.6273179948329926\n",
      "Validation loss: 1.5922765731811523\n",
      "mse 1.5922766607539673\n",
      "New best model found at epoch 27 with validation loss 1.5922765731811523\n",
      "Starting Epoch 28\n",
      "1.6223486264546711\n",
      "Validation loss: 1.5880730152130127\n",
      "mse 1.588072976132359\n",
      "New best model found at epoch 28 with validation loss 1.5880730152130127\n",
      "Starting Epoch 29\n",
      "1.617410068710645\n",
      "Validation loss: 1.585257649421692\n",
      "mse 1.5852576877715294\n",
      "New best model found at epoch 29 with validation loss 1.585257649421692\n",
      "Starting Epoch 30\n",
      "1.612694541613261\n",
      "Validation loss: 1.582458257675171\n",
      "mse 1.582458390349746\n",
      "New best model found at epoch 30 with validation loss 1.582458257675171\n",
      "Starting Epoch 31\n",
      "1.6080131977796555\n",
      "Validation loss: 1.579736351966858\n",
      "mse 1.5797363986989144\n",
      "New best model found at epoch 31 with validation loss 1.579736351966858\n",
      "Starting Epoch 32\n",
      "1.603661318620046\n",
      "Validation loss: 1.5764129161834717\n",
      "mse 1.5764128987576045\n",
      "New best model found at epoch 32 with validation loss 1.5764129161834717\n",
      "Starting Epoch 33\n",
      "1.5990763008594513\n",
      "Validation loss: 1.5739619731903076\n",
      "mse 1.5739620387237514\n",
      "New best model found at epoch 33 with validation loss 1.5739619731903076\n",
      "Starting Epoch 34\n",
      "1.5944846421480179\n",
      "Validation loss: 1.5710893869400024\n",
      "mse 1.5710895178895863\n",
      "New best model found at epoch 34 with validation loss 1.5710893869400024\n",
      "Starting Epoch 35\n",
      "1.5903650373220444\n",
      "Validation loss: 1.567242980003357\n",
      "mse 1.5672430487565918\n",
      "New best model found at epoch 35 with validation loss 1.567242980003357\n",
      "Starting Epoch 36\n",
      "1.5860090553760529\n",
      "Validation loss: 1.5646097660064697\n",
      "mse 1.564609706257099\n",
      "New best model found at epoch 36 with validation loss 1.5646097660064697\n",
      "Starting Epoch 37\n",
      "1.5817191849152248\n",
      "Validation loss: 1.5623700618743896\n",
      "mse 1.5623701913655006\n",
      "New best model found at epoch 37 with validation loss 1.5623700618743896\n",
      "Starting Epoch 38\n",
      "1.5777731041113536\n",
      "Validation loss: 1.5599123239517212\n",
      "mse 1.5599123785865758\n",
      "New best model found at epoch 38 with validation loss 1.5599123239517212\n",
      "Starting Epoch 39\n",
      "1.5736032476027806\n",
      "Validation loss: 1.5572075843811035\n",
      "mse 1.557207551091843\n",
      "New best model found at epoch 39 with validation loss 1.5572075843811035\n",
      "Starting Epoch 40\n",
      "1.5696399162213008\n",
      "Validation loss: 1.5544418096542358\n",
      "mse 1.5544416587596788\n",
      "New best model found at epoch 40 with validation loss 1.5544418096542358\n",
      "Starting Epoch 41\n",
      "1.565356805920601\n",
      "Validation loss: 1.552707552909851\n",
      "mse 1.552707477437603\n",
      "New best model found at epoch 41 with validation loss 1.552707552909851\n",
      "Starting Epoch 42\n",
      "1.5618182768424351\n",
      "Validation loss: 1.5488770008087158\n",
      "mse 1.5488770052606455\n",
      "New best model found at epoch 42 with validation loss 1.5488770008087158\n",
      "Starting Epoch 43\n",
      "1.5578992068767548\n",
      "Validation loss: 1.5464929342269897\n",
      "mse 1.546492905613193\n",
      "New best model found at epoch 43 with validation loss 1.5464929342269897\n",
      "Starting Epoch 44\n",
      "1.5540049970149994\n",
      "Validation loss: 1.5446696281433105\n",
      "mse 1.5446695075772978\n",
      "New best model found at epoch 44 with validation loss 1.5446696281433105\n",
      "Starting Epoch 45\n",
      "1.5505695343017578\n",
      "Validation loss: 1.541926622390747\n",
      "mse 1.5419266090151336\n",
      "New best model found at epoch 45 with validation loss 1.541926622390747\n",
      "Starting Epoch 46\n",
      "1.546758512655894\n",
      "Validation loss: 1.5396733283996582\n",
      "mse 1.5396733786301713\n",
      "New best model found at epoch 46 with validation loss 1.5396733283996582\n",
      "Starting Epoch 47\n",
      "1.5432669073343277\n",
      "Validation loss: 1.537554383277893\n",
      "mse 1.5375542642294033\n",
      "New best model found at epoch 47 with validation loss 1.537554383277893\n",
      "Starting Epoch 48\n",
      "1.5396753400564194\n",
      "Validation loss: 1.5346705913543701\n",
      "mse 1.5346704363419532\n",
      "New best model found at epoch 48 with validation loss 1.5346705913543701\n",
      "Starting Epoch 49\n",
      "1.5361634741226833\n",
      "Validation loss: 1.5322761535644531\n",
      "mse 1.5322761431273708\n",
      "New best model found at epoch 49 with validation loss 1.5322761535644531\n",
      "Starting Epoch 50\n",
      "1.5326111416021984\n",
      "Validation loss: 1.5296419858932495\n",
      "mse 1.5296418362804869\n",
      "New best model found at epoch 50 with validation loss 1.5296419858932495\n",
      "Starting Epoch 51\n",
      "1.5291792104641597\n",
      "Validation loss: 1.5279628038406372\n",
      "mse 1.5279629657774916\n",
      "New best model found at epoch 51 with validation loss 1.5279628038406372\n",
      "Starting Epoch 52\n",
      "1.525925914446513\n",
      "Validation loss: 1.5257608890533447\n",
      "mse 1.5257609596013848\n",
      "New best model found at epoch 52 with validation loss 1.5257608890533447\n",
      "Starting Epoch 53\n",
      "1.5224266896645229\n",
      "Validation loss: 1.522765040397644\n",
      "mse 1.522765056498465\n",
      "New best model found at epoch 53 with validation loss 1.522765040397644\n",
      "Starting Epoch 54\n",
      "1.5189360827207565\n",
      "Validation loss: 1.5201963186264038\n",
      "mse 1.520196332620201\n",
      "New best model found at epoch 54 with validation loss 1.5201963186264038\n",
      "Starting Epoch 55\n",
      "1.5155483931303024\n",
      "Validation loss: 1.5179316997528076\n",
      "mse 1.517931752224108\n",
      "New best model found at epoch 55 with validation loss 1.5179316997528076\n",
      "Starting Epoch 56\n",
      "1.5122066587209702\n",
      "Validation loss: 1.515751838684082\n",
      "mse 1.5157517861043401\n",
      "New best model found at epoch 56 with validation loss 1.515751838684082\n",
      "Starting Epoch 57\n",
      "1.5087359100580215\n",
      "Validation loss: 1.5130378007888794\n",
      "mse 1.5130378392010986\n",
      "New best model found at epoch 57 with validation loss 1.5130378007888794\n",
      "Starting Epoch 58\n",
      "1.5055436839660008\n",
      "Validation loss: 1.51060152053833\n",
      "mse 1.5106015917155085\n",
      "New best model found at epoch 58 with validation loss 1.51060152053833\n",
      "Starting Epoch 59\n",
      "1.5024156669775646\n",
      "Validation loss: 1.508104920387268\n",
      "mse 1.508104870359021\n",
      "New best model found at epoch 59 with validation loss 1.508104920387268\n",
      "Starting Epoch 60\n",
      "1.4994853834311168\n",
      "Validation loss: 1.5058077573776245\n",
      "mse 1.505807784520656\n",
      "New best model found at epoch 60 with validation loss 1.5058077573776245\n",
      "Starting Epoch 61\n",
      "1.4966071943442028\n",
      "Validation loss: 1.503678321838379\n",
      "mse 1.5036783939028169\n",
      "New best model found at epoch 61 with validation loss 1.503678321838379\n",
      "Starting Epoch 62\n",
      "1.4936267683903377\n",
      "Validation loss: 1.5013624429702759\n",
      "mse 1.5013624913533\n",
      "New best model found at epoch 62 with validation loss 1.5013624429702759\n",
      "Starting Epoch 63\n",
      "1.4909296929836273\n",
      "Validation loss: 1.4998890161514282\n",
      "mse 1.4998890061363275\n",
      "New best model found at epoch 63 with validation loss 1.4998890161514282\n",
      "Starting Epoch 64\n",
      "1.4881532241900761\n",
      "Validation loss: 1.4985730648040771\n",
      "mse 1.4985730860999045\n",
      "New best model found at epoch 64 with validation loss 1.4985730648040771\n",
      "Starting Epoch 65\n",
      "1.4858976950248082\n",
      "Validation loss: 1.4957133531570435\n",
      "mse 1.4957132902518964\n",
      "New best model found at epoch 65 with validation loss 1.4957133531570435\n",
      "Starting Epoch 66\n",
      "1.483181968331337\n",
      "Validation loss: 1.4939563274383545\n",
      "mse 1.4939564258496623\n",
      "New best model found at epoch 66 with validation loss 1.4939563274383545\n",
      "Starting Epoch 67\n",
      "1.4805333465337753\n",
      "Validation loss: 1.492229700088501\n",
      "mse 1.4922297207698487\n",
      "New best model found at epoch 67 with validation loss 1.492229700088501\n",
      "Starting Epoch 68\n",
      "1.4783006608486176\n",
      "Validation loss: 1.4899049997329712\n",
      "mse 1.4899051223651554\n",
      "New best model found at epoch 68 with validation loss 1.4899049997329712\n",
      "Starting Epoch 69\n",
      "1.4760246773560841\n",
      "Validation loss: 1.4882656335830688\n",
      "mse 1.488265627527288\n",
      "New best model found at epoch 69 with validation loss 1.4882656335830688\n",
      "Starting Epoch 70\n",
      "1.473598172267278\n",
      "Validation loss: 1.485599160194397\n",
      "mse 1.485599175409897\n",
      "New best model found at epoch 70 with validation loss 1.485599160194397\n",
      "Starting Epoch 71\n",
      "1.4712734371423721\n",
      "Validation loss: 1.4836562871932983\n",
      "mse 1.4836563833944745\n",
      "New best model found at epoch 71 with validation loss 1.4836562871932983\n",
      "Starting Epoch 72\n",
      "1.4691900163888931\n",
      "Validation loss: 1.4820806980133057\n",
      "mse 1.4820806984129156\n",
      "New best model found at epoch 72 with validation loss 1.4820806980133057\n",
      "Starting Epoch 73\n",
      "1.4671219289302826\n",
      "Validation loss: 1.4795585870742798\n",
      "mse 1.479558525261053\n",
      "New best model found at epoch 73 with validation loss 1.4795585870742798\n",
      "Starting Epoch 74\n",
      "1.46490478515625\n",
      "Validation loss: 1.4784337282180786\n",
      "mse 1.4784336834395952\n",
      "New best model found at epoch 74 with validation loss 1.4784337282180786\n",
      "Starting Epoch 75\n",
      "1.4629804740349452\n",
      "Validation loss: 1.476395845413208\n",
      "mse 1.4763958848546372\n",
      "New best model found at epoch 75 with validation loss 1.476395845413208\n",
      "Starting Epoch 76\n",
      "1.4607668668031693\n",
      "Validation loss: 1.475406527519226\n",
      "mse 1.475406548592464\n",
      "New best model found at epoch 76 with validation loss 1.475406527519226\n",
      "Starting Epoch 77\n",
      "1.4589245071013768\n",
      "Validation loss: 1.4730656147003174\n",
      "mse 1.4730656458579514\n",
      "New best model found at epoch 77 with validation loss 1.4730656147003174\n",
      "Starting Epoch 78\n",
      "1.4568620373805363\n",
      "Validation loss: 1.47140371799469\n",
      "mse 1.471403593550295\n",
      "New best model found at epoch 78 with validation loss 1.47140371799469\n",
      "Starting Epoch 79\n",
      "1.4550511538982391\n",
      "Validation loss: 1.4699771404266357\n",
      "mse 1.469977165147197\n",
      "New best model found at epoch 79 with validation loss 1.4699771404266357\n",
      "Starting Epoch 80\n",
      "1.4533455520868301\n",
      "Validation loss: 1.4679123163223267\n",
      "mse 1.4679122893542704\n",
      "New best model found at epoch 80 with validation loss 1.4679123163223267\n",
      "Starting Epoch 81\n",
      "1.4514900197585423\n",
      "Validation loss: 1.4672435522079468\n",
      "mse 1.4672433652654975\n",
      "New best model found at epoch 81 with validation loss 1.4672435522079468\n",
      "Starting Epoch 82\n",
      "1.449718897541364\n",
      "Validation loss: 1.4652695655822754\n",
      "mse 1.4652694965652207\n",
      "New best model found at epoch 82 with validation loss 1.4652695655822754\n",
      "Starting Epoch 83\n",
      "1.4479810297489166\n",
      "Validation loss: 1.4635318517684937\n",
      "mse 1.4635319081570206\n",
      "New best model found at epoch 83 with validation loss 1.4635318517684937\n",
      "Starting Epoch 84\n",
      "1.4463573396205902\n",
      "Validation loss: 1.4618666172027588\n",
      "mse 1.4618667280616322\n",
      "New best model found at epoch 84 with validation loss 1.4618666172027588\n",
      "Starting Epoch 85\n",
      "1.444773222009341\n",
      "Validation loss: 1.460206151008606\n",
      "mse 1.4602060836274986\n",
      "New best model found at epoch 85 with validation loss 1.460206151008606\n",
      "Starting Epoch 86\n",
      "1.4430218636989594\n",
      "Validation loss: 1.4584702253341675\n",
      "mse 1.458470357836566\n",
      "New best model found at epoch 86 with validation loss 1.4584702253341675\n",
      "Starting Epoch 87\n",
      "1.4414536307255428\n",
      "Validation loss: 1.4579055309295654\n",
      "mse 1.4579054934798394\n",
      "New best model found at epoch 87 with validation loss 1.4579055309295654\n",
      "Starting Epoch 88\n",
      "1.4401118258635204\n",
      "Validation loss: 1.456158995628357\n",
      "mse 1.4561589997600417\n",
      "New best model found at epoch 88 with validation loss 1.456158995628357\n",
      "Starting Epoch 89\n",
      "1.4384589617451031\n",
      "Validation loss: 1.4545469284057617\n",
      "mse 1.4545469553625616\n",
      "New best model found at epoch 89 with validation loss 1.4545469284057617\n",
      "Starting Epoch 90\n",
      "1.4370810786883037\n",
      "Validation loss: 1.4530411958694458\n",
      "mse 1.4530411055848382\n",
      "New best model found at epoch 90 with validation loss 1.4530411958694458\n",
      "Starting Epoch 91\n",
      "1.4355030457178752\n",
      "Validation loss: 1.45172119140625\n",
      "mse 1.4517211161335088\n",
      "New best model found at epoch 91 with validation loss 1.45172119140625\n",
      "Starting Epoch 92\n",
      "1.4342424497008324\n",
      "Validation loss: 1.4503569602966309\n",
      "mse 1.450356993911217\n",
      "New best model found at epoch 92 with validation loss 1.4503569602966309\n",
      "Starting Epoch 93\n",
      "1.4327182620763779\n",
      "Validation loss: 1.4491921663284302\n",
      "mse 1.4491920751416476\n",
      "New best model found at epoch 93 with validation loss 1.4491921663284302\n",
      "Starting Epoch 94\n",
      "1.431497720380624\n",
      "Validation loss: 1.447226881980896\n",
      "mse 1.447226840042629\n",
      "New best model found at epoch 94 with validation loss 1.447226881980896\n",
      "Starting Epoch 95\n",
      "1.430031490822633\n",
      "Validation loss: 1.445318341255188\n",
      "mse 1.4453183056820507\n",
      "New best model found at epoch 95 with validation loss 1.445318341255188\n",
      "Starting Epoch 96\n",
      "1.428592378894488\n",
      "Validation loss: 1.4446375370025635\n",
      "mse 1.4446375434768726\n",
      "New best model found at epoch 96 with validation loss 1.4446375370025635\n",
      "Starting Epoch 97\n",
      "1.427356168627739\n",
      "Validation loss: 1.4433037042617798\n",
      "mse 1.443303497839297\n",
      "New best model found at epoch 97 with validation loss 1.4433037042617798\n",
      "Starting Epoch 98\n",
      "1.4260291034976642\n",
      "Validation loss: 1.442439317703247\n",
      "mse 1.4424394098482085\n",
      "New best model found at epoch 98 with validation loss 1.442439317703247\n",
      "Starting Epoch 99\n",
      "1.4247908890247345\n",
      "Validation loss: 1.4410957098007202\n",
      "mse 1.441095672336008\n",
      "New best model found at epoch 99 with validation loss 1.4410957098007202\n",
      "Starting Epoch 100\n",
      "1.42380208025376\n",
      "Validation loss: 1.4397950172424316\n",
      "mse 1.439794968679715\n",
      "New best model found at epoch 100 with validation loss 1.4397950172424316\n",
      "Starting Epoch 101\n",
      "1.4225918278098106\n",
      "Validation loss: 1.4378209114074707\n",
      "mse 1.4378209081509548\n",
      "New best model found at epoch 101 with validation loss 1.4378209114074707\n",
      "Starting Epoch 102\n",
      "1.4212013234694798\n",
      "Validation loss: 1.4370477199554443\n",
      "mse 1.437047749008075\n",
      "New best model found at epoch 102 with validation loss 1.4370477199554443\n",
      "Starting Epoch 103\n",
      "1.420061041911443\n",
      "Validation loss: 1.4360558986663818\n",
      "mse 1.4360558150253302\n",
      "New best model found at epoch 103 with validation loss 1.4360558986663818\n",
      "Starting Epoch 104\n",
      "1.4188918471336365\n",
      "Validation loss: 1.434880018234253\n",
      "mse 1.4348799053033705\n",
      "New best model found at epoch 104 with validation loss 1.434880018234253\n",
      "Starting Epoch 105\n",
      "1.417779803276062\n",
      "Validation loss: 1.4336628913879395\n",
      "mse 1.4336628555793878\n",
      "New best model found at epoch 105 with validation loss 1.4336628913879395\n",
      "Starting Epoch 106\n",
      "1.416770838201046\n",
      "Validation loss: 1.432332992553711\n",
      "mse 1.4323330727525512\n",
      "New best model found at epoch 106 with validation loss 1.432332992553711\n",
      "Starting Epoch 107\n",
      "1.4156169891357422\n",
      "Validation loss: 1.4309062957763672\n",
      "mse 1.430906367799222\n",
      "New best model found at epoch 107 with validation loss 1.4309062957763672\n",
      "Starting Epoch 108\n",
      "1.4144778127471607\n",
      "Validation loss: 1.430101990699768\n",
      "mse 1.430101896314442\n",
      "New best model found at epoch 108 with validation loss 1.430101990699768\n",
      "Starting Epoch 109\n",
      "1.4134910106658936\n",
      "Validation loss: 1.4280849695205688\n",
      "mse 1.4280851346824777\n",
      "New best model found at epoch 109 with validation loss 1.4280849695205688\n",
      "Starting Epoch 110\n",
      "1.4123529170950253\n",
      "Validation loss: 1.4274243116378784\n",
      "mse 1.4274243868837813\n",
      "New best model found at epoch 110 with validation loss 1.4274243116378784\n",
      "Starting Epoch 111\n",
      "1.4111433699727058\n",
      "Validation loss: 1.4274330139160156\n",
      "mse 1.4274330513123359\n",
      "Starting Epoch 112\n",
      "1.4103037764628727\n",
      "Validation loss: 1.42525053024292\n",
      "mse 1.4252506326844911\n",
      "New best model found at epoch 112 with validation loss 1.42525053024292\n",
      "Starting Epoch 113\n",
      "1.4093377913037937\n",
      "Validation loss: 1.4245970249176025\n",
      "mse 1.4245971500912018\n",
      "New best model found at epoch 113 with validation loss 1.4245970249176025\n",
      "Starting Epoch 114\n",
      "1.4081851666172345\n",
      "Validation loss: 1.4227224588394165\n",
      "mse 1.4227223832575144\n",
      "New best model found at epoch 114 with validation loss 1.4227224588394165\n",
      "Starting Epoch 115\n",
      "1.4071836546063423\n",
      "Validation loss: 1.4218308925628662\n",
      "mse 1.4218307972633961\n",
      "New best model found at epoch 115 with validation loss 1.4218308925628662\n",
      "Starting Epoch 116\n",
      "1.4062936902046204\n",
      "Validation loss: 1.4216349124908447\n",
      "mse 1.4216350016709012\n",
      "New best model found at epoch 116 with validation loss 1.4216349124908447\n",
      "Starting Epoch 117\n",
      "1.4053658619523048\n",
      "Validation loss: 1.4199222326278687\n",
      "mse 1.4199220925790867\n",
      "New best model found at epoch 117 with validation loss 1.4199222326278687\n",
      "Starting Epoch 118\n",
      "1.404324581225713\n",
      "Validation loss: 1.4190590381622314\n",
      "mse 1.4190591697630475\n",
      "New best model found at epoch 118 with validation loss 1.4190590381622314\n",
      "Starting Epoch 119\n",
      "1.4034712662299473\n",
      "Validation loss: 1.4176348447799683\n",
      "mse 1.4176348782299277\n",
      "New best model found at epoch 119 with validation loss 1.4176348447799683\n",
      "Starting Epoch 120\n",
      "1.402570699652036\n",
      "Validation loss: 1.4173321723937988\n",
      "mse 1.4173321930487452\n",
      "New best model found at epoch 120 with validation loss 1.4173321723937988\n",
      "Starting Epoch 121\n",
      "1.4015559628605843\n",
      "Validation loss: 1.4157850742340088\n",
      "mse 1.4157850737857087\n",
      "New best model found at epoch 121 with validation loss 1.4157850742340088\n",
      "Starting Epoch 122\n",
      "1.4006890654563904\n",
      "Validation loss: 1.4156465530395508\n",
      "mse 1.4156466502550746\n",
      "New best model found at epoch 122 with validation loss 1.4156465530395508\n",
      "Starting Epoch 123\n",
      "1.3998286972443263\n",
      "Validation loss: 1.4133297204971313\n",
      "mse 1.4133295246647275\n",
      "New best model found at epoch 123 with validation loss 1.4133297204971313\n",
      "Starting Epoch 124\n",
      "1.3987596531709034\n",
      "Validation loss: 1.4127370119094849\n",
      "mse 1.4127371002544502\n",
      "New best model found at epoch 124 with validation loss 1.4127370119094849\n",
      "Starting Epoch 125\n",
      "1.3979120925068855\n",
      "Validation loss: 1.4115252494812012\n",
      "mse 1.411525270186491\n",
      "New best model found at epoch 125 with validation loss 1.4115252494812012\n",
      "Starting Epoch 126\n",
      "1.3970235263307889\n",
      "Validation loss: 1.4107123613357544\n",
      "mse 1.4107123423426755\n",
      "New best model found at epoch 126 with validation loss 1.4107123613357544\n",
      "Starting Epoch 127\n",
      "1.3962190970778465\n",
      "Validation loss: 1.4101511240005493\n",
      "mse 1.4101511861546288\n",
      "New best model found at epoch 127 with validation loss 1.4101511240005493\n",
      "Starting Epoch 128\n",
      "1.3953209047516186\n",
      "Validation loss: 1.4089962244033813\n",
      "mse 1.4089962278929122\n",
      "New best model found at epoch 128 with validation loss 1.4089962244033813\n",
      "Starting Epoch 129\n",
      "1.3943954880038898\n",
      "Validation loss: 1.407746434211731\n",
      "mse 1.4077463800589394\n",
      "New best model found at epoch 129 with validation loss 1.407746434211731\n",
      "Starting Epoch 130\n",
      "1.393456461528937\n",
      "Validation loss: 1.4078267812728882\n",
      "mse 1.4078267327003504\n",
      "Starting Epoch 131\n",
      "1.392804058889548\n",
      "Validation loss: 1.407705545425415\n",
      "mse 1.4077056504837673\n",
      "New best model found at epoch 131 with validation loss 1.407705545425415\n",
      "Starting Epoch 132\n",
      "1.3919764781991641\n",
      "Validation loss: 1.406283974647522\n",
      "mse 1.4062839929522686\n",
      "New best model found at epoch 132 with validation loss 1.406283974647522\n",
      "Starting Epoch 133\n",
      "1.3910589789350827\n",
      "Validation loss: 1.4055101871490479\n",
      "mse 1.4055101295064618\n",
      "New best model found at epoch 133 with validation loss 1.4055101871490479\n",
      "Starting Epoch 134\n",
      "1.3901606599489849\n",
      "Validation loss: 1.4048136472702026\n",
      "mse 1.40481373406491\n",
      "New best model found at epoch 134 with validation loss 1.4048136472702026\n",
      "Starting Epoch 135\n",
      "1.3892902756730716\n",
      "Validation loss: 1.4039071798324585\n",
      "mse 1.403907144047312\n",
      "New best model found at epoch 135 with validation loss 1.4039071798324585\n",
      "Starting Epoch 136\n",
      "1.3885197614630063\n",
      "Validation loss: 1.4030427932739258\n",
      "mse 1.4030427435660513\n",
      "New best model found at epoch 136 with validation loss 1.4030427932739258\n",
      "Starting Epoch 137\n",
      "1.3877653156717618\n",
      "Validation loss: 1.402017593383789\n",
      "mse 1.4020175965708268\n",
      "New best model found at epoch 137 with validation loss 1.402017593383789\n",
      "Starting Epoch 138\n",
      "1.3868974223732948\n",
      "Validation loss: 1.401349663734436\n",
      "mse 1.4013496813048956\n",
      "New best model found at epoch 138 with validation loss 1.401349663734436\n",
      "Starting Epoch 139\n",
      "1.3861965934435527\n",
      "Validation loss: 1.4004931449890137\n",
      "mse 1.400493159267184\n",
      "New best model found at epoch 139 with validation loss 1.4004931449890137\n",
      "Starting Epoch 140\n",
      "1.38541030138731\n",
      "Validation loss: 1.3993644714355469\n",
      "mse 1.3993645431136794\n",
      "New best model found at epoch 140 with validation loss 1.3993644714355469\n",
      "Starting Epoch 141\n",
      "1.384563108285268\n",
      "Validation loss: 1.3993245363235474\n",
      "mse 1.3993246544103357\n",
      "New best model found at epoch 141 with validation loss 1.3993245363235474\n",
      "Starting Epoch 142\n",
      "1.3839326078693073\n",
      "Validation loss: 1.3979148864746094\n",
      "mse 1.3979150182478393\n",
      "New best model found at epoch 142 with validation loss 1.3979148864746094\n",
      "Starting Epoch 143\n",
      "1.3830566977461178\n",
      "Validation loss: 1.397839903831482\n",
      "mse 1.3978397687515545\n",
      "New best model found at epoch 143 with validation loss 1.397839903831482\n",
      "Starting Epoch 144\n",
      "1.3823878665765126\n",
      "Validation loss: 1.3964285850524902\n",
      "mse 1.3964285732837476\n",
      "New best model found at epoch 144 with validation loss 1.3964285850524902\n",
      "Starting Epoch 145\n",
      "1.3818082561095555\n",
      "Validation loss: 1.3959808349609375\n",
      "mse 1.395980898236413\n",
      "New best model found at epoch 145 with validation loss 1.3959808349609375\n",
      "Starting Epoch 146\n",
      "1.3809503118197124\n",
      "Validation loss: 1.3952699899673462\n",
      "mse 1.3952700248177743\n",
      "New best model found at epoch 146 with validation loss 1.3952699899673462\n",
      "Starting Epoch 147\n",
      "1.3803406556447346\n",
      "Validation loss: 1.394970417022705\n",
      "mse 1.3949705371202645\n",
      "New best model found at epoch 147 with validation loss 1.394970417022705\n",
      "Starting Epoch 148\n",
      "1.3797377149264018\n",
      "Validation loss: 1.3945190906524658\n",
      "mse 1.3945190291458465\n",
      "New best model found at epoch 148 with validation loss 1.3945190906524658\n",
      "Starting Epoch 149\n",
      "1.37899353603522\n",
      "Validation loss: 1.3934664726257324\n",
      "mse 1.3934665346018822\n",
      "New best model found at epoch 149 with validation loss 1.3934664726257324\n",
      "Starting Epoch 150\n",
      "1.3784316182136536\n",
      "Validation loss: 1.3928565979003906\n",
      "mse 1.3928565814330083\n",
      "New best model found at epoch 150 with validation loss 1.3928565979003906\n",
      "Starting Epoch 151\n",
      "1.3777737120787303\n",
      "Validation loss: 1.3928884267807007\n",
      "mse 1.392888475427158\n",
      "Starting Epoch 152\n",
      "1.3772329092025757\n",
      "Validation loss: 1.391463041305542\n",
      "mse 1.3914630762514293\n",
      "New best model found at epoch 152 with validation loss 1.391463041305542\n",
      "Starting Epoch 153\n",
      "1.3766851524511974\n",
      "Validation loss: 1.3911222219467163\n",
      "mse 1.3911222535206373\n",
      "New best model found at epoch 153 with validation loss 1.3911222219467163\n",
      "Starting Epoch 154\n",
      "1.3759464472532272\n",
      "Validation loss: 1.3906329870224\n",
      "mse 1.3906329746810415\n",
      "New best model found at epoch 154 with validation loss 1.3906329870224\n",
      "Starting Epoch 155\n",
      "1.3752969255050023\n",
      "Validation loss: 1.3904170989990234\n",
      "mse 1.3904170389250203\n",
      "New best model found at epoch 155 with validation loss 1.3904170989990234\n",
      "Starting Epoch 156\n",
      "1.3748195221026738\n",
      "Validation loss: 1.3893864154815674\n",
      "mse 1.389386325791821\n",
      "New best model found at epoch 156 with validation loss 1.3893864154815674\n",
      "Starting Epoch 157\n",
      "1.3742922345797222\n",
      "Validation loss: 1.3890756368637085\n",
      "mse 1.3890756490834664\n",
      "New best model found at epoch 157 with validation loss 1.3890756368637085\n",
      "Starting Epoch 158\n",
      "1.3736823846896489\n",
      "Validation loss: 1.3881988525390625\n",
      "mse 1.388198798283713\n",
      "New best model found at epoch 158 with validation loss 1.3881988525390625\n",
      "Starting Epoch 159\n",
      "1.3730566675464313\n",
      "Validation loss: 1.388893723487854\n",
      "mse 1.388893638333633\n",
      "Starting Epoch 160\n",
      "1.3725155393282573\n",
      "Validation loss: 1.3865922689437866\n",
      "mse 1.3865922192051292\n",
      "New best model found at epoch 160 with validation loss 1.3865922689437866\n",
      "Starting Epoch 161\n",
      "1.3719242935379345\n",
      "Validation loss: 1.3863465785980225\n",
      "mse 1.3863465203829661\n",
      "New best model found at epoch 161 with validation loss 1.3863465785980225\n",
      "Starting Epoch 162\n",
      "1.3713746642072995\n",
      "Validation loss: 1.385774850845337\n",
      "mse 1.3857747939537013\n",
      "New best model found at epoch 162 with validation loss 1.385774850845337\n",
      "Starting Epoch 163\n",
      "1.370757890244325\n",
      "Validation loss: 1.3861401081085205\n",
      "mse 1.38614015609133\n",
      "Starting Epoch 164\n",
      "1.3701455270250638\n",
      "Validation loss: 1.3848122358322144\n",
      "mse 1.3848120793093552\n",
      "New best model found at epoch 164 with validation loss 1.3848122358322144\n",
      "Starting Epoch 165\n",
      "1.3695193479458492\n",
      "Validation loss: 1.3845442533493042\n",
      "mse 1.3845442507730046\n",
      "New best model found at epoch 165 with validation loss 1.3845442533493042\n",
      "Starting Epoch 166\n",
      "1.3689420123895009\n",
      "Validation loss: 1.383963704109192\n",
      "mse 1.383963638253561\n",
      "New best model found at epoch 166 with validation loss 1.383963704109192\n",
      "Starting Epoch 167\n",
      "1.3682229444384575\n",
      "Validation loss: 1.3841909170150757\n",
      "mse 1.384190971778584\n",
      "Starting Epoch 168\n",
      "1.367851843436559\n",
      "Validation loss: 1.3828928470611572\n",
      "mse 1.3828926675504059\n",
      "New best model found at epoch 168 with validation loss 1.3828928470611572\n",
      "Starting Epoch 169\n",
      "1.3671893899639447\n",
      "Validation loss: 1.3828896284103394\n",
      "mse 1.382889676192001\n",
      "New best model found at epoch 169 with validation loss 1.3828896284103394\n",
      "Starting Epoch 170\n",
      "1.3665605435768764\n",
      "Validation loss: 1.3818259239196777\n",
      "mse 1.3818257809780554\n",
      "New best model found at epoch 170 with validation loss 1.3818259239196777\n",
      "Starting Epoch 171\n",
      "1.3660299902160962\n",
      "Validation loss: 1.381235122680664\n",
      "mse 1.3812351067655695\n",
      "New best model found at epoch 171 with validation loss 1.381235122680664\n",
      "Starting Epoch 172\n",
      "1.3655636608600616\n",
      "Validation loss: 1.3813632726669312\n",
      "mse 1.3813634066846352\n",
      "Starting Epoch 173\n",
      "1.3650471866130829\n",
      "Validation loss: 1.3807824850082397\n",
      "mse 1.3807824758493292\n",
      "New best model found at epoch 173 with validation loss 1.3807824850082397\n",
      "Starting Epoch 174\n",
      "1.3643881976604462\n",
      "Validation loss: 1.37971830368042\n",
      "mse 1.3797182739187621\n",
      "New best model found at epoch 174 with validation loss 1.37971830368042\n",
      "Starting Epoch 175\n",
      "1.3638899152477582\n",
      "Validation loss: 1.3798996210098267\n",
      "mse 1.3798995952572777\n",
      "Starting Epoch 176\n",
      "1.3633705427249272\n",
      "Validation loss: 1.379550814628601\n",
      "mse 1.3795508199626685\n",
      "New best model found at epoch 176 with validation loss 1.379550814628601\n",
      "Starting Epoch 177\n",
      "1.3628449166814487\n",
      "Validation loss: 1.3779363632202148\n",
      "mse 1.3779362881263861\n",
      "New best model found at epoch 177 with validation loss 1.3779363632202148\n",
      "Starting Epoch 178\n",
      "1.3624265591303508\n",
      "Validation loss: 1.3782265186309814\n",
      "mse 1.3782265642373914\n",
      "Starting Epoch 179\n",
      "1.3617647637923558\n",
      "Validation loss: 1.3777068853378296\n",
      "mse 1.3777069143417244\n",
      "New best model found at epoch 179 with validation loss 1.3777068853378296\n",
      "Starting Epoch 180\n",
      "1.3613034437100093\n",
      "Validation loss: 1.3770772218704224\n",
      "mse 1.377077155412537\n",
      "New best model found at epoch 180 with validation loss 1.3770772218704224\n",
      "Starting Epoch 181\n",
      "1.3608775287866592\n",
      "Validation loss: 1.3769776821136475\n",
      "mse 1.376977633705618\n",
      "New best model found at epoch 181 with validation loss 1.3769776821136475\n",
      "Starting Epoch 182\n",
      "1.360456796983878\n",
      "Validation loss: 1.3759578466415405\n",
      "mse 1.375957738887562\n",
      "New best model found at epoch 182 with validation loss 1.3759578466415405\n",
      "Starting Epoch 183\n",
      "1.3598975464701653\n",
      "Validation loss: 1.3749895095825195\n",
      "mse 1.3749895193075843\n",
      "New best model found at epoch 183 with validation loss 1.3749895095825195\n",
      "Starting Epoch 184\n",
      "1.359405701359113\n",
      "Validation loss: 1.3748725652694702\n",
      "mse 1.3748725364272176\n",
      "New best model found at epoch 184 with validation loss 1.3748725652694702\n",
      "Starting Epoch 185\n",
      "1.3589104240139325\n",
      "Validation loss: 1.3744945526123047\n",
      "mse 1.374494532704421\n",
      "New best model found at epoch 185 with validation loss 1.3744945526123047\n",
      "Starting Epoch 186\n",
      "1.3585086986422539\n",
      "Validation loss: 1.374096155166626\n",
      "mse 1.3740962585256182\n",
      "New best model found at epoch 186 with validation loss 1.374096155166626\n",
      "Starting Epoch 187\n",
      "1.3579807231823604\n",
      "Validation loss: 1.3737308979034424\n",
      "mse 1.3737308817591762\n",
      "New best model found at epoch 187 with validation loss 1.3737308979034424\n",
      "Starting Epoch 188\n",
      "1.3575024058421452\n",
      "Validation loss: 1.373106598854065\n",
      "mse 1.373106526462127\n",
      "New best model found at epoch 188 with validation loss 1.373106598854065\n",
      "Starting Epoch 189\n",
      "1.3572017525633175\n",
      "Validation loss: 1.3725908994674683\n",
      "mse 1.3725909063210917\n",
      "New best model found at epoch 189 with validation loss 1.3725908994674683\n",
      "Starting Epoch 190\n",
      "1.356630578637123\n",
      "Validation loss: 1.3725249767303467\n",
      "mse 1.3725248233045522\n",
      "New best model found at epoch 190 with validation loss 1.3725249767303467\n",
      "Starting Epoch 191\n",
      "1.3562627732753754\n",
      "Validation loss: 1.3724138736724854\n",
      "mse 1.3724139322520323\n",
      "New best model found at epoch 191 with validation loss 1.3724138736724854\n",
      "Starting Epoch 192\n",
      "1.3558850288391113\n",
      "Validation loss: 1.371691346168518\n",
      "mse 1.371691242093066\n",
      "New best model found at epoch 192 with validation loss 1.371691346168518\n",
      "Starting Epoch 193\n",
      "1.3554735109210014\n",
      "Validation loss: 1.3711860179901123\n",
      "mse 1.371186056935169\n",
      "New best model found at epoch 193 with validation loss 1.3711860179901123\n",
      "Starting Epoch 194\n",
      "1.3549761672814686\n",
      "Validation loss: 1.3708715438842773\n",
      "mse 1.3708717539716921\n",
      "New best model found at epoch 194 with validation loss 1.3708715438842773\n",
      "Starting Epoch 195\n",
      "1.3546240826447804\n",
      "Validation loss: 1.3708637952804565\n",
      "mse 1.3708638394510646\n",
      "New best model found at epoch 195 with validation loss 1.3708637952804565\n",
      "Starting Epoch 196\n",
      "1.3540993928909302\n",
      "Validation loss: 1.3710272312164307\n",
      "mse 1.3710272779197683\n",
      "Starting Epoch 197\n",
      "1.3536563167969387\n",
      "Validation loss: 1.3706953525543213\n",
      "mse 1.3706954016915447\n",
      "New best model found at epoch 197 with validation loss 1.3706953525543213\n",
      "Starting Epoch 198\n",
      "1.353339523077011\n",
      "Validation loss: 1.3691818714141846\n",
      "mse 1.3691817649168556\n",
      "New best model found at epoch 198 with validation loss 1.3691818714141846\n",
      "Starting Epoch 199\n",
      "1.352951057255268\n",
      "Validation loss: 1.369197130203247\n",
      "mse 1.3691970359929304\n",
      "Starting Epoch 200\n",
      "1.3525458723306656\n",
      "Validation loss: 1.368567943572998\n",
      "mse 1.3685680633812614\n",
      "New best model found at epoch 200 with validation loss 1.368567943572998\n",
      "Starting Epoch 201\n",
      "1.3521678547064464\n",
      "Validation loss: 1.3686496019363403\n",
      "mse 1.3686495532784175\n",
      "Starting Epoch 202\n",
      "1.3515914032856624\n",
      "Validation loss: 1.3690898418426514\n",
      "mse 1.3690898004218484\n",
      "Starting Epoch 203\n",
      "1.3513802240292232\n",
      "Validation loss: 1.3677091598510742\n",
      "mse 1.3677091942609414\n",
      "New best model found at epoch 203 with validation loss 1.3677091598510742\n",
      "Starting Epoch 204\n",
      "1.3508712251981099\n",
      "Validation loss: 1.3682188987731934\n",
      "mse 1.3682188694025468\n",
      "Starting Epoch 205\n",
      "1.3504376138250034\n",
      "Validation loss: 1.367671251296997\n",
      "mse 1.3676711099196108\n",
      "New best model found at epoch 205 with validation loss 1.367671251296997\n",
      "Starting Epoch 206\n",
      "1.3501302649577458\n",
      "Validation loss: 1.3662917613983154\n",
      "mse 1.3662918243785813\n",
      "New best model found at epoch 206 with validation loss 1.3662917613983154\n",
      "Starting Epoch 207\n",
      "1.3497575024763744\n",
      "Validation loss: 1.366055965423584\n",
      "mse 1.3660560679027607\n",
      "New best model found at epoch 207 with validation loss 1.366055965423584\n",
      "Starting Epoch 208\n",
      "1.3492755492528279\n",
      "Validation loss: 1.3664551973342896\n",
      "mse 1.3664552051599812\n",
      "Starting Epoch 209\n",
      "1.3489418476819992\n",
      "Validation loss: 1.3655537366867065\n",
      "mse 1.3655537420796255\n",
      "New best model found at epoch 209 with validation loss 1.3655537366867065\n",
      "Starting Epoch 210\n",
      "1.3484720165530841\n",
      "Validation loss: 1.3656412363052368\n",
      "mse 1.3656411808174356\n",
      "Starting Epoch 211\n",
      "1.3480108231306076\n",
      "Validation loss: 1.365236759185791\n",
      "mse 1.3652367647440156\n",
      "New best model found at epoch 211 with validation loss 1.365236759185791\n",
      "Starting Epoch 212\n",
      "1.3478623653451602\n",
      "Validation loss: 1.3639851808547974\n",
      "mse 1.3639851761601385\n",
      "New best model found at epoch 212 with validation loss 1.3639851808547974\n",
      "Starting Epoch 213\n",
      "1.3474405830105145\n",
      "Validation loss: 1.3636974096298218\n",
      "mse 1.3636973743876704\n",
      "New best model found at epoch 213 with validation loss 1.3636974096298218\n",
      "Starting Epoch 214\n",
      "1.3469659760594368\n",
      "Validation loss: 1.363532304763794\n",
      "mse 1.3635322996844512\n",
      "New best model found at epoch 214 with validation loss 1.363532304763794\n",
      "Starting Epoch 215\n",
      "1.3466092695792515\n",
      "Validation loss: 1.363419771194458\n",
      "mse 1.3634198227507637\n",
      "New best model found at epoch 215 with validation loss 1.363419771194458\n",
      "Starting Epoch 216\n",
      "1.3461940288543701\n",
      "Validation loss: 1.3638533353805542\n",
      "mse 1.3638533254946348\n",
      "Starting Epoch 217\n",
      "1.3460122893253963\n",
      "Validation loss: 1.3622153997421265\n",
      "mse 1.362215414049953\n",
      "New best model found at epoch 217 with validation loss 1.3622153997421265\n",
      "Starting Epoch 218\n",
      "1.3455052350958188\n",
      "Validation loss: 1.3620818853378296\n",
      "mse 1.3620818423754233\n",
      "New best model found at epoch 218 with validation loss 1.3620818853378296\n",
      "Starting Epoch 219\n",
      "1.3450678040583928\n",
      "Validation loss: 1.362273097038269\n",
      "mse 1.3622731008166753\n",
      "Starting Epoch 220\n",
      "1.3446265334884326\n",
      "Validation loss: 1.362076759338379\n",
      "mse 1.3620769002228754\n",
      "New best model found at epoch 220 with validation loss 1.362076759338379\n",
      "Starting Epoch 221\n",
      "1.344471126794815\n",
      "Validation loss: 1.360647201538086\n",
      "mse 1.3606472487020638\n",
      "New best model found at epoch 221 with validation loss 1.360647201538086\n",
      "Starting Epoch 222\n",
      "1.3441536923249562\n",
      "Validation loss: 1.3608864545822144\n",
      "mse 1.3608865221730775\n",
      "Starting Epoch 223\n",
      "1.3437615483999252\n",
      "Validation loss: 1.3608344793319702\n",
      "mse 1.3608345741111563\n",
      "Starting Epoch 224\n",
      "1.343429910639922\n",
      "Validation loss: 1.3602447509765625\n",
      "mse 1.3602446462981705\n",
      "New best model found at epoch 224 with validation loss 1.3602447509765625\n",
      "Starting Epoch 225\n",
      "1.34298491726319\n",
      "Validation loss: 1.3608464002609253\n",
      "mse 1.3608463851449693\n",
      "Starting Epoch 226\n",
      "1.3427832499146461\n",
      "Validation loss: 1.3593405485153198\n",
      "mse 1.3593405912454315\n",
      "New best model found at epoch 226 with validation loss 1.3593405485153198\n",
      "Starting Epoch 227\n",
      "1.3424333358804386\n",
      "Validation loss: 1.360033631324768\n",
      "mse 1.3600337928105248\n",
      "Starting Epoch 228\n",
      "1.342119611799717\n",
      "Validation loss: 1.359359860420227\n",
      "mse 1.3593599534617913\n",
      "Starting Epoch 229\n",
      "1.3418924808502197\n",
      "Validation loss: 1.358715534210205\n",
      "mse 1.3587154774888899\n",
      "New best model found at epoch 229 with validation loss 1.358715534210205\n",
      "Starting Epoch 230\n",
      "1.3415399367610614\n",
      "Validation loss: 1.3582288026809692\n",
      "mse 1.3582288348627523\n",
      "New best model found at epoch 230 with validation loss 1.3582288026809692\n",
      "Starting Epoch 231\n",
      "1.3411962042252223\n",
      "Validation loss: 1.3581278324127197\n",
      "mse 1.3581278738014066\n",
      "New best model found at epoch 231 with validation loss 1.3581278324127197\n",
      "Starting Epoch 232\n",
      "1.3408786728978157\n",
      "Validation loss: 1.3585890531539917\n",
      "mse 1.3585891725384198\n",
      "Starting Epoch 233\n",
      "1.3404974391063054\n",
      "Validation loss: 1.3575823307037354\n",
      "mse 1.3575823837211032\n",
      "New best model found at epoch 233 with validation loss 1.3575823307037354\n",
      "Starting Epoch 234\n",
      "1.3402820577224095\n",
      "Validation loss: 1.3579155206680298\n",
      "mse 1.3579156001439248\n",
      "Starting Epoch 235\n",
      "1.3400409718354542\n",
      "Validation loss: 1.3568416833877563\n",
      "mse 1.356841618250972\n",
      "New best model found at epoch 235 with validation loss 1.3568416833877563\n",
      "Starting Epoch 236\n",
      "1.3395504305760066\n",
      "Validation loss: 1.3566733598709106\n",
      "mse 1.356673409915335\n",
      "New best model found at epoch 236 with validation loss 1.3566733598709106\n",
      "Starting Epoch 237\n",
      "1.3393038834134738\n",
      "Validation loss: 1.357071042060852\n",
      "mse 1.3570710048497605\n",
      "Starting Epoch 238\n",
      "1.3389418224493663\n",
      "Validation loss: 1.3567986488342285\n",
      "mse 1.3567986357659862\n",
      "Starting Epoch 239\n",
      "1.3386063625415165\n",
      "Validation loss: 1.3564506769180298\n",
      "mse 1.356450850605824\n",
      "New best model found at epoch 239 with validation loss 1.3564506769180298\n",
      "Starting Epoch 240\n",
      "1.3382935325304668\n",
      "Validation loss: 1.355376124382019\n",
      "mse 1.3553761379069025\n",
      "New best model found at epoch 240 with validation loss 1.355376124382019\n",
      "Starting Epoch 241\n",
      "1.3379527280728023\n",
      "Validation loss: 1.3549267053604126\n",
      "mse 1.3549267065076285\n",
      "New best model found at epoch 241 with validation loss 1.3549267053604126\n",
      "Starting Epoch 242\n",
      "1.337886966764927\n",
      "Validation loss: 1.3552463054656982\n",
      "mse 1.3552463265488786\n",
      "Starting Epoch 243\n",
      "1.3374522502223651\n",
      "Validation loss: 1.3552778959274292\n",
      "mse 1.3552779806090542\n",
      "Starting Epoch 244\n",
      "1.3372336129347484\n",
      "Validation loss: 1.3540781736373901\n",
      "mse 1.3540782122685566\n",
      "New best model found at epoch 244 with validation loss 1.3540781736373901\n",
      "Starting Epoch 245\n",
      "1.3367479642232258\n",
      "Validation loss: 1.3550152778625488\n",
      "mse 1.3550152725482416\n",
      "Starting Epoch 246\n",
      "1.3365434631705284\n",
      "Validation loss: 1.3542603254318237\n",
      "mse 1.354260180392431\n",
      "Starting Epoch 247\n",
      "1.336326725780964\n",
      "Validation loss: 1.3533062934875488\n",
      "mse 1.3533062498377693\n",
      "New best model found at epoch 247 with validation loss 1.3533062934875488\n",
      "Starting Epoch 248\n",
      "1.335941384236018\n",
      "Validation loss: 1.3544288873672485\n",
      "mse 1.3544288397297903\n",
      "Starting Epoch 249\n",
      "1.3357091297705967\n",
      "Validation loss: 1.353580117225647\n",
      "mse 1.3535801158746825\n",
      "Starting Epoch 250\n",
      "1.3354049449165661\n",
      "Validation loss: 1.3531169891357422\n",
      "mse 1.35311703975879\n",
      "New best model found at epoch 250 with validation loss 1.3531169891357422\n",
      "Starting Epoch 251\n",
      "1.3351577743887901\n",
      "Validation loss: 1.3521113395690918\n",
      "mse 1.3521112991609405\n",
      "New best model found at epoch 251 with validation loss 1.3521113395690918\n",
      "Starting Epoch 252\n",
      "1.3347376063466072\n",
      "Validation loss: 1.35213303565979\n",
      "mse 1.3521329451082529\n",
      "Starting Epoch 253\n",
      "1.33440105120341\n",
      "Validation loss: 1.351456642150879\n",
      "mse 1.3514566227752924\n",
      "New best model found at epoch 253 with validation loss 1.351456642150879\n",
      "Starting Epoch 254\n",
      "1.3341682329773903\n",
      "Validation loss: 1.3524643182754517\n",
      "mse 1.3524643355734272\n",
      "Starting Epoch 255\n",
      "1.3339285229643185\n",
      "Validation loss: 1.3512042760849\n",
      "mse 1.351204242161822\n",
      "New best model found at epoch 255 with validation loss 1.3512042760849\n",
      "Starting Epoch 256\n",
      "1.3336323127150536\n",
      "Validation loss: 1.3509498834609985\n",
      "mse 1.350949860666688\n",
      "New best model found at epoch 256 with validation loss 1.3509498834609985\n",
      "Starting Epoch 257\n",
      "1.3333195274074872\n",
      "Validation loss: 1.352344274520874\n",
      "mse 1.3523442168200546\n",
      "Starting Epoch 258\n",
      "1.3332218478123348\n",
      "Validation loss: 1.350947380065918\n",
      "mse 1.3509473564062902\n",
      "New best model found at epoch 258 with validation loss 1.350947380065918\n",
      "Starting Epoch 259\n",
      "1.3328231945633888\n",
      "Validation loss: 1.3512810468673706\n",
      "mse 1.3512810445082502\n",
      "Starting Epoch 260\n",
      "1.3325224816799164\n",
      "Validation loss: 1.3509260416030884\n",
      "mse 1.350925995171607\n",
      "New best model found at epoch 260 with validation loss 1.3509260416030884\n",
      "Starting Epoch 261\n",
      "1.3322642321387927\n",
      "Validation loss: 1.3501393795013428\n",
      "mse 1.3501394030072023\n",
      "New best model found at epoch 261 with validation loss 1.3501393795013428\n",
      "Starting Epoch 262\n",
      "1.3319081937273343\n",
      "Validation loss: 1.3497570753097534\n",
      "mse 1.3497569909331735\n",
      "New best model found at epoch 262 with validation loss 1.3497570753097534\n",
      "Starting Epoch 263\n",
      "1.3318412279089291\n",
      "Validation loss: 1.3501150608062744\n",
      "mse 1.3501150097769132\n",
      "Starting Epoch 264\n",
      "1.3314697618285816\n",
      "Validation loss: 1.3494333028793335\n",
      "mse 1.3494332754506697\n",
      "New best model found at epoch 264 with validation loss 1.3494333028793335\n",
      "Starting Epoch 265\n",
      "1.3312697038054466\n",
      "Validation loss: 1.3493887186050415\n",
      "mse 1.3493887259156094\n",
      "New best model found at epoch 265 with validation loss 1.3493887186050415\n",
      "Starting Epoch 266\n",
      "1.3309846619764965\n",
      "Validation loss: 1.3497862815856934\n",
      "mse 1.3497862547087451\n",
      "Starting Epoch 267\n",
      "1.3308071220914524\n",
      "Validation loss: 1.3485370874404907\n",
      "mse 1.348537218804404\n",
      "New best model found at epoch 267 with validation loss 1.3485370874404907\n",
      "Starting Epoch 268\n",
      "1.3305259396632512\n",
      "Validation loss: 1.3501871824264526\n",
      "mse 1.3501870894826649\n",
      "Starting Epoch 269\n",
      "1.330331951379776\n",
      "Validation loss: 1.3478386402130127\n",
      "mse 1.3478386574590702\n",
      "New best model found at epoch 269 with validation loss 1.3478386402130127\n",
      "Starting Epoch 270\n",
      "1.329904745022456\n",
      "Validation loss: 1.3489426374435425\n",
      "mse 1.348942727899501\n",
      "Starting Epoch 271\n",
      "1.3297903488079708\n",
      "Validation loss: 1.3495193719863892\n",
      "mse 1.3495193493575932\n",
      "Starting Epoch 272\n",
      "1.3296687776843708\n",
      "Validation loss: 1.3470971584320068\n",
      "mse 1.3470972021413348\n",
      "New best model found at epoch 272 with validation loss 1.3470971584320068\n",
      "Starting Epoch 273\n",
      "1.329108402132988\n",
      "Validation loss: 1.3467477560043335\n",
      "mse 1.3467477510460968\n",
      "New best model found at epoch 273 with validation loss 1.3467477560043335\n",
      "Starting Epoch 274\n",
      "1.328948934872945\n",
      "Validation loss: 1.346856713294983\n",
      "mse 1.346856827156998\n",
      "Starting Epoch 275\n",
      "1.328736315170924\n",
      "Validation loss: 1.3466752767562866\n",
      "mse 1.3466753382942447\n",
      "New best model found at epoch 275 with validation loss 1.3466752767562866\n",
      "Starting Epoch 276\n",
      "1.3283968244989712\n",
      "Validation loss: 1.346750259399414\n",
      "mse 1.346750327180532\n",
      "Starting Epoch 277\n",
      "1.328235258658727\n",
      "Validation loss: 1.3474693298339844\n",
      "mse 1.3474692486094497\n",
      "Starting Epoch 278\n",
      "1.3280872330069542\n",
      "Validation loss: 1.346049189567566\n",
      "mse 1.3460492522127636\n",
      "New best model found at epoch 278 with validation loss 1.346049189567566\n",
      "Starting Epoch 279\n",
      "1.3276920666297276\n",
      "Validation loss: 1.3468421697616577\n",
      "mse 1.3468421455931527\n",
      "Starting Epoch 280\n",
      "1.327535664041837\n",
      "Validation loss: 1.3462315797805786\n",
      "mse 1.3462315898612482\n",
      "Starting Epoch 281\n",
      "1.3272563914457958\n",
      "Validation loss: 1.3450100421905518\n",
      "mse 1.345010115147451\n",
      "New best model found at epoch 281 with validation loss 1.3450100421905518\n",
      "Starting Epoch 282\n",
      "1.3269908626874287\n",
      "Validation loss: 1.3444160223007202\n",
      "mse 1.3444159449631654\n",
      "New best model found at epoch 282 with validation loss 1.3444160223007202\n",
      "Starting Epoch 283\n",
      "1.3267248769601185\n",
      "Validation loss: 1.3443354368209839\n",
      "mse 1.3443354650755044\n",
      "New best model found at epoch 283 with validation loss 1.3443354368209839\n",
      "Starting Epoch 284\n",
      "1.3264315327008565\n",
      "Validation loss: 1.344387173652649\n",
      "mse 1.3443871778777674\n",
      "Starting Epoch 285\n",
      "1.326110194126765\n",
      "Validation loss: 1.3432767391204834\n",
      "mse 1.3432766687286557\n",
      "New best model found at epoch 285 with validation loss 1.3432767391204834\n",
      "Starting Epoch 286\n",
      "1.3256899068752925\n",
      "Validation loss: 1.342872977256775\n",
      "mse 1.342873126459848\n",
      "New best model found at epoch 286 with validation loss 1.342872977256775\n",
      "Starting Epoch 287\n",
      "1.3253671204050381\n",
      "Validation loss: 1.342800259590149\n",
      "mse 1.342800316135149\n",
      "New best model found at epoch 287 with validation loss 1.342800259590149\n",
      "Starting Epoch 288\n",
      "1.32509912053744\n",
      "Validation loss: 1.342624545097351\n",
      "mse 1.3426245285139577\n",
      "New best model found at epoch 288 with validation loss 1.342624545097351\n",
      "Starting Epoch 289\n",
      "1.3246355801820755\n",
      "Validation loss: 1.3416361808776855\n",
      "mse 1.3416361967376433\n",
      "New best model found at epoch 289 with validation loss 1.3416361808776855\n",
      "Starting Epoch 290\n",
      "1.3243310327331226\n",
      "Validation loss: 1.3412095308303833\n",
      "mse 1.3412095314282635\n",
      "New best model found at epoch 290 with validation loss 1.3412095308303833\n",
      "Starting Epoch 291\n",
      "1.3240342264374096\n",
      "Validation loss: 1.341689109802246\n",
      "mse 1.3416890617910493\n",
      "Starting Epoch 292\n",
      "1.3238669683535893\n",
      "Validation loss: 1.3407809734344482\n",
      "mse 1.3407808904542144\n",
      "New best model found at epoch 292 with validation loss 1.3407809734344482\n",
      "Starting Epoch 293\n",
      "1.323536182443301\n",
      "Validation loss: 1.3405392169952393\n",
      "mse 1.3405391893294836\n",
      "New best model found at epoch 293 with validation loss 1.3405392169952393\n",
      "Starting Epoch 294\n",
      "1.3233131815989811\n",
      "Validation loss: 1.3402268886566162\n",
      "mse 1.340226755584036\n",
      "New best model found at epoch 294 with validation loss 1.3402268886566162\n",
      "Starting Epoch 295\n",
      "1.323047399520874\n",
      "Validation loss: 1.3410253524780273\n",
      "mse 1.3410254536824766\n",
      "Starting Epoch 296\n",
      "1.322741337120533\n",
      "Validation loss: 1.3405425548553467\n",
      "mse 1.3405425286823256\n",
      "Starting Epoch 297\n",
      "1.3225616216659546\n",
      "Validation loss: 1.3399624824523926\n",
      "mse 1.3399625680089606\n",
      "New best model found at epoch 297 with validation loss 1.3399624824523926\n",
      "Starting Epoch 298\n",
      "1.3223300899068515\n",
      "Validation loss: 1.3403297662734985\n",
      "mse 1.3403298550941989\n",
      "Starting Epoch 299\n",
      "1.322091336051623\n",
      "Validation loss: 1.3400613069534302\n",
      "mse 1.3400614336634638\n",
      "Starting Epoch 300\n",
      "1.321844960252444\n",
      "Validation loss: 1.340169906616211\n",
      "mse 1.3401698158341004\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-q25: 7-80-50-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c8033",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 6\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.75-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "6f433f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "e74a2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,10,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "8544c157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'q75(container counts)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "398817cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "b42e79c6-e7e3-49a0-8adc-89b9559c3d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.6505762288967767\n",
      "Validation loss: 1.9970009326934814\n",
      "mse 1.9970011007250212\n",
      "New best model found at epoch 1 with validation loss 1.9970009326934814\n",
      "Starting Epoch 2\n",
      "1.9895037561655045\n",
      "Validation loss: 1.838874101638794\n",
      "mse 1.8388740857586703\n",
      "New best model found at epoch 2 with validation loss 1.838874101638794\n",
      "Starting Epoch 3\n",
      "1.8970640897750854\n",
      "Validation loss: 1.7704932689666748\n",
      "mse 1.7704931601826246\n",
      "New best model found at epoch 3 with validation loss 1.7704932689666748\n",
      "Starting Epoch 4\n",
      "1.8466062247753143\n",
      "Validation loss: 1.7316519021987915\n",
      "mse 1.7316520996361628\n",
      "New best model found at epoch 4 with validation loss 1.7316519021987915\n",
      "Starting Epoch 5\n",
      "1.8121842096249263\n",
      "Validation loss: 1.7074283361434937\n",
      "mse 1.7074282321693797\n",
      "New best model found at epoch 5 with validation loss 1.7074283361434937\n",
      "Starting Epoch 6\n",
      "1.784238522251447\n",
      "Validation loss: 1.686314344406128\n",
      "mse 1.6863141568387447\n",
      "New best model found at epoch 6 with validation loss 1.686314344406128\n",
      "Starting Epoch 7\n",
      "1.7609959443410237\n",
      "Validation loss: 1.6666380167007446\n",
      "mse 1.6666380406327168\n",
      "New best model found at epoch 7 with validation loss 1.6666380167007446\n",
      "Starting Epoch 8\n",
      "1.7418700456619263\n",
      "Validation loss: 1.6528184413909912\n",
      "mse 1.6528183588235719\n",
      "New best model found at epoch 8 with validation loss 1.6528184413909912\n",
      "Starting Epoch 9\n",
      "1.7256568570931752\n",
      "Validation loss: 1.638776421546936\n",
      "mse 1.6387764837013314\n",
      "New best model found at epoch 9 with validation loss 1.638776421546936\n",
      "Starting Epoch 10\n",
      "1.7108896126349766\n",
      "Validation loss: 1.6279067993164062\n",
      "mse 1.6279068018572596\n",
      "New best model found at epoch 10 with validation loss 1.6279067993164062\n",
      "Starting Epoch 11\n",
      "1.6971326520045598\n",
      "Validation loss: 1.6157437562942505\n",
      "mse 1.6157436741639468\n",
      "New best model found at epoch 11 with validation loss 1.6157437562942505\n",
      "Starting Epoch 12\n",
      "1.6836815178394318\n",
      "Validation loss: 1.6048065423965454\n",
      "mse 1.6048065957315354\n",
      "New best model found at epoch 12 with validation loss 1.6048065423965454\n",
      "Starting Epoch 13\n",
      "1.6705177028973897\n",
      "Validation loss: 1.5944032669067383\n",
      "mse 1.5944031843722473\n",
      "New best model found at epoch 13 with validation loss 1.5944032669067383\n",
      "Starting Epoch 14\n",
      "1.6591006716092427\n",
      "Validation loss: 1.5855131149291992\n",
      "mse 1.5855133027611477\n",
      "New best model found at epoch 14 with validation loss 1.5855131149291992\n",
      "Starting Epoch 15\n",
      "1.6485165258248646\n",
      "Validation loss: 1.5773751735687256\n",
      "mse 1.5773752293464716\n",
      "New best model found at epoch 15 with validation loss 1.5773751735687256\n",
      "Starting Epoch 16\n",
      "1.6381191859642665\n",
      "Validation loss: 1.5699093341827393\n",
      "mse 1.5699092238359056\n",
      "New best model found at epoch 16 with validation loss 1.5699093341827393\n",
      "Starting Epoch 17\n",
      "1.6282705465952556\n",
      "Validation loss: 1.5612075328826904\n",
      "mse 1.5612075331255453\n",
      "New best model found at epoch 17 with validation loss 1.5612075328826904\n",
      "Starting Epoch 18\n",
      "1.6187559515237808\n",
      "Validation loss: 1.5546865463256836\n",
      "mse 1.5546865944039459\n",
      "New best model found at epoch 18 with validation loss 1.5546865463256836\n",
      "Starting Epoch 19\n",
      "1.6096828877925873\n",
      "Validation loss: 1.5477579832077026\n",
      "mse 1.5477580539253744\n",
      "New best model found at epoch 19 with validation loss 1.5477579832077026\n",
      "Starting Epoch 20\n",
      "1.6009461532036464\n",
      "Validation loss: 1.5402370691299438\n",
      "mse 1.5402369898812105\n",
      "New best model found at epoch 20 with validation loss 1.5402370691299438\n",
      "Starting Epoch 21\n",
      "1.592255676786105\n",
      "Validation loss: 1.535211443901062\n",
      "mse 1.5352114038681914\n",
      "New best model found at epoch 21 with validation loss 1.535211443901062\n",
      "Starting Epoch 22\n",
      "1.5839840769767761\n",
      "Validation loss: 1.5272771120071411\n",
      "mse 1.5272770544295837\n",
      "New best model found at epoch 22 with validation loss 1.5272771120071411\n",
      "Starting Epoch 23\n",
      "1.5757086823383968\n",
      "Validation loss: 1.520013689994812\n",
      "mse 1.520013774190321\n",
      "New best model found at epoch 23 with validation loss 1.520013689994812\n",
      "Starting Epoch 24\n",
      "1.5673610617717106\n",
      "Validation loss: 1.514204978942871\n",
      "mse 1.51420494465457\n",
      "New best model found at epoch 24 with validation loss 1.514204978942871\n",
      "Starting Epoch 25\n",
      "1.5601259221633275\n",
      "Validation loss: 1.5093759298324585\n",
      "mse 1.5093759506262043\n",
      "New best model found at epoch 25 with validation loss 1.5093759298324585\n",
      "Starting Epoch 26\n",
      "1.5526281694571178\n",
      "Validation loss: 1.5040533542633057\n",
      "mse 1.5040533949572434\n",
      "New best model found at epoch 26 with validation loss 1.5040533542633057\n",
      "Starting Epoch 27\n",
      "1.5459882070620854\n",
      "Validation loss: 1.4984701871871948\n",
      "mse 1.4984701698709106\n",
      "New best model found at epoch 27 with validation loss 1.4984701871871948\n",
      "Starting Epoch 28\n",
      "1.539479523897171\n",
      "Validation loss: 1.4944095611572266\n",
      "mse 1.4944096519511239\n",
      "New best model found at epoch 28 with validation loss 1.4944095611572266\n",
      "Starting Epoch 29\n",
      "1.5332386642694473\n",
      "Validation loss: 1.489376187324524\n",
      "mse 1.4893761900286677\n",
      "New best model found at epoch 29 with validation loss 1.489376187324524\n",
      "Starting Epoch 30\n",
      "1.5270612488190334\n",
      "Validation loss: 1.4846434593200684\n",
      "mse 1.4846433709631617\n",
      "New best model found at epoch 30 with validation loss 1.4846434593200684\n",
      "Starting Epoch 31\n",
      "1.5211676607529323\n",
      "Validation loss: 1.4794167280197144\n",
      "mse 1.4794167255426416\n",
      "New best model found at epoch 31 with validation loss 1.4794167280197144\n",
      "Starting Epoch 32\n",
      "1.5152439723412197\n",
      "Validation loss: 1.4748454093933105\n",
      "mse 1.4748452845556659\n",
      "New best model found at epoch 32 with validation loss 1.4748454093933105\n",
      "Starting Epoch 33\n",
      "1.5098778655131657\n",
      "Validation loss: 1.4717042446136475\n",
      "mse 1.4717042468882087\n",
      "New best model found at epoch 33 with validation loss 1.4717042446136475\n",
      "Starting Epoch 34\n",
      "1.504796380798022\n",
      "Validation loss: 1.467323660850525\n",
      "mse 1.467323782385203\n",
      "New best model found at epoch 34 with validation loss 1.467323660850525\n",
      "Starting Epoch 35\n",
      "1.4996262788772583\n",
      "Validation loss: 1.4625245332717896\n",
      "mse 1.4625246274019215\n",
      "New best model found at epoch 35 with validation loss 1.4625245332717896\n",
      "Starting Epoch 36\n",
      "1.4947077979644139\n",
      "Validation loss: 1.4582111835479736\n",
      "mse 1.4582109811387487\n",
      "New best model found at epoch 36 with validation loss 1.4582111835479736\n",
      "Starting Epoch 37\n",
      "1.4900447527567546\n",
      "Validation loss: 1.4538720846176147\n",
      "mse 1.4538720376786194\n",
      "New best model found at epoch 37 with validation loss 1.4538720846176147\n",
      "Starting Epoch 38\n",
      "1.4853254556655884\n",
      "Validation loss: 1.4494414329528809\n",
      "mse 1.4494414977885675\n",
      "New best model found at epoch 38 with validation loss 1.4494414329528809\n",
      "Starting Epoch 39\n",
      "1.48077525695165\n",
      "Validation loss: 1.4457885026931763\n",
      "mse 1.4457886445327186\n",
      "New best model found at epoch 39 with validation loss 1.4457885026931763\n",
      "Starting Epoch 40\n",
      "1.4763714969158173\n",
      "Validation loss: 1.4414560794830322\n",
      "mse 1.4414560738187734\n",
      "New best model found at epoch 40 with validation loss 1.4414560794830322\n",
      "Starting Epoch 41\n",
      "1.4717868516842525\n",
      "Validation loss: 1.4365955591201782\n",
      "mse 1.436595572298948\n",
      "New best model found at epoch 41 with validation loss 1.4365955591201782\n",
      "Starting Epoch 42\n",
      "1.467411682009697\n",
      "Validation loss: 1.4331896305084229\n",
      "mse 1.4331896373071973\n",
      "New best model found at epoch 42 with validation loss 1.4331896305084229\n",
      "Starting Epoch 43\n",
      "1.4632783234119415\n",
      "Validation loss: 1.428928256034851\n",
      "mse 1.4289282685435853\n",
      "New best model found at epoch 43 with validation loss 1.428928256034851\n",
      "Starting Epoch 44\n",
      "1.4594182521104813\n",
      "Validation loss: 1.4253674745559692\n",
      "mse 1.425367511237718\n",
      "New best model found at epoch 44 with validation loss 1.4253674745559692\n",
      "Starting Epoch 45\n",
      "1.4553927928209305\n",
      "Validation loss: 1.421312928199768\n",
      "mse 1.421312915945495\n",
      "New best model found at epoch 45 with validation loss 1.421312928199768\n",
      "Starting Epoch 46\n",
      "1.4513691862424214\n",
      "Validation loss: 1.4186826944351196\n",
      "mse 1.418682756089913\n",
      "New best model found at epoch 46 with validation loss 1.4186826944351196\n",
      "Starting Epoch 47\n",
      "1.4468029489119847\n",
      "Validation loss: 1.415061116218567\n",
      "mse 1.4150610585094003\n",
      "New best model found at epoch 47 with validation loss 1.415061116218567\n",
      "Starting Epoch 48\n",
      "1.4425591280062993\n",
      "Validation loss: 1.4120678901672363\n",
      "mse 1.4120680268983108\n",
      "New best model found at epoch 48 with validation loss 1.4120678901672363\n",
      "Starting Epoch 49\n",
      "1.4384765575329463\n",
      "Validation loss: 1.4059065580368042\n",
      "mse 1.405906473665882\n",
      "New best model found at epoch 49 with validation loss 1.4059065580368042\n",
      "Starting Epoch 50\n",
      "1.434881533185641\n",
      "Validation loss: 1.4048415422439575\n",
      "mse 1.4048415503781766\n",
      "New best model found at epoch 50 with validation loss 1.4048415422439575\n",
      "Starting Epoch 51\n",
      "1.4313367505868275\n",
      "Validation loss: 1.3996082544326782\n",
      "mse 1.3996083652236613\n",
      "New best model found at epoch 51 with validation loss 1.3996082544326782\n",
      "Starting Epoch 52\n",
      "1.4277363071839015\n",
      "Validation loss: 1.3960776329040527\n",
      "mse 1.3960776905868022\n",
      "New best model found at epoch 52 with validation loss 1.3960776329040527\n",
      "Starting Epoch 53\n",
      "1.424562359849612\n",
      "Validation loss: 1.394213318824768\n",
      "mse 1.3942132428949652\n",
      "New best model found at epoch 53 with validation loss 1.394213318824768\n",
      "Starting Epoch 54\n",
      "1.4213473250468571\n",
      "Validation loss: 1.3888418674468994\n",
      "mse 1.3888420003028075\n",
      "New best model found at epoch 54 with validation loss 1.3888418674468994\n",
      "Starting Epoch 55\n",
      "1.4178573737541835\n",
      "Validation loss: 1.3854389190673828\n",
      "mse 1.3854388774735236\n",
      "New best model found at epoch 55 with validation loss 1.3854389190673828\n",
      "Starting Epoch 56\n",
      "1.4146354148785274\n",
      "Validation loss: 1.3803503513336182\n",
      "mse 1.3803504402491489\n",
      "New best model found at epoch 56 with validation loss 1.3803503513336182\n",
      "Starting Epoch 57\n",
      "1.4116990466912587\n",
      "Validation loss: 1.3782896995544434\n",
      "mse 1.3782896357666332\n",
      "New best model found at epoch 57 with validation loss 1.3782896995544434\n",
      "Starting Epoch 58\n",
      "1.4086710065603256\n",
      "Validation loss: 1.374351143836975\n",
      "mse 1.3743511030429107\n",
      "New best model found at epoch 58 with validation loss 1.374351143836975\n",
      "Starting Epoch 59\n",
      "1.4054614851872127\n",
      "Validation loss: 1.3710243701934814\n",
      "mse 1.3710242663270098\n",
      "New best model found at epoch 59 with validation loss 1.3710243701934814\n",
      "Starting Epoch 60\n",
      "1.4025718569755554\n",
      "Validation loss: 1.3678526878356934\n",
      "mse 1.3678526964086506\n",
      "New best model found at epoch 60 with validation loss 1.3678526878356934\n",
      "Starting Epoch 61\n",
      "1.3999136164784431\n",
      "Validation loss: 1.3650981187820435\n",
      "mse 1.3650981424205166\n",
      "New best model found at epoch 61 with validation loss 1.3650981187820435\n",
      "Starting Epoch 62\n",
      "1.3973487541079521\n",
      "Validation loss: 1.3625110387802124\n",
      "mse 1.3625109227498038\n",
      "New best model found at epoch 62 with validation loss 1.3625110387802124\n",
      "Starting Epoch 63\n",
      "1.3949950362245243\n",
      "Validation loss: 1.3628519773483276\n",
      "mse 1.362851840488545\n",
      "Starting Epoch 64\n",
      "1.3925231869022052\n",
      "Validation loss: 1.3586792945861816\n",
      "mse 1.3586792371845478\n",
      "New best model found at epoch 64 with validation loss 1.3586792945861816\n",
      "Starting Epoch 65\n",
      "1.39020890245835\n",
      "Validation loss: 1.3579241037368774\n",
      "mse 1.3579241172059069\n",
      "New best model found at epoch 65 with validation loss 1.3579241037368774\n",
      "Starting Epoch 66\n",
      "1.3882733409603436\n",
      "Validation loss: 1.3545453548431396\n",
      "mse 1.3545454250844333\n",
      "New best model found at epoch 66 with validation loss 1.3545453548431396\n",
      "Starting Epoch 67\n",
      "1.3859997789065044\n",
      "Validation loss: 1.3528821468353271\n",
      "mse 1.352882078112676\n",
      "New best model found at epoch 67 with validation loss 1.3528821468353271\n",
      "Starting Epoch 68\n",
      "1.3836277301112812\n",
      "Validation loss: 1.3500534296035767\n",
      "mse 1.3500533320032002\n",
      "New best model found at epoch 68 with validation loss 1.3500534296035767\n",
      "Starting Epoch 69\n",
      "1.3814561888575554\n",
      "Validation loss: 1.347699522972107\n",
      "mse 1.3476994325286409\n",
      "New best model found at epoch 69 with validation loss 1.347699522972107\n",
      "Starting Epoch 70\n",
      "1.379570412139098\n",
      "Validation loss: 1.3477823734283447\n",
      "mse 1.3477823741809982\n",
      "Starting Epoch 71\n",
      "1.3774649798870087\n",
      "Validation loss: 1.3456424474716187\n",
      "mse 1.3456424871982975\n",
      "New best model found at epoch 71 with validation loss 1.3456424474716187\n",
      "Starting Epoch 72\n",
      "1.3756421779592831\n",
      "Validation loss: 1.343773365020752\n",
      "mse 1.3437734003362607\n",
      "New best model found at epoch 72 with validation loss 1.343773365020752\n",
      "Starting Epoch 73\n",
      "1.3733532403906186\n",
      "Validation loss: 1.342116117477417\n",
      "mse 1.3421161308769731\n",
      "New best model found at epoch 73 with validation loss 1.342116117477417\n",
      "Starting Epoch 74\n",
      "1.3721331531802814\n",
      "Validation loss: 1.3401302099227905\n",
      "mse 1.340130093422945\n",
      "New best model found at epoch 74 with validation loss 1.3401302099227905\n",
      "Starting Epoch 75\n",
      "1.369766707221667\n",
      "Validation loss: 1.33901846408844\n",
      "mse 1.3390184125621212\n",
      "New best model found at epoch 75 with validation loss 1.33901846408844\n",
      "Starting Epoch 76\n",
      "1.3681029006838799\n",
      "Validation loss: 1.3370131254196167\n",
      "mse 1.3370132000995678\n",
      "New best model found at epoch 76 with validation loss 1.3370131254196167\n",
      "Starting Epoch 77\n",
      "1.3661862065394719\n",
      "Validation loss: 1.3364039659500122\n",
      "mse 1.3364040199849363\n",
      "New best model found at epoch 77 with validation loss 1.3364039659500122\n",
      "Starting Epoch 78\n",
      "1.3647300774852436\n",
      "Validation loss: 1.3346805572509766\n",
      "mse 1.3346805854586437\n",
      "New best model found at epoch 78 with validation loss 1.3346805572509766\n",
      "Starting Epoch 79\n",
      "1.3632003987828891\n",
      "Validation loss: 1.333950400352478\n",
      "mse 1.333950333744462\n",
      "New best model found at epoch 79 with validation loss 1.333950400352478\n",
      "Starting Epoch 80\n",
      "1.3617298180858295\n",
      "Validation loss: 1.33171546459198\n",
      "mse 1.3317154165039446\n",
      "New best model found at epoch 80 with validation loss 1.33171546459198\n",
      "Starting Epoch 81\n",
      "1.360135868191719\n",
      "Validation loss: 1.3305304050445557\n",
      "mse 1.3305303311243668\n",
      "New best model found at epoch 81 with validation loss 1.3305304050445557\n",
      "Starting Epoch 82\n",
      "1.3585812325278919\n",
      "Validation loss: 1.3290551900863647\n",
      "mse 1.329055226928359\n",
      "New best model found at epoch 82 with validation loss 1.3290551900863647\n",
      "Starting Epoch 83\n",
      "1.3573697830239932\n",
      "Validation loss: 1.3271129131317139\n",
      "mse 1.327113097839657\n",
      "New best model found at epoch 83 with validation loss 1.3271129131317139\n",
      "Starting Epoch 84\n",
      "1.3560067936778069\n",
      "Validation loss: 1.3270543813705444\n",
      "mse 1.3270544437776504\n",
      "New best model found at epoch 84 with validation loss 1.3270543813705444\n",
      "Starting Epoch 85\n",
      "1.3547844315568607\n",
      "Validation loss: 1.3255105018615723\n",
      "mse 1.3255103838687712\n",
      "New best model found at epoch 85 with validation loss 1.3255105018615723\n",
      "Starting Epoch 86\n",
      "1.3534645835558574\n",
      "Validation loss: 1.3228442668914795\n",
      "mse 1.322844215562145\n",
      "New best model found at epoch 86 with validation loss 1.3228442668914795\n",
      "Starting Epoch 87\n",
      "1.3520107343792915\n",
      "Validation loss: 1.3229917287826538\n",
      "mse 1.3229917588612443\n",
      "Starting Epoch 88\n",
      "1.3505652422706287\n",
      "Validation loss: 1.3209121227264404\n",
      "mse 1.3209121041242182\n",
      "New best model found at epoch 88 with validation loss 1.3209121227264404\n",
      "Starting Epoch 89\n",
      "1.3490955159068108\n",
      "Validation loss: 1.3188915252685547\n",
      "mse 1.3188916036890928\n",
      "New best model found at epoch 89 with validation loss 1.3188915252685547\n",
      "Starting Epoch 90\n",
      "1.3480380127827327\n",
      "Validation loss: 1.3185521364212036\n",
      "mse 1.3185521802859241\n",
      "New best model found at epoch 90 with validation loss 1.3185521364212036\n",
      "Starting Epoch 91\n",
      "1.3468289102117221\n",
      "Validation loss: 1.3179795742034912\n",
      "mse 1.3179795574686715\n",
      "New best model found at epoch 91 with validation loss 1.3179795742034912\n",
      "Starting Epoch 92\n",
      "1.3456313361724217\n",
      "Validation loss: 1.3168292045593262\n",
      "mse 1.3168292091561973\n",
      "New best model found at epoch 92 with validation loss 1.3168292045593262\n",
      "Starting Epoch 93\n",
      "1.3444379195570946\n",
      "Validation loss: 1.3147993087768555\n",
      "mse 1.314799441769127\n",
      "New best model found at epoch 93 with validation loss 1.3147993087768555\n",
      "Starting Epoch 94\n",
      "1.3432330588499706\n",
      "Validation loss: 1.3148053884506226\n",
      "mse 1.31480537314947\n",
      "Starting Epoch 95\n",
      "1.342085247238477\n",
      "Validation loss: 1.314439058303833\n",
      "mse 1.3144390575305835\n",
      "New best model found at epoch 95 with validation loss 1.314439058303833\n",
      "Starting Epoch 96\n",
      "1.341045546034972\n",
      "Validation loss: 1.3120415210723877\n",
      "mse 1.3120414649022318\n",
      "New best model found at epoch 96 with validation loss 1.3120415210723877\n",
      "Starting Epoch 97\n",
      "1.3400148724516232\n",
      "Validation loss: 1.3111464977264404\n",
      "mse 1.3111464812470628\n",
      "New best model found at epoch 97 with validation loss 1.3111464977264404\n",
      "Starting Epoch 98\n",
      "1.338847075899442\n",
      "Validation loss: 1.3103458881378174\n",
      "mse 1.3103457928792246\n",
      "New best model found at epoch 98 with validation loss 1.3103458881378174\n",
      "Starting Epoch 99\n",
      "1.337721551458041\n",
      "Validation loss: 1.3091100454330444\n",
      "mse 1.309110043346326\n",
      "New best model found at epoch 99 with validation loss 1.3091100454330444\n",
      "Starting Epoch 100\n",
      "1.3367529089252155\n",
      "Validation loss: 1.308823585510254\n",
      "mse 1.308823598789311\n",
      "New best model found at epoch 100 with validation loss 1.308823585510254\n",
      "Starting Epoch 101\n",
      "1.3355287065108616\n",
      "Validation loss: 1.3091819286346436\n",
      "mse 1.3091819173078598\n",
      "Starting Epoch 102\n",
      "1.334447058538596\n",
      "Validation loss: 1.3071857690811157\n",
      "mse 1.3071858617872678\n",
      "New best model found at epoch 102 with validation loss 1.3071857690811157\n",
      "Starting Epoch 103\n",
      "1.3334372788667679\n",
      "Validation loss: 1.308656096458435\n",
      "mse 1.308656094921878\n",
      "Starting Epoch 104\n",
      "1.332279587785403\n",
      "Validation loss: 1.3063163757324219\n",
      "mse 1.3063164996754435\n",
      "New best model found at epoch 104 with validation loss 1.3063163757324219\n",
      "Starting Epoch 105\n",
      "1.331269885102908\n",
      "Validation loss: 1.3054343461990356\n",
      "mse 1.3054344147441392\n",
      "New best model found at epoch 105 with validation loss 1.3054343461990356\n",
      "Starting Epoch 106\n",
      "1.3301662405331929\n",
      "Validation loss: 1.3057881593704224\n",
      "mse 1.3057880977283367\n",
      "Starting Epoch 107\n",
      "1.329345390200615\n",
      "Validation loss: 1.3034147024154663\n",
      "mse 1.3034146225126788\n",
      "New best model found at epoch 107 with validation loss 1.3034147024154663\n",
      "Starting Epoch 108\n",
      "1.3280836840470631\n",
      "Validation loss: 1.303243637084961\n",
      "mse 1.3032436798375868\n",
      "New best model found at epoch 108 with validation loss 1.303243637084961\n",
      "Starting Epoch 109\n",
      "1.327269506951173\n",
      "Validation loss: 1.3035908937454224\n",
      "mse 1.303590936092411\n",
      "Starting Epoch 110\n",
      "1.3263232732812564\n",
      "Validation loss: 1.3018243312835693\n",
      "mse 1.3018243506239855\n",
      "New best model found at epoch 110 with validation loss 1.3018243312835693\n",
      "Starting Epoch 111\n",
      "1.3254969716072083\n",
      "Validation loss: 1.3006250858306885\n",
      "mse 1.300625127251343\n",
      "New best model found at epoch 111 with validation loss 1.3006250858306885\n",
      "Starting Epoch 112\n",
      "1.3244344020883243\n",
      "Validation loss: 1.3000332117080688\n",
      "mse 1.3000332373500973\n",
      "New best model found at epoch 112 with validation loss 1.3000332117080688\n",
      "Starting Epoch 113\n",
      "1.3237451215585072\n",
      "Validation loss: 1.2997612953186035\n",
      "mse 1.2997612221195618\n",
      "New best model found at epoch 113 with validation loss 1.2997612953186035\n",
      "Starting Epoch 114\n",
      "1.3228155200680096\n",
      "Validation loss: 1.2994016408920288\n",
      "mse 1.2994016205750203\n",
      "New best model found at epoch 114 with validation loss 1.2994016408920288\n",
      "Starting Epoch 115\n",
      "1.321860668559869\n",
      "Validation loss: 1.297196626663208\n",
      "mse 1.2971967011143088\n",
      "New best model found at epoch 115 with validation loss 1.297196626663208\n",
      "Starting Epoch 116\n",
      "1.3211081276337306\n",
      "Validation loss: 1.297372817993164\n",
      "mse 1.2973728351487737\n",
      "Starting Epoch 117\n",
      "1.320160761475563\n",
      "Validation loss: 1.2971988916397095\n",
      "mse 1.2971989941410382\n",
      "Starting Epoch 118\n",
      "1.319696269929409\n",
      "Validation loss: 1.2971723079681396\n",
      "mse 1.2971722078537236\n",
      "New best model found at epoch 118 with validation loss 1.2971723079681396\n",
      "Starting Epoch 119\n",
      "1.3188567832112312\n",
      "Validation loss: 1.2945317029953003\n",
      "mse 1.2945317513118175\n",
      "New best model found at epoch 119 with validation loss 1.2945317029953003\n",
      "Starting Epoch 120\n",
      "1.3179201905926068\n",
      "Validation loss: 1.295654296875\n",
      "mse 1.2956544480632135\n",
      "Starting Epoch 121\n",
      "1.3173769190907478\n",
      "Validation loss: 1.294711947441101\n",
      "mse 1.2947119662010185\n",
      "Starting Epoch 122\n",
      "1.3166468515992165\n",
      "Validation loss: 1.294467806816101\n",
      "mse 1.294467716875681\n",
      "New best model found at epoch 122 with validation loss 1.294467806816101\n",
      "Starting Epoch 123\n",
      "1.3158974597851436\n",
      "Validation loss: 1.2941272258758545\n",
      "mse 1.2941271504651128\n",
      "New best model found at epoch 123 with validation loss 1.2941272258758545\n",
      "Starting Epoch 124\n",
      "1.3150776127974193\n",
      "Validation loss: 1.293331265449524\n",
      "mse 1.2933312877728294\n",
      "New best model found at epoch 124 with validation loss 1.293331265449524\n",
      "Starting Epoch 125\n",
      "1.3145417645573616\n",
      "Validation loss: 1.29353666305542\n",
      "mse 1.293536532939784\n",
      "Starting Epoch 126\n",
      "1.3138436178366344\n",
      "Validation loss: 1.293067455291748\n",
      "mse 1.2930675753920833\n",
      "New best model found at epoch 126 with validation loss 1.293067455291748\n",
      "Starting Epoch 127\n",
      "1.31300155321757\n",
      "Validation loss: 1.2919479608535767\n",
      "mse 1.2919479061817427\n",
      "New best model found at epoch 127 with validation loss 1.2919479608535767\n",
      "Starting Epoch 128\n",
      "1.3123621741930644\n",
      "Validation loss: 1.2919069528579712\n",
      "mse 1.291906925872523\n",
      "New best model found at epoch 128 with validation loss 1.2919069528579712\n",
      "Starting Epoch 129\n",
      "1.3115789145231247\n",
      "Validation loss: 1.291524887084961\n",
      "mse 1.2915249696398037\n",
      "New best model found at epoch 129 with validation loss 1.291524887084961\n",
      "Starting Epoch 130\n",
      "1.311068502565225\n",
      "Validation loss: 1.291469931602478\n",
      "mse 1.2914699495042175\n",
      "New best model found at epoch 130 with validation loss 1.291469931602478\n",
      "Starting Epoch 131\n",
      "1.3103485405445099\n",
      "Validation loss: 1.2910746335983276\n",
      "mse 1.2910745102009962\n",
      "New best model found at epoch 131 with validation loss 1.2910746335983276\n",
      "Starting Epoch 132\n",
      "1.309832287331422\n",
      "Validation loss: 1.290571689605713\n",
      "mse 1.290571732691685\n",
      "New best model found at epoch 132 with validation loss 1.290571689605713\n",
      "Starting Epoch 133\n",
      "1.3090686326225598\n",
      "Validation loss: 1.290067195892334\n",
      "mse 1.2900672865473282\n",
      "New best model found at epoch 133 with validation loss 1.290067195892334\n",
      "Starting Epoch 134\n",
      "1.3083834076921146\n",
      "Validation loss: 1.2892199754714966\n",
      "mse 1.2892200584464268\n",
      "New best model found at epoch 134 with validation loss 1.2892199754714966\n",
      "Starting Epoch 135\n",
      "1.3076824322342873\n",
      "Validation loss: 1.288597583770752\n",
      "mse 1.2885976114414175\n",
      "New best model found at epoch 135 with validation loss 1.288597583770752\n",
      "Starting Epoch 136\n",
      "1.3071688562631607\n",
      "Validation loss: 1.289110541343689\n",
      "mse 1.2891104824029707\n",
      "Starting Epoch 137\n",
      "1.3065969422459602\n",
      "Validation loss: 1.2893942594528198\n",
      "mse 1.2893942829684422\n",
      "Starting Epoch 138\n",
      "1.3061453228195508\n",
      "Validation loss: 1.2891899347305298\n",
      "mse 1.28918985048795\n",
      "Starting Epoch 139\n",
      "1.3054632445176442\n",
      "Validation loss: 1.2890958786010742\n",
      "mse 1.2890958000860449\n",
      "Starting Epoch 140\n",
      "1.3049322813749313\n",
      "Validation loss: 1.2883810997009277\n",
      "mse 1.2883810150057047\n",
      "New best model found at epoch 140 with validation loss 1.2883810997009277\n",
      "Starting Epoch 141\n",
      "1.3042319441835086\n",
      "Validation loss: 1.2886756658554077\n",
      "mse 1.288675691356555\n",
      "Starting Epoch 142\n",
      "1.3036986589431763\n",
      "Validation loss: 1.288257122039795\n",
      "mse 1.28825709422418\n",
      "New best model found at epoch 142 with validation loss 1.288257122039795\n",
      "Starting Epoch 143\n",
      "1.3030245428284009\n",
      "Validation loss: 1.2881072759628296\n",
      "mse 1.2881072548831423\n",
      "New best model found at epoch 143 with validation loss 1.2881072759628296\n",
      "Starting Epoch 144\n",
      "1.3023558805386226\n",
      "Validation loss: 1.2870516777038574\n",
      "mse 1.287051748927389\n",
      "New best model found at epoch 144 with validation loss 1.2870516777038574\n",
      "Starting Epoch 145\n",
      "1.3017086784044902\n",
      "Validation loss: 1.2854173183441162\n",
      "mse 1.285417159004404\n",
      "New best model found at epoch 145 with validation loss 1.2854173183441162\n",
      "Starting Epoch 146\n",
      "1.3005527183413506\n",
      "Validation loss: 1.2861566543579102\n",
      "mse 1.2861566734623902\n",
      "Starting Epoch 147\n",
      "1.30003260076046\n",
      "Validation loss: 1.2846403121948242\n",
      "mse 1.2846403893392024\n",
      "New best model found at epoch 147 with validation loss 1.2846403121948242\n",
      "Starting Epoch 148\n",
      "1.299286129573981\n",
      "Validation loss: 1.284497618675232\n",
      "mse 1.2844975438818809\n",
      "New best model found at epoch 148 with validation loss 1.284497618675232\n",
      "Starting Epoch 149\n",
      "1.2987558643023174\n",
      "Validation loss: 1.2840181589126587\n",
      "mse 1.284018254767271\n",
      "New best model found at epoch 149 with validation loss 1.2840181589126587\n",
      "Starting Epoch 150\n",
      "1.2981017529964447\n",
      "Validation loss: 1.283238172531128\n",
      "mse 1.2832381707577298\n",
      "New best model found at epoch 150 with validation loss 1.283238172531128\n",
      "Starting Epoch 151\n",
      "1.2976702774564426\n",
      "Validation loss: 1.2842848300933838\n",
      "mse 1.2842847728488305\n",
      "Starting Epoch 152\n",
      "1.2970861072341602\n",
      "Validation loss: 1.2825788259506226\n",
      "mse 1.2825787641390307\n",
      "New best model found at epoch 152 with validation loss 1.2825788259506226\n",
      "Starting Epoch 153\n",
      "1.2963791713118553\n",
      "Validation loss: 1.281956434249878\n",
      "mse 1.2819563525127355\n",
      "New best model found at epoch 153 with validation loss 1.281956434249878\n",
      "Starting Epoch 154\n",
      "1.295927256345749\n",
      "Validation loss: 1.2815089225769043\n",
      "mse 1.2815090132583378\n",
      "New best model found at epoch 154 with validation loss 1.2815089225769043\n",
      "Starting Epoch 155\n",
      "1.295370986064275\n",
      "Validation loss: 1.2812023162841797\n",
      "mse 1.281202226107319\n",
      "New best model found at epoch 155 with validation loss 1.2812023162841797\n",
      "Starting Epoch 156\n",
      "1.294863648712635\n",
      "Validation loss: 1.28154718875885\n",
      "mse 1.2815471545296984\n",
      "Starting Epoch 157\n",
      "1.294234851996104\n",
      "Validation loss: 1.280956745147705\n",
      "mse 1.2809566838695747\n",
      "New best model found at epoch 157 with validation loss 1.280956745147705\n",
      "Starting Epoch 158\n",
      "1.29366734623909\n",
      "Validation loss: 1.2805315256118774\n",
      "mse 1.2805314821530238\n",
      "New best model found at epoch 158 with validation loss 1.2805315256118774\n",
      "Starting Epoch 159\n",
      "1.2931696847081184\n",
      "Validation loss: 1.2799217700958252\n",
      "mse 1.279921698423579\n",
      "New best model found at epoch 159 with validation loss 1.2799217700958252\n",
      "Starting Epoch 160\n",
      "1.2927545408407848\n",
      "Validation loss: 1.2798525094985962\n",
      "mse 1.2798524909384559\n",
      "New best model found at epoch 160 with validation loss 1.2798525094985962\n",
      "Starting Epoch 161\n",
      "1.2922505363821983\n",
      "Validation loss: 1.2796465158462524\n",
      "mse 1.2796464386725148\n",
      "New best model found at epoch 161 with validation loss 1.2796465158462524\n",
      "Starting Epoch 162\n",
      "1.29169965783755\n",
      "Validation loss: 1.2795474529266357\n",
      "mse 1.2795474920694019\n",
      "New best model found at epoch 162 with validation loss 1.2795474529266357\n",
      "Starting Epoch 163\n",
      "1.291103499631087\n",
      "Validation loss: 1.2781227827072144\n",
      "mse 1.2781227783236382\n",
      "New best model found at epoch 163 with validation loss 1.2781227827072144\n",
      "Starting Epoch 164\n",
      "1.290558397769928\n",
      "Validation loss: 1.2794018983840942\n",
      "mse 1.2794019327846027\n",
      "Starting Epoch 165\n",
      "1.2901592552661896\n",
      "Validation loss: 1.2785803079605103\n",
      "mse 1.2785803278618881\n",
      "Starting Epoch 166\n",
      "1.2895838096737862\n",
      "Validation loss: 1.2783219814300537\n",
      "mse 1.2783219308136864\n",
      "Starting Epoch 167\n",
      "1.2891632715861003\n",
      "Validation loss: 1.2775957584381104\n",
      "mse 1.2775958749739933\n",
      "New best model found at epoch 167 with validation loss 1.2775957584381104\n",
      "Starting Epoch 168\n",
      "1.28860288610061\n",
      "Validation loss: 1.2772529125213623\n",
      "mse 1.277252890552789\n",
      "New best model found at epoch 168 with validation loss 1.2772529125213623\n",
      "Starting Epoch 169\n",
      "1.288087122142315\n",
      "Validation loss: 1.2775858640670776\n",
      "mse 1.2775858890546172\n",
      "Starting Epoch 170\n",
      "1.2878228276968002\n",
      "Validation loss: 1.2763696908950806\n",
      "mse 1.2763695869920821\n",
      "New best model found at epoch 170 with validation loss 1.2763696908950806\n",
      "Starting Epoch 171\n",
      "1.2870279128352802\n",
      "Validation loss: 1.2777067422866821\n",
      "mse 1.2777067819945227\n",
      "Starting Epoch 172\n",
      "1.2866126323739688\n",
      "Validation loss: 1.2767819166183472\n",
      "mse 1.2767820018142968\n",
      "Starting Epoch 173\n",
      "1.2861070310076077\n",
      "Validation loss: 1.276334524154663\n",
      "mse 1.2763343545972485\n",
      "New best model found at epoch 173 with validation loss 1.276334524154663\n",
      "Starting Epoch 174\n",
      "1.2858466853698094\n",
      "Validation loss: 1.2753697633743286\n",
      "mse 1.2753697913294941\n",
      "New best model found at epoch 174 with validation loss 1.2753697633743286\n",
      "Starting Epoch 175\n",
      "1.285204216837883\n",
      "Validation loss: 1.2760310173034668\n",
      "mse 1.2760309921393218\n",
      "Starting Epoch 176\n",
      "1.2846856266260147\n",
      "Validation loss: 1.2740261554718018\n",
      "mse 1.274026158008745\n",
      "New best model found at epoch 176 with validation loss 1.2740261554718018\n",
      "Starting Epoch 177\n",
      "1.2845213363567989\n",
      "Validation loss: 1.2747681140899658\n",
      "mse 1.27476819036345\n",
      "Starting Epoch 178\n",
      "1.2837055499355\n",
      "Validation loss: 1.2743961811065674\n",
      "mse 1.2743961332739062\n",
      "Starting Epoch 179\n",
      "1.2835486605763435\n",
      "Validation loss: 1.2743401527404785\n",
      "mse 1.2743401758483053\n",
      "Starting Epoch 180\n",
      "1.2830738524595897\n",
      "Validation loss: 1.2738406658172607\n",
      "mse 1.2738407944186156\n",
      "New best model found at epoch 180 with validation loss 1.2738406658172607\n",
      "Starting Epoch 181\n",
      "1.282559332748254\n",
      "Validation loss: 1.2733867168426514\n",
      "mse 1.2733866605326705\n",
      "New best model found at epoch 181 with validation loss 1.2733867168426514\n",
      "Starting Epoch 182\n",
      "1.2821517462531726\n",
      "Validation loss: 1.27251398563385\n",
      "mse 1.272513969812625\n",
      "New best model found at epoch 182 with validation loss 1.27251398563385\n",
      "Starting Epoch 183\n",
      "1.2817189171910286\n",
      "Validation loss: 1.272406816482544\n",
      "mse 1.2724068641119997\n",
      "New best model found at epoch 183 with validation loss 1.272406816482544\n",
      "Starting Epoch 184\n",
      "1.281183697283268\n",
      "Validation loss: 1.2724580764770508\n",
      "mse 1.2724581878152694\n",
      "Starting Epoch 185\n",
      "1.2806360522905986\n",
      "Validation loss: 1.2715516090393066\n",
      "mse 1.2715516517696042\n",
      "New best model found at epoch 185 with validation loss 1.2715516090393066\n",
      "Starting Epoch 186\n",
      "1.2801648850242298\n",
      "Validation loss: 1.270849347114563\n",
      "mse 1.2708494021851375\n",
      "New best model found at epoch 186 with validation loss 1.270849347114563\n",
      "Starting Epoch 187\n",
      "1.279958004752795\n",
      "Validation loss: 1.2703126668930054\n",
      "mse 1.2703126696037093\n",
      "New best model found at epoch 187 with validation loss 1.2703126668930054\n",
      "Starting Epoch 188\n",
      "1.2796010300517082\n",
      "Validation loss: 1.2708969116210938\n",
      "mse 1.270896977057188\n",
      "Starting Epoch 189\n",
      "1.2791137198607128\n",
      "Validation loss: 1.2706302404403687\n",
      "mse 1.270630166502333\n",
      "Starting Epoch 190\n",
      "1.2786530976494153\n",
      "Validation loss: 1.270041584968567\n",
      "mse 1.2700414939258984\n",
      "New best model found at epoch 190 with validation loss 1.270041584968567\n",
      "Starting Epoch 191\n",
      "1.2780443256100018\n",
      "Validation loss: 1.2694536447525024\n",
      "mse 1.2694535458835265\n",
      "New best model found at epoch 191 with validation loss 1.2694536447525024\n",
      "Starting Epoch 192\n",
      "1.2778500492374103\n",
      "Validation loss: 1.2690304517745972\n",
      "mse 1.2690305545213183\n",
      "New best model found at epoch 192 with validation loss 1.2690304517745972\n",
      "Starting Epoch 193\n",
      "1.2775031477212906\n",
      "Validation loss: 1.2685775756835938\n",
      "mse 1.268577696721013\n",
      "New best model found at epoch 193 with validation loss 1.2685775756835938\n",
      "Starting Epoch 194\n",
      "1.276825341085593\n",
      "Validation loss: 1.2684485912322998\n",
      "mse 1.2684485419688947\n",
      "New best model found at epoch 194 with validation loss 1.2684485912322998\n",
      "Starting Epoch 195\n",
      "1.2760236437122028\n",
      "Validation loss: 1.2687512636184692\n",
      "mse 1.2687511611785225\n",
      "Starting Epoch 196\n",
      "1.2757323210438092\n",
      "Validation loss: 1.2680045366287231\n",
      "mse 1.268004537936352\n",
      "New best model found at epoch 196 with validation loss 1.2680045366287231\n",
      "Starting Epoch 197\n",
      "1.2752293050289154\n",
      "Validation loss: 1.2671974897384644\n",
      "mse 1.267197506187601\n",
      "New best model found at epoch 197 with validation loss 1.2671974897384644\n",
      "Starting Epoch 198\n",
      "1.2745436628659566\n",
      "Validation loss: 1.2680221796035767\n",
      "mse 1.2680221702247225\n",
      "Starting Epoch 199\n",
      "1.2739908869067829\n",
      "Validation loss: 1.267192006111145\n",
      "mse 1.267192010874585\n",
      "New best model found at epoch 199 with validation loss 1.267192006111145\n",
      "Starting Epoch 200\n",
      "1.2736677303910255\n",
      "Validation loss: 1.2674241065979004\n",
      "mse 1.2674241275478904\n",
      "Starting Epoch 201\n",
      "1.2729868392149608\n",
      "Validation loss: 1.2659226655960083\n",
      "mse 1.265922648081204\n",
      "New best model found at epoch 201 with validation loss 1.2659226655960083\n",
      "Starting Epoch 202\n",
      "1.2723731125394504\n",
      "Validation loss: 1.2662429809570312\n",
      "mse 1.2662429148278393\n",
      "Starting Epoch 203\n",
      "1.2719831665356953\n",
      "Validation loss: 1.2664756774902344\n",
      "mse 1.2664756846798975\n",
      "Starting Epoch 204\n",
      "1.271111028889815\n",
      "Validation loss: 1.265583872795105\n",
      "mse 1.265583795228906\n",
      "New best model found at epoch 204 with validation loss 1.265583872795105\n",
      "Starting Epoch 205\n",
      "1.2709240317344666\n",
      "Validation loss: 1.2645816802978516\n",
      "mse 1.2645817234148085\n",
      "New best model found at epoch 205 with validation loss 1.2645816802978516\n",
      "Starting Epoch 206\n",
      "1.2702333331108093\n",
      "Validation loss: 1.2637795209884644\n",
      "mse 1.2637794865821361\n",
      "New best model found at epoch 206 with validation loss 1.2637795209884644\n",
      "Starting Epoch 207\n",
      "1.269924335181713\n",
      "Validation loss: 1.2635180950164795\n",
      "mse 1.263518219834967\n",
      "New best model found at epoch 207 with validation loss 1.2635180950164795\n",
      "Starting Epoch 208\n",
      "1.2696131616830826\n",
      "Validation loss: 1.263127088546753\n",
      "mse 1.2631270980019484\n",
      "New best model found at epoch 208 with validation loss 1.263127088546753\n",
      "Starting Epoch 209\n",
      "1.2689749921361606\n",
      "Validation loss: 1.2627687454223633\n",
      "mse 1.2627687921601514\n",
      "New best model found at epoch 209 with validation loss 1.2627687454223633\n",
      "Starting Epoch 210\n",
      "1.2685943668087323\n",
      "Validation loss: 1.262168049812317\n",
      "mse 1.262168048917573\n",
      "New best model found at epoch 210 with validation loss 1.262168049812317\n",
      "Starting Epoch 211\n",
      "1.2679059281945229\n",
      "Validation loss: 1.2623748779296875\n",
      "mse 1.2623747899606026\n",
      "Starting Epoch 212\n",
      "1.2675344174106915\n",
      "Validation loss: 1.2623518705368042\n",
      "mse 1.2623519686356852\n",
      "Starting Epoch 213\n",
      "1.2670221750934918\n",
      "Validation loss: 1.261722207069397\n",
      "mse 1.2617222406951079\n",
      "New best model found at epoch 213 with validation loss 1.261722207069397\n",
      "Starting Epoch 214\n",
      "1.2664598325888317\n",
      "Validation loss: 1.2608402967453003\n",
      "mse 1.2608404462190483\n",
      "New best model found at epoch 214 with validation loss 1.2608402967453003\n",
      "Starting Epoch 215\n",
      "1.2664436126748722\n",
      "Validation loss: 1.2612026929855347\n",
      "mse 1.2612026053892387\n",
      "Starting Epoch 216\n",
      "1.265880862871806\n",
      "Validation loss: 1.260339617729187\n",
      "mse 1.2603396490495797\n",
      "New best model found at epoch 216 with validation loss 1.260339617729187\n",
      "Starting Epoch 217\n",
      "1.2655264933904011\n",
      "Validation loss: 1.2597627639770508\n",
      "mse 1.259762616846208\n",
      "New best model found at epoch 217 with validation loss 1.2597627639770508\n",
      "Starting Epoch 218\n",
      "1.2649898181358974\n",
      "Validation loss: 1.2600996494293213\n",
      "mse 1.2600996225580914\n",
      "Starting Epoch 219\n",
      "1.264615868528684\n",
      "Validation loss: 1.259849190711975\n",
      "mse 1.2598491491610493\n",
      "Starting Epoch 220\n",
      "1.2639875983198483\n",
      "Validation loss: 1.259749174118042\n",
      "mse 1.2597491521960353\n",
      "New best model found at epoch 220 with validation loss 1.259749174118042\n",
      "Starting Epoch 221\n",
      "1.2635850335160892\n",
      "Validation loss: 1.2593547105789185\n",
      "mse 1.2593547631872364\n",
      "New best model found at epoch 221 with validation loss 1.2593547105789185\n",
      "Starting Epoch 222\n",
      "1.2631473367412884\n",
      "Validation loss: 1.2587900161743164\n",
      "mse 1.2587898917805183\n",
      "New best model found at epoch 222 with validation loss 1.2587900161743164\n",
      "Starting Epoch 223\n",
      "1.263022909561793\n",
      "Validation loss: 1.2587051391601562\n",
      "mse 1.2587052489720223\n",
      "New best model found at epoch 223 with validation loss 1.2587051391601562\n",
      "Starting Epoch 224\n",
      "1.2626805702845256\n",
      "Validation loss: 1.2584941387176514\n",
      "mse 1.258494256459928\n",
      "New best model found at epoch 224 with validation loss 1.2584941387176514\n",
      "Starting Epoch 225\n",
      "1.2622642293572426\n",
      "Validation loss: 1.2582731246948242\n",
      "mse 1.2582730328514604\n",
      "New best model found at epoch 225 with validation loss 1.2582731246948242\n",
      "Starting Epoch 226\n",
      "1.2615656082828839\n",
      "Validation loss: 1.2572109699249268\n",
      "mse 1.2572109602930435\n",
      "New best model found at epoch 226 with validation loss 1.2572109699249268\n",
      "Starting Epoch 227\n",
      "1.2615996698538463\n",
      "Validation loss: 1.257711410522461\n",
      "mse 1.2577113620687164\n",
      "Starting Epoch 228\n",
      "1.2611238410075505\n",
      "Validation loss: 1.2573026418685913\n",
      "mse 1.257302700872477\n",
      "Starting Epoch 229\n",
      "1.2606674656271935\n",
      "Validation loss: 1.257429838180542\n",
      "mse 1.257429850334789\n",
      "Starting Epoch 230\n",
      "1.260275197525819\n",
      "Validation loss: 1.2568851709365845\n",
      "mse 1.2568851539798416\n",
      "New best model found at epoch 230 with validation loss 1.2568851709365845\n",
      "Starting Epoch 231\n",
      "1.2599272355437279\n",
      "Validation loss: 1.2560831308364868\n",
      "mse 1.2560830588401128\n",
      "New best model found at epoch 231 with validation loss 1.2560831308364868\n",
      "Starting Epoch 232\n",
      "1.2595989058415096\n",
      "Validation loss: 1.2562175989151\n",
      "mse 1.2562175038418106\n",
      "Starting Epoch 233\n",
      "1.2588440030813217\n",
      "Validation loss: 1.2558037042617798\n",
      "mse 1.255803621885444\n",
      "New best model found at epoch 233 with validation loss 1.2558037042617798\n",
      "Starting Epoch 234\n",
      "1.258852479358514\n",
      "Validation loss: 1.2556283473968506\n",
      "mse 1.2556284628514245\n",
      "New best model found at epoch 234 with validation loss 1.2556283473968506\n",
      "Starting Epoch 235\n",
      "1.2582005113363266\n",
      "Validation loss: 1.2556135654449463\n",
      "mse 1.2556135980465728\n",
      "New best model found at epoch 235 with validation loss 1.2556135654449463\n",
      "Starting Epoch 236\n",
      "1.2579756528139114\n",
      "Validation loss: 1.2545266151428223\n",
      "mse 1.2545266155058907\n",
      "New best model found at epoch 236 with validation loss 1.2545266151428223\n",
      "Starting Epoch 237\n",
      "1.2576169893145561\n",
      "Validation loss: 1.2549090385437012\n",
      "mse 1.2549091202811338\n",
      "Starting Epoch 238\n",
      "1.2574219902356465\n",
      "Validation loss: 1.2546836137771606\n",
      "mse 1.2546835388328064\n",
      "Starting Epoch 239\n",
      "1.2568480769793193\n",
      "Validation loss: 1.2543329000473022\n",
      "mse 1.2543328517037187\n",
      "New best model found at epoch 239 with validation loss 1.2543329000473022\n",
      "Starting Epoch 240\n",
      "1.2564966430266697\n",
      "Validation loss: 1.254582405090332\n",
      "mse 1.2545824572525137\n",
      "Starting Epoch 241\n",
      "1.2563448672493298\n",
      "Validation loss: 1.2544420957565308\n",
      "mse 1.254442126240617\n",
      "Starting Epoch 242\n",
      "1.2560241694251697\n",
      "Validation loss: 1.253662347793579\n",
      "mse 1.2536622938743431\n",
      "New best model found at epoch 242 with validation loss 1.253662347793579\n",
      "Starting Epoch 243\n",
      "1.2556587407986324\n",
      "Validation loss: 1.2538284063339233\n",
      "mse 1.2538284276278395\n",
      "Starting Epoch 244\n",
      "1.2551011194785435\n",
      "Validation loss: 1.2533984184265137\n",
      "mse 1.253398440384165\n",
      "New best model found at epoch 244 with validation loss 1.2533984184265137\n",
      "Starting Epoch 245\n",
      "1.2549045259753864\n",
      "Validation loss: 1.2527042627334595\n",
      "mse 1.25270425665858\n",
      "New best model found at epoch 245 with validation loss 1.2527042627334595\n",
      "Starting Epoch 246\n",
      "1.2545972093939781\n",
      "Validation loss: 1.2530264854431152\n",
      "mse 1.2530264078128808\n",
      "Starting Epoch 247\n",
      "1.25410691400369\n",
      "Validation loss: 1.2523761987686157\n",
      "mse 1.2523762352895054\n",
      "New best model found at epoch 247 with validation loss 1.2523761987686157\n",
      "Starting Epoch 248\n",
      "1.2538855423529942\n",
      "Validation loss: 1.2516800165176392\n",
      "mse 1.2516800043903198\n",
      "New best model found at epoch 248 with validation loss 1.2516800165176392\n",
      "Starting Epoch 249\n",
      "1.2538087541858356\n",
      "Validation loss: 1.2520537376403809\n",
      "mse 1.2520536725671418\n",
      "Starting Epoch 250\n",
      "1.2531667575240135\n",
      "Validation loss: 1.251941442489624\n",
      "mse 1.2519413568304987\n",
      "Starting Epoch 251\n",
      "1.2528237998485565\n",
      "Validation loss: 1.2512248754501343\n",
      "mse 1.2512249244715878\n",
      "New best model found at epoch 251 with validation loss 1.2512248754501343\n",
      "Starting Epoch 252\n",
      "1.2526768470803897\n",
      "Validation loss: 1.2515275478363037\n",
      "mse 1.251527618956559\n",
      "Starting Epoch 253\n",
      "1.252123090128104\n",
      "Validation loss: 1.250686526298523\n",
      "mse 1.2506865001593401\n",
      "New best model found at epoch 253 with validation loss 1.250686526298523\n",
      "Starting Epoch 254\n",
      "1.2519374986489613\n",
      "Validation loss: 1.250200867652893\n",
      "mse 1.250200813536525\n",
      "New best model found at epoch 254 with validation loss 1.250200867652893\n",
      "Starting Epoch 255\n",
      "1.2515194788575172\n",
      "Validation loss: 1.2501627206802368\n",
      "mse 1.2501626386185918\n",
      "New best model found at epoch 255 with validation loss 1.2501627206802368\n",
      "Starting Epoch 256\n",
      "1.2513458306590717\n",
      "Validation loss: 1.2499974966049194\n",
      "mse 1.2499974467782025\n",
      "New best model found at epoch 256 with validation loss 1.2499974966049194\n",
      "Starting Epoch 257\n",
      "1.2509626746177673\n",
      "Validation loss: 1.250172734260559\n",
      "mse 1.2501724970518857\n",
      "Starting Epoch 258\n",
      "1.2505592157443364\n",
      "Validation loss: 1.2499666213989258\n",
      "mse 1.2499666670441412\n",
      "New best model found at epoch 258 with validation loss 1.2499666213989258\n",
      "Starting Epoch 259\n",
      "1.2505689188838005\n",
      "Validation loss: 1.2493739128112793\n",
      "mse 1.2493740085976126\n",
      "New best model found at epoch 259 with validation loss 1.2493739128112793\n",
      "Starting Epoch 260\n",
      "1.249876854320367\n",
      "Validation loss: 1.2482444047927856\n",
      "mse 1.2482445929336146\n",
      "New best model found at epoch 260 with validation loss 1.2482444047927856\n",
      "Starting Epoch 261\n",
      "1.2497837394475937\n",
      "Validation loss: 1.2487366199493408\n",
      "mse 1.2487366772200996\n",
      "Starting Epoch 262\n",
      "1.249321053425471\n",
      "Validation loss: 1.2485846281051636\n",
      "mse 1.2485846969077379\n",
      "Starting Epoch 263\n",
      "1.2490831439693768\n",
      "Validation loss: 1.2483195066452026\n",
      "mse 1.2483196491262958\n",
      "Starting Epoch 264\n",
      "1.248692919810613\n",
      "Validation loss: 1.2481632232666016\n",
      "mse 1.248163309589278\n",
      "New best model found at epoch 264 with validation loss 1.2481632232666016\n",
      "Starting Epoch 265\n",
      "1.2482121661305428\n",
      "Validation loss: 1.2474254369735718\n",
      "mse 1.2474256364473464\n",
      "New best model found at epoch 265 with validation loss 1.2474254369735718\n",
      "Starting Epoch 266\n",
      "1.248392716050148\n",
      "Validation loss: 1.247674822807312\n",
      "mse 1.247674932215691\n",
      "Starting Epoch 267\n",
      "1.2477339481314023\n",
      "Validation loss: 1.246196985244751\n",
      "mse 1.2461969979626542\n",
      "New best model found at epoch 267 with validation loss 1.246196985244751\n",
      "Starting Epoch 268\n",
      "1.2476965636014938\n",
      "Validation loss: 1.2467420101165771\n",
      "mse 1.2467419713102375\n",
      "Starting Epoch 269\n",
      "1.2472153430183728\n",
      "Validation loss: 1.2457478046417236\n",
      "mse 1.2457478790719594\n",
      "New best model found at epoch 269 with validation loss 1.2457478046417236\n",
      "Starting Epoch 270\n",
      "1.2469072590271633\n",
      "Validation loss: 1.245638132095337\n",
      "mse 1.2456383104033986\n",
      "New best model found at epoch 270 with validation loss 1.245638132095337\n",
      "Starting Epoch 271\n",
      "1.2466715623935063\n",
      "Validation loss: 1.2445461750030518\n",
      "mse 1.2445462451460034\n",
      "New best model found at epoch 271 with validation loss 1.2445461750030518\n",
      "Starting Epoch 272\n",
      "1.2461171199878056\n",
      "Validation loss: 1.2446050643920898\n",
      "mse 1.244605033185357\n",
      "Starting Epoch 273\n",
      "1.245564232269923\n",
      "Validation loss: 1.2436504364013672\n",
      "mse 1.2436505445499522\n",
      "New best model found at epoch 273 with validation loss 1.2436504364013672\n",
      "Starting Epoch 274\n",
      "1.2453401510914166\n",
      "Validation loss: 1.2431281805038452\n",
      "mse 1.243128316585862\n",
      "New best model found at epoch 274 with validation loss 1.2431281805038452\n",
      "Starting Epoch 275\n",
      "1.2450334032376607\n",
      "Validation loss: 1.2433784008026123\n",
      "mse 1.2433784592451689\n",
      "Starting Epoch 276\n",
      "1.2447695409258206\n",
      "Validation loss: 1.2426401376724243\n",
      "mse 1.2426402930593294\n",
      "New best model found at epoch 276 with validation loss 1.2426401376724243\n",
      "Starting Epoch 277\n",
      "1.2442842374245326\n",
      "Validation loss: 1.241989016532898\n",
      "mse 1.2419890409983168\n",
      "New best model found at epoch 277 with validation loss 1.241989016532898\n",
      "Starting Epoch 278\n",
      "1.2438239579399426\n",
      "Validation loss: 1.242203950881958\n",
      "mse 1.242203878995341\n",
      "Starting Epoch 279\n",
      "1.2435755009452503\n",
      "Validation loss: 1.241772174835205\n",
      "mse 1.2417721670756905\n",
      "New best model found at epoch 279 with validation loss 1.241772174835205\n",
      "Starting Epoch 280\n",
      "1.2431715602676074\n",
      "Validation loss: 1.2408297061920166\n",
      "mse 1.2408298129353972\n",
      "New best model found at epoch 280 with validation loss 1.2408297061920166\n",
      "Starting Epoch 281\n",
      "1.2431954070925713\n",
      "Validation loss: 1.241487979888916\n",
      "mse 1.2414880841725562\n",
      "Starting Epoch 282\n",
      "1.2428385739525158\n",
      "Validation loss: 1.241426706314087\n",
      "mse 1.2414267826695464\n",
      "Starting Epoch 283\n",
      "1.2424280121922493\n",
      "Validation loss: 1.240522861480713\n",
      "mse 1.2405227427837215\n",
      "New best model found at epoch 283 with validation loss 1.240522861480713\n",
      "Starting Epoch 284\n",
      "1.2422870968778927\n",
      "Validation loss: 1.2403415441513062\n",
      "mse 1.240341456157686\n",
      "New best model found at epoch 284 with validation loss 1.2403415441513062\n",
      "Starting Epoch 285\n",
      "1.2419170811772346\n",
      "Validation loss: 1.2407585382461548\n",
      "mse 1.2407585273395312\n",
      "Starting Epoch 286\n",
      "1.24149456123511\n",
      "Validation loss: 1.240809679031372\n",
      "mse 1.2408097180498032\n",
      "Starting Epoch 287\n",
      "1.2414683575431507\n",
      "Validation loss: 1.2408219575881958\n",
      "mse 1.240821897272687\n",
      "Starting Epoch 288\n",
      "1.2411412249008815\n",
      "Validation loss: 1.240386724472046\n",
      "mse 1.2403867559390716\n",
      "Starting Epoch 289\n",
      "1.2411023030678432\n",
      "Validation loss: 1.240346908569336\n",
      "mse 1.2403468368860537\n",
      "Starting Epoch 290\n",
      "1.2405925765633583\n",
      "Validation loss: 1.2395188808441162\n",
      "mse 1.23951891517682\n",
      "New best model found at epoch 290 with validation loss 1.2395188808441162\n",
      "Starting Epoch 291\n",
      "1.2400401284297307\n",
      "Validation loss: 1.239428162574768\n",
      "mse 1.239428077945086\n",
      "New best model found at epoch 291 with validation loss 1.239428162574768\n",
      "Starting Epoch 292\n",
      "1.2400943736235301\n",
      "Validation loss: 1.2398298978805542\n",
      "mse 1.2398299660548782\n",
      "Starting Epoch 293\n",
      "1.23985409984986\n",
      "Validation loss: 1.2395130395889282\n",
      "mse 1.2395129813429908\n",
      "Starting Epoch 294\n",
      "1.2393460323413212\n",
      "Validation loss: 1.23874032497406\n",
      "mse 1.2387403623710431\n",
      "New best model found at epoch 294 with validation loss 1.23874032497406\n",
      "Starting Epoch 295\n",
      "1.2393829201658566\n",
      "Validation loss: 1.2392666339874268\n",
      "mse 1.2392666317928691\n",
      "Starting Epoch 296\n",
      "1.2390454038977623\n",
      "Validation loss: 1.2387605905532837\n",
      "mse 1.2387605378245456\n",
      "Starting Epoch 297\n",
      "1.2385897512237232\n",
      "Validation loss: 1.239193320274353\n",
      "mse 1.2391934034173098\n",
      "Starting Epoch 298\n",
      "1.2388794670502346\n",
      "Validation loss: 1.2386016845703125\n",
      "mse 1.2386017323821066\n",
      "New best model found at epoch 298 with validation loss 1.2386016845703125\n",
      "Starting Epoch 299\n",
      "1.238365004460017\n",
      "Validation loss: 1.2382704019546509\n",
      "mse 1.2382704691170188\n",
      "New best model found at epoch 299 with validation loss 1.2382704019546509\n",
      "Starting Epoch 300\n",
      "1.237819862862428\n",
      "Validation loss: 1.2379339933395386\n",
      "mse 1.2379339549052968\n",
      "New best model found at epoch 300 with validation loss 1.2379339933395386\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-q75: 7-80-50-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83e125-5d6a-4e1d-80fe-0d84aaa1d484",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, custom layer\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 1 (best model before)\n",
    "*  Adding a custom layer, where we group all features occuring multiple times together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "53692139-79bf-48b5-98b8-23dc84f17777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.values).float()  # Convert DataFrame to tensor\n",
    "        self.y = torch.from_numpy(y.values).float()  # Convert DataFrame to tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d0f81fc6-39ab-40b7-bc3b-7eac2e90e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "1f909456-53e0-4fa0-a020-f9e11af5bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 1)  \n",
    "        self.fc2 = nn.Linear(1, 1)  \n",
    "        self.fc3 = nn.Linear(1, 1)  \n",
    "        self.fc4 = nn.Linear(1, 1)  \n",
    "        self.fc5 = nn.Linear(1, 1)  \n",
    "        self.fc6 = nn.Linear(6, 1)  \n",
    "        self.fc7 = nn.Linear(6, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        grouped_features = torch.cat((self.fc1(x[:, 0:1]), self.fc2(x[:, 1:2]), self.fc3(x[:, 2:3]), self.fc4(x[:, 3:4]), \n",
    "                                      self.fc5(x[:, 4:5]), self.fc6(x[:, 5:11]), self.fc7(x[:, 11:17])), dim=1)\n",
    "        \n",
    "        return grouped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "0566a675-fad1-4179-9678-fb60888c43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.custom_layer = CustomLayer()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.custom_layer(x)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4a677058-419a-49c9-885b-80c3275b0d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.353097900748253\n",
      "Validation loss: 1.8899248838424683\n",
      "mse 1.8899248810704374\n",
      "New best model found at epoch 1 with validation loss 1.8899248838424683\n",
      "Starting Epoch 2\n",
      "1.8661089887221654\n",
      "Validation loss: 1.7425813674926758\n",
      "mse 1.7425813756343589\n",
      "New best model found at epoch 2 with validation loss 1.7425813674926758\n",
      "Starting Epoch 3\n",
      "1.773332878947258\n",
      "Validation loss: 1.6700836420059204\n",
      "mse 1.670083641114355\n",
      "New best model found at epoch 3 with validation loss 1.6700836420059204\n",
      "Starting Epoch 4\n",
      "1.7175187766551971\n",
      "Validation loss: 1.6186283826828003\n",
      "mse 1.6186285141847019\n",
      "New best model found at epoch 4 with validation loss 1.6186283826828003\n",
      "Starting Epoch 5\n",
      "1.6779919614394505\n",
      "Validation loss: 1.5818618535995483\n",
      "mse 1.5818617768321659\n",
      "New best model found at epoch 5 with validation loss 1.5818618535995483\n",
      "Starting Epoch 6\n",
      "1.6496187696854274\n",
      "Validation loss: 1.5517023801803589\n",
      "mse 1.5517023599205664\n",
      "New best model found at epoch 6 with validation loss 1.5517023801803589\n",
      "Starting Epoch 7\n",
      "1.625946710507075\n",
      "Validation loss: 1.5271366834640503\n",
      "mse 1.5271366344899164\n",
      "New best model found at epoch 7 with validation loss 1.5271366834640503\n",
      "Starting Epoch 8\n",
      "1.6060307770967484\n",
      "Validation loss: 1.5095051527023315\n",
      "mse 1.5095051876073957\n",
      "New best model found at epoch 8 with validation loss 1.5095051527023315\n",
      "Starting Epoch 9\n",
      "1.5881530245145161\n",
      "Validation loss: 1.490696668624878\n",
      "mse 1.4906966005787121\n",
      "New best model found at epoch 9 with validation loss 1.490696668624878\n",
      "Starting Epoch 10\n",
      "1.5727548549572627\n",
      "Validation loss: 1.4769824743270874\n",
      "mse 1.4769824096594777\n",
      "New best model found at epoch 10 with validation loss 1.4769824743270874\n",
      "Starting Epoch 11\n",
      "1.560036614537239\n",
      "Validation loss: 1.4600841999053955\n",
      "mse 1.460084273649117\n",
      "New best model found at epoch 11 with validation loss 1.4600841999053955\n",
      "Starting Epoch 12\n",
      "1.5464362353086472\n",
      "Validation loss: 1.4464133977890015\n",
      "mse 1.4464134628242535\n",
      "New best model found at epoch 12 with validation loss 1.4464133977890015\n",
      "Starting Epoch 13\n",
      "1.5350757489601772\n",
      "Validation loss: 1.4356170892715454\n",
      "mse 1.4356170175701644\n",
      "New best model found at epoch 13 with validation loss 1.4356170892715454\n",
      "Starting Epoch 14\n",
      "1.5243309785922368\n",
      "Validation loss: 1.4254772663116455\n",
      "mse 1.4254774706383058\n",
      "New best model found at epoch 14 with validation loss 1.4254772663116455\n",
      "Starting Epoch 15\n",
      "1.5138186762730281\n",
      "Validation loss: 1.4155374765396118\n",
      "mse 1.415537377857411\n",
      "New best model found at epoch 15 with validation loss 1.4155374765396118\n",
      "Starting Epoch 16\n",
      "1.5040196975072224\n",
      "Validation loss: 1.4039419889450073\n",
      "mse 1.4039419692438089\n",
      "New best model found at epoch 16 with validation loss 1.4039419889450073\n",
      "Starting Epoch 17\n",
      "1.494219794869423\n",
      "Validation loss: 1.3967210054397583\n",
      "mse 1.396721073941087\n",
      "New best model found at epoch 17 with validation loss 1.3967210054397583\n",
      "Starting Epoch 18\n",
      "1.485591173171997\n",
      "Validation loss: 1.389227271080017\n",
      "mse 1.3892272114819126\n",
      "New best model found at epoch 18 with validation loss 1.389227271080017\n",
      "Starting Epoch 19\n",
      "1.4776062319676082\n",
      "Validation loss: 1.3813488483428955\n",
      "mse 1.3813489394709713\n",
      "New best model found at epoch 19 with validation loss 1.3813488483428955\n",
      "Starting Epoch 20\n",
      "1.4695937931537628\n",
      "Validation loss: 1.3732558488845825\n",
      "mse 1.3732558319458512\n",
      "New best model found at epoch 20 with validation loss 1.3732558488845825\n",
      "Starting Epoch 21\n",
      "1.4618673970301945\n",
      "Validation loss: 1.3659305572509766\n",
      "mse 1.3659304252297344\n",
      "New best model found at epoch 21 with validation loss 1.3659305572509766\n",
      "Starting Epoch 22\n",
      "1.4543071538209915\n",
      "Validation loss: 1.3584116697311401\n",
      "mse 1.3584116686629928\n",
      "New best model found at epoch 22 with validation loss 1.3584116697311401\n",
      "Starting Epoch 23\n",
      "1.4471810162067413\n",
      "Validation loss: 1.3530666828155518\n",
      "mse 1.3530667329754484\n",
      "New best model found at epoch 23 with validation loss 1.3530666828155518\n",
      "Starting Epoch 24\n",
      "1.440366044640541\n",
      "Validation loss: 1.344455361366272\n",
      "mse 1.344455420877425\n",
      "New best model found at epoch 24 with validation loss 1.344455361366272\n",
      "Starting Epoch 25\n",
      "1.433975135286649\n",
      "Validation loss: 1.339877963066101\n",
      "mse 1.3398778603753958\n",
      "New best model found at epoch 25 with validation loss 1.339877963066101\n",
      "Starting Epoch 26\n",
      "1.4277047018210094\n",
      "Validation loss: 1.3341233730316162\n",
      "mse 1.3341233305608322\n",
      "New best model found at epoch 26 with validation loss 1.3341233730316162\n",
      "Starting Epoch 27\n",
      "1.4219422390063603\n",
      "Validation loss: 1.327775478363037\n",
      "mse 1.3277755638398325\n",
      "New best model found at epoch 27 with validation loss 1.327775478363037\n",
      "Starting Epoch 28\n",
      "1.4151394665241241\n",
      "Validation loss: 1.3240573406219482\n",
      "mse 1.3240573407038096\n",
      "New best model found at epoch 28 with validation loss 1.3240573406219482\n",
      "Starting Epoch 29\n",
      "1.4090601553519566\n",
      "Validation loss: 1.3209782838821411\n",
      "mse 1.3209782229485794\n",
      "New best model found at epoch 29 with validation loss 1.3209782838821411\n",
      "Starting Epoch 30\n",
      "1.4027675117055576\n",
      "Validation loss: 1.3146615028381348\n",
      "mse 1.3146615210308938\n",
      "New best model found at epoch 30 with validation loss 1.3146615028381348\n",
      "Starting Epoch 31\n",
      "1.3968453854322433\n",
      "Validation loss: 1.3089207410812378\n",
      "mse 1.3089207767613664\n",
      "New best model found at epoch 31 with validation loss 1.3089207410812378\n",
      "Starting Epoch 32\n",
      "1.3909502799312274\n",
      "Validation loss: 1.3040729761123657\n",
      "mse 1.3040729603391628\n",
      "New best model found at epoch 32 with validation loss 1.3040729761123657\n",
      "Starting Epoch 33\n",
      "1.3858541275064151\n",
      "Validation loss: 1.2986589670181274\n",
      "mse 1.2986590058326868\n",
      "New best model found at epoch 33 with validation loss 1.2986589670181274\n",
      "Starting Epoch 34\n",
      "1.3803525045514107\n",
      "Validation loss: 1.2952662706375122\n",
      "mse 1.2952662987561119\n",
      "New best model found at epoch 34 with validation loss 1.2952662706375122\n",
      "Starting Epoch 35\n",
      "1.3752835442622502\n",
      "Validation loss: 1.2902138233184814\n",
      "mse 1.2902138405750283\n",
      "New best model found at epoch 35 with validation loss 1.2902138233184814\n",
      "Starting Epoch 36\n",
      "1.370232107738654\n",
      "Validation loss: 1.2864094972610474\n",
      "mse 1.286409421841752\n",
      "New best model found at epoch 36 with validation loss 1.2864094972610474\n",
      "Starting Epoch 37\n",
      "1.3654607211550076\n",
      "Validation loss: 1.2824475765228271\n",
      "mse 1.28244752175495\n",
      "New best model found at epoch 37 with validation loss 1.2824475765228271\n",
      "Starting Epoch 38\n",
      "1.3606684903303783\n",
      "Validation loss: 1.2778316736221313\n",
      "mse 1.2778316076514458\n",
      "New best model found at epoch 38 with validation loss 1.2778316736221313\n",
      "Starting Epoch 39\n",
      "1.3562089949846268\n",
      "Validation loss: 1.2747231721878052\n",
      "mse 1.2747233492976875\n",
      "New best model found at epoch 39 with validation loss 1.2747231721878052\n",
      "Starting Epoch 40\n",
      "1.3516601870457332\n",
      "Validation loss: 1.2704721689224243\n",
      "mse 1.2704721928959959\n",
      "New best model found at epoch 40 with validation loss 1.2704721689224243\n",
      "Starting Epoch 41\n",
      "1.347071188191573\n",
      "Validation loss: 1.2674235105514526\n",
      "mse 1.2674234999826532\n",
      "New best model found at epoch 41 with validation loss 1.2674235105514526\n",
      "Starting Epoch 42\n",
      "1.3426852871974309\n",
      "Validation loss: 1.2638733386993408\n",
      "mse 1.2638732416781349\n",
      "New best model found at epoch 42 with validation loss 1.2638733386993408\n",
      "Starting Epoch 43\n",
      "1.338195525109768\n",
      "Validation loss: 1.2611912488937378\n",
      "mse 1.2611911705384884\n",
      "New best model found at epoch 43 with validation loss 1.2611912488937378\n",
      "Starting Epoch 44\n",
      "1.3342366814613342\n",
      "Validation loss: 1.2577811479568481\n",
      "mse 1.257781081235847\n",
      "New best model found at epoch 44 with validation loss 1.2577811479568481\n",
      "Starting Epoch 45\n",
      "1.330202413101991\n",
      "Validation loss: 1.25471830368042\n",
      "mse 1.2547183385159737\n",
      "New best model found at epoch 45 with validation loss 1.25471830368042\n",
      "Starting Epoch 46\n",
      "1.3261562610665958\n",
      "Validation loss: 1.2516013383865356\n",
      "mse 1.2516011307344406\n",
      "New best model found at epoch 46 with validation loss 1.2516013383865356\n",
      "Starting Epoch 47\n",
      "1.3222974240779877\n",
      "Validation loss: 1.2488292455673218\n",
      "mse 1.2488291605441126\n",
      "New best model found at epoch 47 with validation loss 1.2488292455673218\n",
      "Starting Epoch 48\n",
      "1.3182200441757839\n",
      "Validation loss: 1.2460861206054688\n",
      "mse 1.2460862650280278\n",
      "New best model found at epoch 48 with validation loss 1.2460861206054688\n",
      "Starting Epoch 49\n",
      "1.314703697959582\n",
      "Validation loss: 1.2431198358535767\n",
      "mse 1.243119667354253\n",
      "New best model found at epoch 49 with validation loss 1.2431198358535767\n",
      "Starting Epoch 50\n",
      "1.3107413053512573\n",
      "Validation loss: 1.2399038076400757\n",
      "mse 1.239903866103228\n",
      "New best model found at epoch 50 with validation loss 1.2399038076400757\n",
      "Starting Epoch 51\n",
      "1.3067257056633632\n",
      "Validation loss: 1.2381850481033325\n",
      "mse 1.2381850266024974\n",
      "New best model found at epoch 51 with validation loss 1.2381850481033325\n",
      "Starting Epoch 52\n",
      "1.3028125688433647\n",
      "Validation loss: 1.2346165180206299\n",
      "mse 1.234616566619686\n",
      "New best model found at epoch 52 with validation loss 1.2346165180206299\n",
      "Starting Epoch 53\n",
      "1.298974687854449\n",
      "Validation loss: 1.2325408458709717\n",
      "mse 1.2325408595163385\n",
      "New best model found at epoch 53 with validation loss 1.2325408458709717\n",
      "Starting Epoch 54\n",
      "1.2958422303199768\n",
      "Validation loss: 1.2302629947662354\n",
      "mse 1.2302629487568713\n",
      "New best model found at epoch 54 with validation loss 1.2302629947662354\n",
      "Starting Epoch 55\n",
      "1.2923848380645115\n",
      "Validation loss: 1.2277878522872925\n",
      "mse 1.2277878628798924\n",
      "New best model found at epoch 55 with validation loss 1.2277878522872925\n",
      "Starting Epoch 56\n",
      "1.28918311248223\n",
      "Validation loss: 1.2260838747024536\n",
      "mse 1.2260837864502019\n",
      "New best model found at epoch 56 with validation loss 1.2260838747024536\n",
      "Starting Epoch 57\n",
      "1.28599667797486\n",
      "Validation loss: 1.2241770029067993\n",
      "mse 1.2241770359407136\n",
      "New best model found at epoch 57 with validation loss 1.2241770029067993\n",
      "Starting Epoch 58\n",
      "1.282965620358785\n",
      "Validation loss: 1.2222739458084106\n",
      "mse 1.2222738424703394\n",
      "New best model found at epoch 58 with validation loss 1.2222739458084106\n",
      "Starting Epoch 59\n",
      "1.2799424628416698\n",
      "Validation loss: 1.2199479341506958\n",
      "mse 1.2199478843706733\n",
      "New best model found at epoch 59 with validation loss 1.2199479341506958\n",
      "Starting Epoch 60\n",
      "1.276973011593024\n",
      "Validation loss: 1.218626618385315\n",
      "mse 1.2186265241363137\n",
      "New best model found at epoch 60 with validation loss 1.218626618385315\n",
      "Starting Epoch 61\n",
      "1.274013802409172\n",
      "Validation loss: 1.2164968252182007\n",
      "mse 1.216496896499789\n",
      "New best model found at epoch 61 with validation loss 1.2164968252182007\n",
      "Starting Epoch 62\n",
      "1.2710783655444782\n",
      "Validation loss: 1.214972734451294\n",
      "mse 1.2149725333610575\n",
      "New best model found at epoch 62 with validation loss 1.214972734451294\n",
      "Starting Epoch 63\n",
      "1.2683119227488835\n",
      "Validation loss: 1.212874174118042\n",
      "mse 1.2128740792201154\n",
      "New best model found at epoch 63 with validation loss 1.212874174118042\n",
      "Starting Epoch 64\n",
      "1.265771711866061\n",
      "Validation loss: 1.2117019891738892\n",
      "mse 1.211701949755886\n",
      "New best model found at epoch 64 with validation loss 1.2117019891738892\n",
      "Starting Epoch 65\n",
      "1.2630130623777707\n",
      "Validation loss: 1.21042799949646\n",
      "mse 1.2104279378559621\n",
      "New best model found at epoch 65 with validation loss 1.21042799949646\n",
      "Starting Epoch 66\n",
      "1.2606309701999028\n",
      "Validation loss: 1.2092642784118652\n",
      "mse 1.2092642440342987\n",
      "New best model found at epoch 66 with validation loss 1.2092642784118652\n",
      "Starting Epoch 67\n",
      "1.2580021570126216\n",
      "Validation loss: 1.2077080011367798\n",
      "mse 1.2077079936058035\n",
      "New best model found at epoch 67 with validation loss 1.2077080011367798\n",
      "Starting Epoch 68\n",
      "1.2554904694358509\n",
      "Validation loss: 1.2069376707077026\n",
      "mse 1.2069376711593638\n",
      "New best model found at epoch 68 with validation loss 1.2069376707077026\n",
      "Starting Epoch 69\n",
      "1.253148968021075\n",
      "Validation loss: 1.2058100700378418\n",
      "mse 1.2058100442110682\n",
      "New best model found at epoch 69 with validation loss 1.2058100700378418\n",
      "Starting Epoch 70\n",
      "1.2509230822324753\n",
      "Validation loss: 1.2040408849716187\n",
      "mse 1.204040902364936\n",
      "New best model found at epoch 70 with validation loss 1.2040408849716187\n",
      "Starting Epoch 71\n",
      "1.2485293745994568\n",
      "Validation loss: 1.2032439708709717\n",
      "mse 1.2032439705214217\n",
      "New best model found at epoch 71 with validation loss 1.2032439708709717\n",
      "Starting Epoch 72\n",
      "1.2463202873865764\n",
      "Validation loss: 1.2017418146133423\n",
      "mse 1.2017417834327533\n",
      "New best model found at epoch 72 with validation loss 1.2017418146133423\n",
      "Starting Epoch 73\n",
      "1.2439130917191505\n",
      "Validation loss: 1.2010353803634644\n",
      "mse 1.2010353831424208\n",
      "New best model found at epoch 73 with validation loss 1.2010353803634644\n",
      "Starting Epoch 74\n",
      "1.2420511469244957\n",
      "Validation loss: 1.2000200748443604\n",
      "mse 1.2000201576380793\n",
      "New best model found at epoch 74 with validation loss 1.2000200748443604\n",
      "Starting Epoch 75\n",
      "1.2399649272362392\n",
      "Validation loss: 1.1986925601959229\n",
      "mse 1.198692608920732\n",
      "New best model found at epoch 75 with validation loss 1.1986925601959229\n",
      "Starting Epoch 76\n",
      "1.237748531003793\n",
      "Validation loss: 1.1975153684616089\n",
      "mse 1.197515407792781\n",
      "New best model found at epoch 76 with validation loss 1.1975153684616089\n",
      "Starting Epoch 77\n",
      "1.235935350259145\n",
      "Validation loss: 1.1971604824066162\n",
      "mse 1.19716052140563\n",
      "New best model found at epoch 77 with validation loss 1.1971604824066162\n",
      "Starting Epoch 78\n",
      "1.234044390420119\n",
      "Validation loss: 1.1962594985961914\n",
      "mse 1.1962594937443702\n",
      "New best model found at epoch 78 with validation loss 1.1962594985961914\n",
      "Starting Epoch 79\n",
      "1.2320669665932655\n",
      "Validation loss: 1.1952635049819946\n",
      "mse 1.1952635055163325\n",
      "New best model found at epoch 79 with validation loss 1.1952635049819946\n",
      "Starting Epoch 80\n",
      "1.230256048341592\n",
      "Validation loss: 1.1943095922470093\n",
      "mse 1.1943094937737526\n",
      "New best model found at epoch 80 with validation loss 1.1943095922470093\n",
      "Starting Epoch 81\n",
      "1.2284570659200351\n",
      "Validation loss: 1.1941981315612793\n",
      "mse 1.1941981503112125\n",
      "New best model found at epoch 81 with validation loss 1.1941981315612793\n",
      "Starting Epoch 82\n",
      "1.2266614759961765\n",
      "Validation loss: 1.1928173303604126\n",
      "mse 1.1928173192342908\n",
      "New best model found at epoch 82 with validation loss 1.1928173303604126\n",
      "Starting Epoch 83\n",
      "1.2248770544926326\n",
      "Validation loss: 1.19235360622406\n",
      "mse 1.1923537096288976\n",
      "New best model found at epoch 83 with validation loss 1.19235360622406\n",
      "Starting Epoch 84\n",
      "1.2232040390372276\n",
      "Validation loss: 1.192321538925171\n",
      "mse 1.1923216477058372\n",
      "New best model found at epoch 84 with validation loss 1.192321538925171\n",
      "Starting Epoch 85\n",
      "1.2215126926700275\n",
      "Validation loss: 1.1913626194000244\n",
      "mse 1.1913626518834435\n",
      "New best model found at epoch 85 with validation loss 1.1913626194000244\n",
      "Starting Epoch 86\n",
      "1.219994346300761\n",
      "Validation loss: 1.1906349658966064\n",
      "mse 1.1906349893747055\n",
      "New best model found at epoch 86 with validation loss 1.1906349658966064\n",
      "Starting Epoch 87\n",
      "1.2184059396386147\n",
      "Validation loss: 1.1903101205825806\n",
      "mse 1.1903101451318967\n",
      "New best model found at epoch 87 with validation loss 1.1903101205825806\n",
      "Starting Epoch 88\n",
      "1.2167794704437256\n",
      "Validation loss: 1.1901276111602783\n",
      "mse 1.1901275379787861\n",
      "New best model found at epoch 88 with validation loss 1.1901276111602783\n",
      "Starting Epoch 89\n",
      "1.2153735632697742\n",
      "Validation loss: 1.1892684698104858\n",
      "mse 1.18926838558324\n",
      "New best model found at epoch 89 with validation loss 1.1892684698104858\n",
      "Starting Epoch 90\n",
      "1.213804468512535\n",
      "Validation loss: 1.1897356510162354\n",
      "mse 1.1897357566529807\n",
      "Starting Epoch 91\n",
      "1.2126141488552094\n",
      "Validation loss: 1.1881747245788574\n",
      "mse 1.18817474292794\n",
      "New best model found at epoch 91 with validation loss 1.1881747245788574\n",
      "Starting Epoch 92\n",
      "1.2111118684212367\n",
      "Validation loss: 1.1883388757705688\n",
      "mse 1.1883388834281015\n",
      "Starting Epoch 93\n",
      "1.2098539844155312\n",
      "Validation loss: 1.1873669624328613\n",
      "mse 1.1873669880950117\n",
      "New best model found at epoch 93 with validation loss 1.1873669624328613\n",
      "Starting Epoch 94\n",
      "1.2082831958929698\n",
      "Validation loss: 1.1874765157699585\n",
      "mse 1.1874765283624789\n",
      "Starting Epoch 95\n",
      "1.2070003698269527\n",
      "Validation loss: 1.1869503259658813\n",
      "mse 1.1869504348309459\n",
      "New best model found at epoch 95 with validation loss 1.1869503259658813\n",
      "Starting Epoch 96\n",
      "1.2053867131471634\n",
      "Validation loss: 1.1863641738891602\n",
      "mse 1.186364172049624\n",
      "New best model found at epoch 96 with validation loss 1.1863641738891602\n",
      "Starting Epoch 97\n",
      "1.2038421034812927\n",
      "Validation loss: 1.1861220598220825\n",
      "mse 1.1861219861576489\n",
      "New best model found at epoch 97 with validation loss 1.1861220598220825\n",
      "Starting Epoch 98\n",
      "1.2022520303726196\n",
      "Validation loss: 1.1861621141433716\n",
      "mse 1.186162108659649\n",
      "Starting Epoch 99\n",
      "1.200774038831393\n",
      "Validation loss: 1.1851927042007446\n",
      "mse 1.1851928237653337\n",
      "New best model found at epoch 99 with validation loss 1.1851927042007446\n",
      "Starting Epoch 100\n",
      "1.199444351096948\n",
      "Validation loss: 1.1850656270980835\n",
      "mse 1.1850655251111823\n",
      "New best model found at epoch 100 with validation loss 1.1850656270980835\n",
      "Starting Epoch 101\n",
      "1.1976915324727695\n",
      "Validation loss: 1.185364007949829\n",
      "mse 1.1853639420861386\n",
      "Starting Epoch 102\n",
      "1.1957052027185757\n",
      "Validation loss: 1.1851615905761719\n",
      "mse 1.185161698701057\n",
      "Starting Epoch 103\n",
      "1.1936878636479378\n",
      "Validation loss: 1.1839361190795898\n",
      "mse 1.1839361303147362\n",
      "New best model found at epoch 103 with validation loss 1.1839361190795898\n",
      "Starting Epoch 104\n",
      "1.1921679402391117\n",
      "Validation loss: 1.183194637298584\n",
      "mse 1.1831946031831329\n",
      "New best model found at epoch 104 with validation loss 1.183194637298584\n",
      "Starting Epoch 105\n",
      "1.190301850438118\n",
      "Validation loss: 1.1833335161209106\n",
      "mse 1.183333522328497\n",
      "Starting Epoch 106\n",
      "1.1890660996238391\n",
      "Validation loss: 1.1828687191009521\n",
      "mse 1.1828686155404047\n",
      "New best model found at epoch 106 with validation loss 1.1828687191009521\n",
      "Starting Epoch 107\n",
      "1.187548540532589\n",
      "Validation loss: 1.1828362941741943\n",
      "mse 1.1828363747251038\n",
      "New best model found at epoch 107 with validation loss 1.1828362941741943\n",
      "Starting Epoch 108\n",
      "1.1861342762907345\n",
      "Validation loss: 1.1824095249176025\n",
      "mse 1.1824094990562042\n",
      "New best model found at epoch 108 with validation loss 1.1824095249176025\n",
      "Starting Epoch 109\n",
      "1.184705764055252\n",
      "Validation loss: 1.1816816329956055\n",
      "mse 1.18168171344366\n",
      "New best model found at epoch 109 with validation loss 1.1816816329956055\n",
      "Starting Epoch 110\n",
      "1.1834251483281453\n",
      "Validation loss: 1.181462287902832\n",
      "mse 1.1814622429835693\n",
      "New best model found at epoch 110 with validation loss 1.181462287902832\n",
      "Starting Epoch 111\n",
      "1.1821322614947956\n",
      "Validation loss: 1.1810392141342163\n",
      "mse 1.1810392327596533\n",
      "New best model found at epoch 111 with validation loss 1.1810392141342163\n",
      "Starting Epoch 112\n",
      "1.181184100608031\n",
      "Validation loss: 1.1811281442642212\n",
      "mse 1.1811281908591127\n",
      "Starting Epoch 113\n",
      "1.1797405257821083\n",
      "Validation loss: 1.1804990768432617\n",
      "mse 1.180499028758836\n",
      "New best model found at epoch 113 with validation loss 1.1804990768432617\n",
      "Starting Epoch 114\n",
      "1.1787417779366176\n",
      "Validation loss: 1.1800578832626343\n",
      "mse 1.1800579231177595\n",
      "New best model found at epoch 114 with validation loss 1.1800578832626343\n",
      "Starting Epoch 115\n",
      "1.1775216460227966\n",
      "Validation loss: 1.1805013418197632\n",
      "mse 1.1805013514827765\n",
      "Starting Epoch 116\n",
      "1.1762027169267337\n",
      "Validation loss: 1.1796038150787354\n",
      "mse 1.1796037478208614\n",
      "New best model found at epoch 116 with validation loss 1.1796038150787354\n",
      "Starting Epoch 117\n",
      "1.1751414313912392\n",
      "Validation loss: 1.1791492700576782\n",
      "mse 1.1791491808995267\n",
      "New best model found at epoch 117 with validation loss 1.1791492700576782\n",
      "Starting Epoch 118\n",
      "1.1742549017071724\n",
      "Validation loss: 1.1787713766098022\n",
      "mse 1.1787712332018083\n",
      "New best model found at epoch 118 with validation loss 1.1787713766098022\n",
      "Starting Epoch 119\n",
      "1.1730397840340931\n",
      "Validation loss: 1.179360032081604\n",
      "mse 1.179360072002677\n",
      "Starting Epoch 120\n",
      "1.1721351121862729\n",
      "Validation loss: 1.1786096096038818\n",
      "mse 1.1786095676548451\n",
      "New best model found at epoch 120 with validation loss 1.1786096096038818\n",
      "Starting Epoch 121\n",
      "1.170917232831319\n",
      "Validation loss: 1.17817223072052\n",
      "mse 1.1781722331787974\n",
      "New best model found at epoch 121 with validation loss 1.17817223072052\n",
      "Starting Epoch 122\n",
      "1.169956550002098\n",
      "Validation loss: 1.1781847476959229\n",
      "mse 1.1781847844158657\n",
      "Starting Epoch 123\n",
      "1.169000007212162\n",
      "Validation loss: 1.1778024435043335\n",
      "mse 1.1778025755992936\n",
      "New best model found at epoch 123 with validation loss 1.1778024435043335\n",
      "Starting Epoch 124\n",
      "1.1680320079127948\n",
      "Validation loss: 1.1781437397003174\n",
      "mse 1.1781437097849274\n",
      "Starting Epoch 125\n",
      "1.1671304181218147\n",
      "Validation loss: 1.1777182817459106\n",
      "mse 1.177718343631263\n",
      "New best model found at epoch 125 with validation loss 1.1777182817459106\n",
      "Starting Epoch 126\n",
      "1.1650142321983974\n",
      "Validation loss: 1.1775707006454468\n",
      "mse 1.177570776017801\n",
      "New best model found at epoch 126 with validation loss 1.1775707006454468\n",
      "Starting Epoch 127\n",
      "1.1634907374779384\n",
      "Validation loss: 1.176932692527771\n",
      "mse 1.1769327061904507\n",
      "New best model found at epoch 127 with validation loss 1.176932692527771\n",
      "Starting Epoch 128\n",
      "1.162038231889407\n",
      "Validation loss: 1.1773838996887207\n",
      "mse 1.177383845237546\n",
      "Starting Epoch 129\n",
      "1.1605623587965965\n",
      "Validation loss: 1.1771446466445923\n",
      "mse 1.177144691080868\n",
      "Starting Epoch 130\n",
      "1.1595364933212597\n",
      "Validation loss: 1.1769089698791504\n",
      "mse 1.1769088692023062\n",
      "New best model found at epoch 130 with validation loss 1.1769089698791504\n",
      "Starting Epoch 131\n",
      "1.1586825052897136\n",
      "Validation loss: 1.1764559745788574\n",
      "mse 1.1764560646126654\n",
      "New best model found at epoch 131 with validation loss 1.1764559745788574\n",
      "Starting Epoch 132\n",
      "1.1575797299544017\n",
      "Validation loss: 1.1768667697906494\n",
      "mse 1.1768666802257213\n",
      "Starting Epoch 133\n",
      "1.1566759943962097\n",
      "Validation loss: 1.176891565322876\n",
      "mse 1.1768915882061945\n",
      "Starting Epoch 134\n",
      "1.155653255681197\n",
      "Validation loss: 1.1751022338867188\n",
      "mse 1.1751021468292864\n",
      "New best model found at epoch 134 with validation loss 1.1751022338867188\n",
      "Starting Epoch 135\n",
      "1.1546857506036758\n",
      "Validation loss: 1.1750956773757935\n",
      "mse 1.1750956957168286\n",
      "New best model found at epoch 135 with validation loss 1.1750956773757935\n",
      "Starting Epoch 136\n",
      "1.1539304976662\n",
      "Validation loss: 1.1750059127807617\n",
      "mse 1.1750059586730255\n",
      "New best model found at epoch 136 with validation loss 1.1750059127807617\n",
      "Starting Epoch 137\n",
      "1.1526491021116574\n",
      "Validation loss: 1.174375057220459\n",
      "mse 1.1743750177481869\n",
      "New best model found at epoch 137 with validation loss 1.174375057220459\n",
      "Starting Epoch 138\n",
      "1.15182310094436\n",
      "Validation loss: 1.1746854782104492\n",
      "mse 1.1746854375629219\n",
      "Starting Epoch 139\n",
      "1.151065727074941\n",
      "Validation loss: 1.1746422052383423\n",
      "mse 1.1746421768640372\n",
      "Starting Epoch 140\n",
      "1.150225428243478\n",
      "Validation loss: 1.1743409633636475\n",
      "mse 1.1743410940923118\n",
      "New best model found at epoch 140 with validation loss 1.1743409633636475\n",
      "Starting Epoch 141\n",
      "1.1494238550464313\n",
      "Validation loss: 1.1740120649337769\n",
      "mse 1.1740120969788577\n",
      "New best model found at epoch 141 with validation loss 1.1740120649337769\n",
      "Starting Epoch 142\n",
      "1.148733248313268\n",
      "Validation loss: 1.173949956893921\n",
      "mse 1.1739500173349036\n",
      "New best model found at epoch 142 with validation loss 1.173949956893921\n",
      "Starting Epoch 143\n",
      "1.1477717061837514\n",
      "Validation loss: 1.1734458208084106\n",
      "mse 1.173445797254576\n",
      "New best model found at epoch 143 with validation loss 1.1734458208084106\n",
      "Starting Epoch 144\n",
      "1.1467255701621373\n",
      "Validation loss: 1.1736979484558105\n",
      "mse 1.1736978255385857\n",
      "Starting Epoch 145\n",
      "1.1459976012508075\n",
      "Validation loss: 1.173715591430664\n",
      "mse 1.1737154258754816\n",
      "Starting Epoch 146\n",
      "1.1453495745857556\n",
      "Validation loss: 1.1733132600784302\n",
      "mse 1.1733133178952155\n",
      "New best model found at epoch 146 with validation loss 1.1733132600784302\n",
      "Starting Epoch 147\n",
      "1.1444196725885074\n",
      "Validation loss: 1.1727265119552612\n",
      "mse 1.1727264853736088\n",
      "New best model found at epoch 147 with validation loss 1.1727265119552612\n",
      "Starting Epoch 148\n",
      "1.1437140951553981\n",
      "Validation loss: 1.1729304790496826\n",
      "mse 1.1729307203276487\n",
      "Starting Epoch 149\n",
      "1.1429717416564624\n",
      "Validation loss: 1.172581434249878\n",
      "mse 1.172581527180131\n",
      "New best model found at epoch 149 with validation loss 1.172581434249878\n",
      "Starting Epoch 150\n",
      "1.142098734776179\n",
      "Validation loss: 1.173068881034851\n",
      "mse 1.1730688486789727\n",
      "Starting Epoch 151\n",
      "1.141164335111777\n",
      "Validation loss: 1.1733392477035522\n",
      "mse 1.173339229877343\n",
      "Starting Epoch 152\n",
      "1.1403605863451958\n",
      "Validation loss: 1.1725566387176514\n",
      "mse 1.172556647727407\n",
      "New best model found at epoch 152 with validation loss 1.1725566387176514\n",
      "Starting Epoch 153\n",
      "1.1394853293895721\n",
      "Validation loss: 1.1727193593978882\n",
      "mse 1.1727193436496077\n",
      "Starting Epoch 154\n",
      "1.1386884326736133\n",
      "Validation loss: 1.1727780103683472\n",
      "mse 1.1727780438256754\n",
      "Starting Epoch 155\n",
      "1.137885349492232\n",
      "Validation loss: 1.1730870008468628\n",
      "mse 1.1730869814167035\n",
      "Starting Epoch 156\n",
      "1.136898842950662\n",
      "Validation loss: 1.1731358766555786\n",
      "mse 1.1731358722928316\n",
      "Starting Epoch 157\n",
      "1.136202332874139\n",
      "Validation loss: 1.172571063041687\n",
      "mse 1.1725710722621059\n",
      "Starting Epoch 158\n",
      "1.135217048227787\n",
      "Validation loss: 1.1723170280456543\n",
      "mse 1.1723170414123447\n",
      "New best model found at epoch 158 with validation loss 1.1723170280456543\n",
      "Starting Epoch 159\n",
      "1.1346046750744183\n",
      "Validation loss: 1.1720274686813354\n",
      "mse 1.1720274315910635\n",
      "New best model found at epoch 159 with validation loss 1.1720274686813354\n",
      "Starting Epoch 160\n",
      "1.1337893903255463\n",
      "Validation loss: 1.1725436449050903\n",
      "mse 1.1725436785872727\n",
      "Starting Epoch 161\n",
      "1.133223849038283\n",
      "Validation loss: 1.171693205833435\n",
      "mse 1.171693288934338\n",
      "New best model found at epoch 161 with validation loss 1.171693205833435\n",
      "Starting Epoch 162\n",
      "1.1321823249260585\n",
      "Validation loss: 1.1724456548690796\n",
      "mse 1.1724457650634232\n",
      "Starting Epoch 163\n",
      "1.131766843299071\n",
      "Validation loss: 1.1708755493164062\n",
      "mse 1.1708754622116473\n",
      "New best model found at epoch 163 with validation loss 1.1708755493164062\n",
      "Starting Epoch 164\n",
      "1.13074791431427\n",
      "Validation loss: 1.171746015548706\n",
      "mse 1.1717459720437837\n",
      "Starting Epoch 165\n",
      "1.1303331802288692\n",
      "Validation loss: 1.1714811325073242\n",
      "mse 1.1714809114650506\n",
      "Starting Epoch 166\n",
      "1.1294011423985164\n",
      "Validation loss: 1.1717525720596313\n",
      "mse 1.1717526933243585\n",
      "Starting Epoch 167\n",
      "1.1288275321324666\n",
      "Validation loss: 1.1712955236434937\n",
      "mse 1.1712955852097777\n",
      "Starting Epoch 168\n",
      "1.1279529233773549\n",
      "Validation loss: 1.17091965675354\n",
      "mse 1.1709196747039556\n",
      "Starting Epoch 169\n",
      "1.1274284919102986\n",
      "Validation loss: 1.1711055040359497\n",
      "mse 1.1711055945900641\n",
      "Starting Epoch 170\n",
      "1.1266993209719658\n",
      "Validation loss: 1.1710243225097656\n",
      "mse 1.1710242563960087\n",
      "Starting Epoch 171\n",
      "1.1259816015760105\n",
      "Validation loss: 1.171075701713562\n",
      "mse 1.171075636764684\n",
      "Starting Epoch 172\n",
      "1.1255387266476948\n",
      "Validation loss: 1.1709874868392944\n",
      "mse 1.1709875294269396\n",
      "Starting Epoch 173\n",
      "1.1246710767348607\n",
      "Validation loss: 1.1711360216140747\n",
      "mse 1.1711360846865932\n",
      "Starting Epoch 174\n",
      "1.1240696782867114\n",
      "Validation loss: 1.171015739440918\n",
      "mse 1.1710156641816147\n",
      "Starting Epoch 175\n",
      "1.1233822653690975\n",
      "Validation loss: 1.170974850654602\n",
      "mse 1.1709748419479624\n",
      "Starting Epoch 176\n",
      "1.1226446131865184\n",
      "Validation loss: 1.1711536645889282\n",
      "mse 1.1711537303381745\n",
      "Starting Epoch 177\n",
      "1.1221842591961224\n",
      "Validation loss: 1.170575499534607\n",
      "mse 1.1705754592727833\n",
      "New best model found at epoch 177 with validation loss 1.170575499534607\n",
      "Starting Epoch 178\n",
      "1.121562972664833\n",
      "Validation loss: 1.170719027519226\n",
      "mse 1.1707189985962645\n",
      "Starting Epoch 179\n",
      "1.1209005936980247\n",
      "Validation loss: 1.1706295013427734\n",
      "mse 1.1706296048095346\n",
      "Starting Epoch 180\n",
      "1.1200168256958325\n",
      "Validation loss: 1.1709132194519043\n",
      "mse 1.1709132778601\n",
      "Starting Epoch 181\n",
      "1.1195852706829708\n",
      "Validation loss: 1.1703413724899292\n",
      "mse 1.1703413436243395\n",
      "New best model found at epoch 181 with validation loss 1.1703413724899292\n",
      "Starting Epoch 182\n",
      "1.119043305516243\n",
      "Validation loss: 1.1705284118652344\n",
      "mse 1.1705283624001308\n",
      "Starting Epoch 183\n",
      "1.1182765141129494\n",
      "Validation loss: 1.1701419353485107\n",
      "mse 1.1701418369688628\n",
      "New best model found at epoch 183 with validation loss 1.1701419353485107\n",
      "Starting Epoch 184\n",
      "1.1177180334925652\n",
      "Validation loss: 1.1698076725006104\n",
      "mse 1.16980762269657\n",
      "New best model found at epoch 184 with validation loss 1.1698076725006104\n",
      "Starting Epoch 185\n",
      "1.1169908468921979\n",
      "Validation loss: 1.1700129508972168\n",
      "mse 1.1700129740429697\n",
      "Starting Epoch 186\n",
      "1.11668765048186\n",
      "Validation loss: 1.17026948928833\n",
      "mse 1.170269544758885\n",
      "Starting Epoch 187\n",
      "1.116007501880328\n",
      "Validation loss: 1.1695208549499512\n",
      "mse 1.169520882237042\n",
      "New best model found at epoch 187 with validation loss 1.1695208549499512\n",
      "Starting Epoch 188\n",
      "1.115137164791425\n",
      "Validation loss: 1.1698100566864014\n",
      "mse 1.169809994560848\n",
      "Starting Epoch 189\n",
      "1.1145390917857487\n",
      "Validation loss: 1.1700880527496338\n",
      "mse 1.1700880088402899\n",
      "Starting Epoch 190\n",
      "1.113961711525917\n",
      "Validation loss: 1.169094204902649\n",
      "mse 1.1690941297592372\n",
      "New best model found at epoch 190 with validation loss 1.169094204902649\n",
      "Starting Epoch 191\n",
      "1.1131626690427463\n",
      "Validation loss: 1.1692014932632446\n",
      "mse 1.169201462071395\n",
      "Starting Epoch 192\n",
      "1.1124939645330112\n",
      "Validation loss: 1.16905677318573\n",
      "mse 1.1690566972199883\n",
      "New best model found at epoch 192 with validation loss 1.16905677318573\n",
      "Starting Epoch 193\n",
      "1.1121344690521557\n",
      "Validation loss: 1.169089913368225\n",
      "mse 1.169089772743068\n",
      "Starting Epoch 194\n",
      "1.1112753227353096\n",
      "Validation loss: 1.1691441535949707\n",
      "mse 1.1691440892609524\n",
      "Starting Epoch 195\n",
      "1.1108098675807316\n",
      "Validation loss: 1.168923258781433\n",
      "mse 1.1689232202107755\n",
      "New best model found at epoch 195 with validation loss 1.168923258781433\n",
      "Starting Epoch 196\n",
      "1.110296296576659\n",
      "Validation loss: 1.1688841581344604\n",
      "mse 1.1688841466393876\n",
      "New best model found at epoch 196 with validation loss 1.1688841581344604\n",
      "Starting Epoch 197\n",
      "1.1096239760518074\n",
      "Validation loss: 1.1691076755523682\n",
      "mse 1.1691076633829958\n",
      "Starting Epoch 198\n",
      "1.109034004310767\n",
      "Validation loss: 1.1688212156295776\n",
      "mse 1.168821258934954\n",
      "New best model found at epoch 198 with validation loss 1.1688212156295776\n",
      "Starting Epoch 199\n",
      "1.1086339950561523\n",
      "Validation loss: 1.168613076210022\n",
      "mse 1.1686131067100767\n",
      "New best model found at epoch 199 with validation loss 1.168613076210022\n",
      "Starting Epoch 200\n",
      "1.1078625942269962\n",
      "Validation loss: 1.168203353881836\n",
      "mse 1.1682033055176455\n",
      "New best model found at epoch 200 with validation loss 1.168203353881836\n",
      "Starting Epoch 201\n",
      "1.1073503916462262\n",
      "Validation loss: 1.1686065196990967\n",
      "mse 1.168606503471603\n",
      "Starting Epoch 202\n",
      "1.1069745272397995\n",
      "Validation loss: 1.1682108640670776\n",
      "mse 1.1682107146919403\n",
      "Starting Epoch 203\n",
      "1.10616435110569\n",
      "Validation loss: 1.1684279441833496\n",
      "mse 1.1684279356501863\n",
      "Starting Epoch 204\n",
      "1.105614684522152\n",
      "Validation loss: 1.1682356595993042\n",
      "mse 1.1682356453155607\n",
      "Starting Epoch 205\n",
      "1.1049746225277584\n",
      "Validation loss: 1.1686562299728394\n",
      "mse 1.1686563096170626\n",
      "Starting Epoch 206\n",
      "1.1045552665988605\n",
      "Validation loss: 1.1684668064117432\n",
      "mse 1.1684668728929055\n",
      "Starting Epoch 207\n",
      "1.10394453505675\n",
      "Validation loss: 1.1685534715652466\n",
      "mse 1.1685534212682958\n",
      "Starting Epoch 208\n",
      "1.1036147251725197\n",
      "Validation loss: 1.1680980920791626\n",
      "mse 1.168098105458141\n",
      "New best model found at epoch 208 with validation loss 1.1680980920791626\n",
      "Starting Epoch 209\n",
      "1.102822517355283\n",
      "Validation loss: 1.1676901578903198\n",
      "mse 1.1676901040699177\n",
      "New best model found at epoch 209 with validation loss 1.1676901578903198\n",
      "Starting Epoch 210\n",
      "1.102283127605915\n",
      "Validation loss: 1.1679396629333496\n",
      "mse 1.1679397504190947\n",
      "Starting Epoch 211\n",
      "1.102028099199136\n",
      "Validation loss: 1.1678329706192017\n",
      "mse 1.1678329679080754\n",
      "Starting Epoch 212\n",
      "1.1013749837875366\n",
      "Validation loss: 1.167556643486023\n",
      "mse 1.167556624379622\n",
      "New best model found at epoch 212 with validation loss 1.167556643486023\n",
      "Starting Epoch 213\n",
      "1.1008560930689175\n",
      "Validation loss: 1.167207956314087\n",
      "mse 1.1672080487294818\n",
      "New best model found at epoch 213 with validation loss 1.167207956314087\n",
      "Starting Epoch 214\n",
      "1.1002036134401958\n",
      "Validation loss: 1.1672165393829346\n",
      "mse 1.1672166086745626\n",
      "Starting Epoch 215\n",
      "1.0996500477194786\n",
      "Validation loss: 1.1672405004501343\n",
      "mse 1.1672405613732317\n",
      "Starting Epoch 216\n",
      "1.0991233984629314\n",
      "Validation loss: 1.1669445037841797\n",
      "mse 1.1669445562337564\n",
      "New best model found at epoch 216 with validation loss 1.1669445037841797\n",
      "Starting Epoch 217\n",
      "1.09872055798769\n",
      "Validation loss: 1.1665431261062622\n",
      "mse 1.1665432342945277\n",
      "New best model found at epoch 217 with validation loss 1.1665431261062622\n",
      "Starting Epoch 218\n",
      "1.098071592549483\n",
      "Validation loss: 1.1667672395706177\n",
      "mse 1.1667670336281424\n",
      "Starting Epoch 219\n",
      "1.0976089512308438\n",
      "Validation loss: 1.1662380695343018\n",
      "mse 1.166238035460463\n",
      "New best model found at epoch 219 with validation loss 1.1662380695343018\n",
      "Starting Epoch 220\n",
      "1.096852384507656\n",
      "Validation loss: 1.1664272546768188\n",
      "mse 1.166427327103061\n",
      "Starting Epoch 221\n",
      "1.0964328174789746\n",
      "Validation loss: 1.1660984754562378\n",
      "mse 1.1660983480864828\n",
      "New best model found at epoch 221 with validation loss 1.1660984754562378\n",
      "Starting Epoch 222\n",
      "1.095978741844495\n",
      "Validation loss: 1.1654858589172363\n",
      "mse 1.16548593290062\n",
      "New best model found at epoch 222 with validation loss 1.1654858589172363\n",
      "Starting Epoch 223\n",
      "1.0954082757234573\n",
      "Validation loss: 1.165052056312561\n",
      "mse 1.1650521470602084\n",
      "New best model found at epoch 223 with validation loss 1.165052056312561\n",
      "Starting Epoch 224\n",
      "1.0946851919094722\n",
      "Validation loss: 1.1649508476257324\n",
      "mse 1.1649509478747075\n",
      "New best model found at epoch 224 with validation loss 1.1649508476257324\n",
      "Starting Epoch 225\n",
      "1.094265140593052\n",
      "Validation loss: 1.1647030115127563\n",
      "mse 1.164703103710988\n",
      "New best model found at epoch 225 with validation loss 1.1647030115127563\n",
      "Starting Epoch 226\n",
      "1.0936778287092845\n",
      "Validation loss: 1.1649173498153687\n",
      "mse 1.1649173483565827\n",
      "Starting Epoch 227\n",
      "1.0930735195676486\n",
      "Validation loss: 1.1645642518997192\n",
      "mse 1.1645642164884642\n",
      "New best model found at epoch 227 with validation loss 1.1645642518997192\n",
      "Starting Epoch 228\n",
      "1.092759686211745\n",
      "Validation loss: 1.1643117666244507\n",
      "mse 1.1643116209974103\n",
      "New best model found at epoch 228 with validation loss 1.1643117666244507\n",
      "Starting Epoch 229\n",
      "1.0921242212255795\n",
      "Validation loss: 1.163833737373352\n",
      "mse 1.1638337458372194\n",
      "New best model found at epoch 229 with validation loss 1.163833737373352\n",
      "Starting Epoch 230\n",
      "1.0918071220318477\n",
      "Validation loss: 1.1640459299087524\n",
      "mse 1.1640460571750961\n",
      "Starting Epoch 231\n",
      "1.0912917430202167\n",
      "Validation loss: 1.1636097431182861\n",
      "mse 1.1636098289527177\n",
      "New best model found at epoch 231 with validation loss 1.1636097431182861\n",
      "Starting Epoch 232\n",
      "1.0906798044840496\n",
      "Validation loss: 1.163450837135315\n",
      "mse 1.163450676177134\n",
      "New best model found at epoch 232 with validation loss 1.163450837135315\n",
      "Starting Epoch 233\n",
      "1.0903962751229603\n",
      "Validation loss: 1.1635206937789917\n",
      "mse 1.1635207317599603\n",
      "Starting Epoch 234\n",
      "1.0898361603418987\n",
      "Validation loss: 1.163157343864441\n",
      "mse 1.1631572715567369\n",
      "New best model found at epoch 234 with validation loss 1.163157343864441\n",
      "Starting Epoch 235\n",
      "1.0893262351552646\n",
      "Validation loss: 1.1627564430236816\n",
      "mse 1.1627564066114213\n",
      "New best model found at epoch 235 with validation loss 1.1627564430236816\n",
      "Starting Epoch 236\n",
      "1.0887248391906421\n",
      "Validation loss: 1.162987232208252\n",
      "mse 1.1629870088749419\n",
      "Starting Epoch 237\n",
      "1.0883067846298218\n",
      "Validation loss: 1.1629223823547363\n",
      "mse 1.1629225061439703\n",
      "Starting Epoch 238\n",
      "1.0880535890658696\n",
      "Validation loss: 1.162262201309204\n",
      "mse 1.162262163922661\n",
      "New best model found at epoch 238 with validation loss 1.162262201309204\n",
      "Starting Epoch 239\n",
      "1.0873959958553314\n",
      "Validation loss: 1.1624152660369873\n",
      "mse 1.1624152077035301\n",
      "Starting Epoch 240\n",
      "1.086959145963192\n",
      "Validation loss: 1.1619367599487305\n",
      "mse 1.1619367912192307\n",
      "New best model found at epoch 240 with validation loss 1.1619367599487305\n",
      "Starting Epoch 241\n",
      "1.0866528178254764\n",
      "Validation loss: 1.1623594760894775\n",
      "mse 1.1623594089197742\n",
      "Starting Epoch 242\n",
      "1.0860714117685955\n",
      "Validation loss: 1.1619696617126465\n",
      "mse 1.1619697319292133\n",
      "Starting Epoch 243\n",
      "1.0855593581994374\n",
      "Validation loss: 1.1621055603027344\n",
      "mse 1.1621054046229788\n",
      "Starting Epoch 244\n",
      "1.0853399361173313\n",
      "Validation loss: 1.1614513397216797\n",
      "mse 1.1614512771661643\n",
      "New best model found at epoch 244 with validation loss 1.1614513397216797\n",
      "Starting Epoch 245\n",
      "1.0846884349981945\n",
      "Validation loss: 1.1616517305374146\n",
      "mse 1.1616516117526836\n",
      "Starting Epoch 246\n",
      "1.084328422943751\n",
      "Validation loss: 1.1614911556243896\n",
      "mse 1.161491197801794\n",
      "Starting Epoch 247\n",
      "1.083937791486581\n",
      "Validation loss: 1.1612131595611572\n",
      "mse 1.161213052931707\n",
      "New best model found at epoch 247 with validation loss 1.1612131595611572\n",
      "Starting Epoch 248\n",
      "1.083458552757899\n",
      "Validation loss: 1.1610419750213623\n",
      "mse 1.1610419458729941\n",
      "New best model found at epoch 248 with validation loss 1.1610419750213623\n",
      "Starting Epoch 249\n",
      "1.0829690520962079\n",
      "Validation loss: 1.1608870029449463\n",
      "mse 1.1608870075287663\n",
      "New best model found at epoch 249 with validation loss 1.1608870029449463\n",
      "Starting Epoch 250\n",
      "1.082569328447183\n",
      "Validation loss: 1.160860538482666\n",
      "mse 1.160860478622812\n",
      "New best model found at epoch 250 with validation loss 1.160860538482666\n",
      "Starting Epoch 251\n",
      "1.0821860954165459\n",
      "Validation loss: 1.1608728170394897\n",
      "mse 1.1608728251095315\n",
      "Starting Epoch 252\n",
      "1.0815464754899342\n",
      "Validation loss: 1.1606941223144531\n",
      "mse 1.1606942185158695\n",
      "New best model found at epoch 252 with validation loss 1.1606941223144531\n",
      "Starting Epoch 253\n",
      "1.0813407550255458\n",
      "Validation loss: 1.1601330041885376\n",
      "mse 1.1601330913190013\n",
      "New best model found at epoch 253 with validation loss 1.1601330041885376\n",
      "Starting Epoch 254\n",
      "1.0811074549953144\n",
      "Validation loss: 1.1603490114212036\n",
      "mse 1.1603490996752601\n",
      "Starting Epoch 255\n",
      "1.0806268354256947\n",
      "Validation loss: 1.159924030303955\n",
      "mse 1.1599239215227155\n",
      "New best model found at epoch 255 with validation loss 1.159924030303955\n",
      "Starting Epoch 256\n",
      "1.0799664830168088\n",
      "Validation loss: 1.1597003936767578\n",
      "mse 1.1597003313757988\n",
      "New best model found at epoch 256 with validation loss 1.1597003936767578\n",
      "Starting Epoch 257\n",
      "1.0796558385094006\n",
      "Validation loss: 1.1596369743347168\n",
      "mse 1.1596370374411045\n",
      "New best model found at epoch 257 with validation loss 1.1596369743347168\n",
      "Starting Epoch 258\n",
      "1.07902559141318\n",
      "Validation loss: 1.1594765186309814\n",
      "mse 1.1594764057479725\n",
      "New best model found at epoch 258 with validation loss 1.1594765186309814\n",
      "Starting Epoch 259\n",
      "1.078623669842879\n",
      "Validation loss: 1.1594576835632324\n",
      "mse 1.1594576437075632\n",
      "New best model found at epoch 259 with validation loss 1.1594576835632324\n",
      "Starting Epoch 260\n",
      "1.078317587574323\n",
      "Validation loss: 1.1594680547714233\n",
      "mse 1.1594680128455648\n",
      "Starting Epoch 261\n",
      "1.077854757507642\n",
      "Validation loss: 1.158867597579956\n",
      "mse 1.1588676025985485\n",
      "New best model found at epoch 261 with validation loss 1.158867597579956\n",
      "Starting Epoch 262\n",
      "1.0773490369319916\n",
      "Validation loss: 1.15876305103302\n",
      "mse 1.1587630746246689\n",
      "New best model found at epoch 262 with validation loss 1.15876305103302\n",
      "Starting Epoch 263\n",
      "1.0769168188174565\n",
      "Validation loss: 1.158625602722168\n",
      "mse 1.1586255622923227\n",
      "New best model found at epoch 263 with validation loss 1.158625602722168\n",
      "Starting Epoch 264\n",
      "1.076738012333711\n",
      "Validation loss: 1.1586464643478394\n",
      "mse 1.1586464825268905\n",
      "Starting Epoch 265\n",
      "1.0761728510260582\n",
      "Validation loss: 1.158535122871399\n",
      "mse 1.1585351180902552\n",
      "New best model found at epoch 265 with validation loss 1.158535122871399\n",
      "Starting Epoch 266\n",
      "1.0758542940020561\n",
      "Validation loss: 1.1586261987686157\n",
      "mse 1.158626222954754\n",
      "Starting Epoch 267\n",
      "1.0754785438378651\n",
      "Validation loss: 1.1578454971313477\n",
      "mse 1.1578454318831004\n",
      "New best model found at epoch 267 with validation loss 1.1578454971313477\n",
      "Starting Epoch 268\n",
      "1.0749863137801488\n",
      "Validation loss: 1.157588005065918\n",
      "mse 1.15758797639227\n",
      "New best model found at epoch 268 with validation loss 1.157588005065918\n",
      "Starting Epoch 269\n",
      "1.0749452312787373\n",
      "Validation loss: 1.15792715549469\n",
      "mse 1.1579272088420984\n",
      "Starting Epoch 270\n",
      "1.0743642151355743\n",
      "Validation loss: 1.1576030254364014\n",
      "mse 1.1576030855352002\n",
      "Starting Epoch 271\n",
      "1.0737925643722217\n",
      "Validation loss: 1.1574643850326538\n",
      "mse 1.1574643747116629\n",
      "New best model found at epoch 271 with validation loss 1.1574643850326538\n",
      "Starting Epoch 272\n",
      "1.073417216539383\n",
      "Validation loss: 1.157571792602539\n",
      "mse 1.1575717228620097\n",
      "Starting Epoch 273\n",
      "1.0731509154041607\n",
      "Validation loss: 1.1575229167938232\n",
      "mse 1.157522852992823\n",
      "Starting Epoch 274\n",
      "1.0726486667990685\n",
      "Validation loss: 1.1568071842193604\n",
      "mse 1.156807129888351\n",
      "New best model found at epoch 274 with validation loss 1.1568071842193604\n",
      "Starting Epoch 275\n",
      "1.072287067770958\n",
      "Validation loss: 1.1573070287704468\n",
      "mse 1.1573070793163203\n",
      "Starting Epoch 276\n",
      "1.0719680065910022\n",
      "Validation loss: 1.1572707891464233\n",
      "mse 1.157270908900427\n",
      "Starting Epoch 277\n",
      "1.0718818704287212\n",
      "Validation loss: 1.1568766832351685\n",
      "mse 1.1568767592042137\n",
      "Starting Epoch 278\n",
      "1.0712100292245548\n",
      "Validation loss: 1.1569267511367798\n",
      "mse 1.1569266742364672\n",
      "Starting Epoch 279\n",
      "1.070891742904981\n",
      "Validation loss: 1.1566518545150757\n",
      "mse 1.1566518125519205\n",
      "New best model found at epoch 279 with validation loss 1.1566518545150757\n",
      "Starting Epoch 280\n",
      "1.0705715815226238\n",
      "Validation loss: 1.156545639038086\n",
      "mse 1.156545608821252\n",
      "New best model found at epoch 280 with validation loss 1.156545639038086\n",
      "Starting Epoch 281\n",
      "1.0701615711053212\n",
      "Validation loss: 1.1566674709320068\n",
      "mse 1.1566674816557059\n",
      "Starting Epoch 282\n",
      "1.0696687599023182\n",
      "Validation loss: 1.1563547849655151\n",
      "mse 1.1563547060968395\n",
      "New best model found at epoch 282 with validation loss 1.1563547849655151\n",
      "Starting Epoch 283\n",
      "1.0693570325771968\n",
      "Validation loss: 1.156431794166565\n",
      "mse 1.1564317850693628\n",
      "Starting Epoch 284\n",
      "1.0689760049184163\n",
      "Validation loss: 1.1558177471160889\n",
      "mse 1.1558177007612995\n",
      "New best model found at epoch 284 with validation loss 1.1558177471160889\n",
      "Starting Epoch 285\n",
      "1.068529191116492\n",
      "Validation loss: 1.1561280488967896\n",
      "mse 1.156128071769635\n",
      "Starting Epoch 286\n",
      "1.0681347077091534\n",
      "Validation loss: 1.1560895442962646\n",
      "mse 1.1560894727947464\n",
      "Starting Epoch 287\n",
      "1.067866250872612\n",
      "Validation loss: 1.1557191610336304\n",
      "mse 1.15571912865117\n",
      "New best model found at epoch 287 with validation loss 1.1557191610336304\n",
      "Starting Epoch 288\n",
      "1.0674786468346913\n",
      "Validation loss: 1.1557600498199463\n",
      "mse 1.1557600784768445\n",
      "Starting Epoch 289\n",
      "1.0671482707063358\n",
      "Validation loss: 1.1553544998168945\n",
      "mse 1.1553544982828183\n",
      "New best model found at epoch 289 with validation loss 1.1553544998168945\n",
      "Starting Epoch 290\n",
      "1.0668100863695145\n",
      "Validation loss: 1.1552728414535522\n",
      "mse 1.1552727485097616\n",
      "New best model found at epoch 290 with validation loss 1.1552728414535522\n",
      "Starting Epoch 291\n",
      "1.0664883131782215\n",
      "Validation loss: 1.1553335189819336\n",
      "mse 1.1553334586905295\n",
      "Starting Epoch 292\n",
      "1.0660131921370823\n",
      "Validation loss: 1.1553629636764526\n",
      "mse 1.1553629252318385\n",
      "Starting Epoch 293\n",
      "1.0657130976517994\n",
      "Validation loss: 1.1550403833389282\n",
      "mse 1.1550403255825297\n",
      "New best model found at epoch 293 with validation loss 1.1550403833389282\n",
      "Starting Epoch 294\n",
      "1.065480150282383\n",
      "Validation loss: 1.1551471948623657\n",
      "mse 1.1551472122014534\n",
      "Starting Epoch 295\n",
      "1.0650123233596485\n",
      "Validation loss: 1.1549304723739624\n",
      "mse 1.1549304415672252\n",
      "New best model found at epoch 295 with validation loss 1.1549304723739624\n",
      "Starting Epoch 296\n",
      "1.0645947655042012\n",
      "Validation loss: 1.1551122665405273\n",
      "mse 1.1551122674409717\n",
      "Starting Epoch 297\n",
      "1.0641916940609615\n",
      "Validation loss: 1.1549122333526611\n",
      "mse 1.154912275382831\n",
      "New best model found at epoch 297 with validation loss 1.1549122333526611\n",
      "Starting Epoch 298\n",
      "1.06374745319287\n",
      "Validation loss: 1.154823660850525\n",
      "mse 1.1548236868272257\n",
      "New best model found at epoch 298 with validation loss 1.154823660850525\n",
      "Starting Epoch 299\n",
      "1.06341336419185\n",
      "Validation loss: 1.1546375751495361\n",
      "mse 1.154637564225252\n",
      "New best model found at epoch 299 with validation loss 1.1546375751495361\n",
      "Starting Epoch 300\n",
      "1.063034527003765\n",
      "Validation loss: 1.1543827056884766\n",
      "mse 1.1543827201180703\n",
      "New best model found at epoch 300 with validation loss 1.1543827056884766\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP, custom: 7-80-50-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "9fcd7ca8-4a6c-4b15-8884-35ceb37ad39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.789418</td>\n",
       "      <td>0.730049</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.579022</td>\n",
       "      <td>0.390659</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>0.612816</td>\n",
       "      <td>0.433778</td>\n",
       "      <td>0.79668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.584555</td>\n",
       "      <td>0.392098</td>\n",
       "      <td>0.817131</td>\n",
       "      <td>0.61371</td>\n",
       "      <td>0.435071</td>\n",
       "      <td>0.796384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>2.323296</td>\n",
       "      <td>0.907326</td>\n",
       "      <td>0.273192</td>\n",
       "      <td>2.371142</td>\n",
       "      <td>0.929039</td>\n",
       "      <td>0.213305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.778288</td>\n",
       "      <td>0.719919</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>1.81521</td>\n",
       "      <td>0.749433</td>\n",
       "      <td>0.397751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.612341</td>\n",
       "      <td>0.692069</td>\n",
       "      <td>0.495604</td>\n",
       "      <td>1.666438</td>\n",
       "      <td>0.727603</td>\n",
       "      <td>0.447111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-1</th>\n",
       "      <td>1.386030</td>\n",
       "      <td>0.840528</td>\n",
       "      <td>0.566402</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-1</th>\n",
       "      <td>1.511389</td>\n",
       "      <td>0.875163</td>\n",
       "      <td>0.527185</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-1</th>\n",
       "      <td>1.442876</td>\n",
       "      <td>0.859189</td>\n",
       "      <td>0.548618</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-1</th>\n",
       "      <td>1.343067</td>\n",
       "      <td>0.821639</td>\n",
       "      <td>0.579842</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-1</th>\n",
       "      <td>1.347905</td>\n",
       "      <td>0.820918</td>\n",
       "      <td>0.578329</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-1</th>\n",
       "      <td>1.388511</td>\n",
       "      <td>0.829501</td>\n",
       "      <td>0.565625</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-1</th>\n",
       "      <td>1.360229</td>\n",
       "      <td>0.822960</td>\n",
       "      <td>0.574473</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-1</th>\n",
       "      <td>1.273426</td>\n",
       "      <td>0.791052</td>\n",
       "      <td>0.601628</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-1</th>\n",
       "      <td>1.285886</td>\n",
       "      <td>0.801589</td>\n",
       "      <td>0.597730</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-1</th>\n",
       "      <td>1.255633</td>\n",
       "      <td>0.796268</td>\n",
       "      <td>0.607194</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-1</th>\n",
       "      <td>1.162645</td>\n",
       "      <td>0.744006</td>\n",
       "      <td>0.636284</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-1</th>\n",
       "      <td>1.183051</td>\n",
       "      <td>0.745964</td>\n",
       "      <td>0.629900</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-1</th>\n",
       "      <td>1.124134</td>\n",
       "      <td>0.712487</td>\n",
       "      <td>0.648332</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-1</th>\n",
       "      <td>1.313112</td>\n",
       "      <td>0.792845</td>\n",
       "      <td>0.589213</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-1</th>\n",
       "      <td>1.274659</td>\n",
       "      <td>0.764669</td>\n",
       "      <td>0.601242</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-1</th>\n",
       "      <td>1.344109</td>\n",
       "      <td>0.802782</td>\n",
       "      <td>0.579516</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-1</th>\n",
       "      <td>1.202730</td>\n",
       "      <td>0.722136</td>\n",
       "      <td>0.623744</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-1</th>\n",
       "      <td>1.339963</td>\n",
       "      <td>0.802546</td>\n",
       "      <td>0.580813</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-1</th>\n",
       "      <td>1.237934</td>\n",
       "      <td>0.760888</td>\n",
       "      <td>0.612731</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-1</th>\n",
       "      <td>1.154383</td>\n",
       "      <td>0.717330</td>\n",
       "      <td>0.638869</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   MSE       MAE        R2       MSE  \\\n",
       "5-NN                          0.673141  0.442646  0.789418  0.730049   \n",
       "Decision tree                 0.579022  0.390659  0.818862  0.612816   \n",
       "Random forest                 0.584555  0.392098  0.817131   0.61371   \n",
       "SVM linear                    2.323296  0.907326  0.273192  2.371142   \n",
       "SVM poly                      1.778288  0.719919  0.443690   1.81521   \n",
       "SVM rbf                       1.612341  0.692069  0.495604  1.666438   \n",
       "MLP: 17-5-1                   1.386030  0.840528  0.566402         -   \n",
       "MLP: 17-10-1                  1.511389  0.875163  0.527185         -   \n",
       "MLP: 17-20-1                  1.442876  0.859189  0.548618         -   \n",
       "MLP: 17-25-1                  1.343067  0.821639  0.579842         -   \n",
       "MLP: 17-40-1                  1.347905  0.820918  0.578329         -   \n",
       "MLP: 17-60-1                  1.388511  0.829501  0.565625         -   \n",
       "MLP: 17-10-5-1                1.360229  0.822960  0.574473         -   \n",
       "MLP: 17-20-10-1               1.273426  0.791052  0.601628         -   \n",
       "MLP: 17-40-20-1               1.285886  0.801589  0.597730         -   \n",
       "MLP: 17-40-10-1               1.255633  0.796268  0.607194         -   \n",
       "MLP: 17-60-40-1               1.162645  0.744006  0.636284         -   \n",
       "MLP: 17-60-20-1               1.183051  0.745964  0.629900         -   \n",
       "MLP: 17-80-50-1               1.124134  0.712487  0.648332         -   \n",
       "MLP, small-median: 7-80-50-1  1.313112  0.792845  0.589213         -   \n",
       "MLP, small-mean: 7-80-50-1    1.274659  0.764669  0.601242         -   \n",
       "MLP, small-min: 7-80-50-1     1.344109  0.802782  0.579516         -   \n",
       "MLP, small-max: 7-80-50-1     1.202730  0.722136  0.623744         -   \n",
       "MLP, small-q25: 7-80-50-1     1.339963  0.802546  0.580813         -   \n",
       "MLP, small-q75: 7-80-50-1     1.237934  0.760888  0.612731         -   \n",
       "MLP, custom: 7-80-50-1        1.154383  0.717330  0.638869         -   \n",
       "\n",
       "                                   MAE        R2  \n",
       "5-NN                          0.478475  0.757785  \n",
       "Decision tree                 0.433778   0.79668  \n",
       "Random forest                 0.435071  0.796384  \n",
       "SVM linear                    0.929039  0.213305  \n",
       "SVM poly                      0.749433  0.397751  \n",
       "SVM rbf                       0.727603  0.447111  \n",
       "MLP: 17-5-1                          -         -  \n",
       "MLP: 17-10-1                         -         -  \n",
       "MLP: 17-20-1                         -         -  \n",
       "MLP: 17-25-1                         -         -  \n",
       "MLP: 17-40-1                         -         -  \n",
       "MLP: 17-60-1                         -         -  \n",
       "MLP: 17-10-5-1                       -         -  \n",
       "MLP: 17-20-10-1                      -         -  \n",
       "MLP: 17-40-20-1                      -         -  \n",
       "MLP: 17-40-10-1                      -         -  \n",
       "MLP: 17-60-40-1                      -         -  \n",
       "MLP: 17-60-20-1                      -         -  \n",
       "MLP: 17-80-50-1                      -         -  \n",
       "MLP, small-median: 7-80-50-1         -         -  \n",
       "MLP, small-mean: 7-80-50-1           -         -  \n",
       "MLP, small-min: 7-80-50-1            -         -  \n",
       "MLP, small-max: 7-80-50-1            -         -  \n",
       "MLP, small-q25: 7-80-50-1            -         -  \n",
       "MLP, small-q75: 7-80-50-1            -         -  \n",
       "MLP, custom: 7-80-50-1               -         -  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17693281-4753-4a5d-abde-cf2ed5eae98a",
   "metadata": {},
   "source": [
    "### HGNN (Hypergraph neural network) with two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "5d80d00f-95a8-400e-ae6f-816fcfc0b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, label_series, hypergraph_column_name):\n",
    "        # Extract features and convert to tensor\n",
    "        self.X = torch.from_numpy(dataframe.drop(columns=[hypergraph_column_name]).values).float()\n",
    "        \n",
    "        # Extract labels and convert to tensor\n",
    "        self.y = torch.from_numpy(label_series.values).float()\n",
    "        \n",
    "        # Store hypergraph objects\n",
    "        self.hypergraphs = dataframe[hypergraph_column_name].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.X[index],\n",
    "            'label': self.y[index],\n",
    "            'hypergraph': self.hypergraphs[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "363bf22d-cb81-4b98-9da2-e6eb03d5a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HGNN_classification(X_training, y_training, X_validation, y_validation, type, text):\n",
    "    model = HGNN(random_seed = 20)  \n",
    "\n",
    "    dataset = CustomDataset(X_training, y_training, hypergraph_column_name='hypergraph')\n",
    "    validation = CustomDataset(X_validation, y_validation, hypergraph_column_name='hypergraph')\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for item in dataset:\n",
    "            optimizer.zero_grad()\n",
    "            input_features = item[\"data\"]\n",
    "            input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "            label = item[\"label\"].long()\n",
    "            output = model(input_hg)\n",
    "            \n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataset):.4f}')\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for item in validation:\n",
    "                input_features = item[\"data\"]\n",
    "                input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "                label = item[\"label\"].long()\n",
    "                output = model(input_hg)\n",
    "                loss = loss_function(output, label)\n",
    "                val_loss += loss.item()\n",
    "    \n",
    "        val_loss /= len(validation)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "        # Save the model if the validation loss is the best we've seen so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Saved the best model with validation loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for item in validation:\n",
    "            i += 1\n",
    "            output = model(item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0))\n",
    "            _, pred = torch.max(output.data, 0)\n",
    "            predicted.append(pred.item())\n",
    "\n",
    "    if type == \"2_class\":\n",
    "        accuracy = accuracy_score(y_validation, predicted)\n",
    "        recall = recall_score(y_validation, predicted)\n",
    "        conf_matrix = confusion_matrix(y_validation, predicted)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_2_classes.loc[text] = [accuracy, recall, \"-\", \"-\"]\n",
    "\n",
    "    if type == \"3_class\":\n",
    "        accuracy = accuracy_score(y_validation, predicted)\n",
    "        recall_micro = recall_score(y_validation, predicted, average='micro')\n",
    "        recall_macro = recall_score(y_validation, predicted, average='macro')\n",
    "        conf_matrix = confusion_matrix(y_validation, predicted)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_3_classes.loc[text] = [accuracy, recall_micro, recall_macro, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e7baad-8a1f-4c5f-9ca2-168c73140bf7",
   "metadata": {},
   "source": [
    "*  Loss: Cross-Entropy\n",
    "*  Epochs: 100 (saving best model)\n",
    "*  Leaning rate: 0.001\n",
    "*  Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd033f26-cc33-4e57-9843-78c03fc96e33",
   "metadata": {},
   "source": [
    "##### HGNN: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 16 - 32 - 2, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "fa0d74ce-89ee-4362-878a-6f6c491f7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "238ce285-3783-425e-b0a5-a2b56dad9627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5671\n",
      "Validation Loss: 0.4874\n",
      "Saved the best model with validation loss: 0.4874\n",
      "Epoch [2/100], Loss: 0.4825\n",
      "Validation Loss: 0.4575\n",
      "Saved the best model with validation loss: 0.4575\n",
      "Epoch [3/100], Loss: 0.4566\n",
      "Validation Loss: 0.4472\n",
      "Saved the best model with validation loss: 0.4472\n",
      "Epoch [4/100], Loss: 0.4440\n",
      "Validation Loss: 0.4382\n",
      "Saved the best model with validation loss: 0.4382\n",
      "Epoch [5/100], Loss: 0.4363\n",
      "Validation Loss: 0.4359\n",
      "Saved the best model with validation loss: 0.4359\n",
      "Epoch [6/100], Loss: 0.4303\n",
      "Validation Loss: 0.4332\n",
      "Saved the best model with validation loss: 0.4332\n",
      "Epoch [7/100], Loss: 0.4263\n",
      "Validation Loss: 0.4295\n",
      "Saved the best model with validation loss: 0.4295\n",
      "Epoch [8/100], Loss: 0.4232\n",
      "Validation Loss: 0.4270\n",
      "Saved the best model with validation loss: 0.4270\n",
      "Epoch [9/100], Loss: 0.4219\n",
      "Validation Loss: 0.4245\n",
      "Saved the best model with validation loss: 0.4245\n",
      "Epoch [10/100], Loss: 0.4193\n",
      "Validation Loss: 0.4229\n",
      "Saved the best model with validation loss: 0.4229\n",
      "Epoch [11/100], Loss: 0.4176\n",
      "Validation Loss: 0.4246\n",
      "Epoch [12/100], Loss: 0.4155\n",
      "Validation Loss: 0.4240\n",
      "Epoch [13/100], Loss: 0.4139\n",
      "Validation Loss: 0.4235\n",
      "Epoch [14/100], Loss: 0.4128\n",
      "Validation Loss: 0.4223\n",
      "Saved the best model with validation loss: 0.4223\n",
      "Epoch [15/100], Loss: 0.4112\n",
      "Validation Loss: 0.4235\n",
      "Epoch [16/100], Loss: 0.4097\n",
      "Validation Loss: 0.4252\n",
      "Epoch [17/100], Loss: 0.4098\n",
      "Validation Loss: 0.4227\n",
      "Epoch [18/100], Loss: 0.4083\n",
      "Validation Loss: 0.4236\n",
      "Epoch [19/100], Loss: 0.4084\n",
      "Validation Loss: 0.4231\n",
      "Epoch [20/100], Loss: 0.4077\n",
      "Validation Loss: 0.4222\n",
      "Saved the best model with validation loss: 0.4222\n",
      "Epoch [21/100], Loss: 0.4066\n",
      "Validation Loss: 0.4199\n",
      "Saved the best model with validation loss: 0.4199\n",
      "Epoch [22/100], Loss: 0.4053\n",
      "Validation Loss: 0.4189\n",
      "Saved the best model with validation loss: 0.4189\n",
      "Epoch [23/100], Loss: 0.4052\n",
      "Validation Loss: 0.4163\n",
      "Saved the best model with validation loss: 0.4163\n",
      "Epoch [24/100], Loss: 0.4040\n",
      "Validation Loss: 0.4137\n",
      "Saved the best model with validation loss: 0.4137\n",
      "Epoch [25/100], Loss: 0.4033\n",
      "Validation Loss: 0.4127\n",
      "Saved the best model with validation loss: 0.4127\n",
      "Epoch [26/100], Loss: 0.4029\n",
      "Validation Loss: 0.4136\n",
      "Epoch [27/100], Loss: 0.4022\n",
      "Validation Loss: 0.4155\n",
      "Epoch [28/100], Loss: 0.4016\n",
      "Validation Loss: 0.4137\n",
      "Epoch [29/100], Loss: 0.4003\n",
      "Validation Loss: 0.4118\n",
      "Saved the best model with validation loss: 0.4118\n",
      "Epoch [30/100], Loss: 0.4012\n",
      "Validation Loss: 0.4155\n",
      "Epoch [31/100], Loss: 0.4011\n",
      "Validation Loss: 0.4134\n",
      "Epoch [32/100], Loss: 0.4003\n",
      "Validation Loss: 0.4135\n",
      "Epoch [33/100], Loss: 0.4006\n",
      "Validation Loss: 0.4105\n",
      "Saved the best model with validation loss: 0.4105\n",
      "Epoch [34/100], Loss: 0.3987\n",
      "Validation Loss: 0.4125\n",
      "Epoch [35/100], Loss: 0.3993\n",
      "Validation Loss: 0.4119\n",
      "Epoch [36/100], Loss: 0.3980\n",
      "Validation Loss: 0.4115\n",
      "Epoch [37/100], Loss: 0.3975\n",
      "Validation Loss: 0.4137\n",
      "Epoch [38/100], Loss: 0.3980\n",
      "Validation Loss: 0.4116\n",
      "Epoch [39/100], Loss: 0.3976\n",
      "Validation Loss: 0.4109\n",
      "Epoch [40/100], Loss: 0.3965\n",
      "Validation Loss: 0.4104\n",
      "Saved the best model with validation loss: 0.4104\n",
      "Epoch [41/100], Loss: 0.3969\n",
      "Validation Loss: 0.4108\n",
      "Epoch [42/100], Loss: 0.3956\n",
      "Validation Loss: 0.4097\n",
      "Saved the best model with validation loss: 0.4097\n",
      "Epoch [43/100], Loss: 0.3976\n",
      "Validation Loss: 0.4135\n",
      "Epoch [44/100], Loss: 0.3964\n",
      "Validation Loss: 0.4110\n",
      "Epoch [45/100], Loss: 0.3954\n",
      "Validation Loss: 0.4091\n",
      "Saved the best model with validation loss: 0.4091\n",
      "Epoch [46/100], Loss: 0.3940\n",
      "Validation Loss: 0.4110\n",
      "Epoch [47/100], Loss: 0.3947\n",
      "Validation Loss: 0.4126\n",
      "Epoch [48/100], Loss: 0.3948\n",
      "Validation Loss: 0.4095\n",
      "Epoch [49/100], Loss: 0.3946\n",
      "Validation Loss: 0.4056\n",
      "Saved the best model with validation loss: 0.4056\n",
      "Epoch [50/100], Loss: 0.3933\n",
      "Validation Loss: 0.4047\n",
      "Saved the best model with validation loss: 0.4047\n",
      "Epoch [51/100], Loss: 0.3938\n",
      "Validation Loss: 0.4076\n",
      "Epoch [52/100], Loss: 0.3933\n",
      "Validation Loss: 0.4048\n",
      "Epoch [53/100], Loss: 0.3935\n",
      "Validation Loss: 0.4031\n",
      "Saved the best model with validation loss: 0.4031\n",
      "Epoch [54/100], Loss: 0.3932\n",
      "Validation Loss: 0.4044\n",
      "Epoch [55/100], Loss: 0.3924\n",
      "Validation Loss: 0.4012\n",
      "Saved the best model with validation loss: 0.4012\n",
      "Epoch [56/100], Loss: 0.3934\n",
      "Validation Loss: 0.3984\n",
      "Saved the best model with validation loss: 0.3984\n",
      "Epoch [57/100], Loss: 0.3929\n",
      "Validation Loss: 0.3952\n",
      "Saved the best model with validation loss: 0.3952\n",
      "Epoch [58/100], Loss: 0.3932\n",
      "Validation Loss: 0.3960\n",
      "Epoch [59/100], Loss: 0.3929\n",
      "Validation Loss: 0.3968\n",
      "Epoch [60/100], Loss: 0.3933\n",
      "Validation Loss: 0.3947\n",
      "Saved the best model with validation loss: 0.3947\n",
      "Epoch [61/100], Loss: 0.3923\n",
      "Validation Loss: 0.3972\n",
      "Epoch [62/100], Loss: 0.3928\n",
      "Validation Loss: 0.3968\n",
      "Epoch [63/100], Loss: 0.3923\n",
      "Validation Loss: 0.3957\n",
      "Epoch [64/100], Loss: 0.3905\n",
      "Validation Loss: 0.3945\n",
      "Saved the best model with validation loss: 0.3945\n",
      "Epoch [65/100], Loss: 0.3912\n",
      "Validation Loss: 0.3950\n",
      "Epoch [66/100], Loss: 0.3919\n",
      "Validation Loss: 0.3911\n",
      "Saved the best model with validation loss: 0.3911\n",
      "Epoch [67/100], Loss: 0.3916\n",
      "Validation Loss: 0.3926\n",
      "Epoch [68/100], Loss: 0.3907\n",
      "Validation Loss: 0.3945\n",
      "Epoch [69/100], Loss: 0.3917\n",
      "Validation Loss: 0.3947\n",
      "Epoch [70/100], Loss: 0.3918\n",
      "Validation Loss: 0.3969\n",
      "Epoch [71/100], Loss: 0.3923\n",
      "Validation Loss: 0.3942\n",
      "Epoch [72/100], Loss: 0.3937\n",
      "Validation Loss: 0.3919\n",
      "Epoch [73/100], Loss: 0.3912\n",
      "Validation Loss: 0.3946\n",
      "Epoch [74/100], Loss: 0.3901\n",
      "Validation Loss: 0.3927\n",
      "Epoch [75/100], Loss: 0.3912\n",
      "Validation Loss: 0.3950\n",
      "Epoch [76/100], Loss: 0.3907\n",
      "Validation Loss: 0.3960\n",
      "Epoch [77/100], Loss: 0.3905\n",
      "Validation Loss: 0.3964\n",
      "Epoch [78/100], Loss: 0.3895\n",
      "Validation Loss: 0.3933\n",
      "Epoch [79/100], Loss: 0.3894\n",
      "Validation Loss: 0.3921\n",
      "Epoch [80/100], Loss: 0.3899\n",
      "Validation Loss: 0.3933\n",
      "Epoch [81/100], Loss: 0.3895\n",
      "Validation Loss: 0.3964\n",
      "Epoch [82/100], Loss: 0.3909\n",
      "Validation Loss: 0.3927\n",
      "Epoch [83/100], Loss: 0.3897\n",
      "Validation Loss: 0.3896\n",
      "Saved the best model with validation loss: 0.3896\n",
      "Epoch [84/100], Loss: 0.3893\n",
      "Validation Loss: 0.3934\n",
      "Epoch [85/100], Loss: 0.3897\n",
      "Validation Loss: 0.3899\n",
      "Epoch [86/100], Loss: 0.3894\n",
      "Validation Loss: 0.3917\n",
      "Epoch [87/100], Loss: 0.3896\n",
      "Validation Loss: 0.3906\n",
      "Epoch [88/100], Loss: 0.3878\n",
      "Validation Loss: 0.3900\n",
      "Epoch [89/100], Loss: 0.3903\n",
      "Validation Loss: 0.3949\n",
      "Epoch [90/100], Loss: 0.3899\n",
      "Validation Loss: 0.3898\n",
      "Epoch [91/100], Loss: 0.3888\n",
      "Validation Loss: 0.3925\n",
      "Epoch [92/100], Loss: 0.3893\n",
      "Validation Loss: 0.3948\n",
      "Epoch [93/100], Loss: 0.3880\n",
      "Validation Loss: 0.3982\n",
      "Epoch [94/100], Loss: 0.3887\n",
      "Validation Loss: 0.4000\n",
      "Epoch [95/100], Loss: 0.3894\n",
      "Validation Loss: 0.3956\n",
      "Epoch [96/100], Loss: 0.3892\n",
      "Validation Loss: 0.3969\n",
      "Epoch [97/100], Loss: 0.3886\n",
      "Validation Loss: 0.3956\n",
      "Epoch [98/100], Loss: 0.3878\n",
      "Validation Loss: 0.3929\n",
      "Epoch [99/100], Loss: 0.3882\n",
      "Validation Loss: 0.3953\n",
      "Epoch [100/100], Loss: 0.3880\n",
      "Validation Loss: 0.3915\n"
     ]
    }
   ],
   "source": [
    "HGNN_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"HGNN: 1-16-32-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc52885-adb9-4b09-bb3e-cac269cac797",
   "metadata": {},
   "source": [
    "##### HGNN: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 16 - 2, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d8330110-ec21-4387-8eae-ed78d699b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "eecd8159-7c65-4e70-b700-8e044bcb6419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5725\n",
      "Validation Loss: 0.5023\n",
      "Saved the best model with validation loss: 0.5023\n",
      "Epoch [2/100], Loss: 0.4933\n",
      "Validation Loss: 0.4796\n",
      "Saved the best model with validation loss: 0.4796\n",
      "Epoch [3/100], Loss: 0.4704\n",
      "Validation Loss: 0.4641\n",
      "Saved the best model with validation loss: 0.4641\n",
      "Epoch [4/100], Loss: 0.4594\n",
      "Validation Loss: 0.4594\n",
      "Saved the best model with validation loss: 0.4594\n",
      "Epoch [5/100], Loss: 0.4503\n",
      "Validation Loss: 0.4546\n",
      "Saved the best model with validation loss: 0.4546\n",
      "Epoch [6/100], Loss: 0.4445\n",
      "Validation Loss: 0.4516\n",
      "Saved the best model with validation loss: 0.4516\n",
      "Epoch [7/100], Loss: 0.4414\n",
      "Validation Loss: 0.4440\n",
      "Saved the best model with validation loss: 0.4440\n",
      "Epoch [8/100], Loss: 0.4358\n",
      "Validation Loss: 0.4391\n",
      "Saved the best model with validation loss: 0.4391\n",
      "Epoch [9/100], Loss: 0.4308\n",
      "Validation Loss: 0.4411\n",
      "Epoch [10/100], Loss: 0.4293\n",
      "Validation Loss: 0.4389\n",
      "Saved the best model with validation loss: 0.4389\n",
      "Epoch [11/100], Loss: 0.4267\n",
      "Validation Loss: 0.4366\n",
      "Saved the best model with validation loss: 0.4366\n",
      "Epoch [12/100], Loss: 0.4248\n",
      "Validation Loss: 0.4366\n",
      "Saved the best model with validation loss: 0.4366\n",
      "Epoch [13/100], Loss: 0.4218\n",
      "Validation Loss: 0.4333\n",
      "Saved the best model with validation loss: 0.4333\n",
      "Epoch [14/100], Loss: 0.4194\n",
      "Validation Loss: 0.4315\n",
      "Saved the best model with validation loss: 0.4315\n",
      "Epoch [15/100], Loss: 0.4175\n",
      "Validation Loss: 0.4239\n",
      "Saved the best model with validation loss: 0.4239\n",
      "Epoch [16/100], Loss: 0.4155\n",
      "Validation Loss: 0.4234\n",
      "Saved the best model with validation loss: 0.4234\n",
      "Epoch [17/100], Loss: 0.4147\n",
      "Validation Loss: 0.4284\n",
      "Epoch [18/100], Loss: 0.4133\n",
      "Validation Loss: 0.4293\n",
      "Epoch [19/100], Loss: 0.4111\n",
      "Validation Loss: 0.4231\n",
      "Saved the best model with validation loss: 0.4231\n",
      "Epoch [20/100], Loss: 0.4098\n",
      "Validation Loss: 0.4207\n",
      "Saved the best model with validation loss: 0.4207\n",
      "Epoch [21/100], Loss: 0.4093\n",
      "Validation Loss: 0.4204\n",
      "Saved the best model with validation loss: 0.4204\n",
      "Epoch [22/100], Loss: 0.4085\n",
      "Validation Loss: 0.4202\n",
      "Saved the best model with validation loss: 0.4202\n",
      "Epoch [23/100], Loss: 0.4075\n",
      "Validation Loss: 0.4156\n",
      "Saved the best model with validation loss: 0.4156\n",
      "Epoch [24/100], Loss: 0.4066\n",
      "Validation Loss: 0.4145\n",
      "Saved the best model with validation loss: 0.4145\n",
      "Epoch [25/100], Loss: 0.4062\n",
      "Validation Loss: 0.4136\n",
      "Saved the best model with validation loss: 0.4136\n",
      "Epoch [26/100], Loss: 0.4063\n",
      "Validation Loss: 0.4144\n",
      "Epoch [27/100], Loss: 0.4055\n",
      "Validation Loss: 0.4122\n",
      "Saved the best model with validation loss: 0.4122\n",
      "Epoch [28/100], Loss: 0.4050\n",
      "Validation Loss: 0.4148\n",
      "Epoch [29/100], Loss: 0.4043\n",
      "Validation Loss: 0.4150\n",
      "Epoch [30/100], Loss: 0.4026\n",
      "Validation Loss: 0.4167\n",
      "Epoch [31/100], Loss: 0.4020\n",
      "Validation Loss: 0.4143\n",
      "Epoch [32/100], Loss: 0.4014\n",
      "Validation Loss: 0.4166\n",
      "Epoch [33/100], Loss: 0.4016\n",
      "Validation Loss: 0.4162\n",
      "Epoch [34/100], Loss: 0.4011\n",
      "Validation Loss: 0.4137\n",
      "Epoch [35/100], Loss: 0.4006\n",
      "Validation Loss: 0.4149\n",
      "Epoch [36/100], Loss: 0.4000\n",
      "Validation Loss: 0.4204\n",
      "Epoch [37/100], Loss: 0.3999\n",
      "Validation Loss: 0.4105\n",
      "Saved the best model with validation loss: 0.4105\n",
      "Epoch [38/100], Loss: 0.3983\n",
      "Validation Loss: 0.4146\n",
      "Epoch [39/100], Loss: 0.3985\n",
      "Validation Loss: 0.4145\n",
      "Epoch [40/100], Loss: 0.3994\n",
      "Validation Loss: 0.4090\n",
      "Saved the best model with validation loss: 0.4090\n",
      "Epoch [41/100], Loss: 0.3980\n",
      "Validation Loss: 0.4107\n",
      "Epoch [42/100], Loss: 0.3981\n",
      "Validation Loss: 0.4112\n",
      "Epoch [43/100], Loss: 0.3972\n",
      "Validation Loss: 0.4117\n",
      "Epoch [44/100], Loss: 0.3979\n",
      "Validation Loss: 0.4109\n",
      "Epoch [45/100], Loss: 0.3963\n",
      "Validation Loss: 0.4087\n",
      "Saved the best model with validation loss: 0.4087\n",
      "Epoch [46/100], Loss: 0.3961\n",
      "Validation Loss: 0.4129\n",
      "Epoch [47/100], Loss: 0.3952\n",
      "Validation Loss: 0.4093\n",
      "Epoch [48/100], Loss: 0.3955\n",
      "Validation Loss: 0.4088\n",
      "Epoch [49/100], Loss: 0.3952\n",
      "Validation Loss: 0.4076\n",
      "Saved the best model with validation loss: 0.4076\n",
      "Epoch [50/100], Loss: 0.3952\n",
      "Validation Loss: 0.4097\n",
      "Epoch [51/100], Loss: 0.3943\n",
      "Validation Loss: 0.4082\n",
      "Epoch [52/100], Loss: 0.3943\n",
      "Validation Loss: 0.4071\n",
      "Saved the best model with validation loss: 0.4071\n",
      "Epoch [53/100], Loss: 0.3947\n",
      "Validation Loss: 0.4076\n",
      "Epoch [54/100], Loss: 0.3944\n",
      "Validation Loss: 0.4078\n",
      "Epoch [55/100], Loss: 0.3940\n",
      "Validation Loss: 0.4056\n",
      "Saved the best model with validation loss: 0.4056\n",
      "Epoch [56/100], Loss: 0.3941\n",
      "Validation Loss: 0.4049\n",
      "Saved the best model with validation loss: 0.4049\n",
      "Epoch [57/100], Loss: 0.3930\n",
      "Validation Loss: 0.4067\n",
      "Epoch [58/100], Loss: 0.3932\n",
      "Validation Loss: 0.4052\n",
      "Epoch [59/100], Loss: 0.3937\n",
      "Validation Loss: 0.4091\n",
      "Epoch [60/100], Loss: 0.3927\n",
      "Validation Loss: 0.4061\n",
      "Epoch [61/100], Loss: 0.3921\n",
      "Validation Loss: 0.4080\n",
      "Epoch [62/100], Loss: 0.3917\n",
      "Validation Loss: 0.4060\n",
      "Epoch [63/100], Loss: 0.3924\n",
      "Validation Loss: 0.4076\n",
      "Epoch [64/100], Loss: 0.3920\n",
      "Validation Loss: 0.4063\n",
      "Epoch [65/100], Loss: 0.3915\n",
      "Validation Loss: 0.4045\n",
      "Saved the best model with validation loss: 0.4045\n",
      "Epoch [66/100], Loss: 0.3922\n",
      "Validation Loss: 0.4052\n",
      "Epoch [67/100], Loss: 0.3915\n",
      "Validation Loss: 0.4073\n",
      "Epoch [68/100], Loss: 0.3915\n",
      "Validation Loss: 0.4065\n",
      "Epoch [69/100], Loss: 0.3910\n",
      "Validation Loss: 0.4057\n",
      "Epoch [70/100], Loss: 0.3909\n",
      "Validation Loss: 0.4061\n",
      "Epoch [71/100], Loss: 0.3917\n",
      "Validation Loss: 0.4063\n",
      "Epoch [72/100], Loss: 0.3909\n",
      "Validation Loss: 0.4005\n",
      "Saved the best model with validation loss: 0.4005\n",
      "Epoch [73/100], Loss: 0.3905\n",
      "Validation Loss: 0.4044\n",
      "Epoch [74/100], Loss: 0.3903\n",
      "Validation Loss: 0.4039\n",
      "Epoch [75/100], Loss: 0.3905\n",
      "Validation Loss: 0.4075\n",
      "Epoch [76/100], Loss: 0.3898\n",
      "Validation Loss: 0.4005\n",
      "Epoch [77/100], Loss: 0.3902\n",
      "Validation Loss: 0.4028\n",
      "Epoch [78/100], Loss: 0.3894\n",
      "Validation Loss: 0.4033\n",
      "Epoch [79/100], Loss: 0.3896\n",
      "Validation Loss: 0.4031\n",
      "Epoch [80/100], Loss: 0.3897\n",
      "Validation Loss: 0.4029\n",
      "Epoch [81/100], Loss: 0.3900\n",
      "Validation Loss: 0.4029\n",
      "Epoch [82/100], Loss: 0.3905\n",
      "Validation Loss: 0.4026\n",
      "Epoch [83/100], Loss: 0.3894\n",
      "Validation Loss: 0.4036\n",
      "Epoch [84/100], Loss: 0.3889\n",
      "Validation Loss: 0.3985\n",
      "Saved the best model with validation loss: 0.3985\n",
      "Epoch [85/100], Loss: 0.3888\n",
      "Validation Loss: 0.4004\n",
      "Epoch [86/100], Loss: 0.3886\n",
      "Validation Loss: 0.4004\n",
      "Epoch [87/100], Loss: 0.3885\n",
      "Validation Loss: 0.4030\n",
      "Epoch [88/100], Loss: 0.3885\n",
      "Validation Loss: 0.4025\n",
      "Epoch [89/100], Loss: 0.3887\n",
      "Validation Loss: 0.4002\n",
      "Epoch [90/100], Loss: 0.3889\n",
      "Validation Loss: 0.4031\n",
      "Epoch [91/100], Loss: 0.3887\n",
      "Validation Loss: 0.4018\n",
      "Epoch [92/100], Loss: 0.3886\n",
      "Validation Loss: 0.3984\n",
      "Saved the best model with validation loss: 0.3984\n",
      "Epoch [93/100], Loss: 0.3884\n",
      "Validation Loss: 0.3984\n",
      "Epoch [94/100], Loss: 0.3881\n",
      "Validation Loss: 0.4021\n",
      "Epoch [95/100], Loss: 0.3883\n",
      "Validation Loss: 0.3995\n",
      "Epoch [96/100], Loss: 0.3885\n",
      "Validation Loss: 0.3968\n",
      "Saved the best model with validation loss: 0.3968\n",
      "Epoch [97/100], Loss: 0.3872\n",
      "Validation Loss: 0.4022\n",
      "Epoch [98/100], Loss: 0.3882\n",
      "Validation Loss: 0.4009\n",
      "Epoch [99/100], Loss: 0.3882\n",
      "Validation Loss: 0.4040\n",
      "Epoch [100/100], Loss: 0.3882\n",
      "Validation Loss: 0.4024\n"
     ]
    }
   ],
   "source": [
    "HGNN_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"HGNN: 1-32-16-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb6eca2-d5c7-4ef8-a355-ea168def346a",
   "metadata": {},
   "source": [
    "##### HGNN: Version 3\n",
    "*  Layers: 5 (including input and output layer), sizes: 1 - 16 - 32 - 16 - 2, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "8819470a-9bd5-4afa-b9b9-d7f22f469f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "c2cf05b9-277d-42b8-b912-0a48ecd28292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5683\n",
      "Validation Loss: 0.4796\n",
      "Saved the best model with validation loss: 0.4796\n",
      "Epoch [2/100], Loss: 0.4735\n",
      "Validation Loss: 0.4531\n",
      "Saved the best model with validation loss: 0.4531\n",
      "Epoch [3/100], Loss: 0.4491\n",
      "Validation Loss: 0.4444\n",
      "Saved the best model with validation loss: 0.4444\n",
      "Epoch [4/100], Loss: 0.4381\n",
      "Validation Loss: 0.4366\n",
      "Saved the best model with validation loss: 0.4366\n",
      "Epoch [5/100], Loss: 0.4297\n",
      "Validation Loss: 0.4392\n",
      "Epoch [6/100], Loss: 0.4263\n",
      "Validation Loss: 0.4340\n",
      "Saved the best model with validation loss: 0.4340\n",
      "Epoch [7/100], Loss: 0.4218\n",
      "Validation Loss: 0.4246\n",
      "Saved the best model with validation loss: 0.4246\n",
      "Epoch [8/100], Loss: 0.4193\n",
      "Validation Loss: 0.4253\n",
      "Epoch [9/100], Loss: 0.4151\n",
      "Validation Loss: 0.4187\n",
      "Saved the best model with validation loss: 0.4187\n",
      "Epoch [10/100], Loss: 0.4133\n",
      "Validation Loss: 0.4207\n",
      "Epoch [11/100], Loss: 0.4099\n",
      "Validation Loss: 0.4207\n",
      "Epoch [12/100], Loss: 0.4098\n",
      "Validation Loss: 0.4200\n",
      "Epoch [13/100], Loss: 0.4078\n",
      "Validation Loss: 0.4124\n",
      "Saved the best model with validation loss: 0.4124\n",
      "Epoch [14/100], Loss: 0.4050\n",
      "Validation Loss: 0.4131\n",
      "Epoch [15/100], Loss: 0.4045\n",
      "Validation Loss: 0.4106\n",
      "Saved the best model with validation loss: 0.4106\n",
      "Epoch [16/100], Loss: 0.4021\n",
      "Validation Loss: 0.4082\n",
      "Saved the best model with validation loss: 0.4082\n",
      "Epoch [17/100], Loss: 0.4005\n",
      "Validation Loss: 0.4102\n",
      "Epoch [18/100], Loss: 0.4021\n",
      "Validation Loss: 0.4069\n",
      "Saved the best model with validation loss: 0.4069\n",
      "Epoch [19/100], Loss: 0.3999\n",
      "Validation Loss: 0.4144\n",
      "Epoch [20/100], Loss: 0.4000\n",
      "Validation Loss: 0.4052\n",
      "Saved the best model with validation loss: 0.4052\n",
      "Epoch [21/100], Loss: 0.3976\n",
      "Validation Loss: 0.4262\n",
      "Epoch [22/100], Loss: 0.3992\n",
      "Validation Loss: 0.4022\n",
      "Saved the best model with validation loss: 0.4022\n",
      "Epoch [23/100], Loss: 0.3987\n",
      "Validation Loss: 0.3996\n",
      "Saved the best model with validation loss: 0.3996\n",
      "Epoch [24/100], Loss: 0.3971\n",
      "Validation Loss: 0.3992\n",
      "Saved the best model with validation loss: 0.3992\n",
      "Epoch [25/100], Loss: 0.3946\n",
      "Validation Loss: 0.4026\n",
      "Epoch [26/100], Loss: 0.3965\n",
      "Validation Loss: 0.4003\n",
      "Epoch [27/100], Loss: 0.3971\n",
      "Validation Loss: 0.4074\n",
      "Epoch [28/100], Loss: 0.3931\n",
      "Validation Loss: 0.4017\n",
      "Epoch [29/100], Loss: 0.3928\n",
      "Validation Loss: 0.3985\n",
      "Saved the best model with validation loss: 0.3985\n",
      "Epoch [30/100], Loss: 0.3940\n",
      "Validation Loss: 0.4017\n",
      "Epoch [31/100], Loss: 0.3916\n",
      "Validation Loss: 0.3972\n",
      "Saved the best model with validation loss: 0.3972\n",
      "Epoch [32/100], Loss: 0.3929\n",
      "Validation Loss: 0.4021\n",
      "Epoch [33/100], Loss: 0.3913\n",
      "Validation Loss: 0.3993\n",
      "Epoch [34/100], Loss: 0.3911\n",
      "Validation Loss: 0.4023\n",
      "Epoch [35/100], Loss: 0.3912\n",
      "Validation Loss: 0.4029\n",
      "Epoch [36/100], Loss: 0.3909\n",
      "Validation Loss: 0.4042\n",
      "Epoch [37/100], Loss: 0.3916\n",
      "Validation Loss: 0.4022\n",
      "Epoch [38/100], Loss: 0.3885\n",
      "Validation Loss: 0.4033\n",
      "Epoch [39/100], Loss: 0.3891\n",
      "Validation Loss: 0.4001\n",
      "Epoch [40/100], Loss: 0.3885\n",
      "Validation Loss: 0.4023\n",
      "Epoch [41/100], Loss: 0.3906\n",
      "Validation Loss: 0.3991\n",
      "Epoch [42/100], Loss: 0.3906\n",
      "Validation Loss: 0.4001\n",
      "Epoch [43/100], Loss: 0.3898\n",
      "Validation Loss: 0.4015\n",
      "Epoch [44/100], Loss: 0.3895\n",
      "Validation Loss: 0.3973\n",
      "Epoch [45/100], Loss: 0.3906\n",
      "Validation Loss: 0.3983\n",
      "Epoch [46/100], Loss: 0.3900\n",
      "Validation Loss: 0.3930\n",
      "Saved the best model with validation loss: 0.3930\n",
      "Epoch [47/100], Loss: 0.3880\n",
      "Validation Loss: 0.3996\n",
      "Epoch [48/100], Loss: 0.3891\n",
      "Validation Loss: 0.3974\n",
      "Epoch [49/100], Loss: 0.3875\n",
      "Validation Loss: 0.4008\n",
      "Epoch [50/100], Loss: 0.3871\n",
      "Validation Loss: 0.3977\n",
      "Epoch [51/100], Loss: 0.3895\n",
      "Validation Loss: 0.3976\n",
      "Epoch [52/100], Loss: 0.3897\n",
      "Validation Loss: 0.3980\n",
      "Epoch [53/100], Loss: 0.3873\n",
      "Validation Loss: 0.3972\n",
      "Epoch [54/100], Loss: 0.3873\n",
      "Validation Loss: 0.3994\n",
      "Epoch [55/100], Loss: 0.3884\n",
      "Validation Loss: 0.3967\n",
      "Epoch [56/100], Loss: 0.3862\n",
      "Validation Loss: 0.3974\n",
      "Epoch [57/100], Loss: 0.3872\n",
      "Validation Loss: 0.3964\n",
      "Epoch [58/100], Loss: 0.3875\n",
      "Validation Loss: 0.3994\n",
      "Epoch [59/100], Loss: 0.3855\n",
      "Validation Loss: 0.3980\n",
      "Epoch [60/100], Loss: 0.3854\n",
      "Validation Loss: 0.3959\n",
      "Epoch [61/100], Loss: 0.3845\n",
      "Validation Loss: 0.3976\n",
      "Epoch [62/100], Loss: 0.3843\n",
      "Validation Loss: 0.3920\n",
      "Saved the best model with validation loss: 0.3920\n",
      "Epoch [63/100], Loss: 0.3842\n",
      "Validation Loss: 0.3939\n",
      "Epoch [64/100], Loss: 0.3834\n",
      "Validation Loss: 0.3958\n",
      "Epoch [65/100], Loss: 0.3838\n",
      "Validation Loss: 0.3921\n",
      "Epoch [66/100], Loss: 0.3826\n",
      "Validation Loss: 0.3924\n",
      "Epoch [67/100], Loss: 0.3808\n",
      "Validation Loss: 0.3921\n",
      "Epoch [68/100], Loss: 0.3842\n",
      "Validation Loss: 0.3921\n",
      "Epoch [69/100], Loss: 0.3849\n",
      "Validation Loss: 0.3922\n",
      "Epoch [70/100], Loss: 0.3821\n",
      "Validation Loss: 0.3954\n",
      "Epoch [71/100], Loss: 0.3832\n",
      "Validation Loss: 0.3920\n",
      "Saved the best model with validation loss: 0.3920\n",
      "Epoch [72/100], Loss: 0.3823\n",
      "Validation Loss: 0.3935\n",
      "Epoch [73/100], Loss: 0.3840\n",
      "Validation Loss: 0.3981\n",
      "Epoch [74/100], Loss: 0.3855\n",
      "Validation Loss: 0.3997\n",
      "Epoch [75/100], Loss: 0.3834\n",
      "Validation Loss: 0.3975\n",
      "Epoch [76/100], Loss: 0.3820\n",
      "Validation Loss: 0.4011\n",
      "Epoch [77/100], Loss: 0.3827\n",
      "Validation Loss: 0.4006\n",
      "Epoch [78/100], Loss: 0.3835\n",
      "Validation Loss: 0.4056\n",
      "Epoch [79/100], Loss: 0.3827\n",
      "Validation Loss: 0.4018\n",
      "Epoch [80/100], Loss: 0.3816\n",
      "Validation Loss: 0.4029\n",
      "Epoch [81/100], Loss: 0.3823\n",
      "Validation Loss: 0.4002\n",
      "Epoch [82/100], Loss: 0.3842\n",
      "Validation Loss: 0.4001\n",
      "Epoch [83/100], Loss: 0.3866\n",
      "Validation Loss: 0.3977\n",
      "Epoch [84/100], Loss: 0.3856\n",
      "Validation Loss: 0.4006\n",
      "Epoch [85/100], Loss: 0.3858\n",
      "Validation Loss: 0.3941\n",
      "Epoch [86/100], Loss: 0.3849\n",
      "Validation Loss: 0.3969\n",
      "Epoch [87/100], Loss: 0.3850\n",
      "Validation Loss: 0.3940\n",
      "Epoch [88/100], Loss: 0.3845\n",
      "Validation Loss: 0.3966\n",
      "Epoch [89/100], Loss: 0.3847\n",
      "Validation Loss: 0.3949\n",
      "Epoch [90/100], Loss: 0.3852\n",
      "Validation Loss: 0.3966\n",
      "Epoch [91/100], Loss: 0.3827\n",
      "Validation Loss: 0.3900\n",
      "Saved the best model with validation loss: 0.3900\n",
      "Epoch [92/100], Loss: 0.3819\n",
      "Validation Loss: 0.3933\n",
      "Epoch [93/100], Loss: 0.3827\n",
      "Validation Loss: 0.3924\n",
      "Epoch [94/100], Loss: 0.3808\n",
      "Validation Loss: 0.3936\n",
      "Epoch [95/100], Loss: 0.3844\n",
      "Validation Loss: 0.3954\n",
      "Epoch [96/100], Loss: 0.3839\n",
      "Validation Loss: 0.3940\n",
      "Epoch [97/100], Loss: 0.3836\n",
      "Validation Loss: 0.3912\n",
      "Epoch [98/100], Loss: 0.3815\n",
      "Validation Loss: 0.3958\n",
      "Epoch [99/100], Loss: 0.3796\n",
      "Validation Loss: 0.3916\n",
      "Epoch [100/100], Loss: 0.3822\n",
      "Validation Loss: 0.3906\n"
     ]
    }
   ],
   "source": [
    "HGNN_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"HGNN: 1-16-32-16-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e88723-42c0-4f9f-823c-6d2927d36a78",
   "metadata": {},
   "source": [
    "##### HGNN: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 64 - 2, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "3abf59de-de4b-489a-91d0-d3c86e91856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "796dbb8d-b948-4adb-b6cb-7540440b772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5597\n",
      "Validation Loss: 0.4815\n",
      "Saved the best model with validation loss: 0.4815\n",
      "Epoch [2/100], Loss: 0.4751\n",
      "Validation Loss: 0.4536\n",
      "Saved the best model with validation loss: 0.4536\n",
      "Epoch [3/100], Loss: 0.4505\n",
      "Validation Loss: 0.4439\n",
      "Saved the best model with validation loss: 0.4439\n",
      "Epoch [4/100], Loss: 0.4387\n",
      "Validation Loss: 0.4378\n",
      "Saved the best model with validation loss: 0.4378\n",
      "Epoch [5/100], Loss: 0.4303\n",
      "Validation Loss: 0.4341\n",
      "Saved the best model with validation loss: 0.4341\n",
      "Epoch [6/100], Loss: 0.4249\n",
      "Validation Loss: 0.4343\n",
      "Epoch [7/100], Loss: 0.4203\n",
      "Validation Loss: 0.4295\n",
      "Saved the best model with validation loss: 0.4295\n",
      "Epoch [8/100], Loss: 0.4169\n",
      "Validation Loss: 0.4229\n",
      "Saved the best model with validation loss: 0.4229\n",
      "Epoch [9/100], Loss: 0.4152\n",
      "Validation Loss: 0.4227\n",
      "Saved the best model with validation loss: 0.4227\n",
      "Epoch [10/100], Loss: 0.4121\n",
      "Validation Loss: 0.4228\n",
      "Epoch [11/100], Loss: 0.4107\n",
      "Validation Loss: 0.4197\n",
      "Saved the best model with validation loss: 0.4197\n",
      "Epoch [12/100], Loss: 0.4091\n",
      "Validation Loss: 0.4164\n",
      "Saved the best model with validation loss: 0.4164\n",
      "Epoch [13/100], Loss: 0.4071\n",
      "Validation Loss: 0.4168\n",
      "Epoch [14/100], Loss: 0.4059\n",
      "Validation Loss: 0.4173\n",
      "Epoch [15/100], Loss: 0.4052\n",
      "Validation Loss: 0.4178\n",
      "Epoch [16/100], Loss: 0.4038\n",
      "Validation Loss: 0.4134\n",
      "Saved the best model with validation loss: 0.4134\n",
      "Epoch [17/100], Loss: 0.4023\n",
      "Validation Loss: 0.4123\n",
      "Saved the best model with validation loss: 0.4123\n",
      "Epoch [18/100], Loss: 0.4024\n",
      "Validation Loss: 0.4096\n",
      "Saved the best model with validation loss: 0.4096\n",
      "Epoch [19/100], Loss: 0.4016\n",
      "Validation Loss: 0.4104\n",
      "Epoch [20/100], Loss: 0.4011\n",
      "Validation Loss: 0.4103\n",
      "Epoch [21/100], Loss: 0.4010\n",
      "Validation Loss: 0.4076\n",
      "Saved the best model with validation loss: 0.4076\n",
      "Epoch [22/100], Loss: 0.3994\n",
      "Validation Loss: 0.4092\n",
      "Epoch [23/100], Loss: 0.3989\n",
      "Validation Loss: 0.4052\n",
      "Saved the best model with validation loss: 0.4052\n",
      "Epoch [24/100], Loss: 0.3987\n",
      "Validation Loss: 0.4056\n",
      "Epoch [25/100], Loss: 0.3989\n",
      "Validation Loss: 0.4061\n",
      "Epoch [26/100], Loss: 0.3973\n",
      "Validation Loss: 0.4055\n",
      "Epoch [27/100], Loss: 0.3971\n",
      "Validation Loss: 0.4036\n",
      "Saved the best model with validation loss: 0.4036\n",
      "Epoch [28/100], Loss: 0.3967\n",
      "Validation Loss: 0.4039\n",
      "Epoch [29/100], Loss: 0.3979\n",
      "Validation Loss: 0.4062\n",
      "Epoch [30/100], Loss: 0.3976\n",
      "Validation Loss: 0.3997\n",
      "Saved the best model with validation loss: 0.3997\n",
      "Epoch [31/100], Loss: 0.3972\n",
      "Validation Loss: 0.4014\n",
      "Epoch [32/100], Loss: 0.3962\n",
      "Validation Loss: 0.4009\n",
      "Epoch [33/100], Loss: 0.3955\n",
      "Validation Loss: 0.4036\n",
      "Epoch [34/100], Loss: 0.3946\n",
      "Validation Loss: 0.4028\n",
      "Epoch [35/100], Loss: 0.3937\n",
      "Validation Loss: 0.4017\n",
      "Epoch [36/100], Loss: 0.3938\n",
      "Validation Loss: 0.4019\n",
      "Epoch [37/100], Loss: 0.3944\n",
      "Validation Loss: 0.4006\n",
      "Epoch [38/100], Loss: 0.3929\n",
      "Validation Loss: 0.4074\n",
      "Epoch [39/100], Loss: 0.3937\n",
      "Validation Loss: 0.4019\n",
      "Epoch [40/100], Loss: 0.3932\n",
      "Validation Loss: 0.4016\n",
      "Epoch [41/100], Loss: 0.3934\n",
      "Validation Loss: 0.4006\n",
      "Epoch [42/100], Loss: 0.3939\n",
      "Validation Loss: 0.3980\n",
      "Saved the best model with validation loss: 0.3980\n",
      "Epoch [43/100], Loss: 0.3929\n",
      "Validation Loss: 0.4000\n",
      "Epoch [44/100], Loss: 0.3926\n",
      "Validation Loss: 0.4038\n",
      "Epoch [45/100], Loss: 0.3920\n",
      "Validation Loss: 0.4018\n",
      "Epoch [46/100], Loss: 0.3915\n",
      "Validation Loss: 0.3970\n",
      "Saved the best model with validation loss: 0.3970\n",
      "Epoch [47/100], Loss: 0.3924\n",
      "Validation Loss: 0.4015\n",
      "Epoch [48/100], Loss: 0.3908\n",
      "Validation Loss: 0.4014\n",
      "Epoch [49/100], Loss: 0.3909\n",
      "Validation Loss: 0.3999\n",
      "Epoch [50/100], Loss: 0.3915\n",
      "Validation Loss: 0.3991\n",
      "Epoch [51/100], Loss: 0.3937\n",
      "Validation Loss: 0.3959\n",
      "Saved the best model with validation loss: 0.3959\n",
      "Epoch [52/100], Loss: 0.3932\n",
      "Validation Loss: 0.3973\n",
      "Epoch [53/100], Loss: 0.3906\n",
      "Validation Loss: 0.3954\n",
      "Saved the best model with validation loss: 0.3954\n",
      "Epoch [54/100], Loss: 0.3935\n",
      "Validation Loss: 0.3965\n",
      "Epoch [55/100], Loss: 0.3904\n",
      "Validation Loss: 0.3968\n",
      "Epoch [56/100], Loss: 0.3896\n",
      "Validation Loss: 0.3956\n",
      "Epoch [57/100], Loss: 0.3908\n",
      "Validation Loss: 0.3950\n",
      "Saved the best model with validation loss: 0.3950\n",
      "Epoch [58/100], Loss: 0.3911\n",
      "Validation Loss: 0.3984\n",
      "Epoch [59/100], Loss: 0.3917\n",
      "Validation Loss: 0.3936\n",
      "Saved the best model with validation loss: 0.3936\n",
      "Epoch [60/100], Loss: 0.3924\n",
      "Validation Loss: 0.3926\n",
      "Saved the best model with validation loss: 0.3926\n",
      "Epoch [61/100], Loss: 0.3958\n",
      "Validation Loss: 0.3956\n",
      "Epoch [62/100], Loss: 0.3896\n",
      "Validation Loss: 0.3943\n",
      "Epoch [63/100], Loss: 0.3896\n",
      "Validation Loss: 0.3929\n",
      "Epoch [64/100], Loss: 0.3893\n",
      "Validation Loss: 0.3916\n",
      "Saved the best model with validation loss: 0.3916\n",
      "Epoch [65/100], Loss: 0.3889\n",
      "Validation Loss: 0.3895\n",
      "Saved the best model with validation loss: 0.3895\n",
      "Epoch [66/100], Loss: 0.3882\n",
      "Validation Loss: 0.3912\n",
      "Epoch [67/100], Loss: 0.3879\n",
      "Validation Loss: 0.3893\n",
      "Saved the best model with validation loss: 0.3893\n",
      "Epoch [68/100], Loss: 0.3874\n",
      "Validation Loss: 0.3911\n",
      "Epoch [69/100], Loss: 0.3878\n",
      "Validation Loss: 0.3919\n",
      "Epoch [70/100], Loss: 0.3882\n",
      "Validation Loss: 0.3938\n",
      "Epoch [71/100], Loss: 0.3874\n",
      "Validation Loss: 0.3962\n",
      "Epoch [72/100], Loss: 0.3895\n",
      "Validation Loss: 0.3988\n",
      "Epoch [73/100], Loss: 0.3894\n",
      "Validation Loss: 0.3925\n",
      "Epoch [74/100], Loss: 0.3889\n",
      "Validation Loss: 0.3963\n",
      "Epoch [75/100], Loss: 0.3873\n",
      "Validation Loss: 0.3953\n",
      "Epoch [76/100], Loss: 0.3866\n",
      "Validation Loss: 0.3918\n",
      "Epoch [77/100], Loss: 0.3892\n",
      "Validation Loss: 0.3925\n",
      "Epoch [78/100], Loss: 0.3890\n",
      "Validation Loss: 0.3894\n",
      "Epoch [79/100], Loss: 0.3870\n",
      "Validation Loss: 0.3894\n",
      "Epoch [80/100], Loss: 0.3881\n",
      "Validation Loss: 0.3941\n",
      "Epoch [81/100], Loss: 0.3863\n",
      "Validation Loss: 0.3943\n",
      "Epoch [82/100], Loss: 0.3883\n",
      "Validation Loss: 0.3956\n",
      "Epoch [83/100], Loss: 0.3843\n",
      "Validation Loss: 0.3876\n",
      "Saved the best model with validation loss: 0.3876\n",
      "Epoch [84/100], Loss: 0.3865\n",
      "Validation Loss: 0.3844\n",
      "Saved the best model with validation loss: 0.3844\n",
      "Epoch [85/100], Loss: 0.3847\n",
      "Validation Loss: 0.3851\n",
      "Epoch [86/100], Loss: 0.3847\n",
      "Validation Loss: 0.3887\n",
      "Epoch [87/100], Loss: 0.3874\n",
      "Validation Loss: 0.3849\n",
      "Epoch [88/100], Loss: 0.3902\n",
      "Validation Loss: 0.3900\n",
      "Epoch [89/100], Loss: 0.3855\n",
      "Validation Loss: 0.3922\n",
      "Epoch [90/100], Loss: 0.3876\n",
      "Validation Loss: 0.3879\n",
      "Epoch [91/100], Loss: 0.3872\n",
      "Validation Loss: 0.3885\n",
      "Epoch [92/100], Loss: 0.3873\n",
      "Validation Loss: 0.3928\n",
      "Epoch [93/100], Loss: 0.3872\n",
      "Validation Loss: 0.3872\n",
      "Epoch [94/100], Loss: 0.3847\n",
      "Validation Loss: 0.3903\n",
      "Epoch [95/100], Loss: 0.3845\n",
      "Validation Loss: 0.3942\n",
      "Epoch [96/100], Loss: 0.3875\n",
      "Validation Loss: 0.4017\n",
      "Epoch [97/100], Loss: 0.3854\n",
      "Validation Loss: 0.3914\n",
      "Epoch [98/100], Loss: 0.3838\n",
      "Validation Loss: 0.3953\n",
      "Epoch [99/100], Loss: 0.3835\n",
      "Validation Loss: 0.3906\n",
      "Epoch [100/100], Loss: 0.3859\n",
      "Validation Loss: 0.3867\n"
     ]
    }
   ],
   "source": [
    "HGNN_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"HGNN: 1-32-64-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a80d0-2d9c-4b99-81ec-3b10f2a2fd17",
   "metadata": {},
   "source": [
    "##### HGNN: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 4 - 16 - 2, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "ae8d16b1-91db-4136-b4c2-0e0c0f6db3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "d72ef586-de14-4fc9-ad14-90bd3a2dd245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6142\n",
      "Validation Loss: 0.5444\n",
      "Saved the best model with validation loss: 0.5444\n",
      "Epoch [2/100], Loss: 0.5300\n",
      "Validation Loss: 0.4960\n",
      "Saved the best model with validation loss: 0.4960\n",
      "Epoch [3/100], Loss: 0.4934\n",
      "Validation Loss: 0.4754\n",
      "Saved the best model with validation loss: 0.4754\n",
      "Epoch [4/100], Loss: 0.4735\n",
      "Validation Loss: 0.4704\n",
      "Saved the best model with validation loss: 0.4704\n",
      "Epoch [5/100], Loss: 0.4619\n",
      "Validation Loss: 0.4594\n",
      "Saved the best model with validation loss: 0.4594\n",
      "Epoch [6/100], Loss: 0.4526\n",
      "Validation Loss: 0.4532\n",
      "Saved the best model with validation loss: 0.4532\n",
      "Epoch [7/100], Loss: 0.4461\n",
      "Validation Loss: 0.4492\n",
      "Saved the best model with validation loss: 0.4492\n",
      "Epoch [8/100], Loss: 0.4410\n",
      "Validation Loss: 0.4477\n",
      "Saved the best model with validation loss: 0.4477\n",
      "Epoch [9/100], Loss: 0.4377\n",
      "Validation Loss: 0.4457\n",
      "Saved the best model with validation loss: 0.4457\n",
      "Epoch [10/100], Loss: 0.4347\n",
      "Validation Loss: 0.4456\n",
      "Saved the best model with validation loss: 0.4456\n",
      "Epoch [11/100], Loss: 0.4317\n",
      "Validation Loss: 0.4432\n",
      "Saved the best model with validation loss: 0.4432\n",
      "Epoch [12/100], Loss: 0.4299\n",
      "Validation Loss: 0.4431\n",
      "Saved the best model with validation loss: 0.4431\n",
      "Epoch [13/100], Loss: 0.4278\n",
      "Validation Loss: 0.4415\n",
      "Saved the best model with validation loss: 0.4415\n",
      "Epoch [14/100], Loss: 0.4264\n",
      "Validation Loss: 0.4418\n",
      "Epoch [15/100], Loss: 0.4252\n",
      "Validation Loss: 0.4403\n",
      "Saved the best model with validation loss: 0.4403\n",
      "Epoch [16/100], Loss: 0.4246\n",
      "Validation Loss: 0.4407\n",
      "Epoch [17/100], Loss: 0.4229\n",
      "Validation Loss: 0.4375\n",
      "Saved the best model with validation loss: 0.4375\n",
      "Epoch [18/100], Loss: 0.4217\n",
      "Validation Loss: 0.4382\n",
      "Epoch [19/100], Loss: 0.4219\n",
      "Validation Loss: 0.4360\n",
      "Saved the best model with validation loss: 0.4360\n",
      "Epoch [20/100], Loss: 0.4199\n",
      "Validation Loss: 0.4351\n",
      "Saved the best model with validation loss: 0.4351\n",
      "Epoch [21/100], Loss: 0.4189\n",
      "Validation Loss: 0.4349\n",
      "Saved the best model with validation loss: 0.4349\n",
      "Epoch [22/100], Loss: 0.4186\n",
      "Validation Loss: 0.4332\n",
      "Saved the best model with validation loss: 0.4332\n",
      "Epoch [23/100], Loss: 0.4181\n",
      "Validation Loss: 0.4309\n",
      "Saved the best model with validation loss: 0.4309\n",
      "Epoch [24/100], Loss: 0.4180\n",
      "Validation Loss: 0.4312\n",
      "Epoch [25/100], Loss: 0.4166\n",
      "Validation Loss: 0.4302\n",
      "Saved the best model with validation loss: 0.4302\n",
      "Epoch [26/100], Loss: 0.4164\n",
      "Validation Loss: 0.4294\n",
      "Saved the best model with validation loss: 0.4294\n",
      "Epoch [27/100], Loss: 0.4157\n",
      "Validation Loss: 0.4299\n",
      "Epoch [28/100], Loss: 0.4151\n",
      "Validation Loss: 0.4282\n",
      "Saved the best model with validation loss: 0.4282\n",
      "Epoch [29/100], Loss: 0.4153\n",
      "Validation Loss: 0.4264\n",
      "Saved the best model with validation loss: 0.4264\n",
      "Epoch [30/100], Loss: 0.4138\n",
      "Validation Loss: 0.4271\n",
      "Epoch [31/100], Loss: 0.4139\n",
      "Validation Loss: 0.4248\n",
      "Saved the best model with validation loss: 0.4248\n",
      "Epoch [32/100], Loss: 0.4124\n",
      "Validation Loss: 0.4227\n",
      "Saved the best model with validation loss: 0.4227\n",
      "Epoch [33/100], Loss: 0.4110\n",
      "Validation Loss: 0.4229\n",
      "Epoch [34/100], Loss: 0.4099\n",
      "Validation Loss: 0.4217\n",
      "Saved the best model with validation loss: 0.4217\n",
      "Epoch [35/100], Loss: 0.4088\n",
      "Validation Loss: 0.4200\n",
      "Saved the best model with validation loss: 0.4200\n",
      "Epoch [36/100], Loss: 0.4084\n",
      "Validation Loss: 0.4190\n",
      "Saved the best model with validation loss: 0.4190\n",
      "Epoch [37/100], Loss: 0.4079\n",
      "Validation Loss: 0.4171\n",
      "Saved the best model with validation loss: 0.4171\n",
      "Epoch [38/100], Loss: 0.4075\n",
      "Validation Loss: 0.4170\n",
      "Saved the best model with validation loss: 0.4170\n",
      "Epoch [39/100], Loss: 0.4072\n",
      "Validation Loss: 0.4172\n",
      "Epoch [40/100], Loss: 0.4073\n",
      "Validation Loss: 0.4156\n",
      "Saved the best model with validation loss: 0.4156\n",
      "Epoch [41/100], Loss: 0.4062\n",
      "Validation Loss: 0.4168\n",
      "Epoch [42/100], Loss: 0.4057\n",
      "Validation Loss: 0.4176\n",
      "Epoch [43/100], Loss: 0.4059\n",
      "Validation Loss: 0.4163\n",
      "Epoch [44/100], Loss: 0.4055\n",
      "Validation Loss: 0.4158\n",
      "Epoch [45/100], Loss: 0.4051\n",
      "Validation Loss: 0.4156\n",
      "Epoch [46/100], Loss: 0.4050\n",
      "Validation Loss: 0.4153\n",
      "Saved the best model with validation loss: 0.4153\n",
      "Epoch [47/100], Loss: 0.4044\n",
      "Validation Loss: 0.4148\n",
      "Saved the best model with validation loss: 0.4148\n",
      "Epoch [48/100], Loss: 0.4045\n",
      "Validation Loss: 0.4154\n",
      "Epoch [49/100], Loss: 0.4040\n",
      "Validation Loss: 0.4164\n",
      "Epoch [50/100], Loss: 0.4034\n",
      "Validation Loss: 0.4163\n",
      "Epoch [51/100], Loss: 0.4038\n",
      "Validation Loss: 0.4130\n",
      "Saved the best model with validation loss: 0.4130\n",
      "Epoch [52/100], Loss: 0.4041\n",
      "Validation Loss: 0.4113\n",
      "Saved the best model with validation loss: 0.4113\n",
      "Epoch [53/100], Loss: 0.4034\n",
      "Validation Loss: 0.4111\n",
      "Saved the best model with validation loss: 0.4111\n",
      "Epoch [54/100], Loss: 0.4026\n",
      "Validation Loss: 0.4114\n",
      "Epoch [55/100], Loss: 0.4029\n",
      "Validation Loss: 0.4109\n",
      "Saved the best model with validation loss: 0.4109\n",
      "Epoch [56/100], Loss: 0.4024\n",
      "Validation Loss: 0.4091\n",
      "Saved the best model with validation loss: 0.4091\n",
      "Epoch [57/100], Loss: 0.4026\n",
      "Validation Loss: 0.4097\n",
      "Epoch [58/100], Loss: 0.4017\n",
      "Validation Loss: 0.4092\n",
      "Epoch [59/100], Loss: 0.4019\n",
      "Validation Loss: 0.4104\n",
      "Epoch [60/100], Loss: 0.4016\n",
      "Validation Loss: 0.4084\n",
      "Saved the best model with validation loss: 0.4084\n",
      "Epoch [61/100], Loss: 0.4012\n",
      "Validation Loss: 0.4082\n",
      "Saved the best model with validation loss: 0.4082\n",
      "Epoch [62/100], Loss: 0.4014\n",
      "Validation Loss: 0.4064\n",
      "Saved the best model with validation loss: 0.4064\n",
      "Epoch [63/100], Loss: 0.4015\n",
      "Validation Loss: 0.4038\n",
      "Saved the best model with validation loss: 0.4038\n",
      "Epoch [64/100], Loss: 0.4003\n",
      "Validation Loss: 0.4048\n",
      "Epoch [65/100], Loss: 0.4005\n",
      "Validation Loss: 0.4056\n",
      "Epoch [66/100], Loss: 0.4006\n",
      "Validation Loss: 0.4051\n",
      "Epoch [67/100], Loss: 0.4008\n",
      "Validation Loss: 0.4073\n",
      "Epoch [68/100], Loss: 0.4007\n",
      "Validation Loss: 0.4068\n",
      "Epoch [69/100], Loss: 0.3998\n",
      "Validation Loss: 0.4072\n",
      "Epoch [70/100], Loss: 0.4008\n",
      "Validation Loss: 0.4044\n",
      "Epoch [71/100], Loss: 0.4009\n",
      "Validation Loss: 0.4056\n",
      "Epoch [72/100], Loss: 0.4006\n",
      "Validation Loss: 0.4047\n",
      "Epoch [73/100], Loss: 0.4002\n",
      "Validation Loss: 0.4046\n",
      "Epoch [74/100], Loss: 0.3991\n",
      "Validation Loss: 0.4036\n",
      "Saved the best model with validation loss: 0.4036\n",
      "Epoch [75/100], Loss: 0.3988\n",
      "Validation Loss: 0.4050\n",
      "Epoch [76/100], Loss: 0.3991\n",
      "Validation Loss: 0.4029\n",
      "Saved the best model with validation loss: 0.4029\n",
      "Epoch [77/100], Loss: 0.3987\n",
      "Validation Loss: 0.4043\n",
      "Epoch [78/100], Loss: 0.3982\n",
      "Validation Loss: 0.4023\n",
      "Saved the best model with validation loss: 0.4023\n",
      "Epoch [79/100], Loss: 0.3979\n",
      "Validation Loss: 0.4033\n",
      "Epoch [80/100], Loss: 0.3978\n",
      "Validation Loss: 0.4031\n",
      "Epoch [81/100], Loss: 0.3979\n",
      "Validation Loss: 0.4021\n",
      "Saved the best model with validation loss: 0.4021\n",
      "Epoch [82/100], Loss: 0.3982\n",
      "Validation Loss: 0.4009\n",
      "Saved the best model with validation loss: 0.4009\n",
      "Epoch [83/100], Loss: 0.3977\n",
      "Validation Loss: 0.3999\n",
      "Saved the best model with validation loss: 0.3999\n",
      "Epoch [84/100], Loss: 0.3976\n",
      "Validation Loss: 0.4015\n",
      "Epoch [85/100], Loss: 0.3973\n",
      "Validation Loss: 0.4009\n",
      "Epoch [86/100], Loss: 0.3977\n",
      "Validation Loss: 0.4013\n",
      "Epoch [87/100], Loss: 0.3969\n",
      "Validation Loss: 0.4024\n",
      "Epoch [88/100], Loss: 0.3966\n",
      "Validation Loss: 0.3999\n",
      "Epoch [89/100], Loss: 0.3969\n",
      "Validation Loss: 0.3986\n",
      "Saved the best model with validation loss: 0.3986\n",
      "Epoch [90/100], Loss: 0.3967\n",
      "Validation Loss: 0.3990\n",
      "Epoch [91/100], Loss: 0.3967\n",
      "Validation Loss: 0.4027\n",
      "Epoch [92/100], Loss: 0.3965\n",
      "Validation Loss: 0.4019\n",
      "Epoch [93/100], Loss: 0.3969\n",
      "Validation Loss: 0.3983\n",
      "Saved the best model with validation loss: 0.3983\n",
      "Epoch [94/100], Loss: 0.3967\n",
      "Validation Loss: 0.4000\n",
      "Epoch [95/100], Loss: 0.3960\n",
      "Validation Loss: 0.3985\n",
      "Epoch [96/100], Loss: 0.3967\n",
      "Validation Loss: 0.3985\n",
      "Epoch [97/100], Loss: 0.3962\n",
      "Validation Loss: 0.3992\n",
      "Epoch [98/100], Loss: 0.3959\n",
      "Validation Loss: 0.4005\n",
      "Epoch [99/100], Loss: 0.3967\n",
      "Validation Loss: 0.3997\n",
      "Epoch [100/100], Loss: 0.3956\n",
      "Validation Loss: 0.3970\n",
      "Saved the best model with validation loss: 0.3970\n"
     ]
    }
   ],
   "source": [
    "HGNN_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"HGNN: 1-4-16-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "6aed147a-aa7e-40e7-8b5b-632fcd4e08e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.800758</td>\n",
       "      <td>0.809452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>0.817704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.812879</td>\n",
       "      <td>0.833458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.679181</td>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.684091</td>\n",
       "      <td>0.555139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.533784</td>\n",
       "      <td>0.714773</td>\n",
       "      <td>0.579145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.710606</td>\n",
       "      <td>0.525881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-2</th>\n",
       "      <td>0.720137</td>\n",
       "      <td>0.574324</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-2</th>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.574324</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-2</th>\n",
       "      <td>0.716724</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-2</th>\n",
       "      <td>0.703072</td>\n",
       "      <td>0.614865</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-2</th>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-2</th>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-2</th>\n",
       "      <td>0.706485</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-2</th>\n",
       "      <td>0.774744</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-2</th>\n",
       "      <td>0.754266</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-2</th>\n",
       "      <td>0.706485</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-2</th>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-2</th>\n",
       "      <td>0.730375</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-2</th>\n",
       "      <td>0.774744</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-2</th>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-2</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-2</th>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-2</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-2</th>\n",
       "      <td>0.750853</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-2</th>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-2</th>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-2</th>\n",
       "      <td>0.805461</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-2</th>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-2</th>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-2</th>\n",
       "      <td>0.805461</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-2</th>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   acc       rec       acc       rec\n",
       "5-NN                          0.829352  0.824324  0.800758  0.809452\n",
       "Decision tree                 0.836177  0.797297  0.814394  0.817704\n",
       "Random forest                 0.832765  0.831081  0.812879  0.833458\n",
       "SVM linear                    0.679181  0.506757  0.684091  0.555139\n",
       "SVM poly                      0.696246  0.533784  0.714773  0.579145\n",
       "SVM rbf                       0.713311  0.513514  0.710606  0.525881\n",
       "MLP: 17-5-2                   0.720137  0.574324         -         -\n",
       "MLP: 17-10-2                  0.692833  0.574324         -         -\n",
       "MLP: 17-20-2                  0.716724  0.587838         -         -\n",
       "MLP: 17-25-2                  0.703072  0.614865         -         -\n",
       "MLP: 17-40-2                  0.696246  0.608108         -         -\n",
       "MLP: 17-60-2                  0.713311  0.655405         -         -\n",
       "MLP: 17-10-5-2                0.706485  0.641892         -         -\n",
       "MLP: 17-20-10-2               0.774744  0.797297         -         -\n",
       "MLP: 17-40-20-2               0.754266  0.729730         -         -\n",
       "MLP: 17-40-10-2               0.706485  0.513514         -         -\n",
       "MLP: 17-60-40-2               0.767918  0.695946         -         -\n",
       "MLP: 17-60-20-2               0.730375  0.641892         -         -\n",
       "MLP: 17-80-50-2               0.774744  0.702703         -         -\n",
       "MLP, small-median: 7-80-50-2  0.767918  0.702703         -         -\n",
       "MLP, small-mean: 7-80-50-2    0.744027  0.655405         -         -\n",
       "MLP, small-min: 7-80-50-2     0.737201  0.689189         -         -\n",
       "MLP, small-max: 7-80-50-2     0.744027  0.709459         -         -\n",
       "MLP, small-q25: 7-80-50-2     0.750853  0.662162         -         -\n",
       "MLP, small-q75: 7-80-50-2     0.737201  0.655405         -         -\n",
       "MLP, custom: 7-80-50-2        0.767918  0.743243         -         -\n",
       "HGNN: 1-16-32-2               0.805461  0.783784         -         -\n",
       "HGNN: 1-32-16-2               0.798635  0.783784         -         -\n",
       "HGNN: 1-16-32-16-2            0.798635  0.783784         -         -\n",
       "HGNN: 1-32-64-2               0.805461  0.770270         -         -\n",
       "HGNN: 1-4-16-2                0.798635  0.783784         -         -"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67dc5cd",
   "metadata": {},
   "source": [
    "### HGNN (Hypergraph Neural Network) with three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7c47a",
   "metadata": {},
   "source": [
    "*  Loss: Cross-Entropy\n",
    "*  Epochs: 100 (saving best model)\n",
    "*  Leaning rate: 0.001\n",
    "*  Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176fb80",
   "metadata": {},
   "source": [
    "##### HGNN: Version 1, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 16 - 32 - 3, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b540e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"HGNN 0.5: 1-16-32-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"HGNN 0.1: 1-16-32-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d27fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"HGNN 0.05: 1-16-32-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"HGNN 0.01: 1-16-32-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61750480",
   "metadata": {},
   "source": [
    "##### HGNN: Version 2, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 16 - 3, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"HGNN 0.5: 1-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860cb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"HGNN 0.1: 1-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932cbb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"HGNN 0.05: 1-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"HGNN 0.01: 1-32-16-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6821f8be",
   "metadata": {},
   "source": [
    "##### HGNN: Version 3\n",
    "*  Layers: 5 (including input and output layer), sizes: 1 - 16 - 32 - 16 - 3, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfaf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4035f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"HGNN 0.5: 1-16-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8dfa76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"HGNN 0.1: 1-16-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e09ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"HGNN 0.05: 1-16-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa03176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"HGNN 0.01: 1-16-32-16-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844010c",
   "metadata": {},
   "source": [
    "##### HGNN: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 64 - 3, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690e452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c143569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"HGNN 0.5: 1-32-64-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735adb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"HGNN 0.1: 1-32-64-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b9257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"HGNN 0.05: 1-32-64-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0db41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"HGNN 0.01: 1-32-64-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee856a",
   "metadata": {},
   "source": [
    "##### HGNN: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 4 - 16 - 3, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6315ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"HGNN 0.5: 1-4-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862adfdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"HGNN 0.1: 1-4-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c4a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"HGNN 0.05: 1-4-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234e626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"HGNN 0.01: 1-4-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f4151",
   "metadata": {},
   "source": [
    "### HGNN (Hypergraph neural network) with time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "bbb12a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, label_series, hypergraph_column_name):\n",
    "        # Extract features and convert to tensor\n",
    "        self.X = torch.from_numpy(dataframe.drop(columns=[hypergraph_column_name]).values).float()\n",
    "        \n",
    "        # Extract labels and convert to tensor\n",
    "        self.y = torch.from_numpy(label_series.values).float()\n",
    "        \n",
    "        # Store hypergraph objects\n",
    "        self.hypergraphs = dataframe[hypergraph_column_name].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.X[index],\n",
    "            'label': self.y[index],\n",
    "            'hypergraph': self.hypergraphs[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "a4a3f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HGNN_regression(X_training, y_training, X_validation, y_validation, text):\n",
    "    model = HGNN(random_seed = 20)  \n",
    "\n",
    "    dataset = CustomDataset(X_training, y_training, hypergraph_column_name='hypergraph')\n",
    "    validation = CustomDataset(X_validation, y_validation, hypergraph_column_name='hypergraph')\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for item in dataset:\n",
    "            optimizer.zero_grad()\n",
    "            input_features = item[\"data\"]\n",
    "            input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "            label = item[\"label\"].float().squeeze(0)\n",
    "            output = model(input_hg)\n",
    "            \n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataset):.4f}')\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for item in validation:\n",
    "                input_features = item[\"data\"]\n",
    "                input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "                label = item[\"label\"].float().squeeze(0)\n",
    "                output = model(input_hg)\n",
    "                loss = loss_function(output, label)\n",
    "                val_loss += loss.item()\n",
    "    \n",
    "        val_loss /= len(validation)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "        # Save the model if the validation loss is the best we've seen so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Saved the best model with validation loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for item in validation:\n",
    "            i += 1\n",
    "            output = model(item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0))\n",
    "            predicted.append(output.item())\n",
    "\n",
    "    mse = mean_squared_error(y_validation, predicted)\n",
    "    mae = mean_absolute_error(y_validation, predicted)\n",
    "    r2 = r2_score(y_validation, predicted)\n",
    "    \n",
    "    table_time_diff.loc[text] = [mse, mae, r2, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b77604",
   "metadata": {},
   "source": [
    "##### HGNN: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 16 - 32 - 1, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "886aa909",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "9aa591ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7029\n",
      "Validation Loss: 1.3213\n",
      "Saved the best model with validation loss: 1.3213\n",
      "Epoch [2/100], Loss: 1.0438\n",
      "Validation Loss: 1.0668\n",
      "Saved the best model with validation loss: 1.0668\n",
      "Epoch [3/100], Loss: 0.8770\n",
      "Validation Loss: 0.9517\n",
      "Saved the best model with validation loss: 0.9517\n",
      "Epoch [4/100], Loss: 0.7989\n",
      "Validation Loss: 0.8756\n",
      "Saved the best model with validation loss: 0.8756\n",
      "Epoch [5/100], Loss: 0.7454\n",
      "Validation Loss: 0.8123\n",
      "Saved the best model with validation loss: 0.8123\n",
      "Epoch [6/100], Loss: 0.7161\n",
      "Validation Loss: 0.7902\n",
      "Saved the best model with validation loss: 0.7902\n",
      "Epoch [7/100], Loss: 0.6921\n",
      "Validation Loss: 0.7593\n",
      "Saved the best model with validation loss: 0.7593\n",
      "Epoch [8/100], Loss: 0.6774\n",
      "Validation Loss: 0.7434\n",
      "Saved the best model with validation loss: 0.7434\n",
      "Epoch [9/100], Loss: 0.6615\n",
      "Validation Loss: 0.7339\n",
      "Saved the best model with validation loss: 0.7339\n",
      "Epoch [10/100], Loss: 0.6518\n",
      "Validation Loss: 0.7218\n",
      "Saved the best model with validation loss: 0.7218\n",
      "Epoch [11/100], Loss: 0.6444\n",
      "Validation Loss: 0.7204\n",
      "Saved the best model with validation loss: 0.7204\n",
      "Epoch [12/100], Loss: 0.6399\n",
      "Validation Loss: 0.7180\n",
      "Saved the best model with validation loss: 0.7180\n",
      "Epoch [13/100], Loss: 0.6360\n",
      "Validation Loss: 0.7175\n",
      "Saved the best model with validation loss: 0.7175\n",
      "Epoch [14/100], Loss: 0.6306\n",
      "Validation Loss: 0.7132\n",
      "Saved the best model with validation loss: 0.7132\n",
      "Epoch [15/100], Loss: 0.6271\n",
      "Validation Loss: 0.7092\n",
      "Saved the best model with validation loss: 0.7092\n",
      "Epoch [16/100], Loss: 0.6235\n",
      "Validation Loss: 0.6970\n",
      "Saved the best model with validation loss: 0.6970\n",
      "Epoch [17/100], Loss: 0.6213\n",
      "Validation Loss: 0.7009\n",
      "Epoch [18/100], Loss: 0.6201\n",
      "Validation Loss: 0.7065\n",
      "Epoch [19/100], Loss: 0.6160\n",
      "Validation Loss: 0.7015\n",
      "Epoch [20/100], Loss: 0.6130\n",
      "Validation Loss: 0.7009\n",
      "Epoch [21/100], Loss: 0.6127\n",
      "Validation Loss: 0.6988\n",
      "Epoch [22/100], Loss: 0.6113\n",
      "Validation Loss: 0.6929\n",
      "Saved the best model with validation loss: 0.6929\n",
      "Epoch [23/100], Loss: 0.6075\n",
      "Validation Loss: 0.6956\n",
      "Epoch [24/100], Loss: 0.6077\n",
      "Validation Loss: 0.6967\n",
      "Epoch [25/100], Loss: 0.6061\n",
      "Validation Loss: 0.6974\n",
      "Epoch [26/100], Loss: 0.6040\n",
      "Validation Loss: 0.6943\n",
      "Epoch [27/100], Loss: 0.6041\n",
      "Validation Loss: 0.6919\n",
      "Saved the best model with validation loss: 0.6919\n",
      "Epoch [28/100], Loss: 0.6028\n",
      "Validation Loss: 0.6936\n",
      "Epoch [29/100], Loss: 0.6001\n",
      "Validation Loss: 0.6932\n",
      "Epoch [30/100], Loss: 0.5991\n",
      "Validation Loss: 0.6874\n",
      "Saved the best model with validation loss: 0.6874\n",
      "Epoch [31/100], Loss: 0.5983\n",
      "Validation Loss: 0.6891\n",
      "Epoch [32/100], Loss: 0.5979\n",
      "Validation Loss: 0.6898\n",
      "Epoch [33/100], Loss: 0.5980\n",
      "Validation Loss: 0.6879\n",
      "Epoch [34/100], Loss: 0.5985\n",
      "Validation Loss: 0.6873\n",
      "Saved the best model with validation loss: 0.6873\n",
      "Epoch [35/100], Loss: 0.5949\n",
      "Validation Loss: 0.6789\n",
      "Saved the best model with validation loss: 0.6789\n",
      "Epoch [36/100], Loss: 0.5923\n",
      "Validation Loss: 0.6806\n",
      "Epoch [37/100], Loss: 0.5924\n",
      "Validation Loss: 0.6891\n",
      "Epoch [38/100], Loss: 0.5914\n",
      "Validation Loss: 0.6770\n",
      "Saved the best model with validation loss: 0.6770\n",
      "Epoch [39/100], Loss: 0.5922\n",
      "Validation Loss: 0.6800\n",
      "Epoch [40/100], Loss: 0.5907\n",
      "Validation Loss: 0.6814\n",
      "Epoch [41/100], Loss: 0.5904\n",
      "Validation Loss: 0.6792\n",
      "Epoch [42/100], Loss: 0.5870\n",
      "Validation Loss: 0.6832\n",
      "Epoch [43/100], Loss: 0.5871\n",
      "Validation Loss: 0.6757\n",
      "Saved the best model with validation loss: 0.6757\n",
      "Epoch [44/100], Loss: 0.5873\n",
      "Validation Loss: 0.6805\n",
      "Epoch [45/100], Loss: 0.5873\n",
      "Validation Loss: 0.6792\n",
      "Epoch [46/100], Loss: 0.5861\n",
      "Validation Loss: 0.6737\n",
      "Saved the best model with validation loss: 0.6737\n",
      "Epoch [47/100], Loss: 0.5864\n",
      "Validation Loss: 0.6916\n",
      "Epoch [48/100], Loss: 0.5866\n",
      "Validation Loss: 0.6845\n",
      "Epoch [49/100], Loss: 0.5851\n",
      "Validation Loss: 0.6793\n",
      "Epoch [50/100], Loss: 0.5845\n",
      "Validation Loss: 0.6729\n",
      "Saved the best model with validation loss: 0.6729\n",
      "Epoch [51/100], Loss: 0.5842\n",
      "Validation Loss: 0.6723\n",
      "Saved the best model with validation loss: 0.6723\n",
      "Epoch [52/100], Loss: 0.5844\n",
      "Validation Loss: 0.6774\n",
      "Epoch [53/100], Loss: 0.5837\n",
      "Validation Loss: 0.6758\n",
      "Epoch [54/100], Loss: 0.5839\n",
      "Validation Loss: 0.6812\n",
      "Epoch [55/100], Loss: 0.5844\n",
      "Validation Loss: 0.6809\n",
      "Epoch [56/100], Loss: 0.5816\n",
      "Validation Loss: 0.6743\n",
      "Epoch [57/100], Loss: 0.5828\n",
      "Validation Loss: 0.6746\n",
      "Epoch [58/100], Loss: 0.5835\n",
      "Validation Loss: 0.6812\n",
      "Epoch [59/100], Loss: 0.5809\n",
      "Validation Loss: 0.6851\n",
      "Epoch [60/100], Loss: 0.5818\n",
      "Validation Loss: 0.6879\n",
      "Epoch [61/100], Loss: 0.5821\n",
      "Validation Loss: 0.6767\n",
      "Epoch [62/100], Loss: 0.5805\n",
      "Validation Loss: 0.6768\n",
      "Epoch [63/100], Loss: 0.5796\n",
      "Validation Loss: 0.6848\n",
      "Epoch [64/100], Loss: 0.5801\n",
      "Validation Loss: 0.6776\n",
      "Epoch [65/100], Loss: 0.5796\n",
      "Validation Loss: 0.6805\n",
      "Epoch [66/100], Loss: 0.5792\n",
      "Validation Loss: 0.6804\n",
      "Epoch [67/100], Loss: 0.5794\n",
      "Validation Loss: 0.6799\n",
      "Epoch [68/100], Loss: 0.5779\n",
      "Validation Loss: 0.6772\n",
      "Epoch [69/100], Loss: 0.5792\n",
      "Validation Loss: 0.6772\n",
      "Epoch [70/100], Loss: 0.5776\n",
      "Validation Loss: 0.6779\n",
      "Epoch [71/100], Loss: 0.5788\n",
      "Validation Loss: 0.6782\n",
      "Epoch [72/100], Loss: 0.5806\n",
      "Validation Loss: 0.6795\n",
      "Epoch [73/100], Loss: 0.5770\n",
      "Validation Loss: 0.6770\n",
      "Epoch [74/100], Loss: 0.5766\n",
      "Validation Loss: 0.6765\n",
      "Epoch [75/100], Loss: 0.5750\n",
      "Validation Loss: 0.6765\n",
      "Epoch [76/100], Loss: 0.5756\n",
      "Validation Loss: 0.6776\n",
      "Epoch [77/100], Loss: 0.5755\n",
      "Validation Loss: 0.6769\n",
      "Epoch [78/100], Loss: 0.5748\n",
      "Validation Loss: 0.6744\n",
      "Epoch [79/100], Loss: 0.5783\n",
      "Validation Loss: 0.6820\n",
      "Epoch [80/100], Loss: 0.5767\n",
      "Validation Loss: 0.6795\n",
      "Epoch [81/100], Loss: 0.5744\n",
      "Validation Loss: 0.6796\n",
      "Epoch [82/100], Loss: 0.5740\n",
      "Validation Loss: 0.6718\n",
      "Saved the best model with validation loss: 0.6718\n",
      "Epoch [83/100], Loss: 0.5753\n",
      "Validation Loss: 0.6756\n",
      "Epoch [84/100], Loss: 0.5743\n",
      "Validation Loss: 0.6778\n",
      "Epoch [85/100], Loss: 0.5750\n",
      "Validation Loss: 0.6801\n",
      "Epoch [86/100], Loss: 0.5752\n",
      "Validation Loss: 0.6744\n",
      "Epoch [87/100], Loss: 0.5745\n",
      "Validation Loss: 0.6817\n",
      "Epoch [88/100], Loss: 0.5726\n",
      "Validation Loss: 0.6798\n",
      "Epoch [89/100], Loss: 0.5727\n",
      "Validation Loss: 0.6732\n",
      "Epoch [90/100], Loss: 0.5717\n",
      "Validation Loss: 0.6810\n",
      "Epoch [91/100], Loss: 0.5739\n",
      "Validation Loss: 0.6754\n",
      "Epoch [92/100], Loss: 0.5732\n",
      "Validation Loss: 0.6745\n",
      "Epoch [93/100], Loss: 0.5721\n",
      "Validation Loss: 0.6741\n",
      "Epoch [94/100], Loss: 0.5718\n",
      "Validation Loss: 0.6737\n",
      "Epoch [95/100], Loss: 0.5734\n",
      "Validation Loss: 0.6738\n",
      "Epoch [96/100], Loss: 0.5725\n",
      "Validation Loss: 0.6746\n",
      "Epoch [97/100], Loss: 0.5711\n",
      "Validation Loss: 0.6723\n",
      "Epoch [98/100], Loss: 0.5711\n",
      "Validation Loss: 0.6714\n",
      "Saved the best model with validation loss: 0.6714\n",
      "Epoch [99/100], Loss: 0.5707\n",
      "Validation Loss: 0.6745\n",
      "Epoch [100/100], Loss: 0.5708\n",
      "Validation Loss: 0.6719\n"
     ]
    }
   ],
   "source": [
    "HGNN_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"HGNN: 1-16-32-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5649f583",
   "metadata": {},
   "source": [
    "##### HGNN: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 16 - 1, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "c73bc508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "15bc52f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.8351\n",
      "Validation Loss: 1.4084\n",
      "Saved the best model with validation loss: 1.4084\n",
      "Epoch [2/100], Loss: 1.1730\n",
      "Validation Loss: 1.2647\n",
      "Saved the best model with validation loss: 1.2647\n",
      "Epoch [3/100], Loss: 1.0139\n",
      "Validation Loss: 1.1749\n",
      "Saved the best model with validation loss: 1.1749\n",
      "Epoch [4/100], Loss: 0.9423\n",
      "Validation Loss: 1.1172\n",
      "Saved the best model with validation loss: 1.1172\n",
      "Epoch [5/100], Loss: 0.8999\n",
      "Validation Loss: 1.0853\n",
      "Saved the best model with validation loss: 1.0853\n",
      "Epoch [6/100], Loss: 0.8730\n",
      "Validation Loss: 1.0425\n",
      "Saved the best model with validation loss: 1.0425\n",
      "Epoch [7/100], Loss: 0.8488\n",
      "Validation Loss: 1.0059\n",
      "Saved the best model with validation loss: 1.0059\n",
      "Epoch [8/100], Loss: 0.8289\n",
      "Validation Loss: 0.9830\n",
      "Saved the best model with validation loss: 0.9830\n",
      "Epoch [9/100], Loss: 0.8149\n",
      "Validation Loss: 0.9646\n",
      "Saved the best model with validation loss: 0.9646\n",
      "Epoch [10/100], Loss: 0.8032\n",
      "Validation Loss: 0.9435\n",
      "Saved the best model with validation loss: 0.9435\n",
      "Epoch [11/100], Loss: 0.7902\n",
      "Validation Loss: 0.9343\n",
      "Saved the best model with validation loss: 0.9343\n",
      "Epoch [12/100], Loss: 0.7819\n",
      "Validation Loss: 0.9283\n",
      "Saved the best model with validation loss: 0.9283\n",
      "Epoch [13/100], Loss: 0.7757\n",
      "Validation Loss: 0.9300\n",
      "Epoch [14/100], Loss: 0.7700\n",
      "Validation Loss: 0.9269\n",
      "Saved the best model with validation loss: 0.9269\n",
      "Epoch [15/100], Loss: 0.7651\n",
      "Validation Loss: 0.9135\n",
      "Saved the best model with validation loss: 0.9135\n",
      "Epoch [16/100], Loss: 0.7594\n",
      "Validation Loss: 0.9106\n",
      "Saved the best model with validation loss: 0.9106\n",
      "Epoch [17/100], Loss: 0.7562\n",
      "Validation Loss: 0.9095\n",
      "Saved the best model with validation loss: 0.9095\n",
      "Epoch [18/100], Loss: 0.7537\n",
      "Validation Loss: 0.9085\n",
      "Saved the best model with validation loss: 0.9085\n",
      "Epoch [19/100], Loss: 0.7536\n",
      "Validation Loss: 0.9051\n",
      "Saved the best model with validation loss: 0.9051\n",
      "Epoch [20/100], Loss: 0.7481\n",
      "Validation Loss: 0.9196\n",
      "Epoch [21/100], Loss: 0.7464\n",
      "Validation Loss: 0.9107\n",
      "Epoch [22/100], Loss: 0.7429\n",
      "Validation Loss: 0.9249\n",
      "Epoch [23/100], Loss: 0.7417\n",
      "Validation Loss: 0.9023\n",
      "Saved the best model with validation loss: 0.9023\n",
      "Epoch [24/100], Loss: 0.7360\n",
      "Validation Loss: 0.9056\n",
      "Epoch [25/100], Loss: 0.7381\n",
      "Validation Loss: 0.9058\n",
      "Epoch [26/100], Loss: 0.7354\n",
      "Validation Loss: 0.9097\n",
      "Epoch [27/100], Loss: 0.7340\n",
      "Validation Loss: 0.9055\n",
      "Epoch [28/100], Loss: 0.7311\n",
      "Validation Loss: 0.9004\n",
      "Saved the best model with validation loss: 0.9004\n",
      "Epoch [29/100], Loss: 0.7314\n",
      "Validation Loss: 0.9070\n",
      "Epoch [30/100], Loss: 0.7298\n",
      "Validation Loss: 0.9110\n",
      "Epoch [31/100], Loss: 0.7278\n",
      "Validation Loss: 0.8987\n",
      "Saved the best model with validation loss: 0.8987\n",
      "Epoch [32/100], Loss: 0.7290\n",
      "Validation Loss: 0.9063\n",
      "Epoch [33/100], Loss: 0.7253\n",
      "Validation Loss: 0.9088\n",
      "Epoch [34/100], Loss: 0.7277\n",
      "Validation Loss: 0.8944\n",
      "Saved the best model with validation loss: 0.8944\n",
      "Epoch [35/100], Loss: 0.7230\n",
      "Validation Loss: 0.8939\n",
      "Saved the best model with validation loss: 0.8939\n",
      "Epoch [36/100], Loss: 0.7227\n",
      "Validation Loss: 0.8952\n",
      "Epoch [37/100], Loss: 0.7228\n",
      "Validation Loss: 0.8952\n",
      "Epoch [38/100], Loss: 0.7230\n",
      "Validation Loss: 0.8968\n",
      "Epoch [39/100], Loss: 0.7212\n",
      "Validation Loss: 0.8941\n",
      "Epoch [40/100], Loss: 0.7130\n",
      "Validation Loss: 0.8638\n",
      "Saved the best model with validation loss: 0.8638\n",
      "Epoch [41/100], Loss: 0.7007\n",
      "Validation Loss: 0.8423\n",
      "Saved the best model with validation loss: 0.8423\n",
      "Epoch [42/100], Loss: 0.6870\n",
      "Validation Loss: 0.8260\n",
      "Saved the best model with validation loss: 0.8260\n",
      "Epoch [43/100], Loss: 0.6789\n",
      "Validation Loss: 0.8158\n",
      "Saved the best model with validation loss: 0.8158\n",
      "Epoch [44/100], Loss: 0.6738\n",
      "Validation Loss: 0.8077\n",
      "Saved the best model with validation loss: 0.8077\n",
      "Epoch [45/100], Loss: 0.6695\n",
      "Validation Loss: 0.7958\n",
      "Saved the best model with validation loss: 0.7958\n",
      "Epoch [46/100], Loss: 0.6655\n",
      "Validation Loss: 0.7856\n",
      "Saved the best model with validation loss: 0.7856\n",
      "Epoch [47/100], Loss: 0.6633\n",
      "Validation Loss: 0.7836\n",
      "Saved the best model with validation loss: 0.7836\n",
      "Epoch [48/100], Loss: 0.6585\n",
      "Validation Loss: 0.7820\n",
      "Saved the best model with validation loss: 0.7820\n",
      "Epoch [49/100], Loss: 0.6574\n",
      "Validation Loss: 0.7733\n",
      "Saved the best model with validation loss: 0.7733\n",
      "Epoch [50/100], Loss: 0.6545\n",
      "Validation Loss: 0.7706\n",
      "Saved the best model with validation loss: 0.7706\n",
      "Epoch [51/100], Loss: 0.6542\n",
      "Validation Loss: 0.7680\n",
      "Saved the best model with validation loss: 0.7680\n",
      "Epoch [52/100], Loss: 0.6545\n",
      "Validation Loss: 0.7659\n",
      "Saved the best model with validation loss: 0.7659\n",
      "Epoch [53/100], Loss: 0.6521\n",
      "Validation Loss: 0.7547\n",
      "Saved the best model with validation loss: 0.7547\n",
      "Epoch [54/100], Loss: 0.6506\n",
      "Validation Loss: 0.7548\n",
      "Epoch [55/100], Loss: 0.6517\n",
      "Validation Loss: 0.7587\n",
      "Epoch [56/100], Loss: 0.6509\n",
      "Validation Loss: 0.7739\n",
      "Epoch [57/100], Loss: 0.6501\n",
      "Validation Loss: 0.7553\n",
      "Epoch [58/100], Loss: 0.6455\n",
      "Validation Loss: 0.7500\n",
      "Saved the best model with validation loss: 0.7500\n",
      "Epoch [59/100], Loss: 0.6474\n",
      "Validation Loss: 0.7479\n",
      "Saved the best model with validation loss: 0.7479\n",
      "Epoch [60/100], Loss: 0.6456\n",
      "Validation Loss: 0.7466\n",
      "Saved the best model with validation loss: 0.7466\n",
      "Epoch [61/100], Loss: 0.6439\n",
      "Validation Loss: 0.7475\n",
      "Epoch [62/100], Loss: 0.6435\n",
      "Validation Loss: 0.7418\n",
      "Saved the best model with validation loss: 0.7418\n",
      "Epoch [63/100], Loss: 0.6422\n",
      "Validation Loss: 0.7383\n",
      "Saved the best model with validation loss: 0.7383\n",
      "Epoch [64/100], Loss: 0.6409\n",
      "Validation Loss: 0.7403\n",
      "Epoch [65/100], Loss: 0.6408\n",
      "Validation Loss: 0.7394\n",
      "Epoch [66/100], Loss: 0.6404\n",
      "Validation Loss: 0.7379\n",
      "Saved the best model with validation loss: 0.7379\n",
      "Epoch [67/100], Loss: 0.6384\n",
      "Validation Loss: 0.7383\n",
      "Epoch [68/100], Loss: 0.6372\n",
      "Validation Loss: 0.7392\n",
      "Epoch [69/100], Loss: 0.6374\n",
      "Validation Loss: 0.7379\n",
      "Saved the best model with validation loss: 0.7379\n",
      "Epoch [70/100], Loss: 0.6366\n",
      "Validation Loss: 0.7368\n",
      "Saved the best model with validation loss: 0.7368\n",
      "Epoch [71/100], Loss: 0.6361\n",
      "Validation Loss: 0.7312\n",
      "Saved the best model with validation loss: 0.7312\n",
      "Epoch [72/100], Loss: 0.6346\n",
      "Validation Loss: 0.7357\n",
      "Epoch [73/100], Loss: 0.6351\n",
      "Validation Loss: 0.7444\n",
      "Epoch [74/100], Loss: 0.6352\n",
      "Validation Loss: 0.7267\n",
      "Saved the best model with validation loss: 0.7267\n",
      "Epoch [75/100], Loss: 0.6342\n",
      "Validation Loss: 0.7266\n",
      "Saved the best model with validation loss: 0.7266\n",
      "Epoch [76/100], Loss: 0.6317\n",
      "Validation Loss: 0.7283\n",
      "Epoch [77/100], Loss: 0.6317\n",
      "Validation Loss: 0.7245\n",
      "Saved the best model with validation loss: 0.7245\n",
      "Epoch [78/100], Loss: 0.6304\n",
      "Validation Loss: 0.7247\n",
      "Epoch [79/100], Loss: 0.6325\n",
      "Validation Loss: 0.7345\n",
      "Epoch [80/100], Loss: 0.6310\n",
      "Validation Loss: 0.7211\n",
      "Saved the best model with validation loss: 0.7211\n",
      "Epoch [81/100], Loss: 0.6312\n",
      "Validation Loss: 0.7232\n",
      "Epoch [82/100], Loss: 0.6292\n",
      "Validation Loss: 0.7193\n",
      "Saved the best model with validation loss: 0.7193\n",
      "Epoch [83/100], Loss: 0.6299\n",
      "Validation Loss: 0.7167\n",
      "Saved the best model with validation loss: 0.7167\n",
      "Epoch [84/100], Loss: 0.6284\n",
      "Validation Loss: 0.7191\n",
      "Epoch [85/100], Loss: 0.6273\n",
      "Validation Loss: 0.7181\n",
      "Epoch [86/100], Loss: 0.6281\n",
      "Validation Loss: 0.7195\n",
      "Epoch [87/100], Loss: 0.6276\n",
      "Validation Loss: 0.7347\n",
      "Epoch [88/100], Loss: 0.6268\n",
      "Validation Loss: 0.7346\n",
      "Epoch [89/100], Loss: 0.6283\n",
      "Validation Loss: 0.7138\n",
      "Saved the best model with validation loss: 0.7138\n",
      "Epoch [90/100], Loss: 0.6261\n",
      "Validation Loss: 0.7193\n",
      "Epoch [91/100], Loss: 0.6249\n",
      "Validation Loss: 0.7165\n",
      "Epoch [92/100], Loss: 0.6279\n",
      "Validation Loss: 0.7311\n",
      "Epoch [93/100], Loss: 0.6240\n",
      "Validation Loss: 0.7108\n",
      "Saved the best model with validation loss: 0.7108\n",
      "Epoch [94/100], Loss: 0.6265\n",
      "Validation Loss: 0.7183\n",
      "Epoch [95/100], Loss: 0.6253\n",
      "Validation Loss: 0.7145\n",
      "Epoch [96/100], Loss: 0.6250\n",
      "Validation Loss: 0.7176\n",
      "Epoch [97/100], Loss: 0.6232\n",
      "Validation Loss: 0.7095\n",
      "Saved the best model with validation loss: 0.7095\n",
      "Epoch [98/100], Loss: 0.6251\n",
      "Validation Loss: 0.7054\n",
      "Saved the best model with validation loss: 0.7054\n",
      "Epoch [99/100], Loss: 0.6229\n",
      "Validation Loss: 0.7118\n",
      "Epoch [100/100], Loss: 0.6226\n",
      "Validation Loss: 0.7122\n"
     ]
    }
   ],
   "source": [
    "HGNN_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"HGNN: 1-32-16-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703583a",
   "metadata": {},
   "source": [
    "##### HGNN: Version 3\n",
    "*  Layers: 5 (including input and output layer), sizes: 1 - 16 - 32 - 16 - 1, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "4508ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "ec1bd6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7468\n",
      "Validation Loss: 1.3707\n",
      "Saved the best model with validation loss: 1.3707\n",
      "Epoch [2/100], Loss: 1.0574\n",
      "Validation Loss: 1.0733\n",
      "Saved the best model with validation loss: 1.0733\n",
      "Epoch [3/100], Loss: 0.8867\n",
      "Validation Loss: 0.9331\n",
      "Saved the best model with validation loss: 0.9331\n",
      "Epoch [4/100], Loss: 0.8189\n",
      "Validation Loss: 0.8784\n",
      "Saved the best model with validation loss: 0.8784\n",
      "Epoch [5/100], Loss: 0.7816\n",
      "Validation Loss: 0.8308\n",
      "Saved the best model with validation loss: 0.8308\n",
      "Epoch [6/100], Loss: 0.7576\n",
      "Validation Loss: 0.8055\n",
      "Saved the best model with validation loss: 0.8055\n",
      "Epoch [7/100], Loss: 0.7398\n",
      "Validation Loss: 0.7802\n",
      "Saved the best model with validation loss: 0.7802\n",
      "Epoch [8/100], Loss: 0.7206\n",
      "Validation Loss: 0.7837\n",
      "Epoch [9/100], Loss: 0.7109\n",
      "Validation Loss: 0.7452\n",
      "Saved the best model with validation loss: 0.7452\n",
      "Epoch [10/100], Loss: 0.6952\n",
      "Validation Loss: 0.7498\n",
      "Epoch [11/100], Loss: 0.6889\n",
      "Validation Loss: 0.7297\n",
      "Saved the best model with validation loss: 0.7297\n",
      "Epoch [12/100], Loss: 0.6854\n",
      "Validation Loss: 0.7329\n",
      "Epoch [13/100], Loss: 0.6790\n",
      "Validation Loss: 0.7192\n",
      "Saved the best model with validation loss: 0.7192\n",
      "Epoch [14/100], Loss: 0.6704\n",
      "Validation Loss: 0.7303\n",
      "Epoch [15/100], Loss: 0.6655\n",
      "Validation Loss: 0.7139\n",
      "Saved the best model with validation loss: 0.7139\n",
      "Epoch [16/100], Loss: 0.6626\n",
      "Validation Loss: 0.7177\n",
      "Epoch [17/100], Loss: 0.6579\n",
      "Validation Loss: 0.7127\n",
      "Saved the best model with validation loss: 0.7127\n",
      "Epoch [18/100], Loss: 0.6544\n",
      "Validation Loss: 0.7192\n",
      "Epoch [19/100], Loss: 0.6499\n",
      "Validation Loss: 0.7140\n",
      "Epoch [20/100], Loss: 0.6461\n",
      "Validation Loss: 0.7095\n",
      "Saved the best model with validation loss: 0.7095\n",
      "Epoch [21/100], Loss: 0.6461\n",
      "Validation Loss: 0.6956\n",
      "Saved the best model with validation loss: 0.6956\n",
      "Epoch [22/100], Loss: 0.6403\n",
      "Validation Loss: 0.7015\n",
      "Epoch [23/100], Loss: 0.6386\n",
      "Validation Loss: 0.7037\n",
      "Epoch [24/100], Loss: 0.6351\n",
      "Validation Loss: 0.6967\n",
      "Epoch [25/100], Loss: 0.6340\n",
      "Validation Loss: 0.6971\n",
      "Epoch [26/100], Loss: 0.6321\n",
      "Validation Loss: 0.6990\n",
      "Epoch [27/100], Loss: 0.6299\n",
      "Validation Loss: 0.6950\n",
      "Saved the best model with validation loss: 0.6950\n",
      "Epoch [28/100], Loss: 0.6287\n",
      "Validation Loss: 0.6874\n",
      "Saved the best model with validation loss: 0.6874\n",
      "Epoch [29/100], Loss: 0.6272\n",
      "Validation Loss: 0.6885\n",
      "Epoch [30/100], Loss: 0.6263\n",
      "Validation Loss: 0.6978\n",
      "Epoch [31/100], Loss: 0.6242\n",
      "Validation Loss: 0.6828\n",
      "Saved the best model with validation loss: 0.6828\n",
      "Epoch [32/100], Loss: 0.6220\n",
      "Validation Loss: 0.6978\n",
      "Epoch [33/100], Loss: 0.6232\n",
      "Validation Loss: 0.6865\n",
      "Epoch [34/100], Loss: 0.6211\n",
      "Validation Loss: 0.7014\n",
      "Epoch [35/100], Loss: 0.6204\n",
      "Validation Loss: 0.6922\n",
      "Epoch [36/100], Loss: 0.6188\n",
      "Validation Loss: 0.6881\n",
      "Epoch [37/100], Loss: 0.6176\n",
      "Validation Loss: 0.6852\n",
      "Epoch [38/100], Loss: 0.6189\n",
      "Validation Loss: 0.6806\n",
      "Saved the best model with validation loss: 0.6806\n",
      "Epoch [39/100], Loss: 0.6156\n",
      "Validation Loss: 0.6866\n",
      "Epoch [40/100], Loss: 0.6187\n",
      "Validation Loss: 0.6733\n",
      "Saved the best model with validation loss: 0.6733\n",
      "Epoch [41/100], Loss: 0.6137\n",
      "Validation Loss: 0.6828\n",
      "Epoch [42/100], Loss: 0.6124\n",
      "Validation Loss: 0.6822\n",
      "Epoch [43/100], Loss: 0.6119\n",
      "Validation Loss: 0.6759\n",
      "Epoch [44/100], Loss: 0.6083\n",
      "Validation Loss: 0.6788\n",
      "Epoch [45/100], Loss: 0.6114\n",
      "Validation Loss: 0.6888\n",
      "Epoch [46/100], Loss: 0.6103\n",
      "Validation Loss: 0.6785\n",
      "Epoch [47/100], Loss: 0.6081\n",
      "Validation Loss: 0.6784\n",
      "Epoch [48/100], Loss: 0.6069\n",
      "Validation Loss: 0.6757\n",
      "Epoch [49/100], Loss: 0.6068\n",
      "Validation Loss: 0.6679\n",
      "Saved the best model with validation loss: 0.6679\n",
      "Epoch [50/100], Loss: 0.6051\n",
      "Validation Loss: 0.6813\n",
      "Epoch [51/100], Loss: 0.6045\n",
      "Validation Loss: 0.6792\n",
      "Epoch [52/100], Loss: 0.6070\n",
      "Validation Loss: 0.6810\n",
      "Epoch [53/100], Loss: 0.6068\n",
      "Validation Loss: 0.6779\n",
      "Epoch [54/100], Loss: 0.6102\n",
      "Validation Loss: 0.6733\n",
      "Epoch [55/100], Loss: 0.6073\n",
      "Validation Loss: 0.6802\n",
      "Epoch [56/100], Loss: 0.6021\n",
      "Validation Loss: 0.6702\n",
      "Epoch [57/100], Loss: 0.6023\n",
      "Validation Loss: 0.6734\n",
      "Epoch [58/100], Loss: 0.6029\n",
      "Validation Loss: 0.6752\n",
      "Epoch [59/100], Loss: 0.6030\n",
      "Validation Loss: 0.6782\n",
      "Epoch [60/100], Loss: 0.6064\n",
      "Validation Loss: 0.6773\n",
      "Epoch [61/100], Loss: 0.6018\n",
      "Validation Loss: 0.6669\n",
      "Saved the best model with validation loss: 0.6669\n",
      "Epoch [62/100], Loss: 0.6027\n",
      "Validation Loss: 0.6701\n",
      "Epoch [63/100], Loss: 0.5981\n",
      "Validation Loss: 0.6620\n",
      "Saved the best model with validation loss: 0.6620\n",
      "Epoch [64/100], Loss: 0.5989\n",
      "Validation Loss: 0.6712\n",
      "Epoch [65/100], Loss: 0.6030\n",
      "Validation Loss: 0.6629\n",
      "Epoch [66/100], Loss: 0.5980\n",
      "Validation Loss: 0.6720\n",
      "Epoch [67/100], Loss: 0.5988\n",
      "Validation Loss: 0.6703\n",
      "Epoch [68/100], Loss: 0.5959\n",
      "Validation Loss: 0.6632\n",
      "Epoch [69/100], Loss: 0.5992\n",
      "Validation Loss: 0.6779\n",
      "Epoch [70/100], Loss: 0.5960\n",
      "Validation Loss: 0.6683\n",
      "Epoch [71/100], Loss: 0.5960\n",
      "Validation Loss: 0.6687\n",
      "Epoch [72/100], Loss: 0.5955\n",
      "Validation Loss: 0.6878\n",
      "Epoch [73/100], Loss: 0.5974\n",
      "Validation Loss: 0.6636\n",
      "Epoch [74/100], Loss: 0.5950\n",
      "Validation Loss: 0.6740\n",
      "Epoch [75/100], Loss: 0.5941\n",
      "Validation Loss: 0.6689\n",
      "Epoch [76/100], Loss: 0.5935\n",
      "Validation Loss: 0.6692\n",
      "Epoch [77/100], Loss: 0.5932\n",
      "Validation Loss: 0.6639\n",
      "Epoch [78/100], Loss: 0.5918\n",
      "Validation Loss: 0.6656\n",
      "Epoch [79/100], Loss: 0.5917\n",
      "Validation Loss: 0.6637\n",
      "Epoch [80/100], Loss: 0.5915\n",
      "Validation Loss: 0.6674\n",
      "Epoch [81/100], Loss: 0.5910\n",
      "Validation Loss: 0.6650\n",
      "Epoch [82/100], Loss: 0.5912\n",
      "Validation Loss: 0.6754\n",
      "Epoch [83/100], Loss: 0.5925\n",
      "Validation Loss: 0.6678\n",
      "Epoch [84/100], Loss: 0.5909\n",
      "Validation Loss: 0.6703\n",
      "Epoch [85/100], Loss: 0.5901\n",
      "Validation Loss: 0.6674\n",
      "Epoch [86/100], Loss: 0.5902\n",
      "Validation Loss: 0.6737\n",
      "Epoch [87/100], Loss: 0.5880\n",
      "Validation Loss: 0.6785\n",
      "Epoch [88/100], Loss: 0.5887\n",
      "Validation Loss: 0.6642\n",
      "Epoch [89/100], Loss: 0.5906\n",
      "Validation Loss: 0.6625\n",
      "Epoch [90/100], Loss: 0.5888\n",
      "Validation Loss: 0.6719\n",
      "Epoch [91/100], Loss: 0.5905\n",
      "Validation Loss: 0.6673\n",
      "Epoch [92/100], Loss: 0.5877\n",
      "Validation Loss: 0.6708\n",
      "Epoch [93/100], Loss: 0.5857\n",
      "Validation Loss: 0.6713\n",
      "Epoch [94/100], Loss: 0.5895\n",
      "Validation Loss: 0.6629\n",
      "Epoch [95/100], Loss: 0.5862\n",
      "Validation Loss: 0.6776\n",
      "Epoch [96/100], Loss: 0.5859\n",
      "Validation Loss: 0.6747\n",
      "Epoch [97/100], Loss: 0.5885\n",
      "Validation Loss: 0.6686\n",
      "Epoch [98/100], Loss: 0.5842\n",
      "Validation Loss: 0.6680\n",
      "Epoch [99/100], Loss: 0.5909\n",
      "Validation Loss: 0.6685\n",
      "Epoch [100/100], Loss: 0.5881\n",
      "Validation Loss: 0.6653\n"
     ]
    }
   ],
   "source": [
    "HGNN_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val,  \"HGNN: 1-16-32-16-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041627fc",
   "metadata": {},
   "source": [
    "##### HGNN: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 64 - 1, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "1ade520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "c7561e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.5574\n",
      "Validation Loss: 1.1889\n",
      "Saved the best model with validation loss: 1.1889\n",
      "Epoch [2/100], Loss: 0.9825\n",
      "Validation Loss: 1.0024\n",
      "Saved the best model with validation loss: 1.0024\n",
      "Epoch [3/100], Loss: 0.8530\n",
      "Validation Loss: 0.9081\n",
      "Saved the best model with validation loss: 0.9081\n",
      "Epoch [4/100], Loss: 0.7894\n",
      "Validation Loss: 0.8464\n",
      "Saved the best model with validation loss: 0.8464\n",
      "Epoch [5/100], Loss: 0.7464\n",
      "Validation Loss: 0.8203\n",
      "Saved the best model with validation loss: 0.8203\n",
      "Epoch [6/100], Loss: 0.7193\n",
      "Validation Loss: 0.7902\n",
      "Saved the best model with validation loss: 0.7902\n",
      "Epoch [7/100], Loss: 0.6970\n",
      "Validation Loss: 0.7755\n",
      "Saved the best model with validation loss: 0.7755\n",
      "Epoch [8/100], Loss: 0.6862\n",
      "Validation Loss: 0.7634\n",
      "Saved the best model with validation loss: 0.7634\n",
      "Epoch [9/100], Loss: 0.6715\n",
      "Validation Loss: 0.7463\n",
      "Saved the best model with validation loss: 0.7463\n",
      "Epoch [10/100], Loss: 0.6655\n",
      "Validation Loss: 0.7320\n",
      "Saved the best model with validation loss: 0.7320\n",
      "Epoch [11/100], Loss: 0.6561\n",
      "Validation Loss: 0.7189\n",
      "Saved the best model with validation loss: 0.7189\n",
      "Epoch [12/100], Loss: 0.6521\n",
      "Validation Loss: 0.7274\n",
      "Epoch [13/100], Loss: 0.6455\n",
      "Validation Loss: 0.7142\n",
      "Saved the best model with validation loss: 0.7142\n",
      "Epoch [14/100], Loss: 0.6391\n",
      "Validation Loss: 0.7141\n",
      "Saved the best model with validation loss: 0.7141\n",
      "Epoch [15/100], Loss: 0.6353\n",
      "Validation Loss: 0.7049\n",
      "Saved the best model with validation loss: 0.7049\n",
      "Epoch [16/100], Loss: 0.6300\n",
      "Validation Loss: 0.7129\n",
      "Epoch [17/100], Loss: 0.6272\n",
      "Validation Loss: 0.7092\n",
      "Epoch [18/100], Loss: 0.6271\n",
      "Validation Loss: 0.7013\n",
      "Saved the best model with validation loss: 0.7013\n",
      "Epoch [19/100], Loss: 0.6216\n",
      "Validation Loss: 0.7075\n",
      "Epoch [20/100], Loss: 0.6191\n",
      "Validation Loss: 0.7020\n",
      "Epoch [21/100], Loss: 0.6164\n",
      "Validation Loss: 0.7007\n",
      "Saved the best model with validation loss: 0.7007\n",
      "Epoch [22/100], Loss: 0.6134\n",
      "Validation Loss: 0.6950\n",
      "Saved the best model with validation loss: 0.6950\n",
      "Epoch [23/100], Loss: 0.6128\n",
      "Validation Loss: 0.6889\n",
      "Saved the best model with validation loss: 0.6889\n",
      "Epoch [24/100], Loss: 0.6101\n",
      "Validation Loss: 0.6911\n",
      "Epoch [25/100], Loss: 0.6100\n",
      "Validation Loss: 0.6855\n",
      "Saved the best model with validation loss: 0.6855\n",
      "Epoch [26/100], Loss: 0.6072\n",
      "Validation Loss: 0.6857\n",
      "Epoch [27/100], Loss: 0.6052\n",
      "Validation Loss: 0.6840\n",
      "Saved the best model with validation loss: 0.6840\n",
      "Epoch [28/100], Loss: 0.6062\n",
      "Validation Loss: 0.6868\n",
      "Epoch [29/100], Loss: 0.6039\n",
      "Validation Loss: 0.6950\n",
      "Epoch [30/100], Loss: 0.6035\n",
      "Validation Loss: 0.6872\n",
      "Epoch [31/100], Loss: 0.6052\n",
      "Validation Loss: 0.6923\n",
      "Epoch [32/100], Loss: 0.6005\n",
      "Validation Loss: 0.6832\n",
      "Saved the best model with validation loss: 0.6832\n",
      "Epoch [33/100], Loss: 0.6009\n",
      "Validation Loss: 0.6858\n",
      "Epoch [34/100], Loss: 0.6008\n",
      "Validation Loss: 0.6831\n",
      "Saved the best model with validation loss: 0.6831\n",
      "Epoch [35/100], Loss: 0.5994\n",
      "Validation Loss: 0.6832\n",
      "Epoch [36/100], Loss: 0.5991\n",
      "Validation Loss: 0.6856\n",
      "Epoch [37/100], Loss: 0.5962\n",
      "Validation Loss: 0.6837\n",
      "Epoch [38/100], Loss: 0.5964\n",
      "Validation Loss: 0.6840\n",
      "Epoch [39/100], Loss: 0.5976\n",
      "Validation Loss: 0.6757\n",
      "Saved the best model with validation loss: 0.6757\n",
      "Epoch [40/100], Loss: 0.5945\n",
      "Validation Loss: 0.6790\n",
      "Epoch [41/100], Loss: 0.5945\n",
      "Validation Loss: 0.6704\n",
      "Saved the best model with validation loss: 0.6704\n",
      "Epoch [42/100], Loss: 0.5951\n",
      "Validation Loss: 0.6789\n",
      "Epoch [43/100], Loss: 0.5919\n",
      "Validation Loss: 0.6802\n",
      "Epoch [44/100], Loss: 0.5935\n",
      "Validation Loss: 0.6784\n",
      "Epoch [45/100], Loss: 0.5937\n",
      "Validation Loss: 0.6805\n",
      "Epoch [46/100], Loss: 0.5936\n",
      "Validation Loss: 0.6795\n",
      "Epoch [47/100], Loss: 0.5932\n",
      "Validation Loss: 0.6766\n",
      "Epoch [48/100], Loss: 0.5911\n",
      "Validation Loss: 0.6765\n",
      "Epoch [49/100], Loss: 0.5910\n",
      "Validation Loss: 0.6717\n",
      "Epoch [50/100], Loss: 0.5881\n",
      "Validation Loss: 0.6706\n",
      "Epoch [51/100], Loss: 0.5875\n",
      "Validation Loss: 0.6778\n",
      "Epoch [52/100], Loss: 0.5873\n",
      "Validation Loss: 0.6784\n",
      "Epoch [53/100], Loss: 0.5885\n",
      "Validation Loss: 0.6806\n",
      "Epoch [54/100], Loss: 0.5863\n",
      "Validation Loss: 0.6710\n",
      "Epoch [55/100], Loss: 0.5862\n",
      "Validation Loss: 0.6641\n",
      "Saved the best model with validation loss: 0.6641\n",
      "Epoch [56/100], Loss: 0.5874\n",
      "Validation Loss: 0.6770\n",
      "Epoch [57/100], Loss: 0.5843\n",
      "Validation Loss: 0.6736\n",
      "Epoch [58/100], Loss: 0.5846\n",
      "Validation Loss: 0.6755\n",
      "Epoch [59/100], Loss: 0.5833\n",
      "Validation Loss: 0.6693\n",
      "Epoch [60/100], Loss: 0.5853\n",
      "Validation Loss: 0.6692\n",
      "Epoch [61/100], Loss: 0.5822\n",
      "Validation Loss: 0.6646\n",
      "Epoch [62/100], Loss: 0.5831\n",
      "Validation Loss: 0.6704\n",
      "Epoch [63/100], Loss: 0.5823\n",
      "Validation Loss: 0.6698\n",
      "Epoch [64/100], Loss: 0.5832\n",
      "Validation Loss: 0.6686\n",
      "Epoch [65/100], Loss: 0.5824\n",
      "Validation Loss: 0.6750\n",
      "Epoch [66/100], Loss: 0.5818\n",
      "Validation Loss: 0.6768\n",
      "Epoch [67/100], Loss: 0.5814\n",
      "Validation Loss: 0.6736\n",
      "Epoch [68/100], Loss: 0.5833\n",
      "Validation Loss: 0.6577\n",
      "Saved the best model with validation loss: 0.6577\n",
      "Epoch [69/100], Loss: 0.5802\n",
      "Validation Loss: 0.6672\n",
      "Epoch [70/100], Loss: 0.5802\n",
      "Validation Loss: 0.6660\n",
      "Epoch [71/100], Loss: 0.5797\n",
      "Validation Loss: 0.6658\n",
      "Epoch [72/100], Loss: 0.5808\n",
      "Validation Loss: 0.6706\n",
      "Epoch [73/100], Loss: 0.5808\n",
      "Validation Loss: 0.6650\n",
      "Epoch [74/100], Loss: 0.5786\n",
      "Validation Loss: 0.6640\n",
      "Epoch [75/100], Loss: 0.5803\n",
      "Validation Loss: 0.6627\n",
      "Epoch [76/100], Loss: 0.5789\n",
      "Validation Loss: 0.6636\n",
      "Epoch [77/100], Loss: 0.5779\n",
      "Validation Loss: 0.6681\n",
      "Epoch [78/100], Loss: 0.5769\n",
      "Validation Loss: 0.6701\n",
      "Epoch [79/100], Loss: 0.5789\n",
      "Validation Loss: 0.6665\n",
      "Epoch [80/100], Loss: 0.5773\n",
      "Validation Loss: 0.6668\n",
      "Epoch [81/100], Loss: 0.5770\n",
      "Validation Loss: 0.6615\n",
      "Epoch [82/100], Loss: 0.5766\n",
      "Validation Loss: 0.6646\n",
      "Epoch [83/100], Loss: 0.5761\n",
      "Validation Loss: 0.6615\n",
      "Epoch [84/100], Loss: 0.5766\n",
      "Validation Loss: 0.6638\n",
      "Epoch [85/100], Loss: 0.5774\n",
      "Validation Loss: 0.6654\n",
      "Epoch [86/100], Loss: 0.5775\n",
      "Validation Loss: 0.6632\n",
      "Epoch [87/100], Loss: 0.5778\n",
      "Validation Loss: 0.6637\n",
      "Epoch [88/100], Loss: 0.5766\n",
      "Validation Loss: 0.6730\n",
      "Epoch [89/100], Loss: 0.5762\n",
      "Validation Loss: 0.6642\n",
      "Epoch [90/100], Loss: 0.5753\n",
      "Validation Loss: 0.6708\n",
      "Epoch [91/100], Loss: 0.5754\n",
      "Validation Loss: 0.6634\n",
      "Epoch [92/100], Loss: 0.5757\n",
      "Validation Loss: 0.6662\n",
      "Epoch [93/100], Loss: 0.5753\n",
      "Validation Loss: 0.6616\n",
      "Epoch [94/100], Loss: 0.5747\n",
      "Validation Loss: 0.6657\n",
      "Epoch [95/100], Loss: 0.5754\n",
      "Validation Loss: 0.6689\n",
      "Epoch [96/100], Loss: 0.5747\n",
      "Validation Loss: 0.6599\n",
      "Epoch [97/100], Loss: 0.5734\n",
      "Validation Loss: 0.6694\n",
      "Epoch [98/100], Loss: 0.5746\n",
      "Validation Loss: 0.6639\n",
      "Epoch [99/100], Loss: 0.5732\n",
      "Validation Loss: 0.6645\n",
      "Epoch [100/100], Loss: 0.5738\n",
      "Validation Loss: 0.6667\n"
     ]
    }
   ],
   "source": [
    "HGNN_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"HGNN: 1-32-64-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c44ed22",
   "metadata": {},
   "source": [
    "##### HGNN: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 4 - 16 - 1, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "870f43ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "28f79560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.3127\n",
      "Validation Loss: 1.7381\n",
      "Saved the best model with validation loss: 1.7381\n",
      "Epoch [2/100], Loss: 1.4562\n",
      "Validation Loss: 1.4711\n",
      "Saved the best model with validation loss: 1.4711\n",
      "Epoch [3/100], Loss: 1.1822\n",
      "Validation Loss: 1.3012\n",
      "Saved the best model with validation loss: 1.3012\n",
      "Epoch [4/100], Loss: 1.0292\n",
      "Validation Loss: 1.2297\n",
      "Saved the best model with validation loss: 1.2297\n",
      "Epoch [5/100], Loss: 0.9565\n",
      "Validation Loss: 1.1857\n",
      "Saved the best model with validation loss: 1.1857\n",
      "Epoch [6/100], Loss: 0.9184\n",
      "Validation Loss: 1.1585\n",
      "Saved the best model with validation loss: 1.1585\n",
      "Epoch [7/100], Loss: 0.8942\n",
      "Validation Loss: 1.1336\n",
      "Saved the best model with validation loss: 1.1336\n",
      "Epoch [8/100], Loss: 0.8758\n",
      "Validation Loss: 1.1070\n",
      "Saved the best model with validation loss: 1.1070\n",
      "Epoch [9/100], Loss: 0.8574\n",
      "Validation Loss: 1.0804\n",
      "Saved the best model with validation loss: 1.0804\n",
      "Epoch [10/100], Loss: 0.8411\n",
      "Validation Loss: 1.0543\n",
      "Saved the best model with validation loss: 1.0543\n",
      "Epoch [11/100], Loss: 0.8255\n",
      "Validation Loss: 1.0356\n",
      "Saved the best model with validation loss: 1.0356\n",
      "Epoch [12/100], Loss: 0.8116\n",
      "Validation Loss: 1.0105\n",
      "Saved the best model with validation loss: 1.0105\n",
      "Epoch [13/100], Loss: 0.7989\n",
      "Validation Loss: 0.9968\n",
      "Saved the best model with validation loss: 0.9968\n",
      "Epoch [14/100], Loss: 0.7897\n",
      "Validation Loss: 0.9861\n",
      "Saved the best model with validation loss: 0.9861\n",
      "Epoch [15/100], Loss: 0.7816\n",
      "Validation Loss: 0.9743\n",
      "Saved the best model with validation loss: 0.9743\n",
      "Epoch [16/100], Loss: 0.7745\n",
      "Validation Loss: 0.9625\n",
      "Saved the best model with validation loss: 0.9625\n",
      "Epoch [17/100], Loss: 0.7671\n",
      "Validation Loss: 0.9469\n",
      "Saved the best model with validation loss: 0.9469\n",
      "Epoch [18/100], Loss: 0.7602\n",
      "Validation Loss: 0.9417\n",
      "Saved the best model with validation loss: 0.9417\n",
      "Epoch [19/100], Loss: 0.7525\n",
      "Validation Loss: 0.9297\n",
      "Saved the best model with validation loss: 0.9297\n",
      "Epoch [20/100], Loss: 0.7465\n",
      "Validation Loss: 0.9189\n",
      "Saved the best model with validation loss: 0.9189\n",
      "Epoch [21/100], Loss: 0.7402\n",
      "Validation Loss: 0.9089\n",
      "Saved the best model with validation loss: 0.9089\n",
      "Epoch [22/100], Loss: 0.7338\n",
      "Validation Loss: 0.8970\n",
      "Saved the best model with validation loss: 0.8970\n",
      "Epoch [23/100], Loss: 0.7297\n",
      "Validation Loss: 0.8948\n",
      "Saved the best model with validation loss: 0.8948\n",
      "Epoch [24/100], Loss: 0.7227\n",
      "Validation Loss: 0.8855\n",
      "Saved the best model with validation loss: 0.8855\n",
      "Epoch [25/100], Loss: 0.7184\n",
      "Validation Loss: 0.8748\n",
      "Saved the best model with validation loss: 0.8748\n",
      "Epoch [26/100], Loss: 0.7126\n",
      "Validation Loss: 0.8730\n",
      "Saved the best model with validation loss: 0.8730\n",
      "Epoch [27/100], Loss: 0.7078\n",
      "Validation Loss: 0.8644\n",
      "Saved the best model with validation loss: 0.8644\n",
      "Epoch [28/100], Loss: 0.7020\n",
      "Validation Loss: 0.8593\n",
      "Saved the best model with validation loss: 0.8593\n",
      "Epoch [29/100], Loss: 0.6982\n",
      "Validation Loss: 0.8505\n",
      "Saved the best model with validation loss: 0.8505\n",
      "Epoch [30/100], Loss: 0.6943\n",
      "Validation Loss: 0.8506\n",
      "Epoch [31/100], Loss: 0.6887\n",
      "Validation Loss: 0.8383\n",
      "Saved the best model with validation loss: 0.8383\n",
      "Epoch [32/100], Loss: 0.6849\n",
      "Validation Loss: 0.8327\n",
      "Saved the best model with validation loss: 0.8327\n",
      "Epoch [33/100], Loss: 0.6803\n",
      "Validation Loss: 0.8318\n",
      "Saved the best model with validation loss: 0.8318\n",
      "Epoch [34/100], Loss: 0.6761\n",
      "Validation Loss: 0.8320\n",
      "Epoch [35/100], Loss: 0.6745\n",
      "Validation Loss: 0.8239\n",
      "Saved the best model with validation loss: 0.8239\n",
      "Epoch [36/100], Loss: 0.6718\n",
      "Validation Loss: 0.8061\n",
      "Saved the best model with validation loss: 0.8061\n",
      "Epoch [37/100], Loss: 0.6692\n",
      "Validation Loss: 0.8105\n",
      "Epoch [38/100], Loss: 0.6661\n",
      "Validation Loss: 0.8087\n",
      "Epoch [39/100], Loss: 0.6632\n",
      "Validation Loss: 0.8031\n",
      "Saved the best model with validation loss: 0.8031\n",
      "Epoch [40/100], Loss: 0.6619\n",
      "Validation Loss: 0.7920\n",
      "Saved the best model with validation loss: 0.7920\n",
      "Epoch [41/100], Loss: 0.6582\n",
      "Validation Loss: 0.7873\n",
      "Saved the best model with validation loss: 0.7873\n",
      "Epoch [42/100], Loss: 0.6564\n",
      "Validation Loss: 0.7897\n",
      "Epoch [43/100], Loss: 0.6557\n",
      "Validation Loss: 0.7817\n",
      "Saved the best model with validation loss: 0.7817\n",
      "Epoch [44/100], Loss: 0.6525\n",
      "Validation Loss: 0.7781\n",
      "Saved the best model with validation loss: 0.7781\n",
      "Epoch [45/100], Loss: 0.6496\n",
      "Validation Loss: 0.7813\n",
      "Epoch [46/100], Loss: 0.6488\n",
      "Validation Loss: 0.7791\n",
      "Epoch [47/100], Loss: 0.6472\n",
      "Validation Loss: 0.7721\n",
      "Saved the best model with validation loss: 0.7721\n",
      "Epoch [48/100], Loss: 0.6452\n",
      "Validation Loss: 0.7736\n",
      "Epoch [49/100], Loss: 0.6448\n",
      "Validation Loss: 0.7727\n",
      "Epoch [50/100], Loss: 0.6437\n",
      "Validation Loss: 0.7662\n",
      "Saved the best model with validation loss: 0.7662\n",
      "Epoch [51/100], Loss: 0.6401\n",
      "Validation Loss: 0.7676\n",
      "Epoch [52/100], Loss: 0.6411\n",
      "Validation Loss: 0.7645\n",
      "Saved the best model with validation loss: 0.7645\n",
      "Epoch [53/100], Loss: 0.6401\n",
      "Validation Loss: 0.7632\n",
      "Saved the best model with validation loss: 0.7632\n",
      "Epoch [54/100], Loss: 0.6388\n",
      "Validation Loss: 0.7624\n",
      "Saved the best model with validation loss: 0.7624\n",
      "Epoch [55/100], Loss: 0.6349\n",
      "Validation Loss: 0.7627\n",
      "Epoch [56/100], Loss: 0.6343\n",
      "Validation Loss: 0.7585\n",
      "Saved the best model with validation loss: 0.7585\n",
      "Epoch [57/100], Loss: 0.6325\n",
      "Validation Loss: 0.7553\n",
      "Saved the best model with validation loss: 0.7553\n",
      "Epoch [58/100], Loss: 0.6319\n",
      "Validation Loss: 0.7508\n",
      "Saved the best model with validation loss: 0.7508\n",
      "Epoch [59/100], Loss: 0.6317\n",
      "Validation Loss: 0.7529\n",
      "Epoch [60/100], Loss: 0.6300\n",
      "Validation Loss: 0.7410\n",
      "Saved the best model with validation loss: 0.7410\n",
      "Epoch [61/100], Loss: 0.6287\n",
      "Validation Loss: 0.7447\n",
      "Epoch [62/100], Loss: 0.6278\n",
      "Validation Loss: 0.7309\n",
      "Saved the best model with validation loss: 0.7309\n",
      "Epoch [63/100], Loss: 0.6263\n",
      "Validation Loss: 0.7410\n",
      "Epoch [64/100], Loss: 0.6258\n",
      "Validation Loss: 0.7406\n",
      "Epoch [65/100], Loss: 0.6252\n",
      "Validation Loss: 0.7360\n",
      "Epoch [66/100], Loss: 0.6244\n",
      "Validation Loss: 0.7296\n",
      "Saved the best model with validation loss: 0.7296\n",
      "Epoch [67/100], Loss: 0.6235\n",
      "Validation Loss: 0.7285\n",
      "Saved the best model with validation loss: 0.7285\n",
      "Epoch [68/100], Loss: 0.6231\n",
      "Validation Loss: 0.7294\n",
      "Epoch [69/100], Loss: 0.6226\n",
      "Validation Loss: 0.7328\n",
      "Epoch [70/100], Loss: 0.6218\n",
      "Validation Loss: 0.7272\n",
      "Saved the best model with validation loss: 0.7272\n",
      "Epoch [71/100], Loss: 0.6215\n",
      "Validation Loss: 0.7301\n",
      "Epoch [72/100], Loss: 0.6211\n",
      "Validation Loss: 0.7311\n",
      "Epoch [73/100], Loss: 0.6210\n",
      "Validation Loss: 0.7288\n",
      "Epoch [74/100], Loss: 0.6184\n",
      "Validation Loss: 0.7252\n",
      "Saved the best model with validation loss: 0.7252\n",
      "Epoch [75/100], Loss: 0.6180\n",
      "Validation Loss: 0.7274\n",
      "Epoch [76/100], Loss: 0.6181\n",
      "Validation Loss: 0.7291\n",
      "Epoch [77/100], Loss: 0.6162\n",
      "Validation Loss: 0.7206\n",
      "Saved the best model with validation loss: 0.7206\n",
      "Epoch [78/100], Loss: 0.6146\n",
      "Validation Loss: 0.7208\n",
      "Epoch [79/100], Loss: 0.6152\n",
      "Validation Loss: 0.7214\n",
      "Epoch [80/100], Loss: 0.6144\n",
      "Validation Loss: 0.7230\n",
      "Epoch [81/100], Loss: 0.6146\n",
      "Validation Loss: 0.7234\n",
      "Epoch [82/100], Loss: 0.6134\n",
      "Validation Loss: 0.7244\n",
      "Epoch [83/100], Loss: 0.6131\n",
      "Validation Loss: 0.7256\n",
      "Epoch [84/100], Loss: 0.6125\n",
      "Validation Loss: 0.7267\n",
      "Epoch [85/100], Loss: 0.6123\n",
      "Validation Loss: 0.7229\n",
      "Epoch [86/100], Loss: 0.6119\n",
      "Validation Loss: 0.7224\n",
      "Epoch [87/100], Loss: 0.6103\n",
      "Validation Loss: 0.7253\n",
      "Epoch [88/100], Loss: 0.6104\n",
      "Validation Loss: 0.7282\n",
      "Epoch [89/100], Loss: 0.6118\n",
      "Validation Loss: 0.7213\n",
      "Epoch [90/100], Loss: 0.6105\n",
      "Validation Loss: 0.7230\n",
      "Epoch [91/100], Loss: 0.6092\n",
      "Validation Loss: 0.7221\n",
      "Epoch [92/100], Loss: 0.6132\n",
      "Validation Loss: 0.7205\n",
      "Saved the best model with validation loss: 0.7205\n",
      "Epoch [93/100], Loss: 0.6107\n",
      "Validation Loss: 0.7185\n",
      "Saved the best model with validation loss: 0.7185\n",
      "Epoch [94/100], Loss: 0.6101\n",
      "Validation Loss: 0.7166\n",
      "Saved the best model with validation loss: 0.7166\n",
      "Epoch [95/100], Loss: 0.6101\n",
      "Validation Loss: 0.7182\n",
      "Epoch [96/100], Loss: 0.6114\n",
      "Validation Loss: 0.7182\n",
      "Epoch [97/100], Loss: 0.6084\n",
      "Validation Loss: 0.7182\n",
      "Epoch [98/100], Loss: 0.6089\n",
      "Validation Loss: 0.7210\n",
      "Epoch [99/100], Loss: 0.6085\n",
      "Validation Loss: 0.7257\n",
      "Epoch [100/100], Loss: 0.6087\n",
      "Validation Loss: 0.7163\n",
      "Saved the best model with validation loss: 0.7163\n"
     ]
    }
   ],
   "source": [
    "HGNN_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"HGNN: 1-4-16-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "5b602905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.789418</td>\n",
       "      <td>0.730049</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.579022</td>\n",
       "      <td>0.390659</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>0.612816</td>\n",
       "      <td>0.433778</td>\n",
       "      <td>0.79668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.584555</td>\n",
       "      <td>0.392098</td>\n",
       "      <td>0.817131</td>\n",
       "      <td>0.61371</td>\n",
       "      <td>0.435071</td>\n",
       "      <td>0.796384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>2.323296</td>\n",
       "      <td>0.907326</td>\n",
       "      <td>0.273192</td>\n",
       "      <td>2.371142</td>\n",
       "      <td>0.929039</td>\n",
       "      <td>0.213305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.778288</td>\n",
       "      <td>0.719919</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>1.81521</td>\n",
       "      <td>0.749433</td>\n",
       "      <td>0.397751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.612341</td>\n",
       "      <td>0.692069</td>\n",
       "      <td>0.495604</td>\n",
       "      <td>1.666438</td>\n",
       "      <td>0.727603</td>\n",
       "      <td>0.447111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-1</th>\n",
       "      <td>1.386030</td>\n",
       "      <td>0.840528</td>\n",
       "      <td>0.566402</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-1</th>\n",
       "      <td>1.511389</td>\n",
       "      <td>0.875163</td>\n",
       "      <td>0.527185</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-1</th>\n",
       "      <td>1.442876</td>\n",
       "      <td>0.859189</td>\n",
       "      <td>0.548618</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-1</th>\n",
       "      <td>1.343067</td>\n",
       "      <td>0.821639</td>\n",
       "      <td>0.579842</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-1</th>\n",
       "      <td>1.347905</td>\n",
       "      <td>0.820918</td>\n",
       "      <td>0.578329</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-1</th>\n",
       "      <td>1.388511</td>\n",
       "      <td>0.829501</td>\n",
       "      <td>0.565625</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-1</th>\n",
       "      <td>1.360229</td>\n",
       "      <td>0.822960</td>\n",
       "      <td>0.574473</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-1</th>\n",
       "      <td>1.273426</td>\n",
       "      <td>0.791052</td>\n",
       "      <td>0.601628</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-1</th>\n",
       "      <td>1.285886</td>\n",
       "      <td>0.801589</td>\n",
       "      <td>0.597730</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-1</th>\n",
       "      <td>1.255633</td>\n",
       "      <td>0.796268</td>\n",
       "      <td>0.607194</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-1</th>\n",
       "      <td>1.162645</td>\n",
       "      <td>0.744006</td>\n",
       "      <td>0.636284</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-1</th>\n",
       "      <td>1.183051</td>\n",
       "      <td>0.745964</td>\n",
       "      <td>0.629900</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-1</th>\n",
       "      <td>1.124134</td>\n",
       "      <td>0.712487</td>\n",
       "      <td>0.648332</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-1</th>\n",
       "      <td>1.313112</td>\n",
       "      <td>0.792845</td>\n",
       "      <td>0.589213</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-1</th>\n",
       "      <td>1.274659</td>\n",
       "      <td>0.764669</td>\n",
       "      <td>0.601242</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-1</th>\n",
       "      <td>1.344109</td>\n",
       "      <td>0.802782</td>\n",
       "      <td>0.579516</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-1</th>\n",
       "      <td>1.202730</td>\n",
       "      <td>0.722136</td>\n",
       "      <td>0.623744</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-1</th>\n",
       "      <td>1.339963</td>\n",
       "      <td>0.802546</td>\n",
       "      <td>0.580813</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-1</th>\n",
       "      <td>1.237934</td>\n",
       "      <td>0.760888</td>\n",
       "      <td>0.612731</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-1</th>\n",
       "      <td>1.154383</td>\n",
       "      <td>0.717330</td>\n",
       "      <td>0.638869</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-1</th>\n",
       "      <td>0.671361</td>\n",
       "      <td>0.475938</td>\n",
       "      <td>0.789975</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-1</th>\n",
       "      <td>0.705351</td>\n",
       "      <td>0.506083</td>\n",
       "      <td>0.779342</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-1</th>\n",
       "      <td>0.661967</td>\n",
       "      <td>0.457578</td>\n",
       "      <td>0.792914</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-1</th>\n",
       "      <td>0.657654</td>\n",
       "      <td>0.488402</td>\n",
       "      <td>0.794263</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-1</th>\n",
       "      <td>0.716271</td>\n",
       "      <td>0.523176</td>\n",
       "      <td>0.775925</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   MSE       MAE        R2       MSE  \\\n",
       "5-NN                          0.673141  0.442646  0.789418  0.730049   \n",
       "Decision tree                 0.579022  0.390659  0.818862  0.612816   \n",
       "Random forest                 0.584555  0.392098  0.817131   0.61371   \n",
       "SVM linear                    2.323296  0.907326  0.273192  2.371142   \n",
       "SVM poly                      1.778288  0.719919  0.443690   1.81521   \n",
       "SVM rbf                       1.612341  0.692069  0.495604  1.666438   \n",
       "MLP: 17-5-1                   1.386030  0.840528  0.566402         -   \n",
       "MLP: 17-10-1                  1.511389  0.875163  0.527185         -   \n",
       "MLP: 17-20-1                  1.442876  0.859189  0.548618         -   \n",
       "MLP: 17-25-1                  1.343067  0.821639  0.579842         -   \n",
       "MLP: 17-40-1                  1.347905  0.820918  0.578329         -   \n",
       "MLP: 17-60-1                  1.388511  0.829501  0.565625         -   \n",
       "MLP: 17-10-5-1                1.360229  0.822960  0.574473         -   \n",
       "MLP: 17-20-10-1               1.273426  0.791052  0.601628         -   \n",
       "MLP: 17-40-20-1               1.285886  0.801589  0.597730         -   \n",
       "MLP: 17-40-10-1               1.255633  0.796268  0.607194         -   \n",
       "MLP: 17-60-40-1               1.162645  0.744006  0.636284         -   \n",
       "MLP: 17-60-20-1               1.183051  0.745964  0.629900         -   \n",
       "MLP: 17-80-50-1               1.124134  0.712487  0.648332         -   \n",
       "MLP, small-median: 7-80-50-1  1.313112  0.792845  0.589213         -   \n",
       "MLP, small-mean: 7-80-50-1    1.274659  0.764669  0.601242         -   \n",
       "MLP, small-min: 7-80-50-1     1.344109  0.802782  0.579516         -   \n",
       "MLP, small-max: 7-80-50-1     1.202730  0.722136  0.623744         -   \n",
       "MLP, small-q25: 7-80-50-1     1.339963  0.802546  0.580813         -   \n",
       "MLP, small-q75: 7-80-50-1     1.237934  0.760888  0.612731         -   \n",
       "MLP, custom: 7-80-50-1        1.154383  0.717330  0.638869         -   \n",
       "HGNN: 1-16-32-1               0.671361  0.475938  0.789975         -   \n",
       "HGNN: 1-32-16-1               0.705351  0.506083  0.779342         -   \n",
       "HGNN: 1-16-32-16-1            0.661967  0.457578  0.792914         -   \n",
       "HGNN: 1-32-64-1               0.657654  0.488402  0.794263         -   \n",
       "HGNN: 1-4-16-1                0.716271  0.523176  0.775925         -   \n",
       "\n",
       "                                   MAE        R2  \n",
       "5-NN                          0.478475  0.757785  \n",
       "Decision tree                 0.433778   0.79668  \n",
       "Random forest                 0.435071  0.796384  \n",
       "SVM linear                    0.929039  0.213305  \n",
       "SVM poly                      0.749433  0.397751  \n",
       "SVM rbf                       0.727603  0.447111  \n",
       "MLP: 17-5-1                          -         -  \n",
       "MLP: 17-10-1                         -         -  \n",
       "MLP: 17-20-1                         -         -  \n",
       "MLP: 17-25-1                         -         -  \n",
       "MLP: 17-40-1                         -         -  \n",
       "MLP: 17-60-1                         -         -  \n",
       "MLP: 17-10-5-1                       -         -  \n",
       "MLP: 17-20-10-1                      -         -  \n",
       "MLP: 17-40-20-1                      -         -  \n",
       "MLP: 17-40-10-1                      -         -  \n",
       "MLP: 17-60-40-1                      -         -  \n",
       "MLP: 17-60-20-1                      -         -  \n",
       "MLP: 17-80-50-1                      -         -  \n",
       "MLP, small-median: 7-80-50-1         -         -  \n",
       "MLP, small-mean: 7-80-50-1           -         -  \n",
       "MLP, small-min: 7-80-50-1            -         -  \n",
       "MLP, small-max: 7-80-50-1            -         -  \n",
       "MLP, small-q25: 7-80-50-1            -         -  \n",
       "MLP, small-q75: 7-80-50-1            -         -  \n",
       "MLP, custom: 7-80-50-1               -         -  \n",
       "HGNN: 1-16-32-1                      -         -  \n",
       "HGNN: 1-32-16-1                      -         -  \n",
       "HGNN: 1-16-32-16-1                   -         -  \n",
       "HGNN: 1-32-64-1                      -         -  \n",
       "HGNN: 1-4-16-1                       -         -  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "396f03d4-eba8-49c9-ab57-eb65f427fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2_classes.to_csv('results/table_2_classes_SPA_rounded.csv')\n",
    "#table_3_classes.to_csv('results/table_3_classes_SPA_rounded.csv')\n",
    "table_time_diff.to_csv('results/table_time_diff_SPA_rounded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f2e9a-cee8-4538-b0fc-ddc20a1445c8",
   "metadata": {},
   "source": [
    "### Combined HGNN+MLP with two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24d18a-bd68-4698-9148-95f4d5bab39f",
   "metadata": {},
   "source": [
    "Taking the best MLP and the best HGNN and combining their output with an additional MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "96c82e80-b7d5-4eb9-9178-cfa94dedd41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, label_series, hypergraph_column_name):\n",
    "        # Extract features and convert to tensor\n",
    "        self.X = torch.from_numpy(dataframe.drop(columns=[hypergraph_column_name]).values).float()\n",
    "        \n",
    "        # Extract labels and convert to tensor\n",
    "        self.y = torch.from_numpy(label_series.values).float()\n",
    "        \n",
    "        # Store hypergraph objects\n",
    "        self.hypergraphs = dataframe[hypergraph_column_name].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.X[index],\n",
    "            'label': self.y[index],\n",
    "            'hypergraph': self.hypergraphs[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "da7817ac-52c3-4f3c-a254-1c332f24be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_classification(X_training, y_training, X_validation, y_validation, type, text):\n",
    "    model = CombinedNetwork(random_seed = 20)  \n",
    "\n",
    "    dataset = CustomDataset(X_training, y_training, hypergraph_column_name='hypergraph')\n",
    "    validation = CustomDataset(X_validation, y_validation, hypergraph_column_name='hypergraph')\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for item in dataset:\n",
    "            optimizer.zero_grad()\n",
    "            input_features = item[\"data\"]\n",
    "            input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "            label = item[\"label\"].long()\n",
    "            output = model(input_features, input_hg)\n",
    "            \n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataset):.4f}')\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for item in validation:\n",
    "                input_features = item[\"data\"]\n",
    "                input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "                label = item[\"label\"].long()\n",
    "                output = model(input_features, input_hg)\n",
    "                loss = loss_function(output, label)\n",
    "                val_loss += loss.item()\n",
    "    \n",
    "        val_loss /= len(validation)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "        # Save the model if the validation loss is the best we've seen so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Saved the best model with validation loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for item in validation:\n",
    "            i += 1\n",
    "            output = model(item[\"data\"], item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0))\n",
    "            _, pred = torch.max(output.data, 0)\n",
    "            predicted.append(pred.item())\n",
    "\n",
    "    if type == \"2_class\":\n",
    "        accuracy = accuracy_score(y_validation, predicted)\n",
    "        recall = recall_score(y_validation, predicted)\n",
    "        conf_matrix = confusion_matrix(y_validation, predicted)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_2_classes.loc[text] = [accuracy, recall, \"-\", \"-\"]\n",
    "\n",
    "    if type == \"3_class\":\n",
    "        accuracy = accuracy_score(y_validation, predicted)\n",
    "        recall_micro = recall_score(y_validation, predicted, average='micro')\n",
    "        recall_macro = recall_score(y_validation, predicted, average='macro')\n",
    "        conf_matrix = confusion_matrix(y_validation, predicted)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_3_classes.loc[text] = [accuracy, recall_micro, recall_macro, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ee190-706a-4aec-971d-e5da3bbc6018",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 1\n",
    "*  MLP 17-80-50-2\n",
    "*  HGNN 1-16-32-2\n",
    "*  Combined 4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "7815966c-c67f-4bdb-b4f5-0ce118f314ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(4, 2)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "188d1cd2-3bf0-4a7b-8768-aac909a50d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5574\n",
      "Validation Loss: 0.4601\n",
      "Saved the best model with validation loss: 0.4601\n",
      "Epoch [2/100], Loss: 0.4601\n",
      "Validation Loss: 0.4349\n",
      "Saved the best model with validation loss: 0.4349\n",
      "Epoch [3/100], Loss: 0.4372\n",
      "Validation Loss: 0.4256\n",
      "Saved the best model with validation loss: 0.4256\n",
      "Epoch [4/100], Loss: 0.4270\n",
      "Validation Loss: 0.4200\n",
      "Saved the best model with validation loss: 0.4200\n",
      "Epoch [5/100], Loss: 0.4183\n",
      "Validation Loss: 0.4149\n",
      "Saved the best model with validation loss: 0.4149\n",
      "Epoch [6/100], Loss: 0.4148\n",
      "Validation Loss: 0.4149\n",
      "Saved the best model with validation loss: 0.4149\n",
      "Epoch [7/100], Loss: 0.4101\n",
      "Validation Loss: 0.4089\n",
      "Saved the best model with validation loss: 0.4089\n",
      "Epoch [8/100], Loss: 0.4068\n",
      "Validation Loss: 0.4079\n",
      "Saved the best model with validation loss: 0.4079\n",
      "Epoch [9/100], Loss: 0.4050\n",
      "Validation Loss: 0.4051\n",
      "Saved the best model with validation loss: 0.4051\n",
      "Epoch [10/100], Loss: 0.4034\n",
      "Validation Loss: 0.4063\n",
      "Epoch [11/100], Loss: 0.4014\n",
      "Validation Loss: 0.4072\n",
      "Epoch [12/100], Loss: 0.4000\n",
      "Validation Loss: 0.4005\n",
      "Saved the best model with validation loss: 0.4005\n",
      "Epoch [13/100], Loss: 0.3987\n",
      "Validation Loss: 0.4049\n",
      "Epoch [14/100], Loss: 0.3973\n",
      "Validation Loss: 0.4051\n",
      "Epoch [15/100], Loss: 0.3953\n",
      "Validation Loss: 0.4093\n",
      "Epoch [16/100], Loss: 0.3946\n",
      "Validation Loss: 0.3960\n",
      "Saved the best model with validation loss: 0.3960\n",
      "Epoch [17/100], Loss: 0.3928\n",
      "Validation Loss: 0.3980\n",
      "Epoch [18/100], Loss: 0.3905\n",
      "Validation Loss: 0.4162\n",
      "Epoch [19/100], Loss: 0.3917\n",
      "Validation Loss: 0.3922\n",
      "Saved the best model with validation loss: 0.3922\n",
      "Epoch [20/100], Loss: 0.3897\n",
      "Validation Loss: 0.3930\n",
      "Epoch [21/100], Loss: 0.3879\n",
      "Validation Loss: 0.4114\n",
      "Epoch [22/100], Loss: 0.3892\n",
      "Validation Loss: 0.3881\n",
      "Saved the best model with validation loss: 0.3881\n",
      "Epoch [23/100], Loss: 0.3870\n",
      "Validation Loss: 0.4020\n",
      "Epoch [24/100], Loss: 0.3866\n",
      "Validation Loss: 0.3900\n",
      "Epoch [25/100], Loss: 0.3862\n",
      "Validation Loss: 0.3984\n",
      "Epoch [26/100], Loss: 0.3847\n",
      "Validation Loss: 0.4228\n",
      "Epoch [27/100], Loss: 0.3852\n",
      "Validation Loss: 0.3826\n",
      "Saved the best model with validation loss: 0.3826\n",
      "Epoch [28/100], Loss: 0.3843\n",
      "Validation Loss: 0.3822\n",
      "Saved the best model with validation loss: 0.3822\n",
      "Epoch [29/100], Loss: 0.3837\n",
      "Validation Loss: 0.3872\n",
      "Epoch [30/100], Loss: 0.3826\n",
      "Validation Loss: 0.3998\n",
      "Epoch [31/100], Loss: 0.3836\n",
      "Validation Loss: 0.3816\n",
      "Saved the best model with validation loss: 0.3816\n",
      "Epoch [32/100], Loss: 0.3821\n",
      "Validation Loss: 0.3774\n",
      "Saved the best model with validation loss: 0.3774\n",
      "Epoch [33/100], Loss: 0.3833\n",
      "Validation Loss: 0.3782\n",
      "Epoch [34/100], Loss: 0.3829\n",
      "Validation Loss: 0.3790\n",
      "Epoch [35/100], Loss: 0.3811\n",
      "Validation Loss: 0.3757\n",
      "Saved the best model with validation loss: 0.3757\n",
      "Epoch [36/100], Loss: 0.3812\n",
      "Validation Loss: 0.3763\n",
      "Epoch [37/100], Loss: 0.3813\n",
      "Validation Loss: 0.3758\n",
      "Epoch [38/100], Loss: 0.3801\n",
      "Validation Loss: 0.3762\n",
      "Epoch [39/100], Loss: 0.3791\n",
      "Validation Loss: 0.3757\n",
      "Saved the best model with validation loss: 0.3757\n",
      "Epoch [40/100], Loss: 0.3772\n",
      "Validation Loss: 0.3748\n",
      "Saved the best model with validation loss: 0.3748\n",
      "Epoch [41/100], Loss: 0.3782\n",
      "Validation Loss: 0.3784\n",
      "Epoch [42/100], Loss: 0.3782\n",
      "Validation Loss: 0.3732\n",
      "Saved the best model with validation loss: 0.3732\n",
      "Epoch [43/100], Loss: 0.3773\n",
      "Validation Loss: 0.3724\n",
      "Saved the best model with validation loss: 0.3724\n",
      "Epoch [44/100], Loss: 0.3764\n",
      "Validation Loss: 0.3737\n",
      "Epoch [45/100], Loss: 0.3765\n",
      "Validation Loss: 0.3757\n",
      "Epoch [46/100], Loss: 0.3778\n",
      "Validation Loss: 0.3738\n",
      "Epoch [47/100], Loss: 0.3765\n",
      "Validation Loss: 0.3748\n",
      "Epoch [48/100], Loss: 0.3775\n",
      "Validation Loss: 0.3709\n",
      "Saved the best model with validation loss: 0.3709\n",
      "Epoch [49/100], Loss: 0.3765\n",
      "Validation Loss: 0.3729\n",
      "Epoch [50/100], Loss: 0.3768\n",
      "Validation Loss: 0.3734\n",
      "Epoch [51/100], Loss: 0.3760\n",
      "Validation Loss: 0.3738\n",
      "Epoch [52/100], Loss: 0.3765\n",
      "Validation Loss: 0.3723\n",
      "Epoch [53/100], Loss: 0.3745\n",
      "Validation Loss: 0.3719\n",
      "Epoch [54/100], Loss: 0.3751\n",
      "Validation Loss: 0.3719\n",
      "Epoch [55/100], Loss: 0.3758\n",
      "Validation Loss: 0.3755\n",
      "Epoch [56/100], Loss: 0.3749\n",
      "Validation Loss: 0.3703\n",
      "Saved the best model with validation loss: 0.3703\n",
      "Epoch [57/100], Loss: 0.3752\n",
      "Validation Loss: 0.3692\n",
      "Saved the best model with validation loss: 0.3692\n",
      "Epoch [58/100], Loss: 0.3757\n",
      "Validation Loss: 0.3691\n",
      "Saved the best model with validation loss: 0.3691\n",
      "Epoch [59/100], Loss: 0.3740\n",
      "Validation Loss: 0.3693\n",
      "Epoch [60/100], Loss: 0.3732\n",
      "Validation Loss: 0.3691\n",
      "Epoch [61/100], Loss: 0.3731\n",
      "Validation Loss: 0.3706\n",
      "Epoch [62/100], Loss: 0.3731\n",
      "Validation Loss: 0.3690\n",
      "Saved the best model with validation loss: 0.3690\n",
      "Epoch [63/100], Loss: 0.3735\n",
      "Validation Loss: 0.3677\n",
      "Saved the best model with validation loss: 0.3677\n",
      "Epoch [64/100], Loss: 0.3727\n",
      "Validation Loss: 0.3664\n",
      "Saved the best model with validation loss: 0.3664\n",
      "Epoch [65/100], Loss: 0.3754\n",
      "Validation Loss: 0.3669\n",
      "Epoch [66/100], Loss: 0.3726\n",
      "Validation Loss: 0.3673\n",
      "Epoch [67/100], Loss: 0.3743\n",
      "Validation Loss: 0.3681\n",
      "Epoch [68/100], Loss: 0.3742\n",
      "Validation Loss: 0.3671\n",
      "Epoch [69/100], Loss: 0.3747\n",
      "Validation Loss: 0.3652\n",
      "Saved the best model with validation loss: 0.3652\n",
      "Epoch [70/100], Loss: 0.3723\n",
      "Validation Loss: 0.3664\n",
      "Epoch [71/100], Loss: 0.3768\n",
      "Validation Loss: 0.3658\n",
      "Epoch [72/100], Loss: 0.3737\n",
      "Validation Loss: 0.3673\n",
      "Epoch [73/100], Loss: 0.3721\n",
      "Validation Loss: 0.3676\n",
      "Epoch [74/100], Loss: 0.3738\n",
      "Validation Loss: 0.3652\n",
      "Epoch [75/100], Loss: 0.3726\n",
      "Validation Loss: 0.3641\n",
      "Saved the best model with validation loss: 0.3641\n",
      "Epoch [76/100], Loss: 0.3718\n",
      "Validation Loss: 0.3642\n",
      "Epoch [77/100], Loss: 0.3790\n",
      "Validation Loss: 0.3656\n",
      "Epoch [78/100], Loss: 0.3727\n",
      "Validation Loss: 0.3663\n",
      "Epoch [79/100], Loss: 0.3717\n",
      "Validation Loss: 0.3664\n",
      "Epoch [80/100], Loss: 0.3738\n",
      "Validation Loss: 0.3642\n",
      "Epoch [81/100], Loss: 0.3732\n",
      "Validation Loss: 0.3682\n",
      "Epoch [82/100], Loss: 0.3718\n",
      "Validation Loss: 0.3635\n",
      "Saved the best model with validation loss: 0.3635\n",
      "Epoch [83/100], Loss: 0.3706\n",
      "Validation Loss: 0.3614\n",
      "Saved the best model with validation loss: 0.3614\n",
      "Epoch [84/100], Loss: 0.3752\n",
      "Validation Loss: 0.3613\n",
      "Saved the best model with validation loss: 0.3613\n",
      "Epoch [85/100], Loss: 0.3708\n",
      "Validation Loss: 0.3614\n",
      "Epoch [86/100], Loss: 0.3708\n",
      "Validation Loss: 0.3605\n",
      "Saved the best model with validation loss: 0.3605\n",
      "Epoch [87/100], Loss: 0.3766\n",
      "Validation Loss: 0.3610\n",
      "Epoch [88/100], Loss: 0.3702\n",
      "Validation Loss: 0.3592\n",
      "Saved the best model with validation loss: 0.3592\n",
      "Epoch [89/100], Loss: 0.3700\n",
      "Validation Loss: 0.3613\n",
      "Epoch [90/100], Loss: 0.3721\n",
      "Validation Loss: 0.3605\n",
      "Epoch [91/100], Loss: 0.3707\n",
      "Validation Loss: 0.3603\n",
      "Epoch [92/100], Loss: 0.3732\n",
      "Validation Loss: 0.3606\n",
      "Epoch [93/100], Loss: 0.3702\n",
      "Validation Loss: 0.3601\n",
      "Epoch [94/100], Loss: 0.3735\n",
      "Validation Loss: 0.3618\n",
      "Epoch [95/100], Loss: 0.3704\n",
      "Validation Loss: 0.3600\n",
      "Epoch [96/100], Loss: 0.3695\n",
      "Validation Loss: 0.3572\n",
      "Saved the best model with validation loss: 0.3572\n",
      "Epoch [97/100], Loss: 0.3705\n",
      "Validation Loss: 0.3650\n",
      "Epoch [98/100], Loss: 0.3704\n",
      "Validation Loss: 0.3589\n",
      "Epoch [99/100], Loss: 0.3692\n",
      "Validation Loss: 0.3600\n",
      "Epoch [100/100], Loss: 0.3705\n",
      "Validation Loss: 0.3596\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"combi: 17-80-50-2/1-16-32-2/4-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6e56f4-8c34-4da2-afa7-eb75ac25c83b",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 2\n",
    "*  MLP 17-80-50-5\n",
    "*  HGNN 1-16-32-5\n",
    "*  Combined 10-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "57327689-8edb-47e5-9236-f570d0e51f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "4570b6bd-4cc4-422f-a225-fb99abdec0a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5535\n",
      "Validation Loss: 0.4706\n",
      "Saved the best model with validation loss: 0.4706\n",
      "Epoch [2/100], Loss: 0.4600\n",
      "Validation Loss: 0.4442\n",
      "Saved the best model with validation loss: 0.4442\n",
      "Epoch [3/100], Loss: 0.4397\n",
      "Validation Loss: 0.4346\n",
      "Saved the best model with validation loss: 0.4346\n",
      "Epoch [4/100], Loss: 0.4298\n",
      "Validation Loss: 0.4277\n",
      "Saved the best model with validation loss: 0.4277\n",
      "Epoch [5/100], Loss: 0.4239\n",
      "Validation Loss: 0.4295\n",
      "Epoch [6/100], Loss: 0.4182\n",
      "Validation Loss: 0.4203\n",
      "Saved the best model with validation loss: 0.4203\n",
      "Epoch [7/100], Loss: 0.4139\n",
      "Validation Loss: 0.4196\n",
      "Saved the best model with validation loss: 0.4196\n",
      "Epoch [8/100], Loss: 0.4105\n",
      "Validation Loss: 0.4152\n",
      "Saved the best model with validation loss: 0.4152\n",
      "Epoch [9/100], Loss: 0.4073\n",
      "Validation Loss: 0.4114\n",
      "Saved the best model with validation loss: 0.4114\n",
      "Epoch [10/100], Loss: 0.4051\n",
      "Validation Loss: 0.4073\n",
      "Saved the best model with validation loss: 0.4073\n",
      "Epoch [11/100], Loss: 0.4040\n",
      "Validation Loss: 0.4041\n",
      "Saved the best model with validation loss: 0.4041\n",
      "Epoch [12/100], Loss: 0.4016\n",
      "Validation Loss: 0.4024\n",
      "Saved the best model with validation loss: 0.4024\n",
      "Epoch [13/100], Loss: 0.4003\n",
      "Validation Loss: 0.4070\n",
      "Epoch [14/100], Loss: 0.3991\n",
      "Validation Loss: 0.4048\n",
      "Epoch [15/100], Loss: 0.3972\n",
      "Validation Loss: 0.3984\n",
      "Saved the best model with validation loss: 0.3984\n",
      "Epoch [16/100], Loss: 0.3957\n",
      "Validation Loss: 0.4148\n",
      "Epoch [17/100], Loss: 0.3953\n",
      "Validation Loss: 0.4189\n",
      "Epoch [18/100], Loss: 0.3938\n",
      "Validation Loss: 0.3940\n",
      "Saved the best model with validation loss: 0.3940\n",
      "Epoch [19/100], Loss: 0.3933\n",
      "Validation Loss: 0.3935\n",
      "Saved the best model with validation loss: 0.3935\n",
      "Epoch [20/100], Loss: 0.3916\n",
      "Validation Loss: 0.3933\n",
      "Saved the best model with validation loss: 0.3933\n",
      "Epoch [21/100], Loss: 0.3903\n",
      "Validation Loss: 0.3932\n",
      "Saved the best model with validation loss: 0.3932\n",
      "Epoch [22/100], Loss: 0.3909\n",
      "Validation Loss: 0.3974\n",
      "Epoch [23/100], Loss: 0.3899\n",
      "Validation Loss: 0.3848\n",
      "Saved the best model with validation loss: 0.3848\n",
      "Epoch [24/100], Loss: 0.3892\n",
      "Validation Loss: 0.3848\n",
      "Saved the best model with validation loss: 0.3848\n",
      "Epoch [25/100], Loss: 0.3877\n",
      "Validation Loss: 0.3829\n",
      "Saved the best model with validation loss: 0.3829\n",
      "Epoch [26/100], Loss: 0.3870\n",
      "Validation Loss: 0.3808\n",
      "Saved the best model with validation loss: 0.3808\n",
      "Epoch [27/100], Loss: 0.3866\n",
      "Validation Loss: 0.3851\n",
      "Epoch [28/100], Loss: 0.3853\n",
      "Validation Loss: 0.3806\n",
      "Saved the best model with validation loss: 0.3806\n",
      "Epoch [29/100], Loss: 0.3844\n",
      "Validation Loss: 0.3836\n",
      "Epoch [30/100], Loss: 0.3846\n",
      "Validation Loss: 0.3778\n",
      "Saved the best model with validation loss: 0.3778\n",
      "Epoch [31/100], Loss: 0.3835\n",
      "Validation Loss: 0.3771\n",
      "Saved the best model with validation loss: 0.3771\n",
      "Epoch [32/100], Loss: 0.3824\n",
      "Validation Loss: 0.3780\n",
      "Epoch [33/100], Loss: 0.3824\n",
      "Validation Loss: 0.3799\n",
      "Epoch [34/100], Loss: 0.3814\n",
      "Validation Loss: 0.3768\n",
      "Saved the best model with validation loss: 0.3768\n",
      "Epoch [35/100], Loss: 0.3811\n",
      "Validation Loss: 0.3739\n",
      "Saved the best model with validation loss: 0.3739\n",
      "Epoch [36/100], Loss: 0.3804\n",
      "Validation Loss: 0.3744\n",
      "Epoch [37/100], Loss: 0.3828\n",
      "Validation Loss: 0.3751\n",
      "Epoch [38/100], Loss: 0.3791\n",
      "Validation Loss: 0.3800\n",
      "Epoch [39/100], Loss: 0.3795\n",
      "Validation Loss: 0.3754\n",
      "Epoch [40/100], Loss: 0.3795\n",
      "Validation Loss: 0.3735\n",
      "Saved the best model with validation loss: 0.3735\n",
      "Epoch [41/100], Loss: 0.3790\n",
      "Validation Loss: 0.3738\n",
      "Epoch [42/100], Loss: 0.3788\n",
      "Validation Loss: 0.3743\n",
      "Epoch [43/100], Loss: 0.3782\n",
      "Validation Loss: 0.3710\n",
      "Saved the best model with validation loss: 0.3710\n",
      "Epoch [44/100], Loss: 0.3773\n",
      "Validation Loss: 0.3697\n",
      "Saved the best model with validation loss: 0.3697\n",
      "Epoch [45/100], Loss: 0.3766\n",
      "Validation Loss: 0.3735\n",
      "Epoch [46/100], Loss: 0.3769\n",
      "Validation Loss: 0.3763\n",
      "Epoch [47/100], Loss: 0.3751\n",
      "Validation Loss: 0.3764\n",
      "Epoch [48/100], Loss: 0.3755\n",
      "Validation Loss: 0.3684\n",
      "Saved the best model with validation loss: 0.3684\n",
      "Epoch [49/100], Loss: 0.3751\n",
      "Validation Loss: 0.3713\n",
      "Epoch [50/100], Loss: 0.3751\n",
      "Validation Loss: 0.3727\n",
      "Epoch [51/100], Loss: 0.3735\n",
      "Validation Loss: 0.3673\n",
      "Saved the best model with validation loss: 0.3673\n",
      "Epoch [52/100], Loss: 0.3734\n",
      "Validation Loss: 0.3668\n",
      "Saved the best model with validation loss: 0.3668\n",
      "Epoch [53/100], Loss: 0.3734\n",
      "Validation Loss: 0.3750\n",
      "Epoch [54/100], Loss: 0.3729\n",
      "Validation Loss: 0.3690\n",
      "Epoch [55/100], Loss: 0.3735\n",
      "Validation Loss: 0.3707\n",
      "Epoch [56/100], Loss: 0.3737\n",
      "Validation Loss: 0.3673\n",
      "Epoch [57/100], Loss: 0.3715\n",
      "Validation Loss: 0.3696\n",
      "Epoch [58/100], Loss: 0.3709\n",
      "Validation Loss: 0.3692\n",
      "Epoch [59/100], Loss: 0.3711\n",
      "Validation Loss: 0.3687\n",
      "Epoch [60/100], Loss: 0.3716\n",
      "Validation Loss: 0.3671\n",
      "Epoch [61/100], Loss: 0.3700\n",
      "Validation Loss: 0.3747\n",
      "Epoch [62/100], Loss: 0.3715\n",
      "Validation Loss: 0.3697\n",
      "Epoch [63/100], Loss: 0.3721\n",
      "Validation Loss: 0.3665\n",
      "Saved the best model with validation loss: 0.3665\n",
      "Epoch [64/100], Loss: 0.3701\n",
      "Validation Loss: 0.3675\n",
      "Epoch [65/100], Loss: 0.3697\n",
      "Validation Loss: 0.3672\n",
      "Epoch [66/100], Loss: 0.3699\n",
      "Validation Loss: 0.3658\n",
      "Saved the best model with validation loss: 0.3658\n",
      "Epoch [67/100], Loss: 0.3688\n",
      "Validation Loss: 0.3670\n",
      "Epoch [68/100], Loss: 0.3688\n",
      "Validation Loss: 0.3662\n",
      "Epoch [69/100], Loss: 0.3688\n",
      "Validation Loss: 0.3666\n",
      "Epoch [70/100], Loss: 0.3684\n",
      "Validation Loss: 0.3730\n",
      "Epoch [71/100], Loss: 0.3685\n",
      "Validation Loss: 0.3809\n",
      "Epoch [72/100], Loss: 0.3698\n",
      "Validation Loss: 0.3666\n",
      "Epoch [73/100], Loss: 0.3681\n",
      "Validation Loss: 0.3736\n",
      "Epoch [74/100], Loss: 0.3677\n",
      "Validation Loss: 0.3679\n",
      "Epoch [75/100], Loss: 0.3671\n",
      "Validation Loss: 0.3662\n",
      "Epoch [76/100], Loss: 0.3659\n",
      "Validation Loss: 0.3651\n",
      "Saved the best model with validation loss: 0.3651\n",
      "Epoch [77/100], Loss: 0.3653\n",
      "Validation Loss: 0.3656\n",
      "Epoch [78/100], Loss: 0.3655\n",
      "Validation Loss: 0.3689\n",
      "Epoch [79/100], Loss: 0.3666\n",
      "Validation Loss: 0.3657\n",
      "Epoch [80/100], Loss: 0.3654\n",
      "Validation Loss: 0.3643\n",
      "Saved the best model with validation loss: 0.3643\n",
      "Epoch [81/100], Loss: 0.3660\n",
      "Validation Loss: 0.3655\n",
      "Epoch [82/100], Loss: 0.3645\n",
      "Validation Loss: 0.3620\n",
      "Saved the best model with validation loss: 0.3620\n",
      "Epoch [83/100], Loss: 0.3665\n",
      "Validation Loss: 0.3616\n",
      "Saved the best model with validation loss: 0.3616\n",
      "Epoch [84/100], Loss: 0.3641\n",
      "Validation Loss: 0.3651\n",
      "Epoch [85/100], Loss: 0.3638\n",
      "Validation Loss: 0.3633\n",
      "Epoch [86/100], Loss: 0.3644\n",
      "Validation Loss: 0.3632\n",
      "Epoch [87/100], Loss: 0.3628\n",
      "Validation Loss: 0.3670\n",
      "Epoch [88/100], Loss: 0.3637\n",
      "Validation Loss: 0.3661\n",
      "Epoch [89/100], Loss: 0.3640\n",
      "Validation Loss: 0.3670\n",
      "Epoch [90/100], Loss: 0.3629\n",
      "Validation Loss: 0.3646\n",
      "Epoch [91/100], Loss: 0.3644\n",
      "Validation Loss: 0.3639\n",
      "Epoch [92/100], Loss: 0.3631\n",
      "Validation Loss: 0.3649\n",
      "Epoch [93/100], Loss: 0.3641\n",
      "Validation Loss: 0.3703\n",
      "Epoch [94/100], Loss: 0.3684\n",
      "Validation Loss: 0.3682\n",
      "Epoch [95/100], Loss: 0.3631\n",
      "Validation Loss: 0.3781\n",
      "Epoch [96/100], Loss: 0.3641\n",
      "Validation Loss: 0.3630\n",
      "Epoch [97/100], Loss: 0.3621\n",
      "Validation Loss: 0.3699\n",
      "Epoch [98/100], Loss: 0.3631\n",
      "Validation Loss: 0.3653\n",
      "Epoch [99/100], Loss: 0.3621\n",
      "Validation Loss: 0.3657\n",
      "Epoch [100/100], Loss: 0.3624\n",
      "Validation Loss: 0.3682\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"combi: 17-80-50-5/1-16-32-5/10-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7efab64-d410-48eb-9c1e-fd545b6b2c05",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 3\n",
    "*  MLP 17-80-50-5\n",
    "*  HGNN 1-16-32-5\n",
    "*  Combined 10-20-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "2fcd6ff8-da22-4b8b-a056-a0b4d5c4546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "84553275-43ea-4b4b-a1ba-f3439b4044c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5752\n",
      "Validation Loss: 0.4924\n",
      "Saved the best model with validation loss: 0.4924\n",
      "Epoch [2/100], Loss: 0.4756\n",
      "Validation Loss: 0.4481\n",
      "Saved the best model with validation loss: 0.4481\n",
      "Epoch [3/100], Loss: 0.4398\n",
      "Validation Loss: 0.4253\n",
      "Saved the best model with validation loss: 0.4253\n",
      "Epoch [4/100], Loss: 0.4211\n",
      "Validation Loss: 0.4214\n",
      "Saved the best model with validation loss: 0.4214\n",
      "Epoch [5/100], Loss: 0.4106\n",
      "Validation Loss: 0.4159\n",
      "Saved the best model with validation loss: 0.4159\n",
      "Epoch [6/100], Loss: 0.4030\n",
      "Validation Loss: 0.4179\n",
      "Epoch [7/100], Loss: 0.3954\n",
      "Validation Loss: 0.4168\n",
      "Epoch [8/100], Loss: 0.3921\n",
      "Validation Loss: 0.4169\n",
      "Epoch [9/100], Loss: 0.3862\n",
      "Validation Loss: 0.4438\n",
      "Epoch [10/100], Loss: 0.3822\n",
      "Validation Loss: 0.4077\n",
      "Saved the best model with validation loss: 0.4077\n",
      "Epoch [11/100], Loss: 0.3801\n",
      "Validation Loss: 0.3985\n",
      "Saved the best model with validation loss: 0.3985\n",
      "Epoch [12/100], Loss: 0.3746\n",
      "Validation Loss: 0.4068\n",
      "Epoch [13/100], Loss: 0.3742\n",
      "Validation Loss: 0.3858\n",
      "Saved the best model with validation loss: 0.3858\n",
      "Epoch [14/100], Loss: 0.3715\n",
      "Validation Loss: 0.3963\n",
      "Epoch [15/100], Loss: 0.3676\n",
      "Validation Loss: 0.4075\n",
      "Epoch [16/100], Loss: 0.3670\n",
      "Validation Loss: 0.4080\n",
      "Epoch [17/100], Loss: 0.3665\n",
      "Validation Loss: 0.3913\n",
      "Epoch [18/100], Loss: 0.3630\n",
      "Validation Loss: 0.3989\n",
      "Epoch [19/100], Loss: 0.3623\n",
      "Validation Loss: 0.4043\n",
      "Epoch [20/100], Loss: 0.3605\n",
      "Validation Loss: 0.3929\n",
      "Epoch [21/100], Loss: 0.3576\n",
      "Validation Loss: 0.4028\n",
      "Epoch [22/100], Loss: 0.3607\n",
      "Validation Loss: 0.4080\n",
      "Epoch [23/100], Loss: 0.3571\n",
      "Validation Loss: 0.4173\n",
      "Epoch [24/100], Loss: 0.3581\n",
      "Validation Loss: 0.4142\n",
      "Epoch [25/100], Loss: 0.3581\n",
      "Validation Loss: 0.3875\n",
      "Epoch [26/100], Loss: 0.3556\n",
      "Validation Loss: 0.4218\n",
      "Epoch [27/100], Loss: 0.3555\n",
      "Validation Loss: 0.3782\n",
      "Saved the best model with validation loss: 0.3782\n",
      "Epoch [28/100], Loss: 0.3527\n",
      "Validation Loss: 0.3921\n",
      "Epoch [29/100], Loss: 0.3531\n",
      "Validation Loss: 0.3884\n",
      "Epoch [30/100], Loss: 0.3531\n",
      "Validation Loss: 0.3739\n",
      "Saved the best model with validation loss: 0.3739\n",
      "Epoch [31/100], Loss: 0.3525\n",
      "Validation Loss: 0.3878\n",
      "Epoch [32/100], Loss: 0.3491\n",
      "Validation Loss: 0.3744\n",
      "Epoch [33/100], Loss: 0.3517\n",
      "Validation Loss: 0.3955\n",
      "Epoch [34/100], Loss: 0.3472\n",
      "Validation Loss: 0.3707\n",
      "Saved the best model with validation loss: 0.3707\n",
      "Epoch [35/100], Loss: 0.3493\n",
      "Validation Loss: 0.3679\n",
      "Saved the best model with validation loss: 0.3679\n",
      "Epoch [36/100], Loss: 0.3520\n",
      "Validation Loss: 0.3566\n",
      "Saved the best model with validation loss: 0.3566\n",
      "Epoch [37/100], Loss: 0.3452\n",
      "Validation Loss: 0.3606\n",
      "Epoch [38/100], Loss: 0.3478\n",
      "Validation Loss: 0.3702\n",
      "Epoch [39/100], Loss: 0.3441\n",
      "Validation Loss: 0.3786\n",
      "Epoch [40/100], Loss: 0.3468\n",
      "Validation Loss: 0.3631\n",
      "Epoch [41/100], Loss: 0.3476\n",
      "Validation Loss: 0.3731\n",
      "Epoch [42/100], Loss: 0.3496\n",
      "Validation Loss: 0.3833\n",
      "Epoch [43/100], Loss: 0.3449\n",
      "Validation Loss: 0.3684\n",
      "Epoch [44/100], Loss: 0.3424\n",
      "Validation Loss: 0.3792\n",
      "Epoch [45/100], Loss: 0.3444\n",
      "Validation Loss: 0.3790\n",
      "Epoch [46/100], Loss: 0.3409\n",
      "Validation Loss: 0.3683\n",
      "Epoch [47/100], Loss: 0.3529\n",
      "Validation Loss: 0.3710\n",
      "Epoch [48/100], Loss: 0.3420\n",
      "Validation Loss: 0.3888\n",
      "Epoch [49/100], Loss: 0.3470\n",
      "Validation Loss: 0.3720\n",
      "Epoch [50/100], Loss: 0.3445\n",
      "Validation Loss: 0.3639\n",
      "Epoch [51/100], Loss: 0.3431\n",
      "Validation Loss: 0.3649\n",
      "Epoch [52/100], Loss: 0.3416\n",
      "Validation Loss: 0.3714\n",
      "Epoch [53/100], Loss: 0.3423\n",
      "Validation Loss: 0.3551\n",
      "Saved the best model with validation loss: 0.3551\n",
      "Epoch [54/100], Loss: 0.3448\n",
      "Validation Loss: 0.3686\n",
      "Epoch [55/100], Loss: 0.3421\n",
      "Validation Loss: 0.3649\n",
      "Epoch [56/100], Loss: 0.3423\n",
      "Validation Loss: 0.3721\n",
      "Epoch [57/100], Loss: 0.3511\n",
      "Validation Loss: 0.3630\n",
      "Epoch [58/100], Loss: 0.3397\n",
      "Validation Loss: 0.3686\n",
      "Epoch [59/100], Loss: 0.3549\n",
      "Validation Loss: 0.3820\n",
      "Epoch [60/100], Loss: 0.3439\n",
      "Validation Loss: 0.3641\n",
      "Epoch [61/100], Loss: 0.3397\n",
      "Validation Loss: 0.3648\n",
      "Epoch [62/100], Loss: 0.3407\n",
      "Validation Loss: 0.3492\n",
      "Saved the best model with validation loss: 0.3492\n",
      "Epoch [63/100], Loss: 0.3417\n",
      "Validation Loss: 0.3518\n",
      "Epoch [64/100], Loss: 0.3421\n",
      "Validation Loss: 0.3755\n",
      "Epoch [65/100], Loss: 0.3426\n",
      "Validation Loss: 0.3604\n",
      "Epoch [66/100], Loss: 0.3428\n",
      "Validation Loss: 0.3595\n",
      "Epoch [67/100], Loss: 0.3420\n",
      "Validation Loss: 0.3544\n",
      "Epoch [68/100], Loss: 0.3410\n",
      "Validation Loss: 0.3741\n",
      "Epoch [69/100], Loss: 0.3506\n",
      "Validation Loss: 0.3826\n",
      "Epoch [70/100], Loss: 0.3437\n",
      "Validation Loss: 0.4010\n",
      "Epoch [71/100], Loss: 0.3454\n",
      "Validation Loss: 0.3720\n",
      "Epoch [72/100], Loss: 0.3430\n",
      "Validation Loss: 0.3787\n",
      "Epoch [73/100], Loss: 0.3397\n",
      "Validation Loss: 0.3837\n",
      "Epoch [74/100], Loss: 0.3403\n",
      "Validation Loss: 0.3909\n",
      "Epoch [75/100], Loss: 0.3416\n",
      "Validation Loss: 0.3580\n",
      "Epoch [76/100], Loss: 0.3346\n",
      "Validation Loss: 0.3847\n",
      "Epoch [77/100], Loss: 0.3526\n",
      "Validation Loss: 0.3659\n",
      "Epoch [78/100], Loss: 0.3406\n",
      "Validation Loss: 0.3585\n",
      "Epoch [79/100], Loss: 0.3435\n",
      "Validation Loss: 0.3623\n",
      "Epoch [80/100], Loss: 0.3432\n",
      "Validation Loss: 0.3639\n",
      "Epoch [81/100], Loss: 0.3374\n",
      "Validation Loss: 0.3788\n",
      "Epoch [82/100], Loss: 0.3436\n",
      "Validation Loss: 0.3806\n",
      "Epoch [83/100], Loss: 0.3364\n",
      "Validation Loss: 0.3577\n",
      "Epoch [84/100], Loss: 0.3406\n",
      "Validation Loss: 0.3774\n",
      "Epoch [85/100], Loss: 0.3391\n",
      "Validation Loss: 0.3639\n",
      "Epoch [86/100], Loss: 0.3413\n",
      "Validation Loss: 0.3816\n",
      "Epoch [87/100], Loss: 0.3333\n",
      "Validation Loss: 0.3737\n",
      "Epoch [88/100], Loss: 0.3326\n",
      "Validation Loss: 0.3687\n",
      "Epoch [89/100], Loss: 0.3444\n",
      "Validation Loss: 0.3609\n",
      "Epoch [90/100], Loss: 0.3341\n",
      "Validation Loss: 0.3778\n",
      "Epoch [91/100], Loss: 0.3402\n",
      "Validation Loss: 0.3807\n",
      "Epoch [92/100], Loss: 0.3346\n",
      "Validation Loss: 0.6522\n",
      "Epoch [93/100], Loss: 0.3464\n",
      "Validation Loss: 0.3719\n",
      "Epoch [94/100], Loss: 0.3430\n",
      "Validation Loss: 0.3979\n",
      "Epoch [95/100], Loss: 0.3403\n",
      "Validation Loss: 0.4392\n",
      "Epoch [96/100], Loss: 0.3348\n",
      "Validation Loss: 0.3573\n",
      "Epoch [97/100], Loss: 0.3382\n",
      "Validation Loss: 0.4076\n",
      "Epoch [98/100], Loss: 0.3361\n",
      "Validation Loss: 0.3750\n",
      "Epoch [99/100], Loss: 0.3386\n",
      "Validation Loss: 0.3543\n",
      "Epoch [100/100], Loss: 0.3472\n",
      "Validation Loss: 0.4009\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"combi: 17-80-50-5/1-16-32-5/10-20-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd93d43-fab3-4973-b99b-c1f2dda63143",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 4\n",
    "*  MLP 17-80-50-10\n",
    "*  HGNN 1-16-32-10\n",
    "*  Combined 20-40-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "6d72135c-3168-4fa9-8ea4-78054fd222b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "6b3a113d-b276-4b10-aab3-7b111a417ea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5682\n",
      "Validation Loss: 0.4645\n",
      "Saved the best model with validation loss: 0.4645\n",
      "Epoch [2/100], Loss: 0.4646\n",
      "Validation Loss: 0.4328\n",
      "Saved the best model with validation loss: 0.4328\n",
      "Epoch [3/100], Loss: 0.4384\n",
      "Validation Loss: 0.4225\n",
      "Saved the best model with validation loss: 0.4225\n",
      "Epoch [4/100], Loss: 0.4246\n",
      "Validation Loss: 0.4093\n",
      "Saved the best model with validation loss: 0.4093\n",
      "Epoch [5/100], Loss: 0.4143\n",
      "Validation Loss: 0.4047\n",
      "Saved the best model with validation loss: 0.4047\n",
      "Epoch [6/100], Loss: 0.4052\n",
      "Validation Loss: 0.4136\n",
      "Epoch [7/100], Loss: 0.3978\n",
      "Validation Loss: 0.4045\n",
      "Saved the best model with validation loss: 0.4045\n",
      "Epoch [8/100], Loss: 0.3918\n",
      "Validation Loss: 0.3949\n",
      "Saved the best model with validation loss: 0.3949\n",
      "Epoch [9/100], Loss: 0.3865\n",
      "Validation Loss: 0.4329\n",
      "Epoch [10/100], Loss: 0.3855\n",
      "Validation Loss: 0.4293\n",
      "Epoch [11/100], Loss: 0.3821\n",
      "Validation Loss: 0.4446\n",
      "Epoch [12/100], Loss: 0.3787\n",
      "Validation Loss: 0.4215\n",
      "Epoch [13/100], Loss: 0.3736\n",
      "Validation Loss: 0.4482\n",
      "Epoch [14/100], Loss: 0.3728\n",
      "Validation Loss: 0.4082\n",
      "Epoch [15/100], Loss: 0.3713\n",
      "Validation Loss: 0.4358\n",
      "Epoch [16/100], Loss: 0.3679\n",
      "Validation Loss: 0.4378\n",
      "Epoch [17/100], Loss: 0.3671\n",
      "Validation Loss: 0.4392\n",
      "Epoch [18/100], Loss: 0.3668\n",
      "Validation Loss: 0.4114\n",
      "Epoch [19/100], Loss: 0.3678\n",
      "Validation Loss: 0.3974\n",
      "Epoch [20/100], Loss: 0.3664\n",
      "Validation Loss: 0.4062\n",
      "Epoch [21/100], Loss: 0.3620\n",
      "Validation Loss: 0.4021\n",
      "Epoch [22/100], Loss: 0.3608\n",
      "Validation Loss: 0.3887\n",
      "Saved the best model with validation loss: 0.3887\n",
      "Epoch [23/100], Loss: 0.3565\n",
      "Validation Loss: 0.3880\n",
      "Saved the best model with validation loss: 0.3880\n",
      "Epoch [24/100], Loss: 0.3633\n",
      "Validation Loss: 0.3877\n",
      "Saved the best model with validation loss: 0.3877\n",
      "Epoch [25/100], Loss: 0.3595\n",
      "Validation Loss: 0.4450\n",
      "Epoch [26/100], Loss: 0.3607\n",
      "Validation Loss: 0.3748\n",
      "Saved the best model with validation loss: 0.3748\n",
      "Epoch [27/100], Loss: 0.3595\n",
      "Validation Loss: 0.3723\n",
      "Saved the best model with validation loss: 0.3723\n",
      "Epoch [28/100], Loss: 0.3602\n",
      "Validation Loss: 0.3644\n",
      "Saved the best model with validation loss: 0.3644\n",
      "Epoch [29/100], Loss: 0.3528\n",
      "Validation Loss: 0.3615\n",
      "Saved the best model with validation loss: 0.3615\n",
      "Epoch [30/100], Loss: 0.3548\n",
      "Validation Loss: 0.3727\n",
      "Epoch [31/100], Loss: 0.3551\n",
      "Validation Loss: 0.3760\n",
      "Epoch [32/100], Loss: 0.3515\n",
      "Validation Loss: 0.3798\n",
      "Epoch [33/100], Loss: 0.3565\n",
      "Validation Loss: 0.3693\n",
      "Epoch [34/100], Loss: 0.3521\n",
      "Validation Loss: 0.3685\n",
      "Epoch [35/100], Loss: 0.3495\n",
      "Validation Loss: 0.3758\n",
      "Epoch [36/100], Loss: 0.3525\n",
      "Validation Loss: 0.3769\n",
      "Epoch [37/100], Loss: 0.3457\n",
      "Validation Loss: 0.3704\n",
      "Epoch [38/100], Loss: 0.3476\n",
      "Validation Loss: 0.3840\n",
      "Epoch [39/100], Loss: 0.3496\n",
      "Validation Loss: 0.3812\n",
      "Epoch [40/100], Loss: 0.3459\n",
      "Validation Loss: 0.3772\n",
      "Epoch [41/100], Loss: 0.3499\n",
      "Validation Loss: 0.5398\n",
      "Epoch [42/100], Loss: 0.3515\n",
      "Validation Loss: 0.3944\n",
      "Epoch [43/100], Loss: 0.3464\n",
      "Validation Loss: 0.3823\n",
      "Epoch [44/100], Loss: 0.3457\n",
      "Validation Loss: 0.3659\n",
      "Epoch [45/100], Loss: 0.3447\n",
      "Validation Loss: 0.3809\n",
      "Epoch [46/100], Loss: 0.3428\n",
      "Validation Loss: 0.3747\n",
      "Epoch [47/100], Loss: 0.3426\n",
      "Validation Loss: 0.4033\n",
      "Epoch [48/100], Loss: 0.3434\n",
      "Validation Loss: 0.3752\n",
      "Epoch [49/100], Loss: 0.3436\n",
      "Validation Loss: 0.3676\n",
      "Epoch [50/100], Loss: 0.3470\n",
      "Validation Loss: 0.3594\n",
      "Saved the best model with validation loss: 0.3594\n",
      "Epoch [51/100], Loss: 0.3425\n",
      "Validation Loss: 0.3839\n",
      "Epoch [52/100], Loss: 0.3440\n",
      "Validation Loss: 0.3557\n",
      "Saved the best model with validation loss: 0.3557\n",
      "Epoch [53/100], Loss: 0.3472\n",
      "Validation Loss: 0.3577\n",
      "Epoch [54/100], Loss: 0.3386\n",
      "Validation Loss: 0.3605\n",
      "Epoch [55/100], Loss: 0.3449\n",
      "Validation Loss: 0.3586\n",
      "Epoch [56/100], Loss: 0.3409\n",
      "Validation Loss: 0.3579\n",
      "Epoch [57/100], Loss: 0.3494\n",
      "Validation Loss: 0.3650\n",
      "Epoch [58/100], Loss: 0.3416\n",
      "Validation Loss: 0.3596\n",
      "Epoch [59/100], Loss: 0.3531\n",
      "Validation Loss: 0.3556\n",
      "Saved the best model with validation loss: 0.3556\n",
      "Epoch [60/100], Loss: 0.3342\n",
      "Validation Loss: 0.3709\n",
      "Epoch [61/100], Loss: 0.3439\n",
      "Validation Loss: 0.3666\n",
      "Epoch [62/100], Loss: 0.3409\n",
      "Validation Loss: 0.3562\n",
      "Epoch [63/100], Loss: 0.3558\n",
      "Validation Loss: 0.3511\n",
      "Saved the best model with validation loss: 0.3511\n",
      "Epoch [64/100], Loss: 0.3359\n",
      "Validation Loss: 0.3555\n",
      "Epoch [65/100], Loss: 0.3457\n",
      "Validation Loss: 0.3443\n",
      "Saved the best model with validation loss: 0.3443\n",
      "Epoch [66/100], Loss: 0.3367\n",
      "Validation Loss: 0.3427\n",
      "Saved the best model with validation loss: 0.3427\n",
      "Epoch [67/100], Loss: 0.3364\n",
      "Validation Loss: 0.3674\n",
      "Epoch [68/100], Loss: 0.3371\n",
      "Validation Loss: 0.3482\n",
      "Epoch [69/100], Loss: 0.3376\n",
      "Validation Loss: 0.3583\n",
      "Epoch [70/100], Loss: 0.3339\n",
      "Validation Loss: 0.3532\n",
      "Epoch [71/100], Loss: 0.3445\n",
      "Validation Loss: 0.3461\n",
      "Epoch [72/100], Loss: 0.3300\n",
      "Validation Loss: 0.3630\n",
      "Epoch [73/100], Loss: 0.3326\n",
      "Validation Loss: 0.3849\n",
      "Epoch [74/100], Loss: 0.3448\n",
      "Validation Loss: 0.3840\n",
      "Epoch [75/100], Loss: 0.3343\n",
      "Validation Loss: 0.3695\n",
      "Epoch [76/100], Loss: 0.3376\n",
      "Validation Loss: 0.3966\n",
      "Epoch [77/100], Loss: 0.3321\n",
      "Validation Loss: 0.3611\n",
      "Epoch [78/100], Loss: 0.3329\n",
      "Validation Loss: 0.3723\n",
      "Epoch [79/100], Loss: 0.3556\n",
      "Validation Loss: 0.3735\n",
      "Epoch [80/100], Loss: 0.3334\n",
      "Validation Loss: 0.3776\n",
      "Epoch [81/100], Loss: 0.3312\n",
      "Validation Loss: 0.3761\n",
      "Epoch [82/100], Loss: 0.3332\n",
      "Validation Loss: 0.3782\n",
      "Epoch [83/100], Loss: 0.3411\n",
      "Validation Loss: 0.3672\n",
      "Epoch [84/100], Loss: 0.3334\n",
      "Validation Loss: 0.3710\n",
      "Epoch [85/100], Loss: 0.3372\n",
      "Validation Loss: 0.3866\n",
      "Epoch [86/100], Loss: 0.3303\n",
      "Validation Loss: 0.3764\n",
      "Epoch [87/100], Loss: 0.3336\n",
      "Validation Loss: 0.3931\n",
      "Epoch [88/100], Loss: 0.3354\n",
      "Validation Loss: 0.3731\n",
      "Epoch [89/100], Loss: 0.3434\n",
      "Validation Loss: 0.3646\n",
      "Epoch [90/100], Loss: 0.3285\n",
      "Validation Loss: 0.3524\n",
      "Epoch [91/100], Loss: 0.3311\n",
      "Validation Loss: 0.3601\n",
      "Epoch [92/100], Loss: 0.3381\n",
      "Validation Loss: 0.3609\n",
      "Epoch [93/100], Loss: 0.3262\n",
      "Validation Loss: 0.3798\n",
      "Epoch [94/100], Loss: 0.3863\n",
      "Validation Loss: 0.3708\n",
      "Epoch [95/100], Loss: 0.3301\n",
      "Validation Loss: 0.3984\n",
      "Epoch [96/100], Loss: 0.3352\n",
      "Validation Loss: 0.3868\n",
      "Epoch [97/100], Loss: 0.3353\n",
      "Validation Loss: 0.4185\n",
      "Epoch [98/100], Loss: 0.3377\n",
      "Validation Loss: 0.4124\n",
      "Epoch [99/100], Loss: 0.3321\n",
      "Validation Loss: 0.4130\n",
      "Epoch [100/100], Loss: 0.3356\n",
      "Validation Loss: 0.4588\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"combi: 17-80-50-10/1-16-32-10/20-40-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0edada4-75ec-4607-8a74-9def9f50f527",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 5\n",
    "*  MLP 17-80-50-10\n",
    "*  HGNN 1-16-32-10\n",
    "*  Combined 20-60-20-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "866ada28-2a5e-4b65-82f0-291b8895375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4057aade-9775-42e1-b2a4-08c5281897cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5765\n",
      "Validation Loss: 0.4813\n",
      "Saved the best model with validation loss: 0.4813\n",
      "Epoch [2/100], Loss: 0.4688\n",
      "Validation Loss: 0.4349\n",
      "Saved the best model with validation loss: 0.4349\n",
      "Epoch [3/100], Loss: 0.4366\n",
      "Validation Loss: 0.4106\n",
      "Saved the best model with validation loss: 0.4106\n",
      "Epoch [4/100], Loss: 0.4183\n",
      "Validation Loss: 0.4076\n",
      "Saved the best model with validation loss: 0.4076\n",
      "Epoch [5/100], Loss: 0.4081\n",
      "Validation Loss: 0.3948\n",
      "Saved the best model with validation loss: 0.3948\n",
      "Epoch [6/100], Loss: 0.4009\n",
      "Validation Loss: 0.3934\n",
      "Saved the best model with validation loss: 0.3934\n",
      "Epoch [7/100], Loss: 0.3939\n",
      "Validation Loss: 0.4025\n",
      "Epoch [8/100], Loss: 0.3918\n",
      "Validation Loss: 0.3953\n",
      "Epoch [9/100], Loss: 0.3816\n",
      "Validation Loss: 0.4540\n",
      "Epoch [10/100], Loss: 0.3798\n",
      "Validation Loss: 0.4869\n",
      "Epoch [11/100], Loss: 0.3803\n",
      "Validation Loss: 0.4187\n",
      "Epoch [12/100], Loss: 0.3749\n",
      "Validation Loss: 0.3832\n",
      "Saved the best model with validation loss: 0.3832\n",
      "Epoch [13/100], Loss: 0.3695\n",
      "Validation Loss: 0.3834\n",
      "Epoch [14/100], Loss: 0.3713\n",
      "Validation Loss: 0.4111\n",
      "Epoch [15/100], Loss: 0.3672\n",
      "Validation Loss: 0.5234\n",
      "Epoch [16/100], Loss: 0.3658\n",
      "Validation Loss: 0.6416\n",
      "Epoch [17/100], Loss: 0.3693\n",
      "Validation Loss: 0.3976\n",
      "Epoch [18/100], Loss: 0.3651\n",
      "Validation Loss: 0.3640\n",
      "Saved the best model with validation loss: 0.3640\n",
      "Epoch [19/100], Loss: 0.3627\n",
      "Validation Loss: 0.4392\n",
      "Epoch [20/100], Loss: 0.3587\n",
      "Validation Loss: 0.6487\n",
      "Epoch [21/100], Loss: 0.3635\n",
      "Validation Loss: 0.4514\n",
      "Epoch [22/100], Loss: 0.3620\n",
      "Validation Loss: 0.3754\n",
      "Epoch [23/100], Loss: 0.3570\n",
      "Validation Loss: 0.3720\n",
      "Epoch [24/100], Loss: 0.3575\n",
      "Validation Loss: 0.3656\n",
      "Epoch [25/100], Loss: 0.3562\n",
      "Validation Loss: 0.3743\n",
      "Epoch [26/100], Loss: 0.3539\n",
      "Validation Loss: 0.3707\n",
      "Epoch [27/100], Loss: 0.3494\n",
      "Validation Loss: 0.7326\n",
      "Epoch [28/100], Loss: 0.3597\n",
      "Validation Loss: 0.3926\n",
      "Epoch [29/100], Loss: 0.3538\n",
      "Validation Loss: 0.3594\n",
      "Saved the best model with validation loss: 0.3594\n",
      "Epoch [30/100], Loss: 0.3438\n",
      "Validation Loss: 0.3928\n",
      "Epoch [31/100], Loss: 0.3452\n",
      "Validation Loss: 0.3820\n",
      "Epoch [32/100], Loss: 0.3464\n",
      "Validation Loss: 0.3727\n",
      "Epoch [33/100], Loss: 0.3446\n",
      "Validation Loss: 0.3800\n",
      "Epoch [34/100], Loss: 0.3563\n",
      "Validation Loss: 0.3806\n",
      "Epoch [35/100], Loss: 0.3434\n",
      "Validation Loss: 0.3765\n",
      "Epoch [36/100], Loss: 0.3427\n",
      "Validation Loss: 0.3746\n",
      "Epoch [37/100], Loss: 0.3347\n",
      "Validation Loss: 0.3891\n",
      "Epoch [38/100], Loss: 0.3420\n",
      "Validation Loss: 0.3817\n",
      "Epoch [39/100], Loss: 0.3415\n",
      "Validation Loss: 0.3783\n",
      "Epoch [40/100], Loss: 0.3360\n",
      "Validation Loss: 0.3986\n",
      "Epoch [41/100], Loss: 0.3496\n",
      "Validation Loss: 0.3748\n",
      "Epoch [42/100], Loss: 0.3450\n",
      "Validation Loss: 0.3678\n",
      "Epoch [43/100], Loss: 0.3341\n",
      "Validation Loss: 0.3898\n",
      "Epoch [44/100], Loss: 0.3511\n",
      "Validation Loss: 0.4047\n",
      "Epoch [45/100], Loss: 0.3393\n",
      "Validation Loss: 0.3871\n",
      "Epoch [46/100], Loss: 0.3358\n",
      "Validation Loss: 0.3762\n",
      "Epoch [47/100], Loss: 0.3328\n",
      "Validation Loss: 0.3899\n",
      "Epoch [48/100], Loss: 0.3386\n",
      "Validation Loss: 0.3892\n",
      "Epoch [49/100], Loss: 0.3330\n",
      "Validation Loss: 0.4055\n",
      "Epoch [50/100], Loss: 0.3372\n",
      "Validation Loss: 0.3898\n",
      "Epoch [51/100], Loss: 0.3310\n",
      "Validation Loss: 0.3959\n",
      "Epoch [52/100], Loss: 0.3324\n",
      "Validation Loss: 0.3846\n",
      "Epoch [53/100], Loss: 0.3442\n",
      "Validation Loss: 0.3777\n",
      "Epoch [54/100], Loss: 0.3279\n",
      "Validation Loss: 0.3949\n",
      "Epoch [55/100], Loss: 0.3319\n",
      "Validation Loss: 0.3871\n",
      "Epoch [56/100], Loss: 0.3381\n",
      "Validation Loss: 0.3888\n",
      "Epoch [57/100], Loss: 0.3280\n",
      "Validation Loss: 0.3958\n",
      "Epoch [58/100], Loss: 0.3287\n",
      "Validation Loss: 0.3841\n",
      "Epoch [59/100], Loss: 0.3370\n",
      "Validation Loss: 0.3705\n",
      "Epoch [60/100], Loss: 0.3315\n",
      "Validation Loss: 0.3994\n",
      "Epoch [61/100], Loss: 0.3406\n",
      "Validation Loss: 0.3790\n",
      "Epoch [62/100], Loss: 0.3306\n",
      "Validation Loss: 0.4065\n",
      "Epoch [63/100], Loss: 0.3302\n",
      "Validation Loss: 0.3906\n",
      "Epoch [64/100], Loss: 0.3313\n",
      "Validation Loss: 0.3729\n",
      "Epoch [65/100], Loss: 0.3255\n",
      "Validation Loss: 0.4069\n",
      "Epoch [66/100], Loss: 0.3360\n",
      "Validation Loss: 0.4095\n",
      "Epoch [67/100], Loss: 0.3296\n",
      "Validation Loss: 0.4011\n",
      "Epoch [68/100], Loss: 0.3282\n",
      "Validation Loss: 0.3762\n",
      "Epoch [69/100], Loss: 0.3292\n",
      "Validation Loss: 0.3690\n",
      "Epoch [70/100], Loss: 0.3384\n",
      "Validation Loss: 0.3762\n",
      "Epoch [71/100], Loss: 0.3365\n",
      "Validation Loss: 0.3790\n",
      "Epoch [72/100], Loss: 0.3282\n",
      "Validation Loss: 0.3786\n",
      "Epoch [73/100], Loss: 0.3684\n",
      "Validation Loss: 0.3874\n",
      "Epoch [74/100], Loss: 0.3268\n",
      "Validation Loss: 0.3630\n",
      "Epoch [75/100], Loss: 0.3250\n",
      "Validation Loss: 0.4346\n",
      "Epoch [76/100], Loss: 0.3320\n",
      "Validation Loss: 0.3554\n",
      "Saved the best model with validation loss: 0.3554\n",
      "Epoch [77/100], Loss: 0.3590\n",
      "Validation Loss: 0.4344\n",
      "Epoch [78/100], Loss: 0.3378\n",
      "Validation Loss: 0.3516\n",
      "Saved the best model with validation loss: 0.3516\n",
      "Epoch [79/100], Loss: 0.3423\n",
      "Validation Loss: 0.3679\n",
      "Epoch [80/100], Loss: 0.3252\n",
      "Validation Loss: 0.4065\n",
      "Epoch [81/100], Loss: 0.3418\n",
      "Validation Loss: 0.3636\n",
      "Epoch [82/100], Loss: 0.3306\n",
      "Validation Loss: 0.4064\n",
      "Epoch [83/100], Loss: 0.3316\n",
      "Validation Loss: 0.3869\n",
      "Epoch [84/100], Loss: 0.3359\n",
      "Validation Loss: 0.3765\n",
      "Epoch [85/100], Loss: 0.3245\n",
      "Validation Loss: 0.3867\n",
      "Epoch [86/100], Loss: 0.3307\n",
      "Validation Loss: 0.3670\n",
      "Epoch [87/100], Loss: 0.3389\n",
      "Validation Loss: 0.4165\n",
      "Epoch [88/100], Loss: 0.3435\n",
      "Validation Loss: 0.4189\n",
      "Epoch [89/100], Loss: 0.3310\n",
      "Validation Loss: 0.4215\n",
      "Epoch [90/100], Loss: 0.3344\n",
      "Validation Loss: 0.4199\n",
      "Epoch [91/100], Loss: 0.3283\n",
      "Validation Loss: 0.3988\n",
      "Epoch [92/100], Loss: 0.3408\n",
      "Validation Loss: 0.3855\n",
      "Epoch [93/100], Loss: 0.3343\n",
      "Validation Loss: 0.3612\n",
      "Epoch [94/100], Loss: 0.3280\n",
      "Validation Loss: 0.3922\n",
      "Epoch [95/100], Loss: 0.3379\n",
      "Validation Loss: 0.3678\n",
      "Epoch [96/100], Loss: 0.3550\n",
      "Validation Loss: 0.3585\n",
      "Epoch [97/100], Loss: 0.3304\n",
      "Validation Loss: 0.3797\n",
      "Epoch [98/100], Loss: 0.3362\n",
      "Validation Loss: 0.3716\n",
      "Epoch [99/100], Loss: 0.3457\n",
      "Validation Loss: 0.4525\n",
      "Epoch [100/100], Loss: 0.3355\n",
      "Validation Loss: 2.0087\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"combi: 17-80-50-10/1-16-32-10/20-60-20-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "15257cb7-4057-4bb4-bf95-bb431b9ac53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.800758</td>\n",
       "      <td>0.809452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.814394</td>\n",
       "      <td>0.817704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.832765</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.812879</td>\n",
       "      <td>0.833458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.679181</td>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.684091</td>\n",
       "      <td>0.555139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.533784</td>\n",
       "      <td>0.714773</td>\n",
       "      <td>0.579145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.710606</td>\n",
       "      <td>0.525881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-2</th>\n",
       "      <td>0.720137</td>\n",
       "      <td>0.574324</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-2</th>\n",
       "      <td>0.692833</td>\n",
       "      <td>0.574324</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-2</th>\n",
       "      <td>0.716724</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-2</th>\n",
       "      <td>0.703072</td>\n",
       "      <td>0.614865</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-2</th>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-2</th>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-2</th>\n",
       "      <td>0.706485</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-2</th>\n",
       "      <td>0.774744</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-2</th>\n",
       "      <td>0.754266</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-2</th>\n",
       "      <td>0.706485</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-2</th>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-2</th>\n",
       "      <td>0.730375</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-2</th>\n",
       "      <td>0.774744</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-2</th>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-2</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-2</th>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-2</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-2</th>\n",
       "      <td>0.750853</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-2</th>\n",
       "      <td>0.737201</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-2</th>\n",
       "      <td>0.767918</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-2</th>\n",
       "      <td>0.805461</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-2</th>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-2</th>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-2</th>\n",
       "      <td>0.805461</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-2</th>\n",
       "      <td>0.798635</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-2/1-16-32-2/4-2</th>\n",
       "      <td>0.808874</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-16-32-5/10-2</th>\n",
       "      <td>0.802048</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-16-32-5/10-20-2</th>\n",
       "      <td>0.829352</td>\n",
       "      <td>0.817568</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-16-32-10/20-40-2</th>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-16-32-10/20-60-20-2</th>\n",
       "      <td>0.839590</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               acc       rec       acc  \\\n",
       "5-NN                                      0.829352  0.824324  0.800758   \n",
       "Decision tree                             0.836177  0.797297  0.814394   \n",
       "Random forest                             0.832765  0.831081  0.812879   \n",
       "SVM linear                                0.679181  0.506757  0.684091   \n",
       "SVM poly                                  0.696246  0.533784  0.714773   \n",
       "SVM rbf                                   0.713311  0.513514  0.710606   \n",
       "MLP: 17-5-2                               0.720137  0.574324         -   \n",
       "MLP: 17-10-2                              0.692833  0.574324         -   \n",
       "MLP: 17-20-2                              0.716724  0.587838         -   \n",
       "MLP: 17-25-2                              0.703072  0.614865         -   \n",
       "MLP: 17-40-2                              0.696246  0.608108         -   \n",
       "MLP: 17-60-2                              0.713311  0.655405         -   \n",
       "MLP: 17-10-5-2                            0.706485  0.641892         -   \n",
       "MLP: 17-20-10-2                           0.774744  0.797297         -   \n",
       "MLP: 17-40-20-2                           0.754266  0.729730         -   \n",
       "MLP: 17-40-10-2                           0.706485  0.513514         -   \n",
       "MLP: 17-60-40-2                           0.767918  0.695946         -   \n",
       "MLP: 17-60-20-2                           0.730375  0.641892         -   \n",
       "MLP: 17-80-50-2                           0.774744  0.702703         -   \n",
       "MLP, small-median: 7-80-50-2              0.767918  0.702703         -   \n",
       "MLP, small-mean: 7-80-50-2                0.744027  0.655405         -   \n",
       "MLP, small-min: 7-80-50-2                 0.737201  0.689189         -   \n",
       "MLP, small-max: 7-80-50-2                 0.744027  0.709459         -   \n",
       "MLP, small-q25: 7-80-50-2                 0.750853  0.662162         -   \n",
       "MLP, small-q75: 7-80-50-2                 0.737201  0.655405         -   \n",
       "MLP, custom: 7-80-50-2                    0.767918  0.743243         -   \n",
       "HGNN: 1-16-32-2                           0.805461  0.783784         -   \n",
       "HGNN: 1-32-16-2                           0.798635  0.783784         -   \n",
       "HGNN: 1-16-32-16-2                        0.798635  0.783784         -   \n",
       "HGNN: 1-32-64-2                           0.805461  0.770270         -   \n",
       "HGNN: 1-4-16-2                            0.798635  0.783784         -   \n",
       "combi: 17-80-50-2/1-16-32-2/4-2           0.808874  0.824324         -   \n",
       "combi: 17-80-50-5/1-16-32-5/10-2          0.802048  0.810811         -   \n",
       "combi: 17-80-50-5/1-16-32-5/10-20-2       0.829352  0.817568         -   \n",
       "combi: 17-80-50-10/1-16-32-10/20-40-2     0.822526  0.797297         -   \n",
       "combi: 17-80-50-10/1-16-32-10/20-60-20-2  0.839590  0.831081         -   \n",
       "\n",
       "                                               rec  \n",
       "5-NN                                      0.809452  \n",
       "Decision tree                             0.817704  \n",
       "Random forest                             0.833458  \n",
       "SVM linear                                0.555139  \n",
       "SVM poly                                  0.579145  \n",
       "SVM rbf                                   0.525881  \n",
       "MLP: 17-5-2                                      -  \n",
       "MLP: 17-10-2                                     -  \n",
       "MLP: 17-20-2                                     -  \n",
       "MLP: 17-25-2                                     -  \n",
       "MLP: 17-40-2                                     -  \n",
       "MLP: 17-60-2                                     -  \n",
       "MLP: 17-10-5-2                                   -  \n",
       "MLP: 17-20-10-2                                  -  \n",
       "MLP: 17-40-20-2                                  -  \n",
       "MLP: 17-40-10-2                                  -  \n",
       "MLP: 17-60-40-2                                  -  \n",
       "MLP: 17-60-20-2                                  -  \n",
       "MLP: 17-80-50-2                                  -  \n",
       "MLP, small-median: 7-80-50-2                     -  \n",
       "MLP, small-mean: 7-80-50-2                       -  \n",
       "MLP, small-min: 7-80-50-2                        -  \n",
       "MLP, small-max: 7-80-50-2                        -  \n",
       "MLP, small-q25: 7-80-50-2                        -  \n",
       "MLP, small-q75: 7-80-50-2                        -  \n",
       "MLP, custom: 7-80-50-2                           -  \n",
       "HGNN: 1-16-32-2                                  -  \n",
       "HGNN: 1-32-16-2                                  -  \n",
       "HGNN: 1-16-32-16-2                               -  \n",
       "HGNN: 1-32-64-2                                  -  \n",
       "HGNN: 1-4-16-2                                   -  \n",
       "combi: 17-80-50-2/1-16-32-2/4-2                  -  \n",
       "combi: 17-80-50-5/1-16-32-5/10-2                 -  \n",
       "combi: 17-80-50-5/1-16-32-5/10-20-2              -  \n",
       "combi: 17-80-50-10/1-16-32-10/20-40-2            -  \n",
       "combi: 17-80-50-10/1-16-32-10/20-60-20-2         -  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9c6ca5bf-8483-47e6-bb63-e68cdfe093df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2237103/692307941.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  table_2_classes = table_2_classes.applymap(round_if_number)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.8294</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.8008</td>\n",
       "      <td>0.8095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.8362</td>\n",
       "      <td>0.7973</td>\n",
       "      <td>0.8144</td>\n",
       "      <td>0.8177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>0.8335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.6792</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.6841</td>\n",
       "      <td>0.5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.6962</td>\n",
       "      <td>0.5338</td>\n",
       "      <td>0.7148</td>\n",
       "      <td>0.5791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.5135</td>\n",
       "      <td>0.7106</td>\n",
       "      <td>0.5259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-2</th>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-2</th>\n",
       "      <td>0.6928</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-2</th>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.5878</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-2</th>\n",
       "      <td>0.7031</td>\n",
       "      <td>0.6149</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-2</th>\n",
       "      <td>0.6962</td>\n",
       "      <td>0.6081</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-2</th>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-2</th>\n",
       "      <td>0.7065</td>\n",
       "      <td>0.6419</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-2</th>\n",
       "      <td>0.7747</td>\n",
       "      <td>0.7973</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-2</th>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-2</th>\n",
       "      <td>0.7065</td>\n",
       "      <td>0.5135</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-2</th>\n",
       "      <td>0.7679</td>\n",
       "      <td>0.6959</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-2</th>\n",
       "      <td>0.7304</td>\n",
       "      <td>0.6419</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-2</th>\n",
       "      <td>0.7747</td>\n",
       "      <td>0.7027</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-2</th>\n",
       "      <td>0.7679</td>\n",
       "      <td>0.7027</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-2</th>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-2</th>\n",
       "      <td>0.7372</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-2</th>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-2</th>\n",
       "      <td>0.7509</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-2</th>\n",
       "      <td>0.7372</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-2</th>\n",
       "      <td>0.7679</td>\n",
       "      <td>0.7432</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-2</th>\n",
       "      <td>0.8055</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-2</th>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-2</th>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-2</th>\n",
       "      <td>0.8055</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-2</th>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-2/1-16-32-2/4-2</th>\n",
       "      <td>0.8089</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-16-32-5/10-2</th>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-16-32-5/10-20-2</th>\n",
       "      <td>0.8294</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-16-32-10/20-40-2</th>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.7973</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-16-32-10/20-60-20-2</th>\n",
       "      <td>0.8396</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             acc     rec     acc     rec\n",
       "5-NN                                      0.8294  0.8243  0.8008  0.8095\n",
       "Decision tree                             0.8362  0.7973  0.8144  0.8177\n",
       "Random forest                             0.8328  0.8311  0.8129  0.8335\n",
       "SVM linear                                0.6792  0.5068  0.6841  0.5551\n",
       "SVM poly                                  0.6962  0.5338  0.7148  0.5791\n",
       "SVM rbf                                   0.7133  0.5135  0.7106  0.5259\n",
       "MLP: 17-5-2                               0.7201  0.5743       -       -\n",
       "MLP: 17-10-2                              0.6928  0.5743       -       -\n",
       "MLP: 17-20-2                              0.7167  0.5878       -       -\n",
       "MLP: 17-25-2                              0.7031  0.6149       -       -\n",
       "MLP: 17-40-2                              0.6962  0.6081       -       -\n",
       "MLP: 17-60-2                              0.7133  0.6554       -       -\n",
       "MLP: 17-10-5-2                            0.7065  0.6419       -       -\n",
       "MLP: 17-20-10-2                           0.7747  0.7973       -       -\n",
       "MLP: 17-40-20-2                           0.7543  0.7297       -       -\n",
       "MLP: 17-40-10-2                           0.7065  0.5135       -       -\n",
       "MLP: 17-60-40-2                           0.7679  0.6959       -       -\n",
       "MLP: 17-60-20-2                           0.7304  0.6419       -       -\n",
       "MLP: 17-80-50-2                           0.7747  0.7027       -       -\n",
       "MLP, small-median: 7-80-50-2              0.7679  0.7027       -       -\n",
       "MLP, small-mean: 7-80-50-2                0.7440  0.6554       -       -\n",
       "MLP, small-min: 7-80-50-2                 0.7372  0.6892       -       -\n",
       "MLP, small-max: 7-80-50-2                 0.7440  0.7095       -       -\n",
       "MLP, small-q25: 7-80-50-2                 0.7509  0.6622       -       -\n",
       "MLP, small-q75: 7-80-50-2                 0.7372  0.6554       -       -\n",
       "MLP, custom: 7-80-50-2                    0.7679  0.7432       -       -\n",
       "HGNN: 1-16-32-2                           0.8055  0.7838       -       -\n",
       "HGNN: 1-32-16-2                           0.7986  0.7838       -       -\n",
       "HGNN: 1-16-32-16-2                        0.7986  0.7838       -       -\n",
       "HGNN: 1-32-64-2                           0.8055  0.7703       -       -\n",
       "HGNN: 1-4-16-2                            0.7986  0.7838       -       -\n",
       "combi: 17-80-50-2/1-16-32-2/4-2           0.8089  0.8243       -       -\n",
       "combi: 17-80-50-5/1-16-32-5/10-2          0.8020  0.8108       -       -\n",
       "combi: 17-80-50-5/1-16-32-5/10-20-2       0.8294  0.8176       -       -\n",
       "combi: 17-80-50-10/1-16-32-10/20-40-2     0.8225  0.7973       -       -\n",
       "combi: 17-80-50-10/1-16-32-10/20-60-20-2  0.8396  0.8311       -       -"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def round_if_number(x):\n",
    "    try:\n",
    "        return round(float(x), 4)\n",
    "    except ValueError:\n",
    "        return x\n",
    "\n",
    "table_2_classes = table_2_classes.applymap(round_if_number)\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "a21a0a91-ab84-421f-81b2-1a92c6b539e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2_classes.to_csv('results/table_2_classes_SPA_rounded.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80cd325",
   "metadata": {},
   "source": [
    "### Combined HGNN with three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd1a2f",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 1, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  MLP 17-80-50-3\n",
    "*  HGNN 1-4-16-3\n",
    "*  Combined 6-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(6, 3)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef380f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"combi 0.5: 17-80-50-3/1-4-16-3/6-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea4ad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"combi 0.1: 17-80-50-3/1-4-16-3/6-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb4d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"combi 0.05: 17-80-50-3/1-4-16-3/6-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14721ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"combi 0.01: 17-80-50-3/1-4-16-3/6-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352815a",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 2, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  MLP 17-80-50-5\n",
    "*  HGNN 1-4-16-5\n",
    "*  Combined 10-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c43284",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(10, 3)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a27e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"combi 0.5: 17-80-50-5/1-4-16-5/10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d63488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"combi 0.1: 17-80-50-5/1-4-16-5/10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b081dff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"combi 0.05: 17-80-50-5/1-4-16-5/10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d033f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"combi 0.01: 17-80-50-5/1-4-16-5/10-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6353b02e",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 3, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  MLP 17-80-50-5\n",
    "*  HGNN 1-4-16-5\n",
    "*  Combined 10-20-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d95cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a7359f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"combi 0.5: 17-80-50-5/1-4-16-5/10-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff275836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"combi 0.1: 17-80-50-5/1-4-16-5/10-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d569b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"combi 0.05: 17-80-50-5/1-4-16-5/10-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5f13b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"combi 0.01: 17-80-50-5/1-4-16-5/10-20-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88943826",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 4, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  MLP 17-80-50-10\n",
    "*  HGNN 1-4-16-10\n",
    "*  Combined 20-40-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac88ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195dcb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"combi 0.5: 17-80-50-10/1-4-16-10/20-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f1bfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"combi 0.1: 17-80-50-10/1-4-16-10/20-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9fee6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"combi 0.05: 17-80-50-10/1-4-16-10/20-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8882651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"combi 0.01: 17-80-50-10/1-4-16-10/20-40-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca99a07",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 5, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  MLP 17-80-50-10\n",
    "*  HGNN 1-4-16-10\n",
    "*  Combined 20-60-20-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06788c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b91d1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"combi 0.5: 17-80-50-10/1-4-16-10/20-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00679a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"combi 0.1: 17-80-50-10/1-4-16-10/20-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd9386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"combi 0.05: 17-80-50-10/1-4-16-10/20-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1702e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"combi 0.01: 17-80-50-10/1-4-16-10/20-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd574071-eb53-44eb-bf52-c92b7eda7175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_if_number(x):\n",
    "    try:\n",
    "        return round(float(x), 4)\n",
    "    except ValueError:\n",
    "        return x\n",
    "\n",
    "table_3_classes = table_3_classes.applymap(round_if_number)\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23ecec-bf12-4021-a8d9-8dee0411dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes.to_csv('results/table_3_classes_SPA_rounded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b86c9-50da-4715-9643-c508df55ce90",
   "metadata": {},
   "source": [
    "Save the tables of each cut off seperately, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f565165-abb6-48f6-ac35-aa00db55a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes[::4].to_csv(\"results/table_3_classes_05_SPA_rounded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313741f-ba1c-4537-9932-b6be32a6e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes[1::4].to_csv(\"results/table_3_classes_01_SPA_rounded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d985f-8bec-447c-804d-a257ade21189",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes[2::4].to_csv(\"results/table_3_classes_005_SPA_rounded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d31728-15be-4cd3-b3d3-0025626dcefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes[3::4].to_csv(\"results/table_3_classes_001_SPA_rounded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e1b57a-f307-4ce1-bc33-dee8d4910fba",
   "metadata": {},
   "source": [
    "### Combined HGNN for time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "239fda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, label_series, hypergraph_column_name):\n",
    "        # Extract features and convert to tensor\n",
    "        self.X = torch.from_numpy(dataframe.drop(columns=[hypergraph_column_name]).values).float()\n",
    "        \n",
    "        # Extract labels and convert to tensor\n",
    "        self.y = torch.from_numpy(label_series.values).float()\n",
    "        \n",
    "        # Store hypergraph objects\n",
    "        self.hypergraphs = dataframe[hypergraph_column_name].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.X[index],\n",
    "            'label': self.y[index],\n",
    "            'hypergraph': self.hypergraphs[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "5de8de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_regression(X_training, y_training, X_validation, y_validation, text):\n",
    "    model = CombinedNetwork(random_seed = 20)  \n",
    "\n",
    "    dataset = CustomDataset(X_training, y_training, hypergraph_column_name='hypergraph')\n",
    "    validation = CustomDataset(X_validation, y_validation, hypergraph_column_name='hypergraph')\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for item in dataset:\n",
    "            optimizer.zero_grad()\n",
    "            input_features = item[\"data\"]\n",
    "            input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "            label = item[\"label\"].float().unsqueeze(0)\n",
    "            #print(label.size())\n",
    "            output = model(input_features, input_hg)\n",
    "\n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataset):.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for item in validation:\n",
    "                input_features = item[\"data\"]\n",
    "                input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "                label = item[\"label\"].float().unsqueeze(0)\n",
    "                output = model(input_features, input_hg)\n",
    "                loss = loss_function(output, label)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(validation)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Save the model if the validation loss is the best we've seen so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Saved the best model with validation loss: {val_loss:.4f}')\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for item in validation:\n",
    "            i += 1\n",
    "            output = model(item[\"data\"], item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0))\n",
    "            predicted.append(output.item())\n",
    "\n",
    "    mse = mean_squared_error(y_validation, predicted)\n",
    "    mae = mean_absolute_error(y_validation, predicted)\n",
    "    r2 = r2_score(y_validation, predicted)\n",
    "    \n",
    "    table_time_diff.loc[text] = [mse, mae, r2, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec22f9",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 1\n",
    "*  MLP 17-80-50-2\n",
    "*  HGNN 1-32-64-2\n",
    "*  Combined 4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "a7aeafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(4, 1)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "486ba98b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.5226\n",
      "Validation Loss: 0.9599\n",
      "Saved the best model with validation loss: 0.9599\n",
      "Epoch [2/100], Loss: 0.8978\n",
      "Validation Loss: 0.8713\n",
      "Saved the best model with validation loss: 0.8713\n",
      "Epoch [3/100], Loss: 0.8033\n",
      "Validation Loss: 0.8002\n",
      "Saved the best model with validation loss: 0.8002\n",
      "Epoch [4/100], Loss: 0.7513\n",
      "Validation Loss: 0.7692\n",
      "Saved the best model with validation loss: 0.7692\n",
      "Epoch [5/100], Loss: 0.7197\n",
      "Validation Loss: 0.7435\n",
      "Saved the best model with validation loss: 0.7435\n",
      "Epoch [6/100], Loss: 0.6955\n",
      "Validation Loss: 0.7169\n",
      "Saved the best model with validation loss: 0.7169\n",
      "Epoch [7/100], Loss: 0.6710\n",
      "Validation Loss: 0.6999\n",
      "Saved the best model with validation loss: 0.6999\n",
      "Epoch [8/100], Loss: 0.6532\n",
      "Validation Loss: 0.6825\n",
      "Saved the best model with validation loss: 0.6825\n",
      "Epoch [9/100], Loss: 0.6383\n",
      "Validation Loss: 0.6693\n",
      "Saved the best model with validation loss: 0.6693\n",
      "Epoch [10/100], Loss: 0.6270\n",
      "Validation Loss: 0.6616\n",
      "Saved the best model with validation loss: 0.6616\n",
      "Epoch [11/100], Loss: 0.6214\n",
      "Validation Loss: 0.6613\n",
      "Saved the best model with validation loss: 0.6613\n",
      "Epoch [12/100], Loss: 0.6109\n",
      "Validation Loss: 0.6450\n",
      "Saved the best model with validation loss: 0.6450\n",
      "Epoch [13/100], Loss: 0.6036\n",
      "Validation Loss: 0.6411\n",
      "Saved the best model with validation loss: 0.6411\n",
      "Epoch [14/100], Loss: 0.5990\n",
      "Validation Loss: 0.6338\n",
      "Saved the best model with validation loss: 0.6338\n",
      "Epoch [15/100], Loss: 0.5919\n",
      "Validation Loss: 0.6373\n",
      "Epoch [16/100], Loss: 0.5872\n",
      "Validation Loss: 0.6366\n",
      "Epoch [17/100], Loss: 0.5832\n",
      "Validation Loss: 0.6294\n",
      "Saved the best model with validation loss: 0.6294\n",
      "Epoch [18/100], Loss: 0.5803\n",
      "Validation Loss: 0.6233\n",
      "Saved the best model with validation loss: 0.6233\n",
      "Epoch [19/100], Loss: 0.5749\n",
      "Validation Loss: 0.6377\n",
      "Epoch [20/100], Loss: 0.5726\n",
      "Validation Loss: 0.6207\n",
      "Saved the best model with validation loss: 0.6207\n",
      "Epoch [21/100], Loss: 0.5706\n",
      "Validation Loss: 0.6113\n",
      "Saved the best model with validation loss: 0.6113\n",
      "Epoch [22/100], Loss: 0.5677\n",
      "Validation Loss: 0.6140\n",
      "Epoch [23/100], Loss: 0.5624\n",
      "Validation Loss: 0.6215\n",
      "Epoch [24/100], Loss: 0.5597\n",
      "Validation Loss: 0.6213\n",
      "Epoch [25/100], Loss: 0.5578\n",
      "Validation Loss: 0.6115\n",
      "Epoch [26/100], Loss: 0.5547\n",
      "Validation Loss: 0.6130\n",
      "Epoch [27/100], Loss: 0.5537\n",
      "Validation Loss: 0.6126\n",
      "Epoch [28/100], Loss: 0.5491\n",
      "Validation Loss: 0.6094\n",
      "Saved the best model with validation loss: 0.6094\n",
      "Epoch [29/100], Loss: 0.5504\n",
      "Validation Loss: 0.5990\n",
      "Saved the best model with validation loss: 0.5990\n",
      "Epoch [30/100], Loss: 0.5464\n",
      "Validation Loss: 0.6017\n",
      "Epoch [31/100], Loss: 0.5431\n",
      "Validation Loss: 0.5990\n",
      "Saved the best model with validation loss: 0.5990\n",
      "Epoch [32/100], Loss: 0.5392\n",
      "Validation Loss: 0.6034\n",
      "Epoch [33/100], Loss: 0.5387\n",
      "Validation Loss: 0.5961\n",
      "Saved the best model with validation loss: 0.5961\n",
      "Epoch [34/100], Loss: 0.5361\n",
      "Validation Loss: 0.5909\n",
      "Saved the best model with validation loss: 0.5909\n",
      "Epoch [35/100], Loss: 0.5343\n",
      "Validation Loss: 0.5899\n",
      "Saved the best model with validation loss: 0.5899\n",
      "Epoch [36/100], Loss: 0.5338\n",
      "Validation Loss: 0.5898\n",
      "Saved the best model with validation loss: 0.5898\n",
      "Epoch [37/100], Loss: 0.5297\n",
      "Validation Loss: 0.5897\n",
      "Saved the best model with validation loss: 0.5897\n",
      "Epoch [38/100], Loss: 0.5270\n",
      "Validation Loss: 0.5829\n",
      "Saved the best model with validation loss: 0.5829\n",
      "Epoch [39/100], Loss: 0.5258\n",
      "Validation Loss: 0.5827\n",
      "Saved the best model with validation loss: 0.5827\n",
      "Epoch [40/100], Loss: 0.5250\n",
      "Validation Loss: 0.5833\n",
      "Epoch [41/100], Loss: 0.5229\n",
      "Validation Loss: 0.5852\n",
      "Epoch [42/100], Loss: 0.5207\n",
      "Validation Loss: 0.5939\n",
      "Epoch [43/100], Loss: 0.5198\n",
      "Validation Loss: 0.5866\n",
      "Epoch [44/100], Loss: 0.5189\n",
      "Validation Loss: 0.5814\n",
      "Saved the best model with validation loss: 0.5814\n",
      "Epoch [45/100], Loss: 0.5184\n",
      "Validation Loss: 0.5916\n",
      "Epoch [46/100], Loss: 0.5198\n",
      "Validation Loss: 0.5781\n",
      "Saved the best model with validation loss: 0.5781\n",
      "Epoch [47/100], Loss: 0.5152\n",
      "Validation Loss: 0.5886\n",
      "Epoch [48/100], Loss: 0.5162\n",
      "Validation Loss: 0.5855\n",
      "Epoch [49/100], Loss: 0.5133\n",
      "Validation Loss: 0.5882\n",
      "Epoch [50/100], Loss: 0.5132\n",
      "Validation Loss: 0.5841\n",
      "Epoch [51/100], Loss: 0.5101\n",
      "Validation Loss: 0.5810\n",
      "Epoch [52/100], Loss: 0.5098\n",
      "Validation Loss: 0.5744\n",
      "Saved the best model with validation loss: 0.5744\n",
      "Epoch [53/100], Loss: 0.5083\n",
      "Validation Loss: 0.5785\n",
      "Epoch [54/100], Loss: 0.5044\n",
      "Validation Loss: 0.5773\n",
      "Epoch [55/100], Loss: 0.5055\n",
      "Validation Loss: 0.5792\n",
      "Epoch [56/100], Loss: 0.5072\n",
      "Validation Loss: 0.5699\n",
      "Saved the best model with validation loss: 0.5699\n",
      "Epoch [57/100], Loss: 0.5028\n",
      "Validation Loss: 0.5792\n",
      "Epoch [58/100], Loss: 0.5026\n",
      "Validation Loss: 0.5701\n",
      "Epoch [59/100], Loss: 0.5067\n",
      "Validation Loss: 0.5757\n",
      "Epoch [60/100], Loss: 0.5037\n",
      "Validation Loss: 0.5762\n",
      "Epoch [61/100], Loss: 0.5017\n",
      "Validation Loss: 0.5796\n",
      "Epoch [62/100], Loss: 0.5005\n",
      "Validation Loss: 0.5718\n",
      "Epoch [63/100], Loss: 0.4994\n",
      "Validation Loss: 0.5820\n",
      "Epoch [64/100], Loss: 0.4989\n",
      "Validation Loss: 0.5623\n",
      "Saved the best model with validation loss: 0.5623\n",
      "Epoch [65/100], Loss: 0.4970\n",
      "Validation Loss: 0.5691\n",
      "Epoch [66/100], Loss: 0.4980\n",
      "Validation Loss: 0.5690\n",
      "Epoch [67/100], Loss: 0.4981\n",
      "Validation Loss: 0.5583\n",
      "Saved the best model with validation loss: 0.5583\n",
      "Epoch [68/100], Loss: 0.4950\n",
      "Validation Loss: 0.5624\n",
      "Epoch [69/100], Loss: 0.4954\n",
      "Validation Loss: 0.5714\n",
      "Epoch [70/100], Loss: 0.4947\n",
      "Validation Loss: 0.5652\n",
      "Epoch [71/100], Loss: 0.4925\n",
      "Validation Loss: 0.5588\n",
      "Epoch [72/100], Loss: 0.4902\n",
      "Validation Loss: 0.5640\n",
      "Epoch [73/100], Loss: 0.4925\n",
      "Validation Loss: 0.5671\n",
      "Epoch [74/100], Loss: 0.4890\n",
      "Validation Loss: 0.5664\n",
      "Epoch [75/100], Loss: 0.4900\n",
      "Validation Loss: 0.5635\n",
      "Epoch [76/100], Loss: 0.4901\n",
      "Validation Loss: 0.5598\n",
      "Epoch [77/100], Loss: 0.4866\n",
      "Validation Loss: 0.5661\n",
      "Epoch [78/100], Loss: 0.4882\n",
      "Validation Loss: 0.5584\n",
      "Epoch [79/100], Loss: 0.4900\n",
      "Validation Loss: 0.5625\n",
      "Epoch [80/100], Loss: 0.4877\n",
      "Validation Loss: 0.5604\n",
      "Epoch [81/100], Loss: 0.4852\n",
      "Validation Loss: 0.5591\n",
      "Epoch [82/100], Loss: 0.4875\n",
      "Validation Loss: 0.5640\n",
      "Epoch [83/100], Loss: 0.4881\n",
      "Validation Loss: 0.5575\n",
      "Saved the best model with validation loss: 0.5575\n",
      "Epoch [84/100], Loss: 0.4887\n",
      "Validation Loss: 0.5690\n",
      "Epoch [85/100], Loss: 0.4882\n",
      "Validation Loss: 0.5577\n",
      "Epoch [86/100], Loss: 0.4867\n",
      "Validation Loss: 0.5640\n",
      "Epoch [87/100], Loss: 0.4882\n",
      "Validation Loss: 0.5639\n",
      "Epoch [88/100], Loss: 0.4864\n",
      "Validation Loss: 0.5639\n",
      "Epoch [89/100], Loss: 0.4870\n",
      "Validation Loss: 0.5587\n",
      "Epoch [90/100], Loss: 0.4855\n",
      "Validation Loss: 0.5653\n",
      "Epoch [91/100], Loss: 0.4904\n",
      "Validation Loss: 0.5591\n",
      "Epoch [92/100], Loss: 0.4812\n",
      "Validation Loss: 0.5559\n",
      "Saved the best model with validation loss: 0.5559\n",
      "Epoch [93/100], Loss: 0.4819\n",
      "Validation Loss: 0.5636\n",
      "Epoch [94/100], Loss: 0.4846\n",
      "Validation Loss: 0.5557\n",
      "Saved the best model with validation loss: 0.5557\n",
      "Epoch [95/100], Loss: 0.4824\n",
      "Validation Loss: 0.5578\n",
      "Epoch [96/100], Loss: 0.4819\n",
      "Validation Loss: 0.5570\n",
      "Epoch [97/100], Loss: 0.4818\n",
      "Validation Loss: 0.5615\n",
      "Epoch [98/100], Loss: 0.4818\n",
      "Validation Loss: 0.5688\n",
      "Epoch [99/100], Loss: 0.4813\n",
      "Validation Loss: 0.5679\n",
      "Epoch [100/100], Loss: 0.4798\n",
      "Validation Loss: 0.5673\n"
     ]
    }
   ],
   "source": [
    "combined_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"combi: 17-80-50-2/1-32-64-2/4-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f134e",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 2\n",
    "*  MLP 17-80-50-5\n",
    "*  HGNN 1-32-64-5\n",
    "*  Combined 10-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "19e2002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "f7b4de78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.5028\n",
      "Validation Loss: 1.0027\n",
      "Saved the best model with validation loss: 1.0027\n",
      "Epoch [2/100], Loss: 0.9064\n",
      "Validation Loss: 0.8646\n",
      "Saved the best model with validation loss: 0.8646\n",
      "Epoch [3/100], Loss: 0.8049\n",
      "Validation Loss: 0.8068\n",
      "Saved the best model with validation loss: 0.8068\n",
      "Epoch [4/100], Loss: 0.7541\n",
      "Validation Loss: 0.7706\n",
      "Saved the best model with validation loss: 0.7706\n",
      "Epoch [5/100], Loss: 0.7216\n",
      "Validation Loss: 0.7414\n",
      "Saved the best model with validation loss: 0.7414\n",
      "Epoch [6/100], Loss: 0.6965\n",
      "Validation Loss: 0.7251\n",
      "Saved the best model with validation loss: 0.7251\n",
      "Epoch [7/100], Loss: 0.6782\n",
      "Validation Loss: 0.7111\n",
      "Saved the best model with validation loss: 0.7111\n",
      "Epoch [8/100], Loss: 0.6606\n",
      "Validation Loss: 0.7008\n",
      "Saved the best model with validation loss: 0.7008\n",
      "Epoch [9/100], Loss: 0.6465\n",
      "Validation Loss: 0.6856\n",
      "Saved the best model with validation loss: 0.6856\n",
      "Epoch [10/100], Loss: 0.6389\n",
      "Validation Loss: 0.6862\n",
      "Epoch [11/100], Loss: 0.6285\n",
      "Validation Loss: 0.6749\n",
      "Saved the best model with validation loss: 0.6749\n",
      "Epoch [12/100], Loss: 0.6211\n",
      "Validation Loss: 0.6638\n",
      "Saved the best model with validation loss: 0.6638\n",
      "Epoch [13/100], Loss: 0.6125\n",
      "Validation Loss: 0.6600\n",
      "Saved the best model with validation loss: 0.6600\n",
      "Epoch [14/100], Loss: 0.6086\n",
      "Validation Loss: 0.6508\n",
      "Saved the best model with validation loss: 0.6508\n",
      "Epoch [15/100], Loss: 0.6024\n",
      "Validation Loss: 0.6454\n",
      "Saved the best model with validation loss: 0.6454\n",
      "Epoch [16/100], Loss: 0.5961\n",
      "Validation Loss: 0.6393\n",
      "Saved the best model with validation loss: 0.6393\n",
      "Epoch [17/100], Loss: 0.5909\n",
      "Validation Loss: 0.6428\n",
      "Epoch [18/100], Loss: 0.5879\n",
      "Validation Loss: 0.6414\n",
      "Epoch [19/100], Loss: 0.5825\n",
      "Validation Loss: 0.6324\n",
      "Saved the best model with validation loss: 0.6324\n",
      "Epoch [20/100], Loss: 0.5784\n",
      "Validation Loss: 0.6350\n",
      "Epoch [21/100], Loss: 0.5751\n",
      "Validation Loss: 0.6249\n",
      "Saved the best model with validation loss: 0.6249\n",
      "Epoch [22/100], Loss: 0.5722\n",
      "Validation Loss: 0.6302\n",
      "Epoch [23/100], Loss: 0.5681\n",
      "Validation Loss: 0.6271\n",
      "Epoch [24/100], Loss: 0.5643\n",
      "Validation Loss: 0.6280\n",
      "Epoch [25/100], Loss: 0.5614\n",
      "Validation Loss: 0.6174\n",
      "Saved the best model with validation loss: 0.6174\n",
      "Epoch [26/100], Loss: 0.5559\n",
      "Validation Loss: 0.6209\n",
      "Epoch [27/100], Loss: 0.5568\n",
      "Validation Loss: 0.6236\n",
      "Epoch [28/100], Loss: 0.5517\n",
      "Validation Loss: 0.6113\n",
      "Saved the best model with validation loss: 0.6113\n",
      "Epoch [29/100], Loss: 0.5487\n",
      "Validation Loss: 0.6235\n",
      "Epoch [30/100], Loss: 0.5523\n",
      "Validation Loss: 0.6143\n",
      "Epoch [31/100], Loss: 0.5492\n",
      "Validation Loss: 0.6120\n",
      "Epoch [32/100], Loss: 0.5472\n",
      "Validation Loss: 0.6087\n",
      "Saved the best model with validation loss: 0.6087\n",
      "Epoch [33/100], Loss: 0.5427\n",
      "Validation Loss: 0.6118\n",
      "Epoch [34/100], Loss: 0.5417\n",
      "Validation Loss: 0.6268\n",
      "Epoch [35/100], Loss: 0.5390\n",
      "Validation Loss: 0.6030\n",
      "Saved the best model with validation loss: 0.6030\n",
      "Epoch [36/100], Loss: 0.5380\n",
      "Validation Loss: 0.6006\n",
      "Saved the best model with validation loss: 0.6006\n",
      "Epoch [37/100], Loss: 0.5367\n",
      "Validation Loss: 0.5941\n",
      "Saved the best model with validation loss: 0.5941\n",
      "Epoch [38/100], Loss: 0.5342\n",
      "Validation Loss: 0.6002\n",
      "Epoch [39/100], Loss: 0.5359\n",
      "Validation Loss: 0.5869\n",
      "Saved the best model with validation loss: 0.5869\n",
      "Epoch [40/100], Loss: 0.5324\n",
      "Validation Loss: 0.5899\n",
      "Epoch [41/100], Loss: 0.5311\n",
      "Validation Loss: 0.5908\n",
      "Epoch [42/100], Loss: 0.5266\n",
      "Validation Loss: 0.5900\n",
      "Epoch [43/100], Loss: 0.5259\n",
      "Validation Loss: 0.5954\n",
      "Epoch [44/100], Loss: 0.5260\n",
      "Validation Loss: 0.5915\n",
      "Epoch [45/100], Loss: 0.5232\n",
      "Validation Loss: 0.5764\n",
      "Saved the best model with validation loss: 0.5764\n",
      "Epoch [46/100], Loss: 0.5240\n",
      "Validation Loss: 0.6074\n",
      "Epoch [47/100], Loss: 0.5211\n",
      "Validation Loss: 0.5863\n",
      "Epoch [48/100], Loss: 0.5195\n",
      "Validation Loss: 0.5895\n",
      "Epoch [49/100], Loss: 0.5179\n",
      "Validation Loss: 0.5795\n",
      "Epoch [50/100], Loss: 0.5145\n",
      "Validation Loss: 0.5795\n",
      "Epoch [51/100], Loss: 0.5135\n",
      "Validation Loss: 0.5723\n",
      "Saved the best model with validation loss: 0.5723\n",
      "Epoch [52/100], Loss: 0.5143\n",
      "Validation Loss: 0.5760\n",
      "Epoch [53/100], Loss: 0.5120\n",
      "Validation Loss: 0.5967\n",
      "Epoch [54/100], Loss: 0.5132\n",
      "Validation Loss: 0.5794\n",
      "Epoch [55/100], Loss: 0.5061\n",
      "Validation Loss: 0.5922\n",
      "Epoch [56/100], Loss: 0.5056\n",
      "Validation Loss: 0.5933\n",
      "Epoch [57/100], Loss: 0.5034\n",
      "Validation Loss: 0.6045\n",
      "Epoch [58/100], Loss: 0.5051\n",
      "Validation Loss: 0.6001\n",
      "Epoch [59/100], Loss: 0.5024\n",
      "Validation Loss: 0.5856\n",
      "Epoch [60/100], Loss: 0.5021\n",
      "Validation Loss: 0.5920\n",
      "Epoch [61/100], Loss: 0.5032\n",
      "Validation Loss: 0.5792\n",
      "Epoch [62/100], Loss: 0.5040\n",
      "Validation Loss: 0.5745\n",
      "Epoch [63/100], Loss: 0.5058\n",
      "Validation Loss: 0.5772\n",
      "Epoch [64/100], Loss: 0.5014\n",
      "Validation Loss: 0.5846\n",
      "Epoch [65/100], Loss: 0.5012\n",
      "Validation Loss: 0.5833\n",
      "Epoch [66/100], Loss: 0.4985\n",
      "Validation Loss: 0.5782\n",
      "Epoch [67/100], Loss: 0.5014\n",
      "Validation Loss: 0.5760\n",
      "Epoch [68/100], Loss: 0.4982\n",
      "Validation Loss: 0.5734\n",
      "Epoch [69/100], Loss: 0.4978\n",
      "Validation Loss: 0.5759\n",
      "Epoch [70/100], Loss: 0.4945\n",
      "Validation Loss: 0.5861\n",
      "Epoch [71/100], Loss: 0.4981\n",
      "Validation Loss: 0.5829\n",
      "Epoch [72/100], Loss: 0.5007\n",
      "Validation Loss: 0.5779\n",
      "Epoch [73/100], Loss: 0.4970\n",
      "Validation Loss: 0.5754\n",
      "Epoch [74/100], Loss: 0.5002\n",
      "Validation Loss: 0.5736\n",
      "Epoch [75/100], Loss: 0.4955\n",
      "Validation Loss: 0.5701\n",
      "Saved the best model with validation loss: 0.5701\n",
      "Epoch [76/100], Loss: 0.4956\n",
      "Validation Loss: 0.5782\n",
      "Epoch [77/100], Loss: 0.4951\n",
      "Validation Loss: 0.5709\n",
      "Epoch [78/100], Loss: 0.4953\n",
      "Validation Loss: 0.5719\n",
      "Epoch [79/100], Loss: 0.4928\n",
      "Validation Loss: 0.5756\n",
      "Epoch [80/100], Loss: 0.4952\n",
      "Validation Loss: 0.5780\n",
      "Epoch [81/100], Loss: 0.4901\n",
      "Validation Loss: 0.5754\n",
      "Epoch [82/100], Loss: 0.4916\n",
      "Validation Loss: 0.5791\n",
      "Epoch [83/100], Loss: 0.4908\n",
      "Validation Loss: 0.5845\n",
      "Epoch [84/100], Loss: 0.4923\n",
      "Validation Loss: 0.5813\n",
      "Epoch [85/100], Loss: 0.4906\n",
      "Validation Loss: 0.5829\n",
      "Epoch [86/100], Loss: 0.4882\n",
      "Validation Loss: 0.5719\n",
      "Epoch [87/100], Loss: 0.4891\n",
      "Validation Loss: 0.5745\n",
      "Epoch [88/100], Loss: 0.4882\n",
      "Validation Loss: 0.5709\n",
      "Epoch [89/100], Loss: 0.4849\n",
      "Validation Loss: 0.5788\n",
      "Epoch [90/100], Loss: 0.4882\n",
      "Validation Loss: 0.5766\n",
      "Epoch [91/100], Loss: 0.4859\n",
      "Validation Loss: 0.5717\n",
      "Epoch [92/100], Loss: 0.4840\n",
      "Validation Loss: 0.5657\n",
      "Saved the best model with validation loss: 0.5657\n",
      "Epoch [93/100], Loss: 0.4852\n",
      "Validation Loss: 0.5741\n",
      "Epoch [94/100], Loss: 0.4847\n",
      "Validation Loss: 0.5740\n",
      "Epoch [95/100], Loss: 0.4854\n",
      "Validation Loss: 0.5740\n",
      "Epoch [96/100], Loss: 0.4834\n",
      "Validation Loss: 0.5668\n",
      "Epoch [97/100], Loss: 0.4813\n",
      "Validation Loss: 0.5725\n",
      "Epoch [98/100], Loss: 0.4829\n",
      "Validation Loss: 0.5738\n",
      "Epoch [99/100], Loss: 0.4835\n",
      "Validation Loss: 0.5784\n",
      "Epoch [100/100], Loss: 0.4823\n",
      "Validation Loss: 0.5682\n"
     ]
    }
   ],
   "source": [
    "combined_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"combi: 17-80-50-5/1-32-64-5/10-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442903ed",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 3\n",
    "*  MLP 17-80-50-5\n",
    "*  HGNN 1-32-64-5\n",
    "*  Combined 10-20-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "da80b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "0bf95640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.6580\n",
      "Validation Loss: 1.0737\n",
      "Saved the best model with validation loss: 1.0737\n",
      "Epoch [2/100], Loss: 0.9520\n",
      "Validation Loss: 0.8472\n",
      "Saved the best model with validation loss: 0.8472\n",
      "Epoch [3/100], Loss: 0.7891\n",
      "Validation Loss: 0.7696\n",
      "Saved the best model with validation loss: 0.7696\n",
      "Epoch [4/100], Loss: 0.7098\n",
      "Validation Loss: 0.7149\n",
      "Saved the best model with validation loss: 0.7149\n",
      "Epoch [5/100], Loss: 0.6579\n",
      "Validation Loss: 0.6617\n",
      "Saved the best model with validation loss: 0.6617\n",
      "Epoch [6/100], Loss: 0.6178\n",
      "Validation Loss: 0.5982\n",
      "Saved the best model with validation loss: 0.5982\n",
      "Epoch [7/100], Loss: 0.5887\n",
      "Validation Loss: 0.5822\n",
      "Saved the best model with validation loss: 0.5822\n",
      "Epoch [8/100], Loss: 0.5710\n",
      "Validation Loss: 0.5303\n",
      "Saved the best model with validation loss: 0.5303\n",
      "Epoch [9/100], Loss: 0.5579\n",
      "Validation Loss: 0.5194\n",
      "Saved the best model with validation loss: 0.5194\n",
      "Epoch [10/100], Loss: 0.5409\n",
      "Validation Loss: 0.5344\n",
      "Epoch [11/100], Loss: 0.5445\n",
      "Validation Loss: 0.5210\n",
      "Epoch [12/100], Loss: 0.5311\n",
      "Validation Loss: 0.5168\n",
      "Saved the best model with validation loss: 0.5168\n",
      "Epoch [13/100], Loss: 0.5234\n",
      "Validation Loss: 0.5192\n",
      "Epoch [14/100], Loss: 0.5202\n",
      "Validation Loss: 0.5199\n",
      "Epoch [15/100], Loss: 0.5134\n",
      "Validation Loss: 0.5314\n",
      "Epoch [16/100], Loss: 0.5119\n",
      "Validation Loss: 0.5140\n",
      "Saved the best model with validation loss: 0.5140\n",
      "Epoch [17/100], Loss: 0.5076\n",
      "Validation Loss: 0.5146\n",
      "Epoch [18/100], Loss: 0.5036\n",
      "Validation Loss: 0.5349\n",
      "Epoch [19/100], Loss: 0.4980\n",
      "Validation Loss: 0.5423\n",
      "Epoch [20/100], Loss: 0.4948\n",
      "Validation Loss: 0.5273\n",
      "Epoch [21/100], Loss: 0.4917\n",
      "Validation Loss: 0.5371\n",
      "Epoch [22/100], Loss: 0.4883\n",
      "Validation Loss: 0.5298\n",
      "Epoch [23/100], Loss: 0.4842\n",
      "Validation Loss: 0.5118\n",
      "Saved the best model with validation loss: 0.5118\n",
      "Epoch [24/100], Loss: 0.4843\n",
      "Validation Loss: 0.5285\n",
      "Epoch [25/100], Loss: 0.4839\n",
      "Validation Loss: 0.5211\n",
      "Epoch [26/100], Loss: 0.4874\n",
      "Validation Loss: 0.5134\n",
      "Epoch [27/100], Loss: 0.4833\n",
      "Validation Loss: 0.5136\n",
      "Epoch [28/100], Loss: 0.4851\n",
      "Validation Loss: 0.5024\n",
      "Saved the best model with validation loss: 0.5024\n",
      "Epoch [29/100], Loss: 0.4865\n",
      "Validation Loss: 0.5117\n",
      "Epoch [30/100], Loss: 0.4764\n",
      "Validation Loss: 0.5049\n",
      "Epoch [31/100], Loss: 0.4784\n",
      "Validation Loss: 0.5018\n",
      "Saved the best model with validation loss: 0.5018\n",
      "Epoch [32/100], Loss: 0.4824\n",
      "Validation Loss: 0.4980\n",
      "Saved the best model with validation loss: 0.4980\n",
      "Epoch [33/100], Loss: 0.4751\n",
      "Validation Loss: 0.4887\n",
      "Saved the best model with validation loss: 0.4887\n",
      "Epoch [34/100], Loss: 0.4737\n",
      "Validation Loss: 0.4800\n",
      "Saved the best model with validation loss: 0.4800\n",
      "Epoch [35/100], Loss: 0.4748\n",
      "Validation Loss: 0.4836\n",
      "Epoch [36/100], Loss: 0.4743\n",
      "Validation Loss: 0.4827\n",
      "Epoch [37/100], Loss: 0.4682\n",
      "Validation Loss: 0.4697\n",
      "Saved the best model with validation loss: 0.4697\n",
      "Epoch [38/100], Loss: 0.4658\n",
      "Validation Loss: 0.4885\n",
      "Epoch [39/100], Loss: 0.4626\n",
      "Validation Loss: 0.4866\n",
      "Epoch [40/100], Loss: 0.4639\n",
      "Validation Loss: 0.4854\n",
      "Epoch [41/100], Loss: 0.4624\n",
      "Validation Loss: 0.4826\n",
      "Epoch [42/100], Loss: 0.4614\n",
      "Validation Loss: 0.4950\n",
      "Epoch [43/100], Loss: 0.4691\n",
      "Validation Loss: 0.4794\n",
      "Epoch [44/100], Loss: 0.4599\n",
      "Validation Loss: 0.4859\n",
      "Epoch [45/100], Loss: 0.4610\n",
      "Validation Loss: 0.4935\n",
      "Epoch [46/100], Loss: 0.4608\n",
      "Validation Loss: 0.4886\n",
      "Epoch [47/100], Loss: 0.4563\n",
      "Validation Loss: 0.5038\n",
      "Epoch [48/100], Loss: 0.4575\n",
      "Validation Loss: 0.4952\n",
      "Epoch [49/100], Loss: 0.4556\n",
      "Validation Loss: 0.4972\n",
      "Epoch [50/100], Loss: 0.4578\n",
      "Validation Loss: 0.4807\n",
      "Epoch [51/100], Loss: 0.4522\n",
      "Validation Loss: 0.4982\n",
      "Epoch [52/100], Loss: 0.4535\n",
      "Validation Loss: 0.4978\n",
      "Epoch [53/100], Loss: 0.4500\n",
      "Validation Loss: 0.4960\n",
      "Epoch [54/100], Loss: 0.4508\n",
      "Validation Loss: 0.4950\n",
      "Epoch [55/100], Loss: 0.4470\n",
      "Validation Loss: 0.4742\n",
      "Epoch [56/100], Loss: 0.4493\n",
      "Validation Loss: 0.4688\n",
      "Saved the best model with validation loss: 0.4688\n",
      "Epoch [57/100], Loss: 0.4463\n",
      "Validation Loss: 0.4927\n",
      "Epoch [58/100], Loss: 0.4450\n",
      "Validation Loss: 0.4933\n",
      "Epoch [59/100], Loss: 0.4395\n",
      "Validation Loss: 0.4950\n",
      "Epoch [60/100], Loss: 0.4478\n",
      "Validation Loss: 0.4870\n",
      "Epoch [61/100], Loss: 0.4404\n",
      "Validation Loss: 0.4839\n",
      "Epoch [62/100], Loss: 0.4428\n",
      "Validation Loss: 0.4906\n",
      "Epoch [63/100], Loss: 0.4406\n",
      "Validation Loss: 0.4973\n",
      "Epoch [64/100], Loss: 0.4451\n",
      "Validation Loss: 0.4986\n",
      "Epoch [65/100], Loss: 0.4394\n",
      "Validation Loss: 0.4740\n",
      "Epoch [66/100], Loss: 0.4395\n",
      "Validation Loss: 0.4887\n",
      "Epoch [67/100], Loss: 0.4367\n",
      "Validation Loss: 0.4861\n",
      "Epoch [68/100], Loss: 0.4344\n",
      "Validation Loss: 0.4949\n",
      "Epoch [69/100], Loss: 0.4369\n",
      "Validation Loss: 0.4861\n",
      "Epoch [70/100], Loss: 0.4406\n",
      "Validation Loss: 0.4732\n",
      "Epoch [71/100], Loss: 0.4364\n",
      "Validation Loss: 0.4861\n",
      "Epoch [72/100], Loss: 0.4384\n",
      "Validation Loss: 0.5031\n",
      "Epoch [73/100], Loss: 0.4338\n",
      "Validation Loss: 0.4981\n",
      "Epoch [74/100], Loss: 0.4352\n",
      "Validation Loss: 0.5035\n",
      "Epoch [75/100], Loss: 0.4379\n",
      "Validation Loss: 0.5016\n",
      "Epoch [76/100], Loss: 0.4390\n",
      "Validation Loss: 0.5088\n",
      "Epoch [77/100], Loss: 0.4317\n",
      "Validation Loss: 0.5049\n",
      "Epoch [78/100], Loss: 0.4348\n",
      "Validation Loss: 0.5027\n",
      "Epoch [79/100], Loss: 0.4347\n",
      "Validation Loss: 0.4925\n",
      "Epoch [80/100], Loss: 0.4315\n",
      "Validation Loss: 0.5161\n",
      "Epoch [81/100], Loss: 0.4299\n",
      "Validation Loss: 0.4953\n",
      "Epoch [82/100], Loss: 0.4302\n",
      "Validation Loss: 0.5088\n",
      "Epoch [83/100], Loss: 0.4297\n",
      "Validation Loss: 0.4932\n",
      "Epoch [84/100], Loss: 0.4289\n",
      "Validation Loss: 0.4999\n",
      "Epoch [85/100], Loss: 0.4259\n",
      "Validation Loss: 0.4881\n",
      "Epoch [86/100], Loss: 0.4262\n",
      "Validation Loss: 0.4813\n",
      "Epoch [87/100], Loss: 0.4309\n",
      "Validation Loss: 0.4907\n",
      "Epoch [88/100], Loss: 0.4304\n",
      "Validation Loss: 0.4898\n",
      "Epoch [89/100], Loss: 0.4296\n",
      "Validation Loss: 0.4711\n",
      "Epoch [90/100], Loss: 0.4252\n",
      "Validation Loss: 0.4808\n",
      "Epoch [91/100], Loss: 0.4324\n",
      "Validation Loss: 0.4742\n",
      "Epoch [92/100], Loss: 0.4267\n",
      "Validation Loss: 0.4878\n",
      "Epoch [93/100], Loss: 0.4239\n",
      "Validation Loss: 0.4759\n",
      "Epoch [94/100], Loss: 0.4216\n",
      "Validation Loss: 0.4984\n",
      "Epoch [95/100], Loss: 0.4270\n",
      "Validation Loss: 0.5015\n",
      "Epoch [96/100], Loss: 0.4215\n",
      "Validation Loss: 0.5103\n",
      "Epoch [97/100], Loss: 0.4236\n",
      "Validation Loss: 0.5037\n",
      "Epoch [98/100], Loss: 0.4215\n",
      "Validation Loss: 0.5028\n",
      "Epoch [99/100], Loss: 0.4262\n",
      "Validation Loss: 0.4810\n",
      "Epoch [100/100], Loss: 0.4202\n",
      "Validation Loss: 0.4942\n"
     ]
    }
   ],
   "source": [
    "combined_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"combi: 17-80-50-5/1-32-64-5/10-20-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b86f7",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 4\n",
    "*  MLP 17-80-50-10\n",
    "*  HGNN 1-32-64-10\n",
    "*  Combined 20-40-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "54f658dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "53479f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.5665\n",
      "Validation Loss: 0.9333\n",
      "Saved the best model with validation loss: 0.9333\n",
      "Epoch [2/100], Loss: 0.8933\n",
      "Validation Loss: 0.8332\n",
      "Saved the best model with validation loss: 0.8332\n",
      "Epoch [3/100], Loss: 0.7606\n",
      "Validation Loss: 0.7836\n",
      "Saved the best model with validation loss: 0.7836\n",
      "Epoch [4/100], Loss: 0.6928\n",
      "Validation Loss: 0.7259\n",
      "Saved the best model with validation loss: 0.7259\n",
      "Epoch [5/100], Loss: 0.6583\n",
      "Validation Loss: 0.6825\n",
      "Saved the best model with validation loss: 0.6825\n",
      "Epoch [6/100], Loss: 0.6208\n",
      "Validation Loss: 0.6551\n",
      "Saved the best model with validation loss: 0.6551\n",
      "Epoch [7/100], Loss: 0.5956\n",
      "Validation Loss: 0.6091\n",
      "Saved the best model with validation loss: 0.6091\n",
      "Epoch [8/100], Loss: 0.5768\n",
      "Validation Loss: 0.5474\n",
      "Saved the best model with validation loss: 0.5474\n",
      "Epoch [9/100], Loss: 0.5604\n",
      "Validation Loss: 0.5315\n",
      "Saved the best model with validation loss: 0.5315\n",
      "Epoch [10/100], Loss: 0.5494\n",
      "Validation Loss: 0.5226\n",
      "Saved the best model with validation loss: 0.5226\n",
      "Epoch [11/100], Loss: 0.5347\n",
      "Validation Loss: 0.5014\n",
      "Saved the best model with validation loss: 0.5014\n",
      "Epoch [12/100], Loss: 0.5439\n",
      "Validation Loss: 0.5017\n",
      "Epoch [13/100], Loss: 0.5208\n",
      "Validation Loss: 0.5077\n",
      "Epoch [14/100], Loss: 0.5150\n",
      "Validation Loss: 0.5137\n",
      "Epoch [15/100], Loss: 0.5123\n",
      "Validation Loss: 0.5107\n",
      "Epoch [16/100], Loss: 0.5004\n",
      "Validation Loss: 0.4953\n",
      "Saved the best model with validation loss: 0.4953\n",
      "Epoch [17/100], Loss: 0.5007\n",
      "Validation Loss: 0.5008\n",
      "Epoch [18/100], Loss: 0.4894\n",
      "Validation Loss: 0.5037\n",
      "Epoch [19/100], Loss: 0.4920\n",
      "Validation Loss: 0.4968\n",
      "Epoch [20/100], Loss: 0.4842\n",
      "Validation Loss: 0.5109\n",
      "Epoch [21/100], Loss: 0.4857\n",
      "Validation Loss: 0.4911\n",
      "Saved the best model with validation loss: 0.4911\n",
      "Epoch [22/100], Loss: 0.4817\n",
      "Validation Loss: 0.5158\n",
      "Epoch [23/100], Loss: 0.4799\n",
      "Validation Loss: 0.4917\n",
      "Epoch [24/100], Loss: 0.4889\n",
      "Validation Loss: 0.5086\n",
      "Epoch [25/100], Loss: 0.4844\n",
      "Validation Loss: 0.4979\n",
      "Epoch [26/100], Loss: 0.4772\n",
      "Validation Loss: 0.4973\n",
      "Epoch [27/100], Loss: 0.4715\n",
      "Validation Loss: 0.5116\n",
      "Epoch [28/100], Loss: 0.4744\n",
      "Validation Loss: 0.5342\n",
      "Epoch [29/100], Loss: 0.4676\n",
      "Validation Loss: 0.4962\n",
      "Epoch [30/100], Loss: 0.4679\n",
      "Validation Loss: 0.5098\n",
      "Epoch [31/100], Loss: 0.4657\n",
      "Validation Loss: 0.4963\n",
      "Epoch [32/100], Loss: 0.4667\n",
      "Validation Loss: 0.5032\n",
      "Epoch [33/100], Loss: 0.4624\n",
      "Validation Loss: 0.5084\n",
      "Epoch [34/100], Loss: 0.4607\n",
      "Validation Loss: 0.5084\n",
      "Epoch [35/100], Loss: 0.4621\n",
      "Validation Loss: 0.5045\n",
      "Epoch [36/100], Loss: 0.4580\n",
      "Validation Loss: 0.4967\n",
      "Epoch [37/100], Loss: 0.4598\n",
      "Validation Loss: 0.4929\n",
      "Epoch [38/100], Loss: 0.4600\n",
      "Validation Loss: 0.4981\n",
      "Epoch [39/100], Loss: 0.4563\n",
      "Validation Loss: 0.4935\n",
      "Epoch [40/100], Loss: 0.4589\n",
      "Validation Loss: 0.4874\n",
      "Saved the best model with validation loss: 0.4874\n",
      "Epoch [41/100], Loss: 0.4528\n",
      "Validation Loss: 0.5030\n",
      "Epoch [42/100], Loss: 0.4519\n",
      "Validation Loss: 0.4844\n",
      "Saved the best model with validation loss: 0.4844\n",
      "Epoch [43/100], Loss: 0.4479\n",
      "Validation Loss: 0.4986\n",
      "Epoch [44/100], Loss: 0.4484\n",
      "Validation Loss: 0.4932\n",
      "Epoch [45/100], Loss: 0.4524\n",
      "Validation Loss: 0.4851\n",
      "Epoch [46/100], Loss: 0.4492\n",
      "Validation Loss: 0.4818\n",
      "Saved the best model with validation loss: 0.4818\n",
      "Epoch [47/100], Loss: 0.4470\n",
      "Validation Loss: 0.4943\n",
      "Epoch [48/100], Loss: 0.4479\n",
      "Validation Loss: 0.4910\n",
      "Epoch [49/100], Loss: 0.4544\n",
      "Validation Loss: 0.4972\n",
      "Epoch [50/100], Loss: 0.4444\n",
      "Validation Loss: 0.4890\n",
      "Epoch [51/100], Loss: 0.4453\n",
      "Validation Loss: 0.4761\n",
      "Saved the best model with validation loss: 0.4761\n",
      "Epoch [52/100], Loss: 0.4510\n",
      "Validation Loss: 0.5161\n",
      "Epoch [53/100], Loss: 0.4474\n",
      "Validation Loss: 0.4727\n",
      "Saved the best model with validation loss: 0.4727\n",
      "Epoch [54/100], Loss: 0.4416\n",
      "Validation Loss: 0.4898\n",
      "Epoch [55/100], Loss: 0.4402\n",
      "Validation Loss: 0.5115\n",
      "Epoch [56/100], Loss: 0.4413\n",
      "Validation Loss: 0.4926\n",
      "Epoch [57/100], Loss: 0.4464\n",
      "Validation Loss: 0.4810\n",
      "Epoch [58/100], Loss: 0.4443\n",
      "Validation Loss: 0.4860\n",
      "Epoch [59/100], Loss: 0.4420\n",
      "Validation Loss: 0.4892\n",
      "Epoch [60/100], Loss: 0.4394\n",
      "Validation Loss: 0.4878\n",
      "Epoch [61/100], Loss: 0.4411\n",
      "Validation Loss: 0.4752\n",
      "Epoch [62/100], Loss: 0.4428\n",
      "Validation Loss: 0.4828\n",
      "Epoch [63/100], Loss: 0.4395\n",
      "Validation Loss: 0.4727\n",
      "Saved the best model with validation loss: 0.4727\n",
      "Epoch [64/100], Loss: 0.4382\n",
      "Validation Loss: 0.4624\n",
      "Saved the best model with validation loss: 0.4624\n",
      "Epoch [65/100], Loss: 0.4390\n",
      "Validation Loss: 0.4706\n",
      "Epoch [66/100], Loss: 0.4366\n",
      "Validation Loss: 0.4687\n",
      "Epoch [67/100], Loss: 0.4354\n",
      "Validation Loss: 0.4717\n",
      "Epoch [68/100], Loss: 0.4366\n",
      "Validation Loss: 0.4746\n",
      "Epoch [69/100], Loss: 0.4377\n",
      "Validation Loss: 0.4889\n",
      "Epoch [70/100], Loss: 0.4357\n",
      "Validation Loss: 0.4902\n",
      "Epoch [71/100], Loss: 0.4393\n",
      "Validation Loss: 0.4794\n",
      "Epoch [72/100], Loss: 0.4340\n",
      "Validation Loss: 0.4698\n",
      "Epoch [73/100], Loss: 0.4379\n",
      "Validation Loss: 0.5080\n",
      "Epoch [74/100], Loss: 0.4338\n",
      "Validation Loss: 0.4986\n",
      "Epoch [75/100], Loss: 0.4318\n",
      "Validation Loss: 0.4895\n",
      "Epoch [76/100], Loss: 0.4337\n",
      "Validation Loss: 0.5081\n",
      "Epoch [77/100], Loss: 0.4381\n",
      "Validation Loss: 0.4816\n",
      "Epoch [78/100], Loss: 0.4320\n",
      "Validation Loss: 0.4853\n",
      "Epoch [79/100], Loss: 0.4326\n",
      "Validation Loss: 0.4843\n",
      "Epoch [80/100], Loss: 0.4316\n",
      "Validation Loss: 0.5087\n",
      "Epoch [81/100], Loss: 0.4323\n",
      "Validation Loss: 0.4978\n",
      "Epoch [82/100], Loss: 0.4311\n",
      "Validation Loss: 0.4692\n",
      "Epoch [83/100], Loss: 0.4297\n",
      "Validation Loss: 0.4692\n",
      "Epoch [84/100], Loss: 0.4322\n",
      "Validation Loss: 0.4819\n",
      "Epoch [85/100], Loss: 0.4300\n",
      "Validation Loss: 0.4728\n",
      "Epoch [86/100], Loss: 0.4335\n",
      "Validation Loss: 0.4870\n",
      "Epoch [87/100], Loss: 0.4377\n",
      "Validation Loss: 0.4522\n",
      "Saved the best model with validation loss: 0.4522\n",
      "Epoch [88/100], Loss: 0.4312\n",
      "Validation Loss: 0.4484\n",
      "Saved the best model with validation loss: 0.4484\n",
      "Epoch [89/100], Loss: 0.4317\n",
      "Validation Loss: 0.4346\n",
      "Saved the best model with validation loss: 0.4346\n",
      "Epoch [90/100], Loss: 0.4319\n",
      "Validation Loss: 0.4668\n",
      "Epoch [91/100], Loss: 0.4315\n",
      "Validation Loss: 0.4642\n",
      "Epoch [92/100], Loss: 0.4286\n",
      "Validation Loss: 0.4574\n",
      "Epoch [93/100], Loss: 0.4273\n",
      "Validation Loss: 0.4675\n",
      "Epoch [94/100], Loss: 0.4296\n",
      "Validation Loss: 0.4712\n",
      "Epoch [95/100], Loss: 0.4275\n",
      "Validation Loss: 0.4597\n",
      "Epoch [96/100], Loss: 0.4270\n",
      "Validation Loss: 0.4590\n",
      "Epoch [97/100], Loss: 0.4274\n",
      "Validation Loss: 0.4634\n",
      "Epoch [98/100], Loss: 0.4295\n",
      "Validation Loss: 0.4645\n",
      "Epoch [99/100], Loss: 0.4256\n",
      "Validation Loss: 0.4572\n",
      "Epoch [100/100], Loss: 0.4243\n",
      "Validation Loss: 0.4503\n"
     ]
    }
   ],
   "source": [
    "combined_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"combi: 17-80-50-10/1-32-64-10/20-40-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae2026",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 5\n",
    "*  MLP 17-80-50-10\n",
    "*  HGNN 1-32-64-10\n",
    "*  Combined 20-60-20-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "66fe07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "88b22c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7236\n",
      "Validation Loss: 1.2830\n",
      "Saved the best model with validation loss: 1.2830\n",
      "Epoch [2/100], Loss: 1.0588\n",
      "Validation Loss: 0.9117\n",
      "Saved the best model with validation loss: 0.9117\n",
      "Epoch [3/100], Loss: 0.8310\n",
      "Validation Loss: 0.8931\n",
      "Saved the best model with validation loss: 0.8931\n",
      "Epoch [4/100], Loss: 0.7223\n",
      "Validation Loss: 0.7506\n",
      "Saved the best model with validation loss: 0.7506\n",
      "Epoch [5/100], Loss: 0.6417\n",
      "Validation Loss: 0.6615\n",
      "Saved the best model with validation loss: 0.6615\n",
      "Epoch [6/100], Loss: 0.6192\n",
      "Validation Loss: 0.5815\n",
      "Saved the best model with validation loss: 0.5815\n",
      "Epoch [7/100], Loss: 0.5817\n",
      "Validation Loss: 0.5901\n",
      "Epoch [8/100], Loss: 0.5943\n",
      "Validation Loss: 0.5601\n",
      "Saved the best model with validation loss: 0.5601\n",
      "Epoch [9/100], Loss: 0.5645\n",
      "Validation Loss: 0.5670\n",
      "Epoch [10/100], Loss: 0.5519\n",
      "Validation Loss: 0.6096\n",
      "Epoch [11/100], Loss: 0.5443\n",
      "Validation Loss: 0.5996\n",
      "Epoch [12/100], Loss: 0.5197\n",
      "Validation Loss: 0.6140\n",
      "Epoch [13/100], Loss: 0.5285\n",
      "Validation Loss: 0.5874\n",
      "Epoch [14/100], Loss: 0.5120\n",
      "Validation Loss: 0.5730\n",
      "Epoch [15/100], Loss: 0.5064\n",
      "Validation Loss: 0.5935\n",
      "Epoch [16/100], Loss: 0.5046\n",
      "Validation Loss: 0.5771\n",
      "Epoch [17/100], Loss: 0.4907\n",
      "Validation Loss: 0.5839\n",
      "Epoch [18/100], Loss: 0.4931\n",
      "Validation Loss: 0.5925\n",
      "Epoch [19/100], Loss: 0.4886\n",
      "Validation Loss: 0.5772\n",
      "Epoch [20/100], Loss: 0.4913\n",
      "Validation Loss: 0.5640\n",
      "Epoch [21/100], Loss: 0.4800\n",
      "Validation Loss: 0.5925\n",
      "Epoch [22/100], Loss: 0.4766\n",
      "Validation Loss: 0.5800\n",
      "Epoch [23/100], Loss: 0.4857\n",
      "Validation Loss: 0.5734\n",
      "Epoch [24/100], Loss: 0.4687\n",
      "Validation Loss: 0.5653\n",
      "Epoch [25/100], Loss: 0.4696\n",
      "Validation Loss: 0.5571\n",
      "Saved the best model with validation loss: 0.5571\n",
      "Epoch [26/100], Loss: 0.4611\n",
      "Validation Loss: 0.5697\n",
      "Epoch [27/100], Loss: 0.4582\n",
      "Validation Loss: 0.5739\n",
      "Epoch [28/100], Loss: 0.4655\n",
      "Validation Loss: 0.5220\n",
      "Saved the best model with validation loss: 0.5220\n",
      "Epoch [29/100], Loss: 0.4610\n",
      "Validation Loss: 0.5618\n",
      "Epoch [30/100], Loss: 0.4613\n",
      "Validation Loss: 0.5553\n",
      "Epoch [31/100], Loss: 0.4505\n",
      "Validation Loss: 0.5631\n",
      "Epoch [32/100], Loss: 0.4527\n",
      "Validation Loss: 0.6035\n",
      "Epoch [33/100], Loss: 0.4665\n",
      "Validation Loss: 0.5839\n",
      "Epoch [34/100], Loss: 0.4537\n",
      "Validation Loss: 0.5366\n",
      "Epoch [35/100], Loss: 0.4425\n",
      "Validation Loss: 0.5467\n",
      "Epoch [36/100], Loss: 0.4486\n",
      "Validation Loss: 0.5484\n",
      "Epoch [37/100], Loss: 0.4738\n",
      "Validation Loss: 0.5309\n",
      "Epoch [38/100], Loss: 0.4494\n",
      "Validation Loss: 0.5110\n",
      "Saved the best model with validation loss: 0.5110\n",
      "Epoch [39/100], Loss: 0.4436\n",
      "Validation Loss: 0.5420\n",
      "Epoch [40/100], Loss: 0.4513\n",
      "Validation Loss: 0.5740\n",
      "Epoch [41/100], Loss: 0.4450\n",
      "Validation Loss: 0.5346\n",
      "Epoch [42/100], Loss: 0.4407\n",
      "Validation Loss: 0.5422\n",
      "Epoch [43/100], Loss: 0.4392\n",
      "Validation Loss: 0.5496\n",
      "Epoch [44/100], Loss: 0.4404\n",
      "Validation Loss: 0.5410\n",
      "Epoch [45/100], Loss: 0.4319\n",
      "Validation Loss: 0.5177\n",
      "Epoch [46/100], Loss: 0.4354\n",
      "Validation Loss: 0.5173\n",
      "Epoch [47/100], Loss: 0.4386\n",
      "Validation Loss: 0.5115\n",
      "Epoch [48/100], Loss: 0.4347\n",
      "Validation Loss: 0.5306\n",
      "Epoch [49/100], Loss: 0.4315\n",
      "Validation Loss: 0.5189\n",
      "Epoch [50/100], Loss: 0.4315\n",
      "Validation Loss: 0.5578\n",
      "Epoch [51/100], Loss: 0.4278\n",
      "Validation Loss: 0.5312\n",
      "Epoch [52/100], Loss: 0.4332\n",
      "Validation Loss: 0.5267\n",
      "Epoch [53/100], Loss: 0.4337\n",
      "Validation Loss: 0.5342\n",
      "Epoch [54/100], Loss: 0.4225\n",
      "Validation Loss: 0.5285\n",
      "Epoch [55/100], Loss: 0.4227\n",
      "Validation Loss: 0.5295\n",
      "Epoch [56/100], Loss: 0.4320\n",
      "Validation Loss: 0.5287\n",
      "Epoch [57/100], Loss: 0.4430\n",
      "Validation Loss: 0.5257\n",
      "Epoch [58/100], Loss: 0.4226\n",
      "Validation Loss: 0.5258\n",
      "Epoch [59/100], Loss: 0.4291\n",
      "Validation Loss: 0.5248\n",
      "Epoch [60/100], Loss: 0.4386\n",
      "Validation Loss: 0.5424\n",
      "Epoch [61/100], Loss: 0.4303\n",
      "Validation Loss: 0.5304\n",
      "Epoch [62/100], Loss: 0.4265\n",
      "Validation Loss: 0.5336\n",
      "Epoch [63/100], Loss: 0.4233\n",
      "Validation Loss: 0.5509\n",
      "Epoch [64/100], Loss: 0.4298\n",
      "Validation Loss: 0.5585\n",
      "Epoch [65/100], Loss: 0.4360\n",
      "Validation Loss: 0.5300\n",
      "Epoch [66/100], Loss: 0.4374\n",
      "Validation Loss: 0.5231\n",
      "Epoch [67/100], Loss: 0.4168\n",
      "Validation Loss: 0.4973\n",
      "Saved the best model with validation loss: 0.4973\n",
      "Epoch [68/100], Loss: 0.4262\n",
      "Validation Loss: 0.5288\n",
      "Epoch [69/100], Loss: 0.4278\n",
      "Validation Loss: 0.5222\n",
      "Epoch [70/100], Loss: 0.4301\n",
      "Validation Loss: 0.5056\n",
      "Epoch [71/100], Loss: 0.4166\n",
      "Validation Loss: 0.5226\n",
      "Epoch [72/100], Loss: 0.4327\n",
      "Validation Loss: 0.5466\n",
      "Epoch [73/100], Loss: 0.4193\n",
      "Validation Loss: 0.5229\n",
      "Epoch [74/100], Loss: 0.4191\n",
      "Validation Loss: 0.4931\n",
      "Saved the best model with validation loss: 0.4931\n",
      "Epoch [75/100], Loss: 0.4217\n",
      "Validation Loss: 0.5082\n",
      "Epoch [76/100], Loss: 0.4189\n",
      "Validation Loss: 0.5299\n",
      "Epoch [77/100], Loss: 0.4146\n",
      "Validation Loss: 0.5171\n",
      "Epoch [78/100], Loss: 0.4366\n",
      "Validation Loss: 0.4929\n",
      "Saved the best model with validation loss: 0.4929\n",
      "Epoch [79/100], Loss: 0.4186\n",
      "Validation Loss: 0.5133\n",
      "Epoch [80/100], Loss: 0.4177\n",
      "Validation Loss: 0.5359\n",
      "Epoch [81/100], Loss: 0.4207\n",
      "Validation Loss: 0.4975\n",
      "Epoch [82/100], Loss: 0.4142\n",
      "Validation Loss: 0.5046\n",
      "Epoch [83/100], Loss: 0.4136\n",
      "Validation Loss: 0.4895\n",
      "Saved the best model with validation loss: 0.4895\n",
      "Epoch [84/100], Loss: 0.4385\n",
      "Validation Loss: 0.4952\n",
      "Epoch [85/100], Loss: 0.4239\n",
      "Validation Loss: 0.4909\n",
      "Epoch [86/100], Loss: 0.4108\n",
      "Validation Loss: 0.5098\n",
      "Epoch [87/100], Loss: 0.4196\n",
      "Validation Loss: 0.4933\n",
      "Epoch [88/100], Loss: 0.4381\n",
      "Validation Loss: 0.5179\n",
      "Epoch [89/100], Loss: 0.4146\n",
      "Validation Loss: 0.5044\n",
      "Epoch [90/100], Loss: 0.4323\n",
      "Validation Loss: 0.4941\n",
      "Epoch [91/100], Loss: 0.4134\n",
      "Validation Loss: 0.5132\n",
      "Epoch [92/100], Loss: 0.4213\n",
      "Validation Loss: 0.5195\n",
      "Epoch [93/100], Loss: 0.4261\n",
      "Validation Loss: 0.5004\n",
      "Epoch [94/100], Loss: 0.4118\n",
      "Validation Loss: 0.5071\n",
      "Epoch [95/100], Loss: 0.4246\n",
      "Validation Loss: 0.4943\n",
      "Epoch [96/100], Loss: 0.4240\n",
      "Validation Loss: 0.5025\n",
      "Epoch [97/100], Loss: 0.4128\n",
      "Validation Loss: 0.4794\n",
      "Saved the best model with validation loss: 0.4794\n",
      "Epoch [98/100], Loss: 0.4123\n",
      "Validation Loss: 0.5082\n",
      "Epoch [99/100], Loss: 0.4130\n",
      "Validation Loss: 0.4914\n",
      "Epoch [100/100], Loss: 0.4248\n",
      "Validation Loss: 0.4840\n"
     ]
    }
   ],
   "source": [
    "combined_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"combi: 17-80-50-10/1-32-64-10/20-60-20-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "8aedd500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.789418</td>\n",
       "      <td>0.730049</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.579022</td>\n",
       "      <td>0.390659</td>\n",
       "      <td>0.818862</td>\n",
       "      <td>0.612816</td>\n",
       "      <td>0.433778</td>\n",
       "      <td>0.79668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.584555</td>\n",
       "      <td>0.392098</td>\n",
       "      <td>0.817131</td>\n",
       "      <td>0.61371</td>\n",
       "      <td>0.435071</td>\n",
       "      <td>0.796384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>2.323296</td>\n",
       "      <td>0.907326</td>\n",
       "      <td>0.273192</td>\n",
       "      <td>2.371142</td>\n",
       "      <td>0.929039</td>\n",
       "      <td>0.213305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.778288</td>\n",
       "      <td>0.719919</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>1.81521</td>\n",
       "      <td>0.749433</td>\n",
       "      <td>0.397751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.612341</td>\n",
       "      <td>0.692069</td>\n",
       "      <td>0.495604</td>\n",
       "      <td>1.666438</td>\n",
       "      <td>0.727603</td>\n",
       "      <td>0.447111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-1</th>\n",
       "      <td>1.386030</td>\n",
       "      <td>0.840528</td>\n",
       "      <td>0.566402</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-1</th>\n",
       "      <td>1.511389</td>\n",
       "      <td>0.875163</td>\n",
       "      <td>0.527185</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-1</th>\n",
       "      <td>1.442876</td>\n",
       "      <td>0.859189</td>\n",
       "      <td>0.548618</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-1</th>\n",
       "      <td>1.343067</td>\n",
       "      <td>0.821639</td>\n",
       "      <td>0.579842</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-1</th>\n",
       "      <td>1.347905</td>\n",
       "      <td>0.820918</td>\n",
       "      <td>0.578329</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-1</th>\n",
       "      <td>1.388511</td>\n",
       "      <td>0.829501</td>\n",
       "      <td>0.565625</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-1</th>\n",
       "      <td>1.360229</td>\n",
       "      <td>0.822960</td>\n",
       "      <td>0.574473</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-1</th>\n",
       "      <td>1.273426</td>\n",
       "      <td>0.791052</td>\n",
       "      <td>0.601628</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-1</th>\n",
       "      <td>1.285886</td>\n",
       "      <td>0.801589</td>\n",
       "      <td>0.597730</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-1</th>\n",
       "      <td>1.255633</td>\n",
       "      <td>0.796268</td>\n",
       "      <td>0.607194</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-1</th>\n",
       "      <td>1.162645</td>\n",
       "      <td>0.744006</td>\n",
       "      <td>0.636284</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-1</th>\n",
       "      <td>1.183051</td>\n",
       "      <td>0.745964</td>\n",
       "      <td>0.629900</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-1</th>\n",
       "      <td>1.124134</td>\n",
       "      <td>0.712487</td>\n",
       "      <td>0.648332</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-1</th>\n",
       "      <td>1.313112</td>\n",
       "      <td>0.792845</td>\n",
       "      <td>0.589213</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-1</th>\n",
       "      <td>1.274659</td>\n",
       "      <td>0.764669</td>\n",
       "      <td>0.601242</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-1</th>\n",
       "      <td>1.344109</td>\n",
       "      <td>0.802782</td>\n",
       "      <td>0.579516</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-1</th>\n",
       "      <td>1.202730</td>\n",
       "      <td>0.722136</td>\n",
       "      <td>0.623744</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-1</th>\n",
       "      <td>1.339963</td>\n",
       "      <td>0.802546</td>\n",
       "      <td>0.580813</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-1</th>\n",
       "      <td>1.237934</td>\n",
       "      <td>0.760888</td>\n",
       "      <td>0.612731</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-1</th>\n",
       "      <td>1.154383</td>\n",
       "      <td>0.717330</td>\n",
       "      <td>0.638869</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-1</th>\n",
       "      <td>0.671361</td>\n",
       "      <td>0.475938</td>\n",
       "      <td>0.789975</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-1</th>\n",
       "      <td>0.705351</td>\n",
       "      <td>0.506083</td>\n",
       "      <td>0.779342</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-1</th>\n",
       "      <td>0.661967</td>\n",
       "      <td>0.457578</td>\n",
       "      <td>0.792914</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-1</th>\n",
       "      <td>0.657654</td>\n",
       "      <td>0.488402</td>\n",
       "      <td>0.794263</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-1</th>\n",
       "      <td>0.716271</td>\n",
       "      <td>0.523176</td>\n",
       "      <td>0.775925</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-2/1-32-64-2/4-1</th>\n",
       "      <td>0.555735</td>\n",
       "      <td>0.458384</td>\n",
       "      <td>0.826147</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-32-64-5/10-2</th>\n",
       "      <td>0.565674</td>\n",
       "      <td>0.463923</td>\n",
       "      <td>0.823038</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-32-64-5/10-20-2</th>\n",
       "      <td>0.468850</td>\n",
       "      <td>0.390846</td>\n",
       "      <td>0.853327</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-32-64-10/20-40-2</th>\n",
       "      <td>0.434580</td>\n",
       "      <td>0.370065</td>\n",
       "      <td>0.864048</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-32-64-10/20-60-20-2</th>\n",
       "      <td>0.479359</td>\n",
       "      <td>0.384279</td>\n",
       "      <td>0.850040</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               MSE       MAE        R2  \\\n",
       "5-NN                                      0.673141  0.442646  0.789418   \n",
       "Decision tree                             0.579022  0.390659  0.818862   \n",
       "Random forest                             0.584555  0.392098  0.817131   \n",
       "SVM linear                                2.323296  0.907326  0.273192   \n",
       "SVM poly                                  1.778288  0.719919  0.443690   \n",
       "SVM rbf                                   1.612341  0.692069  0.495604   \n",
       "MLP: 17-5-1                               1.386030  0.840528  0.566402   \n",
       "MLP: 17-10-1                              1.511389  0.875163  0.527185   \n",
       "MLP: 17-20-1                              1.442876  0.859189  0.548618   \n",
       "MLP: 17-25-1                              1.343067  0.821639  0.579842   \n",
       "MLP: 17-40-1                              1.347905  0.820918  0.578329   \n",
       "MLP: 17-60-1                              1.388511  0.829501  0.565625   \n",
       "MLP: 17-10-5-1                            1.360229  0.822960  0.574473   \n",
       "MLP: 17-20-10-1                           1.273426  0.791052  0.601628   \n",
       "MLP: 17-40-20-1                           1.285886  0.801589  0.597730   \n",
       "MLP: 17-40-10-1                           1.255633  0.796268  0.607194   \n",
       "MLP: 17-60-40-1                           1.162645  0.744006  0.636284   \n",
       "MLP: 17-60-20-1                           1.183051  0.745964  0.629900   \n",
       "MLP: 17-80-50-1                           1.124134  0.712487  0.648332   \n",
       "MLP, small-median: 7-80-50-1              1.313112  0.792845  0.589213   \n",
       "MLP, small-mean: 7-80-50-1                1.274659  0.764669  0.601242   \n",
       "MLP, small-min: 7-80-50-1                 1.344109  0.802782  0.579516   \n",
       "MLP, small-max: 7-80-50-1                 1.202730  0.722136  0.623744   \n",
       "MLP, small-q25: 7-80-50-1                 1.339963  0.802546  0.580813   \n",
       "MLP, small-q75: 7-80-50-1                 1.237934  0.760888  0.612731   \n",
       "MLP, custom: 7-80-50-1                    1.154383  0.717330  0.638869   \n",
       "HGNN: 1-16-32-1                           0.671361  0.475938  0.789975   \n",
       "HGNN: 1-32-16-1                           0.705351  0.506083  0.779342   \n",
       "HGNN: 1-16-32-16-1                        0.661967  0.457578  0.792914   \n",
       "HGNN: 1-32-64-1                           0.657654  0.488402  0.794263   \n",
       "HGNN: 1-4-16-1                            0.716271  0.523176  0.775925   \n",
       "combi: 17-80-50-2/1-32-64-2/4-1           0.555735  0.458384  0.826147   \n",
       "combi: 17-80-50-5/1-32-64-5/10-2          0.565674  0.463923  0.823038   \n",
       "combi: 17-80-50-5/1-32-64-5/10-20-2       0.468850  0.390846  0.853327   \n",
       "combi: 17-80-50-10/1-32-64-10/20-40-2     0.434580  0.370065  0.864048   \n",
       "combi: 17-80-50-10/1-32-64-10/20-60-20-2  0.479359  0.384279  0.850040   \n",
       "\n",
       "                                               MSE       MAE        R2  \n",
       "5-NN                                      0.730049  0.478475  0.757785  \n",
       "Decision tree                             0.612816  0.433778   0.79668  \n",
       "Random forest                              0.61371  0.435071  0.796384  \n",
       "SVM linear                                2.371142  0.929039  0.213305  \n",
       "SVM poly                                   1.81521  0.749433  0.397751  \n",
       "SVM rbf                                   1.666438  0.727603  0.447111  \n",
       "MLP: 17-5-1                                      -         -         -  \n",
       "MLP: 17-10-1                                     -         -         -  \n",
       "MLP: 17-20-1                                     -         -         -  \n",
       "MLP: 17-25-1                                     -         -         -  \n",
       "MLP: 17-40-1                                     -         -         -  \n",
       "MLP: 17-60-1                                     -         -         -  \n",
       "MLP: 17-10-5-1                                   -         -         -  \n",
       "MLP: 17-20-10-1                                  -         -         -  \n",
       "MLP: 17-40-20-1                                  -         -         -  \n",
       "MLP: 17-40-10-1                                  -         -         -  \n",
       "MLP: 17-60-40-1                                  -         -         -  \n",
       "MLP: 17-60-20-1                                  -         -         -  \n",
       "MLP: 17-80-50-1                                  -         -         -  \n",
       "MLP, small-median: 7-80-50-1                     -         -         -  \n",
       "MLP, small-mean: 7-80-50-1                       -         -         -  \n",
       "MLP, small-min: 7-80-50-1                        -         -         -  \n",
       "MLP, small-max: 7-80-50-1                        -         -         -  \n",
       "MLP, small-q25: 7-80-50-1                        -         -         -  \n",
       "MLP, small-q75: 7-80-50-1                        -         -         -  \n",
       "MLP, custom: 7-80-50-1                           -         -         -  \n",
       "HGNN: 1-16-32-1                                  -         -         -  \n",
       "HGNN: 1-32-16-1                                  -         -         -  \n",
       "HGNN: 1-16-32-16-1                               -         -         -  \n",
       "HGNN: 1-32-64-1                                  -         -         -  \n",
       "HGNN: 1-4-16-1                                   -         -         -  \n",
       "combi: 17-80-50-2/1-32-64-2/4-1                  -         -         -  \n",
       "combi: 17-80-50-5/1-32-64-5/10-2                 -         -         -  \n",
       "combi: 17-80-50-5/1-32-64-5/10-20-2              -         -         -  \n",
       "combi: 17-80-50-10/1-32-64-10/20-40-2            -         -         -  \n",
       "combi: 17-80-50-10/1-32-64-10/20-60-20-2         -         -         -  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "84c4b322-8edd-4a65-9408-1ddbe72a45e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2237103/2575078847.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  table_time_diff = table_time_diff.applymap(round_if_number)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.6731</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.7894</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>0.7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.5790</td>\n",
       "      <td>0.3907</td>\n",
       "      <td>0.8189</td>\n",
       "      <td>0.6128</td>\n",
       "      <td>0.4338</td>\n",
       "      <td>0.7967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.5846</td>\n",
       "      <td>0.3921</td>\n",
       "      <td>0.8171</td>\n",
       "      <td>0.6137</td>\n",
       "      <td>0.4351</td>\n",
       "      <td>0.7964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>2.3233</td>\n",
       "      <td>0.9073</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>2.3711</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.7783</td>\n",
       "      <td>0.7199</td>\n",
       "      <td>0.4437</td>\n",
       "      <td>1.8152</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.3978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.6123</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.6664</td>\n",
       "      <td>0.7276</td>\n",
       "      <td>0.4471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-1</th>\n",
       "      <td>1.3860</td>\n",
       "      <td>0.8405</td>\n",
       "      <td>0.5664</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-1</th>\n",
       "      <td>1.5114</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>0.5272</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-1</th>\n",
       "      <td>1.4429</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-1</th>\n",
       "      <td>1.3431</td>\n",
       "      <td>0.8216</td>\n",
       "      <td>0.5798</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-1</th>\n",
       "      <td>1.3479</td>\n",
       "      <td>0.8209</td>\n",
       "      <td>0.5783</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-1</th>\n",
       "      <td>1.3885</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.5656</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-1</th>\n",
       "      <td>1.3602</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-1</th>\n",
       "      <td>1.2734</td>\n",
       "      <td>0.7911</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-1</th>\n",
       "      <td>1.2859</td>\n",
       "      <td>0.8016</td>\n",
       "      <td>0.5977</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-1</th>\n",
       "      <td>1.2556</td>\n",
       "      <td>0.7963</td>\n",
       "      <td>0.6072</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-1</th>\n",
       "      <td>1.1626</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.6363</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-1</th>\n",
       "      <td>1.1831</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>0.6299</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-1</th>\n",
       "      <td>1.1241</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.6483</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-1</th>\n",
       "      <td>1.3131</td>\n",
       "      <td>0.7928</td>\n",
       "      <td>0.5892</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-1</th>\n",
       "      <td>1.2747</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.6012</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-1</th>\n",
       "      <td>1.3441</td>\n",
       "      <td>0.8028</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-1</th>\n",
       "      <td>1.2027</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>0.6237</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-1</th>\n",
       "      <td>1.3400</td>\n",
       "      <td>0.8025</td>\n",
       "      <td>0.5808</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-1</th>\n",
       "      <td>1.2379</td>\n",
       "      <td>0.7609</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-1</th>\n",
       "      <td>1.1544</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-1</th>\n",
       "      <td>0.6714</td>\n",
       "      <td>0.4759</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-1</th>\n",
       "      <td>0.7054</td>\n",
       "      <td>0.5061</td>\n",
       "      <td>0.7793</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-1</th>\n",
       "      <td>0.6620</td>\n",
       "      <td>0.4576</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-1</th>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.4884</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-1</th>\n",
       "      <td>0.7163</td>\n",
       "      <td>0.5232</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-2/1-32-64-2/4-1</th>\n",
       "      <td>0.5557</td>\n",
       "      <td>0.4584</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-32-64-5/10-2</th>\n",
       "      <td>0.5657</td>\n",
       "      <td>0.4639</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-32-64-5/10-20-2</th>\n",
       "      <td>0.4688</td>\n",
       "      <td>0.3908</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-32-64-10/20-40-2</th>\n",
       "      <td>0.4346</td>\n",
       "      <td>0.3701</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-32-64-10/20-60-20-2</th>\n",
       "      <td>0.4794</td>\n",
       "      <td>0.3843</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             MSE     MAE      R2     MSE  \\\n",
       "5-NN                                      0.6731  0.4426  0.7894    0.73   \n",
       "Decision tree                             0.5790  0.3907  0.8189  0.6128   \n",
       "Random forest                             0.5846  0.3921  0.8171  0.6137   \n",
       "SVM linear                                2.3233  0.9073  0.2732  2.3711   \n",
       "SVM poly                                  1.7783  0.7199  0.4437  1.8152   \n",
       "SVM rbf                                   1.6123  0.6921  0.4956  1.6664   \n",
       "MLP: 17-5-1                               1.3860  0.8405  0.5664       -   \n",
       "MLP: 17-10-1                              1.5114  0.8752  0.5272       -   \n",
       "MLP: 17-20-1                              1.4429  0.8592  0.5486       -   \n",
       "MLP: 17-25-1                              1.3431  0.8216  0.5798       -   \n",
       "MLP: 17-40-1                              1.3479  0.8209  0.5783       -   \n",
       "MLP: 17-60-1                              1.3885  0.8295  0.5656       -   \n",
       "MLP: 17-10-5-1                            1.3602  0.8230  0.5745       -   \n",
       "MLP: 17-20-10-1                           1.2734  0.7911  0.6016       -   \n",
       "MLP: 17-40-20-1                           1.2859  0.8016  0.5977       -   \n",
       "MLP: 17-40-10-1                           1.2556  0.7963  0.6072       -   \n",
       "MLP: 17-60-40-1                           1.1626  0.7440  0.6363       -   \n",
       "MLP: 17-60-20-1                           1.1831  0.7460  0.6299       -   \n",
       "MLP: 17-80-50-1                           1.1241  0.7125  0.6483       -   \n",
       "MLP, small-median: 7-80-50-1              1.3131  0.7928  0.5892       -   \n",
       "MLP, small-mean: 7-80-50-1                1.2747  0.7647  0.6012       -   \n",
       "MLP, small-min: 7-80-50-1                 1.3441  0.8028  0.5795       -   \n",
       "MLP, small-max: 7-80-50-1                 1.2027  0.7221  0.6237       -   \n",
       "MLP, small-q25: 7-80-50-1                 1.3400  0.8025  0.5808       -   \n",
       "MLP, small-q75: 7-80-50-1                 1.2379  0.7609  0.6127       -   \n",
       "MLP, custom: 7-80-50-1                    1.1544  0.7173  0.6389       -   \n",
       "HGNN: 1-16-32-1                           0.6714  0.4759  0.7900       -   \n",
       "HGNN: 1-32-16-1                           0.7054  0.5061  0.7793       -   \n",
       "HGNN: 1-16-32-16-1                        0.6620  0.4576  0.7929       -   \n",
       "HGNN: 1-32-64-1                           0.6577  0.4884  0.7943       -   \n",
       "HGNN: 1-4-16-1                            0.7163  0.5232  0.7759       -   \n",
       "combi: 17-80-50-2/1-32-64-2/4-1           0.5557  0.4584  0.8261       -   \n",
       "combi: 17-80-50-5/1-32-64-5/10-2          0.5657  0.4639  0.8230       -   \n",
       "combi: 17-80-50-5/1-32-64-5/10-20-2       0.4688  0.3908  0.8533       -   \n",
       "combi: 17-80-50-10/1-32-64-10/20-40-2     0.4346  0.3701  0.8640       -   \n",
       "combi: 17-80-50-10/1-32-64-10/20-60-20-2  0.4794  0.3843  0.8500       -   \n",
       "\n",
       "                                             MAE      R2  \n",
       "5-NN                                      0.4785  0.7578  \n",
       "Decision tree                             0.4338  0.7967  \n",
       "Random forest                             0.4351  0.7964  \n",
       "SVM linear                                 0.929  0.2133  \n",
       "SVM poly                                  0.7494  0.3978  \n",
       "SVM rbf                                   0.7276  0.4471  \n",
       "MLP: 17-5-1                                    -       -  \n",
       "MLP: 17-10-1                                   -       -  \n",
       "MLP: 17-20-1                                   -       -  \n",
       "MLP: 17-25-1                                   -       -  \n",
       "MLP: 17-40-1                                   -       -  \n",
       "MLP: 17-60-1                                   -       -  \n",
       "MLP: 17-10-5-1                                 -       -  \n",
       "MLP: 17-20-10-1                                -       -  \n",
       "MLP: 17-40-20-1                                -       -  \n",
       "MLP: 17-40-10-1                                -       -  \n",
       "MLP: 17-60-40-1                                -       -  \n",
       "MLP: 17-60-20-1                                -       -  \n",
       "MLP: 17-80-50-1                                -       -  \n",
       "MLP, small-median: 7-80-50-1                   -       -  \n",
       "MLP, small-mean: 7-80-50-1                     -       -  \n",
       "MLP, small-min: 7-80-50-1                      -       -  \n",
       "MLP, small-max: 7-80-50-1                      -       -  \n",
       "MLP, small-q25: 7-80-50-1                      -       -  \n",
       "MLP, small-q75: 7-80-50-1                      -       -  \n",
       "MLP, custom: 7-80-50-1                         -       -  \n",
       "HGNN: 1-16-32-1                                -       -  \n",
       "HGNN: 1-32-16-1                                -       -  \n",
       "HGNN: 1-16-32-16-1                             -       -  \n",
       "HGNN: 1-32-64-1                                -       -  \n",
       "HGNN: 1-4-16-1                                 -       -  \n",
       "combi: 17-80-50-2/1-32-64-2/4-1                -       -  \n",
       "combi: 17-80-50-5/1-32-64-5/10-2               -       -  \n",
       "combi: 17-80-50-5/1-32-64-5/10-20-2            -       -  \n",
       "combi: 17-80-50-10/1-32-64-10/20-40-2          -       -  \n",
       "combi: 17-80-50-10/1-32-64-10/20-60-20-2       -       -  "
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def round_if_number(x):\n",
    "    try:\n",
    "        return round(float(x), 4)\n",
    "    except ValueError:\n",
    "        return x\n",
    "\n",
    "table_time_diff = table_time_diff.applymap(round_if_number)\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "05502976-89c7-4b69-8407-88c18b7bb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_time_diff.to_csv('results/table_time_diff_SPA_rounded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc2c36-bbcd-4c9c-bcfa-9a69d07cff09",
   "metadata": {},
   "source": [
    "## Performance of regression version as decision program with split into the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4675f3-6a50-4f71-a08e-7b3f97bac9a7",
   "metadata": {},
   "source": [
    "In the regression case, we still need to provide a splitting value if we want to use it as prediction model for our purpose (if we should use the original or rewritten version). Here we provide three different splitting values (0.5,0.1,0.01) and the corresponding accuracy and misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "598664ac-6014-4763-87c5-d79a1a36a6ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.5665\n",
      "Validation Loss: 0.9333\n",
      "Saved the best model with validation loss: 0.9333\n",
      "Epoch [2/100], Loss: 0.8933\n",
      "Validation Loss: 0.8332\n",
      "Saved the best model with validation loss: 0.8332\n",
      "Epoch [3/100], Loss: 0.7606\n",
      "Validation Loss: 0.7836\n",
      "Saved the best model with validation loss: 0.7836\n",
      "Epoch [4/100], Loss: 0.6928\n",
      "Validation Loss: 0.7259\n",
      "Saved the best model with validation loss: 0.7259\n",
      "Epoch [5/100], Loss: 0.6583\n",
      "Validation Loss: 0.6825\n",
      "Saved the best model with validation loss: 0.6825\n",
      "Epoch [6/100], Loss: 0.6208\n",
      "Validation Loss: 0.6551\n",
      "Saved the best model with validation loss: 0.6551\n",
      "Epoch [7/100], Loss: 0.5956\n",
      "Validation Loss: 0.6091\n",
      "Saved the best model with validation loss: 0.6091\n",
      "Epoch [8/100], Loss: 0.5768\n",
      "Validation Loss: 0.5474\n",
      "Saved the best model with validation loss: 0.5474\n",
      "Epoch [9/100], Loss: 0.5604\n",
      "Validation Loss: 0.5315\n",
      "Saved the best model with validation loss: 0.5315\n",
      "Epoch [10/100], Loss: 0.5494\n",
      "Validation Loss: 0.5226\n",
      "Saved the best model with validation loss: 0.5226\n",
      "Epoch [11/100], Loss: 0.5347\n",
      "Validation Loss: 0.5014\n",
      "Saved the best model with validation loss: 0.5014\n",
      "Epoch [12/100], Loss: 0.5439\n",
      "Validation Loss: 0.5017\n",
      "Epoch [13/100], Loss: 0.5208\n",
      "Validation Loss: 0.5077\n",
      "Epoch [14/100], Loss: 0.5150\n",
      "Validation Loss: 0.5137\n",
      "Epoch [15/100], Loss: 0.5123\n",
      "Validation Loss: 0.5107\n",
      "Epoch [16/100], Loss: 0.5004\n",
      "Validation Loss: 0.4953\n",
      "Saved the best model with validation loss: 0.4953\n",
      "Epoch [17/100], Loss: 0.5007\n",
      "Validation Loss: 0.5008\n",
      "Epoch [18/100], Loss: 0.4894\n",
      "Validation Loss: 0.5037\n",
      "Epoch [19/100], Loss: 0.4920\n",
      "Validation Loss: 0.4968\n",
      "Epoch [20/100], Loss: 0.4842\n",
      "Validation Loss: 0.5109\n",
      "Epoch [21/100], Loss: 0.4857\n",
      "Validation Loss: 0.4911\n",
      "Saved the best model with validation loss: 0.4911\n",
      "Epoch [22/100], Loss: 0.4817\n",
      "Validation Loss: 0.5158\n",
      "Epoch [23/100], Loss: 0.4799\n",
      "Validation Loss: 0.4917\n",
      "Epoch [24/100], Loss: 0.4889\n",
      "Validation Loss: 0.5086\n",
      "Epoch [25/100], Loss: 0.4844\n",
      "Validation Loss: 0.4979\n",
      "Epoch [26/100], Loss: 0.4772\n",
      "Validation Loss: 0.4973\n",
      "Epoch [27/100], Loss: 0.4715\n",
      "Validation Loss: 0.5116\n",
      "Epoch [28/100], Loss: 0.4744\n",
      "Validation Loss: 0.5342\n",
      "Epoch [29/100], Loss: 0.4676\n",
      "Validation Loss: 0.4962\n",
      "Epoch [30/100], Loss: 0.4679\n",
      "Validation Loss: 0.5098\n",
      "Epoch [31/100], Loss: 0.4657\n",
      "Validation Loss: 0.4963\n",
      "Epoch [32/100], Loss: 0.4667\n",
      "Validation Loss: 0.5032\n",
      "Epoch [33/100], Loss: 0.4624\n",
      "Validation Loss: 0.5084\n",
      "Epoch [34/100], Loss: 0.4607\n",
      "Validation Loss: 0.5084\n",
      "Epoch [35/100], Loss: 0.4621\n",
      "Validation Loss: 0.5045\n",
      "Epoch [36/100], Loss: 0.4580\n",
      "Validation Loss: 0.4967\n",
      "Epoch [37/100], Loss: 0.4598\n",
      "Validation Loss: 0.4929\n",
      "Epoch [38/100], Loss: 0.4600\n",
      "Validation Loss: 0.4981\n",
      "Epoch [39/100], Loss: 0.4563\n",
      "Validation Loss: 0.4935\n",
      "Epoch [40/100], Loss: 0.4589\n",
      "Validation Loss: 0.4874\n",
      "Saved the best model with validation loss: 0.4874\n",
      "Epoch [41/100], Loss: 0.4528\n",
      "Validation Loss: 0.5030\n",
      "Epoch [42/100], Loss: 0.4519\n",
      "Validation Loss: 0.4844\n",
      "Saved the best model with validation loss: 0.4844\n",
      "Epoch [43/100], Loss: 0.4479\n",
      "Validation Loss: 0.4986\n",
      "Epoch [44/100], Loss: 0.4484\n",
      "Validation Loss: 0.4932\n",
      "Epoch [45/100], Loss: 0.4524\n",
      "Validation Loss: 0.4851\n",
      "Epoch [46/100], Loss: 0.4492\n",
      "Validation Loss: 0.4818\n",
      "Saved the best model with validation loss: 0.4818\n",
      "Epoch [47/100], Loss: 0.4470\n",
      "Validation Loss: 0.4943\n",
      "Epoch [48/100], Loss: 0.4479\n",
      "Validation Loss: 0.4910\n",
      "Epoch [49/100], Loss: 0.4544\n",
      "Validation Loss: 0.4972\n",
      "Epoch [50/100], Loss: 0.4444\n",
      "Validation Loss: 0.4890\n",
      "Epoch [51/100], Loss: 0.4453\n",
      "Validation Loss: 0.4761\n",
      "Saved the best model with validation loss: 0.4761\n",
      "Epoch [52/100], Loss: 0.4510\n",
      "Validation Loss: 0.5161\n",
      "Epoch [53/100], Loss: 0.4474\n",
      "Validation Loss: 0.4727\n",
      "Saved the best model with validation loss: 0.4727\n",
      "Epoch [54/100], Loss: 0.4416\n",
      "Validation Loss: 0.4898\n",
      "Epoch [55/100], Loss: 0.4402\n",
      "Validation Loss: 0.5115\n",
      "Epoch [56/100], Loss: 0.4413\n",
      "Validation Loss: 0.4926\n",
      "Epoch [57/100], Loss: 0.4464\n",
      "Validation Loss: 0.4810\n",
      "Epoch [58/100], Loss: 0.4443\n",
      "Validation Loss: 0.4860\n",
      "Epoch [59/100], Loss: 0.4420\n",
      "Validation Loss: 0.4892\n",
      "Epoch [60/100], Loss: 0.4394\n",
      "Validation Loss: 0.4878\n",
      "Epoch [61/100], Loss: 0.4411\n",
      "Validation Loss: 0.4752\n",
      "Epoch [62/100], Loss: 0.4428\n",
      "Validation Loss: 0.4828\n",
      "Epoch [63/100], Loss: 0.4395\n",
      "Validation Loss: 0.4727\n",
      "Saved the best model with validation loss: 0.4727\n",
      "Epoch [64/100], Loss: 0.4382\n",
      "Validation Loss: 0.4624\n",
      "Saved the best model with validation loss: 0.4624\n",
      "Epoch [65/100], Loss: 0.4390\n",
      "Validation Loss: 0.4706\n",
      "Epoch [66/100], Loss: 0.4366\n",
      "Validation Loss: 0.4687\n",
      "Epoch [67/100], Loss: 0.4354\n",
      "Validation Loss: 0.4717\n",
      "Epoch [68/100], Loss: 0.4366\n",
      "Validation Loss: 0.4746\n",
      "Epoch [69/100], Loss: 0.4377\n",
      "Validation Loss: 0.4889\n",
      "Epoch [70/100], Loss: 0.4357\n",
      "Validation Loss: 0.4902\n",
      "Epoch [71/100], Loss: 0.4393\n",
      "Validation Loss: 0.4794\n",
      "Epoch [72/100], Loss: 0.4340\n",
      "Validation Loss: 0.4698\n",
      "Epoch [73/100], Loss: 0.4379\n",
      "Validation Loss: 0.5080\n",
      "Epoch [74/100], Loss: 0.4338\n",
      "Validation Loss: 0.4986\n",
      "Epoch [75/100], Loss: 0.4318\n",
      "Validation Loss: 0.4895\n",
      "Epoch [76/100], Loss: 0.4337\n",
      "Validation Loss: 0.5081\n",
      "Epoch [77/100], Loss: 0.4381\n",
      "Validation Loss: 0.4816\n",
      "Epoch [78/100], Loss: 0.4320\n",
      "Validation Loss: 0.4853\n",
      "Epoch [79/100], Loss: 0.4326\n",
      "Validation Loss: 0.4843\n",
      "Epoch [80/100], Loss: 0.4316\n",
      "Validation Loss: 0.5087\n",
      "Epoch [81/100], Loss: 0.4323\n",
      "Validation Loss: 0.4978\n",
      "Epoch [82/100], Loss: 0.4311\n",
      "Validation Loss: 0.4692\n",
      "Epoch [83/100], Loss: 0.4297\n",
      "Validation Loss: 0.4692\n",
      "Epoch [84/100], Loss: 0.4322\n",
      "Validation Loss: 0.4819\n",
      "Epoch [85/100], Loss: 0.4300\n",
      "Validation Loss: 0.4728\n",
      "Epoch [86/100], Loss: 0.4335\n",
      "Validation Loss: 0.4870\n",
      "Epoch [87/100], Loss: 0.4377\n",
      "Validation Loss: 0.4522\n",
      "Saved the best model with validation loss: 0.4522\n",
      "Epoch [88/100], Loss: 0.4312\n",
      "Validation Loss: 0.4484\n",
      "Saved the best model with validation loss: 0.4484\n",
      "Epoch [89/100], Loss: 0.4317\n",
      "Validation Loss: 0.4346\n",
      "Saved the best model with validation loss: 0.4346\n",
      "Epoch [90/100], Loss: 0.4319\n",
      "Validation Loss: 0.4668\n",
      "Epoch [91/100], Loss: 0.4315\n",
      "Validation Loss: 0.4642\n",
      "Epoch [92/100], Loss: 0.4286\n",
      "Validation Loss: 0.4574\n",
      "Epoch [93/100], Loss: 0.4273\n",
      "Validation Loss: 0.4675\n",
      "Epoch [94/100], Loss: 0.4296\n",
      "Validation Loss: 0.4712\n",
      "Epoch [95/100], Loss: 0.4275\n",
      "Validation Loss: 0.4597\n",
      "Epoch [96/100], Loss: 0.4270\n",
      "Validation Loss: 0.4590\n",
      "Epoch [97/100], Loss: 0.4274\n",
      "Validation Loss: 0.4634\n",
      "Epoch [98/100], Loss: 0.4295\n",
      "Validation Loss: 0.4645\n",
      "Epoch [99/100], Loss: 0.4256\n",
      "Validation Loss: 0.4572\n",
      "Epoch [100/100], Loss: 0.4243\n",
      "Validation Loss: 0.4503\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>Bad misc.</th>\n",
       "      <th>All misc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dec. Tree (0.5)</th>\n",
       "      <td>79.52</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dec. Tree (0.1)</th>\n",
       "      <td>84.98</td>\n",
       "      <td>20</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dec. Tree (0.01)</th>\n",
       "      <td>83.62</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rand. Forest (0.5)</th>\n",
       "      <td>79.52</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rand. Forest (0.1)</th>\n",
       "      <td>84.64</td>\n",
       "      <td>21</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rand. Forest (0.01)</th>\n",
       "      <td>83.62</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combi (0.5)</th>\n",
       "      <td>78.84</td>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combi (0.1)</th>\n",
       "      <td>81.91</td>\n",
       "      <td>27</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combi (0.01)</th>\n",
       "      <td>75.77</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Acc  Bad misc.  All misc.\n",
       "Dec. Tree (0.5)      79.52         13         60\n",
       "Dec. Tree (0.1)      84.98         20         44\n",
       "Dec. Tree (0.01)     83.62         30         48\n",
       "Rand. Forest (0.5)   79.52         13         60\n",
       "Rand. Forest (0.1)   84.64         21         45\n",
       "Rand. Forest (0.01)  83.62         30         48\n",
       "Combi (0.5)          78.84          8         62\n",
       "Combi (0.1)          81.91         27         53\n",
       "Combi (0.01)         75.77         59         71"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_reg_class = pd.DataFrame(columns=['Acc', 'Bad misc.', 'All misc.'])\n",
    "\n",
    "model = DecisionTreeRegressor(random_state = 20)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_dec_tree_reg = model.predict(X_val)\n",
    "\n",
    "y1_pred_dec_tree_class = (y1_pred_dec_tree_reg < np.sign(-0.5)*np.log(abs(-0.5)+1)).astype(int)\n",
    "accuracy = round(accuracy_score(y1_val, y1_pred_dec_tree_class),4)*100\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_dec_tree_class)\n",
    "table_reg_class.loc[\"Dec. Tree (0.5)\"] = [accuracy, conf_matrix[0][1], conf_matrix[0][1]+conf_matrix[1][0]]\n",
    "\n",
    "y1_pred_dec_tree_class = (y1_pred_dec_tree_reg < np.sign(-0.1)*np.log(abs(-0.1)+1)).astype(int)\n",
    "accuracy = round(accuracy_score(y1_val, y1_pred_dec_tree_class),4)*100\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_dec_tree_class)\n",
    "table_reg_class.loc[\"Dec. Tree (0.1)\"] = [accuracy, conf_matrix[0][1], conf_matrix[0][1]+conf_matrix[1][0]]\n",
    "\n",
    "y1_pred_dec_tree_class = (y1_pred_dec_tree_reg < np.sign(-0.01)*np.log(abs(-0.01)+1)).astype(int)\n",
    "accuracy = round(accuracy_score(y1_val, y1_pred_dec_tree_class),4)*100\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_dec_tree_class)\n",
    "table_reg_class.loc[\"Dec. Tree (0.01)\"] = [accuracy, conf_matrix[0][1], conf_matrix[0][1]+conf_matrix[1][0]]\n",
    "\n",
    "model = RandomForestRegressor(random_state = 20)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_rand_forest_reg = model.predict(X_val)\n",
    "\n",
    "y1_pred_rand_forest_class = (y1_pred_rand_forest_reg < np.sign(-0.5)*np.log(abs(-0.5)+1)).astype(int)\n",
    "accuracy = round(accuracy_score(y1_val, y1_pred_rand_forest_class),4)*100\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_rand_forest_class)\n",
    "table_reg_class.loc[\"Rand. Forest (0.5)\"] = [accuracy, conf_matrix[0][1], conf_matrix[0][1]+conf_matrix[1][0]]\n",
    "\n",
    "y1_pred_rand_forest_class = (y1_pred_rand_forest_reg < np.sign(-0.1)*np.log(abs(-0.1)+1)).astype(int)\n",
    "accuracy = round(accuracy_score(y1_val, y1_pred_rand_forest_class),4)*100\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_rand_forest_class)\n",
    "table_reg_class.loc[\"Rand. Forest (0.1)\"] = [accuracy, conf_matrix[0][1], conf_matrix[0][1]+conf_matrix[1][0]]\n",
    "\n",
    "y1_pred_rand_forest_class = (y1_pred_rand_forest_reg < np.sign(-0.01)*np.log(abs(-0.01)+1)).astype(int)\n",
    "accuracy = round(accuracy_score(y1_val, y1_pred_rand_forest_class),4)*100\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_rand_forest_class)\n",
    "table_reg_class.loc[\"Rand. Forest (0.01)\"] = [accuracy, conf_matrix[0][1], conf_matrix[0][1]+conf_matrix[1][0]]\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, label_series, hypergraph_column_name):\n",
    "        # Extract features and convert to tensor\n",
    "        self.X = torch.from_numpy(dataframe.drop(columns=[hypergraph_column_name]).values).float()\n",
    "        \n",
    "        # Extract labels and convert to tensor\n",
    "        self.y = torch.from_numpy(label_series.values).float()\n",
    "        \n",
    "        # Store hypergraph objects\n",
    "        self.hypergraphs = dataframe[hypergraph_column_name].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.X[index],\n",
    "            'label': self.y[index],\n",
    "            'hypergraph': self.hypergraphs[index]\n",
    "        }\n",
    "\n",
    "def combined_regression(X_training, y_training, X_validation, y_validation, text):\n",
    "    model = CombinedNetwork(random_seed = 20)  \n",
    "\n",
    "    dataset = CustomDataset(X_training, y_training, hypergraph_column_name='hypergraph')\n",
    "    validation = CustomDataset(X_validation, y_validation, hypergraph_column_name='hypergraph')\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for item in dataset:\n",
    "            optimizer.zero_grad()\n",
    "            input_features = item[\"data\"]\n",
    "            input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "            label = item[\"label\"].float().unsqueeze(0)\n",
    "            #print(label.size())\n",
    "            output = model(input_features, input_hg)\n",
    "\n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataset):.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for item in validation:\n",
    "                input_features = item[\"data\"]\n",
    "                input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "                label = item[\"label\"].float().unsqueeze(0)\n",
    "                output = model(input_features, input_hg)\n",
    "                loss = loss_function(output, label)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(validation)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Save the model if the validation loss is the best we've seen so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Saved the best model with validation loss: {val_loss:.4f}')\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for item in validation:\n",
    "            i += 1\n",
    "            output = model(item[\"data\"], item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0))\n",
    "            predicted.append(output.item())\n",
    "\n",
    "    return predicted\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output\n",
    "\n",
    "y1_pred_combi_reg = combined_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"combi: 17-80-50-10/1-32-64-10/20-40-1\")\n",
    "\n",
    "y1_pred_combi_class = (y1_pred_combi_reg < np.sign(-0.5)*np.log(abs(-0.5)+1)).astype(int)\n",
    "accuracy = round(accuracy_score(y1_val, y1_pred_combi_class),4)*100\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_combi_class)\n",
    "table_reg_class.loc[\"Combi (0.5)\"] = [accuracy, conf_matrix[0][1], conf_matrix[0][1]+conf_matrix[1][0]]\n",
    "\n",
    "y1_pred_combi_class = (y1_pred_combi_reg < np.sign(-0.1)*np.log(abs(-0.1)+1)).astype(int)\n",
    "accuracy = round(accuracy_score(y1_val, y1_pred_combi_class),4)*100\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_combi_class)\n",
    "table_reg_class.loc[\"Combi (0.1)\"] = [accuracy, conf_matrix[0][1], conf_matrix[0][1]+conf_matrix[1][0]]\n",
    "\n",
    "y1_pred_combi_class = (y1_pred_combi_reg < np.sign(-0.01)*np.log(abs(-0.01)+1)).astype(int)\n",
    "accuracy = round(accuracy_score(y1_val, y1_pred_combi_class),4)*100\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_combi_class)\n",
    "table_reg_class.loc[\"Combi (0.01)\"] = [accuracy, conf_matrix[0][1], conf_matrix[0][1]+conf_matrix[1][0]]\n",
    "\n",
    "table_reg_class[\"Bad misc.\"] = table_reg_class[\"Bad misc.\"].astype(int)\n",
    "table_reg_class[\"All misc.\"] = table_reg_class[\"All misc.\"].astype(int)\n",
    "table_reg_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43911344-0e24-4cfe-86a9-407a4aaeb60b",
   "metadata": {},
   "source": [
    "## Inspection of the misclassifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59f235-23d6-4dcc-beb2-aedb9b047af1",
   "metadata": {},
   "source": [
    "For the decision tree, random forest and combi: MLP+HGNN (best version) we inspect the misclassifications. We look at how many samples were misclassified and if they are FP (false positives) or FN (false negatives). Additionally, we check how much the runtimes differ in the misclassification cases (if it is wrongly classified, but the runtimes are nearly the same anyway, we do not care so much) and we look at the accuracy, precision, recall and confusion matrix of these models.\n",
    "\n",
    "Since most importantly we do not want to classify queries, which have a faster original runtime as rewritten, we want to avoid FP.  \n",
    "(original = 0, rewritten = 1: if true = 0 and pred = 1 -> FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb6e2942-043a-4f3f-98ff-ceb5ab2b1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "545d56f1-9819-4e10-ac3c-a61fbd5615f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8361774744027304\n",
      "0.8676470588235294\n",
      "0.7972972972972973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[127,  18],\n",
       "       [ 30, 118]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_dec_tree)\n",
    "print(accuracy)\n",
    "precision = precision_score(y1_val, y1_pred_dec_tree)\n",
    "print(precision)\n",
    "recall = recall_score(y1_val, y1_pred_dec_tree)\n",
    "print(recall)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b31ec3e0-118a-42a5-996b-f136bff67246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred label</th>\n",
       "      <th>true label</th>\n",
       "      <th>bench</th>\n",
       "      <th>query</th>\n",
       "      <th>orig/rewr(mean)</th>\n",
       "      <th>orig/rewr+rewr(mean)</th>\n",
       "      <th>orig mean</th>\n",
       "      <th>rewr mean</th>\n",
       "      <th>rewr mean+rewr</th>\n",
       "      <th>diff rewr-orig</th>\n",
       "      <th>...</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <th>balancedness factor</th>\n",
       "      <th>container counts list</th>\n",
       "      <th>branching factors list</th>\n",
       "      <th>hypergraph</th>\n",
       "      <th>text</th>\n",
       "      <th>orig/rewr/equal 0.5</th>\n",
       "      <th>orig/rewr/equal 0.1</th>\n",
       "      <th>orig/rewr/equal 0.05</th>\n",
       "      <th>orig/rewr/equal 0.01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>111-056-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.596748</td>\n",
       "      <td>0.532240</td>\n",
       "      <td>2.328231</td>\n",
       "      <td>-0.064508</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=28, num_e=5)</td>\n",
       "      <td>SELECT MIN(p.id) FROM tags as t, posts as p, u...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-08-CpDpCtD-augA5</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.184137</td>\n",
       "      <td>0.300639</td>\n",
       "      <td>2.454935</td>\n",
       "      <td>0.116503</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(t.sid) FROM compound c1, palliates ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-16-CtDuGuD-augA6</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.574174</td>\n",
       "      <td>0.586411</td>\n",
       "      <td>2.638695</td>\n",
       "      <td>0.012236</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(d2.nid) FROM compound c1, treats t,...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>104-088-augF2-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.215694</td>\n",
       "      <td>0.275453</td>\n",
       "      <td>1.273657</td>\n",
       "      <td>0.059759</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=3)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, badges as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>2-05-CuGdD-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.557119</td>\n",
       "      <td>0.539519</td>\n",
       "      <td>2.760506</td>\n",
       "      <td>-0.017600</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(g.nid) FROM compound c, upregulates...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>023-018-augF2-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.283540</td>\n",
       "      <td>0.270736</td>\n",
       "      <td>2.124599</td>\n",
       "      <td>-0.012804</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=3)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM posts as p, postLinks a...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>110-138-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.481653</td>\n",
       "      <td>0.459576</td>\n",
       "      <td>1.484276</td>\n",
       "      <td>-0.022076</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=28, num_e=5)</td>\n",
       "      <td>SELECT MIN(v.id) FROM tags as t, posts as p, u...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>137-141-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>5.530137</td>\n",
       "      <td>0.724227</td>\n",
       "      <td>2.626288</td>\n",
       "      <td>-4.805910</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 1]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>9-07-DuGcGpMF-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>1.934141</td>\n",
       "      <td>2.029559</td>\n",
       "      <td>4.014254</td>\n",
       "      <td>0.095418</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(g2.nid) FROM disease d, upregulates...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-09-CrCrCtD-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.315867</td>\n",
       "      <td>0.331699</td>\n",
       "      <td>2.236466</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(r1.sid) FROM compound c1, resembles...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>101-043-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.314957</td>\n",
       "      <td>0.265431</td>\n",
       "      <td>2.169154</td>\n",
       "      <td>-0.049526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=24, num_e=4)</td>\n",
       "      <td>SELECT MIN(b.id) FROM postHistory as ph, posts...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>137-141-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>5.530431</td>\n",
       "      <td>0.792268</td>\n",
       "      <td>2.848849</td>\n",
       "      <td>-4.738162</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 1]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, posts as...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>wiki-tree01-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>47.316149</td>\n",
       "      <td>49.300901</td>\n",
       "      <td>-52.683851</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(p4b.fromnode) FROM wiki p1, wiki p2...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>098-124-augF1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.496431</td>\n",
       "      <td>0.489113</td>\n",
       "      <td>1.590290</td>\n",
       "      <td>-0.007318</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=4)</td>\n",
       "      <td>SELECT MIN(ph.Id) FROM postHistory as ph, vote...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>093-075-augF2-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.669017</td>\n",
       "      <td>0.667051</td>\n",
       "      <td>2.649943</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, posts as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>137-141</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>5.258001</td>\n",
       "      <td>0.825190</td>\n",
       "      <td>2.791115</td>\n",
       "      <td>-4.432811</td>\n",
       "      <td>...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-08-CpDpCtD-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.190571</td>\n",
       "      <td>0.293480</td>\n",
       "      <td>2.259293</td>\n",
       "      <td>0.102909</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(c2.nid) FROM compound c1, palliates...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>096-095-augF1-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.605563</td>\n",
       "      <td>0.587985</td>\n",
       "      <td>2.769054</td>\n",
       "      <td>-0.017578</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=26, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>JOB</td>\n",
       "      <td>17e-augF1-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>62.264197</td>\n",
       "      <td>64.633271</td>\n",
       "      <td>66.638959</td>\n",
       "      <td>2.369074</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>Hypergraph(num_v=46, num_e=7)</td>\n",
       "      <td>SELECT MIN(mc.id) AS member_in_charnamed_movie...</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>075-037-augF2-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.510466</td>\n",
       "      <td>2.482725</td>\n",
       "      <td>-0.038890</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=21, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, postLinks...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>139-034-augF1-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.187277</td>\n",
       "      <td>0.375633</td>\n",
       "      <td>2.325579</td>\n",
       "      <td>0.188355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, votes as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>078-082-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.428752</td>\n",
       "      <td>0.477420</td>\n",
       "      <td>2.450607</td>\n",
       "      <td>0.048668</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=3)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>086-083-augF2-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.439631</td>\n",
       "      <td>0.443599</td>\n",
       "      <td>2.432668</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=3)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>079-112-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.602283</td>\n",
       "      <td>0.576377</td>\n",
       "      <td>2.642454</td>\n",
       "      <td>-0.025906</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=31, num_e=5)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, postLink...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>074-072-augF1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.620385</td>\n",
       "      <td>0.611789</td>\n",
       "      <td>1.680814</td>\n",
       "      <td>-0.008595</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>Hypergraph(num_v=34, num_e=6)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>064-116-augF2-augA3</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.312055</td>\n",
       "      <td>2.550724</td>\n",
       "      <td>0.066645</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=19, num_e=4)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>8-01-CCpGdCcSE-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.157892</td>\n",
       "      <td>2.260612</td>\n",
       "      <td>4.226928</td>\n",
       "      <td>0.102720</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(c.nid) FROM cellular_component cc, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>108-060-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.605470</td>\n",
       "      <td>0.528589</td>\n",
       "      <td>2.401235</td>\n",
       "      <td>-0.076881</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>6-01-BPpGeA-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.284644</td>\n",
       "      <td>2.003512</td>\n",
       "      <td>3.956240</td>\n",
       "      <td>-0.281132</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(e.sid) FROM biological_process bp, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>dblp-tree01-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.059813</td>\n",
       "      <td>4.357800</td>\n",
       "      <td>-97.940187</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(p4b.fromnode) FROM dblp p1, dblp p2...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>125-051-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.396640</td>\n",
       "      <td>0.456243</td>\n",
       "      <td>1.497873</td>\n",
       "      <td>0.059602</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>023-018-augF1-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.458169</td>\n",
       "      <td>0.385003</td>\n",
       "      <td>2.186201</td>\n",
       "      <td>-0.073166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=3)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM posts as p, postLinks a...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>8-01-CCpGdCcSE-augF2-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.071347</td>\n",
       "      <td>2.062725</td>\n",
       "      <td>4.075672</td>\n",
       "      <td>-0.008622</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(d.sid) FROM cellular_component cc, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>013-055-augF2-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.465446</td>\n",
       "      <td>0.460443</td>\n",
       "      <td>1.434189</td>\n",
       "      <td>-0.005003</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=5)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM tags as t, posts as p, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>130-123-augF2-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.405899</td>\n",
       "      <td>0.468322</td>\n",
       "      <td>2.437323</td>\n",
       "      <td>0.062423</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=24, num_e=4)</td>\n",
       "      <td>SELECT MIN(u.id) FROM postHistory as ph, posts...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>036-100-augF2-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.503076</td>\n",
       "      <td>0.420642</td>\n",
       "      <td>2.365454</td>\n",
       "      <td>-0.082434</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>115-144-augF2-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.614087</td>\n",
       "      <td>0.705318</td>\n",
       "      <td>1.710992</td>\n",
       "      <td>0.091231</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(p.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>055-009-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.497410</td>\n",
       "      <td>0.411260</td>\n",
       "      <td>2.225097</td>\n",
       "      <td>-0.086150</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=3)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, posts as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>117-114-augF2-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.373415</td>\n",
       "      <td>0.364921</td>\n",
       "      <td>1.365446</td>\n",
       "      <td>-0.008494</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=19, num_e=4)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>107-104-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.544392</td>\n",
       "      <td>0.510644</td>\n",
       "      <td>2.470447</td>\n",
       "      <td>-0.033748</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=22, num_e=4)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>040-101-augF1-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.570664</td>\n",
       "      <td>0.452450</td>\n",
       "      <td>2.678936</td>\n",
       "      <td>-0.118214</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>050-106-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.306332</td>\n",
       "      <td>0.504485</td>\n",
       "      <td>2.638419</td>\n",
       "      <td>0.198153</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=22, num_e=4)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-03-CbGiGaD2-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.552251</td>\n",
       "      <td>0.581946</td>\n",
       "      <td>2.635486</td>\n",
       "      <td>0.029695</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(g2.nid) FROM compound c1, binds b1,...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>101-043</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.406486</td>\n",
       "      <td>0.263467</td>\n",
       "      <td>2.132344</td>\n",
       "      <td>-0.143019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=24, num_e=4)</td>\n",
       "      <td>SELECT MIN(ph.Id) FROM postHistory as ph, post...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>121-097-augF1-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.238843</td>\n",
       "      <td>0.435648</td>\n",
       "      <td>2.658918</td>\n",
       "      <td>0.196805</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(p.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>7-01-DaGiGpBP-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.245658</td>\n",
       "      <td>2.210728</td>\n",
       "      <td>4.229289</td>\n",
       "      <td>-0.034930</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(i.sid) FROM disease d, associates a...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>059-061-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.518876</td>\n",
       "      <td>0.507485</td>\n",
       "      <td>2.473964</td>\n",
       "      <td>-0.011392</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>081-111-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.617876</td>\n",
       "      <td>0.569743</td>\n",
       "      <td>2.545614</td>\n",
       "      <td>-0.048133</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=31, num_e=5)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, postLinks...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred label  true label  bench                       query  \\\n",
       "1349           0           1  STATS               111-056-augA1   \n",
       "2477           1           0  HETIO          3-08-CpDpCtD-augA5   \n",
       "2534           1           0  HETIO          3-16-CtDuGuD-augA6   \n",
       "1268           1           0  STATS         104-088-augF2-augA1   \n",
       "2420           0           1  HETIO            2-05-CuGdD-augA2   \n",
       "299            0           1  STATS         023-018-augF2-augA2   \n",
       "1341           0           1  STATS         110-138-augF1-augA3   \n",
       "1740           0           1  STATS               137-141-augA4   \n",
       "2694           1           0  HETIO         9-07-DuGcGpMF-augA4   \n",
       "2480           1           0  HETIO          3-09-CrCrCtD-augA1   \n",
       "1237           0           1  STATS               101-043-augA3   \n",
       "1739           0           1  STATS               137-141-augA3   \n",
       "2105           0           1   SNAP           wiki-tree01-augA4   \n",
       "1210           0           1  STATS               098-124-augF1   \n",
       "1149           0           1  STATS         093-075-augF2-augA2   \n",
       "1736           0           1  STATS                     137-141   \n",
       "2476           1           0  HETIO          3-08-CpDpCtD-augA4   \n",
       "1186           0           1  STATS         096-095-augF1-augA2   \n",
       "2293           1           0    JOB             17e-augF1-augA4   \n",
       "927            0           1  STATS         075-037-augF2-augA3   \n",
       "1774           1           0  STATS         139-034-augF1-augA1   \n",
       "955            1           0  STATS               078-082-augF1   \n",
       "1056           1           0  STATS         086-083-augF2-augA2   \n",
       "963            0           1  STATS               079-112-augA2   \n",
       "904            0           1  STATS               074-072-augF1   \n",
       "798            1           0  STATS         064-116-augF2-augA3   \n",
       "2631           1           0  HETIO        8-01-CCpGdCcSE-augA4   \n",
       "1309           0           1  STATS         108-060-augF1-augA3   \n",
       "2599           0           1  HETIO     6-01-BPpGeA-augF1-augA3   \n",
       "1922           0           1   SNAP           dblp-tree01-augA4   \n",
       "1549           1           0  STATS               125-051-augF1   \n",
       "296            0           1  STATS         023-018-augF1-augA2   \n",
       "2644           0           1  HETIO  8-01-CCpGdCcSE-augF2-augA3   \n",
       "172            0           1  STATS         013-055-augF2-augA3   \n",
       "1638           1           0  STATS         130-123-augF2-augA2   \n",
       "446            0           1  STATS         036-100-augF2-augA2   \n",
       "1410           1           0  STATS         115-144-augF2-augA1   \n",
       "678            0           1  STATS               055-009-augA2   \n",
       "1438           0           1  STATS         117-114-augF2-augA3   \n",
       "1291           0           1  STATS               107-104-augA3   \n",
       "484            0           1  STATS         040-101-augF1-augA2   \n",
       "620            1           0  STATS               050-106-augF1   \n",
       "2441           1           0  HETIO         3-03-CbGiGaD2-augA4   \n",
       "1234           0           1  STATS                     101-043   \n",
       "1486           1           0  STATS         121-097-augF1-augA1   \n",
       "2616           0           1  HETIO   7-01-DaGiGpBP-augF1-augA3   \n",
       "715            0           1  STATS               059-061-augA3   \n",
       "991            0           1  STATS               081-111-augA3   \n",
       "\n",
       "     orig/rewr(mean) orig/rewr+rewr(mean)   orig mean  rewr mean  \\\n",
       "1349            rewr                 orig    0.596748   0.532240   \n",
       "2477            orig                 orig    0.184137   0.300639   \n",
       "2534            orig                 orig    0.574174   0.586411   \n",
       "1268            orig                 orig    0.215694   0.275453   \n",
       "2420            rewr                 orig    0.557119   0.539519   \n",
       "299             rewr                 orig    0.283540   0.270736   \n",
       "1341            rewr                 orig    0.481653   0.459576   \n",
       "1740            rewr                 rewr    5.530137   0.724227   \n",
       "2694            orig                 orig    1.934141   2.029559   \n",
       "2480            orig                 orig    0.315867   0.331699   \n",
       "1237            rewr                 orig    0.314957   0.265431   \n",
       "1739            rewr                 rewr    5.530431   0.792268   \n",
       "2105            rewr                 rewr  100.000000  47.316149   \n",
       "1210            rewr                 orig    0.496431   0.489113   \n",
       "1149            rewr                 orig    0.669017   0.667051   \n",
       "1736            rewr                 rewr    5.258001   0.825190   \n",
       "2476            orig                 orig    0.190571   0.293480   \n",
       "1186            rewr                 orig    0.605563   0.587985   \n",
       "2293            orig                 orig   62.264197  64.633271   \n",
       "927             rewr                 orig    0.549356   0.510466   \n",
       "1774            orig                 orig    0.187277   0.375633   \n",
       "955             orig                 orig    0.428752   0.477420   \n",
       "1056            orig                 orig    0.439631   0.443599   \n",
       "963             rewr                 orig    0.602283   0.576377   \n",
       "904             rewr                 orig    0.620385   0.611789   \n",
       "798             orig                 orig    0.245410   0.312055   \n",
       "2631            orig                 orig    2.157892   2.260612   \n",
       "1309            rewr                 orig    0.605470   0.528589   \n",
       "2599            rewr                 orig    2.284644   2.003512   \n",
       "1922            rewr                 rewr  100.000000   2.059813   \n",
       "1549            orig                 orig    0.396640   0.456243   \n",
       "296             rewr                 orig    0.458169   0.385003   \n",
       "2644            rewr                 orig    2.071347   2.062725   \n",
       "172             rewr                 orig    0.465446   0.460443   \n",
       "1638            orig                 orig    0.405899   0.468322   \n",
       "446             rewr                 orig    0.503076   0.420642   \n",
       "1410            orig                 orig    0.614087   0.705318   \n",
       "678             rewr                 orig    0.497410   0.411260   \n",
       "1438            rewr                 orig    0.373415   0.364921   \n",
       "1291            rewr                 orig    0.544392   0.510644   \n",
       "484             rewr                 orig    0.570664   0.452450   \n",
       "620             orig                 orig    0.306332   0.504485   \n",
       "2441            orig                 orig    0.552251   0.581946   \n",
       "1234            rewr                 orig    0.406486   0.263467   \n",
       "1486            orig                 orig    0.238843   0.435648   \n",
       "2616            rewr                 orig    2.245658   2.210728   \n",
       "715             rewr                 orig    0.518876   0.507485   \n",
       "991             rewr                 orig    0.617876   0.569743   \n",
       "\n",
       "      rewr mean+rewr  diff rewr-orig  ...  q75(branching factors)  \\\n",
       "1349        2.328231       -0.064508  ...                    4.00   \n",
       "2477        2.454935        0.116503  ...                    2.50   \n",
       "2534        2.638695        0.012236  ...                    2.50   \n",
       "1268        1.273657        0.059759  ...                    1.00   \n",
       "2420        2.760506       -0.017600  ...                    2.50   \n",
       "299         2.124599       -0.012804  ...                    1.00   \n",
       "1341        1.484276       -0.022076  ...                    2.50   \n",
       "1740        2.626288       -4.805910  ...                    4.00   \n",
       "2694        4.014254        0.095418  ...                    2.50   \n",
       "2480        2.236466        0.015833  ...                    2.50   \n",
       "1237        2.169154       -0.049526  ...                    1.75   \n",
       "1739        2.848849       -4.738162  ...                    4.00   \n",
       "2105       49.300901      -52.683851  ...                    2.50   \n",
       "1210        1.590290       -0.007318  ...                    3.00   \n",
       "1149        2.649943       -0.001965  ...                    3.25   \n",
       "1736        2.791115       -4.432811  ...                    6.00   \n",
       "2476        2.259293        0.102909  ...                    2.50   \n",
       "1186        2.769054       -0.017578  ...                    1.75   \n",
       "2293       66.638959        2.369074  ...                    2.50   \n",
       "927         2.482725       -0.038890  ...                    1.75   \n",
       "1774        2.325579        0.188355  ...                    1.75   \n",
       "955         2.450607        0.048668  ...                    1.00   \n",
       "1056        2.432668        0.003967  ...                    2.00   \n",
       "963         2.642454       -0.025906  ...                    4.00   \n",
       "904         1.680814       -0.008595  ...                    5.00   \n",
       "798         2.550724        0.066645  ...                    3.00   \n",
       "2631        4.226928        0.102720  ...                    2.00   \n",
       "1309        2.401235       -0.076881  ...                    3.25   \n",
       "2599        3.956240       -0.281132  ...                    2.50   \n",
       "1922        4.357800      -97.940187  ...                    2.50   \n",
       "1549        1.497873        0.059602  ...                    2.50   \n",
       "296         2.186201       -0.073166  ...                    1.00   \n",
       "2644        4.075672       -0.008622  ...                    2.50   \n",
       "172         1.434189       -0.005003  ...                    2.50   \n",
       "1638        2.437323        0.062423  ...                    3.00   \n",
       "446         2.365454       -0.082434  ...                    1.75   \n",
       "1410        1.710992        0.091231  ...                    5.00   \n",
       "678         2.225097       -0.086150  ...                    2.00   \n",
       "1438        1.365446       -0.008494  ...                    3.00   \n",
       "1291        2.470447       -0.033748  ...                    3.00   \n",
       "484         2.678936       -0.118214  ...                    1.75   \n",
       "620         2.638419        0.198153  ...                    3.00   \n",
       "2441        2.635486        0.029695  ...                    2.50   \n",
       "1234        2.132344       -0.143019  ...                    1.75   \n",
       "1486        2.658918        0.196805  ...                    1.75   \n",
       "2616        4.229289       -0.034930  ...                    2.00   \n",
       "715         2.473964       -0.011392  ...                    3.25   \n",
       "991         2.545614       -0.048133  ...                    2.50   \n",
       "\n",
       "      balancedness factor                              container counts list  \\\n",
       "1349             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2477             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2534             0.625000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1268                  NaN               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "2420             1.000000                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "299                   NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1341             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1740             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2694             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2480             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1237             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1739             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2105             1.000000                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "1210             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1149             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1736             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2476             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1186             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2293             0.666667  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "927              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1774             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "955                   NaN         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "1056             1.000000         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "963              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "904              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "798              1.000000   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]   \n",
       "2631             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1309             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2599             1.000000                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "1922             1.000000                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "1549             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "296                   NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2644             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "172              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1638             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "446              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1410             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "678              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1438             1.000000   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]   \n",
       "1291             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "484              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "620              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2441             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1234             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1486             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2616             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "715              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "991              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "      branching factors list                     hypergraph  \\\n",
       "1349                     [4]  Hypergraph(num_v=28, num_e=5)   \n",
       "2477               [1, 1, 4]  Hypergraph(num_v=14, num_e=7)   \n",
       "2534               [1, 3, 2]  Hypergraph(num_v=14, num_e=7)   \n",
       "1268                  [1, 1]  Hypergraph(num_v=14, num_e=3)   \n",
       "2420                  [1, 3]  Hypergraph(num_v=10, num_e=5)   \n",
       "299                   [1, 1]  Hypergraph(num_v=20, num_e=3)   \n",
       "1341                  [3, 1]  Hypergraph(num_v=28, num_e=5)   \n",
       "1740                  [5, 1]  Hypergraph(num_v=40, num_e=7)   \n",
       "2694               [2, 1, 3]  Hypergraph(num_v=14, num_e=7)   \n",
       "2480               [2, 1, 3]  Hypergraph(num_v=14, num_e=7)   \n",
       "1237                  [2, 1]  Hypergraph(num_v=24, num_e=4)   \n",
       "1739                  [5, 1]  Hypergraph(num_v=40, num_e=7)   \n",
       "2105                  [1, 3]  Hypergraph(num_v=10, num_e=5)   \n",
       "1210                     [3]  Hypergraph(num_v=20, num_e=4)   \n",
       "1149                  [4, 1]  Hypergraph(num_v=35, num_e=6)   \n",
       "1736                     [6]  Hypergraph(num_v=40, num_e=7)   \n",
       "2476               [1, 1, 4]  Hypergraph(num_v=14, num_e=7)   \n",
       "1186                  [2, 1]  Hypergraph(num_v=26, num_e=4)   \n",
       "2293               [1, 2, 3]  Hypergraph(num_v=46, num_e=7)   \n",
       "927                   [2, 1]  Hypergraph(num_v=21, num_e=4)   \n",
       "1774                  [2, 1]  Hypergraph(num_v=20, num_e=4)   \n",
       "955                   [1, 1]  Hypergraph(num_v=16, num_e=3)   \n",
       "1056                     [2]  Hypergraph(num_v=16, num_e=3)   \n",
       "963                      [4]  Hypergraph(num_v=31, num_e=5)   \n",
       "904                      [5]  Hypergraph(num_v=34, num_e=6)   \n",
       "798                      [3]  Hypergraph(num_v=19, num_e=4)   \n",
       "2631               [2, 2, 2]  Hypergraph(num_v=14, num_e=7)   \n",
       "1309                  [4, 1]  Hypergraph(num_v=35, num_e=6)   \n",
       "2599                  [1, 3]  Hypergraph(num_v=10, num_e=5)   \n",
       "1922                  [1, 3]  Hypergraph(num_v=10, num_e=5)   \n",
       "1549                  [3, 1]  Hypergraph(num_v=29, num_e=5)   \n",
       "296                   [1, 1]  Hypergraph(num_v=20, num_e=3)   \n",
       "2644               [1, 1, 4]  Hypergraph(num_v=14, num_e=7)   \n",
       "172                   [3, 1]  Hypergraph(num_v=27, num_e=5)   \n",
       "1638                     [3]  Hypergraph(num_v=24, num_e=4)   \n",
       "446                   [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "1410                     [5]  Hypergraph(num_v=35, num_e=6)   \n",
       "678                      [2]  Hypergraph(num_v=20, num_e=3)   \n",
       "1438                     [3]  Hypergraph(num_v=19, num_e=4)   \n",
       "1291                     [3]  Hypergraph(num_v=22, num_e=4)   \n",
       "484                   [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "620                      [3]  Hypergraph(num_v=22, num_e=4)   \n",
       "2441               [2, 1, 3]  Hypergraph(num_v=14, num_e=7)   \n",
       "1234                  [2, 1]  Hypergraph(num_v=24, num_e=4)   \n",
       "1486                  [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "2616               [2, 2, 2]  Hypergraph(num_v=14, num_e=7)   \n",
       "715                   [4, 1]  Hypergraph(num_v=35, num_e=6)   \n",
       "991                   [3, 1]  Hypergraph(num_v=31, num_e=5)   \n",
       "\n",
       "                                                   text  orig/rewr/equal 0.5  \\\n",
       "1349  SELECT MIN(p.id) FROM tags as t, posts as p, u...                equal   \n",
       "2477  SELECT MIN(t.sid) FROM compound c1, palliates ...                equal   \n",
       "2534  SELECT MIN(d2.nid) FROM compound c1, treats t,...                equal   \n",
       "1268  SELECT MIN(b.id) FROM comments as c, badges as...                equal   \n",
       "2420  SELECT MIN(g.nid) FROM compound c, upregulates...                equal   \n",
       "299   SELECT MIN(ph.id) FROM posts as p, postLinks a...                equal   \n",
       "1341  SELECT MIN(v.id) FROM tags as t, posts as p, u...                equal   \n",
       "1740  SELECT MIN(v.id) FROM comments as c, posts as ...                 rewr   \n",
       "2694  SELECT MIN(g2.nid) FROM disease d, upregulates...                equal   \n",
       "2480  SELECT MIN(r1.sid) FROM compound c1, resembles...                equal   \n",
       "1237  SELECT MIN(b.id) FROM postHistory as ph, posts...                equal   \n",
       "1739  SELECT MIN(ph.id) FROM comments as c, posts as...                 rewr   \n",
       "2105  SELECT MIN(p4b.fromnode) FROM wiki p1, wiki p2...                 rewr   \n",
       "1210  SELECT MIN(ph.Id) FROM postHistory as ph, vote...                equal   \n",
       "1149  SELECT MIN(ph.id) FROM comments as c, posts as...                equal   \n",
       "1736  SELECT MIN(c.Id) FROM comments as c, posts as ...                 rewr   \n",
       "2476  SELECT MIN(c2.nid) FROM compound c1, palliates...                equal   \n",
       "1186  SELECT MIN(v.id) FROM comments as c, postHisto...                equal   \n",
       "2293  SELECT MIN(mc.id) AS member_in_charnamed_movie...                 orig   \n",
       "927   SELECT MIN(v.id) FROM comments as c, postLinks...                equal   \n",
       "1774  SELECT MIN(v.id) FROM comments as c, votes as ...                equal   \n",
       "955   SELECT MIN(c.Id) FROM comments as c, postHisto...                equal   \n",
       "1056  SELECT MIN(u.id) FROM comments as c, postHisto...                equal   \n",
       "963   SELECT MIN(ph.id) FROM comments as c, postLink...                equal   \n",
       "904   SELECT MIN(c.Id) FROM comments as c, posts as ...                equal   \n",
       "798   SELECT MIN(u.id) FROM comments as c, postHisto...                equal   \n",
       "2631  SELECT MIN(c.nid) FROM cellular_component cc, ...                equal   \n",
       "1309  SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "2599  SELECT MIN(e.sid) FROM biological_process bp, ...                equal   \n",
       "1922  SELECT MIN(p4b.fromnode) FROM dblp p1, dblp p2...                 rewr   \n",
       "1549  SELECT MIN(c.Id) FROM comments as c, posts as ...                equal   \n",
       "296   SELECT MIN(ph.id) FROM posts as p, postLinks a...                equal   \n",
       "2644  SELECT MIN(d.sid) FROM cellular_component cc, ...                equal   \n",
       "172   SELECT MIN(ph.id) FROM tags as t, posts as p, ...                equal   \n",
       "1638  SELECT MIN(u.id) FROM postHistory as ph, posts...                equal   \n",
       "446   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "1410  SELECT MIN(p.id) FROM comments as c, posts as ...                equal   \n",
       "678   SELECT MIN(ph.id) FROM comments as c, posts as...                equal   \n",
       "1438  SELECT MIN(u.id) FROM comments as c, postHisto...                equal   \n",
       "1291  SELECT MIN(u.id) FROM comments as c, postHisto...                equal   \n",
       "484   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "620   SELECT MIN(c.Id) FROM comments as c, postHisto...                equal   \n",
       "2441  SELECT MIN(g2.nid) FROM compound c1, binds b1,...                equal   \n",
       "1234  SELECT MIN(ph.Id) FROM postHistory as ph, post...                equal   \n",
       "1486  SELECT MIN(p.id) FROM comments as c, posts as ...                equal   \n",
       "2616  SELECT MIN(i.sid) FROM disease d, associates a...                equal   \n",
       "715   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "991   SELECT MIN(v.id) FROM comments as c, postLinks...                equal   \n",
       "\n",
       "      orig/rewr/equal 0.1  orig/rewr/equal 0.05  orig/rewr/equal 0.01  \n",
       "1349                equal                  rewr                  rewr  \n",
       "2477                 orig                  orig                  orig  \n",
       "2534                equal                 equal                  orig  \n",
       "1268                equal                  orig                  orig  \n",
       "2420                equal                 equal                  rewr  \n",
       "299                 equal                 equal                  rewr  \n",
       "1341                equal                 equal                  rewr  \n",
       "1740                 rewr                  rewr                  rewr  \n",
       "2694                equal                  orig                  orig  \n",
       "2480                equal                 equal                  orig  \n",
       "1237                equal                 equal                  rewr  \n",
       "1739                 rewr                  rewr                  rewr  \n",
       "2105                 rewr                  rewr                  rewr  \n",
       "1210                equal                 equal                 equal  \n",
       "1149                equal                 equal                 equal  \n",
       "1736                 rewr                  rewr                  rewr  \n",
       "2476                 orig                  orig                  orig  \n",
       "1186                equal                 equal                  rewr  \n",
       "2293                 orig                  orig                  orig  \n",
       "927                 equal                 equal                  rewr  \n",
       "1774                 orig                  orig                  orig  \n",
       "955                 equal                 equal                  orig  \n",
       "1056                equal                 equal                 equal  \n",
       "963                 equal                 equal                  rewr  \n",
       "904                 equal                 equal                 equal  \n",
       "798                 equal                  orig                  orig  \n",
       "2631                 orig                  orig                  orig  \n",
       "1309                equal                  rewr                  rewr  \n",
       "2599                 rewr                  rewr                  rewr  \n",
       "1922                 rewr                  rewr                  rewr  \n",
       "1549                equal                  orig                  orig  \n",
       "296                 equal                  rewr                  rewr  \n",
       "2644                equal                 equal                 equal  \n",
       "172                 equal                 equal                 equal  \n",
       "1638                equal                  orig                  orig  \n",
       "446                 equal                  rewr                  rewr  \n",
       "1410                equal                  orig                  orig  \n",
       "678                 equal                  rewr                  rewr  \n",
       "1438                equal                 equal                 equal  \n",
       "1291                equal                 equal                  rewr  \n",
       "484                  rewr                  rewr                  rewr  \n",
       "620                  orig                  orig                  orig  \n",
       "2441                equal                 equal                  orig  \n",
       "1234                 rewr                  rewr                  rewr  \n",
       "1486                 orig                  orig                  orig  \n",
       "2616                equal                 equal                  rewr  \n",
       "715                 equal                 equal                  rewr  \n",
       "991                 equal                 equal                  rewr  \n",
       "\n",
       "[48 rows x 37 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass = df.loc[X_val.index]\n",
    "misclass.insert(0, 'true label', np.array(y1_val))\n",
    "misclass.insert(0, 'pred label', y1_pred_dec_tree)\n",
    "indices_not_equal = np.where(y1_val != y1_pred_dec_tree)[0]\n",
    "misclass = misclass.iloc[indices_not_equal]\n",
    "misclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7612f2e-e20f-45dc-afcb-59cf8a20913f",
   "metadata": {},
   "source": [
    "We observe in which orders of magnitude the difference between the original and rewritten runtimes are in cases of misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "434c18c4-7fd2-4e5f-aa3e-ee9b284350b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1098346/2236301608.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass_1[\"cut\"] = pd.cut(abs(misclass_1['diff rewr-orig']), bins=bins, labels=labels)\n",
      "/tmp/ipykernel_1098346/2236301608.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass_0[\"cut\"] = pd.cut(abs(misclass_0['diff rewr-orig']), bins=bins, labels=labels)\n",
      "/tmp/ipykernel_1098346/2236301608.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  table_1 = misclass_1.groupby('cut').size().reset_index(name='count_1')\n",
      "/tmp/ipykernel_1098346/2236301608.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  table_0 = misclass_0.groupby('cut').size().reset_index(name='count_0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cut</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>TO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cut  0.01  0.1  1  10  100  TO\n",
       "FP      1   10  6   1    0   0\n",
       "FN      6   16  3   3    2   0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 0.01, 0.1, 1, 10, 100, float('inf')]\n",
    "labels = ['0.01', '0.1', '1', '10', '100', 'TO']\n",
    "\n",
    "misclass_1 = misclass[misclass[\"pred label\"] == 1]\n",
    "misclass_0 = misclass[misclass[\"pred label\"] == 0]\n",
    "\n",
    "misclass_1[\"cut\"] = pd.cut(abs(misclass_1['diff rewr-orig']), bins=bins, labels=labels)\n",
    "misclass_0[\"cut\"] = pd.cut(abs(misclass_0['diff rewr-orig']), bins=bins, labels=labels)\n",
    "\n",
    "table_1 = misclass_1.groupby('cut').size().reset_index(name='count_1')\n",
    "table_0 = misclass_0.groupby('cut').size().reset_index(name='count_0')\n",
    "\n",
    "table = pd.merge(table_1, table_0, on='cut', how='outer')\n",
    "table = table.set_index('cut').T\n",
    "table.index = ['FP', 'FN']\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d772e27-b5e7-4bfb-bda8-eb577dd53b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8327645051194539\n",
      "0.8367346938775511\n",
      "0.831081081081081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[121,  24],\n",
       "       [ 25, 123]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_rand_forest = clf.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y1_val, y1_pred_rand_forest)\n",
    "print(accuracy)\n",
    "precision = precision_score(y1_val, y1_pred_rand_forest)\n",
    "print(precision)\n",
    "recall = recall_score(y1_val, y1_pred_rand_forest)\n",
    "print(recall)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_rand_forest)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "309ad84d-f80e-4611-b2dc-aacb2d6deecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred label</th>\n",
       "      <th>true label</th>\n",
       "      <th>bench</th>\n",
       "      <th>query</th>\n",
       "      <th>orig/rewr(mean)</th>\n",
       "      <th>orig/rewr+rewr(mean)</th>\n",
       "      <th>orig mean</th>\n",
       "      <th>rewr mean</th>\n",
       "      <th>rewr mean+rewr</th>\n",
       "      <th>diff rewr-orig</th>\n",
       "      <th>...</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <th>balancedness factor</th>\n",
       "      <th>container counts list</th>\n",
       "      <th>branching factors list</th>\n",
       "      <th>hypergraph</th>\n",
       "      <th>text</th>\n",
       "      <th>orig/rewr/equal 0.5</th>\n",
       "      <th>orig/rewr/equal 0.1</th>\n",
       "      <th>orig/rewr/equal 0.05</th>\n",
       "      <th>orig/rewr/equal 0.01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>111-056-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.596748</td>\n",
       "      <td>0.532240</td>\n",
       "      <td>2.328231</td>\n",
       "      <td>-0.064508</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=28, num_e=5)</td>\n",
       "      <td>SELECT MIN(p.id) FROM tags as t, posts as p, u...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-08-CpDpCtD-augA5</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.184137</td>\n",
       "      <td>0.300639</td>\n",
       "      <td>2.454935</td>\n",
       "      <td>0.116503</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(t.sid) FROM compound c1, palliates ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-16-CtDuGuD-augA6</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.574174</td>\n",
       "      <td>0.586411</td>\n",
       "      <td>2.638695</td>\n",
       "      <td>0.012236</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(d2.nid) FROM compound c1, treats t,...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>104-088-augF2-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.215694</td>\n",
       "      <td>0.275453</td>\n",
       "      <td>1.273657</td>\n",
       "      <td>0.059759</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=3)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, badges as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>2-05-CuGdD-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.557119</td>\n",
       "      <td>0.539519</td>\n",
       "      <td>2.760506</td>\n",
       "      <td>-0.017600</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(g.nid) FROM compound c, upregulates...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>023-018-augF2-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.283540</td>\n",
       "      <td>0.270736</td>\n",
       "      <td>2.124599</td>\n",
       "      <td>-0.012804</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=3)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM posts as p, postLinks a...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>110-138-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.481653</td>\n",
       "      <td>0.459576</td>\n",
       "      <td>1.484276</td>\n",
       "      <td>-0.022076</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=28, num_e=5)</td>\n",
       "      <td>SELECT MIN(v.id) FROM tags as t, posts as p, u...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>137-141-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>5.530137</td>\n",
       "      <td>0.724227</td>\n",
       "      <td>2.626288</td>\n",
       "      <td>-4.805910</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 1]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>9-07-DuGcGpMF-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>1.934141</td>\n",
       "      <td>2.029559</td>\n",
       "      <td>4.014254</td>\n",
       "      <td>0.095418</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(g2.nid) FROM disease d, upregulates...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-09-CrCrCtD-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.315867</td>\n",
       "      <td>0.331699</td>\n",
       "      <td>2.236466</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(r1.sid) FROM compound c1, resembles...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>049-118-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.531513</td>\n",
       "      <td>0.625120</td>\n",
       "      <td>2.745154</td>\n",
       "      <td>0.093607</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(ph.Id) FROM postHistory as ph, post...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>137-141-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>5.530431</td>\n",
       "      <td>0.792268</td>\n",
       "      <td>2.848849</td>\n",
       "      <td>-4.738162</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 1]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, posts as...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>wiki-tree01-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>47.316149</td>\n",
       "      <td>49.300901</td>\n",
       "      <td>-52.683851</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(p4b.fromnode) FROM wiki p1, wiki p2...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>098-124-augF1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.496431</td>\n",
       "      <td>0.489113</td>\n",
       "      <td>1.590290</td>\n",
       "      <td>-0.007318</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=4)</td>\n",
       "      <td>SELECT MIN(ph.Id) FROM postHistory as ph, vote...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>083-039</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.282343</td>\n",
       "      <td>0.323916</td>\n",
       "      <td>2.291740</td>\n",
       "      <td>0.041573</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=19, num_e=4)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>096-095</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.642257</td>\n",
       "      <td>0.754238</td>\n",
       "      <td>2.639731</td>\n",
       "      <td>0.111981</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=26, num_e=4)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>093-075-augF2-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.669017</td>\n",
       "      <td>0.667051</td>\n",
       "      <td>2.649943</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, posts as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>137-141</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>5.258001</td>\n",
       "      <td>0.825190</td>\n",
       "      <td>2.791115</td>\n",
       "      <td>-4.432811</td>\n",
       "      <td>...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-08-CpDpCtD-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.190571</td>\n",
       "      <td>0.293480</td>\n",
       "      <td>2.259293</td>\n",
       "      <td>0.102909</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(c2.nid) FROM compound c1, palliates...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>001-014-augF2-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.248959</td>\n",
       "      <td>0.305712</td>\n",
       "      <td>2.158816</td>\n",
       "      <td>0.056753</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "      <td>SELECT MIN(c.id) FROM comments as c, votes as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>JOB</td>\n",
       "      <td>17e-augF1-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>62.264197</td>\n",
       "      <td>64.633271</td>\n",
       "      <td>66.638959</td>\n",
       "      <td>2.369074</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>Hypergraph(num_v=46, num_e=7)</td>\n",
       "      <td>SELECT MIN(mc.id) AS member_in_charnamed_movie...</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>075-037-augF2-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.510466</td>\n",
       "      <td>2.482725</td>\n",
       "      <td>-0.038890</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=21, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, postLinks...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>139-034-augF1-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.187277</td>\n",
       "      <td>0.375633</td>\n",
       "      <td>2.325579</td>\n",
       "      <td>0.188355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, votes as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>078-082-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.428752</td>\n",
       "      <td>0.477420</td>\n",
       "      <td>2.450607</td>\n",
       "      <td>0.048668</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=3)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>086-083-augF2-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.439631</td>\n",
       "      <td>0.443599</td>\n",
       "      <td>2.432668</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=3)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>075-037-augF2-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.519803</td>\n",
       "      <td>0.617351</td>\n",
       "      <td>2.585629</td>\n",
       "      <td>0.097549</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=21, num_e=4)</td>\n",
       "      <td>SELECT MIN(pl.id) FROM comments as c, postLink...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>079-112-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.602283</td>\n",
       "      <td>0.576377</td>\n",
       "      <td>2.642454</td>\n",
       "      <td>-0.025906</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=31, num_e=5)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, postLink...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>074-072-augF1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.620385</td>\n",
       "      <td>0.611789</td>\n",
       "      <td>1.680814</td>\n",
       "      <td>-0.008595</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>Hypergraph(num_v=34, num_e=6)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>064-116-augF2-augA3</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.312055</td>\n",
       "      <td>2.550724</td>\n",
       "      <td>0.066645</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=19, num_e=4)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>8-01-CCpGdCcSE-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.157892</td>\n",
       "      <td>2.260612</td>\n",
       "      <td>4.226928</td>\n",
       "      <td>0.102720</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(c.nid) FROM cellular_component cc, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>108-060-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.605470</td>\n",
       "      <td>0.528589</td>\n",
       "      <td>2.401235</td>\n",
       "      <td>-0.076881</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>6-01-BPpGeA-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.284644</td>\n",
       "      <td>2.003512</td>\n",
       "      <td>3.956240</td>\n",
       "      <td>-0.281132</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(e.sid) FROM biological_process bp, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>dblp-tree01-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.059813</td>\n",
       "      <td>4.357800</td>\n",
       "      <td>-97.940187</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(p4b.fromnode) FROM dblp p1, dblp p2...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>125-051-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.396640</td>\n",
       "      <td>0.456243</td>\n",
       "      <td>1.497873</td>\n",
       "      <td>0.059602</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>023-018-augF1-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.458169</td>\n",
       "      <td>0.385003</td>\n",
       "      <td>2.186201</td>\n",
       "      <td>-0.073166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=3)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM posts as p, postLinks a...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>8-01-CCpGdCcSE-augF2-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.071347</td>\n",
       "      <td>2.062725</td>\n",
       "      <td>4.075672</td>\n",
       "      <td>-0.008622</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(d.sid) FROM cellular_component cc, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>013-055-augF2-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.465446</td>\n",
       "      <td>0.460443</td>\n",
       "      <td>1.434189</td>\n",
       "      <td>-0.005003</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=5)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM tags as t, posts as p, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>130-123-augF2-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.405899</td>\n",
       "      <td>0.468322</td>\n",
       "      <td>2.437323</td>\n",
       "      <td>0.062423</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=24, num_e=4)</td>\n",
       "      <td>SELECT MIN(u.id) FROM postHistory as ph, posts...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>036-100-augF2-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.503076</td>\n",
       "      <td>0.420642</td>\n",
       "      <td>2.365454</td>\n",
       "      <td>-0.082434</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>115-144-augF2-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.614087</td>\n",
       "      <td>0.705318</td>\n",
       "      <td>1.710992</td>\n",
       "      <td>0.091231</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(p.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>055-009-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.497410</td>\n",
       "      <td>0.411260</td>\n",
       "      <td>2.225097</td>\n",
       "      <td>-0.086150</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=3)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, posts as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>107-104-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.544392</td>\n",
       "      <td>0.510644</td>\n",
       "      <td>2.470447</td>\n",
       "      <td>-0.033748</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=22, num_e=4)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>040-101</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.539265</td>\n",
       "      <td>0.650891</td>\n",
       "      <td>2.563208</td>\n",
       "      <td>0.111626</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>050-106-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.306332</td>\n",
       "      <td>0.504485</td>\n",
       "      <td>2.638419</td>\n",
       "      <td>0.198153</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=22, num_e=4)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-03-CbGiGaD2-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.552251</td>\n",
       "      <td>0.581946</td>\n",
       "      <td>2.635486</td>\n",
       "      <td>0.029695</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(g2.nid) FROM compound c1, binds b1,...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>121-097-augF1-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.238843</td>\n",
       "      <td>0.435648</td>\n",
       "      <td>2.658918</td>\n",
       "      <td>0.196805</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(p.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>7-01-DaGiGpBP-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.245658</td>\n",
       "      <td>2.210728</td>\n",
       "      <td>4.229289</td>\n",
       "      <td>-0.034930</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(i.sid) FROM disease d, associates a...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>059-061-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.518876</td>\n",
       "      <td>0.507485</td>\n",
       "      <td>2.473964</td>\n",
       "      <td>-0.011392</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>081-111-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.617876</td>\n",
       "      <td>0.569743</td>\n",
       "      <td>2.545614</td>\n",
       "      <td>-0.048133</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=31, num_e=5)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, postLinks...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred label  true label  bench                       query  \\\n",
       "1349           0           1  STATS               111-056-augA1   \n",
       "2477           1           0  HETIO          3-08-CpDpCtD-augA5   \n",
       "2534           1           0  HETIO          3-16-CtDuGuD-augA6   \n",
       "1268           1           0  STATS         104-088-augF2-augA1   \n",
       "2420           0           1  HETIO            2-05-CuGdD-augA2   \n",
       "299            0           1  STATS         023-018-augF2-augA2   \n",
       "1341           0           1  STATS         110-138-augF1-augA3   \n",
       "1740           0           1  STATS               137-141-augA4   \n",
       "2694           1           0  HETIO         9-07-DuGcGpMF-augA4   \n",
       "2480           1           0  HETIO          3-09-CrCrCtD-augA1   \n",
       "608            1           0  STATS               049-118-augF1   \n",
       "1739           0           1  STATS               137-141-augA3   \n",
       "2105           0           1   SNAP           wiki-tree01-augA4   \n",
       "1210           0           1  STATS               098-124-augF1   \n",
       "1015           1           0  STATS                     083-039   \n",
       "1180           1           0  STATS                     096-095   \n",
       "1149           0           1  STATS         093-075-augF2-augA2   \n",
       "1736           0           1  STATS                     137-141   \n",
       "2476           1           0  HETIO          3-08-CpDpCtD-augA4   \n",
       "7              1           0  STATS         001-014-augF2-augA1   \n",
       "2293           1           0    JOB             17e-augF1-augA4   \n",
       "927            0           1  STATS         075-037-augF2-augA3   \n",
       "1774           1           0  STATS         139-034-augF1-augA1   \n",
       "955            1           0  STATS               078-082-augF1   \n",
       "1056           1           0  STATS         086-083-augF2-augA2   \n",
       "925            1           0  STATS         075-037-augF2-augA1   \n",
       "963            0           1  STATS               079-112-augA2   \n",
       "904            0           1  STATS               074-072-augF1   \n",
       "798            1           0  STATS         064-116-augF2-augA3   \n",
       "2631           1           0  HETIO        8-01-CCpGdCcSE-augA4   \n",
       "1309           0           1  STATS         108-060-augF1-augA3   \n",
       "2599           0           1  HETIO     6-01-BPpGeA-augF1-augA3   \n",
       "1922           0           1   SNAP           dblp-tree01-augA4   \n",
       "1549           1           0  STATS               125-051-augF1   \n",
       "296            0           1  STATS         023-018-augF1-augA2   \n",
       "2644           0           1  HETIO  8-01-CCpGdCcSE-augF2-augA3   \n",
       "172            0           1  STATS         013-055-augF2-augA3   \n",
       "1638           1           0  STATS         130-123-augF2-augA2   \n",
       "446            0           1  STATS         036-100-augF2-augA2   \n",
       "1410           1           0  STATS         115-144-augF2-augA1   \n",
       "678            0           1  STATS               055-009-augA2   \n",
       "1291           0           1  STATS               107-104-augA3   \n",
       "478            1           0  STATS                     040-101   \n",
       "620            1           0  STATS               050-106-augF1   \n",
       "2441           1           0  HETIO         3-03-CbGiGaD2-augA4   \n",
       "1486           1           0  STATS         121-097-augF1-augA1   \n",
       "2616           0           1  HETIO   7-01-DaGiGpBP-augF1-augA3   \n",
       "715            0           1  STATS               059-061-augA3   \n",
       "991            0           1  STATS               081-111-augA3   \n",
       "\n",
       "     orig/rewr(mean) orig/rewr+rewr(mean)   orig mean  rewr mean  \\\n",
       "1349            rewr                 orig    0.596748   0.532240   \n",
       "2477            orig                 orig    0.184137   0.300639   \n",
       "2534            orig                 orig    0.574174   0.586411   \n",
       "1268            orig                 orig    0.215694   0.275453   \n",
       "2420            rewr                 orig    0.557119   0.539519   \n",
       "299             rewr                 orig    0.283540   0.270736   \n",
       "1341            rewr                 orig    0.481653   0.459576   \n",
       "1740            rewr                 rewr    5.530137   0.724227   \n",
       "2694            orig                 orig    1.934141   2.029559   \n",
       "2480            orig                 orig    0.315867   0.331699   \n",
       "608             orig                 orig    0.531513   0.625120   \n",
       "1739            rewr                 rewr    5.530431   0.792268   \n",
       "2105            rewr                 rewr  100.000000  47.316149   \n",
       "1210            rewr                 orig    0.496431   0.489113   \n",
       "1015            orig                 orig    0.282343   0.323916   \n",
       "1180            orig                 orig    0.642257   0.754238   \n",
       "1149            rewr                 orig    0.669017   0.667051   \n",
       "1736            rewr                 rewr    5.258001   0.825190   \n",
       "2476            orig                 orig    0.190571   0.293480   \n",
       "7               orig                 orig    0.248959   0.305712   \n",
       "2293            orig                 orig   62.264197  64.633271   \n",
       "927             rewr                 orig    0.549356   0.510466   \n",
       "1774            orig                 orig    0.187277   0.375633   \n",
       "955             orig                 orig    0.428752   0.477420   \n",
       "1056            orig                 orig    0.439631   0.443599   \n",
       "925             orig                 orig    0.519803   0.617351   \n",
       "963             rewr                 orig    0.602283   0.576377   \n",
       "904             rewr                 orig    0.620385   0.611789   \n",
       "798             orig                 orig    0.245410   0.312055   \n",
       "2631            orig                 orig    2.157892   2.260612   \n",
       "1309            rewr                 orig    0.605470   0.528589   \n",
       "2599            rewr                 orig    2.284644   2.003512   \n",
       "1922            rewr                 rewr  100.000000   2.059813   \n",
       "1549            orig                 orig    0.396640   0.456243   \n",
       "296             rewr                 orig    0.458169   0.385003   \n",
       "2644            rewr                 orig    2.071347   2.062725   \n",
       "172             rewr                 orig    0.465446   0.460443   \n",
       "1638            orig                 orig    0.405899   0.468322   \n",
       "446             rewr                 orig    0.503076   0.420642   \n",
       "1410            orig                 orig    0.614087   0.705318   \n",
       "678             rewr                 orig    0.497410   0.411260   \n",
       "1291            rewr                 orig    0.544392   0.510644   \n",
       "478             orig                 orig    0.539265   0.650891   \n",
       "620             orig                 orig    0.306332   0.504485   \n",
       "2441            orig                 orig    0.552251   0.581946   \n",
       "1486            orig                 orig    0.238843   0.435648   \n",
       "2616            rewr                 orig    2.245658   2.210728   \n",
       "715             rewr                 orig    0.518876   0.507485   \n",
       "991             rewr                 orig    0.617876   0.569743   \n",
       "\n",
       "      rewr mean+rewr  diff rewr-orig  ...  q75(branching factors)  \\\n",
       "1349        2.328231       -0.064508  ...                    4.00   \n",
       "2477        2.454935        0.116503  ...                    2.50   \n",
       "2534        2.638695        0.012236  ...                    2.50   \n",
       "1268        1.273657        0.059759  ...                    1.00   \n",
       "2420        2.760506       -0.017600  ...                    2.50   \n",
       "299         2.124599       -0.012804  ...                    1.00   \n",
       "1341        1.484276       -0.022076  ...                    2.50   \n",
       "1740        2.626288       -4.805910  ...                    4.00   \n",
       "2694        4.014254        0.095418  ...                    2.50   \n",
       "2480        2.236466        0.015833  ...                    2.50   \n",
       "608         2.745154        0.093607  ...                    1.75   \n",
       "1739        2.848849       -4.738162  ...                    4.00   \n",
       "2105       49.300901      -52.683851  ...                    2.50   \n",
       "1210        1.590290       -0.007318  ...                    3.00   \n",
       "1015        2.291740        0.041573  ...                    3.00   \n",
       "1180        2.639731        0.111981  ...                    1.75   \n",
       "1149        2.649943       -0.001965  ...                    3.25   \n",
       "1736        2.791115       -4.432811  ...                    6.00   \n",
       "2476        2.259293        0.102909  ...                    2.50   \n",
       "7           2.158816        0.056753  ...                    1.00   \n",
       "2293       66.638959        2.369074  ...                    2.50   \n",
       "927         2.482725       -0.038890  ...                    1.75   \n",
       "1774        2.325579        0.188355  ...                    1.75   \n",
       "955         2.450607        0.048668  ...                    1.00   \n",
       "1056        2.432668        0.003967  ...                    2.00   \n",
       "925         2.585629        0.097549  ...                    3.00   \n",
       "963         2.642454       -0.025906  ...                    4.00   \n",
       "904         1.680814       -0.008595  ...                    5.00   \n",
       "798         2.550724        0.066645  ...                    3.00   \n",
       "2631        4.226928        0.102720  ...                    2.00   \n",
       "1309        2.401235       -0.076881  ...                    3.25   \n",
       "2599        3.956240       -0.281132  ...                    2.50   \n",
       "1922        4.357800      -97.940187  ...                    2.50   \n",
       "1549        1.497873        0.059602  ...                    2.50   \n",
       "296         2.186201       -0.073166  ...                    1.00   \n",
       "2644        4.075672       -0.008622  ...                    2.50   \n",
       "172         1.434189       -0.005003  ...                    2.50   \n",
       "1638        2.437323        0.062423  ...                    3.00   \n",
       "446         2.365454       -0.082434  ...                    1.75   \n",
       "1410        1.710992        0.091231  ...                    5.00   \n",
       "678         2.225097       -0.086150  ...                    2.00   \n",
       "1291        2.470447       -0.033748  ...                    3.00   \n",
       "478         2.563208        0.111626  ...                    1.75   \n",
       "620         2.638419        0.198153  ...                    3.00   \n",
       "2441        2.635486        0.029695  ...                    2.50   \n",
       "1486        2.658918        0.196805  ...                    1.75   \n",
       "2616        4.229289       -0.034930  ...                    2.00   \n",
       "715         2.473964       -0.011392  ...                    3.25   \n",
       "991         2.545614       -0.048133  ...                    2.50   \n",
       "\n",
       "      balancedness factor                              container counts list  \\\n",
       "1349             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2477             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2534             0.625000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1268                  NaN               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "2420             1.000000                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "299                   NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1341             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1740             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2694             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2480             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "608              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1739             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2105             1.000000                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "1210             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1015             1.000000   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]   \n",
       "1180             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1149             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1736             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2476             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "7                     NaN      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "2293             0.666667  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "927              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1774             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "955                   NaN         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "1056             1.000000         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "925              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "963              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "904              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "798              1.000000   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]   \n",
       "2631             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1309             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2599             1.000000                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "1922             1.000000                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "1549             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "296                   NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2644             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "172              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1638             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "446              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1410             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "678              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1291             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "478              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "620              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2441             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1486             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2616             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "715              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "991              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "      branching factors list                     hypergraph  \\\n",
       "1349                     [4]  Hypergraph(num_v=28, num_e=5)   \n",
       "2477               [1, 1, 4]  Hypergraph(num_v=14, num_e=7)   \n",
       "2534               [1, 3, 2]  Hypergraph(num_v=14, num_e=7)   \n",
       "1268                  [1, 1]  Hypergraph(num_v=14, num_e=3)   \n",
       "2420                  [1, 3]  Hypergraph(num_v=10, num_e=5)   \n",
       "299                   [1, 1]  Hypergraph(num_v=20, num_e=3)   \n",
       "1341                  [3, 1]  Hypergraph(num_v=28, num_e=5)   \n",
       "1740                  [5, 1]  Hypergraph(num_v=40, num_e=7)   \n",
       "2694               [2, 1, 3]  Hypergraph(num_v=14, num_e=7)   \n",
       "2480               [2, 1, 3]  Hypergraph(num_v=14, num_e=7)   \n",
       "608                   [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "1739                  [5, 1]  Hypergraph(num_v=40, num_e=7)   \n",
       "2105                  [1, 3]  Hypergraph(num_v=10, num_e=5)   \n",
       "1210                     [3]  Hypergraph(num_v=20, num_e=4)   \n",
       "1015                     [3]  Hypergraph(num_v=19, num_e=4)   \n",
       "1180                  [2, 1]  Hypergraph(num_v=26, num_e=4)   \n",
       "1149                  [4, 1]  Hypergraph(num_v=35, num_e=6)   \n",
       "1736                     [6]  Hypergraph(num_v=40, num_e=7)   \n",
       "2476               [1, 1, 4]  Hypergraph(num_v=14, num_e=7)   \n",
       "7                     [1, 1]  Hypergraph(num_v=17, num_e=3)   \n",
       "2293               [1, 2, 3]  Hypergraph(num_v=46, num_e=7)   \n",
       "927                   [2, 1]  Hypergraph(num_v=21, num_e=4)   \n",
       "1774                  [2, 1]  Hypergraph(num_v=20, num_e=4)   \n",
       "955                   [1, 1]  Hypergraph(num_v=16, num_e=3)   \n",
       "1056                     [2]  Hypergraph(num_v=16, num_e=3)   \n",
       "925                      [3]  Hypergraph(num_v=21, num_e=4)   \n",
       "963                      [4]  Hypergraph(num_v=31, num_e=5)   \n",
       "904                      [5]  Hypergraph(num_v=34, num_e=6)   \n",
       "798                      [3]  Hypergraph(num_v=19, num_e=4)   \n",
       "2631               [2, 2, 2]  Hypergraph(num_v=14, num_e=7)   \n",
       "1309                  [4, 1]  Hypergraph(num_v=35, num_e=6)   \n",
       "2599                  [1, 3]  Hypergraph(num_v=10, num_e=5)   \n",
       "1922                  [1, 3]  Hypergraph(num_v=10, num_e=5)   \n",
       "1549                  [3, 1]  Hypergraph(num_v=29, num_e=5)   \n",
       "296                   [1, 1]  Hypergraph(num_v=20, num_e=3)   \n",
       "2644               [1, 1, 4]  Hypergraph(num_v=14, num_e=7)   \n",
       "172                   [3, 1]  Hypergraph(num_v=27, num_e=5)   \n",
       "1638                     [3]  Hypergraph(num_v=24, num_e=4)   \n",
       "446                   [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "1410                     [5]  Hypergraph(num_v=35, num_e=6)   \n",
       "678                      [2]  Hypergraph(num_v=20, num_e=3)   \n",
       "1291                     [3]  Hypergraph(num_v=22, num_e=4)   \n",
       "478                   [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "620                      [3]  Hypergraph(num_v=22, num_e=4)   \n",
       "2441               [2, 1, 3]  Hypergraph(num_v=14, num_e=7)   \n",
       "1486                  [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "2616               [2, 2, 2]  Hypergraph(num_v=14, num_e=7)   \n",
       "715                   [4, 1]  Hypergraph(num_v=35, num_e=6)   \n",
       "991                   [3, 1]  Hypergraph(num_v=31, num_e=5)   \n",
       "\n",
       "                                                   text  orig/rewr/equal 0.5  \\\n",
       "1349  SELECT MIN(p.id) FROM tags as t, posts as p, u...                equal   \n",
       "2477  SELECT MIN(t.sid) FROM compound c1, palliates ...                equal   \n",
       "2534  SELECT MIN(d2.nid) FROM compound c1, treats t,...                equal   \n",
       "1268  SELECT MIN(b.id) FROM comments as c, badges as...                equal   \n",
       "2420  SELECT MIN(g.nid) FROM compound c, upregulates...                equal   \n",
       "299   SELECT MIN(ph.id) FROM posts as p, postLinks a...                equal   \n",
       "1341  SELECT MIN(v.id) FROM tags as t, posts as p, u...                equal   \n",
       "1740  SELECT MIN(v.id) FROM comments as c, posts as ...                 rewr   \n",
       "2694  SELECT MIN(g2.nid) FROM disease d, upregulates...                equal   \n",
       "2480  SELECT MIN(r1.sid) FROM compound c1, resembles...                equal   \n",
       "608   SELECT MIN(ph.Id) FROM postHistory as ph, post...                equal   \n",
       "1739  SELECT MIN(ph.id) FROM comments as c, posts as...                 rewr   \n",
       "2105  SELECT MIN(p4b.fromnode) FROM wiki p1, wiki p2...                 rewr   \n",
       "1210  SELECT MIN(ph.Id) FROM postHistory as ph, vote...                equal   \n",
       "1015  SELECT MIN(c.Id) FROM comments as c, postHisto...                equal   \n",
       "1180  SELECT MIN(c.Id) FROM comments as c, postHisto...                equal   \n",
       "1149  SELECT MIN(ph.id) FROM comments as c, posts as...                equal   \n",
       "1736  SELECT MIN(c.Id) FROM comments as c, posts as ...                 rewr   \n",
       "2476  SELECT MIN(c2.nid) FROM compound c1, palliates...                equal   \n",
       "7     SELECT MIN(c.id) FROM comments as c, votes as ...                equal   \n",
       "2293  SELECT MIN(mc.id) AS member_in_charnamed_movie...                 orig   \n",
       "927   SELECT MIN(v.id) FROM comments as c, postLinks...                equal   \n",
       "1774  SELECT MIN(v.id) FROM comments as c, votes as ...                equal   \n",
       "955   SELECT MIN(c.Id) FROM comments as c, postHisto...                equal   \n",
       "1056  SELECT MIN(u.id) FROM comments as c, postHisto...                equal   \n",
       "925   SELECT MIN(pl.id) FROM comments as c, postLink...                equal   \n",
       "963   SELECT MIN(ph.id) FROM comments as c, postLink...                equal   \n",
       "904   SELECT MIN(c.Id) FROM comments as c, posts as ...                equal   \n",
       "798   SELECT MIN(u.id) FROM comments as c, postHisto...                equal   \n",
       "2631  SELECT MIN(c.nid) FROM cellular_component cc, ...                equal   \n",
       "1309  SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "2599  SELECT MIN(e.sid) FROM biological_process bp, ...                equal   \n",
       "1922  SELECT MIN(p4b.fromnode) FROM dblp p1, dblp p2...                 rewr   \n",
       "1549  SELECT MIN(c.Id) FROM comments as c, posts as ...                equal   \n",
       "296   SELECT MIN(ph.id) FROM posts as p, postLinks a...                equal   \n",
       "2644  SELECT MIN(d.sid) FROM cellular_component cc, ...                equal   \n",
       "172   SELECT MIN(ph.id) FROM tags as t, posts as p, ...                equal   \n",
       "1638  SELECT MIN(u.id) FROM postHistory as ph, posts...                equal   \n",
       "446   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "1410  SELECT MIN(p.id) FROM comments as c, posts as ...                equal   \n",
       "678   SELECT MIN(ph.id) FROM comments as c, posts as...                equal   \n",
       "1291  SELECT MIN(u.id) FROM comments as c, postHisto...                equal   \n",
       "478   SELECT MIN(c.Id) FROM comments as c, posts as ...                equal   \n",
       "620   SELECT MIN(c.Id) FROM comments as c, postHisto...                equal   \n",
       "2441  SELECT MIN(g2.nid) FROM compound c1, binds b1,...                equal   \n",
       "1486  SELECT MIN(p.id) FROM comments as c, posts as ...                equal   \n",
       "2616  SELECT MIN(i.sid) FROM disease d, associates a...                equal   \n",
       "715   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "991   SELECT MIN(v.id) FROM comments as c, postLinks...                equal   \n",
       "\n",
       "      orig/rewr/equal 0.1  orig/rewr/equal 0.05  orig/rewr/equal 0.01  \n",
       "1349                equal                  rewr                  rewr  \n",
       "2477                 orig                  orig                  orig  \n",
       "2534                equal                 equal                  orig  \n",
       "1268                equal                  orig                  orig  \n",
       "2420                equal                 equal                  rewr  \n",
       "299                 equal                 equal                  rewr  \n",
       "1341                equal                 equal                  rewr  \n",
       "1740                 rewr                  rewr                  rewr  \n",
       "2694                equal                  orig                  orig  \n",
       "2480                equal                 equal                  orig  \n",
       "608                 equal                  orig                  orig  \n",
       "1739                 rewr                  rewr                  rewr  \n",
       "2105                 rewr                  rewr                  rewr  \n",
       "1210                equal                 equal                 equal  \n",
       "1015                equal                 equal                  orig  \n",
       "1180                 orig                  orig                  orig  \n",
       "1149                equal                 equal                 equal  \n",
       "1736                 rewr                  rewr                  rewr  \n",
       "2476                 orig                  orig                  orig  \n",
       "7                   equal                  orig                  orig  \n",
       "2293                 orig                  orig                  orig  \n",
       "927                 equal                 equal                  rewr  \n",
       "1774                 orig                  orig                  orig  \n",
       "955                 equal                 equal                  orig  \n",
       "1056                equal                 equal                 equal  \n",
       "925                 equal                  orig                  orig  \n",
       "963                 equal                 equal                  rewr  \n",
       "904                 equal                 equal                 equal  \n",
       "798                 equal                  orig                  orig  \n",
       "2631                 orig                  orig                  orig  \n",
       "1309                equal                  rewr                  rewr  \n",
       "2599                 rewr                  rewr                  rewr  \n",
       "1922                 rewr                  rewr                  rewr  \n",
       "1549                equal                  orig                  orig  \n",
       "296                 equal                  rewr                  rewr  \n",
       "2644                equal                 equal                 equal  \n",
       "172                 equal                 equal                 equal  \n",
       "1638                equal                  orig                  orig  \n",
       "446                 equal                  rewr                  rewr  \n",
       "1410                equal                  orig                  orig  \n",
       "678                 equal                  rewr                  rewr  \n",
       "1291                equal                 equal                  rewr  \n",
       "478                  orig                  orig                  orig  \n",
       "620                  orig                  orig                  orig  \n",
       "2441                equal                 equal                  orig  \n",
       "1486                 orig                  orig                  orig  \n",
       "2616                equal                 equal                  rewr  \n",
       "715                 equal                 equal                  rewr  \n",
       "991                 equal                 equal                  rewr  \n",
       "\n",
       "[49 rows x 37 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass_forest = df.loc[X_val.index]\n",
    "misclass_forest.insert(0, 'true label', np.array(y1_val))\n",
    "misclass_forest.insert(0, 'pred label', y1_pred_rand_forest)\n",
    "indices_not_equal = np.where(y1_val != y1_pred_rand_forest)[0]\n",
    "misclass_forest = misclass_forest.iloc[indices_not_equal]\n",
    "misclass_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "930dc37c-ba10-4dc3-b2dc-96fab2e9b620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1098346/3310901294.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass_1_forest[\"cut\"] = pd.cut(abs(misclass_1_forest['diff rewr-orig']), bins=bins, labels=labels)\n",
      "/tmp/ipykernel_1098346/3310901294.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass_0_forest[\"cut\"] = pd.cut(abs(misclass_0_forest['diff rewr-orig']), bins=bins, labels=labels)\n",
      "/tmp/ipykernel_1098346/3310901294.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  table_1_forest = misclass_1_forest.groupby('cut').size().reset_index(name='count_1')\n",
      "/tmp/ipykernel_1098346/3310901294.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  table_0_forest = misclass_0_forest.groupby('cut').size().reset_index(name='count_0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cut</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>TO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cut  0.01  0.1  1  10  100  TO\n",
       "FP      1   14  8   1    0   0\n",
       "FN      5   14  1   3    2   0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 0.01, 0.1, 1, 10, 100, float('inf')]\n",
    "labels = ['0.01', '0.1', '1', '10', '100', 'TO']\n",
    "\n",
    "misclass_1_forest = misclass_forest[misclass_forest[\"pred label\"] == 1]\n",
    "misclass_0_forest = misclass_forest[misclass_forest[\"pred label\"] == 0]\n",
    "\n",
    "misclass_1_forest[\"cut\"] = pd.cut(abs(misclass_1_forest['diff rewr-orig']), bins=bins, labels=labels)\n",
    "misclass_0_forest[\"cut\"] = pd.cut(abs(misclass_0_forest['diff rewr-orig']), bins=bins, labels=labels)\n",
    "\n",
    "table_1_forest = misclass_1_forest.groupby('cut').size().reset_index(name='count_1')\n",
    "table_0_forest = misclass_0_forest.groupby('cut').size().reset_index(name='count_0')\n",
    "\n",
    "table_forest = pd.merge(table_1_forest, table_0_forest, on='cut', how='outer')\n",
    "table_forest = table_forest.set_index('cut').T\n",
    "table_forest.index = ['FP', 'FN']\n",
    "table_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a10757a7-0d69-450b-9571-3e1fb054b1b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5765\n",
      "Validation Loss: 0.4813\n",
      "Saved the best model with validation loss: 0.4813\n",
      "Epoch [2/100], Loss: 0.4688\n",
      "Validation Loss: 0.4349\n",
      "Saved the best model with validation loss: 0.4349\n",
      "Epoch [3/100], Loss: 0.4366\n",
      "Validation Loss: 0.4106\n",
      "Saved the best model with validation loss: 0.4106\n",
      "Epoch [4/100], Loss: 0.4183\n",
      "Validation Loss: 0.4076\n",
      "Saved the best model with validation loss: 0.4076\n",
      "Epoch [5/100], Loss: 0.4081\n",
      "Validation Loss: 0.3948\n",
      "Saved the best model with validation loss: 0.3948\n",
      "Epoch [6/100], Loss: 0.4009\n",
      "Validation Loss: 0.3934\n",
      "Saved the best model with validation loss: 0.3934\n",
      "Epoch [7/100], Loss: 0.3939\n",
      "Validation Loss: 0.4025\n",
      "Epoch [8/100], Loss: 0.3918\n",
      "Validation Loss: 0.3953\n",
      "Epoch [9/100], Loss: 0.3816\n",
      "Validation Loss: 0.4540\n",
      "Epoch [10/100], Loss: 0.3798\n",
      "Validation Loss: 0.4869\n",
      "Epoch [11/100], Loss: 0.3803\n",
      "Validation Loss: 0.4187\n",
      "Epoch [12/100], Loss: 0.3749\n",
      "Validation Loss: 0.3832\n",
      "Saved the best model with validation loss: 0.3832\n",
      "Epoch [13/100], Loss: 0.3695\n",
      "Validation Loss: 0.3834\n",
      "Epoch [14/100], Loss: 0.3713\n",
      "Validation Loss: 0.4111\n",
      "Epoch [15/100], Loss: 0.3672\n",
      "Validation Loss: 0.5234\n",
      "Epoch [16/100], Loss: 0.3658\n",
      "Validation Loss: 0.6416\n",
      "Epoch [17/100], Loss: 0.3693\n",
      "Validation Loss: 0.3976\n",
      "Epoch [18/100], Loss: 0.3651\n",
      "Validation Loss: 0.3640\n",
      "Saved the best model with validation loss: 0.3640\n",
      "Epoch [19/100], Loss: 0.3627\n",
      "Validation Loss: 0.4392\n",
      "Epoch [20/100], Loss: 0.3587\n",
      "Validation Loss: 0.6487\n",
      "Epoch [21/100], Loss: 0.3635\n",
      "Validation Loss: 0.4514\n",
      "Epoch [22/100], Loss: 0.3620\n",
      "Validation Loss: 0.3754\n",
      "Epoch [23/100], Loss: 0.3570\n",
      "Validation Loss: 0.3720\n",
      "Epoch [24/100], Loss: 0.3575\n",
      "Validation Loss: 0.3656\n",
      "Epoch [25/100], Loss: 0.3562\n",
      "Validation Loss: 0.3743\n",
      "Epoch [26/100], Loss: 0.3539\n",
      "Validation Loss: 0.3707\n",
      "Epoch [27/100], Loss: 0.3494\n",
      "Validation Loss: 0.7326\n",
      "Epoch [28/100], Loss: 0.3597\n",
      "Validation Loss: 0.3926\n",
      "Epoch [29/100], Loss: 0.3538\n",
      "Validation Loss: 0.3594\n",
      "Saved the best model with validation loss: 0.3594\n",
      "Epoch [30/100], Loss: 0.3438\n",
      "Validation Loss: 0.3928\n",
      "Epoch [31/100], Loss: 0.3452\n",
      "Validation Loss: 0.3820\n",
      "Epoch [32/100], Loss: 0.3464\n",
      "Validation Loss: 0.3727\n",
      "Epoch [33/100], Loss: 0.3446\n",
      "Validation Loss: 0.3800\n",
      "Epoch [34/100], Loss: 0.3563\n",
      "Validation Loss: 0.3806\n",
      "Epoch [35/100], Loss: 0.3434\n",
      "Validation Loss: 0.3765\n",
      "Epoch [36/100], Loss: 0.3427\n",
      "Validation Loss: 0.3746\n",
      "Epoch [37/100], Loss: 0.3347\n",
      "Validation Loss: 0.3891\n",
      "Epoch [38/100], Loss: 0.3420\n",
      "Validation Loss: 0.3817\n",
      "Epoch [39/100], Loss: 0.3415\n",
      "Validation Loss: 0.3783\n",
      "Epoch [40/100], Loss: 0.3360\n",
      "Validation Loss: 0.3986\n",
      "Epoch [41/100], Loss: 0.3496\n",
      "Validation Loss: 0.3748\n",
      "Epoch [42/100], Loss: 0.3450\n",
      "Validation Loss: 0.3678\n",
      "Epoch [43/100], Loss: 0.3341\n",
      "Validation Loss: 0.3898\n",
      "Epoch [44/100], Loss: 0.3511\n",
      "Validation Loss: 0.4047\n",
      "Epoch [45/100], Loss: 0.3393\n",
      "Validation Loss: 0.3871\n",
      "Epoch [46/100], Loss: 0.3358\n",
      "Validation Loss: 0.3762\n",
      "Epoch [47/100], Loss: 0.3328\n",
      "Validation Loss: 0.3899\n",
      "Epoch [48/100], Loss: 0.3386\n",
      "Validation Loss: 0.3892\n",
      "Epoch [49/100], Loss: 0.3330\n",
      "Validation Loss: 0.4055\n",
      "Epoch [50/100], Loss: 0.3372\n",
      "Validation Loss: 0.3898\n",
      "Epoch [51/100], Loss: 0.3310\n",
      "Validation Loss: 0.3959\n",
      "Epoch [52/100], Loss: 0.3324\n",
      "Validation Loss: 0.3846\n",
      "Epoch [53/100], Loss: 0.3442\n",
      "Validation Loss: 0.3777\n",
      "Epoch [54/100], Loss: 0.3279\n",
      "Validation Loss: 0.3949\n",
      "Epoch [55/100], Loss: 0.3319\n",
      "Validation Loss: 0.3871\n",
      "Epoch [56/100], Loss: 0.3381\n",
      "Validation Loss: 0.3888\n",
      "Epoch [57/100], Loss: 0.3280\n",
      "Validation Loss: 0.3958\n",
      "Epoch [58/100], Loss: 0.3287\n",
      "Validation Loss: 0.3841\n",
      "Epoch [59/100], Loss: 0.3370\n",
      "Validation Loss: 0.3705\n",
      "Epoch [60/100], Loss: 0.3315\n",
      "Validation Loss: 0.3994\n",
      "Epoch [61/100], Loss: 0.3406\n",
      "Validation Loss: 0.3790\n",
      "Epoch [62/100], Loss: 0.3306\n",
      "Validation Loss: 0.4065\n",
      "Epoch [63/100], Loss: 0.3302\n",
      "Validation Loss: 0.3906\n",
      "Epoch [64/100], Loss: 0.3313\n",
      "Validation Loss: 0.3729\n",
      "Epoch [65/100], Loss: 0.3255\n",
      "Validation Loss: 0.4069\n",
      "Epoch [66/100], Loss: 0.3360\n",
      "Validation Loss: 0.4095\n",
      "Epoch [67/100], Loss: 0.3296\n",
      "Validation Loss: 0.4011\n",
      "Epoch [68/100], Loss: 0.3282\n",
      "Validation Loss: 0.3762\n",
      "Epoch [69/100], Loss: 0.3292\n",
      "Validation Loss: 0.3690\n",
      "Epoch [70/100], Loss: 0.3384\n",
      "Validation Loss: 0.3762\n",
      "Epoch [71/100], Loss: 0.3365\n",
      "Validation Loss: 0.3790\n",
      "Epoch [72/100], Loss: 0.3282\n",
      "Validation Loss: 0.3786\n",
      "Epoch [73/100], Loss: 0.3684\n",
      "Validation Loss: 0.3874\n",
      "Epoch [74/100], Loss: 0.3268\n",
      "Validation Loss: 0.3630\n",
      "Epoch [75/100], Loss: 0.3250\n",
      "Validation Loss: 0.4346\n",
      "Epoch [76/100], Loss: 0.3320\n",
      "Validation Loss: 0.3554\n",
      "Saved the best model with validation loss: 0.3554\n",
      "Epoch [77/100], Loss: 0.3590\n",
      "Validation Loss: 0.4344\n",
      "Epoch [78/100], Loss: 0.3378\n",
      "Validation Loss: 0.3516\n",
      "Saved the best model with validation loss: 0.3516\n",
      "Epoch [79/100], Loss: 0.3423\n",
      "Validation Loss: 0.3679\n",
      "Epoch [80/100], Loss: 0.3252\n",
      "Validation Loss: 0.4065\n",
      "Epoch [81/100], Loss: 0.3418\n",
      "Validation Loss: 0.3636\n",
      "Epoch [82/100], Loss: 0.3306\n",
      "Validation Loss: 0.4064\n",
      "Epoch [83/100], Loss: 0.3316\n",
      "Validation Loss: 0.3869\n",
      "Epoch [84/100], Loss: 0.3359\n",
      "Validation Loss: 0.3765\n",
      "Epoch [85/100], Loss: 0.3245\n",
      "Validation Loss: 0.3867\n",
      "Epoch [86/100], Loss: 0.3307\n",
      "Validation Loss: 0.3670\n",
      "Epoch [87/100], Loss: 0.3389\n",
      "Validation Loss: 0.4165\n",
      "Epoch [88/100], Loss: 0.3435\n",
      "Validation Loss: 0.4189\n",
      "Epoch [89/100], Loss: 0.3310\n",
      "Validation Loss: 0.4215\n",
      "Epoch [90/100], Loss: 0.3344\n",
      "Validation Loss: 0.4199\n",
      "Epoch [91/100], Loss: 0.3283\n",
      "Validation Loss: 0.3988\n",
      "Epoch [92/100], Loss: 0.3408\n",
      "Validation Loss: 0.3855\n",
      "Epoch [93/100], Loss: 0.3343\n",
      "Validation Loss: 0.3612\n",
      "Epoch [94/100], Loss: 0.3280\n",
      "Validation Loss: 0.3922\n",
      "Epoch [95/100], Loss: 0.3379\n",
      "Validation Loss: 0.3678\n",
      "Epoch [96/100], Loss: 0.3550\n",
      "Validation Loss: 0.3585\n",
      "Epoch [97/100], Loss: 0.3304\n",
      "Validation Loss: 0.3797\n",
      "Epoch [98/100], Loss: 0.3362\n",
      "Validation Loss: 0.3716\n",
      "Epoch [99/100], Loss: 0.3457\n",
      "Validation Loss: 0.4525\n",
      "Epoch [100/100], Loss: 0.3355\n",
      "Validation Loss: 2.0087\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, label_series, hypergraph_column_name):\n",
    "        # Extract features and convert to tensor\n",
    "        self.X = torch.from_numpy(dataframe.drop(columns=[hypergraph_column_name]).values).float()\n",
    "        \n",
    "        # Extract labels and convert to tensor\n",
    "        self.y = torch.from_numpy(label_series.values).float()\n",
    "        \n",
    "        # Store hypergraph objects\n",
    "        self.hypergraphs = dataframe[hypergraph_column_name].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.X[index],\n",
    "            'label': self.y[index],\n",
    "            'hypergraph': self.hypergraphs[index]\n",
    "        }\n",
    "\n",
    "def combined_classification(X_training, y_training, X_validation, y_validation, type, text):\n",
    "    model = CombinedNetwork(random_seed = 20)  \n",
    "\n",
    "    dataset = CustomDataset(X_training, y_training, hypergraph_column_name='hypergraph')\n",
    "    validation = CustomDataset(X_validation, y_validation, hypergraph_column_name='hypergraph')\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for item in dataset:\n",
    "            optimizer.zero_grad()\n",
    "            input_features = item[\"data\"]\n",
    "            input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "            label = item[\"label\"].long()\n",
    "            output = model(input_features, input_hg)\n",
    "            \n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataset):.4f}')\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for item in validation:\n",
    "                input_features = item[\"data\"]\n",
    "                input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "                label = item[\"label\"].long()\n",
    "                output = model(input_features, input_hg)\n",
    "                loss = loss_function(output, label)\n",
    "                val_loss += loss.item()\n",
    "    \n",
    "        val_loss /= len(validation)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "        # Save the model if the validation loss is the best we've seen so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Saved the best model with validation loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for item in validation:\n",
    "            i += 1\n",
    "            output = model(item[\"data\"], item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0))\n",
    "            _, pred = torch.max(output.data, 0)\n",
    "            predicted.append(pred.item())\n",
    "\n",
    "    return predicted\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output\n",
    "\n",
    "y1_pred_combi = combined_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"combi: 17-80-50-10/1-16-32-10/20-60-20-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "531ea541-1e31-44d5-8e38-648cc3f6f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8395904436860068\n",
      "0.8482758620689655\n",
      "0.831081081081081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[123,  22],\n",
       "       [ 25, 123]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_combi)\n",
    "print(accuracy)\n",
    "precision = precision_score(y1_val, y1_pred_combi)\n",
    "print(precision)\n",
    "recall = recall_score(y1_val, y1_pred_combi)\n",
    "print(recall)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_combi)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "617051ac-309c-467a-a12d-c51f1d853d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred label</th>\n",
       "      <th>true label</th>\n",
       "      <th>bench</th>\n",
       "      <th>query</th>\n",
       "      <th>orig/rewr(mean)</th>\n",
       "      <th>orig/rewr+rewr(mean)</th>\n",
       "      <th>orig mean</th>\n",
       "      <th>rewr mean</th>\n",
       "      <th>rewr mean+rewr</th>\n",
       "      <th>diff rewr-orig</th>\n",
       "      <th>...</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <th>balancedness factor</th>\n",
       "      <th>container counts list</th>\n",
       "      <th>branching factors list</th>\n",
       "      <th>hypergraph</th>\n",
       "      <th>text</th>\n",
       "      <th>orig/rewr/equal 0.5</th>\n",
       "      <th>orig/rewr/equal 0.1</th>\n",
       "      <th>orig/rewr/equal 0.05</th>\n",
       "      <th>orig/rewr/equal 0.01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>111-056-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.596748</td>\n",
       "      <td>0.532240</td>\n",
       "      <td>2.328231</td>\n",
       "      <td>-0.064508</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=28, num_e=5)</td>\n",
       "      <td>SELECT MIN(p.id) FROM tags as t, posts as p, u...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-08-CpDpCtD-augA5</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.184137</td>\n",
       "      <td>0.300639</td>\n",
       "      <td>2.454935</td>\n",
       "      <td>0.116503</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(t.sid) FROM compound c1, palliates ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-16-CtDuGuD-augA6</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.574174</td>\n",
       "      <td>0.586411</td>\n",
       "      <td>2.638695</td>\n",
       "      <td>0.012236</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(d2.nid) FROM compound c1, treats t,...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>104-088-augF2-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.215694</td>\n",
       "      <td>0.275453</td>\n",
       "      <td>1.273657</td>\n",
       "      <td>0.059759</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=3)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, badges as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>2-05-CuGdD-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.557119</td>\n",
       "      <td>0.539519</td>\n",
       "      <td>2.760506</td>\n",
       "      <td>-0.017600</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(g.nid) FROM compound c, upregulates...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>023-018-augF2-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.283540</td>\n",
       "      <td>0.270736</td>\n",
       "      <td>2.124599</td>\n",
       "      <td>-0.012804</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=3)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM posts as p, postLinks a...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>110-138-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.481653</td>\n",
       "      <td>0.459576</td>\n",
       "      <td>1.484276</td>\n",
       "      <td>-0.022076</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=28, num_e=5)</td>\n",
       "      <td>SELECT MIN(v.id) FROM tags as t, posts as p, u...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>137-141-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>5.530137</td>\n",
       "      <td>0.724227</td>\n",
       "      <td>2.626288</td>\n",
       "      <td>-4.805910</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 1]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>9-07-DuGcGpMF-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>1.934141</td>\n",
       "      <td>2.029559</td>\n",
       "      <td>4.014254</td>\n",
       "      <td>0.095418</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(g2.nid) FROM disease d, upregulates...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-09-CrCrCtD-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.315867</td>\n",
       "      <td>0.331699</td>\n",
       "      <td>2.236466</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(r1.sid) FROM compound c1, resembles...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>137-141-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>5.530431</td>\n",
       "      <td>0.792268</td>\n",
       "      <td>2.848849</td>\n",
       "      <td>-4.738162</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5, 1]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, posts as...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>014-134-augA3</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.428753</td>\n",
       "      <td>0.548521</td>\n",
       "      <td>2.462337</td>\n",
       "      <td>0.119768</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>098-124-augF1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.496431</td>\n",
       "      <td>0.489113</td>\n",
       "      <td>1.590290</td>\n",
       "      <td>-0.007318</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=4)</td>\n",
       "      <td>SELECT MIN(ph.Id) FROM postHistory as ph, vote...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>093-075-augF2-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.669017</td>\n",
       "      <td>0.667051</td>\n",
       "      <td>2.649943</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, posts as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>7-01-DaGiGpBP-augF2-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>1.995038</td>\n",
       "      <td>2.303148</td>\n",
       "      <td>4.285069</td>\n",
       "      <td>0.308110</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(g1.nid) FROM disease d, associates ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>137-141</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>5.258001</td>\n",
       "      <td>0.825190</td>\n",
       "      <td>2.791115</td>\n",
       "      <td>-4.432811</td>\n",
       "      <td>...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-08-CpDpCtD-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.190571</td>\n",
       "      <td>0.293480</td>\n",
       "      <td>2.259293</td>\n",
       "      <td>0.102909</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(c2.nid) FROM compound c1, palliates...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>096-095-augF1-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.605563</td>\n",
       "      <td>0.587985</td>\n",
       "      <td>2.769054</td>\n",
       "      <td>-0.017578</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=26, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>JOB</td>\n",
       "      <td>17e-augF1-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>62.264197</td>\n",
       "      <td>64.633271</td>\n",
       "      <td>66.638959</td>\n",
       "      <td>2.369074</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>Hypergraph(num_v=46, num_e=7)</td>\n",
       "      <td>SELECT MIN(mc.id) AS member_in_charnamed_movie...</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>075-037-augF2-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.510466</td>\n",
       "      <td>2.482725</td>\n",
       "      <td>-0.038890</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=21, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, postLinks...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>139-034-augF1-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.187277</td>\n",
       "      <td>0.375633</td>\n",
       "      <td>2.325579</td>\n",
       "      <td>0.188355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, votes as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>078-082-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.428752</td>\n",
       "      <td>0.477420</td>\n",
       "      <td>2.450607</td>\n",
       "      <td>0.048668</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=3)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>086-083-augF2-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.439631</td>\n",
       "      <td>0.443599</td>\n",
       "      <td>2.432668</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=3)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>079-112-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.602283</td>\n",
       "      <td>0.576377</td>\n",
       "      <td>2.642454</td>\n",
       "      <td>-0.025906</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=31, num_e=5)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, postLink...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>8-01-CCpGdCcSE-augF2-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.092116</td>\n",
       "      <td>2.099886</td>\n",
       "      <td>4.096027</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(p.sid) FROM cellular_component cc, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>119-098-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.687296</td>\n",
       "      <td>0.481457</td>\n",
       "      <td>2.727080</td>\n",
       "      <td>-0.205839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(p.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>074-072-augF1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.620385</td>\n",
       "      <td>0.611789</td>\n",
       "      <td>1.680814</td>\n",
       "      <td>-0.008595</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>Hypergraph(num_v=34, num_e=6)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>064-116-augF2-augA3</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.312055</td>\n",
       "      <td>2.550724</td>\n",
       "      <td>0.066645</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=19, num_e=4)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>8-01-CCpGdCcSE-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.157892</td>\n",
       "      <td>2.260612</td>\n",
       "      <td>4.226928</td>\n",
       "      <td>0.102720</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(c.nid) FROM cellular_component cc, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>108-060-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.605470</td>\n",
       "      <td>0.528589</td>\n",
       "      <td>2.401235</td>\n",
       "      <td>-0.076881</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>125-051-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.396640</td>\n",
       "      <td>0.456243</td>\n",
       "      <td>1.497873</td>\n",
       "      <td>0.059602</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>023-018-augF1-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.458169</td>\n",
       "      <td>0.385003</td>\n",
       "      <td>2.186201</td>\n",
       "      <td>-0.073166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=3)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM posts as p, postLinks a...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>013-055-augF2-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.465446</td>\n",
       "      <td>0.460443</td>\n",
       "      <td>1.434189</td>\n",
       "      <td>-0.005003</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=5)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM tags as t, posts as p, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>130-123-augF2-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.405899</td>\n",
       "      <td>0.468322</td>\n",
       "      <td>2.437323</td>\n",
       "      <td>0.062423</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=24, num_e=4)</td>\n",
       "      <td>SELECT MIN(u.id) FROM postHistory as ph, posts...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>036-100-augF2-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.503076</td>\n",
       "      <td>0.420642</td>\n",
       "      <td>2.365454</td>\n",
       "      <td>-0.082434</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>055-009-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.497410</td>\n",
       "      <td>0.411260</td>\n",
       "      <td>2.225097</td>\n",
       "      <td>-0.086150</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=3)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, posts as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>118-074</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>1.256618</td>\n",
       "      <td>0.719613</td>\n",
       "      <td>2.641345</td>\n",
       "      <td>-0.537005</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>014-134-augF2-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.419243</td>\n",
       "      <td>0.503065</td>\n",
       "      <td>2.574495</td>\n",
       "      <td>0.083822</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>014-134-augF1-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.431259</td>\n",
       "      <td>0.493483</td>\n",
       "      <td>2.699853</td>\n",
       "      <td>0.062224</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>040-101-augF1-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.570664</td>\n",
       "      <td>0.452450</td>\n",
       "      <td>2.678936</td>\n",
       "      <td>-0.118214</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>119-098-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.667652</td>\n",
       "      <td>0.439039</td>\n",
       "      <td>2.400244</td>\n",
       "      <td>-0.228613</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-03-CbGiGaD2-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.552251</td>\n",
       "      <td>0.581946</td>\n",
       "      <td>2.635486</td>\n",
       "      <td>0.029695</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(g2.nid) FROM compound c1, binds b1,...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>JOB</td>\n",
       "      <td>2b-augF1-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>6.980856</td>\n",
       "      <td>7.007206</td>\n",
       "      <td>9.030058</td>\n",
       "      <td>0.026350</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 2, 1]</td>\n",
       "      <td>Hypergraph(num_v=30, num_e=5)</td>\n",
       "      <td>SELECT MIN(cn.imdb_id) AS movie_title FROM com...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>121-097-augF1-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.238843</td>\n",
       "      <td>0.435648</td>\n",
       "      <td>2.658918</td>\n",
       "      <td>0.196805</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(p.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>7-01-DaGiGpBP-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.245658</td>\n",
       "      <td>2.210728</td>\n",
       "      <td>4.229289</td>\n",
       "      <td>-0.034930</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(i.sid) FROM disease d, associates a...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>059-061-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.518876</td>\n",
       "      <td>0.507485</td>\n",
       "      <td>2.473964</td>\n",
       "      <td>-0.011392</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>081-111-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.617876</td>\n",
       "      <td>0.569743</td>\n",
       "      <td>2.545614</td>\n",
       "      <td>-0.048133</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=31, num_e=5)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, postLinks...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred label  true label  bench                       query  \\\n",
       "1349           0           1  STATS               111-056-augA1   \n",
       "2477           1           0  HETIO          3-08-CpDpCtD-augA5   \n",
       "2534           1           0  HETIO          3-16-CtDuGuD-augA6   \n",
       "1268           1           0  STATS         104-088-augF2-augA1   \n",
       "2420           0           1  HETIO            2-05-CuGdD-augA2   \n",
       "299            0           1  STATS         023-018-augF2-augA2   \n",
       "1341           0           1  STATS         110-138-augF1-augA3   \n",
       "1740           0           1  STATS               137-141-augA4   \n",
       "2694           1           0  HETIO         9-07-DuGcGpMF-augA4   \n",
       "2480           1           0  HETIO          3-09-CrCrCtD-augA1   \n",
       "1739           0           1  STATS               137-141-augA3   \n",
       "177            1           0  STATS               014-134-augA3   \n",
       "1210           0           1  STATS               098-124-augF1   \n",
       "1149           0           1  STATS         093-075-augF2-augA2   \n",
       "2622           1           0  HETIO   7-01-DaGiGpBP-augF2-augA2   \n",
       "1736           0           1  STATS                     137-141   \n",
       "2476           1           0  HETIO          3-08-CpDpCtD-augA4   \n",
       "1186           0           1  STATS         096-095-augF1-augA2   \n",
       "2293           1           0    JOB             17e-augF1-augA4   \n",
       "927            0           1  STATS         075-037-augF2-augA3   \n",
       "1774           1           0  STATS         139-034-augF1-augA1   \n",
       "955            1           0  STATS               078-082-augF1   \n",
       "1056           1           0  STATS         086-083-augF2-augA2   \n",
       "963            0           1  STATS               079-112-augA2   \n",
       "2642           1           0  HETIO  8-01-CCpGdCcSE-augF2-augA1   \n",
       "1458           0           1  STATS               119-098-augA1   \n",
       "904            0           1  STATS               074-072-augF1   \n",
       "798            1           0  STATS         064-116-augF2-augA3   \n",
       "2631           1           0  HETIO        8-01-CCpGdCcSE-augA4   \n",
       "1309           0           1  STATS         108-060-augF1-augA3   \n",
       "1549           1           0  STATS               125-051-augF1   \n",
       "296            0           1  STATS         023-018-augF1-augA2   \n",
       "172            0           1  STATS         013-055-augF2-augA3   \n",
       "1638           1           0  STATS         130-123-augF2-augA2   \n",
       "446            0           1  STATS         036-100-augF2-augA2   \n",
       "678            0           1  STATS               055-009-augA2   \n",
       "1439           0           1  STATS                     118-074   \n",
       "188            1           0  STATS         014-134-augF2-augA4   \n",
       "183            1           0  STATS         014-134-augF1-augA4   \n",
       "484            0           1  STATS         040-101-augF1-augA2   \n",
       "1459           0           1  STATS               119-098-augA2   \n",
       "2441           1           0  HETIO         3-03-CbGiGaD2-augA4   \n",
       "2141           1           0    JOB              2b-augF1-augA1   \n",
       "1486           1           0  STATS         121-097-augF1-augA1   \n",
       "2616           0           1  HETIO   7-01-DaGiGpBP-augF1-augA3   \n",
       "715            0           1  STATS               059-061-augA3   \n",
       "991            0           1  STATS               081-111-augA3   \n",
       "\n",
       "     orig/rewr(mean) orig/rewr+rewr(mean)  orig mean  rewr mean  \\\n",
       "1349            rewr                 orig   0.596748   0.532240   \n",
       "2477            orig                 orig   0.184137   0.300639   \n",
       "2534            orig                 orig   0.574174   0.586411   \n",
       "1268            orig                 orig   0.215694   0.275453   \n",
       "2420            rewr                 orig   0.557119   0.539519   \n",
       "299             rewr                 orig   0.283540   0.270736   \n",
       "1341            rewr                 orig   0.481653   0.459576   \n",
       "1740            rewr                 rewr   5.530137   0.724227   \n",
       "2694            orig                 orig   1.934141   2.029559   \n",
       "2480            orig                 orig   0.315867   0.331699   \n",
       "1739            rewr                 rewr   5.530431   0.792268   \n",
       "177             orig                 orig   0.428753   0.548521   \n",
       "1210            rewr                 orig   0.496431   0.489113   \n",
       "1149            rewr                 orig   0.669017   0.667051   \n",
       "2622            orig                 orig   1.995038   2.303148   \n",
       "1736            rewr                 rewr   5.258001   0.825190   \n",
       "2476            orig                 orig   0.190571   0.293480   \n",
       "1186            rewr                 orig   0.605563   0.587985   \n",
       "2293            orig                 orig  62.264197  64.633271   \n",
       "927             rewr                 orig   0.549356   0.510466   \n",
       "1774            orig                 orig   0.187277   0.375633   \n",
       "955             orig                 orig   0.428752   0.477420   \n",
       "1056            orig                 orig   0.439631   0.443599   \n",
       "963             rewr                 orig   0.602283   0.576377   \n",
       "2642            orig                 orig   2.092116   2.099886   \n",
       "1458            rewr                 orig   0.687296   0.481457   \n",
       "904             rewr                 orig   0.620385   0.611789   \n",
       "798             orig                 orig   0.245410   0.312055   \n",
       "2631            orig                 orig   2.157892   2.260612   \n",
       "1309            rewr                 orig   0.605470   0.528589   \n",
       "1549            orig                 orig   0.396640   0.456243   \n",
       "296             rewr                 orig   0.458169   0.385003   \n",
       "172             rewr                 orig   0.465446   0.460443   \n",
       "1638            orig                 orig   0.405899   0.468322   \n",
       "446             rewr                 orig   0.503076   0.420642   \n",
       "678             rewr                 orig   0.497410   0.411260   \n",
       "1439            rewr                 orig   1.256618   0.719613   \n",
       "188             orig                 orig   0.419243   0.503065   \n",
       "183             orig                 orig   0.431259   0.493483   \n",
       "484             rewr                 orig   0.570664   0.452450   \n",
       "1459            rewr                 orig   0.667652   0.439039   \n",
       "2441            orig                 orig   0.552251   0.581946   \n",
       "2141            orig                 orig   6.980856   7.007206   \n",
       "1486            orig                 orig   0.238843   0.435648   \n",
       "2616            rewr                 orig   2.245658   2.210728   \n",
       "715             rewr                 orig   0.518876   0.507485   \n",
       "991             rewr                 orig   0.617876   0.569743   \n",
       "\n",
       "      rewr mean+rewr  diff rewr-orig  ...  q75(branching factors)  \\\n",
       "1349        2.328231       -0.064508  ...                    4.00   \n",
       "2477        2.454935        0.116503  ...                    2.50   \n",
       "2534        2.638695        0.012236  ...                    2.50   \n",
       "1268        1.273657        0.059759  ...                    1.00   \n",
       "2420        2.760506       -0.017600  ...                    2.50   \n",
       "299         2.124599       -0.012804  ...                    1.00   \n",
       "1341        1.484276       -0.022076  ...                    2.50   \n",
       "1740        2.626288       -4.805910  ...                    4.00   \n",
       "2694        4.014254        0.095418  ...                    2.50   \n",
       "2480        2.236466        0.015833  ...                    2.50   \n",
       "1739        2.848849       -4.738162  ...                    4.00   \n",
       "177         2.462337        0.119768  ...                    2.50   \n",
       "1210        1.590290       -0.007318  ...                    3.00   \n",
       "1149        2.649943       -0.001965  ...                    3.25   \n",
       "2622        4.285069        0.308110  ...                    2.50   \n",
       "1736        2.791115       -4.432811  ...                    6.00   \n",
       "2476        2.259293        0.102909  ...                    2.50   \n",
       "1186        2.769054       -0.017578  ...                    1.75   \n",
       "2293       66.638959        2.369074  ...                    2.50   \n",
       "927         2.482725       -0.038890  ...                    1.75   \n",
       "1774        2.325579        0.188355  ...                    1.75   \n",
       "955         2.450607        0.048668  ...                    1.00   \n",
       "1056        2.432668        0.003967  ...                    2.00   \n",
       "963         2.642454       -0.025906  ...                    4.00   \n",
       "2642        4.096027        0.007770  ...                    2.50   \n",
       "1458        2.727080       -0.205839  ...                    1.75   \n",
       "904         1.680814       -0.008595  ...                    5.00   \n",
       "798         2.550724        0.066645  ...                    3.00   \n",
       "2631        4.226928        0.102720  ...                    2.00   \n",
       "1309        2.401235       -0.076881  ...                    3.25   \n",
       "1549        1.497873        0.059602  ...                    2.50   \n",
       "296         2.186201       -0.073166  ...                    1.00   \n",
       "172         1.434189       -0.005003  ...                    2.50   \n",
       "1638        2.437323        0.062423  ...                    3.00   \n",
       "446         2.365454       -0.082434  ...                    1.75   \n",
       "678         2.225097       -0.086150  ...                    2.00   \n",
       "1439        2.641345       -0.537005  ...                    3.25   \n",
       "188         2.574495        0.083822  ...                    4.00   \n",
       "183         2.699853        0.062224  ...                    4.00   \n",
       "484         2.678936       -0.118214  ...                    1.75   \n",
       "1459        2.400244       -0.228613  ...                    1.75   \n",
       "2441        2.635486        0.029695  ...                    2.50   \n",
       "2141        9.030058        0.026350  ...                    1.50   \n",
       "1486        2.658918        0.196805  ...                    1.75   \n",
       "2616        4.229289       -0.034930  ...                    2.00   \n",
       "715         2.473964       -0.011392  ...                    3.25   \n",
       "991         2.545614       -0.048133  ...                    2.50   \n",
       "\n",
       "      balancedness factor                              container counts list  \\\n",
       "1349             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2477             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2534             0.625000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1268                  NaN               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "2420             1.000000                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "299                   NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1341             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1740             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2694             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2480             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1739             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "177              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1210             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1149             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2622             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1736             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2476             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1186             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2293             0.666667  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "927              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1774             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "955                   NaN         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "1056             1.000000         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "963              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2642             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1458             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "904              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "798              1.000000   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]   \n",
       "2631             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1309             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1549             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "296                   NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "172              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1638             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "446              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "678              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1439             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "188              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "183              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "484              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1459             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2441             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2141             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1486             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2616             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "715              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "991              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "      branching factors list                     hypergraph  \\\n",
       "1349                     [4]  Hypergraph(num_v=28, num_e=5)   \n",
       "2477               [1, 1, 4]  Hypergraph(num_v=14, num_e=7)   \n",
       "2534               [1, 3, 2]  Hypergraph(num_v=14, num_e=7)   \n",
       "1268                  [1, 1]  Hypergraph(num_v=14, num_e=3)   \n",
       "2420                  [1, 3]  Hypergraph(num_v=10, num_e=5)   \n",
       "299                   [1, 1]  Hypergraph(num_v=20, num_e=3)   \n",
       "1341                  [3, 1]  Hypergraph(num_v=28, num_e=5)   \n",
       "1740                  [5, 1]  Hypergraph(num_v=40, num_e=7)   \n",
       "2694               [2, 1, 3]  Hypergraph(num_v=14, num_e=7)   \n",
       "2480               [2, 1, 3]  Hypergraph(num_v=14, num_e=7)   \n",
       "1739                  [5, 1]  Hypergraph(num_v=40, num_e=7)   \n",
       "177                   [3, 1]  Hypergraph(num_v=29, num_e=5)   \n",
       "1210                     [3]  Hypergraph(num_v=20, num_e=4)   \n",
       "1149                  [4, 1]  Hypergraph(num_v=35, num_e=6)   \n",
       "2622               [1, 1, 4]  Hypergraph(num_v=14, num_e=7)   \n",
       "1736                     [6]  Hypergraph(num_v=40, num_e=7)   \n",
       "2476               [1, 1, 4]  Hypergraph(num_v=14, num_e=7)   \n",
       "1186                  [2, 1]  Hypergraph(num_v=26, num_e=4)   \n",
       "2293               [1, 2, 3]  Hypergraph(num_v=46, num_e=7)   \n",
       "927                   [2, 1]  Hypergraph(num_v=21, num_e=4)   \n",
       "1774                  [2, 1]  Hypergraph(num_v=20, num_e=4)   \n",
       "955                   [1, 1]  Hypergraph(num_v=16, num_e=3)   \n",
       "1056                     [2]  Hypergraph(num_v=16, num_e=3)   \n",
       "963                      [4]  Hypergraph(num_v=31, num_e=5)   \n",
       "2642               [2, 1, 3]  Hypergraph(num_v=14, num_e=7)   \n",
       "1458                  [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "904                      [5]  Hypergraph(num_v=34, num_e=6)   \n",
       "798                      [3]  Hypergraph(num_v=19, num_e=4)   \n",
       "2631               [2, 2, 2]  Hypergraph(num_v=14, num_e=7)   \n",
       "1309                  [4, 1]  Hypergraph(num_v=35, num_e=6)   \n",
       "1549                  [3, 1]  Hypergraph(num_v=29, num_e=5)   \n",
       "296                   [1, 1]  Hypergraph(num_v=20, num_e=3)   \n",
       "172                   [3, 1]  Hypergraph(num_v=27, num_e=5)   \n",
       "1638                     [3]  Hypergraph(num_v=24, num_e=4)   \n",
       "446                   [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "678                      [2]  Hypergraph(num_v=20, num_e=3)   \n",
       "1439                  [4, 1]  Hypergraph(num_v=35, num_e=6)   \n",
       "188                      [4]  Hypergraph(num_v=29, num_e=5)   \n",
       "183                      [4]  Hypergraph(num_v=29, num_e=5)   \n",
       "484                   [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "1459                  [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "2441               [2, 1, 3]  Hypergraph(num_v=14, num_e=7)   \n",
       "2141               [1, 2, 1]  Hypergraph(num_v=30, num_e=5)   \n",
       "1486                  [2, 1]  Hypergraph(num_v=27, num_e=4)   \n",
       "2616               [2, 2, 2]  Hypergraph(num_v=14, num_e=7)   \n",
       "715                   [4, 1]  Hypergraph(num_v=35, num_e=6)   \n",
       "991                   [3, 1]  Hypergraph(num_v=31, num_e=5)   \n",
       "\n",
       "                                                   text  orig/rewr/equal 0.5  \\\n",
       "1349  SELECT MIN(p.id) FROM tags as t, posts as p, u...                equal   \n",
       "2477  SELECT MIN(t.sid) FROM compound c1, palliates ...                equal   \n",
       "2534  SELECT MIN(d2.nid) FROM compound c1, treats t,...                equal   \n",
       "1268  SELECT MIN(b.id) FROM comments as c, badges as...                equal   \n",
       "2420  SELECT MIN(g.nid) FROM compound c, upregulates...                equal   \n",
       "299   SELECT MIN(ph.id) FROM posts as p, postLinks a...                equal   \n",
       "1341  SELECT MIN(v.id) FROM tags as t, posts as p, u...                equal   \n",
       "1740  SELECT MIN(v.id) FROM comments as c, posts as ...                 rewr   \n",
       "2694  SELECT MIN(g2.nid) FROM disease d, upregulates...                equal   \n",
       "2480  SELECT MIN(r1.sid) FROM compound c1, resembles...                equal   \n",
       "1739  SELECT MIN(ph.id) FROM comments as c, posts as...                 rewr   \n",
       "177   SELECT MIN(b.id) FROM comments as c, posts as ...                equal   \n",
       "1210  SELECT MIN(ph.Id) FROM postHistory as ph, vote...                equal   \n",
       "1149  SELECT MIN(ph.id) FROM comments as c, posts as...                equal   \n",
       "2622  SELECT MIN(g1.nid) FROM disease d, associates ...                equal   \n",
       "1736  SELECT MIN(c.Id) FROM comments as c, posts as ...                 rewr   \n",
       "2476  SELECT MIN(c2.nid) FROM compound c1, palliates...                equal   \n",
       "1186  SELECT MIN(v.id) FROM comments as c, postHisto...                equal   \n",
       "2293  SELECT MIN(mc.id) AS member_in_charnamed_movie...                 orig   \n",
       "927   SELECT MIN(v.id) FROM comments as c, postLinks...                equal   \n",
       "1774  SELECT MIN(v.id) FROM comments as c, votes as ...                equal   \n",
       "955   SELECT MIN(c.Id) FROM comments as c, postHisto...                equal   \n",
       "1056  SELECT MIN(u.id) FROM comments as c, postHisto...                equal   \n",
       "963   SELECT MIN(ph.id) FROM comments as c, postLink...                equal   \n",
       "2642  SELECT MIN(p.sid) FROM cellular_component cc, ...                equal   \n",
       "1458  SELECT MIN(p.id) FROM comments as c, posts as ...                equal   \n",
       "904   SELECT MIN(c.Id) FROM comments as c, posts as ...                equal   \n",
       "798   SELECT MIN(u.id) FROM comments as c, postHisto...                equal   \n",
       "2631  SELECT MIN(c.nid) FROM cellular_component cc, ...                equal   \n",
       "1309  SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "1549  SELECT MIN(c.Id) FROM comments as c, posts as ...                equal   \n",
       "296   SELECT MIN(ph.id) FROM posts as p, postLinks a...                equal   \n",
       "172   SELECT MIN(ph.id) FROM tags as t, posts as p, ...                equal   \n",
       "1638  SELECT MIN(u.id) FROM postHistory as ph, posts...                equal   \n",
       "446   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "678   SELECT MIN(ph.id) FROM comments as c, posts as...                equal   \n",
       "1439  SELECT MIN(c.Id) FROM comments as c, posts as ...                 rewr   \n",
       "188   SELECT MIN(u.id) FROM comments as c, posts as ...                equal   \n",
       "183   SELECT MIN(u.id) FROM comments as c, posts as ...                equal   \n",
       "484   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "1459  SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "2441  SELECT MIN(g2.nid) FROM compound c1, binds b1,...                equal   \n",
       "2141  SELECT MIN(cn.imdb_id) AS movie_title FROM com...                equal   \n",
       "1486  SELECT MIN(p.id) FROM comments as c, posts as ...                equal   \n",
       "2616  SELECT MIN(i.sid) FROM disease d, associates a...                equal   \n",
       "715   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "991   SELECT MIN(v.id) FROM comments as c, postLinks...                equal   \n",
       "\n",
       "      orig/rewr/equal 0.1  orig/rewr/equal 0.05  orig/rewr/equal 0.01  \n",
       "1349                equal                  rewr                  rewr  \n",
       "2477                 orig                  orig                  orig  \n",
       "2534                equal                 equal                  orig  \n",
       "1268                equal                  orig                  orig  \n",
       "2420                equal                 equal                  rewr  \n",
       "299                 equal                 equal                  rewr  \n",
       "1341                equal                 equal                  rewr  \n",
       "1740                 rewr                  rewr                  rewr  \n",
       "2694                equal                  orig                  orig  \n",
       "2480                equal                 equal                  orig  \n",
       "1739                 rewr                  rewr                  rewr  \n",
       "177                  orig                  orig                  orig  \n",
       "1210                equal                 equal                 equal  \n",
       "1149                equal                 equal                 equal  \n",
       "2622                 orig                  orig                  orig  \n",
       "1736                 rewr                  rewr                  rewr  \n",
       "2476                 orig                  orig                  orig  \n",
       "1186                equal                 equal                  rewr  \n",
       "2293                 orig                  orig                  orig  \n",
       "927                 equal                 equal                  rewr  \n",
       "1774                 orig                  orig                  orig  \n",
       "955                 equal                 equal                  orig  \n",
       "1056                equal                 equal                 equal  \n",
       "963                 equal                 equal                  rewr  \n",
       "2642                equal                 equal                 equal  \n",
       "1458                 rewr                  rewr                  rewr  \n",
       "904                 equal                 equal                 equal  \n",
       "798                 equal                  orig                  orig  \n",
       "2631                 orig                  orig                  orig  \n",
       "1309                equal                  rewr                  rewr  \n",
       "1549                equal                  orig                  orig  \n",
       "296                 equal                  rewr                  rewr  \n",
       "172                 equal                 equal                 equal  \n",
       "1638                equal                  orig                  orig  \n",
       "446                 equal                  rewr                  rewr  \n",
       "678                 equal                  rewr                  rewr  \n",
       "1439                 rewr                  rewr                  rewr  \n",
       "188                 equal                  orig                  orig  \n",
       "183                 equal                  orig                  orig  \n",
       "484                  rewr                  rewr                  rewr  \n",
       "1459                 rewr                  rewr                  rewr  \n",
       "2441                equal                 equal                  orig  \n",
       "2141                equal                 equal                  orig  \n",
       "1486                 orig                  orig                  orig  \n",
       "2616                equal                 equal                  rewr  \n",
       "715                 equal                 equal                  rewr  \n",
       "991                 equal                 equal                  rewr  \n",
       "\n",
       "[47 rows x 37 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass_combi = df.loc[X_val.index]\n",
    "misclass_combi.insert(0, 'true label', np.array(y1_val))\n",
    "misclass_combi.insert(0, 'pred label', y1_pred_combi)\n",
    "indices_not_equal = np.where(y1_val != y1_pred_combi)[0]\n",
    "misclass_combi = misclass_combi.iloc[indices_not_equal]\n",
    "misclass_combi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cebc68b6-9bf9-4b44-bcb2-1ad0776a66db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1098346/1332133532.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass_1_combi[\"cut\"] = pd.cut(abs(misclass_1_combi['diff rewr-orig']), bins=bins, labels=labels)\n",
      "/tmp/ipykernel_1098346/1332133532.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass_0_combi[\"cut\"] = pd.cut(abs(misclass_0_combi['diff rewr-orig']), bins=bins, labels=labels)\n",
      "/tmp/ipykernel_1098346/1332133532.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  table_1_combi = misclass_1_combi.groupby('cut').size().reset_index(name='count_1')\n",
      "/tmp/ipykernel_1098346/1332133532.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  table_0_combi = misclass_0_combi.groupby('cut').size().reset_index(name='count_0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cut</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>TO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cut  0.01  0.1  1  10  100  TO\n",
       "FP      2   12  7   1    0   0\n",
       "FN      4   14  4   3    0   0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 0.01, 0.1, 1, 10, 100, float('inf')]\n",
    "labels = ['0.01', '0.1', '1', '10', '100', 'TO']\n",
    "\n",
    "misclass_1_combi = misclass_combi[misclass_combi[\"pred label\"] == 1]\n",
    "misclass_0_combi = misclass_combi[misclass_combi[\"pred label\"] == 0]\n",
    "\n",
    "misclass_1_combi[\"cut\"] = pd.cut(abs(misclass_1_combi['diff rewr-orig']), bins=bins, labels=labels)\n",
    "misclass_0_combi[\"cut\"] = pd.cut(abs(misclass_0_combi['diff rewr-orig']), bins=bins, labels=labels)\n",
    "\n",
    "table_1_combi = misclass_1_combi.groupby('cut').size().reset_index(name='count_1')\n",
    "table_0_combi = misclass_0_combi.groupby('cut').size().reset_index(name='count_0')\n",
    "\n",
    "table_combi = pd.merge(table_1_combi, table_0_combi, on='cut', how='outer')\n",
    "table_combi = table_combi.set_index('cut').T\n",
    "table_combi.index = ['FP', 'FN']\n",
    "table_combi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c663703-13b9-4e80-bfae-e417ad90b32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>TO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">misclass</th>\n",
       "      <th>FP</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">misclass_forest</th>\n",
       "      <th>FP</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">misclass_combi</th>\n",
       "      <th>FP</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cut                 0.01  0.1  1  10  100  TO\n",
       "misclass        FP     1   10  6   1    0   0\n",
       "                FN     6   16  3   3    2   0\n",
       "misclass_forest FP     1   14  8   1    0   0\n",
       "                FN     5   14  1   3    2   0\n",
       "misclass_combi  FP     2   12  7   1    0   0\n",
       "                FN     4   14  4   3    0   0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_table = pd.concat([table, table_forest, table_combi], keys=['misclass', 'misclass_forest', 'misclass_combi'])\n",
    "combined_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a68da64-f853-46e9-aa8b-ea54264892b8",
   "metadata": {},
   "source": [
    "We plot the time differences between the original and rewritten runtimes for the three models for all misclassifications and color it in TP and TN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67ffbfd3-b306-4739-9a01-f400b47d3a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABv0AAAJOCAYAAACUQctNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACP50lEQVR4nOzdd5wU9f0/8Pcd5ShSpHPAAQooBgsaewGxooJgi2JDY0eNNUa/UbFrTOy9AWqsESyoYMUWNTasiCIgEIoe0o/O/v7gd5uDKxzsteWez8djH3A3n5n57Ozs7vvmNfOZjEQikQgAAAAAAAAgbWVWdgcAAAAAAACA1Aj9AAAAAAAAIM0J/QAAAAAAACDNCf0AAAAAAAAgzQn9AAAAAAAAIM0J/QAAAAAAACDNCf0AAAAAAAAgzQn9AAAAAAAAIM0J/QAAAAAAACDNCf0o0dChQyMjIyMyMjJi8uTJld2dpA4dOkRGRkYMHDiwsrtSZiZPnpzc1kOHDi223ZQpU+L000+PzTffPOrUqZOc5/nnn4+IiIEDB0ZGRkZ06NChQvpdnnr27BkZGRnRs2fPyu4KVVh57fNV9fMPSE1VfW+rbdQ2sL7y3yuDBw+u7K4A60k9UnHUI4WpRyhLZVGPjBkzJrmcMWPGlFnfoLoS+qW5gh+KGRkZ0aBBg8jLy1vnfIsXL45GjRqtMa8P1apvypQpscMOO8QDDzwQEydOjKVLl1Z2l0gjBf/YKfjIzMyMxo0bR/v27WOXXXaJQYMGxWOPPRYLFy6s7C6ToqJe7/V9VKWDEFQPapvqRW1DKoqrbTIyMqJOnTqRnZ0d+++/f9x+++0xf/78yu4uKSoYkpTm4TuAVKhHqhf1CGVp1apV8eKLL8bpp58eW2+9dbRo0SJq1aoVTZo0ia233jpOPvnkeP7552P58uWV3dVqZ+3aMTMzM37++edSzdulS5c15i3qJIKCy9+QkyfyTy4o7rjdtttuG4MGDYqxY8eu97LLwuDBg9f7uy3/ZJLSnjAxY8aMuO222+KQQw6JzTffPBo2bBi1a9eO5s2bx/bbbx9//OMf45lnninxO3nt7/A//OEP61xvwW1flILPPSMjI+699951LjP/uVfGCRZCv43MwoULk2chleSFF17wh28auvbaayM3Nzdq1qwZN910U3z44Yfx9ddfx9dffx377LNPZXevVDams+M2FolEIubNmxdTpkyJjz/+OO6555444YQTIjs7Oy644IJYtGhRZXcRqMbUNhs3tQ3lZenSpTFjxox4/fXX47zzzotu3brF559/XtndgnLnaonyoR7ZuKlHKCvvvPNObLfddnHooYfGAw88EN988038+uuvsWLFipgzZ0588803MWTIkOjfv3906NChxKtPKX+JRCL++c9/rrPdRx99FD/++GMF9Kho+cftvvrqq7jnnntihx12iP/7v/+rtP6Uh6VLl8bFF18cm2++eZx//vnx8ssvx8SJE2PBggWxfPnyyM3NjS+++CIeeeSR+MMf/hCtWrWKK664olQn5Dz77LPx9ddfl2l/r7/++ip9gkjNyu4AZadOnTqxZMmSeOyxx2LAgAEltn3sscfWmKc4AwcO3KiGdajKOnToEIlEosQ2b7zxRkRE9OvXL/785z8X2Wbo0KEbTdHgj9Tyc+ihh8a1116b/DkvLy/mzp0b3333XbzzzjsxcuTIWLBgQdx6663x8ssvx8iRI6Nz586V2OPildc+vzF8/pVU1BxwwAExffr0yM7OjtGjRxfbrk2bNuXRNSgVtU16U9sUprYpP2vXNnPmzInvv/8+br311hg3blxMnTo1Dj744Bg/fnw0bNiwEntKWbj22mvj0EMPLbFNx44dK6g3bOzUI+lNPVKYeqR8DBkyJE4//fTkFXy77LJLHHbYYbHddttF06ZNY968efHTTz/FK6+8Ei+//HJMnz49zjvvPJ8FsXrI2XW9T8tawc/2yy67rMS2pf1sL0ujR4+O7OzsiFh99eisWbPi5ZdfjrvvvjtWrFgR119/fbRp0ybOOuusCulPecrNzY2+ffvGhx9+GBER9evXj6OOOip69eoVOTk50aBBg5g9e3ZMmDAhXn/99Xj11VdjwYIFcc0118RBBx0Uu+yyS4nLTyQSceWVV8bw4cPLrM/Tpk2L+++/P84999wyW2ZZEvptRPr27RvPPPNMvP766zFz5sxo1apVke1++eWXeO211yJi9R/HTz/9dEV2kxT897//jYjVl5RDKho3bhzdunUr9Pv9998/zjvvvJgyZUqccsop8frrr8cPP/wQhxxySHz00Uex6aabVkJv2VBFvcb5atWqlfy3pHZQmdQ2Gz+1DWWlqNpmzz33jIEDB8Zee+0VH330UcycOTMeeOCBuOiiiyqpl5SVNm3aqF+oMOqRjZ96hFS9+eabccopp8SqVauifv36MXTo0DjiiCMKtdt7773jlFNOicmTJ8df/vKXGDVqVCX0loj/fbZ///338emnn8bvf//7ItstX748+XlekZ/tXbp0KXTl7n777Rf77LNP9O3bNyJWDzl5+umnR40aNUq1zMmTJydPipo0aVKVuDJ45cqVceSRRyYDv759+8aDDz4YLVq0KNR23333jTPOOCNmzZoVN998c9x2223rXH6zZs0iNzc3RowYEV988UV079495T7nL/OGG26IU089NerWrZvyMsua4T03Ivvvv3+0atUqVq5cGU8++WSx7Z588slYsWJFtGrVKvbbb78K7CGpWrZsWUT872A9lJecnJx49dVX4+CDD46IiB9++CGlmzIDbAi1zcZPbUN5q1Wr1hpXAOZfzQFQWuqRjZ96hFTk5eXFcccdF6tWrYrMzMx4+eWXiwz8CurQoUM89dRTcccdd1RQL1lb165dk0Ff/pV8RXnllVdi9uzZUbt27VLdG6689enTJ/bcc8+IiPj111/Tfvj6W2+9NXn18SGHHBIjRowoMvArqGXLlvH3v/893nvvvWjevHmJbc8999zIysqKiIgrrriiTPqcf0X4zJkz45577imTZZY1od9GpEaNGnHMMcdERMkfVo8++mhERAwYMGCdZwIUvFn65MmTi2zz2WefxR//+Mfo0qVL1K9fP+rUqRPt2rWLHXbYIQYNGhQvvvhiiZdoT548OS655JLYYYcdomnTplGrVq1o1qxZ7LnnnjF48OCYOHHiOp55YTNmzIh77rknjjjiiOjcuXPUr18/srKyok2bNsmzMlatWlXiMpYsWRJ33HFH9OzZM5o3b5686e4WW2wRvXv3jltuuaVMt0nBm70WHDKi4GuQ76qrrlrj5qEFhwIo7TjuCxYsiH/84x/Rq1evaNWqVdSuXTsaNmwY3bt3j3POOSc++OCDQvOsWrUq3nrrrbjoooti9913j2bNmkWtWrWicePGsd1228VFF10UU6ZMKXJ9+Tc8HTZsWERE/Pzzz0XenLagnj17luqGp++//34cf/zx0aFDh6hTp040btw4unfvHn/961/j119/LXa+ou538cwzz8Q+++wTzZs3j7p168YWW2wRf/7zn+O3334rsQ8//PBDnHPOOdGtW7do0KBB1K5dO7Kzs2O77baLk08+OZ5++ukqPdZzUWrUqBFDhw6NevXqRUTEgw8+GLm5ucW2nzdvXtxwww2x++67R/PmzaN27drRunXr6NOnT/zrX/8q1VANG7JflmafHzFiRPTr1y/atm0bWVlZ0aBBg9hss81izz33jMsvvzz+85//FJqnNJ9/EauLrL/+9a/RvXv3aNy4cdSpUyc6dOgQxx9/fLz//vslPt/8m/rmv4fHjx8fp556anTo0CGysrKiZcuW0b9///joo49KXE55WHu7zpgxIy655JL43e9+Fw0aNCjyPjErV66MYcOGxSGHHBLZ2dmRlZUVTZs2jT322CNuueWWWLx48TrXWxbLYOOhtvkftY3aRm2z4bbeeuvk/6dOnVpkm1T2hXxrv77//e9/44ILLohOnTpF3bp1o2nTpnHAAQfEq6++Wqp+P/HEE9GzZ8/YdNNNY5NNNolu3brFlVdeGXPnzi3V/BGrD2Tfc889sffeeyfrs1atWsVBBx0Ujz/+eImfG2u/92bOnBkXXXRRdOnSJerVqxdt2rSJo446Kr799ts15ps8eXKce+650aVLl6hbt260bNkyjj322Pjpp59K3e/ysnDhwrjxxhtj1113jSZNmkRWVla0bds2jjjiiBg5cmSJ8679+v74449x9tlnR+fOnaNevXpFfq8sWbIk7rrrrthnn32Sn0stWrSIfffdNx5++OFYsWJFiet866234phjjomOHTtG3bp1o169etG+ffvYZZdd4qKLLoq33nor2Tb/M3fvvfdO/m7vvfcu9Jm0sQxPWJHUI/+jHlGPqEcKe+SRR2LmzJkRETFo0KDo0aNHqec94YQTip329ddfx2mnnZb8nmnQoEH87ne/i/PPP7/EYxRF7fPDhw+P/fffP1q0aBH169ePbbfdNu68887kUKQRq4dAzK89WrRoEfXq1Yvtt98+7rvvvvUaevONN96Ivn37RuvWraNOnTqx2Wabxdlnn528orYolXU/2uOPPz4iIp566qliv5PzP9sPOeSQKjP61U477ZT8/88//1yJPUnN0qVL4x//+EdERNSrVy8efvjhyMwsfVy16667xuabb15im3bt2sVpp50WEREjR44s8vjf+jriiCNim222iYiIm266KRYtWpTyMstcgrT29ttvJyIiERGJIUOGJD7//PPkz998802h9t9++21y+hdffJEYMmRI8ue33367UPuC0ydNmlRo+i233JLIzMxMtinusWDBgiL7f/PNNydq1apV4rw9evQoNF/79u0TEZE48cQTC01bsWJFqfq03377Fduv6dOnJ7baaqt1LuPCCy8ss20yadKkNV7Lol6D4h4Ft8OJJ56YiIhE+/bti3xuiUQi8frrryeaNWu2zuWu7corr1znPPXq1UsMHz58g+Zde509evQodh9IJBKJlStXJgYNGlTi8ho1apR47bXXipy/4PvnzTffTBx33HHFLqdTp06JGTNmFLmcZ555JlG7du11Prevv/662NekIhTcx4p67xTntNNOS873z3/+s8g2b7zxRqJp06YlPv+DDjqo2PdcIrHh+2VJ+/yKFSsSRx555DqXucMOOxSad12ff4lEIjF69OhEw4YNS1z2oEGDEitXrixy/oKfZcOHD0/Uq1evyGXUqFEj8dRTTxW77TZE/rqL+6wouF0//PDDIl+bgt8bP//8c2LbbbctcVt06tQpMX78+GL7VBbLIP2pbU4sNE1to7Yp+FDb/E9pa5s5c+Yk22277bZFtkllX8hX8PV9//33S9wnb7755mKXs3z58hLrl8022ywxceLE5M9XXnllsdtnyy23LPE57bHHHonZs2cXOX/B997YsWMTrVq1KnIZ9evXT7z33nuJRCKRePPNNxONGjUqst2mm25a5Od4aRX87Cj4mVJan3/+eSI7O7vE7XHYYYclFi9eXOT8BV/f559/PlG/fv1C8xf8Xhk7dmzys724x4477piYOXNmkes777zz1rlPNm3aNNm+4PuhpMeGbLvqSD1yYqFp6hH1SMGHeuR/tt9++0REJDIyMhITJkwok2Vef/31Je7vWVlZiWHDhhU579r7/Jlnnlnscg477LDEihUrEkuWLEkcccQRxbY79dRTi+1rfpsrr7wyMXjw4BL3mXfffbfIZRTcZ4r6zEwkEmt8p26ogtvmyiuvTMyaNStRs2bNREQkRo4cWaj9b7/9lsjKykpERGLEiBGFvhtKWv76HHfLl/85E1H8cahEIpH4y1/+kmy3PseKCvavpOUXp+DnTXGv09pKOvb0wgsvJJd38sknr3d/irP26zR9+vRE3bp1ExGR2H///Yucp+C2L0rB5z5p0qTEiBEjkj9ff/31Rc6T/9yL+6wtT+7pt5Hp3r17/O53v4tvv/02HnvssbjxxhvXmJ5/Vlq3bt1iu+22i7Fjx27wur766qu46KKLYtWqVdGxY8c4++yzY7vttosmTZrEggULYvz48fH222/HCy+8UOT811xzTfKy2saNG8dZZ50Ve++9dzRt2jTmzp0bn3/+eQwfPrzQGUnrkvj/Z5/06tUrevfuHVtvvXU0b948FixYEBMnTowHH3wwPvzww3j99ddj0KBBybOhCjrnnHPiu+++i4iI4447Lg477LDIzs6OGjVqxIwZM+LTTz8t8nmluk2K0q9fv+Tl5vlnKZ955plr3Kh1fc40efvtt6N3796xYsWKqFGjRhx//PFx6KGHRk5OTixZsiS+++67ePXVV+Oll14qNO+KFSuidevW0b9//9h1111js802izp16sTUqVPj3//+d9xzzz2xcOHCGDBgQHz++efRtWvX5LxnnXVWHHHEEfHXv/41XnjhhcjOzo7Ro0eXut9F+ctf/hJ33313RER07NgxLrnkkth+++1j0aJF8eKLL8Zdd90V8+bNi0MOOST+85//xLbbblvssi6//PL497//Hf369YsTTjgh2rdvH7NmzYq77747Xn755ZgwYUKcf/75hYZzmTVrVpx00kmxbNmyaNGiRZx99tmxyy67RLNmzWLx4sUxYcKEeOedd+L5559P6blWpn333TceeOCBiIh47733Ct28/oMPPojevXvH8uXLo2XLlnHOOefEtttuG9nZ2TF9+vR4+umn4/HHH49XXnklTjzxxHjuuecKrSOV/bIk9957bzz77LMREbHHHnvEKaecEptvvnnUr18/Zs+eHV999VWMGjUq5s2bt97bZezYsdGnT59YtmxZ1KpVK84+++zo27dv1K9fP7744ou48cYbY9KkSXH33XdH/fr146abbip2WV9//XU8/fTT0bp167jwwgvj97//fSQSiRg9enTceOONsWTJkjjttNOiV69e6xy6oKwtXLgwDj/88FiyZEn83//9X+y3335Rr169+Prrr6N169YRETF79uzYY489YurUqZGVlRWnnnpq9OjRIzp06BALFy6M1157LW6//faYMGFC9O7dOz7//PNo1KjRGuspi2WwcVLbqG3WRW1TNLXN/4wbNy75/+Ku0EhlX1jbjBkzol+/fpGZmRk33nhj7LHHHlG7du14//334+qrr465c+fGpZdeGr17947f/e53hea/6KKLkvVL/pUQ22yzTcybNy+effbZePDBB9c5vNTChQtjn332SV7J069fvzj55JMjOzs7Jk2aFHfddVe888478f7770efPn3i3XffLfbKpLy8vOjfv38sW7Ysrr/++ujRo0fUqFEjRo0aFddff30sWrQojj/++Hj99dejX79+0ahRo7j66qtj5513jhUrVsRzzz0Xt912W8yZMyf++Mc/VsoIBv/9739jn332iTlz5iSv3jn66KOjadOm8d1338U//vGP+PLLL2P48OExcODAeOqpp4pd1pQpU+K4446LevXqxeWXXx577rln1KhRIz755JPYZJNNIiJiwoQJ0aNHj5g3b140bNgwBg0aFDvttFO0a9cuZs+eHS+++GLcf//98cknn8Shhx4a77333hrDCo4cOTJ5n5ptttkmzjzzzOjatWs0atQo5s6dG99++2288cYba5yt3qZNm/j666/jk08+iZNPPjkiVl99suOOO67R/7Zt25bVZq1W1CPqkXVRjxRtY69H5s+fn3y/b7HFFuu86qg07rnnnrjssssiIqJ58+ZxySWXxO677x4rV66MN954I26++eZYtGhRDBw4MJo1axYHHXRQscu677774uOPP46DDjooTjnllGjfvn1MnTo1brjhhvj4449j+PDhMWTIkPjqq6/iX//6VwwYMCAGDBgQrVu3jh9//DEGDx4c33//fTz44INx2GGHxYEHHljsul5++eX49NNPi61d8veZb775Jtq1a5fydioLLVq0iAMOOCBefvnleOyxx5K3uMn3zDPPxNKlS6Np06Zx0EEHxb///e9K6umavv766+T/s7OzK7EnqXnnnXeS/y9p30pV69at48wzz4xbbrklXnvttXj//fdjjz32SGmZ/fr1ix122CE+++yz+Pvf/x6DBg2Khg0bllGPy0CFx4yUqaLOMLjpppsSEZFo165dYtWqVcm2q1atSrRr1y4REYm//e1viUQikdLZZ5dffnkiYvWZncWdnZhIJBJz584tdJXL559/njxjpUuXLompU6cWO/+UKVMK/a6ks89WrVqV+PHHH4tdXiKRSFxxxRXJs3B++OGHNaYtXrw4eUZcUWeXFbT2WbGpbJPizj4rKH96cWfzJhIln322ePHi5Nmt9erVK/GsjKK2+6RJkxLLli0rdp6pU6cm2rRpk4iIxHHHHbfe/VtbSWefffXVV8l9qFu3bok5c+YUavPqq68m2+y0006Fphd8/0RE4tprry3UZtWqVYn9998/ERGJmjVrJn755Zc1pj/88MOlOrssLy8vkZeXt87nXJ429IyjCRMmJOfr1avXGtOWLVuW6NChQyIiEgceeGBi0aJFRS7jgQceSC5j7bMBU90vS9qn9txzz0REJHbeeefE8uXLi11uUWe4r+vs2x133DERsfoqvNGjRxea/ttvvyXPYs3MzCzyjOCCZ6rtsMMOiXnz5hVq8/jjjyfb3HLLLcU+h/VV2iv9IiKxySabJMaOHVvssgYMGJBc1sSJE4ts8/nnnyfPiL/sssvKZRlsHNQ2JxaaprZR2+RT26yptLVNnz59ku0ee+yxYpeV6r6Q//rm7w/Tpk0r1Oa9995LZGRkJCIice655xaaXnA/2H777Yu8WmbYsGFrvM5FvX8uuuii5PS//vWvhaavWrUqceyxxybb3HPPPYXaFKwFmjVrVuTVC3fddVeyTfPmzROdO3cutE8lEonExRdfnGz3+eefF5peGgU/v6+99trE119/Xexj7fdPwasXHnrooULLXrJkSWLvvfdOtnnllVcKtSn4+mZnZyd+/vnnYvu62267JSIi0b1798Svv/5aZJuC7+cHHnhgjWnHH398cj8qaaSMomrY0lwtwbqpR04sNE09oh7Jpx75n/fffz/Zz2OPPTbl5f3yyy/JEYCys7OL3F8K/l3cpk2bQvvO2ld+n3feeYWWsWjRouT7vWnTpomMjIzEbbfdVqjdjBkzEg0aNEhERKJv375F9rnguoqrXR599NFkmyOPPLLQ9Mq60i+RSCSefvrpREQk6tatW+iYzO67756IiMRZZ51VqJ+VdaXf2LFjEzVq1Eh+3hQ3QkFRyvJKv0ceeaTEWiz/kf/ZWNRn07777ptcXlldJZtIFP06zZo1K/m+2XvvvQvNs75X+iUSicTLL7+c/N1VV11VaJ7KvNLPPf02Qscee2xkZmbG1KlT1xgHecyYMTF16tTIzMwsdKXOhsgfr7pLly7RsmXLYts1atSo0Hi8N998c6xatSoyMjLiqaeeKvFsw/U9+yMjIyM6depUYpsrrrgimjVrFolEIl588cU1pv3222/JMa332muvEpfTpEmTNX5OZZtUhEcffTSmT58eERHXX399ieO3F7XdO3ToUOKNrdu2bRsXX3xxRMQ67y+QqnvvvTd5r4CHHnooGjduXKjNgQcemDzL9T//+U988sknxS5vhx12SJ5JVVBGRkZccMEFEbH67LsPP/xwjen5r/mmm24a3bp1K3b5devWjbp165b8pKqopk2bJv8/Z86cNaY99dRTMXny5KhTp048+uijyfv/re3UU09Njjm+9n1EUt0vS5L/+uy2225Rs2bxF7ev/V5el4L706mnnhr7779/oTabbrpp8grJVatWrfPmvo888kiRZwUNGDAgeebWe++9t179LCt//vOfiz17c/LkyfH0009HRMRdd90VHTt2LLJd9+7dY9CgQRFReB8oi2WwcVPbqG2Ko7ZR2xRn7ty58eGHH0bfvn2TV1XsuuuuxV4hV9b7wp133hlt2rQp9Ps99tgjdt5554go+nv9vvvuS+4HDzzwQPLKsYJOOOGE6N27d7HrXrp0aTz00EMREfG73/0uBg8eXKhNRkZG3HPPPck676677irx+VxzzTVFXr1w8sknR506dSJi9X2O77jjjiJHJTjzzDOT/y+Leuavf/1rbL311sU+Cl75MX369BgxYkRErH4P/fGPfyy0vKysrHjkkUeS9eK6tseNN94YOTk5RU577733klcCDBs2LJo1a1ZkuwMPPDCOOOKIiChc1+S/D7fffvsi94F861vDkhr1iHqkOOqR6luPzJ49O/n/Fi1apLy8IUOGRF5eXkRE3HLLLUXuL927d49LL700IlZfyV7S1Y7t2rWLv/3tb4V+X69evTjxxBMjYvVz2HnnneNPf/pToXatWrWK/v37R0Tpvr+Lq12OP/74ZO0yYsSI5OtbFfTt2zcaNWoUixcvXmNkqokTJybvwZl/77/KkkgkYubMmfHQQw/FvvvuGytXroyIiHPPPTdZh1W0k08+ucRaLP+R/9lYlNzc3OT/SxrVavbs2fHNN98U+Zg0aVKp+pt/xXDE6iuz33777VI+0+IddNBBscsuu0TE6vfr2sdMK5PQbyPUpk2b5M27C95kOv//vXr1KvIP0PWVP6zbd999t143wVy1alXy5vU9e/aM7t27p9yXda1v+vTpMX78+OQHwrhx45LF75dffrlG+6ZNm0bt2rUjYvU2W9fN1Qva0G1SUfJvTl+/fv049dRTU17e/PnzY9KkSfHtt98mt21+6JM/rby88cYbEbH6QEb+gZOiFHye+fMUZcCAAcUOb7LDDjsk/7/2zc7zX/M5c+as11Ai6aRgwbZgwYI1puX/IdejR491DjuZ/4fd2sV8We+XBeW/Pi+99NIaxUSqCu5LRR04yrf77rsnh14paf/beuutkzcBXltGRkbyc3Lt/a+iHHvsscVOe/nll2PlypVRr169Eg9ARvxvH5g+ffoaN6Ivi2WwcVPbFF6f2mY1tY3aJt+wYcMiIyMj+dh0001jt912i5deeilq1aoVAwcOjFGjRpV4ULWgVPaFxo0bFxoeqqD87V/U93r+a7r11luv8TqtLf9ga1E+++yzmDt3bkREDBw4sNhhOxs2bBhHHXVURKx+j8+YMaPIdhkZGcl2a6tbt2507tw5IlYfmD3ggAOKbNexY8do0KBBRFR8PTNmzJjkwbGS6rYOHTrEfvvtV2ietdWuXTuOPPLIYpeTXx9vscUWySEDi5Nf13zyySdrfDbnvw/ffffd+Omnn0pcBhVHPVJ4feqR1dQj1bceKXiMpH79+ikvL39bNm7cOA477LBi251yyimF5inKYYcdVmztU/DE3pKGDc9vN2fOnGR9UZTS1i4rVqxY48SJ0po8eXIkEokyD73r1KmTPAmn4Gf7448/HhERnTt3TgY7Faljx47JujYzMzNat24dp556avLY1sEHHxxXX311hferLJX2/fPYY48VGyqedNJJpV7fxRdfnKxHL7/88g3veAH5r8G8efPiH//4R5kssywI/TZSJ5xwQkREPPfcc7F48eJYvHhx/Otf/1pjWqqOOeaYqFWrVixdujR233336NOnT9x3333xzTfflPgBPGnSpOSXxJ577lkmfVlbIpGIxx9/PPbee+/YZJNNok2bNrHllluu8aGQP+b22kFAVlZW8svuX//6V3Tq1Cn+/Oc/xyuvvFLil1vEhm+TivLFF19ExOrCqrgrstbl559/jnPOOSc6dOgQjRo1is022yy6deuW3K6nnXZasm1ZhiwFLV26NH788ceIiBKL0IjVZ0DlFzjffPNNse223HLLYqcVPMtw7dCrb9++yTPf+vfvH7169Ypbb701Pvvss2IPFJTW3Llziz2T5Ycffkhp2euj4HNe+0q0Tz/9NCIiRo8evcaBtqIef//73yMiCp3RVRb7ZXHyz1ybMGFCdOrUKU4++eR48sknY9q0aSktN39fql27dmy33XYlts3fR3/88cdYtmxZkW1K2v8i/rcPrr3/VYRNNtkkNttss2Kn5+8DeXl5UbNmzRL3gUMOOSQ5X8H9oCyWwcZPbaO2KYraRm1TGp07d47zzz9/nffZKKt9oXPnziVeaVLc93rB/WDt+7CtLX8EhaIU3C/WtT8VnF7c/tSsWbMSryjL3186depU4j3C8tuVRT0zZMiQ5IG/oh4DBw5Mtt2Q7ZGXl1dsONm5c+cSz6rPr2vGjx+/zvo4/4zz5cuXx2+//ZZcRv732uzZs6Nbt25x9NFHx5AhQ2LChAkl9p/ypx5RjxRFPVJ965H8ACEiYtGiRSn1K+J/23L77bcv8USlli1bJu9TXNL279KlS7HTCl7FWdp2JX2Hr0/tUvCedFVB/ud3/pXbEf8LACv7Kr+CateuHbvvvnsMGzYseWLb2gYOHFhs3VFwVKWCoeLaj5KuVs739ttvl1iL5T/at29f7DLK+v2zLk2bNo3zzjsvIiI++OCDlO9/GhGx3377Jb9z77jjjjWu/q1MQr+N1GGHHRb16tWL+fPnxwsvvBDPP/98LFiwIOrXr1/imSLrY8stt4wnn3wyNt1001ixYkWMHDkyzjzzzNh6662jRYsWcfzxxxd56XfB4iT/zJ2ytGTJkjj44IPj+OOPjzFjxsTixYtLbF/U9Lvuuiv69OkTEasLr5tvvjkOPvjgaNq0aey4445x8803x7x58wrNt6HbpKLkb/sN3e6vvvpqbLXVVnHXXXfFzz//vM7269r2G6rg5dLrGj6hVq1ayWGLCv4hvbaSCvOCB23WLi6bNm0aL774YrRp0yYSiUS8/fbbccEFF8Tvf//7aNKkSRx22GHJs/7W1/PPP1/smSxFDSdZXgq+Z9c+4PPLL7+s9/LW3i9S3S9LcvLJJ8dll10WNWvWjHnz5sWQIUNiwIAB0a5du+jUqVNceOGFG3S2ef6+1KRJkxKHDY1YPRxGxOo/kIu71H9dfxjm74Op/nGzIYoazqWgDdkHIiI5ZElZLYONn9pGbVMUtY3aJt+hhx4aX3/9dXz99dfx5Zdfxquvvhp/+tOfok6dOvHdd99Fz549Y/z48cXOX5b7Qmm/1/OHT8s3Z86c5MHrde0HJQ1vV3C/WNdy8uuUtecrqLTPp6rWM2W9PTbddNMSl1EWdc0+++wTd911V9StWzeWLFkSTz/9dJx88snRuXPnaNu2bZxxxhmFrqKiYqhH1CNFUY9U33qk4O1QZs2atUH9KSh/W5ZmqND876yy2P4b+joVtD61S0l9rgx77rlntG/fPhKJRPzzn/+MDz/8MCZMmBAZGRlx3HHHVUqfRo8enaxtv/322/j5559jwYIF8f7778cJJ5xQ4olW6aLg++fXX38ttt15551XKEzcUBdccEHyONeVV165wcsp6JprromI1aF4UcPpVgah30Zqk002SY65/NhjjyXPTujfv3+ZXG6e7/DDD49JkybF/fffH4cddlhyeL/c3Nx4/PHHY6+99oqBAwcW+oO2PF133XXJIS169OgRzzzzTEyYMCEWLlwYK1euTH445KfwRX1QNGzYMF588cX4+OOP48ILL4wddtghatSoEatWrYpPP/00/vznP0eXLl0KDVMYUTW3SVnIzc2NAQMGRF5eXmyyySYxePDg+PDDD+OXX36JpUuXJrfrm2++mZynIs64qwpfcnvuuWdMmDAhHn/88RgwYEByOJP58+fHiBEjok+fPnHggQembUCRf9ZixOphigrKL/h69+6dLEZK86hI1113XUyYMCGuu+666NWrV7KY/emnn+KWW26JLbfcMu67774NWnZV2P/KW3FDguXL3weaNWu2XvtAwbMAy2IZbPzUNmqbsqa2KV461jaNGzeObt26Rbdu3WKbbbaJAw88MG677bYYOXJk1KxZM+bMmRMDBgwo8mBVVdwXymo/qAr7U1VSFtujtLXRtttuu151zdrDQg4aNCgmT54ct956axx00EHRqFGjiFh9/6b7778/unfvHn/9619Tfj6sH/WIeqSsVcXvoIiq8f2RDvXI1ltvnQzFPv/88zJbblXY/usrHfucr2C4V/Czfffdd1/j6riK1KVLl2Rtu9VWW0VOTk5yiOSSXHfddcXWGgWvbCsYKq79GDJkSHk+taSCQ8wWPPZYnho3bpy8n+jHH3+8wScPFNSjR4/o1atXRKw+uaUsTgBIVcmXJ5DWTjjhhPjnP/8Zr7322hq/K2uNGjWK0047LTnUwLhx4+KFF16IO++8M6ZPnx7Dhg2L7t27J28IW/BG5sXdN2JDJRKJ5E3r99xzz3jrrbeKHVqnNGeV7LTTTsnLzxcsWBBjxoyJoUOHxvDhw+OXX36Jww8/PH766adCNw1e321SUZo1axbTpk3boO3+r3/9KznkxogRI2Lfffctsl1FnK1T8OzadX2QrlixInlpdXne6L5OnTpx7LHHJu99NmnSpHj55ZfjzjvvjB9++CFGjx4d//d//xe33nprqZc5cODANYYmqiyvv/568v977LHHGtOaNm0a06dPj2XLlpV4c+2SpLJfllb79u3jsssui8suuyyWL18en3zySTzzzDNx//33x5IlS+Kss86KnXfeudT3vcjfl2bPnh0rVqwo8Wq//CEo8+8vtLHJPzNrwYIF0bVr13UeCCuvZVA9qG3UNmtT26ht1mWfffaJP/3pT/GPf/wjPv/88xg6dGih+7pVlX2h4NX169oPSppecL+YNWtWiUN2FRwquzz3p8q09vZo165dsW3LYnvk1zULFy7c4Po4X4sWLeK8886L8847L1atWhVjx46NESNGxF133RVz586N6667Lnbcccc49NBDU1oP60c9oh5Zm3qk+tYjDRs2jO222y4+//zzGD9+fPLWIhuqSZMmMWPGjFKFBvnfWVXl+3t9apeq0ueCTjjhhLjuuuviu+++S44IVR6f7eWtTZs2xd5fdpNNNkn+v0uXLskhYitLjx494pZbbomIiFGjRiXvrVjezjvvvLj99ttj9uzZceWVV65xG5kNdc0118Rbb70VeXl5ceONN67XZ1J5cKXfRmyfffaJ1q1bx4oVK2LFihWRnZ0d++yzT7mvt2vXrvGXv/wlPvroo+SZbs8880xyeseOHZN/0L777rtluu7ffvst+aV35JFHFluELly4sMThfYrSoEGD6NOnTzz33HNx7rnnRsTqQvr9999f57zr2iYVZfvtt4+I1feZWN8zob799tuIWP3FXFwRmr/skpTFmT9ZWVnRuXPniFh9VkZJvvjii1i+fHlERMp/dK+Pjh07xtlnnx2ffPJJ8my0ynjNU/Xrr7/GE088ERGrb6q79lAX+SHZp59+Wuz96tYllf1yQ9SqVSt22223uO2225LPLZFIJO/FURr5+9KyZcuS96woTv6N5jt37lyqs7LSTf4+sHTp0nW+/8tzGVQPahu1zdrUNmqb0rjsssuS9/O76qqrCtUsZbUvpKpOnTrJ/eCTTz4psW1J0wvuF+van/LrlLXn25hsyPaoV69eifc0Lkl+XTNx4sQyvf9wZmZmbL/99nHNNdesccXP2u/DdL7SIl2oR9Qja1OPVO965KSTToqI1ccV7rjjjpSWlb8tP//881ixYkWx7X755ZfkULBV5ft7fWqXqtLngrp06ZI8GWHJkiWRlZUVRx55ZCX3auN2wAEHJId9feqpp0oc4rMsNWjQIC6++OKIWP1eGzFiRMrL3G233eLAAw+MiIj77rsvpk+fnvIyUyH024jVqFEjjj/++MjKyoqsrKw4/vjjS7yhfFlr165d8qzSgmPLZ2ZmxsEHHxwREe+8806ZXr5b8AuxpBuAPvTQQyV+ea5LwYJ+fW6gXNw2qSj5Y+fn5eXFAw88sF7z5m+vJUuWFDtcRl5eXvIS+OLk3/R+6dKl67X+teUXw99+++0aByvWln82YsF5KlLDhg2TQxBWxmueilWrVsXAgQOTf7Scdtpphc7G6tu3b0RE8n55GyKV/TJVG/peLrgvPfLII8W2+/DDD+O7774rNM/GpE+fPsk/MG+77bZKWwbVg9pGbbM2tY3apjSaNGkSgwYNioiIqVOnxrBhw9aYXlb7QlnIf02//vrrEj9LSqo/dthhh+SB/2HDhhX7nBYsWJA8ULrVVluVyz3AqoKePXsmRxEoabtNmTIlOcJFwXnWV359nEgk4vbbb9+gZazL9ttvn7wiZ+33Yf5nUkTqn0sUTT2iHlmbeqR61yMnn3xy8v56d999d7zzzjulnnft1zV/W86dOzeGDx9e7HwPP/xwcpjXqnKsobS1S40aNaJnz54V1Kv1c+KJJyY/2/v377/GKAyUvaysrORQm4sWLYpTTz21woZoPvvss5P3obzyyivLZNjkq6++OiJWf55ff/31KS8vFUK/jdxNN90US5YsiSVLlsSNN95Ypst+/vnnk0MQFGXq1Knx/fffR0QUGv/4oosuiszMzEgkEnH00UfHtGnTil1OSdPW1rx58+QH8pNPPllksfPJJ5/E5ZdfXuwyJk6cuM4v6ILDeBR8bqlsk4pw3HHHJS/x/r//+78Sn+fa2z3/bK+8vLwiz6JauXJlnHLKKes8kyH/YMIvv/wSCxYsWK/+F3TmmWcm/7A67bTTYv78+YXavPbaa/Hwww9HxOrhQ8rj/l+jR48ucQiPefPmJQvlyhoHfENMmTIlDjzwwHjllVciYvWN04u6we2JJ56YHCLpoosuWucZpe+//36h/S6V/XJdHn/88RL/6CzuvbwuO+20U/z+97+PiIgHH3xwjbOt882bNy9OP/30iFj9B/iZZ55Z6uWnky222CJ59ttTTz2VHJqhOJMmTYonn3yyzJdB9aG2UdsUpLZR25TW+eefn7yv74033rjGvf3Kal8oC6effnryRJjTTjutyIPr//znP5M1WlGysrLilFNOiYiIb775Jq655ppCbRKJRJx99tnJA6Vnn312WXS/SsrOzk7eg+3VV18tFPpGrB694eSTT05etZLK9th///2TVwrcfPPN67wC5euvv46XXnppjd89/fTTsXjx4mLn+fTTT2POnDkRUfh9WDC8/emnn9ar75SeekQ9UpB6pHrXI/Xq1YvHH388MjMzY9WqVXHwwQfHc889V+I8U6ZMiWOOOSbOOeecNX5/0kknJeuVCy+8MP773/8WmvfLL79MBgpt2rSJfv36lc0TKQPF1S5PPPFEsnbp16/fBp1o1KFDh8jIyCjXK9rPOuus5Ge7Yw4V44ILLoi99torIiJeeOGFOOKII9YZ5OfXQKmoX79+XHLJJRGxuhYrqbYurR133DF5EsiDDz5YJv3cUO7pxwa77bbb4thjj42DDz44evXqFV27do1GjRrFnDlz4tNPP40777wz+YfKGWecsca82223XVx11VVx+eWXxw8//BBbb711DBo0KPbee+9o2rRpzJ07N8aOHRvDhw+PGjVqxNtvv12qPmVmZsaxxx4bd999d3z11Vexxx57xAUXXBCdO3eOefPmxSuvvBL33HNPbLLJJpGdnR0//PBDoWVMmTIl9t5779hqq62if//+8fvf/z5ZvE2dOjWefvrpZCG23Xbbxc4771wm26Qi1KlTJx577LHYf//9Iy8vL/bdd984/vjjo1+/ftG2bdtYunRpfP/99/HKK6/Eiy++uEYhf9RRR8Vll10WS5cujZNOOinGjh0b++23XzRq1Ci+/fbbuPPOO+Ozzz6L3XffPT744INi+7DbbrtFxOqryM4444w455xz1rj3QGnHPt96663jwgsvjJtvvjm+/PLL2H777eOSSy6J7t27x6JFi+Kll16KO+64I1auXBm1a9eO+++/fwO3WsmefPLJ6NOnT+y3336x//77R7du3aJJkyaxYMGC+Oabb+Kuu+5KFmmV8ZoXZ+7cufHNN98kf168eHHMnTs3vvvuu3jnnXfipZdeSoZlW2yxRYwcOTIaNWpUaDlZWVnxzDPPRM+ePWPhwoXRq1evOProo6Nfv37RsWPHWLVqVcyYMSM+++yzGDFiRHz99ddx5513Ro8ePZLLSGW/XJfjjz8+LrroojjssMNit912i8033zzq1KkTs2bNitdffz3uvffeiFg9rnn+PQJK68EHH4ydd945li1bFgcddFCcc8450adPn6hfv3588cUXceONNybHgb/ooouq5PAVZeXee++NTz/9NCZOnBgXXnhhvPDCC3HCCSfE7373u8jKyorZs2fHl19+GaNGjYq33nor+vfvH8ccc0yZLwNSpbZR26ht0re2WZfmzZvHqaeeGrfffntMnDgxnnjiiTj++OMjouz2hbKw7bbbxqBBg+Kuu+6KTz/9NH7/+9/HJZdcEltvvXXMmzcvnn322XjggQfi97//fYlDvV1xxRUxfPjwmDhxYgwePDi+/vrrOOmkk6J169YxadKkuOuuu2LMmDEREbHrrrsm74+1sbr11lvjzTffjDlz5sTJJ58c77//fvzhD3+ITTfdNL7//vv4+9//nhyy/aijjorevXuntL4nnngidtppp/jtt9/iD3/4Qzz++OPxhz/8ITp37hw1atSIX375Jb744ot46aWX4qOPPooLL7wweZAoIuKSSy6JM844Iw499NDYa6+9okuXLlG/fv2YPXt2vP/++3HnnXdGxOqrJfID3nw5OTnRtm3bmDZtWvz973+Ptm3bxhZbbJG8crFly5bRoEGDlJ4f5Us9oh5Rj6RfPbLPPvvEQw89FKeffnosWrQojjjiiNhll13iiCOOiO222y6aNGkS8+bNi4kTJ8aoUaOS+8Hax1maN28eN998cwwaNCimTZsWO+ywQ/zlL3+J3XbbLVasWBFvvPFG3HzzzbFw4cLIyMiIBx54IGrVqlVJz3pN+bXJ2rXLv/71r+R+0qBBg/j73/9eyT2tGBMmTIihQ4eus91OO+0UW221Vfl3qIqqWbNmPPvss9GnT5/4z3/+EyNGjIjXX389jj766Nh7770jJycnGjRoEIsWLYqJEyfGu+++G08//XRy/vyQfEOceeaZ8fe//z1mzJhRZlcMX3311TFy5MhYtmzZBt8GqUwkSGtvv/12IiISEZEYMmTIes8/ZMiQ5Pxvv/12idMnTZq0xrQePXokpxX3yMzMTFxzzTXFrv+6665L1KxZs8Rl9OjRo9B87du3T0RE4sQTTyw0be7cuYntttuu2OU1adIk8c477yT7v/byC27Tkh5bbrllYuLEiWW2TSZNmrTO1zJ/+pVXXlnsNj3xxBMTEZFo3759sW1GjRqV2HTTTdfZ17U98sgjiczMzGLb/+EPf0i88cYbJe5TK1euTOyyyy6lWmdxr1HBZZ111lklPodGjRolRo8eXeT8BV/rovpaUHHbPn97r+txxhlnJFauXFniOspbwX2sNI+GDRsmLrzwwsSiRYvWuewPP/ww0a5du1Itd9iwYUUuY0P3y5L2+dL0p1GjRolXX3210Lwlff7lGz16dKJhw4YlLn/QoEHFvvYlfZaV9jluqPx1F7fM9V3njBkzEnvuuWeptvlJJ51Ubssg/altTiw0TW2jtln7e0tts1rBfWxd36WJRCIxderURO3atRMRkejatesa/S+LfWFdr2++K6+8sth9MpFIJJYtW5Y47LDDiu1Lx44dEz/99NM63z+TJk1KbLnlliW+jrvvvnti9uzZRc5f2lqgtM+7tHVPcQp+fm/I98Pnn3+eyM7OLnF7HHbYYYnFixcXOX9pn2e+8ePHJ7p161aq99NVV121xrz526qkR1ZWVrHb4Z577il2vg3ZdtWReuTEQtPUI+qRgg/1SNHGjBlT6s/+nJycxBNPPFHkcq677roS94msrKxij62UZp9PJEr/Oq3r2EjB17BgjbP2o2HDhokxY8ZscF8KfjduqILbpqT3e3HW9d2wvsfdIiJx6623JucvuN8XdxwqFQX7tyHLL/j6ruu9nW9dx57yLV68OHH++ecn6tSpU6rt1rBhw8Rll12WWLhwYaFlrc93+J133rnOz+i1n/u6tt3hhx++xvJKWzuWJVf6scGefPLJGDlyZIwZMya+++67mDlzZuTm5kadOnWiffv2sddee8UZZ5wR22yzTbHLuOyyy+LII4+Me+65J954442YMmVK5OXlxaabbhpbbbVV7LfffnHCCSesV78aNWoUH3zwQdxyyy3xzDPPxI8//hg1a9aMdu3axcEHHxx/+tOfkjf7Lcqee+4ZY8aMidGjR8dHH30UU6dOjVmzZsWSJUuiSZMmse2228Zhhx0WAwcOjKysrDLfJhXhgAMOiIkTJ8a9994bI0eOjPHjx8fcuXOjfv360alTp9hrr71iwIABheY76aSTYosttoibb745Pvjgg5g7d240a9Ystt122zjppJPiqKOOSp4xXJzMzMx47bXX4m9/+1u89NJL8dNPP8WiRYs2aOzkzMzMuPvuu+Poo4+O+++/P957772YNWtWZGVlxWabbRYHHXRQnHfeedG8efP1XnZp3XrrrbHffvvFW2+9FV999VXMmDEjfv3116hRo0a0a9cudt111zjllFNijz32KLc+pCojIyMaNGgQDRs2jDZt2sT2228fu+22W/Tv3z95M/R12WWXXeLHH3+MoUOHxksvvRRffPFF5ObmRmZmZjRv3jy6du0aPXr0iMMPPzy22GKLIpexoftlSb755pt4+eWX4/3334+ffvopZs2aFXPnzo0GDRrElltuGQcccECceeaZyRsHr6/9998/JkyYELfddlu88sorMXHixFi6dGm0bNky9txzzzjjjDOq9Gtfllq1ahXvvvtuvPzyy/Hkk0/Ghx9+GDNnzozly5dH48aNo3PnzrHrrrtG3759k0M3lMcyIBVqG7WN2mbjqG2K07Zt2zjxxBPjwQcfjHHjxsVzzz2XHF66LPaFslKrVq147rnn4vHHH48HHnggvvrqq1i+fHm0b98++vfvHxdddFHyfm4l6dChQ3z55Zfx4IMPxrPPPhvffPNNzJ8/P5o0aRLdu3ePY489NgYMGFCh9yKrTN27d4/x48fHXXfdFc8//3yMHz8+8vLyolmzZrHLLrvEwIED17jaLlVdunSJsWPHxjPPPBPPPfdcfPLJJ/Hrr7/GypUro2nTprHFFlvEHnvsEf3794/tt99+jXnffvvteOmll+Ldd9+NH374IWbOnBlz5syJevXqxeabbx777LNPnHnmmbHZZpsVue78+vb++++PsWPHxm+//ZbSfdaoWOoR9Yh6JH3rkR49esSXX34ZI0eOjJEjR8a///3v5HGITTbZJNq2bRs77bRTHHrooXHQQQdFzZpFH5q/7LLL4pBDDom77ror3nrrrZg+fXpkZmZGTk5O7L///nHeeedFhw4dKvbJlcLgwYNj1113jTvvvDM5FHV2dnYcdNBBcemll5b4GUH1VqdOnbjlllvi4osvjieffDLefPPN+O677yI3NzeWLl0ajRs3juzs7Nhhhx2iV69e0b9//5Su8st36qmnxt/+9reYOnVqGTyL1a666qoYMWJEhd2fsCgZiQ359AcAAAAAAACqjOpxSh8AAAAAAABsxIR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmalZ2ByrLqlWrYvr06dGgQYPIyMio7O4AANVIIpGIBQsWRHZ2dmRmVs45WGohAKCyqIUAgOqsPGuhahv6TZ8+Pdq1a1fZ3QAAqrGpU6dG27ZtK2XdaiEAoLKphQCA6qw8aqFqG/o1aNAgIlZv1IYNG1ZybwCA6mT+/PnRrl27ZD1SGdRCAEBlUQsBANVZedZC1Tb0yx+6oWHDhoo7AKBSVOZQUmohAKCyqYUAgOqsPGqhyhk4HQAAAAAAACgzQj8AAAAAAABIc0I/AAAAAAAASHPV9p5+AED5WLVqVSxbtqyyu1GpatWqFTVq1KjsbgAAlWTlypWxfPnyyu5GpVELAUD1Vt1roYiI2rVrR2ZmxV93J/QDAMrMsmXLYtKkSbFq1arK7kqla9y4cbRq1apcbsoMAFRNiUQiZs6cGXPnzq3srlQ6tRAAVD9qof/JzMyMjh07Ru3atSt0vUI/AKBMJBKJmDFjRtSoUSPatWtXKWczVQWJRCLy8vLil19+iYiI1q1bV3KPAICKkn+Qq0WLFlGvXr1qGXiphQCg+lILrbZq1aqYPn16zJgxI3Jycip0Owj9AIAysWLFisjLy4vs7OyoV69eZXenUtWtWzciIn755Zdo0aKF4a0AoBpYuXJl8iBX06ZNK7s7lUotBADVj1poTc2bN4/p06fHihUrolatWhW23up5Cj4AUOZWrlwZEVHhwxZUVfnBZ3Ufwx4Aqov87/zqfvJTPrUQAFQvaqE15R8fyz9eVlGEfgBAmaquQzeszXYAgOpJDbCa7QAA1ZMaYLXK2g5CPwAAAAAAAEhz7ukHAJSrKVOmRG5uboWtr1mzZpGTk1Nh6wMAKIlaCACo7iqyHqrutZDQDwAoN1OmTImuXbtGXl5eha2zXr16MW7cuPUq8AYOHBjDhg0r9Psff/wxrr322hg2bFjccMMN8Ze//CU57fnnn4/+/ftHIpEok34DABsftRAAUN1VdD1U3WshoR8AUG5yc3MjLy8vzr/ilmjbvlO5r2/azxPi1qsviNzc3PU+q+vAAw+MIUOGrPG75s2bR0REnTp14qabborTTz89Nt100zLrLwCwcVMLAQDVXUXWQ2ohoR8AUAHatu8Um2/RrbK7UaKsrKxo1apVkdP23XffmDBhQtxwww3xt7/9rYJ7BgCkO7UQAFDdVfV6aGOphTIruwMAAFVdjRo14vrrr48777wzpk2bVtndAQCoUGohAKA6S6daSOgHABARI0eOjE022ST5OPLII9eY3r9//9huu+3iyiuvrKQeAgCUH7UQAFCdbSy1UJUM/W644YbYcccdo0GDBtGiRYvo169fjB8/fo02PXv2jIyMjDUeZ5xxRiX1GABId3vvvXeMHTs2+bjjjjsKtbnpppti2LBhMW7cuEroIQBA+VELAQDV2cZSC1XJ0O+dd96JQYMGxUcffRSvv/56LF++PPbff/9YtGjRGu1OPfXUmDFjRvJR1cdSBQCqrvr160enTp2Sj9atWxdqs9dee8UBBxwQl156aSX0EACg/KiFAIDqbGOphWpWdgeKMmrUqDV+Hjp0aLRo0SI+++yz2GuvvZK/r1evXrE3VgQAKA833nhjbLfddrHFFltUdlcAACqcWggAqM6qei1UJa/0W9u8efMiIqJJkyZr/P6f//xnNGvWLLp16xaXXnpp5OXlVUb3AIBqZOutt45jjz22yGEeAAA2dmohAKA6q+q1UJW80q+gVatWxXnnnRe77757dOvWLfn7AQMGRPv27SM7Ozu++uqruOSSS2L8+PExfPjwIpezdOnSWLp0afLn+fPnl3vfgfQ2ZcqUyM3NXa95mjVrFjk5OeXUI0hf036esFGt5+qrr46nn366QtZVVtRCAFB51EKVTy0EAJWrIuoUtVBERiKRSFR2J0py5plnxquvvhrvv/9+tG3btth2b731Vuyzzz4xYcKE2HzzzQtNHzx4cFx11VWFfj9v3rxo2LBhmfYZSH9TpkyJrl27rvcVxPXq1Ytx48YJ/qiWlixZEpMmTYqOHTtGnTp1ImLD30upqCrvw6K2R7758+dHo0aNKrQOUQsBQPlSC61JLQQA1Utx3/0VXQ9V91qoSl/pd/bZZ8fIkSPj3XffLTHwi4jYeeedIyKKDf0uvfTSuOCCC5I/z58/P9q1a1e2HQY2Grm5uZGXlxfnX3FLtG3fqVTzTPt5Qtx69QWRm5tb6V8qUFXk5OTEuHHj1vuq2VS44rZoaiEAqHhqoapDLQQAlaOi66HqXgtVydAvkUjEOeecEyNGjIgxY8ZEx44d1znP2LFjIyKidevWRU7PysqKrKyssuwmUA20bd8pNt+i27obAsXKycmp1sVWVaEWAoDKoRaqGtRCAFB51EMVp0qGfoMGDYonnngiXnjhhWjQoEHMnDkzIiIaNWoUdevWjZ9++imeeOKJOOigg6Jp06bx1Vdfxfnnnx977bVXbLPNNpXcewAAAAAAAKhYVTL0u/feeyMiomfPnmv8fsiQITFw4MCoXbt2vPHGG3HbbbfFokWLol27dnH44YfHX//610roLQAAAAAAAFSuKhn6JRKJEqe3a9cu3nnnnQrqDQAAAAAAAFRtmZXdAQAAAAAAACA1Qj8AAAAAAABIc0I/AAAAAAAASHNCPwAAAAAAAEhzNSu7AwDAxm3KlCmRm5tbYetr1qxZ5OTkVNj6AABKohYCAKq7iqyHqnstJPQDAMrNlClTouuWW0Te4iUVts56devEuO/Hr1eBN3DgwBg2bFih3//4449x7bXXJqfVqlUrcnJy4oQTTojLLrssatZUSgEAxVMLAQDVXUXXQ9W9Fqp6PQIANhq5ubmRt3hJPH5WRNfs8l/fuOkRx92zJHJzc9f7rK4DDzwwhgwZssbvmjdvvsa0pUuXxiuvvBKDBg2KWrVqxaWXXlpmfQcANj5qIQCguqvIekgtJPQDACpA1+yI7TtWdi9KlpWVFa1atVrntDPPPDNGjBgRL774YpUs7gCAqkctBABUd1W9HtpYaqHMyu4AAEC6qVu3bixbtqyyuwEAUCnUQgBAdVaVayGhHwBARIwcOTI22WST5OPII48s1CaRSMQbb7wRo0ePjl69elVCLwEAyodaCACozjaWWsjwngAAEbH33nvHvffem/y5fv36yf/nF37Lly+PVatWxYABA2Lw4MGV0EsAgPKhFgIAqrONpRYS+gEAxOpirlOnTkVOyy/8ateuHdnZ2VGzphIKIFVTpkyJ3NzcUrdv1qxZ5OTklGOPoHpTCwEA1dnGUgtV3Z4BAFQRJRV+AKy/KVOmRNctt4i8xUtKPU+9unVi3PfjBX9QCdRCAEB1lk61kNAPAACACpWbmxt5i5fE42dFdM1ed/tx0yOOu2dJ5ObmCv0AAACKIfQDAMrduOkb13oAKBtdsyO271jZvYDypxYCAKq7iqhT1EJCPwCgHDVr1izq1a0Tx91T+uHbUlWvbp1o1qzZes0zdOjQDZoGAFAStRAAUN1VdD1U3WshoR8AUG5ycnJi3PfjIzc3t8LW2axZM0O/AQBVgloIAKjuKroequ61kNAPAChXOTk51brYAgCqN7UQAFDdqYcqTmZldwAAAAAAAABIjdAPAAAAAAAA0pzQDwAAAAAAANKc0A8AKFOJRKKyu1AlrFq1qrK7AABUAjXAarYDAFRPaoDVKuv4WM1KWSsAsNGpVatWZGRkxK+//hrNmzePjIyMyu5SpUgkErFs2bL49ddfIzMzM2rXrl3ZXQIAKkDt2rUjMzMzpk+fHs2bN4/atWtXy3pILQQA1ZNa6H8SiUT8+uuvkZGREbVq1arQdQv9AIAyUaNGjWjbtm1MmzYtJk+eXNndqXT16tWLnJycyMw0sAIAVAeZmZnRsWPHmDFjRkyfPr2yu1Pp1EIAUL2ohdaUkZERbdu2jRo1alToeoV+AECZ2WSTTaJz586xfPnyyu5KpapRo0bUrFmz2p7RBgDVVe3atSMnJydWrFgRK1eurOzuVBq1EABUT2qh/6lVq1aFB34RQj8AoIzVqFGjUooaAICqIH8Yp4oeygkAoCpQC1UuYywAAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJqrWdkdAAAAAACAdDVlypTIzc1dr3mWLl0aWVlZ6zVPs2bNIicnZ73mAaoXoR8AAAAAAGyAKVOmRNeuXSMvL2+95quRGbFy1fqtq17dOjHu+/GCP6BYQj8AAAAAANgAubm5kZeXF+dfcUu0bd+pVPN89tGYeOLBW+LxsyK6ZpduPeOmRxx3z5LIzc0V+gHFEvoBAAAAAEAK2rbvFJtv0a1Ubaf9/FNErA78tu9Ynr0CqpvMyu4AAAAAAAAAkBqhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkuSoZ+t1www2x4447RoMGDaJFixbRr1+/GD9+/BptlixZEoMGDYqmTZvGJptsEocffnjMmjWrknoMAAAAAAAAladKhn7vvPNODBo0KD766KN4/fXXY/ny5bH//vvHokWLkm3OP//8eOmll+LZZ5+Nd955J6ZPnx6HHXZYJfYaAAAAAAAAKkfNyu5AUUaNGrXGz0OHDo0WLVrEZ599FnvttVfMmzcvHn744XjiiSeiV69eERExZMiQ6Nq1a3z00Uexyy67VEa3AQAAAAAAoFJUydBvbfPmzYuIiCZNmkRExGeffRbLly+PfffdN9lmyy23jJycnPjwww+LDP2WLl0aS5cuTf48f/78cu41AEDVoRYCytOUKVMiNze31O3HjRtXjr0BKEwtBABUB1U+9Fu1alWcd955sfvuu0e3bt0iImLmzJlRu3btaNy48RptW7ZsGTNnzixyOTfccENcddVV5d1dAIAqSS0ElJcpU6ZE165dIy8vr7K7AlAstRAAUB1U+dBv0KBB8c0338T777+f0nIuvfTSuOCCC5I/z58/P9q1a5dq9wAA0oJaCCgvubm5kZeXF+dfcUu0bd+pVPN89tGYeOLBW8q5ZwD/oxYCAKqDKh36nX322TFy5Mh49913o23btsnft2rVKpYtWxZz585d42q/WbNmRatWrYpcVlZWVmRlZZV3lwEAqiS1EFDe2rbvFJtv0a1Ubaf9/FM59wZgTWohAKA6yKzsDhQlkUjE2WefHSNGjIi33norOnbsuMb0HXbYIWrVqhVvvvlm8nfjx4+PKVOmxK677lrR3QUAAAAAAIBKVSWv9Bs0aFA88cQT8cILL0SDBg2S9+lr1KhR1K1bNxo1ahR//OMf44ILLogmTZpEw4YN45xzzoldd901dtlll0ruPQAAAAAAAFSsKhn63XvvvRER0bNnzzV+P2TIkBg4cGBERNx6662RmZkZhx9+eCxdujQOOOCAuOeeeyq4pwAAAAAAAFD5qmTol0gk1tmmTp06cffdd8fdd99dAT0CAAAAAACAqqtK3tMPAAAAAAAAKD2hHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKQ5oR8AAAAAAACkOaEfAAAAAAAApDmhHwAAAAAAAKS5mpXdAYCNzbhx49Z7nmbNmkVOTk459AYAAAAAgOpA6AdQRubM/jUyMyKOO+649Z63Xt06Me778YI/AAAAAAA2iNAPoIwsWjg/ViUiHj8romt26ecbNz3iuHuWRG5urtAPAAAAAIANIvQDKGNdsyO271jZvQAAAAAAoDrJrOwOAAAAAAAAAKkR+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaE/oBAAAAAABAmhP6AQAAAAAAQJoT+gEAAAAAAECaSyn0mzNnTln1AwAAAAAAANhAKYV+bdu2jVNPPTXGjh1bRt0BAAAAAAAA1ldKod+yZcvi4Ycfjh122CH23HPPePrpp2PFihVl1TcAAAAAAACgFFIK/aZMmRKXX355tGzZMj744IMYMGBA5OTkxFVXXRUzZ84sqz4CAAAAAAAAJUgp9GvdunVcddVVMWXKlHjiiSdit912i5kzZ8bVV18d7du3j2OOOSbef//9suorAAAAAAAAUISUQr98NWvWjKOPPjree++9+PLLL+OUU06J2rVrx9NPPx09evSI7t27x8MPPxxLliwpi9UBAAAAAAAABZRJ6FfQ1ltvHffff39MmzYtLrrookgkEvHVV1/FaaedFm3atInLL7885s+fX9arBQAAAAAAgGqrzEO/iIj33nsvTjvttLj99tsjIqJ27dqx0047xdy5c+P666+PrbbaKr799tvyWDUAAAAAAABUO2UW+i1evDgeeOCB2HbbbaNnz57x7LPPRrNmzeLqq6+OKVOmxIcffhjff/99HHnkkTF9+vS48MILy2rVAAAAAAAAUK3VTHUBEyZMiLvvvjuGDRsW8+bNi0QiETvttFOce+65cdRRR0XNmv9bRefOneOpp56Kn3/+OT766KNUVw0AAAAAAABEiqFf79694/XXX49Vq1ZFrVq14uijj45zzz03dt555xLn22qrreI///lPKqsGAAAAAAAA/r+UQr/Ro0dH8+bN47TTTouzzjorWrduXar5+vXrFzk5OamsGgAAAAAAAPj/Ugr9HnnkkRgwYEDUrl17vebr06dP9OnTJ5VVAwAAAAAAAP9fSqHfwIEDy6gbAAAAAAAAwIbKTGXmqVOnxqOPPhrjx48vts33338fjz76aEybNq3Uy3333XejT58+kZ2dHRkZGfH888+vMX3gwIGRkZGxxuPAAw/c0KcBAAAAAAAAaS2l0O/OO++Mk046KRKJRLFtEolEDBw4MO65555SL3fRokWx7bbbxt13311smwMPPDBmzJiRfDz55JPr1XcAAAAAAADYWKQ0vOdrr70WXbt2jS233LLYNl27do2tttoqRo0aFddff32pltu7d+/o3bt3iW2ysrKiVatW69VfAAAAAAAA2BilPLxnp06d1tmuU6dOMXXq1FRWVciYMWOiRYsWscUWW8SZZ54Zs2fPLrH90qVLY/78+Ws8AACqC7UQAFCdqYUAgOogpdAvLy8v6tatu852devWjQULFqSyqjUceOCB8eijj8abb74ZN910U7zzzjvRu3fvWLlyZbHz3HDDDdGoUaPko127dmXWHwCAqk4tBABUZ2ohAKA6SCn0a926dYwdO3ad7b788sto0aJFKqtaw9FHHx19+/aNrbfeOvr16xcjR46MTz75JMaMGVPsPJdeemnMmzcv+SjrKw8BAKoytRAAUJ2phQCA6iCl0G/PPfeMH374IZ577rli2wwfPjy+//772GuvvVJZVYk222yzaNasWUyYMKHYNllZWdGwYcM1HgAA1YVaCACoztRCAEB1kFLo96c//SkyMjLihBNOiNtvv32NITwXLFgQt99+e5xwwgmRmZkZ5557bsqdLc60adNi9uzZ0bp163JbBwAAAAAAAFRVKYV+22+/fdxwww2xePHiuOCCC6JJkyaRk5MTOTk50aRJk7jgggsiLy8vrr322thpp51KvdyFCxfG2LFjk0OHTpo0KcaOHRtTpkyJhQsXxsUXXxwfffRRTJ48Od5888049NBDo1OnTnHAAQek8nQAAAAAAAAgLaUU+kVEXHzxxfH888/HNttsEytXroxp06bFtGnTYuXKlbHNNtvE8OHD4y9/+ct6LfPTTz+N7t27R/fu3SMi4oILLoju3bvHFVdcETVq1Iivvvoq+vbtG126dIk//vGPscMOO8R7770XWVlZqT4dAAAAAAAASDs1y2Ihffv2jb59+8asWbNiypQpERGRk5MTLVu23KDl9ezZMxKJRLHTR48evUHLBQAAAAAAgI1RmYR++Vq2bLnBQR8AAAAAAACwYVIe3hMAAAAAAACoXGVypd/HH38cb7zxRvz3v/+NJUuWFNkmIyMjHn744bJYHQAAAAAAAFBASqHfsmXL4phjjonnn38+IqLE+/AJ/QAAAAAAAKB8pBT6XXPNNTFixIioX79+HH/88dG1a9do2LBhWfUNAAAAAAAAKIWUQr8nn3wy6tWrFx9//HFstdVWZdUnAAAAAAAAYD1kpjLztGnTYvfddxf4AQAAAAAAQCVKKfTbdNNNo0mTJmXVFwAAAAAAAGADpBT67bvvvvHxxx9HIpEoq/4AAAAAAAAA6yml0O+aa66J3377LQYPHlxG3QEAAAAAAADWV81UZn733XfjpJNOimuvvTZGjRoVBx98cOTk5ERmZtFZ4gknnJDK6gAAAAAAAIAipBT6DRw4MDIyMiKRSMQnn3wSn376aYnthX4AAAAAAABQ9lIK/U444YTIyMgoq74AAAAAAAAAGyCl0G/o0KFl1A0AAAAAAABgQxV98z0AAAAAAAAgbaR0pd/aJkyYEL/++ms0bdo0unTpUpaLBgAAAAAAAIqR8pV+K1eujGuvvTZatWoVW2yxReyxxx5x4403Jqf/85//jN122y2+/fbbVFcFAAAAAAAAFCGl0G/lypVxyCGHxJVXXhlz5syJrl27RiKRWKPN7rvvHh999FEMHz48pY4CAAAAAAAARUsp9Lvvvvti9OjRsffee8ekSZPim2++KdSmQ4cOsfnmm8drr72WyqoAAAAAAACAYqQU+g0bNiyaNGkSzz77bGRnZxfbrmvXrjFlypRUVgUAAAAAAAAUI6XQ7/vvv4+ddtopNt100xLbNWrUKH755ZdUVgUAAAAAAAAUI+V7+mVlZa2z3YwZM0rVDgAAAAAAAFh/KYV+7du3j6+++qrENsuXL49vvvkmOnfunMqqAAAAAAAAgGKkFPodeOCBMXny5HjggQeKbXPnnXfGr7/+GgcffHAqqwIAAAAAAACKUTOVmS+++OIYOnRonHXWWfHdd9/FUUcdFRERixYtis8//zyeeeaZuOWWW6JZs2Zx9tlnl0mHAQAAAAAAgDWldKVf69at4/nnn4/GjRvHHXfcEXvuuWdkZGTEv/71r9hxxx3jb3/7W2yyySbx3HPPRbNmzcqqzwAAAAAAAEABKYV+ERF77bVXfPvtt/HnP/85fve730XdunUjKysrOnXqFOeee258/fXXsccee5RFXwEAAAAAAIAipDS8Z76WLVvGjTfeGDfeeGNZLA4AAAAAAABYDylf6QcAAAAAAABULqEfAAAAAAAApLmUhvfs1atXqdtmZGTEm2++mcrqAAAAAAAAgCKkFPqNGTNmnW0yMjIikUhERkZGKqsCAAAAAAAAipFS6Pf2228X+ftVq1bFzz//HCNHjozhw4fHpZdeGvvvv38qqwIAAAAAAACKkVLo16NHjxKnDxw4MO64447485//HEcddVQqqwIAAAAAAACKkVneKzj33HOjXbt2MXjw4PJeFQAAAAAAAFRL5R76RURsu+228f7771fEqgAAAAAAAKDaqZDQ77fffouFCxdWxKoAAAAAAACg2in30O/dd9+N9957LzbffPPyXhUAAAAAAABUSzVTmfnqq68udtqCBQti3LhxMXr06Fi1alWccsopqawKAAAAAAAAKEZKod/gwYMjIyMjEolEsW0yMzPjT3/6U5x33nmprAoAAAAAAAAoRkqh35VXXlnstNq1a0ebNm2iV69e0bZt21RWAwAAAAAAAJSg3EI/AAAAAAAAoGJkVnYHAAAAAAAAgNQI/QAAAAAAACDNpTS858knn7zB82ZkZMTDDz+cyuoBAAAAAACASDH0Gzp0aESsDvAiIhKJxBrTi/t9/jShHwAAAAAAAKQupdBvyJAh8cknn8Q999wTrVq1iqOOOio6duwYERGTJ0+OZ599NqZPnx5nnXVW7LjjjmXSYQAAAAAAAGBNKYV+O+ywQ5x55plx1llnxT/+8Y/IyspaY/pNN90UF154YTzyyCNx+umnx9Zbb51SZwEAAAAAAIDCMlOZefDgwdG6deu44447CgV+ERG1a9eO22+/PVq1ahWDBw9OZVUAAAAAAABAMVIK/d59993YeeedIzOz+MVkZmbGzjvvHO+9914qqwIAAAAAAACKkVLot2DBgpgzZ846282ZMycWLlyYyqoAAAAAAACAYqQU+nXq1CnGjBkTP/zwQ7Ftxo8fH2+//XZsvvnmqawKAAAAAAAAKEZKod8f//jHWLp0afTs2TMefPDByMvLS07Ly8uLhx56KPbZZ59Yvnx5/PGPf0y5swAAAAAAAEBhNVOZ+Zxzzol33nknXnjhhTjjjDPijDPOiGbNmkVERG5ubkREJBKJ6Nu3b5x77rmp9xYAAAAAAAAoJKUr/WrUqBHDhw+PO++8MzbbbLNIJBLx66+/xq+//hqJRCI6duwYd9xxR4wYMSIyM1NaFQAAAAAAAFCMlK70i4jIyMiIQYMGxaBBg2L69Okxbdq0iIho06ZNtGnTJuUOAgAAAAAAACVLOfQrKDs7O7Kzs8tykQAAAAAAAMA6lFnoN2/evPjkk0/i119/jfbt28duu+1WVosGAAAAAAAASpDyjfYWLFgQp5xySrRo0SIOOOCAOO644+Khhx5KTn/ooYciOzs7Pv7441RXBQAAAAAAABQhpdBv8eLF0bNnz3jkkUdi0003jd69e0cikVijzSGHHBKzZs2K559/PpVVAQAAAAAAAMVIKfS75ZZb4osvvohjjjkmfvrppxg5cmShNq1atYquXbvG22+/ncqqAAAAAAAAgGKkFPo9/fTT0apVq3j44Yejfv36xbbr0qVLTJs2LZVVAQAAAAAAAMVIKfT76aefYqeddoo6deqU2K5evXqRm5ubyqoAAAAAAACAYqQU+tWoUSOWL1++znbTpk0r8UpAAAAAAAAAYMOlFPptvvnm8eWXX8aKFSuKbbNw4cL46quvomvXrqmsCgAAAAAAAChGSqFf3759Y8aMGXHttdcW2+baa6+NefPmRf/+/VNZFQAAAAAAAFCMlEK/888/P9q0aRPXXHNN9OvXL5544omIiJg1a1YMHz48jj766Lj55pujQ4cOccYZZ5RJhwEAAAAAAIA11Uxl5saNG8eoUaOib9++8eKLL8ZLL70UGRkZMWrUqBg1alQkEolo3759vPTSS+7pBwAAAAAAAOUkpdAvImKrrbaKb775JoYOHRqvvPJKTJw4MVatWhXt2rWL3r17x2mnnRb16tUri74CAAAAAAAARUgp9Hv33XejRo0asfvuu8cZZ5xhCE8AAAAAAACoBCnd069nz55x+eWXl1VfAAAAAAAAgA2QUui36aabRnZ2dln1BQAAAAAAANgAKYV+2223Xfz4449l1RcAAAAAAABgA6QU+p177rnxySefxMsvv1xW/QEAAAAAAADWU81UZu7evXucffbZ0b9//xg4cGAcfvjh0aFDh6hbt26R7XNyclJZHQAAAAAAAFCElEK/jh07RkREIpGIhx9+OB5++OFi22ZkZMSKFStSWR0AAAAAAABQhJRCv3bt2kVGRkZZ9QUAAAAAAADYAOsV+t1xxx2x1VZbxb777hsREZMnTy6PPgEAAAAAAADrIXN9Gp933nnxxBNPFDmtV69ecfPNN5dJpwAAAAAAAIDSS2l4z4LGjBkTHTp0KKvFAQAAAAAAAKW0Xlf6AQAAAAAAAFWP0A8AAAAAAADSXJUM/d59993o06dPZGdnR0ZGRjz//PNrTE8kEnHFFVdE69ato27durHvvvvGjz/+WDmdBQAAAAAAgEpWJUO/RYsWxbbbbht33313kdP/9re/xR133BH33XdffPzxx1G/fv044IADYsmSJRXcUwAAAAAAAKh8Ndd3hgkTJsSjjz663tMiIk444YRSraN3797Ru3fvIqclEom47bbb4q9//WsceuihERHx6KOPRsuWLeP555+Po48+ulTrAAAAAAAAgI3Feod+H3zwQXzwwQeFfp+RkVHstPzppQ39SjJp0qSYOXNm7LvvvsnfNWrUKHbeeef48MMPhX4AAAAAAABUO+sV+uXk5ERGRkZ59aVUZs6cGRERLVu2XOP3LVu2TE4rytKlS2Pp0qXJn+fPn18+HQQAqILUQgBAdaYWAgCqg/UK/SZPnlxO3Sh/N9xwQ1x11VWV3Q0AgEqhFgIAqjO1EABQHWRWdgfWV6tWrSIiYtasWWv8ftasWclpRbn00ktj3rx5ycfUqVPLtZ8AAFWJWggAqM7UQgBAdbDe9/SrbB07doxWrVrFm2++Gdttt11ErB6S4eOPP44zzzyz2PmysrIiKyurgnoJAFC1qIUAgOpMLQQAVAdVMvRbuHBhTJgwIfnzpEmTYuzYsdGkSZPIycmJ8847L6699tro3LlzdOzYMS6//PLIzs6Ofv36VV6nAQAAAAAAoJJUydDv008/jb333jv58wUXXBARESeeeGIMHTo0/vznP8eiRYvitNNOi7lz58Yee+wRo0aNijp16lRWlwEAAAAAAKDSVMnQr2fPnpFIJIqdnpGREVdffXVcffXVFdgrAAAAAAAAqJoyK7sDAAAAAAAAQGqEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDmhH4AAAAAAACQ5oR+AAAAAAAAkOaEfgAAAAAAAJDm0jL0Gzx4cGRkZKzx2HLLLSu7WwAAAAAAAFApalZ2BzbU7373u3jjjTeSP9esmbZPBQAAAAAAAFKStklZzZo1o1WrVpXdDQAAAAAAAKh0aRv6/fjjj5GdnR116tSJXXfdNW644YbIyckptv3SpUtj6dKlyZ/nz59fEd0EAKgS1EIAQHWmFgIAqoO0vKffzjvvHEOHDo1Ro0bFvffeG5MmTYo999wzFixYUOw8N9xwQzRq1Cj5aNeuXQX2GACgcqmFAIDqTC0EAFQHaRn69e7dO4488sjYZptt4oADDohXXnkl5s6dG88880yx81x66aUxb9685GPq1KkV2GMAgMqlFgIAqjO1EABQHaTt8J4FNW7cOLp06RITJkwotk1WVlZkZWVVYK8AAKoOtRAAUJ2phQCA6iAtr/Rb28KFC+Onn36K1q1bV3ZXAAAAAAAAoMKlZeh30UUXxTvvvBOTJ0+Of//739G/f/+oUaNGHHPMMZXdNQAAAAAAAKhwaTm857Rp0+KYY46J2bNnR/PmzWOPPfaIjz76KJo3b17ZXQMAAAAAAIAKl5ah31NPPVXZXQAAAAAAAIAqIy2H9wQAAAAAAAD+R+gHAAAAAAAAaU7oBwAAAAAAAGlO6AcAAAAAAABpTugHAAAAAAAAaU7oBwAAAAAAAGlO6AcAAAAAAABpTugHAAAAAAAAaU7oBwAAAAAAAGlO6AcAAAAAAABpTugHAAAAAAAAaU7oBwAAAAAAAGlO6AcAAAAAAABpTugHAAAAAAAAaU7oBwAAAAAAAGlO6AcAAAAAAABpTugHAAAAAAAAaU7oBwAAAAAAAGlO6AcAAAAAAABpTugHAAAAAAAAaU7oBwAAAAAAAGlO6AcAAAAAAABpTugHAAAAAAAAaU7oBwAAAAAAAGlO6AcAAAAAAABpTugHAAAAAAAAaU7oBwAAAAAAAGlO6AcAAAAAAABpTugHAAAAAAAAaU7oBwAAAAAAAGmuZmV3AKA4U6ZMidzc3PWap1mzZpGTk1NOPQIAqLrWt3ZSNwEAGxPHkQCEfkAVNWXKlOjatWvk5eWt13z16tWLcePGKdgAgGplQ2ondRMAsLFwHAlgNaEfUCXl5uZGXl5enH/FLdG2fadSzTPt5wlx69UXRG5urmINAKhW1rd2UjcBABsTx5EAVhP6AVVa2/adYvMtulV2NwAA0oLaCQCoztRCQHWXWdkdAAAAAAAAAFIj9AMAAAAAAIA0J/QDAAAAAACANCf0AwAAAAAAgDQn9AMAAAAAAIA0J/QDAAAAAACANCf0AwAAAAAAgDQn9AMAAAAAAIA0J/QDAAAAAACANCf0AwAAAAAAgDQn9AMAAAAAAIA0J/QDAAAAAACANCf0AwAAAAAAgDQn9AMAAAAAAIA0J/QDAAAAAACANCf0AwAAAAAAgDQn9AMAAAAAAIA0J/QDAAAAAACANCf0AwAAAAAAgDQn9AMAAAAAAIA0J/QDAAAAAACANCf0AwAAAAAAgDQn9AMAAAAAAIA0J/QDAAAAAACANCf0AwAAAAAAgDQn9AMAAAAAAIA0J/QDAAAAAACANCf0AwAAAAAAgDQn9AMAAAAAAIA0J/QDAAAAAACANCf0AwAAAAAAgDQn9AMAAAAAAIA0J/QDAAAAAACANFezsjtQVUyZMiVyc3PXa55mzZpFTk5OOfWoetqQ1yHCawEAVdX6frf7Ti8balsAAACofoR+sfqgSNeuXSMvL2+95qtXr16MGzfOwZEysqGvQ4TXAgCqog35bvednjq1LQAAAFRPQr+IyM3Njby8vDj/iluibftOpZpn2s8T4tarL4jc3FwHRsrIhrwOEV4LAKiq1ve73Xd62VDbAgAAQPUk9CugbftOsfkW3Sq7G9We1wEANi6+2yuH7Q4AAADVS2ZldwAAAAAAAABIjdAPAAAAAAAA0pzQDwAAAAAAANKc0A8AAAAAAADSnNAPAAAAAAAA0pzQDwAAAAAAANKc0A8AAAAAAADSnNAPAAAAAAAA0pzQDwAAAAAAANKc0A8AAAAAAADSnNAPAAAAAAAA0lxah3533313dOjQIerUqRM777xz/Oc//6nsLgEAAAAAAECFS9vQ7+mnn44LLrggrrzyyvj8889j2223jQMOOCB++eWXyu4aAAAAAAAAVKi0Df1uueWWOPXUU+Okk06KrbbaKu67776oV69ePPLII5XdNQAAAAAAAKhQaRn6LVu2LD777LPYd999k7/LzMyMfffdNz788MNK7BkAAAAAAABUvJqV3YENkZubGytXroyWLVuu8fuWLVvG999/X+Q8S5cujaVLlyZ/njdvXkREzJ8/PxYuXBgRET/98E0sWZxXqj78d+rEiIj47LPPkvOXRqtWraJVq1ZFTps5c2bMnDmz1MuKWB12rlq1ar3mqap92JDX4f+1d+9RUdf5H8dfgwiKCoiIIgqittRmiqGyCmquruCal3Jdj7fQrLZSt9LUrf0Z2snV1S07dSprt4U6aSWWly7qGoltK14y8YrkDe9oqah5Q+Tz+4Mzo9OMCgozDPN8nMMpvp/PfL+f73s+zLzkM3y/UsU/F97+PFSVMbj75/JWjn9o/+7S4+dLP18s8+GVV3D1mGfOnLFrc/fzwBhce/yqMIaq/DxUlTFUBOvPujGm0o7xSzfKQpWlvK+lnvieXpHz1Z2Z6lZqXxXP/VaOfSvHr4qv1e78eXNFbrpRXpK8d87dyvGry7m7OxN4a90rirdkIYmfE2/9OeHcvSsDu+p3SBX5+yPmHOd+u8f35ve3ilCZWchiXJmwKsiRI0cUERGhNWvWqFOnTrbtkyZN0urVq7Vu3TqHx0ydOlXTpk1z5TABAABuaM+ePWrRooVLjkUWAgAAVc3BgwfVtGlTlxyLLAQAAKqayvi9kEcu+hUVFSkgIEALFy7UgAEDbNtTUlJUWFioJUuWODzml5/oKiwsVFRUlA4cOKCgoCBXDLtKO3PmjJo1a6aDBw8qMDDQ3cNxO+rhiJrYox72qIc96uGImtg7ffq0IiMjderUKQUHB7vkmL/MQiUlJTp58qQaNGggi8VSYcfhuaYGVtSBGlhRB2pgRR2ogXS1Bjt27FBMTIx8fFxz5xmykOtQg1LUgRpYUQdqYEUdqIFVZf5eyCMv7+nn56e4uDhlZmbaFv1KSkqUmZmpsWPHOn2Mv7+//P39HbYHBQV59eT6pcDAQOpxDerhiJrYox72qIc96uGImthz1S+5JOdZqDIXHHmuqYEVdaAGVtSBGlhRB2ogSREREWShao4alKIO1MCKOlADK+pADawqIwt55KKfJI0fP14pKSlq3769OnbsqFdffVXnzp3TqFGj3D00AAAAAAAAAAAAwKU8dtFv8ODB+vHHH/XCCy+ooKBAsbGxWr58uRo1auTuoQEAAAAAAAAAAAAu5bGLfpI0duzY617O82b8/f2Vmprq9JKf3oh62KMejqiJPephj3rYox6OqIm96lyP6nxuZUUNSlEHamBFHaiBFXWgBlL1r0F1P7+yoAalqAM1sKIO1MCKOlADq8qsg8UYYyp8rwAAAAAAAAAAAABcxnV3TAYAAAAAAAAAAABQKVj0AwAAAAAAAAAAADwci34AAAAAAAAAAACAh6v2i37Tp09X586dFRAQoODgYKd9Dhw4oD59+iggIEBhYWGaOHGiiouL7fpkZWXp3nvvlb+/v1q1aqX09PTKH7wLZGVlyWKxOP3asGGDJCk/P99p+9q1a908+srRvHlzh3OdOXOmXZ8tW7aoS5cuqlWrlpo1a6ZZs2a5abSVLz8/X6NHj1Z0dLRq166tli1bKjU1VUVFRXZ9vGmOvPHGG2revLlq1aql+Ph4rV+/3t1DcokZM2aoQ4cOqlevnsLCwjRgwADl5eXZ9bnvvvsc5sHjjz/uphFXvqlTpzqc75133mlrv3jxosaMGaMGDRqobt26GjhwoI4dO+bGEVcuZ6+fFotFY8aMkVT958c333yjvn37qkmTJrJYLFq8eLFduzFGL7zwgsLDw1W7dm317NlTu3btsutz8uRJDRs2TIGBgQoODtbo0aP1888/u/Asyo6M5YhcdZW35yny01XelJvISqXIR96bichCjshCZCGyEFmILEQW8sYsJHlnHqoqWajaL/oVFRVp0KBBeuKJJ5y2X7lyRX369FFRUZHWrFmj9957T+np6XrhhRdsffbt26c+ffqoe/fuysnJ0dNPP61HHnlEK1ascNVpVJrOnTvr6NGjdl+PPPKIoqOj1b59e7u+X331lV2/uLg4N4268r344ot25zpu3Dhb25kzZ9SrVy9FRUVp48aNmj17tqZOnap33nnHjSOuPDt37lRJSYnefvttbd++XXPmzNHcuXP1/PPPO/T1hjny8ccfa/z48UpNTdX333+vtm3bKikpScePH3f30Crd6tWrNWbMGK1du1YrV67U5cuX1atXL507d86u36OPPmo3D6rTP1ycufvuu+3O99tvv7W1PfPMM/rss8+UkZGh1atX68iRI3rwwQfdONrKtWHDBrtarFy5UpI0aNAgW5/qPD/OnTuntm3b6o033nDaPmvWLL322muaO3eu1q1bpzp16igpKUkXL1609Rk2bJi2b9+ulStX6vPPP9c333yjxx57zFWnUC5kLEfkKnvenKfIT6W8LTeRla7y9nzkrZmILGSPLEQWIguRhchCZCFvzUKSd+ahKpOFjJdIS0szQUFBDtu//PJL4+PjYwoKCmzb3nrrLRMYGGguXbpkjDFm0qRJ5u6777Z73ODBg01SUlKljtkdioqKTMOGDc2LL75o27Zv3z4jyWzatMl9A3OhqKgoM2fOnOu2v/nmm6Z+/fq2+WGMMZMnTzYxMTEuGF3VMGvWLBMdHW373pvmSMeOHc2YMWNs31+5csU0adLEzJgxw42jco/jx48bSWb16tW2bd26dTNPPfWU+wblYqmpqaZt27ZO2woLC03NmjVNRkaGbVtubq6RZLKzs100Qvd66qmnTMuWLU1JSYkxxrvmhySzaNEi2/clJSWmcePGZvbs2bZthYWFxt/f33z44YfGGGN27NhhJJkNGzbY+ixbtsxYLBZz+PBhl429vMhY1+fNuYo85cgb85O35yZvzUrkI0femInIQmQhY8hCZCF7ZCGykDHe8R5IFnLO2/KQO7NQtf9Lv5vJzs7WPffco0aNGtm2JSUl6cyZM9q+fbutT8+ePe0el5SUpOzsbJeO1RWWLl2qEydOaNSoUQ5t/fr1U1hYmBITE7V06VI3jM51Zs6cqQYNGqhdu3aaPXu23eU3srOz1bVrV/n5+dm2JSUlKS8vT6dOnXLHcF3u9OnTCgkJcdhe3edIUVGRNm7caPd64OPjo549e1bL14ObOX36tCQ5zIV58+YpNDRUrVu31nPPPafz58+7Y3gus2vXLjVp0kQtWrTQsGHDdODAAUnSxo0bdfnyZbv5cueddyoyMtIr5ktRUZE++OADPfzww7JYLLbt3jY/rPbt26eCggK7+RAUFKT4+HjbfMjOzlZwcLDdp6B79uwpHx8frVu3zuVjvl1kLHIVecqet+UncpN3ZyXy0VVkolJkoVJkoauq6/vftchC9shCZCErb3gPJAvZIw+5Ngv5VtywPVNBQYFdAJNk+76goOCGfc6cOaMLFy6odu3arhmsC7z77rtKSkpS06ZNbdvq1q2rl19+WQkJCfLx8dEnn3yiAQMGaPHixerXr58bR1s5/vznP+vee+9VSEiI1qxZo+eee05Hjx7VK6+8Iql0PkRHR9s95to5U79+fZeP2ZV2796t119/Xf/4xz9s27xljvz000+6cuWK09eDnTt3umlU7lFSUqKnn35aCQkJat26tW370KFDFRUVpSZNmmjLli2aPHmy8vLy9Omnn7pxtJUnPj5e6enpiomJ0dGjRzVt2jR16dJF27ZtU0FBgfz8/Bzu79GoUSPb+0t1tnjxYhUWFmrkyJG2bd42P65lfc6dvX5cmzfCwsLs2n19fRUSEuKRc4aM5d25ijxlzxvzk7fnJm/OSuQje2SiUmShUmSh6v/+Z0UWskcWuoosVP3fA8lCjshDrs1CHrno95e//EV///vfb9gnNzfX7gaZ3uZWanTo0CGtWLFCCxYssOsXGhqq8ePH277v0KGDjhw5otmzZ3vMm3B56nHtubZp00Z+fn7605/+pBkzZsjf37+yh+oytzJHDh8+rOTkZA0aNEiPPvqobXt1mCMonzFjxmjbtm121ySXZHeN6XvuuUfh4eHq0aOH9uzZo5YtW7p6mJWud+/etv9v06aN4uPjFRUVpQULFnj8P9Bv17vvvqvevXurSZMmtm3eNj88ERnLOXJVKfIU+Qll581ZiXxkj0zkWchCzpGFSpGFyEIoO7JQKbJQKfKQa3nkot+ECRPsVoWdadGiRZn21bhxY61fv95u27Fjx2xt1v9at13bJzAwsMr+oN5KjdLS0tSgQYMyvbHGx8fbbr7pCW5nzsTHx6u4uFj5+fmKiYm57nyQrs4ZT1Demhw5ckTdu3dX586dy3RjaU+bI2URGhqqGjVqOH3+Pem5v11jx4613Uj22k9sOhMfHy+p9FN93vCGHRwcrF/96lfavXu3fve736moqEiFhYV2n+Dyhvmyf/9+ffXVVzf9dJY3zQ/rc37s2DGFh4fbth87dkyxsbG2Pr+8oXtxcbFOnjzpsjlDxnKOXFWKPEV+Kg9vzk1kJXvenI/IRFeRhUqRhZzzlPc/shBZqDzIQmQhK2/OQhJ5yMqVWcgjF/0aNmyohg0bVsi+OnXqpOnTp+v48eO2P51cuXKlAgMD9etf/9rW58svv7R73MqVK9WpU6cKGUNlKG+NjDFKS0vTQw89pJo1a960f05Ojt3krOpuZ87k5OTIx8fHNj86deqkv/71r7p8+bKtVitXrlRMTIxHXX6hPDU5fPiwunfvrri4OKWlpcnH5+a3A/W0OVIWfn5+iouLU2ZmpgYMGCCp9HIFmZmZGjt2rHsH5wLGGI0bN06LFi1SVlaWw6VInMnJyZGkajcXrufnn3/Wnj17NGLECMXFxalmzZrKzMzUwIEDJUl5eXk6cOBAlX7/qAhpaWkKCwtTnz59btjPm+ZHdHS0GjdurMzMTFuYO3PmjNatW6cnnnhCUun7S2FhoTZu3Ki4uDhJ0tdff62SkhJb+K1sZCznyFWlyFPkp/LwxtxEVnLOm/MRmegqshBZ6EY85f2PLEQWKg+yEFnIypuzkEQesnJpFjLV3P79+82mTZvMtGnTTN26dc2mTZvMpk2bzNmzZ40xxhQXF5vWrVubXr16mZycHLN8+XLTsGFD89xzz9n2sXfvXhMQEGAmTpxocnNzzRtvvGFq1Khhli9f7q7TqnBfffWVkWRyc3Md2tLT0838+fNNbm6uyc3NNdOnTzc+Pj7m3//+txtGWrnWrFlj5syZY3JycsyePXvMBx98YBo2bGgeeughW5/CwkLTqFEjM2LECLNt2zbz0UcfmYCAAPP222+7ceSV59ChQ6ZVq1amR48e5tChQ+bo0aO2LytvmiMfffSR8ff3N+np6WbHjh3mscceM8HBwaagoMDdQ6t0TzzxhAkKCjJZWVl28+D8+fPGGGN2795tXnzxRfPdd9+Zffv2mSVLlpgWLVqYrl27unnklWfChAkmKyvL7Nu3z/zvf/8zPXv2NKGhoeb48ePGGGMef/xxExkZab7++mvz3XffmU6dOplOnTq5edSV68qVKyYyMtJMnjzZbrs3zI+zZ8/acoYk88orr5hNmzaZ/fv3G2OMmTlzpgkODjZLliwxW7ZsMf379zfR0dHmwoULtn0kJyebdu3amXXr1plvv/3W3HHHHWbIkCHuOqUbImNdn7fnKvIU+cnK23ITWakU+aiUN2YishBZyIosRBYiC5UiC5GFvDkLGeN9eaiqZKFqv+iXkpJiJDl8rVq1ytYnPz/f9O7d29SuXduEhoaaCRMmmMuXL9vtZ9WqVSY2Ntb4+fmZFi1amLS0NNeeSCUbMmSI6dy5s9O29PR0c9ddd5mAgAATGBhoOnbsaDIyMlw8QtfYuHGjiY+PN0FBQaZWrVrmrrvuMn/729/MxYsX7fpt3rzZJCYmGn9/fxMREWFmzpzpphFXvrS0NKc/Q9d+ZsCb5ogxxrz++usmMjLS+Pn5mY4dO5q1a9e6e0gucb15YH09PHDggOnatasJCQkx/v7+plWrVmbixInm9OnT7h14JRo8eLAJDw83fn5+JiIiwgwePNjs3r3b1n7hwgXz5JNPmvr165uAgADzwAMP2P0jpzpasWKFkWTy8vLstnvD/Fi1apXTn5GUlBRjjDElJSVmypQpplGjRsbf39/06NHDoU4nTpwwQ4YMMXXr1jWBgYFm1KhRtl8cVTVkrOvz9lxFniI/XcubchNZqRT5qJQ3ZiKyEFnIiixEFiILXUUWIgt5axYyxvvyUFXJQhZjjCn73wUCAAAAAAAAAAAAqGpufjFlAAAAAAAAAAAAAFUai34AAAAAAAAAAACAh2PRDwAAAAAAAAAAAPBwLPoBAAAAAAAAAAAAHo5FPwAAAAAAAAAAAMDDsegHAAAAAAAAAAAAeDgW/QAAAAAAAAAAAAAPx6IfAAAAAAAAAAAA4OFY9AOqOYvFUu6v++67T5J03333yWKxKCsry63nUFny8/NlsVjUvHlzhzZrLZxZs2aNevXqpZCQEPn4+MhisSg9Pd3W/tlnn6lLly4KDAy07ae61hAAgKqOLHR9ZCEAAKo/stD1kYUAVEe+7h4AgMqVkpLisK2goEArVqy4bvudd95Z6ePyVEeOHFGfPn10+vRpJSYmqnnz5vLx8VGrVq0kSTk5ORo4cKBKSkr029/+VuHh4bJYLGrcuLGbRw4AgHciC1UsshAAAJ6FLFSxyEIAqjoW/YBq7tpPGlllZWXZwp2zdqv3339f58+fV2RkZCWNrurKzc11uv0///mPCgsLNXToUM2bN8+hffHixbp8+bKef/55TZ8+vbKHCQAAboIsdGvIQgAAVA9koVtDFgLgqVj0A3Bd3hjqrK73qbYDBw5Iku64445bagcAAJ6DLOSILAQAgPcgCzkiCwGo6rinH4Drut6120eOHGm7XnleXp4GDx6ssLAw1alTRx06dNCSJUtsfdetW6d+/fqpYcOGql27tjp16qTMzMzrHvPChQt6+eWX9Zvf/EbBwcGqVauWYmJiNGnSJJ04ceKWzuPzzz9Xt27dVK9ePQUFBalLly52Y3Tml9duT09Pl8ViUWpqqiRp2rRptj7NmzfX1KlTZbFYlJaWJkkaNWqUw7XwrU6dOqXU1FTFxsaqXr16CggI0D333KOXXnpJ58+fdxiLdd9Tp07VgQMHNHr0aDVr1kw1a9bUyJEj7fouXLhQycnJatiwofz8/BQREaHhw4drx44dDvu99tr1xhi98847iouLU506dRQUFKRevXopOzv7ujU6f/68Xn31VSUmJqp+/fry9/dXVFSU+vbtq/nz5zt9THnGBwCAu5GFyEJkIQCANyMLkYXIQoDn4S/9ANyy77//XmPHjlXTpk3Vo0cP7d+/X9nZ2XrggQe0YMEC+fr66o9//KNat26tHj16aOfOnVq7dq2Sk5O1atUqJSYm2u3vyJEjSk5O1tatWxUSEqIOHTqoXr16+v777zV79mxlZGQoKytLUVFRZR7jnDlzNH78eElSx44d1bJlS+3atUsDBgywbS+LVq1aKSUlRTk5Odq8ebPatm2r2NhYSVJoaKhiY2OVkpKib7/9Vnv27FFCQoLteu7Xfjpsx44dSk5O1sGDBxUeHq7ExETVrFlT69ev15QpU/TJJ58oKytLQUFBDmPYtWuX2rVrJz8/PyUkJMgYo9DQUElScXGxhg0bpgULFsjf319xcXGKiIjQDz/8oHnz5unTTz/Vp59+quTkZKfnN2rUKM2fP19dunTR/fffr5ycHK1cuVLffPONVq9erfj4eLv+Bw8eVHJysnbs2KGAgAAlJCSoQYMGOnz4sP773/9q69atGjp0qK3/7Y4PAICqiCwUK4ksRBYCAHgrslCsJLIQWQioYgwAr7Nq1SojydzsJaBbt25Gklm1apXd9pSUFNvjX3rpJVNSUmJre+2114wk07RpU1O/fn3z/vvv2z326aefNpJMz5497baXlJSYhIQEI8mMHj3anDlzxtZ2+fJlM2HCBCPJdO/evcznuXnzZlOjRg3j4+NjMjIy7No++OADY7FYjCQTFRXl8Njr1Sc1NdVIMqmpqU6Paa1NWlqaQ9v58+dNy5YtjSTzf//3f+bSpUu2tnPnzpkhQ4YYSWbUqFFOjynJDB8+3Fy8eNFh388//7yRZOLj483evXvt2jIyMkyNGjVM/fr1zalTp2zb9+3bZ9tvVFSUycvLs7UVFxebhx9+2EgyvXr1stvflStXTPv27W1tx48ft2u/cOGC+eKLL257fAAAVBayEFnIGLIQAMB7kYXIQsaQhYDqikU/wAtVVLjr2LGjXbAzpjSIhYSEGElm0KBBDvv86aefjCTj5+dnioqKbNuXLVtmJJnY2Fhz+fJlh8dduXLFtG7d2kgyW7duLdN5PvLII0aSGTx4sNP2/v37uzTcvfXWW0aSuf/++50+9uzZsyYsLMz4+vqakydPOhwzJCTEFBYWOjzuxIkTpnbt2qZWrVrm0KFDTvf95JNPGknm9ddft227NtwtXbrU4TFHjx41koy/v7/dc7V48WIjyYSHh5uzZ886PV5FjA8AgMpCFipFFiILAQC8E1moFFmILARUR9zTD8At6927t931zSXJ19dX0dHRkqTf//73Do9p0KCBQkJCVFRUZHct9i+++EKSNHDgQPn6Ol552MfHR127dpUkrVmzpkzjs15zfvjw4U7bU1JSyrSfimI9x8GDBzttr1u3rtq3b6/i4mJt2LDBob1nz55OL++watUqXbhwQQkJCYqIiHC6b+v1453VztfX1+nlExo3bqz69evr0qVLds/V8uXLJUlDhw5V3bp1nR6vIscHAEBVRRYqH7IQWQgAUL2QhcqHLEQWAlyBe/oBuGWRkZFOt1vf8K/XXq9ePZ08eVIXL160bdu7d68kacqUKZoyZcoNj/vjjz+WaXyHDh2SJFvY/KXrba8s1nMcMWKERowYccO+zs6xefPmN9xvZmamQ9guy37Dw8NVs2ZNp/0DAwN16tQpu+dq//79kuyvSX8jtzs+AACqKrJQ+ZCFyEIAgOqFLFQ+ZCGyEOAKLPoBuGU+Pjf+Y+GbtV+rpKREkpSYmKiWLVvesO/dd99d5v1WJdZzTE5OVqNGjW7Y19lNqWvXrn3D/bZq1UoJCQk33K+zQFae5+lW3O74AACoqshC5UMWIgsBAKoXslD5kIXIQoArsOgHoEpo1qyZJKl///569tlnK2SfERER2rNnj/Lz850Gwvz8/Ao5Tlk1a9ZMO3fu1OjRo/WHP/yhQvcrSTExMUpPT6+w/V6P9ZN6O3fuLFN/V48PAABPRBa6vf1KZCEAADwZWej29iuRhQCU4p5+AKqE3r17S5IyMjJkjKmQfXbr1k2SNG/ePKft77//foUcp6ys57hgwYIK3W+PHj3k5+enrKwsHT9+vEL37Yz1Ou8ffvihzp07d9P+rh4fAACeiCx068hCAAB4PrLQrSMLAbgWi34AqoT+/furQ4cOWr9+vUaNGuX0Gt6nTp3S3LlzVVxcXKZ9jhs3TjVq1NCCBQu0aNEiu7aPPvpIixcvroihl9ljjz2mqKgoZWRkaPLkyTp79qxDn4KCAv3zn/8s134bNWqkcePG6dy5c+rbt6+2bt3q0OfSpUtaunRpmT+FdSP9+vVTu3btdOTIEQ0aNMjuZs6SdPHiRS1btsxt4wMAwBORhUqRhchCAADvRBYqRRYiCwG3i8t7AqgSfHx8tHjxYvXp00fvvfeeFi5cqLZt2yoyMlJFRUXau3evtm7dqitXrmjkyJHy9b35y1dsbKxmzJihSZMm6cEHH1R8fLxatmypXbt2acOGDXrmmWc0Z84cF5xdqTp16uiLL77Q/fffr1mzZumdd95RmzZt1LRpU50/f14//PCDcnNzFRYWpkcffbRc+545c6aOHj2q+fPnKzY2Vm3btlWLFi3k6+urQ4cOKScnR+fOndOyZctu+/roPj4+WrRokZKSkrRs2TJFRkYqMTFRDRo00OHDh7V582YFBwfbXSbDleMDAMATkYXIQmQhAIA3IwuRhchCQMVg0Q9AldGkSROtXbtW6enp+vjjj7VlyxatX79eISEhatKkiR5//HH169dPtWrVKvM+J06cqJiYGM2ePVubNm3S9u3b1aZNGy1cuFBxcXEuDXdS6c2mt2zZorlz52rRokXasmWLsrOzFRoaqqZNm+rZZ5/VAw88UO79+vr6at68eRo+fLj+9a9/ad26ddq2bZvq1Kmj8PBw9e3bV/369VPXrl0r5DyioqL03Xff6c0339TChQuVnZ2toqIiNW7cWN26ddPQoUPdOj4AADwRWYgsRBYCAHgzshBZiCwE3D6LqaiLJAMAAAAAAAAAAABwC+7pBwAAAAAAAAAAAHg4Fv0AAAAAAAAAAAAAD8eiHwAAAAAAAAAAAODhWPQDAAAAAAAAAAAAPByLfgAAAAAAAAAAAICHY9EPAAAAAAAAAAAA8HAs+gEAAAAAAAAAAAAejkU/AAAAAAAAAAAAwMOx6AcAAAAAAAAAAAB4OBb9AAAAAAAAAAAAAA/Hoh8AAAAAAAAAAADg4Vj0AwAAAAAAAAAAADwci34AAAAAAAAAAACAh/t/JlP8z+rHjDMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "diff_0 = misclass[misclass['pred label'] == 0]['diff rewr-orig']\n",
    "diff_1 = misclass[misclass['pred label'] == 1]['diff rewr-orig']\n",
    "diff_0_forest = misclass_forest[misclass_forest['pred label'] == 0]['diff rewr-orig']\n",
    "diff_1_forest = misclass_forest[misclass_forest['pred label'] == 1]['diff rewr-orig']\n",
    "diff_0_combi = misclass_combi[misclass_combi['pred label'] == 0]['diff rewr-orig']\n",
    "diff_1_combi = misclass_combi[misclass_combi['pred label'] == 1]['diff rewr-orig']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "bins=list(range(-100, 101, 12))\n",
    "axes[0].hist([diff_0, diff_1], bins=bins, edgecolor='black', color=['lightsteelblue', 'orange'], label=['FN', 'FP'])\n",
    "axes[0].set_xlabel('Time difference', fontsize = 16)\n",
    "axes[0].set_ylabel('Frequency', fontsize = 16)\n",
    "axes[0].set_title('Misclassifications - Decision Tree', fontsize = 20)\n",
    "axes[0].legend(title='')\n",
    "axes[0].set_xlim([-100,100])\n",
    "axes[1].hist([diff_0_forest, diff_1_forest], bins=bins, edgecolor='black', color=['lightsteelblue', 'orange'], label=['FN', 'FP'])\n",
    "axes[1].set_xlabel('Time difference', fontsize = 16)\n",
    "axes[1].set_title('Misclassifications - Random Forest', fontsize = 20)\n",
    "axes[1].legend(title='')\n",
    "axes[2].hist([diff_0_combi, diff_1_combi], bins=bins, edgecolor='black', color=['lightsteelblue', 'orange'], label=['FN', 'FP'])\n",
    "axes[2].set_xlabel('Time difference', fontsize = 16)\n",
    "axes[2].set_title('Misclassifications - Combi: MLP+HGNN', fontsize = 20)\n",
    "axes[2].legend(title='')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/res_spa_mis\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f5c31-8919-4ecf-a744-59f036904eb3",
   "metadata": {},
   "source": [
    "## Final model on test set (with statistical tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f1314-40b5-48fb-ad28-928c1a632f6e",
   "metadata": {},
   "source": [
    "We apply the final model (= the decision tree) on the untouched test set and observe the metrics and misclassifications on it (= how well it generalizes). Additionally, we compare the mean/median between the original runtimes on the test set and the decided runtimes on the test set (either the rewritten or the original one, based on the decision program)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee8f139a-635b-44c5-bab7-36ca7fe83a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_dec_tree = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c1aa1d3-308f-419b-b4e7-230bb2a9fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8027210884353742\n",
      "0.8053691275167785\n",
      "0.8053691275167785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[116,  29],\n",
       "       [ 29, 120]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_test, y1_pred_dec_tree)\n",
    "print(accuracy)\n",
    "precision = precision_score(y1_test, y1_pred_dec_tree)\n",
    "print(precision)\n",
    "recall = recall_score(y1_test, y1_pred_dec_tree)\n",
    "print(recall)\n",
    "conf_matrix = confusion_matrix(y1_test, y1_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837245d-8ab8-4729-b1a8-fd1d7c26d0d1",
   "metadata": {},
   "source": [
    "We inspect the misclassifications of this final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "323c4017-08e5-4ea8-938d-f501ccb69fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred label</th>\n",
       "      <th>true label</th>\n",
       "      <th>bench</th>\n",
       "      <th>query</th>\n",
       "      <th>orig/rewr(mean)</th>\n",
       "      <th>orig/rewr+rewr(mean)</th>\n",
       "      <th>orig mean</th>\n",
       "      <th>rewr mean</th>\n",
       "      <th>rewr mean+rewr</th>\n",
       "      <th>diff rewr-orig</th>\n",
       "      <th>...</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <th>balancedness factor</th>\n",
       "      <th>container counts list</th>\n",
       "      <th>branching factors list</th>\n",
       "      <th>hypergraph</th>\n",
       "      <th>text</th>\n",
       "      <th>orig/rewr/equal 0.5</th>\n",
       "      <th>orig/rewr/equal 0.1</th>\n",
       "      <th>orig/rewr/equal 0.05</th>\n",
       "      <th>orig/rewr/equal 0.01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>131-143-augF1-augA6</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.514398</td>\n",
       "      <td>0.614337</td>\n",
       "      <td>1.721684</td>\n",
       "      <td>0.099939</td>\n",
       "      <td>...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>106-084-augF1-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.444406</td>\n",
       "      <td>0.375596</td>\n",
       "      <td>2.261096</td>\n",
       "      <td>-0.068810</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, votes as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>112-028-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.744023</td>\n",
       "      <td>0.590712</td>\n",
       "      <td>2.486703</td>\n",
       "      <td>-0.153311</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=25, num_e=4)</td>\n",
       "      <td>SELECT MIN(p.id) FROM votes as v, posts as p, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>123-047-augF2-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>2.914643</td>\n",
       "      <td>0.386885</td>\n",
       "      <td>2.228317</td>\n",
       "      <td>-2.527758</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=32, num_e=5)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, posts as ...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>097-077-augF1-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.671410</td>\n",
       "      <td>0.595359</td>\n",
       "      <td>1.651878</td>\n",
       "      <td>-0.076052</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>133-052-augF2-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.509872</td>\n",
       "      <td>0.557117</td>\n",
       "      <td>1.660219</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(p.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>9-07-DuGcGpMF-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>1.923481</td>\n",
       "      <td>2.035968</td>\n",
       "      <td>3.998621</td>\n",
       "      <td>0.112487</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(g1.nid) FROM disease d, upregulates...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>JOB</td>\n",
       "      <td>20a-augF1-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>14.335614</td>\n",
       "      <td>13.860463</td>\n",
       "      <td>16.085109</td>\n",
       "      <td>-0.475151</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 4, 3]</td>\n",
       "      <td>Hypergraph(num_v=51, num_e=10)</td>\n",
       "      <td>SELECT MIN(cc.id) AS complete_downey_ironman_m...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>112-028-augF2-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.702430</td>\n",
       "      <td>0.592540</td>\n",
       "      <td>2.536817</td>\n",
       "      <td>-0.109891</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=25, num_e=4)</td>\n",
       "      <td>SELECT MIN(p.id) FROM votes as v, posts as p, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>022-125-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.212628</td>\n",
       "      <td>0.474945</td>\n",
       "      <td>1.429150</td>\n",
       "      <td>0.262317</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=4)</td>\n",
       "      <td>SELECT MIN(ph.Id) FROM postHistory as ph, vote...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>125-051-augF2-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.351449</td>\n",
       "      <td>0.412348</td>\n",
       "      <td>1.417049</td>\n",
       "      <td>0.060899</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, posts as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>142-135-augF1-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.480683</td>\n",
       "      <td>0.609105</td>\n",
       "      <td>2.508436</td>\n",
       "      <td>0.128422</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>JOB</td>\n",
       "      <td>2d-augF1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>10.806420</td>\n",
       "      <td>6.803201</td>\n",
       "      <td>8.809977</td>\n",
       "      <td>-4.003219</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 2, 1]</td>\n",
       "      <td>Hypergraph(num_v=30, num_e=5)</td>\n",
       "      <td>SELECT MIN(t.title) AS movie_title FROM compan...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>031-025-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.451071</td>\n",
       "      <td>0.385170</td>\n",
       "      <td>2.442815</td>\n",
       "      <td>-0.065901</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=26, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>112-028</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.596337</td>\n",
       "      <td>0.486450</td>\n",
       "      <td>2.383341</td>\n",
       "      <td>-0.109887</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=25, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.Id) FROM votes as v, posts as p, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-03-CbGiGaD2-augA3</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.521077</td>\n",
       "      <td>0.565190</td>\n",
       "      <td>2.491052</td>\n",
       "      <td>0.044113</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(i.sid) FROM compound c1, binds b1, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>7-01-DaGiGpBP-augF1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.401645</td>\n",
       "      <td>2.174763</td>\n",
       "      <td>4.124332</td>\n",
       "      <td>-0.226882</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(d.name) FROM disease d, associates ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>JOB</td>\n",
       "      <td>2c-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>6.076379</td>\n",
       "      <td>6.628287</td>\n",
       "      <td>8.948643</td>\n",
       "      <td>0.551908</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=30, num_e=5)</td>\n",
       "      <td>SELECT MIN(k.id) AS movie_title FROM company_n...</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>8-01-CCpGdCcSE-augA5</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.173825</td>\n",
       "      <td>2.086451</td>\n",
       "      <td>4.069379</td>\n",
       "      <td>-0.087374</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(ca.sid) FROM cellular_component cc,...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>JOB</td>\n",
       "      <td>2b-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>6.482365</td>\n",
       "      <td>7.103009</td>\n",
       "      <td>9.048851</td>\n",
       "      <td>0.620644</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=30, num_e=5)</td>\n",
       "      <td>SELECT MIN(k.id) AS movie_title FROM company_n...</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>JOB</td>\n",
       "      <td>2b</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>6.593898</td>\n",
       "      <td>6.488478</td>\n",
       "      <td>8.409934</td>\n",
       "      <td>-0.105421</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 2, 1]</td>\n",
       "      <td>Hypergraph(num_v=30, num_e=5)</td>\n",
       "      <td>SELECT MIN(t.title) AS movie_title FROM compan...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>138-107-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>5.236664</td>\n",
       "      <td>0.246144</td>\n",
       "      <td>1.353136</td>\n",
       "      <td>-4.990520</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=4)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, votes as ...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>7-01-DaGiGpBP-augA5</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.083080</td>\n",
       "      <td>2.034319</td>\n",
       "      <td>3.918282</td>\n",
       "      <td>-0.048761</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(p.sid) FROM disease d, associates a...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>135-136-augF1-augA3</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.101950</td>\n",
       "      <td>0.244749</td>\n",
       "      <td>2.497154</td>\n",
       "      <td>0.142799</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>125-051-augF2-augA3</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.374617</td>\n",
       "      <td>0.433815</td>\n",
       "      <td>1.426381</td>\n",
       "      <td>0.059198</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>102-002-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.323852</td>\n",
       "      <td>0.252281</td>\n",
       "      <td>1.373406</td>\n",
       "      <td>-0.071571</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 2]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Hypergraph(num_v=8, num_e=2)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, badges as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>093-075-augF1-augA5</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.509245</td>\n",
       "      <td>0.608235</td>\n",
       "      <td>2.506711</td>\n",
       "      <td>0.098989</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-17-CuGdCtD-augA5</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.597274</td>\n",
       "      <td>0.601660</td>\n",
       "      <td>2.567291</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(treats.sid) FROM compound c1, upreg...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-15-CtDuGdD</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.592155</td>\n",
       "      <td>0.623228</td>\n",
       "      <td>2.622500</td>\n",
       "      <td>0.031073</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(c1.nid) FROM compound c1, treats t,...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>2-02-CdGuD-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.537245</td>\n",
       "      <td>0.537814</td>\n",
       "      <td>2.490737</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(down.sid) FROM compound c, downregu...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>123-047-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>2.870160</td>\n",
       "      <td>0.402608</td>\n",
       "      <td>2.527320</td>\n",
       "      <td>-2.467551</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=32, num_e=5)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, posts as ...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>111-056</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.585661</td>\n",
       "      <td>0.521762</td>\n",
       "      <td>2.344305</td>\n",
       "      <td>-0.063899</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=28, num_e=5)</td>\n",
       "      <td>SELECT MIN(t.Id) FROM tags as t, posts as p, u...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>125-051-augF2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.375090</td>\n",
       "      <td>0.432785</td>\n",
       "      <td>1.441031</td>\n",
       "      <td>0.057696</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-08-CpDpCtD-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.170041</td>\n",
       "      <td>0.311214</td>\n",
       "      <td>2.191933</td>\n",
       "      <td>0.141174</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(p1.sid) FROM compound c1, palliates...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>9-08-DdGcGpMF-augA5</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>1.923045</td>\n",
       "      <td>2.026649</td>\n",
       "      <td>3.984608</td>\n",
       "      <td>0.103604</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(p.sid) FROM disease d, downregulate...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>040-101-augF2-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.521375</td>\n",
       "      <td>0.447288</td>\n",
       "      <td>2.342032</td>\n",
       "      <td>-0.074087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>022-125-augF2-augA3</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.211995</td>\n",
       "      <td>0.275285</td>\n",
       "      <td>1.308859</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=4)</td>\n",
       "      <td>SELECT MIN(b.id) FROM postHistory as ph, votes...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>019-130-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.525307</td>\n",
       "      <td>0.450182</td>\n",
       "      <td>2.387983</td>\n",
       "      <td>-0.075125</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=31, num_e=5)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, posts as...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>091-035-augF1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.290568</td>\n",
       "      <td>0.275750</td>\n",
       "      <td>2.253252</td>\n",
       "      <td>-0.014818</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=20, num_e=4)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, votes as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>133-052-augF2-augA3</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.470533</td>\n",
       "      <td>0.542690</td>\n",
       "      <td>1.581971</td>\n",
       "      <td>0.072157</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>045-046-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.580235</td>\n",
       "      <td>0.512736</td>\n",
       "      <td>2.471983</td>\n",
       "      <td>-0.067499</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=31, num_e=5)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>046-128-augF2-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.584494</td>\n",
       "      <td>0.524198</td>\n",
       "      <td>2.480509</td>\n",
       "      <td>-0.060296</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=31, num_e=5)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>112-028-augF2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.572517</td>\n",
       "      <td>0.456640</td>\n",
       "      <td>2.715186</td>\n",
       "      <td>-0.115877</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=25, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.Id) FROM votes as v, posts as p, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>JOB</td>\n",
       "      <td>2a-augF2-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>6.688609</td>\n",
       "      <td>7.077094</td>\n",
       "      <td>9.033088</td>\n",
       "      <td>0.388485</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>Hypergraph(num_v=30, num_e=5)</td>\n",
       "      <td>SELECT MIN(k.id) AS movie_title FROM company_n...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>123-047-augF1-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.091003</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>2.274842</td>\n",
       "      <td>0.333238</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=32, num_e=5)</td>\n",
       "      <td>SELECT MIN(p.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>117-114-augF1-augA3</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>3.549436</td>\n",
       "      <td>0.364973</td>\n",
       "      <td>1.556664</td>\n",
       "      <td>-3.184463</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Hypergraph(num_v=19, num_e=4)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, postHisto...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-13-CtDlAlD-augA5</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.323151</td>\n",
       "      <td>0.358594</td>\n",
       "      <td>2.341480</td>\n",
       "      <td>0.035443</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(l2.sid) FROM compound c1, treats t,...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>009-033-augF2-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>47.763357</td>\n",
       "      <td>0.431627</td>\n",
       "      <td>2.522775</td>\n",
       "      <td>-47.331729</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=22, num_e=4)</td>\n",
       "      <td>SELECT MIN(ph.id) FROM comments as c, postHist...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>115-144-augF2-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.583693</td>\n",
       "      <td>0.700194</td>\n",
       "      <td>1.708560</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>Hypergraph(num_v=35, num_e=6)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>2-01-CbGaD-augA3</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.245808</td>\n",
       "      <td>0.318594</td>\n",
       "      <td>2.458617</td>\n",
       "      <td>0.072786</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(a.sid) FROM compound c, binds b, ge...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>7-01-DaGiGpBP-augF2-augA1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>2.130950</td>\n",
       "      <td>2.200876</td>\n",
       "      <td>4.204264</td>\n",
       "      <td>0.069927</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(a.sid) FROM disease d, associates a...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>3-15-CtDuGdD-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.561352</td>\n",
       "      <td>0.591570</td>\n",
       "      <td>2.864515</td>\n",
       "      <td>0.030219</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(g.nid) FROM compound c1, treats t, ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>117-114-augF1-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>3.740351</td>\n",
       "      <td>0.370794</td>\n",
       "      <td>1.459710</td>\n",
       "      <td>-3.369557</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=19, num_e=4)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, postHisto...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>060-042-augF1-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.556196</td>\n",
       "      <td>0.551689</td>\n",
       "      <td>2.390185</td>\n",
       "      <td>-0.004507</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=27, num_e=4)</td>\n",
       "      <td>SELECT MIN(v.id) FROM postHistory as ph, posts...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>133-052-augF2-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.480860</td>\n",
       "      <td>0.540853</td>\n",
       "      <td>1.579660</td>\n",
       "      <td>0.059993</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>Hypergraph(num_v=29, num_e=5)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>google-tree01-augA4</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>8.658750</td>\n",
       "      <td>10.612904</td>\n",
       "      <td>-91.341250</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>Hypergraph(num_v=10, num_e=5)</td>\n",
       "      <td>SELECT MIN(p4b.fromnode) FROM google p1, googl...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>117-114-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.503430</td>\n",
       "      <td>0.372188</td>\n",
       "      <td>1.588319</td>\n",
       "      <td>-0.131242</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>Hypergraph(num_v=19, num_e=4)</td>\n",
       "      <td>SELECT MIN(b.id) FROM comments as c, postHisto...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>9-07-DuGcGpMF</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>1.921195</td>\n",
       "      <td>2.119223</td>\n",
       "      <td>4.095740</td>\n",
       "      <td>0.198028</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 3, 2]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(d.nid) FROM disease d, upregulates ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred label  true label  bench                      query  \\\n",
       "1653           1           0  STATS        131-143-augF1-augA6   \n",
       "1283           0           1  STATS        106-084-augF1-augA1   \n",
       "1359           0           1  STATS              112-028-augA1   \n",
       "1525           0           1  STATS        123-047-augF2-augA4   \n",
       "1198           0           1  STATS        097-077-augF1-augA4   \n",
       "1684           1           0  STATS        133-052-augF2-augA1   \n",
       "2692           1           0  HETIO        9-07-DuGcGpMF-augA2   \n",
       "2335           0           1    JOB            20a-augF1-augA1   \n",
       "1367           0           1  STATS        112-028-augF2-augA1   \n",
       "283            1           0  STATS              022-125-augF1   \n",
       "1556           1           0  STATS        125-051-augF2-augA2   \n",
       "1820           1           0  STATS        142-135-augF1-augA4   \n",
       "2170           0           1    JOB                   2d-augF1   \n",
       "382            0           1  STATS              031-025-augA3   \n",
       "1358           0           1  STATS                    112-028   \n",
       "2440           1           0  HETIO        3-03-CbGiGaD2-augA3   \n",
       "2613           0           1  HETIO        7-01-DaGiGpBP-augF1   \n",
       "2152           1           0    JOB                   2c-augA2   \n",
       "2632           0           1  HETIO       8-01-CCpGdCcSE-augA5   \n",
       "2137           1           0    JOB                   2b-augA2   \n",
       "2135           0           1    JOB                         2b   \n",
       "1760           0           1  STATS              138-107-augA3   \n",
       "2611           0           1  HETIO        7-01-DaGiGpBP-augA5   \n",
       "1708           1           0  STATS        135-136-augF1-augA3   \n",
       "1557           1           0  STATS        125-051-augF2-augA3   \n",
       "1247           0           1  STATS              102-002-augA1   \n",
       "1146           1           0  STATS        093-075-augF1-augA5   \n",
       "2540           1           0  HETIO         3-17-CuGdCtD-augA5   \n",
       "2521           1           0  HETIO               3-15-CtDuGdD   \n",
       "2404           1           0  HETIO           2-02-CdGuD-augA1   \n",
       "1515           0           1  STATS              123-047-augA4   \n",
       "1348           0           1  STATS                    111-056   \n",
       "1554           1           0  STATS              125-051-augF2   \n",
       "2473           1           0  HETIO         3-08-CpDpCtD-augA1   \n",
       "2702           1           0  HETIO        9-08-DdGcGpMF-augA5   \n",
       "488            0           1  STATS        040-101-augF2-augA2   \n",
       "290            1           0  STATS        022-125-augF2-augA3   \n",
       "248            0           1  STATS        019-130-augF1-augA3   \n",
       "1115           0           1  STATS              091-035-augF1   \n",
       "1686           1           0  STATS        133-052-augF2-augA3   \n",
       "554            0           1  STATS              045-046-augA4   \n",
       "579            0           1  STATS        046-128-augF2-augA4   \n",
       "1366           0           1  STATS              112-028-augF2   \n",
       "2132           1           0    JOB             2a-augF2-augA2   \n",
       "1517           1           0  STATS        123-047-augF1-augA1   \n",
       "1434           0           1  STATS        117-114-augF1-augA3   \n",
       "2512           1           0  HETIO         3-13-CtDlAlD-augA5   \n",
       "114            0           1  STATS        009-033-augF2-augA1   \n",
       "1413           1           0  STATS        115-144-augF2-augA4   \n",
       "2401           1           0  HETIO           2-01-CbGaD-augA3   \n",
       "2621           1           0  HETIO  7-01-DaGiGpBP-augF2-augA1   \n",
       "2525           1           0  HETIO         3-15-CtDuGdD-augA4   \n",
       "1433           0           1  STATS        117-114-augF1-augA2   \n",
       "736            0           1  STATS        060-042-augF1-augA2   \n",
       "1687           1           0  STATS        133-052-augF2-augA4   \n",
       "1983           0           1   SNAP        google-tree01-augA4   \n",
       "1429           0           1  STATS              117-114-augA2   \n",
       "2690           1           0  HETIO              9-07-DuGcGpMF   \n",
       "\n",
       "     orig/rewr(mean) orig/rewr+rewr(mean)   orig mean  rewr mean  \\\n",
       "1653            orig                 orig    0.514398   0.614337   \n",
       "1283            rewr                 orig    0.444406   0.375596   \n",
       "1359            rewr                 orig    0.744023   0.590712   \n",
       "1525            rewr                 rewr    2.914643   0.386885   \n",
       "1198            rewr                 orig    0.671410   0.595359   \n",
       "1684            orig                 orig    0.509872   0.557117   \n",
       "2692            orig                 orig    1.923481   2.035968   \n",
       "2335            rewr                 orig   14.335614  13.860463   \n",
       "1367            rewr                 orig    0.702430   0.592540   \n",
       "283             orig                 orig    0.212628   0.474945   \n",
       "1556            orig                 orig    0.351449   0.412348   \n",
       "1820            orig                 orig    0.480683   0.609105   \n",
       "2170            rewr                 rewr   10.806420   6.803201   \n",
       "382             rewr                 orig    0.451071   0.385170   \n",
       "1358            rewr                 orig    0.596337   0.486450   \n",
       "2440            orig                 orig    0.521077   0.565190   \n",
       "2613            rewr                 orig    2.401645   2.174763   \n",
       "2152            orig                 orig    6.076379   6.628287   \n",
       "2632            rewr                 orig    2.173825   2.086451   \n",
       "2137            orig                 orig    6.482365   7.103009   \n",
       "2135            rewr                 orig    6.593898   6.488478   \n",
       "1760            rewr                 rewr    5.236664   0.246144   \n",
       "2611            rewr                 orig    2.083080   2.034319   \n",
       "1708            orig                 orig    0.101950   0.244749   \n",
       "1557            orig                 orig    0.374617   0.433815   \n",
       "1247            rewr                 orig    0.323852   0.252281   \n",
       "1146            orig                 orig    0.509245   0.608235   \n",
       "2540            orig                 orig    0.597274   0.601660   \n",
       "2521            orig                 orig    0.592155   0.623228   \n",
       "2404            orig                 orig    0.537245   0.537814   \n",
       "1515            rewr                 rewr    2.870160   0.402608   \n",
       "1348            rewr                 orig    0.585661   0.521762   \n",
       "1554            orig                 orig    0.375090   0.432785   \n",
       "2473            orig                 orig    0.170041   0.311214   \n",
       "2702            orig                 orig    1.923045   2.026649   \n",
       "488             rewr                 orig    0.521375   0.447288   \n",
       "290             orig                 orig    0.211995   0.275285   \n",
       "248             rewr                 orig    0.525307   0.450182   \n",
       "1115            rewr                 orig    0.290568   0.275750   \n",
       "1686            orig                 orig    0.470533   0.542690   \n",
       "554             rewr                 orig    0.580235   0.512736   \n",
       "579             rewr                 orig    0.584494   0.524198   \n",
       "1366            rewr                 orig    0.572517   0.456640   \n",
       "2132            orig                 orig    6.688609   7.077094   \n",
       "1517            orig                 orig    0.091003   0.424242   \n",
       "1434            rewr                 rewr    3.549436   0.364973   \n",
       "2512            orig                 orig    0.323151   0.358594   \n",
       "114             rewr                 rewr   47.763357   0.431627   \n",
       "1413            orig                 orig    0.583693   0.700194   \n",
       "2401            orig                 orig    0.245808   0.318594   \n",
       "2621            orig                 orig    2.130950   2.200876   \n",
       "2525            orig                 orig    0.561352   0.591570   \n",
       "1433            rewr                 rewr    3.740351   0.370794   \n",
       "736             rewr                 orig    0.556196   0.551689   \n",
       "1687            orig                 orig    0.480860   0.540853   \n",
       "1983            rewr                 rewr  100.000000   8.658750   \n",
       "1429            rewr                 orig    0.503430   0.372188   \n",
       "2690            orig                 orig    1.921195   2.119223   \n",
       "\n",
       "      rewr mean+rewr  diff rewr-orig  ...  q75(branching factors)  \\\n",
       "1653        1.721684        0.099939  ...                    6.00   \n",
       "1283        2.261096       -0.068810  ...                    1.00   \n",
       "1359        2.486703       -0.153311  ...                    3.00   \n",
       "1525        2.228317       -2.527758  ...                    4.00   \n",
       "1198        1.651878       -0.076052  ...                    3.25   \n",
       "1684        1.660219        0.047244  ...                    4.00   \n",
       "2692        3.998621        0.112487  ...                    2.50   \n",
       "2335       16.085109       -0.475151  ...                    3.25   \n",
       "1367        2.536817       -0.109891  ...                    3.00   \n",
       "283         1.429150        0.262317  ...                    1.75   \n",
       "1556        1.417049        0.060899  ...                    2.50   \n",
       "1820        2.508436        0.128422  ...                    4.00   \n",
       "2170        8.809977       -4.003219  ...                    1.50   \n",
       "382         2.442815       -0.065901  ...                    1.75   \n",
       "1358        2.383341       -0.109887  ...                    1.75   \n",
       "2440        2.491052        0.044113  ...                    2.50   \n",
       "2613        4.124332       -0.226882  ...                    1.50   \n",
       "2152        8.948643        0.551908  ...                    2.50   \n",
       "2632        4.069379       -0.087374  ...                    2.50   \n",
       "2137        9.048851        0.620644  ...                    2.50   \n",
       "2135        8.409934       -0.105421  ...                    1.50   \n",
       "1760        1.353136       -4.990520  ...                    3.00   \n",
       "2611        3.918282       -0.048761  ...                    2.00   \n",
       "1708        2.497154        0.142799  ...                    2.50   \n",
       "1557        1.426381        0.059198  ...                    2.50   \n",
       "1247        1.373406       -0.071571  ...                    1.00   \n",
       "1146        2.506711        0.098989  ...                    5.00   \n",
       "2540        2.567291        0.004386  ...                    2.00   \n",
       "2521        2.622500        0.031073  ...                    2.50   \n",
       "2404        2.490737        0.000569  ...                    2.00   \n",
       "1515        2.527320       -2.467551  ...                    4.00   \n",
       "1348        2.344305       -0.063899  ...                    2.50   \n",
       "1554        1.441031        0.057696  ...                    2.50   \n",
       "2473        2.191933        0.141174  ...                    2.50   \n",
       "2702        3.984608        0.103604  ...                    2.50   \n",
       "488         2.342032       -0.074087  ...                    1.75   \n",
       "290         1.308859        0.063291  ...                    1.75   \n",
       "248         2.387983       -0.075125  ...                    2.50   \n",
       "1115        2.253252       -0.014818  ...                    1.75   \n",
       "1686        1.581971        0.072157  ...                    2.50   \n",
       "554         2.471983       -0.067499  ...                    2.50   \n",
       "579         2.480509       -0.060296  ...                    2.50   \n",
       "1366        2.715186       -0.115877  ...                    1.75   \n",
       "2132        9.033088        0.388485  ...                    2.00   \n",
       "1517        2.274842        0.333238  ...                    2.50   \n",
       "1434        1.556664       -3.184463  ...                    3.00   \n",
       "2512        2.341480        0.035443  ...                    2.50   \n",
       "114         2.522775      -47.331729  ...                    1.75   \n",
       "1413        1.708560        0.116500  ...                    3.25   \n",
       "2401        2.458617        0.072786  ...                    2.00   \n",
       "2621        4.204264        0.069927  ...                    2.50   \n",
       "2525        2.864515        0.030219  ...                    2.00   \n",
       "1433        1.459710       -3.369557  ...                    1.75   \n",
       "736         2.390185       -0.004507  ...                    1.75   \n",
       "1687        1.579660        0.059993  ...                    4.00   \n",
       "1983       10.612904      -91.341250  ...                    2.50   \n",
       "1429        1.588319       -0.131242  ...                    1.75   \n",
       "2690        4.095740        0.198028  ...                    2.50   \n",
       "\n",
       "      balancedness factor                              container counts list  \\\n",
       "1653             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1283                  NaN      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "1359             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1525             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1198             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1684             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2692             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2335             0.600000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1367             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "283              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1556             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1820             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2170             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "382              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1358             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2440             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2613             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2152             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2632             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2137             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2135             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1760             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2611             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1708             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1557             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1247                  NaN                              [1, 1, 1, 1, 1, 1, 2]   \n",
       "1146             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2540             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2521             0.625000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2404             0.666667                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "1515             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1348             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1554             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2473             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2702             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "488              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "290              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "248              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1115             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1686             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "554              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "579              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1366             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2132             0.666667  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1517             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1434             1.000000   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]   \n",
       "2512             0.625000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "114              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1413             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2401             0.666667                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "2621             0.666667                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2525             1.000000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "1433             1.000000   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]   \n",
       "736              1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1687             1.000000  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1983             1.000000                              [1, 1, 1, 1, 1, 2, 3]   \n",
       "1429             1.000000   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]   \n",
       "2690             0.625000                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "\n",
       "      branching factors list                      hypergraph  \\\n",
       "1653                     [6]   Hypergraph(num_v=40, num_e=7)   \n",
       "1283                  [1, 1]   Hypergraph(num_v=17, num_e=3)   \n",
       "1359                     [3]   Hypergraph(num_v=25, num_e=4)   \n",
       "1525                     [4]   Hypergraph(num_v=32, num_e=5)   \n",
       "1198                  [4, 1]   Hypergraph(num_v=35, num_e=6)   \n",
       "1684                     [4]   Hypergraph(num_v=29, num_e=5)   \n",
       "2692               [1, 2, 3]   Hypergraph(num_v=14, num_e=7)   \n",
       "2335            [1, 1, 4, 3]  Hypergraph(num_v=51, num_e=10)   \n",
       "1367                     [3]   Hypergraph(num_v=25, num_e=4)   \n",
       "283                   [2, 1]   Hypergraph(num_v=20, num_e=4)   \n",
       "1556                  [3, 1]   Hypergraph(num_v=29, num_e=5)   \n",
       "1820                     [4]   Hypergraph(num_v=29, num_e=5)   \n",
       "2170               [1, 2, 1]   Hypergraph(num_v=30, num_e=5)   \n",
       "382                   [2, 1]   Hypergraph(num_v=26, num_e=4)   \n",
       "1358                  [2, 1]   Hypergraph(num_v=25, num_e=4)   \n",
       "2440               [1, 1, 4]   Hypergraph(num_v=14, num_e=7)   \n",
       "2613            [1, 3, 1, 1]   Hypergraph(num_v=14, num_e=7)   \n",
       "2152                  [1, 3]   Hypergraph(num_v=30, num_e=5)   \n",
       "2632               [2, 1, 3]   Hypergraph(num_v=14, num_e=7)   \n",
       "2137                  [1, 3]   Hypergraph(num_v=30, num_e=5)   \n",
       "2135               [1, 2, 1]   Hypergraph(num_v=30, num_e=5)   \n",
       "1760                     [3]   Hypergraph(num_v=20, num_e=4)   \n",
       "2611               [2, 2, 2]   Hypergraph(num_v=14, num_e=7)   \n",
       "1708                  [3, 1]   Hypergraph(num_v=29, num_e=5)   \n",
       "1557                  [3, 1]   Hypergraph(num_v=29, num_e=5)   \n",
       "1247                     [1]    Hypergraph(num_v=8, num_e=2)   \n",
       "1146                     [5]   Hypergraph(num_v=35, num_e=6)   \n",
       "2540               [2, 2, 2]   Hypergraph(num_v=14, num_e=7)   \n",
       "2521               [1, 3, 2]   Hypergraph(num_v=14, num_e=7)   \n",
       "2404                  [2, 2]   Hypergraph(num_v=10, num_e=5)   \n",
       "1515                     [4]   Hypergraph(num_v=32, num_e=5)   \n",
       "1348                  [3, 1]   Hypergraph(num_v=28, num_e=5)   \n",
       "1554                  [3, 1]   Hypergraph(num_v=29, num_e=5)   \n",
       "2473               [2, 1, 3]   Hypergraph(num_v=14, num_e=7)   \n",
       "2702               [1, 1, 4]   Hypergraph(num_v=14, num_e=7)   \n",
       "488                   [2, 1]   Hypergraph(num_v=27, num_e=4)   \n",
       "290                   [2, 1]   Hypergraph(num_v=20, num_e=4)   \n",
       "248                   [3, 1]   Hypergraph(num_v=31, num_e=5)   \n",
       "1115                  [2, 1]   Hypergraph(num_v=20, num_e=4)   \n",
       "1686                  [3, 1]   Hypergraph(num_v=29, num_e=5)   \n",
       "554                   [3, 1]   Hypergraph(num_v=31, num_e=5)   \n",
       "579                   [3, 1]   Hypergraph(num_v=31, num_e=5)   \n",
       "1366                  [2, 1]   Hypergraph(num_v=25, num_e=4)   \n",
       "2132                  [2, 2]   Hypergraph(num_v=30, num_e=5)   \n",
       "1517                  [3, 1]   Hypergraph(num_v=32, num_e=5)   \n",
       "1434                     [3]   Hypergraph(num_v=19, num_e=4)   \n",
       "2512               [1, 3, 2]   Hypergraph(num_v=14, num_e=7)   \n",
       "114                   [2, 1]   Hypergraph(num_v=22, num_e=4)   \n",
       "1413                  [4, 1]   Hypergraph(num_v=35, num_e=6)   \n",
       "2401                  [2, 2]   Hypergraph(num_v=10, num_e=5)   \n",
       "2621               [2, 1, 3]   Hypergraph(num_v=14, num_e=7)   \n",
       "2525               [2, 2, 2]   Hypergraph(num_v=14, num_e=7)   \n",
       "1433                  [2, 1]   Hypergraph(num_v=19, num_e=4)   \n",
       "736                   [2, 1]   Hypergraph(num_v=27, num_e=4)   \n",
       "1687                     [4]   Hypergraph(num_v=29, num_e=5)   \n",
       "1983                  [1, 3]   Hypergraph(num_v=10, num_e=5)   \n",
       "1429                  [2, 1]   Hypergraph(num_v=19, num_e=4)   \n",
       "2690               [1, 3, 2]   Hypergraph(num_v=14, num_e=7)   \n",
       "\n",
       "                                                   text  orig/rewr/equal 0.5  \\\n",
       "1653  SELECT MIN(u.id) FROM comments as c, posts as ...                equal   \n",
       "1283  SELECT MIN(v.id) FROM comments as c, votes as ...                equal   \n",
       "1359  SELECT MIN(p.id) FROM votes as v, posts as p, ...                equal   \n",
       "1525  SELECT MIN(u.id) FROM comments as c, posts as ...                 rewr   \n",
       "1198  SELECT MIN(b.id) FROM comments as c, posts as ...                equal   \n",
       "1684  SELECT MIN(p.id) FROM comments as c, posts as ...                equal   \n",
       "2692  SELECT MIN(g1.nid) FROM disease d, upregulates...                equal   \n",
       "2335  SELECT MIN(cc.id) AS complete_downey_ironman_m...                equal   \n",
       "1367  SELECT MIN(p.id) FROM votes as v, posts as p, ...                equal   \n",
       "283   SELECT MIN(ph.Id) FROM postHistory as ph, vote...                equal   \n",
       "1556  SELECT MIN(ph.id) FROM comments as c, posts as...                equal   \n",
       "1820  SELECT MIN(u.id) FROM comments as c, posts as ...                equal   \n",
       "2170  SELECT MIN(t.title) AS movie_title FROM compan...                 rewr   \n",
       "382   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "1358  SELECT MIN(v.Id) FROM votes as v, posts as p, ...                equal   \n",
       "2440  SELECT MIN(i.sid) FROM compound c1, binds b1, ...                equal   \n",
       "2613  SELECT MIN(d.name) FROM disease d, associates ...                equal   \n",
       "2152  SELECT MIN(k.id) AS movie_title FROM company_n...                 orig   \n",
       "2632  SELECT MIN(ca.sid) FROM cellular_component cc,...                equal   \n",
       "2137  SELECT MIN(k.id) AS movie_title FROM company_n...                 orig   \n",
       "2135  SELECT MIN(t.title) AS movie_title FROM compan...                equal   \n",
       "1760  SELECT MIN(u.id) FROM comments as c, votes as ...                 rewr   \n",
       "2611  SELECT MIN(p.sid) FROM disease d, associates a...                equal   \n",
       "1708  SELECT MIN(b.id) FROM comments as c, posts as ...                equal   \n",
       "1557  SELECT MIN(b.id) FROM comments as c, posts as ...                equal   \n",
       "1247  SELECT MIN(b.id) FROM comments as c, badges as...                equal   \n",
       "1146  SELECT MIN(u.id) FROM comments as c, posts as ...                equal   \n",
       "2540  SELECT MIN(treats.sid) FROM compound c1, upreg...                equal   \n",
       "2521  SELECT MIN(c1.nid) FROM compound c1, treats t,...                equal   \n",
       "2404  SELECT MIN(down.sid) FROM compound c, downregu...                equal   \n",
       "1515  SELECT MIN(u.id) FROM comments as c, posts as ...                 rewr   \n",
       "1348  SELECT MIN(t.Id) FROM tags as t, posts as p, u...                equal   \n",
       "1554  SELECT MIN(c.Id) FROM comments as c, posts as ...                equal   \n",
       "2473  SELECT MIN(p1.sid) FROM compound c1, palliates...                equal   \n",
       "2702  SELECT MIN(p.sid) FROM disease d, downregulate...                equal   \n",
       "488   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "290   SELECT MIN(b.id) FROM postHistory as ph, votes...                equal   \n",
       "248   SELECT MIN(ph.id) FROM comments as c, posts as...                equal   \n",
       "1115  SELECT MIN(c.Id) FROM comments as c, votes as ...                equal   \n",
       "1686  SELECT MIN(b.id) FROM comments as c, posts as ...                equal   \n",
       "554   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "579   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "1366  SELECT MIN(v.Id) FROM votes as v, posts as p, ...                equal   \n",
       "2132  SELECT MIN(k.id) AS movie_title FROM company_n...                equal   \n",
       "1517  SELECT MIN(p.id) FROM comments as c, posts as ...                equal   \n",
       "1434  SELECT MIN(u.id) FROM comments as c, postHisto...                 rewr   \n",
       "2512  SELECT MIN(l2.sid) FROM compound c1, treats t,...                equal   \n",
       "114   SELECT MIN(ph.id) FROM comments as c, postHist...                 rewr   \n",
       "1413  SELECT MIN(b.id) FROM comments as c, posts as ...                equal   \n",
       "2401  SELECT MIN(a.sid) FROM compound c, binds b, ge...                equal   \n",
       "2621  SELECT MIN(a.sid) FROM disease d, associates a...                equal   \n",
       "2525  SELECT MIN(g.nid) FROM compound c1, treats t, ...                equal   \n",
       "1433  SELECT MIN(b.id) FROM comments as c, postHisto...                 rewr   \n",
       "736   SELECT MIN(v.id) FROM postHistory as ph, posts...                equal   \n",
       "1687  SELECT MIN(u.id) FROM comments as c, posts as ...                equal   \n",
       "1983  SELECT MIN(p4b.fromnode) FROM google p1, googl...                 rewr   \n",
       "1429  SELECT MIN(b.id) FROM comments as c, postHisto...                equal   \n",
       "2690  SELECT MIN(d.nid) FROM disease d, upregulates ...                equal   \n",
       "\n",
       "      orig/rewr/equal 0.1  orig/rewr/equal 0.05  orig/rewr/equal 0.01  \n",
       "1653                equal                  orig                  orig  \n",
       "1283                equal                  rewr                  rewr  \n",
       "1359                 rewr                  rewr                  rewr  \n",
       "1525                 rewr                  rewr                  rewr  \n",
       "1198                equal                  rewr                  rewr  \n",
       "1684                equal                 equal                  orig  \n",
       "2692                 orig                  orig                  orig  \n",
       "2335                 rewr                  rewr                  rewr  \n",
       "1367                 rewr                  rewr                  rewr  \n",
       "283                  orig                  orig                  orig  \n",
       "1556                equal                  orig                  orig  \n",
       "1820                 orig                  orig                  orig  \n",
       "2170                 rewr                  rewr                  rewr  \n",
       "382                 equal                  rewr                  rewr  \n",
       "1358                 rewr                  rewr                  rewr  \n",
       "2440                equal                 equal                  orig  \n",
       "2613                 rewr                  rewr                  rewr  \n",
       "2152                 orig                  orig                  orig  \n",
       "2632                equal                  rewr                  rewr  \n",
       "2137                 orig                  orig                  orig  \n",
       "2135                 rewr                  rewr                  rewr  \n",
       "1760                 rewr                  rewr                  rewr  \n",
       "2611                equal                 equal                  rewr  \n",
       "1708                 orig                  orig                  orig  \n",
       "1557                equal                  orig                  orig  \n",
       "1247                equal                  rewr                  rewr  \n",
       "1146                equal                  orig                  orig  \n",
       "2540                equal                 equal                 equal  \n",
       "2521                equal                 equal                  orig  \n",
       "2404                equal                 equal                 equal  \n",
       "1515                 rewr                  rewr                  rewr  \n",
       "1348                equal                  rewr                  rewr  \n",
       "1554                equal                  orig                  orig  \n",
       "2473                 orig                  orig                  orig  \n",
       "2702                 orig                  orig                  orig  \n",
       "488                 equal                  rewr                  rewr  \n",
       "290                 equal                  orig                  orig  \n",
       "248                 equal                  rewr                  rewr  \n",
       "1115                equal                 equal                  rewr  \n",
       "1686                equal                  orig                  orig  \n",
       "554                 equal                  rewr                  rewr  \n",
       "579                 equal                  rewr                  rewr  \n",
       "1366                 rewr                  rewr                  rewr  \n",
       "2132                 orig                  orig                  orig  \n",
       "1517                 orig                  orig                  orig  \n",
       "1434                 rewr                  rewr                  rewr  \n",
       "2512                equal                 equal                  orig  \n",
       "114                  rewr                  rewr                  rewr  \n",
       "1413                 orig                  orig                  orig  \n",
       "2401                equal                  orig                  orig  \n",
       "2621                equal                  orig                  orig  \n",
       "2525                equal                 equal                  orig  \n",
       "1433                 rewr                  rewr                  rewr  \n",
       "736                 equal                 equal                 equal  \n",
       "1687                equal                  orig                  orig  \n",
       "1983                 rewr                  rewr                  rewr  \n",
       "1429                 rewr                  rewr                  rewr  \n",
       "2690                 orig                  orig                  orig  \n",
       "\n",
       "[58 rows x 37 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass = df.loc[X_test.index]\n",
    "misclass.insert(0, 'true label', np.array(y1_test))\n",
    "misclass.insert(0, 'pred label', y1_pred_dec_tree)\n",
    "indices_not_equal = np.where(y1_test != y1_pred_dec_tree)[0]\n",
    "misclass = misclass.iloc[indices_not_equal]\n",
    "misclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ef3f402-fda4-4b8a-a597-eb343fe7fe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff_0 = misclass[misclass['pred label'] == 0]['diff rewr-orig']\n",
    "diff_1 = misclass[misclass['pred label'] == 1]['diff rewr-orig']\n",
    "\n",
    "# Plotting the histogram\n",
    "bins=list(range(-100, 101, 12))\n",
    "plt.hist([diff_0, diff_1], bins=bins, edgecolor='black', color=['lightsteelblue', 'orange'], label=['FN', 'FP'])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Time difference')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of distribution of misclassifications')\n",
    "plt.legend(title='')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ae41ca4-9103-4230-91b9-6809e1f88bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1098346/2236301608.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass_1[\"cut\"] = pd.cut(abs(misclass_1['diff rewr-orig']), bins=bins, labels=labels)\n",
      "/tmp/ipykernel_1098346/2236301608.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass_0[\"cut\"] = pd.cut(abs(misclass_0['diff rewr-orig']), bins=bins, labels=labels)\n",
      "/tmp/ipykernel_1098346/2236301608.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  table_1 = misclass_1.groupby('cut').size().reset_index(name='count_1')\n",
      "/tmp/ipykernel_1098346/2236301608.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  table_0 = misclass_0.groupby('cut').size().reset_index(name='count_0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cut</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>TO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cut  0.01  0.1   1  10  100  TO\n",
       "FP      2   15  12   0    0   0\n",
       "FN      1   12   8   6    2   0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 0.01, 0.1, 1, 10, 100, float('inf')]\n",
    "labels = ['0.01', '0.1', '1', '10', '100', 'TO']\n",
    "\n",
    "misclass_1 = misclass[misclass[\"pred label\"] == 1]\n",
    "misclass_0 = misclass[misclass[\"pred label\"] == 0]\n",
    "\n",
    "misclass_1[\"cut\"] = pd.cut(abs(misclass_1['diff rewr-orig']), bins=bins, labels=labels)\n",
    "misclass_0[\"cut\"] = pd.cut(abs(misclass_0['diff rewr-orig']), bins=bins, labels=labels)\n",
    "\n",
    "table_1 = misclass_1.groupby('cut').size().reset_index(name='count_1')\n",
    "table_0 = misclass_0.groupby('cut').size().reset_index(name='count_0')\n",
    "\n",
    "table = pd.merge(table_1, table_0, on='cut', how='outer')\n",
    "table = table.set_index('cut').T\n",
    "table.index = ['FP', 'FN']\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fea2ac-d78e-4c80-9d70-c2a1c42a273e",
   "metadata": {},
   "source": [
    "We perform the statistical tests here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a53fc55-b16f-4d5e-899a-5ffc2de3ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = df.loc[X_test.index]\n",
    "test_set.insert(0, 'true label', np.array(y1_test))\n",
    "test_set.insert(0, 'pred label', y1_pred_dec_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f60064af-4aec-4192-a052-4387253eba9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred label</th>\n",
       "      <th>true label</th>\n",
       "      <th>bench</th>\n",
       "      <th>query</th>\n",
       "      <th>orig/rewr(mean)</th>\n",
       "      <th>orig/rewr+rewr(mean)</th>\n",
       "      <th>orig mean</th>\n",
       "      <th>rewr mean</th>\n",
       "      <th>rewr mean+rewr</th>\n",
       "      <th>diff rewr-orig</th>\n",
       "      <th>...</th>\n",
       "      <th>balancedness factor</th>\n",
       "      <th>container counts list</th>\n",
       "      <th>branching factors list</th>\n",
       "      <th>hypergraph</th>\n",
       "      <th>text</th>\n",
       "      <th>orig/rewr/equal 0.5</th>\n",
       "      <th>orig/rewr/equal 0.1</th>\n",
       "      <th>orig/rewr/equal 0.05</th>\n",
       "      <th>orig/rewr/equal 0.01</th>\n",
       "      <th>pred mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>046-128-augF1-augA4</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.591848</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>2.668834</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>Hypergraph(num_v=31, num_e=5)</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.591848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>wiki-path07-augA2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>83.424965</td>\n",
       "      <td>85.298854</td>\n",
       "      <td>-16.575035</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=8)</td>\n",
       "      <td>select MIN(p3.fromnode) from wiki p1, wiki p2,...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>83.424965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>STATS</td>\n",
       "      <td>129-140-augF2</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.911721</td>\n",
       "      <td>0.755924</td>\n",
       "      <td>1.982493</td>\n",
       "      <td>-0.155797</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>0.755924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STATS</td>\n",
       "      <td>131-143-augF1-augA6</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.514398</td>\n",
       "      <td>0.614337</td>\n",
       "      <td>1.721684</td>\n",
       "      <td>0.099939</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>Hypergraph(num_v=40, num_e=7)</td>\n",
       "      <td>SELECT MIN(u.id) FROM comments as c, posts as ...</td>\n",
       "      <td>equal</td>\n",
       "      <td>equal</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.614337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>HETIO</td>\n",
       "      <td>9-03-DaGrGpMF-augA6</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>6.209357</td>\n",
       "      <td>1.834116</td>\n",
       "      <td>3.915546</td>\n",
       "      <td>-4.375241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=14, num_e=7)</td>\n",
       "      <td>SELECT MIN(mf.nid) FROM disease d, associates ...</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>rewr</td>\n",
       "      <td>1.834116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred label  true label  bench                query orig/rewr(mean)  \\\n",
       "574            0           0  STATS  046-128-augF1-augA4            orig   \n",
       "2086           1           1   SNAP    wiki-path07-augA2            rewr   \n",
       "1621           1           1  STATS        129-140-augF2            rewr   \n",
       "1653           1           0  STATS  131-143-augF1-augA6            orig   \n",
       "2668           1           1  HETIO  9-03-DaGrGpMF-augA6            rewr   \n",
       "\n",
       "     orig/rewr+rewr(mean)   orig mean  rewr mean  rewr mean+rewr  \\\n",
       "574                  orig    0.591848   0.604455        2.668834   \n",
       "2086                 rewr  100.000000  83.424965       85.298854   \n",
       "1621                 orig    0.911721   0.755924        1.982493   \n",
       "1653                 orig    0.514398   0.614337        1.721684   \n",
       "2668                 rewr    6.209357   1.834116        3.915546   \n",
       "\n",
       "      diff rewr-orig  ...  balancedness factor  \\\n",
       "574         0.012607  ...             1.000000   \n",
       "2086      -16.575035  ...             1.000000   \n",
       "1621       -0.155797  ...             1.000000   \n",
       "1653        0.099939  ...             1.000000   \n",
       "2668       -4.375241  ...             0.666667   \n",
       "\n",
       "                                  container counts list  \\\n",
       "574   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2086      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]   \n",
       "1621  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1653  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2668                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "\n",
       "      branching factors list                     hypergraph  \\\n",
       "574                   [3, 1]  Hypergraph(num_v=31, num_e=5)   \n",
       "2086      [1, 1, 1, 1, 1, 2]  Hypergraph(num_v=16, num_e=8)   \n",
       "1621                     [6]  Hypergraph(num_v=40, num_e=7)   \n",
       "1653                     [6]  Hypergraph(num_v=40, num_e=7)   \n",
       "2668               [2, 1, 3]  Hypergraph(num_v=14, num_e=7)   \n",
       "\n",
       "                                                   text  orig/rewr/equal 0.5  \\\n",
       "574   SELECT MIN(v.id) FROM comments as c, posts as ...                equal   \n",
       "2086  select MIN(p3.fromnode) from wiki p1, wiki p2,...                 rewr   \n",
       "1621  SELECT MIN(c.Id) FROM comments as c, posts as ...                equal   \n",
       "1653  SELECT MIN(u.id) FROM comments as c, posts as ...                equal   \n",
       "2668  SELECT MIN(mf.nid) FROM disease d, associates ...                 rewr   \n",
       "\n",
       "      orig/rewr/equal 0.1  orig/rewr/equal 0.05  orig/rewr/equal 0.01  \\\n",
       "574                 equal                 equal                  orig   \n",
       "2086                 rewr                  rewr                  rewr   \n",
       "1621                 rewr                  rewr                  rewr   \n",
       "1653                equal                  orig                  orig   \n",
       "2668                 rewr                  rewr                  rewr   \n",
       "\n",
       "      pred mean  \n",
       "574    0.591848  \n",
       "2086  83.424965  \n",
       "1621   0.755924  \n",
       "1653   0.614337  \n",
       "2668   1.834116  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['pred mean'] = np.where(test_set['pred label'] == 0, test_set['orig mean'], test_set['rewr mean'])\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6437e-b111-40aa-911a-e02ada5fb328",
   "metadata": {},
   "source": [
    "The Wilcoxon rank test is to compare medians (of dependent groups).  \n",
    "The Nullhypothesis is that the medians are equal. If the p-value is smaller than a chosen alpha value, we can reject the null and say that the median with only original runtimes is significantly different to the median of the chosen versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97a89505-e280-4e57-8c91-7b99fede6e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon statistic: 696.0\n",
      "P-value: 1.8638497960501474e-20\n"
     ]
    }
   ],
   "source": [
    "w_stat, p_val = stats.wilcoxon(test_set[\"orig mean\"], test_set[\"pred mean\"])\n",
    "\n",
    "print(f\"Wilcoxon statistic: {w_stat}\")\n",
    "print(f\"P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37186c8-800b-4033-9485-73505834f8bc",
   "metadata": {},
   "source": [
    "The paired sample t-test is to compare means (of dependent groups).  \n",
    "The Nullhypothesis is that the means are equal. If the p-value is smaller than a chosen alpha value, we can reject the null and say that the mean with only original runtimes is significantly different to the mean of the chosen versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1666d97c-1c8d-4420-a162-2de9337f5441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 7.0012538442327275\n",
      "P-value: 1.7362171226801174e-11\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_val = stats.ttest_rel(test_set[\"orig mean\"], test_set[\"pred mean\"])\n",
    "\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8457367-2f76-4c01-a8bf-f5fa326cc1a4",
   "metadata": {},
   "source": [
    "Finally, we inspect the decision tree as graphic and provide the feature importances (based on the Gini importance) for all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f49c685d-3729-4dc9-bc09-bc1bba9902d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#relations</th>\n",
       "      <th>#conditions</th>\n",
       "      <th>#filters</th>\n",
       "      <th>#joins</th>\n",
       "      <th>depth</th>\n",
       "      <th>min(container counts)</th>\n",
       "      <th>max(container counts)</th>\n",
       "      <th>mean(container counts)</th>\n",
       "      <th>q25(container counts)</th>\n",
       "      <th>median(container counts)</th>\n",
       "      <th>q75(container counts)</th>\n",
       "      <th>min(branching factors)</th>\n",
       "      <th>max(branching factors)</th>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <th>median(branching factors)</th>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Importance</th>\n",
       "      <td>0.063368</td>\n",
       "      <td>0.120211</td>\n",
       "      <td>0.393823</td>\n",
       "      <td>0.044418</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061582</td>\n",
       "      <td>0.270023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.018918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            #relations  #conditions  #filters    #joins     depth  \\\n",
       "Importance    0.063368     0.120211  0.393823  0.044418  0.004182   \n",
       "\n",
       "            min(container counts)  max(container counts)  \\\n",
       "Importance                    0.0               0.061582   \n",
       "\n",
       "            mean(container counts)  q25(container counts)  \\\n",
       "Importance                0.270023                    0.0   \n",
       "\n",
       "            median(container counts)  q75(container counts)  \\\n",
       "Importance                       0.0                    0.0   \n",
       "\n",
       "            min(branching factors)  max(branching factors)  \\\n",
       "Importance                0.003849                0.003813   \n",
       "\n",
       "            mean(branching factors)  median(branching factors)  \\\n",
       "Importance                 0.001634                   0.010049   \n",
       "\n",
       "            q25(branching factors)  q75(branching factors)  \n",
       "Importance                0.004131                0.018918  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = X.columns.tolist()\n",
    "feature_importances = clf.feature_importances_\n",
    "df_importances = pd.DataFrame(data=feature_importances, index=feature_names, columns=[\"Importance\"])\n",
    "df_importances.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fa03f4e-5a4b-4f91-b36e-784643327049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#relations</th>\n",
       "      <td>0.063368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#conditions</th>\n",
       "      <td>0.120211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#filters</th>\n",
       "      <td>0.393823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#joins</th>\n",
       "      <td>0.044418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depth</th>\n",
       "      <td>0.004182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min(container counts)</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max(container counts)</th>\n",
       "      <td>0.061582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean(container counts)</th>\n",
       "      <td>0.270023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q25(container counts)</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median(container counts)</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q75(container counts)</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min(branching factors)</th>\n",
       "      <td>0.003849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max(branching factors)</th>\n",
       "      <td>0.003813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <td>0.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median(branching factors)</th>\n",
       "      <td>0.010049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <td>0.004131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <td>0.018918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Importance\n",
       "#relations                   0.063368\n",
       "#conditions                  0.120211\n",
       "#filters                     0.393823\n",
       "#joins                       0.044418\n",
       "depth                        0.004182\n",
       "min(container counts)        0.000000\n",
       "max(container counts)        0.061582\n",
       "mean(container counts)       0.270023\n",
       "q25(container counts)        0.000000\n",
       "median(container counts)     0.000000\n",
       "q75(container counts)        0.000000\n",
       "min(branching factors)       0.003849\n",
       "max(branching factors)       0.003813\n",
       "mean(branching factors)      0.001634\n",
       "median(branching factors)    0.010049\n",
       "q25(branching factors)       0.004131\n",
       "q75(branching factors)       0.018918"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ab1a1b8-6bb0-429c-af1b-52d59ded99ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9cb10533-7197-4462-a861-71c572130e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))  # Customize the size as needed\n",
    "plot_tree(clf, filled=True, feature_names=X_train.columns, class_names=[\"0\",\"1\"], rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77b9593-8f4d-4f94-8749-ad078a8d8f99",
   "metadata": {},
   "source": [
    "Plots of the distribution of the orders of magnitude for the final model on the test set in comparison to the original and rewritten plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77c71eb2-cdba-4465-9398-b584bac66584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1422/3989257457.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_orig = test_set.groupby(['interval orig', 'bench']).size().unstack(fill_value=0)\n",
      "/tmp/ipykernel_1422/3989257457.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_rewr = test_set.groupby(['interval rewr', 'bench']).size().unstack(fill_value=0)\n",
      "/tmp/ipykernel_1422/3989257457.py:12: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_pred = test_set.groupby(['interval pred', 'bench']).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set[\"orig mean\"] = test_set['orig mean'].astype(\"float64\")\n",
    "test_set[\"rewr mean\"] = test_set['rewr mean'].astype(\"float64\")\n",
    "test_set[\"pred mean\"] = test_set['pred mean'].astype(\"float64\")\n",
    "bins = [0, 0.01, 0.1, 1, 10, 99.99, float('inf')]\n",
    "labels = ['0.01', '0.1', '1', '10', '100', 'TO']\n",
    "test_set['interval orig'] = pd.cut(test_set['orig mean'], bins=bins, labels=labels)\n",
    "test_set['interval rewr'] = pd.cut(test_set['rewr mean'], bins=bins, labels=labels)\n",
    "test_set['interval pred'] = pd.cut(test_set['pred mean'], bins=bins, labels=labels)\n",
    "\n",
    "grouped_orig = test_set.groupby(['interval orig', 'bench']).size().unstack(fill_value=0)\n",
    "grouped_rewr = test_set.groupby(['interval rewr', 'bench']).size().unstack(fill_value=0)\n",
    "grouped_pred = test_set.groupby(['interval pred', 'bench']).size().unstack(fill_value=0)\n",
    "\n",
    "paired_colors = [\n",
    "    '#a6cee3', '#1f78b4', '#b2df8a', '#33a02c',\n",
    "    '#fb9a99', '#e31a1c', '#fdbf6f', '#ff7f00',\n",
    "    '#cab2d6', '#6a3d9a', '#ffff99', '#b15928'\n",
    "]\n",
    "\n",
    "category_colors = {\n",
    "    'HETIO': paired_colors[3],\n",
    "    'JOB': paired_colors[2],\n",
    "    'LSQB': paired_colors[1],\n",
    "    'SNAP': paired_colors[8],\n",
    "    'STATS': paired_colors[0]\n",
    "}\n",
    "\n",
    "colors = [category_colors[col] for col in grouped_orig.columns]\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Plot for 'orig mean'\n",
    "grouped_orig.plot(kind='barh', stacked=True, color=colors, ax=ax1)\n",
    "ax1.set_xlim(0,250)\n",
    "ax1.set_xlabel('Count', fontsize=14)  # Increase font size for x-axis label\n",
    "ax1.set_ylabel('Order of magnitude', fontsize=14)  # Increase font size for y-axis label\n",
    "ax1.set_title('Distribution of runtimes of original queries', fontsize=16)  # Increase font size for title\n",
    "ax1.legend(title='Benchmark', fontsize=14)  # Increase font size for legend\n",
    "ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# Plot for 'rewr mean'\n",
    "grouped_rewr.plot(kind='barh', stacked=True, color=colors, ax=ax2)\n",
    "ax2.set_xlabel('Count', fontsize=14)\n",
    "ax2.set_ylabel('Order of magnitude', fontsize=14)\n",
    "ax2.set_title('Distribution of runtimes of rewritten queries', fontsize=16)\n",
    "ax2.legend(title='Benchmark', fontsize=14)  \n",
    "ax2.set_xlim(0,250)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# Plot for 'pred mean'\n",
    "grouped_pred.plot(kind='barh', stacked=True, color=colors, ax=ax3)\n",
    "ax3.set_xlabel('Count', fontsize=14)\n",
    "ax3.set_ylabel('Order of magnitude', fontsize=14)\n",
    "ax3.set_title('Distribution of runtimes of queries with decision', fontsize=16)\n",
    "ax3.legend(title='Benchmark', fontsize=14)  \n",
    "ax3.set_xlim(0,250)\n",
    "ax3.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17d038d0-207a-4bec-9d6d-97aebab5176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set[\"orig mean\"] = test_set['orig mean'].astype(\"float64\")\n",
    "test_set[\"rewr mean\"] = test_set['rewr mean'].astype(\"float64\")\n",
    "test_set[\"pred mean\"] = test_set['pred mean'].astype(\"float64\")\n",
    "bins = [0, 0.01, 0.1, 1, 10, 99.99, float('inf')]\n",
    "labels = ['0.01', '0.1', '1', '10', '100', 'TO']\n",
    "test_set['interval orig'] = pd.cut(test_set['orig mean'], bins=bins, labels=labels)\n",
    "test_set['interval rewr'] = pd.cut(test_set['rewr mean'], bins=bins, labels=labels)\n",
    "test_set['interval pred'] = pd.cut(test_set['pred mean'], bins=bins, labels=labels)\n",
    "\n",
    "grouped_orig = test_set['interval orig'].value_counts().sort_index()\n",
    "grouped_rewr = test_set['interval rewr'].value_counts().sort_index()\n",
    "grouped_pred = test_set['interval pred'].value_counts().sort_index()\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Plot for 'orig mean'\n",
    "grouped_orig.plot(kind='barh', stacked=True, ax=ax1)\n",
    "ax1.set_xlim(0,250)\n",
    "ax1.set_xlabel('Count', fontsize=14)  # Increase font size for x-axis label\n",
    "ax1.set_ylabel('Order of magnitude', fontsize=14)  # Increase font size for y-axis label\n",
    "ax1.set_title('Distribution of runtimes of original queries', fontsize=16)  # Increase font size for title\n",
    "ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# Plot for 'rewr mean'\n",
    "grouped_rewr.plot(kind='barh', stacked=True, ax=ax2)\n",
    "ax2.set_xlabel('Count', fontsize=14)\n",
    "ax2.set_ylabel('Order of magnitude', fontsize=14)\n",
    "ax2.set_title('Distribution of runtimes of rewritten queries', fontsize=16)\n",
    "ax2.set_xlim(0,250)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# Plot for 'pred mean'\n",
    "grouped_pred.plot(kind='barh', stacked=True, ax=ax3)\n",
    "ax3.set_xlabel('Count', fontsize=14)\n",
    "ax3.set_ylabel('Order of magnitude', fontsize=14)\n",
    "ax3.set_title('Distribution of runtimes of queries with decision', fontsize=16)\n",
    "ax3.set_xlim(0,250)\n",
    "ax3.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
