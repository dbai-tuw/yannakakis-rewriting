{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19cbf1d8-de7f-4b5b-b13c-4f92a846298f",
   "metadata": {},
   "source": [
    "# Get all features together with the evaluation times for all queries (SparkSQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfaa467-7734-447b-bf41-1238d0f68c63",
   "metadata": {},
   "source": [
    "Features based on the query:   \n",
    "*  number of relations\n",
    "*  number of conditions\n",
    "*  number of filters\n",
    "*  number of joins\n",
    "\n",
    "Features based on the join tree:\n",
    "*  depth\n",
    "*  container count (min, max, mean, median, q1, q3)\n",
    "*  branching factors (min, max, mean, median, q1, q3)\n",
    "*  balancedness factor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4fd341-9bd9-4d8e-b22f-f27949dc1c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.3 in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.3) (2.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.3) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.3) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary==2.9.9 in /usr/local/lib/python3.10/dist-packages (2.9.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install pandas==2.2.3\n",
    "pip install psycopg2-binary==2.9.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb971097-ee96-48f8-ae56-ef8d2ceb2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db751e9-7b01-48d3-b378-beb7838bb418",
   "metadata": {},
   "source": [
    "### Get the features based on the structure of the query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e4e0be-b09f-40ac-be0b-f83d7603b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31896a16-44ae-4fef-b82e-b78a808a22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output file paths\n",
    "input_file = 'scala_commands_augment_full_enum.txt'\n",
    "output_file = 'results/featuresDatabase_SPA_full_enum.csv'\n",
    "\n",
    "# Open input and output files\n",
    "with open(input_file, 'r') as f_input, open(output_file, 'w', newline='') as f_output:\n",
    "    csv_writer = csv.writer(f_output)\n",
    "    \n",
    "    # Write header to CSV file\n",
    "    csv_writer.writerow(['bench', 'query', '#relations', '#conditions', '#filters', '#joins', 'text'])\n",
    "    \n",
    "    # Read input file line by line\n",
    "    for line in f_input:\n",
    "        # Split each line into components\n",
    "        pattern = r'(?<!\\\\)\\\"|\\\"(?<!\\\\)(?=\\s+\\\"|$)'\n",
    "        components = re.split(pattern, line)\n",
    "        \n",
    "        # Extract relevant information\n",
    "        benchmark = components[3]\n",
    "        number = components[5]\n",
    "        query = components[1].strip()\n",
    "\n",
    "        # FEATURES BASED ON QUERY STRUCTURE\n",
    "        # get the number of relations\n",
    "        query_upper = query.upper()\n",
    "        from_index = query_upper.find(\"FROM\")\n",
    "        where_index = query_upper.find(\"WHERE\")\n",
    "        number_of_relations = query[from_index:where_index].count(\",\") + 1\n",
    "\n",
    "        # get the number of conditions\n",
    "        number_of_conditions = query.count(\"AND\") + 1\n",
    "\n",
    "        # get how many filter and join conditions\n",
    "        parts = query_upper.split(\"WHERE\")[1].split(\"AND\")\n",
    "        filter = 0\n",
    "        join = 0\n",
    "        joins = []\n",
    "        for p in parts:\n",
    "            partners = []\n",
    "            p_split = p.split(\"=\")\n",
    "            if len(p_split) == 2 and p_split[1].count(\"'\") == 0 and p_split[1].count('\"') == 0 and is_number(p_split[1].strip()) == False:\n",
    "                partners = [p2.strip().split(\".\")[0] for p2 in p.split(\"=\")]\n",
    "                if partners not in joins and list(reversed(partners)) not in joins:\n",
    "                    joins.append(partners)\n",
    "                    join += 1\n",
    "            else:\n",
    "                filter += 1\n",
    "                \n",
    "        # Write data to CSV file\n",
    "        csv_writer.writerow([benchmark, number, number_of_relations, number_of_conditions, filter, join, query])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42371ab7-d2dc-4a0c-b995-92a170de5af8",
   "metadata": {},
   "source": [
    "### Get the features based on the join tree structure (calculated in Scala, imported and formated here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce9ecb0d-050c-404c-bfd6-f3274e55d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'results/featuresScala_SPA_full_enum.csv'\n",
    "csv_header = [\"bench\", \"query\", \"depth\", \"min(container counts)\", \"max(container counts)\", \"mean(container counts)\", \"q25(container counts)\",\n",
    "              \"median(container counts)\", \"q75(container counts)\", \"min(branching factors)\", \"max(branching factors)\", \"mean(branching factors)\", \n",
    "              \"median(branching factors)\", \"q25(branching factors)\", \"q75(branching factors)\", \"balancedness factor\", \"container counts list\", \n",
    "              \"branching factors list\"]\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(csv_header)\n",
    "\n",
    "    directory = 'output/'\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"output.json\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            benchmark = filename.split(\"_\")[0]\n",
    "            number = filename.split(\"_\")[1]\n",
    "            with open(filepath, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                # FEATURES BASED ON THE JOIN TREE STRUCTURE\n",
    "                feature = data.get(\"features\", [])\n",
    "                features = feature.split(\"List(\")\n",
    "                depth = int(features[1][:-2])\n",
    "                container_counts = [int(x) for x in features[2][:-3].split(\", \")]\n",
    "                container_counts_min = np.min(container_counts)\n",
    "                container_counts_max = np.max(container_counts)\n",
    "                container_counts_mean = np.mean(container_counts)\n",
    "                container_counts_median = np.median(container_counts)\n",
    "                container_counts_q25 = np.quantile(container_counts, 0.25)\n",
    "                container_counts_q75 = np.quantile(container_counts, 0.75)\n",
    "                branching_factors = [int(x) for x in features[3].split(\"), \")[0].split(\", \")]\n",
    "                branching_factors_min = np.min(branching_factors)\n",
    "                branching_factors_max = np.max(branching_factors)\n",
    "                branching_factors_mean = np.mean(branching_factors)\n",
    "                branching_factors_median = np.median(branching_factors)\n",
    "                branching_factors_q25 = np.quantile(branching_factors, 0.25)\n",
    "                branching_factors_q75 = np.quantile(branching_factors, 0.75)\n",
    "                balancedness_factor = float(features[3].split(\"), \")[1][:-1])\n",
    "\n",
    "                # Write data to CSV file\n",
    "                csv_row = [benchmark, number, depth, container_counts_min, container_counts_max, container_counts_mean, container_counts_q25,\n",
    "                           container_counts_median, container_counts_q75, branching_factors_min, branching_factors_max, branching_factors_mean,\n",
    "                           branching_factors_median, branching_factors_q25, branching_factors_q75, balancedness_factor, container_counts, \n",
    "                           branching_factors]\n",
    "                writer.writerow(csv_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150916d8-d9b5-44dc-aa0a-2b9f5a820036",
   "metadata": {},
   "source": [
    "### Merge features and evaluation times for each query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea468490-09ca-4d6a-ae85-61860594f3f6",
   "metadata": {},
   "source": [
    "1. Merge features of the query structure and the join tree with the evaluation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da88139b-4925-4f2a-8f21-f6df2ffbc9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/featuresDatabase_SPA_full_enum.csv')\n",
    "df2 = pd.read_csv('results/featuresScala_SPA_full_enum.csv')\n",
    "df4 = pd.read_csv('results/SPA_Scala_comparison_TO_augment_server_full_enum_infos.csv')\n",
    "df2[\"bench\"] = df2[\"bench\"].replace(\"IMDB\", \"JOB\")\n",
    "\n",
    "merged_df = pd.merge(df1, df2, on=[\"bench\", \"query\"], how='inner').merge(df4, on=[\"bench\", \"query\"], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a63b91-4f61-4d12-842c-4f53d749c3ca",
   "metadata": {},
   "source": [
    "2. Merge features of the query structure, the join tree and the PostgreSQL EXPLAIN with the evaluation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f4d9152-b152-4441-ac13-4d16914c064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0_extra = pd.read_csv('results/featuresDatabase_POS_extra_full_enum.csv')\n",
    "df0_extra = df0_extra[['bench', 'query', 'total cost', 'min(table rows)', 'max(table rows)', 'mean(table rows)', 'q25(table rows)', \n",
    "                       'median(table rows)', 'q75(table rows)', 'min(join rows)', 'max(join rows)', 'mean(join rows)', 'q25(join rows)', \n",
    "                       'median(join rows)', 'q75(join rows)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e385f073-0356-4fec-a4db-7027639931d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_extra = pd.read_csv('results/featuresDatabase_SPA_full_enum.csv')\n",
    "df2_extra = pd.read_csv('results/featuresScala_SPA_full_enum.csv')\n",
    "df4_extra = pd.read_csv('results/POS_Scala_comparison_TO_augment_server_full_enum_infos.csv')\n",
    "df2_extra[\"bench\"] = df2_extra[\"bench\"].replace(\"IMDB\", \"JOB\")\n",
    "\n",
    "merged_df_extra = pd.merge(pd.merge(df1_extra, df0_extra, on=[\"bench\", \"query\"], how='inner'), df2_extra, on=[\"bench\", \"query\"], how='inner').merge(df4_extra, on=[\"bench\", \"query\"], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b65b7-e81b-4e07-b676-054f4767a153",
   "metadata": {},
   "source": [
    "### Save the resulting dataframes as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13d5607f-16bc-4238-a728-3c15fbc9973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[[\"bench\", \"query\", \"orig/rewr(med)\", \"orig(med)\", \"rewr(med)\", \"stage0(med)\", \"stage1(med)\", \"stage2(med)\", \"stage3(med)\", \n",
    "           \"#relations\", \"#conditions\", \"#filters\", \"#joins\", \"depth\", \"min(container counts)\", \"max(container counts)\", \n",
    "           \"mean(container counts)\", \"q25(container counts)\", \"median(container counts)\", \"q75(container counts)\", \"min(branching factors)\", \n",
    "           \"max(branching factors)\", \"mean(branching factors)\",  \"median(branching factors)\", \"q25(branching factors)\", \"q75(branching factors)\", \n",
    "           \"balancedness factor\", \"container counts list\", \"branching factors list\", \"text\"]].to_csv('results/features_times_SPA_full_enum_infos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202fe4db-4faa-48f6-85f9-20567a6ec876",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_extra[[\"bench\", \"query\", \"orig/rewr(med)\", \"orig(med)\", \"rewr(med)\", \"stage0(med)\", \"stage1(med)\", \"stage2(med)\", \"stage3(med)\", \n",
    "           \"#relations\", \"#conditions\", \"#filters\", \"#joins\", 'total cost','min(table rows)',\n",
    "           'max(table rows)', 'mean(table rows)', 'q25(table rows)', 'median(table rows)', 'q75(table rows)', 'min(join rows)', 'max(join rows)', \n",
    "           'mean(join rows)', 'q25(join rows)', 'median(join rows)', 'q75(join rows)', \"depth\", \"min(container counts)\", \"max(container counts)\", \n",
    "           \"mean(container counts)\", \"q25(container counts)\", \"median(container counts)\", \"q75(container counts)\", \"min(branching factors)\", \n",
    "           \"max(branching factors)\", \"mean(branching factors)\",  \"median(branching factors)\", \"q25(branching factors)\", \"q75(branching factors)\", \n",
    "           \"balancedness factor\",\"container counts list\", \"branching factors list\", \n",
    "           \"text\"]].to_csv('results/features_times_SPA_extra_full_enum_infos.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440254c6-fb7c-44fd-b9fd-b7763d776a3e",
   "metadata": {},
   "source": [
    "## The same for the 0MA data with additional stage infos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332fe1eb-715c-4a43-9bae-eb0917736977",
   "metadata": {},
   "source": [
    "### Merge features and evaluation times for each query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8133166-6007-40f3-9103-c0fe32831a94",
   "metadata": {},
   "source": [
    "1. Merge features of the query structure and the join tree with the evaluation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c569632-145c-41f5-b286-eb598d636e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/featuresDatabase_SPA.csv')\n",
    "df2 = pd.read_csv('results/featuresScala_SPA.csv')\n",
    "df3 = pd.read_csv('results/featuresHypergraph_SPA.csv')\n",
    "df4 = pd.read_csv('results/SPA_Scala_comparison_TO_augment_server_infos.csv')\n",
    "\n",
    "merged_df = pd.merge(df1, df2, on=[\"bench\", \"query\"], how='inner').merge(df3, on=[\"bench\", \"query\"], how='inner')\\\n",
    "                .merge(df4, on=[\"bench\", \"query\"], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420ff10d-a94c-491c-9202-ee40a90b37b6",
   "metadata": {},
   "source": [
    "2. Merge features of the query structure, the join tree and the PostgreSQL EXPLAIN with the evaluation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1fc7a5-c510-4b44-865c-b50a7750981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0_extra = pd.read_csv('results/featuresDatabase_POS_extra.csv')\n",
    "df0_extra = df0_extra[['bench', 'query', 'total cost', 'min(table rows)', 'max(table rows)', 'mean(table rows)', 'q25(table rows)', \n",
    "                       'median(table rows)', 'q75(table rows)', 'min(join rows)', 'max(join rows)', 'mean(join rows)', 'q25(join rows)', \n",
    "                       'median(join rows)', 'q75(join rows)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ef72f88-59cc-472a-b572-96bb4124763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_extra = pd.read_csv('results/featuresDatabase_SPA.csv')\n",
    "df2_extra = pd.read_csv('results/featuresScala_SPA.csv')\n",
    "df4_extra = pd.read_csv('results/POS_Scala_comparison_TO_augment_server_infos.csv')\n",
    "df2_extra[\"bench\"] = df2_extra[\"bench\"].replace(\"IMDB\", \"JOB\")\n",
    "\n",
    "merged_df_extra = pd.merge(pd.merge(df1_extra, df0_extra, on=[\"bench\", \"query\"], how='inner'), df2_extra, on=[\"bench\", \"query\"], how='inner').merge(df4_extra, on=[\"bench\", \"query\"], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c8e9c-9df0-4687-b2f3-a8206fd7ed24",
   "metadata": {},
   "source": [
    "### Save the resulting dataframes as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29504c6e-1093-42e8-8eb6-e60268e88e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[[\"bench\", \"query\", \"orig/rewr(med)\", \"orig(med)\", \"rewr(med)\", \"stage0(med)\", \"stage1(med)\", \n",
    "           \"#relations\", \"#conditions\", \"#filters\", \"#joins\", \"depth\", \"min(container counts)\", \"max(container counts)\", \n",
    "           \"mean(container counts)\", \"q25(container counts)\", \"median(container counts)\", \"q75(container counts)\", \"min(branching factors)\", \n",
    "           \"max(branching factors)\", \"mean(branching factors)\",  \"median(branching factors)\", \"q25(branching factors)\", \"q75(branching factors)\", \n",
    "           \"balancedness factor\", \"container counts list\", \"branching factors list\", \"text\"]].to_csv('results/features_times_SPA_infos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d85db1-1c12-481d-9939-7ee2e86c82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_extra[[\"bench\", \"query\", \"orig/rewr(med)\", \"orig(med)\", \"rewr(med)\", \"stage0(med)\", \"stage1(med)\",\n",
    "           \"#relations\", \"#conditions\", \"#filters\", \"#joins\", 'total cost','min(table rows)',\n",
    "           'max(table rows)', 'mean(table rows)', 'q25(table rows)', 'median(table rows)', 'q75(table rows)', 'min(join rows)', 'max(join rows)', \n",
    "           'mean(join rows)', 'q25(join rows)', 'median(join rows)', 'q75(join rows)', \"depth\", \"min(container counts)\", \"max(container counts)\", \n",
    "           \"mean(container counts)\", \"q25(container counts)\", \"median(container counts)\", \"q75(container counts)\", \"min(branching factors)\", \n",
    "           \"max(branching factors)\", \"mean(branching factors)\",  \"median(branching factors)\", \"q25(branching factors)\", \"q75(branching factors)\", \n",
    "           \"balancedness factor\",\"container counts list\", \"branching factors list\", \n",
    "           \"text\"]].to_csv('results/features_times_SPA_extra_infos.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
