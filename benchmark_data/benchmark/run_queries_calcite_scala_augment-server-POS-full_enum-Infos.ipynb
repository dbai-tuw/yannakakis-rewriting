{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e4175a-8e11-4ab2-b5f2-af33b04201ab",
   "metadata": {},
   "source": [
    "# Running queries using JSONS produced by Scala code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe4fae-04cc-4b9c-beb7-510662a4660d",
   "metadata": {},
   "source": [
    "Install and import all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2fa7d7-3b51-416f-b221-1369637b4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install psycopg2-binary\n",
    "pip install numpy\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6645fd-f261-4197-ab65-bac11ae4cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import csv\n",
    "import multiprocessing\n",
    "import signal\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c950d3-619f-4c9c-9eac-0853eb8242d4",
   "metadata": {},
   "source": [
    "Function for running one query. This means\n",
    "*  run the original query 5 times (after one initial run, which we do not use)\n",
    "*  run the rewritten queries 5 times (after one initial run, which we do not use) and drop the created tables each time\n",
    "*  take the runtimes and calculate mean, median and standard deviation of time for either the original or rewritten query\n",
    "*  additionaly save the runtimes for each stage\n",
    "*  save everything in a csv output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33ec17-289d-4a51-97d7-3044afcd9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to handle the timeouts\n",
    "def handler_orig(signum, frame):\n",
    "    global timeout_flag_orig\n",
    "    timeout_flag_orig = True\n",
    "    raise Exception(\"Query execution of the original query > 100s\")\n",
    "\n",
    "def handler_rewr(signum, frame):\n",
    "    global timeout_flag_rewr\n",
    "    timeout_flag_rewr = True\n",
    "    raise Exception(\"Query execution of the rewritten query > 100s\")\n",
    "\n",
    "def run_query(benchmark, query):\n",
    "    print(benchmark, query)\n",
    "    file_path = f'output/{benchmark}_{query}_output.json'\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    # get the original and rewritten query\n",
    "    original_query = json_data[\"original_query\"]\n",
    "    rewritten_query_list = json_data[\"rewritten_query\"]\n",
    "    rewriting_time = json_data[\"time\"]\n",
    "\n",
    "    rewritten_query_list[-2] = rewritten_query_list[-2].replace(\"UNLOGGED TABLE\", \"VIEW\")\n",
    "    rewritten_query_list_stage1 = rewritten_query_list[:-2]\n",
    "    rewritten_query_list_stage3 = rewritten_query_list[-2:]\n",
    "    rewritten_query_list_stage2 = [r for r in rewritten_query_list_stage1 if \"stage2\" in r]\n",
    "    rewritten_query_list_stage0 = [r for r in rewritten_query_list_stage1 if \"VIEW\" in r]\n",
    "    rewritten_query_list_stage1 = [r for r in rewritten_query_list_stage1 if \"stage2\" not in r and \"VIEW\" not in r]\n",
    "    \n",
    "    # get the drop queries\n",
    "    file_path_drop = f'output/{benchmark}_{query}_drop.json'\n",
    "    with open(file_path_drop, 'r') as file:\n",
    "        json_drop = json.load(file)\n",
    "    drop_query_list = json_drop[\"rewritten_query\"]\n",
    "    drop_query_list[0] = drop_query_list[0].replace(\"TABLE\", \"VIEW\")\n",
    "\n",
    "    # connect to PostgreSQL\n",
    "    if benchmark == \"JOB\":\n",
    "        database = \"imdb\"\n",
    "    else:\n",
    "        database = benchmark.lower()\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"postgres\",\n",
    "        database=database,\n",
    "        user=database,\n",
    "        password=database\n",
    "    )\n",
    "    \n",
    "    # if the evaluation takes longer than 100sec then break it\n",
    "    global timeout_flag_orig\n",
    "    global timeout_flag_rewr\n",
    "    timeout_flag_orig = False\n",
    "    timeout_flag_rewr = False\n",
    "\n",
    "    print(\"original1\")\n",
    "    # the first run is just a warm up run and to check for the time out\n",
    "    signal.signal(signal.SIGALRM, handler_orig) \n",
    "    signal.alarm(100) #TO at 100 sec, can be changed\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(original_query)\n",
    "        result = cur.fetchall()\n",
    "        rows_orig = len(result)\n",
    "    except Exception as exc: \n",
    "        print(exc)\n",
    "    signal.alarm(0) \n",
    "\n",
    "    for drop_query in drop_query_list:\n",
    "        cur.execute(drop_query.replace(\"DROP VIEW\", \"DROP VIEW IF EXISTS\").replace(\"DROP TABLE\", \"DROP TABLE IF EXISTS\"))\n",
    "\n",
    "    print(\"rewritten1\")\n",
    "    signal.signal(signal.SIGALRM, handler_rewr) \n",
    "    signal.alarm(100) \n",
    "    last_executed_query = None\n",
    "    try:\n",
    "        for rewritten_query in rewritten_query_list:\n",
    "            last_executed_query = rewritten_query\n",
    "            cur.execute(rewritten_query)\n",
    "            if rewritten_query.startswith(\"SELECT\"):\n",
    "                result1 = cur.fetchall()\n",
    "                rows_rewr = len(result1)\n",
    "        for drop_query in drop_query_list:\n",
    "            last_executed_query = drop_query\n",
    "            cur.execute(drop_query)\n",
    "    except Exception as exc: \n",
    "        print(exc)\n",
    "        print(last_executed_query)\n",
    "    signal.alarm(0)\n",
    "\n",
    "    print(timeout_flag_orig, timeout_flag_rewr)\n",
    "    # original and rewritten query are TOs\n",
    "    if timeout_flag_orig and timeout_flag_rewr:\n",
    "        list_original_time = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        orig_mean = \"TO\"\n",
    "        orig_med = \"TO\"\n",
    "        orig_std = \"-\"\n",
    "\n",
    "        list_rewritten_time_stage0 = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        rewr_stage0_mean = \"-\"\n",
    "        rewr_stage0_med = \"-\"\n",
    "        rewr_stage0_std = \"-\"\n",
    "        list_rewritten_time_stage1 = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        rewr_stage1_mean = \"-\"\n",
    "        rewr_stage1_med = \"-\"\n",
    "        rewr_stage1_std = \"-\"\n",
    "        list_rewritten_time_stage2 = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        rewr_stage2_mean = \"-\"\n",
    "        rewr_stage2_med = \"-\"\n",
    "        rewr_stage2_std = \"-\"\n",
    "        list_rewritten_time_stage3 = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        rewr_stage3_mean = \"-\"\n",
    "        rewr_stage3_med = \"-\"\n",
    "        rewr_stage3_std = \"-\"\n",
    "        list_rewritten_time = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        rewr_mean = \"TO\"\n",
    "        rewr_med = \"TO\"\n",
    "        rewr_std = \"-\"\n",
    "\n",
    "        orig_rewr = \"-\"\n",
    "        rows = \"-\"\n",
    "\n",
    "    # original query is a TO and the rewritten not\n",
    "    elif timeout_flag_orig:\n",
    "        list_original_time = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        orig_mean = \"TO\"\n",
    "        orig_med = \"TO\"\n",
    "        orig_std = \"-\"\n",
    "\n",
    "        list_rewritten_time_stage0 = []\n",
    "        list_rewritten_time_stage1 = []\n",
    "        list_rewritten_time_stage2 = []\n",
    "        list_rewritten_time_stage3 = []\n",
    "        list_rewritten_time = []\n",
    "\n",
    "        for i in range(5):\n",
    "            print(i)\n",
    "            # execute the rewritten query\n",
    "            start_time_rewritten_stage0 = time.time()\n",
    "            for rewritten_query in rewritten_query_list_stage0:\n",
    "                cur.execute(rewritten_query)\n",
    "            end_time_rewritten_stage0 = time.time()\n",
    "            rewritten_time_stage0 = end_time_rewritten_stage0 - start_time_rewritten_stage0\n",
    "            list_rewritten_time_stage0.append(rewritten_time_stage0)\n",
    "            \n",
    "            start_time_rewritten_stage1 = time.time()\n",
    "            for rewritten_query in rewritten_query_list_stage1:\n",
    "                cur.execute(rewritten_query)\n",
    "            end_time_rewritten_stage1 = time.time()\n",
    "            rewritten_time_stage1 = end_time_rewritten_stage1 - start_time_rewritten_stage1\n",
    "            list_rewritten_time_stage1.append(rewritten_time_stage1)\n",
    "            \n",
    "            start_time_rewritten_stage2 = time.time()\n",
    "            for rewritten_query in rewritten_query_list_stage2:\n",
    "                cur.execute(rewritten_query)\n",
    "            end_time_rewritten_stage2 = time.time()\n",
    "            rewritten_time_stage2 = end_time_rewritten_stage2 - start_time_rewritten_stage2\n",
    "            list_rewritten_time_stage2.append(rewritten_time_stage2)\n",
    "        \n",
    "            start_time_rewritten_stage3 = time.time()\n",
    "            for rewritten_query in rewritten_query_list_stage3:\n",
    "                cur.execute(rewritten_query)\n",
    "            end_time_rewritten_stage3 = time.time()\n",
    "            rewritten_time_stage3 = end_time_rewritten_stage3 - start_time_rewritten_stage3\n",
    "            list_rewritten_time_stage3.append(rewritten_time_stage3)\n",
    "            \n",
    "            list_rewritten_time.append(rewritten_time_stage0 + rewritten_time_stage1 + rewritten_time_stage2 + rewritten_time_stage3) \n",
    "        \n",
    "            # drop all created tables\n",
    "            for drop_query in drop_query_list:\n",
    "                cur.execute(drop_query)\n",
    "\n",
    "        rewr_stage0_mean = np.mean(list_rewritten_time_stage0)\n",
    "        rewr_stage0_med = np.median(list_rewritten_time_stage0)\n",
    "        rewr_stage0_std = np.std(list_rewritten_time_stage0)\n",
    "        rewr_stage1_mean = np.mean(list_rewritten_time_stage1)\n",
    "        rewr_stage1_med = np.median(list_rewritten_time_stage1)\n",
    "        rewr_stage1_std = np.std(list_rewritten_time_stage1)\n",
    "        rewr_stage2_mean = np.mean(list_rewritten_time_stage2)\n",
    "        rewr_stage2_med = np.median(list_rewritten_time_stage2)\n",
    "        rewr_stage2_std = np.std(list_rewritten_time_stage2)\n",
    "        rewr_stage3_mean = np.mean(list_rewritten_time_stage3)\n",
    "        rewr_stage3_med = np.median(list_rewritten_time_stage3)\n",
    "        rewr_stage3_std = np.std(list_rewritten_time_stage3)\n",
    "        rewr_mean = np.mean(list_rewritten_time)\n",
    "        rewr_med = np.median(list_rewritten_time)\n",
    "        rewr_std = np.std(list_rewritten_time)\n",
    "        \n",
    "        orig_rewr = \"rewr\"\n",
    "        rows = rows_rewr\n",
    "\n",
    "    # rewritten query is a TO and the original not\n",
    "    elif timeout_flag_rewr:\n",
    "        list_original_time = []\n",
    "\n",
    "        for i in range(5):\n",
    "            print(i)\n",
    "            # execute the original query\n",
    "            start_time_original = time.time()\n",
    "            cur.execute(original_query)\n",
    "            end_time_original = time.time()\n",
    "            list_original_time.append(end_time_original - start_time_original)\n",
    "\n",
    "        orig_mean = np.mean(list_original_time)\n",
    "        orig_med = np.median(list_original_time)\n",
    "        orig_std = np.std(list_original_time)\n",
    "\n",
    "        list_rewritten_time_stage0 = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        rewr_stage0_mean = \"-\"\n",
    "        rewr_stage0_med = \"-\"\n",
    "        rewr_stage0_std = \"-\"\n",
    "        list_rewritten_time_stage1 = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        rewr_stage1_mean = \"-\"\n",
    "        rewr_stage1_med = \"-\"\n",
    "        rewr_stage1_std = \"-\"\n",
    "        list_rewritten_time_stage2 = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        rewr_stage2_mean = \"-\"\n",
    "        rewr_stage2_med = \"-\"\n",
    "        rewr_stage2_std = \"-\"\n",
    "        list_rewritten_time_stage3 = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        rewr_stage3_mean = \"-\"\n",
    "        rewr_stage3_med = \"-\"\n",
    "        rewr_stage3_std = \"-\"\n",
    "        list_rewritten_time = [\"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        rewr_mean = \"TO\"\n",
    "        rewr_med = \"TO\"\n",
    "        rewr_std = \"-\"\n",
    "        \n",
    "        orig_rewr = \"orig\"\n",
    "        rows = rows_orig\n",
    "\n",
    "    # both queries are no TOs\n",
    "    else:\n",
    "        list_original_time = []\n",
    "        list_rewritten_time_stage0 = []\n",
    "        list_rewritten_time_stage1 = []\n",
    "        list_rewritten_time_stage2 = []\n",
    "        list_rewritten_time_stage3 = []\n",
    "        list_rewritten_time = []\n",
    "\n",
    "        for i in range(5):\n",
    "            print(i)\n",
    "            # execute the original query\n",
    "            start_time_original = time.time()\n",
    "            cur.execute(original_query)\n",
    "            end_time_original = time.time()\n",
    "            list_original_time.append(end_time_original - start_time_original)\n",
    "        \n",
    "            # execute the rewritten query\n",
    "            start_time_rewritten_stage0 = time.time()\n",
    "            for rewritten_query in rewritten_query_list_stage0:\n",
    "                cur.execute(rewritten_query)\n",
    "            end_time_rewritten_stage0 = time.time()\n",
    "            rewritten_time_stage0 = end_time_rewritten_stage0 - start_time_rewritten_stage0\n",
    "            list_rewritten_time_stage0.append(rewritten_time_stage0)\n",
    "            \n",
    "            start_time_rewritten_stage1 = time.time()\n",
    "            for rewritten_query in rewritten_query_list_stage1:\n",
    "                cur.execute(rewritten_query)\n",
    "            end_time_rewritten_stage1 = time.time()\n",
    "            rewritten_time_stage1 = end_time_rewritten_stage1 - start_time_rewritten_stage1\n",
    "            list_rewritten_time_stage1.append(rewritten_time_stage1)\n",
    "            \n",
    "            start_time_rewritten_stage2 = time.time()\n",
    "            for rewritten_query in rewritten_query_list_stage2:\n",
    "                cur.execute(rewritten_query)\n",
    "            end_time_rewritten_stage2 = time.time()\n",
    "            rewritten_time_stage2 = end_time_rewritten_stage2 - start_time_rewritten_stage2\n",
    "            list_rewritten_time_stage2.append(rewritten_time_stage2)\n",
    "        \n",
    "            start_time_rewritten_stage3 = time.time()\n",
    "            for rewritten_query in rewritten_query_list_stage3:\n",
    "                cur.execute(rewritten_query)\n",
    "            end_time_rewritten_stage3 = time.time()\n",
    "            rewritten_time_stage3 = end_time_rewritten_stage3 - start_time_rewritten_stage3\n",
    "            list_rewritten_time_stage3.append(rewritten_time_stage3)\n",
    "            \n",
    "            list_rewritten_time.append(rewritten_time_stage0 + rewritten_time_stage1 + rewritten_time_stage2 + rewritten_time_stage3) \n",
    "        \n",
    "            # drop all created tables\n",
    "            for drop_query in drop_query_list:\n",
    "                cur.execute(drop_query)\n",
    "\n",
    "        orig_mean = np.mean(list_original_time)\n",
    "        orig_med = np.median(list_original_time)\n",
    "        orig_std = np.std(list_original_time)\n",
    "        rewr_stage0_mean = np.mean(list_rewritten_time_stage0)\n",
    "        rewr_stage0_med = np.median(list_rewritten_time_stage0)\n",
    "        rewr_stage0_std = np.std(list_rewritten_time_stage0)\n",
    "        rewr_stage1_mean = np.mean(list_rewritten_time_stage1)\n",
    "        rewr_stage1_med = np.median(list_rewritten_time_stage1)\n",
    "        rewr_stage1_std = np.std(list_rewritten_time_stage1)\n",
    "        rewr_stage2_mean = np.mean(list_rewritten_time_stage2)\n",
    "        rewr_stage2_med = np.median(list_rewritten_time_stage2)\n",
    "        rewr_stage2_std = np.std(list_rewritten_time_stage2)\n",
    "        rewr_stage3_mean = np.mean(list_rewritten_time_stage3)\n",
    "        rewr_stage3_med = np.median(list_rewritten_time_stage3)\n",
    "        rewr_stage3_std = np.std(list_rewritten_time_stage3)\n",
    "        rewr_mean = np.mean(list_rewritten_time)\n",
    "        rewr_med = np.median(list_rewritten_time)\n",
    "        rewr_std = np.std(list_rewritten_time)\n",
    "            \n",
    "        if orig_med > rewr_med:\n",
    "            orig_rewr = \"rewr\"\n",
    "        else:\n",
    "            orig_rewr = \"orig\"\n",
    "    \n",
    "        if rows_orig == rows_rewr:\n",
    "            rows = rows_orig\n",
    "        else:\n",
    "            rows = \"not the same!\"\n",
    "\n",
    "    if benchmark == \"IMDB\":\n",
    "        benchmark = \"JOB\"\n",
    "    list_output = [benchmark, query, orig_rewr, orig_med, rewr_med, rewr_stage0_med, rewr_stage1_med, rewr_stage2_med, rewr_stage3_med, rows] + \\\n",
    "                    list_original_time + [orig_mean, orig_std] + list_rewritten_time + [rewr_mean, rewr_std] + list_rewritten_time_stage0 + \\\n",
    "                    [rewr_stage0_mean, rewr_stage0_std] + list_rewritten_time_stage1 + [rewr_stage1_mean, rewr_stage1_std] + \\\n",
    "                    list_rewritten_time_stage2 + [rewr_stage2_mean, rewr_stage2_std] + list_rewritten_time_stage3 + [rewr_stage3_mean, rewr_stage3_std]\n",
    "        \n",
    "\n",
    "    file_path = \"results/POS_Scala_comparison_TO_augment_server_full_enum_infos.csv\"\n",
    "    with open(file_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(list_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea09d6e-44f4-47c9-b574-cf55fedac6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"results/POS_Scala_comparison_TO_augment_server_full_enum_infos.csv\"\n",
    "\n",
    "names = [\"bench\", \"query\", \"orig/rewr(med)\", \"orig(med)\", \"rewr(med)\", \"stage0(med)\", \"stage1(med)\", \"stage2(med)\", \"stage3(med)\", \"rows\",\n",
    "        \"orig 1\", \"orig 2\", \"orig 3\", \"orig 4\", \"orig 5\", \"orig(mean)\", \"orig(std)\", \n",
    "        \"rewr 1\", \"rewr 2\", \"rewr 3\", \"rewr 4\", \"rewr 5\", \"rewr(mean)\", \"rewr(std)\",\n",
    "        \"stage0 1\", \"stage0 2\", \"stage0 3\", \"stage0 4\", \"stage0 5\", \"stage0(mean)\", \"stage0(std)\",\n",
    "        \"stage1 1\", \"stage1 2\", \"stage1 3\", \"stage1 4\", \"stage1 5\", \"stage1(mean)\", \"stage1(std)\",\n",
    "        \"stage2 1\", \"stage2 2\", \"stage2 3\", \"stage2 4\", \"stage2 5\", \"stage2(mean)\", \"stage2(std)\",\n",
    "        \"stage3 1\", \"stage3 2\", \"stage3 3\", \"stage3 4\", \"stage3 5\", \"stage3(mean)\", \"stage3(std)\"]\n",
    "\n",
    "with open(file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5954b39-c9e8-48b2-85e5-7c055647dc8a",
   "metadata": {},
   "source": [
    "### STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10daa48c-601b-4001-835d-b45f30e94591",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'output/'\n",
    "files = sorted(os.listdir(folder_path))\n",
    "output_files = [file for file in files if file.endswith('_output.json') and file.startswith('STATS')]\n",
    "\n",
    "for file in output_files:\n",
    "    file_split = file.split(\"_\")\n",
    "    number = int(file_split[1].split(\"-\")[0])\n",
    "    if number <= 50:\n",
    "        run_query(file_split[0], file_split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63607e23-31d2-42cd-a222-7cea5c56722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'output/'\n",
    "files = sorted(os.listdir(folder_path))\n",
    "output_files = [file for file in files if file.endswith('_output.json') and file.startswith('STATS')]\n",
    "\n",
    "for file in output_files:\n",
    "    file_split = file.split(\"_\")\n",
    "    number = int(file_split[1].split(\"-\")[0])\n",
    "    if number > 50 and number <= 100:\n",
    "        run_query(file_split[0], file_split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dce20e-464e-4e7b-ba10-d232a7dc4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'output/'\n",
    "files = sorted(os.listdir(folder_path))\n",
    "output_files = [file for file in files if file.endswith('_output.json') and file.startswith('STATS')]\n",
    "\n",
    "for file in output_files:\n",
    "    file_split = file.split(\"_\")\n",
    "    number = int(file_split[1].split(\"-\")[0])\n",
    "    if number > 100:\n",
    "        run_query(file_split[0], file_split[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ce6f6-8b60-45a4-a080-b4706d0e2771",
   "metadata": {},
   "source": [
    "### SNAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da76f4a7-a208-46a9-a3b6-1e7b0d2928df",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'output/'\n",
    "files = sorted(os.listdir(folder_path))\n",
    "output_files = [file for file in files if file.endswith('_output.json') and file.startswith('SNAP')]\n",
    "\n",
    "for file in output_files:\n",
    "    file_split = file.split(\"_\")\n",
    "    run_query(file_split[0], file_split[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fc3cb4-07a3-4e77-a8f0-e4142c5b3a74",
   "metadata": {},
   "source": [
    "### JOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7067b0d9-6c73-4590-a8b3-aaf883a883c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'output/'\n",
    "files = sorted(os.listdir(folder_path))\n",
    "output_files = [file for file in files if file.endswith('_output.json') and file.startswith('IMDB')]\n",
    "\n",
    "for file in output_files:\n",
    "    file_split = file.split(\"_\")\n",
    "    run_query(file_split[0], file_split[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42842f5d-a9e0-4c1c-9795-be766ff267b5",
   "metadata": {},
   "source": [
    "### LSQB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95364cb-6a19-4e21-8a5d-023ce41d6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'output/'\n",
    "files = sorted(os.listdir(folder_path))\n",
    "output_files = [file for file in files if file.endswith('_output.json') and file.startswith('LSQB')]\n",
    "\n",
    "for file in output_files:\n",
    "    file_split = file.split(\"_\")\n",
    "    run_query(file_split[0], file_split[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665d6b1-e165-43a5-ad64-0c92fcb6e92b",
   "metadata": {},
   "source": [
    "### HETIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb81e4a-aeac-4077-b8d0-c0de31a9beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'output/'\n",
    "files = sorted(os.listdir(folder_path))\n",
    "output_files = [file for file in files if file.endswith('_output.json') and file.startswith('HETIO')]\n",
    "\n",
    "for file in output_files:\n",
    "    file_split = file.split(\"_\")\n",
    "    run_query(file_split[0], file_split[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
