{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19cbf1d8-de7f-4b5b-b13c-4f92a846298f",
   "metadata": {},
   "source": [
    "# Get all features together with the evaluation times for all queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfaa467-7734-447b-bf41-1238d0f68c63",
   "metadata": {},
   "source": [
    "Features based on the query:   \n",
    "*  number of relations\n",
    "*  number of conditions\n",
    "*  number of filters\n",
    "*  number of joins\n",
    "\n",
    "Features based on the join tree:\n",
    "*  depth\n",
    "*  container count (min, max, mean, median, q1, q3)\n",
    "*  branching factors (min, max, mean, median, q1, q3)\n",
    "*  balancedness factor \n",
    "\n",
    "Features based on the data in the database (EXPLAIN):\n",
    "*  estimated total cost\n",
    "*  estimated single table rows (min, max, mean, median, q1, q3)\n",
    "*  estimated join rows (min, max, mean, median, q1, q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4fd341-9bd9-4d8e-b22f-f27949dc1c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.10/dist-packages (2.9.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install pandas\n",
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb971097-ee96-48f8-ae56-ef8d2ceb2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db751e9-7b01-48d3-b378-beb7838bb418",
   "metadata": {},
   "source": [
    "### Get the features based on the structure of the query and database information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c308525-8e8f-4ab6-a3c6-ef7d8f31172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_through_plan(plan, table_rows, join_rows):\n",
    "    if plan[\"Node Type\"] == \"Seq Scan\":\n",
    "        table_rows.append(plan[\"Plan Rows\"])\n",
    "    elif plan[\"Node Type\"] == \"Index Only Scan\":\n",
    "        table_rows.append(plan[\"Plan Rows\"])\n",
    "    elif plan[\"Node Type\"] == \"Index Scan\":\n",
    "        table_rows.append(plan[\"Plan Rows\"])\n",
    "    elif plan[\"Node Type\"] == \"Bitmap Index Scan\":\n",
    "        table_rows.append(plan[\"Plan Rows\"])\n",
    "    \n",
    "    if plan[\"Node Type\"] == \"Hash Join\":\n",
    "        join_rows.append(plan[\"Plan Rows\"])\n",
    "    elif plan[\"Node Type\"] == \"Merge Join\":\n",
    "        join_rows.append(plan[\"Plan Rows\"])\n",
    "    elif plan[\"Node Type\"] == \"Nested Loop\":\n",
    "        join_rows.append(plan[\"Plan Rows\"])\n",
    "\n",
    "    if \"Plans\" in plan.keys():\n",
    "        for i in range(len(plan[\"Plans\"])):\n",
    "            iterate_through_plan(plan[\"Plans\"][i], table_rows, join_rows)\n",
    "\n",
    "    return table_rows, join_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7e4e0be-b09f-40ac-be0b-f83d7603b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4a11116-dd33-4e4e-b38a-6bdbb75bab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output file paths\n",
    "input_file = 'scala_commands_with_MIN.txt'\n",
    "output_file = 'results/featuresDatabase.csv'\n",
    "\n",
    "# Open input and output files\n",
    "with open(input_file, 'r') as f_input, open(output_file, 'w', newline='') as f_output:\n",
    "    csv_writer = csv.writer(f_output)\n",
    "    \n",
    "    # Write header to CSV file\n",
    "    csv_writer.writerow(['bench', 'query', '#relations', '#conditions', '#filters', '#joins', 'total cost', 'min(table rows)', 'max(table rows)', 'mean(table rows)',\n",
    "                         'q25(table rows)', 'median(table rows)', 'q75(table rows)', 'min(join rows)', 'max(join rows)', 'mean(join rows)', \n",
    "                         'q25(join rows)', 'median(join rows)', 'q75(join rows)', 'list table rows', 'list join rows', 'text'])\n",
    "    \n",
    "    # Read input file line by line\n",
    "    for line in f_input:\n",
    "        # Split each line into components\n",
    "        pattern = r'(?<!\\\\)\\\"|\\\"(?<!\\\\)(?=\\s+\\\"|$)'\n",
    "        components = re.split(pattern, line)\n",
    "        \n",
    "        # Extract relevant information\n",
    "        benchmark = components[3]\n",
    "        number = components[5]\n",
    "        query = components[1].strip()\n",
    "\n",
    "        # FEATURES BASED ON QUERY STRUCTURE\n",
    "        # get the number of relations\n",
    "        query_upper = query.upper()\n",
    "        from_index = query_upper.find(\"FROM\")\n",
    "        where_index = query_upper.find(\"WHERE\")\n",
    "        number_of_relations = query[from_index:where_index].count(\",\") + 1\n",
    "\n",
    "        # get the number of conditions\n",
    "        number_of_conditions = query.count(\"AND\") + 1\n",
    "\n",
    "        # get how many filter and join conditions\n",
    "        parts = query_upper.split(\"WHERE\")[1].split(\"AND\")\n",
    "        filter = 0\n",
    "        join = 0\n",
    "        joins = []\n",
    "        for p in parts:\n",
    "            partners = []\n",
    "            p_split = p.split(\"=\")\n",
    "            if len(p_split) == 2 and p_split[1].count(\"'\") == 0 and p_split[1].count('\"') == 0 and is_number(p_split[1].strip()) == False:\n",
    "                partners = [p2.strip().split(\".\")[0] for p2 in p.split(\"=\")]\n",
    "                if partners not in joins and list(reversed(partners)) not in joins:\n",
    "                    joins.append(partners)\n",
    "                    join += 1\n",
    "            else:\n",
    "                filter += 1\n",
    "\n",
    "        # FEATURES BASED ON DATABASE\n",
    "        # get features based on the Postgresql Plan by EXPLAIN\n",
    "        if benchmark == \"JOB\":\n",
    "            database = \"imdb\"\n",
    "        else:\n",
    "            database = benchmark.lower()\n",
    "        conn = psycopg2.connect(\n",
    "            host=\"postgres\",\n",
    "            database=database,\n",
    "            user=database,\n",
    "            password=database\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        query2 = query.replace('\\\\\\\\\\\\\"', '')\n",
    "        cur.execute(\"EXPLAIN (format json)\" + query2)\n",
    "        result = cur.fetchall()\n",
    "        total_cost = result[0][0][0][\"Plan\"][\"Total Cost\"]\n",
    "        # get the estimated rows for each single table and the intermediate results\n",
    "        table_rows, join_rows = iterate_through_plan(result[0][0][0][\"Plan\"], [], [])\n",
    "        # calculate min, max, mean, median, 0.25-quantile and 0.75-quantile\n",
    "        table_rows_min = np.min(table_rows)\n",
    "        table_rows_max = np.max(table_rows)\n",
    "        table_rows_median = np.median(table_rows)\n",
    "        table_rows_mean = np.mean(table_rows)\n",
    "        table_rows_q25 = np.quantile(table_rows, 0.25)\n",
    "        table_rows_q75 = np.quantile(table_rows, 0.75)\n",
    "        join_rows_min = np.min(join_rows)\n",
    "        join_rows_max = np.max(join_rows)\n",
    "        join_rows_median = np.median(join_rows)\n",
    "        join_rows_mean = np.mean(join_rows)\n",
    "        join_rows_q25 = np.quantile(join_rows, 0.25)\n",
    "        join_rows_q75 = np.quantile(join_rows, 0.75)\n",
    "                \n",
    "        # Write data to CSV file\n",
    "        csv_writer.writerow([benchmark, number, number_of_relations, number_of_conditions, filter, join, total_cost, table_rows_min, table_rows_max, \n",
    "                             table_rows_mean, table_rows_q25, table_rows_median, table_rows_q75, join_rows_min, join_rows_max, join_rows_mean, \n",
    "                             join_rows_q25, join_rows_median, join_rows_q75, table_rows, join_rows, query])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42371ab7-d2dc-4a0c-b995-92a170de5af8",
   "metadata": {},
   "source": [
    "### Get the features based on the join tree structure (calculated in Scala, imported and formated here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd828bb-ad68-49c4-b1a6-b5f2229b09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'results/featuresScala.csv'\n",
    "csv_header = [\"bench\", \"query\", \"depth\", \"min(container counts)\", \"max(container counts)\", \"mean(container counts)\", \"q25(container counts)\",\n",
    "              \"median(container counts)\", \"q75(container counts)\", \"min(branching factors)\", \"max(branching factors)\", \"mean(branching factors)\", \n",
    "              \"median(branching factors)\", \"balancedness factor\", \"container counts list\", \"branching factors list\"]\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(csv_header)\n",
    "\n",
    "    directory = 'rewritten_benchmark_queries/'\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"output.json\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            benchmark = filename.split(\"_\")[0]\n",
    "            number = filename.split(\"_\")[1]\n",
    "            with open(filepath, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                # FEATURES BASED ON THE JOIN TREE STRUCTURE\n",
    "                feature = data.get(\"features\", [])\n",
    "                features = feature.split(\"List(\")\n",
    "                depth = int(features[1][:-2])\n",
    "                container_counts = [int(x) for x in features[2][:-3].split(\", \")]\n",
    "                container_counts_min = np.min(container_counts)\n",
    "                container_counts_max = np.max(container_counts)\n",
    "                container_counts_mean = np.mean(container_counts)\n",
    "                container_counts_median = np.median(container_counts)\n",
    "                container_counts_q25 = np.quantile(container_counts, 0.25)\n",
    "                container_counts_q75 = np.quantile(container_counts, 0.25)\n",
    "                branching_factors = [int(x) for x in features[3].split(\"), \")[0].split(\", \")]\n",
    "                branching_factors_min = np.min(branching_factors)\n",
    "                branching_factors_max = np.max(branching_factors)\n",
    "                branching_factors_mean = np.mean(branching_factors)\n",
    "                branching_factors_median = np.median(branching_factors)\n",
    "                balancedness_factor = float(features[3].split(\"), \")[1][:-1])\n",
    "\n",
    "                # Write data to CSV file\n",
    "                csv_row = [benchmark, number, depth, container_counts_min, container_counts_max, container_counts_mean, container_counts_q25,\n",
    "                           container_counts_median, container_counts_q75, branching_factors_min, branching_factors_max, branching_factors_mean,\n",
    "                           branching_factors_median, balancedness_factor, container_counts, branching_factors]\n",
    "                writer.writerow(csv_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150916d8-d9b5-44dc-aa0a-2b9f5a820036",
   "metadata": {},
   "source": [
    "### Merge all features and evaluation times for each query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2afbc001-ca32-4855-9b72-319e361f6b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#relations</th>\n",
       "      <th>depth</th>\n",
       "      <th>orig/rewr(mean)</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>orig</td>\n",
       "      <td>SELECT MIN(u.Id) FROM comments as c, votes as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>orig</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, postHisto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>orig</td>\n",
       "      <td>SELECT MIN(c.Id) FROM comments as c, posts as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>orig</td>\n",
       "      <td>SELECT MIN(pl.Id) FROM postLinks as pl, posts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>orig</td>\n",
       "      <td>SELECT MIN(v.Id) FROM votes as v, badges as b,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>orig</td>\n",
       "      <td>SELECT MIN(n.name) AS member_in_charnamed_movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>orig</td>\n",
       "      <td>SELECT MIN(t.title) AS complete_downey_ironman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>orig</td>\n",
       "      <td>SELECT MIN(t.title) AS complete_downey_ironman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>rewr</td>\n",
       "      <td>SELECT MIN(Country.CountryId) FROM Country, Ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>SELECT MIN(Message_hasTag_Tag.MessageId) FROM ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #relations  depth orig/rewr(mean)  \\\n",
       "0             3      1            orig   \n",
       "1             5      2            orig   \n",
       "2             6      1            orig   \n",
       "3             4      2            orig   \n",
       "4             3      1            orig   \n",
       "..          ...    ...             ...   \n",
       "198           7      4            orig   \n",
       "199          10      2            orig   \n",
       "200          10      3            orig   \n",
       "201          10      7            rewr   \n",
       "202           4      1            rewr   \n",
       "\n",
       "                                                  text  \n",
       "0    SELECT MIN(u.Id) FROM comments as c, votes as ...  \n",
       "1    SELECT MIN(c.Id) FROM comments as c, postHisto...  \n",
       "2    SELECT MIN(c.Id) FROM comments as c, posts as ...  \n",
       "3    SELECT MIN(pl.Id) FROM postLinks as pl, posts ...  \n",
       "4    SELECT MIN(v.Id) FROM votes as v, badges as b,...  \n",
       "..                                                 ...  \n",
       "198  SELECT MIN(n.name) AS member_in_charnamed_movi...  \n",
       "199  SELECT MIN(t.title) AS complete_downey_ironman...  \n",
       "200  SELECT MIN(t.title) AS complete_downey_ironman...  \n",
       "201  SELECT MIN(Country.CountryId) FROM Country, Ci...  \n",
       "202  SELECT MIN(Message_hasTag_Tag.MessageId) FROM ...  \n",
       "\n",
       "[203 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('results/featuresDatabase.csv')\n",
    "df2 = pd.read_csv('results/featuresScala.csv')\n",
    "df3 = pd.read_csv('results/POS_Scala_comparison_TO.csv')\n",
    "df3['orig mean'] = df3['orig mean'].replace('TO', 1800).astype(\"float64\")\n",
    "df3['diff rewr+rewr-orig'] = df3['rewr mean+rewr'] - df3['orig mean']\n",
    "df3['diff rewr-orig'] = df3['rewr mean'] - df3['orig mean']\n",
    "\n",
    "merged_df = pd.merge(df1, df2, on=[\"bench\", \"query\"], how='inner').merge(df3, on=[\"bench\", \"query\"], how='inner')\n",
    "merged_df[[\"#relations\", \"depth\", \"orig/rewr(mean)\", \"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b65b7-e81b-4e07-b676-054f4767a153",
   "metadata": {},
   "source": [
    "### Save the resulting dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d5607f-16bc-4238-a728-3c15fbc9973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[[\"bench\", \"query\", \"orig/rewr(mean)\", \"orig/rewr+rewr(mean)\", \"orig mean\", \"rewr mean\", \"rewr mean+rewr\", \"diff rewr-orig\", \n",
    "           \"diff rewr+rewr-orig\", \"#relations\", \"#conditions\", \"#filters\", \"#joins\", 'total cost','min(table rows)',\n",
    "           'max(table rows)', 'mean(table rows)', 'q25(table rows)', 'median(table rows)', 'q75(table rows)', 'min(join rows)', 'max(join rows)', \n",
    "           'mean(join rows)', 'q25(join rows)', 'median(join rows)', 'q75(join rows)', \"depth\", \"min(container counts)\", \"max(container counts)\", \n",
    "           \"mean(container counts)\", \"q25(container counts)\", \"median(container counts)\", \"q75(container counts)\", \"min(branching factors)\", \n",
    "           \"max(branching factors)\", \"mean(branching factors)\",  \"median(branching factors)\", \"balancedness factor\",'list table rows', \n",
    "           'list join rows',\"container counts list\", \"branching factors list\", \"text\"]].to_csv('results/features_times.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
