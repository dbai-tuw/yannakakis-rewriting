{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db35e3d-1124-4cc4-9732-30c61afa7a26",
   "metadata": {},
   "source": [
    "# Decision program using machine learning methods\n",
    "## DuckDB, basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42129418-1fba-457e-a372-a3a81aabed89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.23 in /usr/local/lib/python3.10/dist-packages (1.23.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.2)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.23.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.0)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.13.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.9.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: dhg in /usr/local/lib/python3.10/dist-packages (0.9.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from dhg) (1.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dhg) (1.23.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from dhg) (3.9.0)\n",
      "Requirement already satisfied: torch<2.0,>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from dhg) (1.13.1)\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from dhg) (3.6.1)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from dhg) (1.13.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dhg) (2.31.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.12.1->dhg) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.12.1->dhg) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.12.1->dhg) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.12.1->dhg) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch<2.0,>=1.12.1->dhg) (11.10.3.66)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0,>=1.12.1->dhg) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0,>=1.12.1->dhg) (59.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg) (24.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg) (1.2.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg) (10.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->dhg) (3.1.2)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->dhg) (6.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->dhg) (2.0.30)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna->dhg) (6.0.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->dhg) (1.13.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna->dhg) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dhg) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dhg) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dhg) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dhg) (3.7)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->dhg) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->dhg) (1.4.2)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->dhg) (1.3.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->dhg) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->dhg) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->dhg) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.23\n",
    "!pip install scikit-learn\n",
    "!pip install statsmodels\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install torch\n",
    "!pip install tqdm\n",
    "!pip install dhg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424d2e00-9146-4aa9-a3be-9731421befa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import dhg\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd7b210-2488-4a03-9bea-98548da6e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample DataFrame\n",
    "data = {'A': [1.0, 2.0, 3.0], 'B': [4.0, 5.0, 6.0]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert DataFrame to numpy array\n",
    "np_array = df.values\n",
    "\n",
    "# Convert numpy array to PyTorch tensor\n",
    "tensor = torch.from_numpy(np_array).float()\n",
    "\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef47a79-a56d-4997-b56b-64f938e3e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb24904-9f15-44f7-8909-3e069e5e46d6",
   "metadata": {},
   "source": [
    "#### Distribution of the runtimes in orders of magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab4fe1-abef-49e5-b702-d1752bd405d9",
   "metadata": {},
   "source": [
    "For the original queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b336eca-d8b8-431e-89d7-f2d31f559e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances with original runtime <= 0.01: 7\n",
      "Number of instances with original runtime (0.01, 0.1]: 101\n",
      "Number of instances with original runtime (0.1, 1]: 1706\n",
      "Number of instances with original runtime (1,10]: 638\n",
      "Number of instances with original runtime (10,100]: 219\n",
      "Number of instances with original runtime TO: 265\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('results/DDB_Scala_comparison_TO_augment_server.csv')\n",
    "\n",
    "df.loc[df['orig mean'] == 'TO', 'orig mean'] = 101\n",
    "column = df['orig mean'].astype(\"float64\")\n",
    "\n",
    "count_0_01_orig = 0\n",
    "count_0_1_orig = 0\n",
    "count_1_orig = 0\n",
    "count_10_orig = 0\n",
    "count_100_orig = 0\n",
    "count_TO_orig = 0\n",
    "\n",
    "for value in column:\n",
    "    if value <= 0.01:\n",
    "        count_0_01_orig += 1\n",
    "    elif value > 0.01 and value <= 0.1:\n",
    "        count_0_1_orig += 1\n",
    "    elif value > 0.1 and value <= 1:\n",
    "        count_1_orig += 1\n",
    "    elif value > 1 and value <= 10:\n",
    "        count_10_orig += 1\n",
    "    elif value > 10 and value <= 100:\n",
    "        count_100_orig += 1\n",
    "    else:\n",
    "        count_TO_orig += 1\n",
    "    \n",
    "\n",
    "print(\"Number of instances with original runtime <= 0.01:\", count_0_01_orig)\n",
    "print(\"Number of instances with original runtime (0.01, 0.1]:\", count_0_1_orig)\n",
    "print(\"Number of instances with original runtime (0.1, 1]:\", count_1_orig)\n",
    "print(\"Number of instances with original runtime (1,10]:\", count_10_orig)\n",
    "print(\"Number of instances with original runtime (10,100]:\", count_100_orig)\n",
    "print(\"Number of instances with original runtime TO:\", count_TO_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e943a9d8-52bf-4556-ad36-482c00972f62",
   "metadata": {},
   "source": [
    "for the rewritten queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0b2a25-5990-405c-a325-92f4f43266da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances with original runtime <= 0.01: 0\n",
      "Number of instances with original runtime (0.01, 0.1]: 103\n",
      "Number of instances with original runtime (0.1, 1]: 1930\n",
      "Number of instances with original runtime (1,10]: 560\n",
      "Number of instances with original runtime (10,100]: 219\n",
      "Number of instances with original runtime TO: 124\n"
     ]
    }
   ],
   "source": [
    "df.loc[df['rewr mean'] == 'TO', 'rewr mean'] = 101\n",
    "column = df['rewr mean'].astype(\"float64\")\n",
    "\n",
    "count_0_01_rewr = 0\n",
    "count_0_1_rewr = 0\n",
    "count_1_rewr = 0\n",
    "count_10_rewr = 0\n",
    "count_100_rewr = 0\n",
    "count_TO_rewr = 0\n",
    "\n",
    "for value in column:\n",
    "    if value <= 0.01:\n",
    "        count_0_01_rewr += 1\n",
    "    elif value > 0.01 and value <= 0.1:\n",
    "        count_0_1_rewr += 1\n",
    "    elif value > 0.1 and value <= 1:\n",
    "        count_1_rewr += 1\n",
    "    elif value > 1 and value <= 10:\n",
    "        count_10_rewr += 1\n",
    "    elif value > 10 and value <= 100:\n",
    "        count_100_rewr += 1\n",
    "    else:\n",
    "        count_TO_rewr += 1\n",
    "    \n",
    "\n",
    "print(\"Number of instances with original runtime <= 0.01:\", count_0_01_rewr)\n",
    "print(\"Number of instances with original runtime (0.01, 0.1]:\", count_0_1_rewr)\n",
    "print(\"Number of instances with original runtime (0.1, 1]:\", count_1_rewr)\n",
    "print(\"Number of instances with original runtime (1,10]:\", count_10_rewr)\n",
    "print(\"Number of instances with original runtime (10,100]:\", count_100_rewr)\n",
    "print(\"Number of instances with original runtime TO:\", count_TO_rewr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10afb32e-3e67-48af-a767-7b4dbc21ab5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numbers_orig = [count_0_01_orig, count_0_1_orig, count_1_orig, count_10_orig, count_100_orig, count_TO_orig]\n",
    "numbers_rewr = [count_0_01_rewr, count_0_1_rewr, count_1_rewr, count_10_rewr, count_100_rewr, count_TO_rewr]\n",
    "\n",
    "# Indices for each number\n",
    "indices = [\"0.01\", \"0.1\", \"1\", \"10\", \"100\", \"TO\"]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot original numbers\n",
    "axs[0].barh(indices, numbers_orig)\n",
    "axs[0].set_xlabel('Count')\n",
    "axs[0].set_ylabel('Order of magnitude')\n",
    "axs[0].set_title('Original queries')\n",
    "axs[0].set_xlim(0, 2200)\n",
    "\n",
    "# Plot rewritten numbers\n",
    "axs[1].barh(indices, numbers_rewr)\n",
    "axs[1].set_xlabel('Count')\n",
    "axs[1].set_ylabel('Order of magnitude')\n",
    "axs[1].set_title('Rewritten queries')\n",
    "axs[1].set_xlim(0, 2200)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da2cf6-ee27-4e05-ae58-473e58cc8bd2",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77dacf66-452f-4185-ab16-d77b08bc169f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bench</th>\n",
       "      <th>query</th>\n",
       "      <th>orig/rewr(mean)</th>\n",
       "      <th>orig/rewr+rewr(mean)</th>\n",
       "      <th>orig mean</th>\n",
       "      <th>rewr mean</th>\n",
       "      <th>rewr mean+rewr</th>\n",
       "      <th>diff rewr-orig</th>\n",
       "      <th>diff rewr+rewr-orig</th>\n",
       "      <th>#relations</th>\n",
       "      <th>...</th>\n",
       "      <th>max(branching factors)</th>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <th>median(branching factors)</th>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <th>balancedness factor</th>\n",
       "      <th>container counts list</th>\n",
       "      <th>branching factors list</th>\n",
       "      <th>hypergraph</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STATS</td>\n",
       "      <td>001-014</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.152974</td>\n",
       "      <td>0.111106</td>\n",
       "      <td>2.036514</td>\n",
       "      <td>-0.041868</td>\n",
       "      <td>1.883540</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>SELECT MIN(u.Id) FROM comments as c, votes as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STATS</td>\n",
       "      <td>001-014-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.164154</td>\n",
       "      <td>0.136223</td>\n",
       "      <td>1.933056</td>\n",
       "      <td>-0.027931</td>\n",
       "      <td>1.768902</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>SELECT MIN(c.id) FROM comments as c, votes as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STATS</td>\n",
       "      <td>001-014-augA2</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.167567</td>\n",
       "      <td>0.199151</td>\n",
       "      <td>2.017481</td>\n",
       "      <td>0.031583</td>\n",
       "      <td>1.849914</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>SELECT MIN(v.id) FROM comments as c, votes as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STATS</td>\n",
       "      <td>001-014-augF1</td>\n",
       "      <td>orig</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.155335</td>\n",
       "      <td>0.199072</td>\n",
       "      <td>2.031366</td>\n",
       "      <td>0.043737</td>\n",
       "      <td>1.876031</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>SELECT MIN(u.Id) FROM comments as c, votes as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STATS</td>\n",
       "      <td>001-014-augF1-augA1</td>\n",
       "      <td>rewr</td>\n",
       "      <td>orig</td>\n",
       "      <td>0.165553</td>\n",
       "      <td>0.139130</td>\n",
       "      <td>1.994132</td>\n",
       "      <td>-0.026423</td>\n",
       "      <td>1.828579</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>SELECT MIN(c.id) FROM comments as c, votes as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bench                query orig/rewr(mean) orig/rewr+rewr(mean)  orig mean  \\\n",
       "0  STATS              001-014            rewr                 orig   0.152974   \n",
       "1  STATS        001-014-augA1            rewr                 orig   0.164154   \n",
       "2  STATS        001-014-augA2            orig                 orig   0.167567   \n",
       "3  STATS        001-014-augF1            orig                 orig   0.155335   \n",
       "4  STATS  001-014-augF1-augA1            rewr                 orig   0.165553   \n",
       "\n",
       "   rewr mean  rewr mean+rewr  diff rewr-orig  diff rewr+rewr-orig  #relations  \\\n",
       "0   0.111106        2.036514       -0.041868             1.883540           3   \n",
       "1   0.136223        1.933056       -0.027931             1.768902           3   \n",
       "2   0.199151        2.017481        0.031583             1.849914           3   \n",
       "3   0.199072        2.031366        0.043737             1.876031           3   \n",
       "4   0.139130        1.994132       -0.026423             1.828579           3   \n",
       "\n",
       "   ...  max(branching factors)  mean(branching factors)  \\\n",
       "0  ...                       2                      2.0   \n",
       "1  ...                       1                      1.0   \n",
       "2  ...                       1                      1.0   \n",
       "3  ...                       2                      2.0   \n",
       "4  ...                       1                      1.0   \n",
       "\n",
       "   median(branching factors)  q25(branching factors)  q75(branching factors)  \\\n",
       "0                        2.0                     2.0                     2.0   \n",
       "1                        1.0                     1.0                     1.0   \n",
       "2                        1.0                     1.0                     1.0   \n",
       "3                        2.0                     2.0                     2.0   \n",
       "4                        1.0                     1.0                     1.0   \n",
       "\n",
       "   balancedness factor                          container counts list  \\\n",
       "0                  1.0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "1                  NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "2                  NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "3                  1.0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "4                  NaN  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]   \n",
       "\n",
       "   branching factors list                                         hypergraph  \\\n",
       "0                     [2]  b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "1                  [1, 1]  b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "2                  [1, 1]  b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "3                     [2]  b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "4                  [1, 1]  b'\\x80\\x04\\x95\\xe8\\x01\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "\n",
       "                                                text  \n",
       "0  SELECT MIN(u.Id) FROM comments as c, votes as ...  \n",
       "1  SELECT MIN(c.id) FROM comments as c, votes as ...  \n",
       "2  SELECT MIN(v.id) FROM comments as c, votes as ...  \n",
       "3  SELECT MIN(u.Id) FROM comments as c, votes as ...  \n",
       "4  SELECT MIN(c.id) FROM comments as c, votes as ...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'results/features_times_DDB.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d95e056c-cbfb-48fb-ad35-8b45b10e923f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bench                         object\n",
       "query                         object\n",
       "orig/rewr(mean)               object\n",
       "orig/rewr+rewr(mean)          object\n",
       "orig mean                    float64\n",
       "rewr mean                    float64\n",
       "rewr mean+rewr               float64\n",
       "diff rewr-orig               float64\n",
       "diff rewr+rewr-orig          float64\n",
       "#relations                     int64\n",
       "#conditions                    int64\n",
       "#filters                       int64\n",
       "#joins                         int64\n",
       "depth                          int64\n",
       "min(container counts)          int64\n",
       "max(container counts)          int64\n",
       "mean(container counts)       float64\n",
       "q25(container counts)        float64\n",
       "median(container counts)     float64\n",
       "q75(container counts)        float64\n",
       "min(branching factors)         int64\n",
       "max(branching factors)         int64\n",
       "mean(branching factors)      float64\n",
       "median(branching factors)    float64\n",
       "q25(branching factors)       float64\n",
       "q75(branching factors)       float64\n",
       "balancedness factor          float64\n",
       "container counts list         object\n",
       "branching factors list        object\n",
       "hypergraph                    object\n",
       "text                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1137fd08-d578-4457-b75a-39a1c0b012e8",
   "metadata": {},
   "source": [
    "Transform the hypergraph, which is saved as pickle object, back to a dhg hypergraph object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc15423-1e19-4b2d-9351-1c022e647d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hypergraph\"] = df[\"hypergraph\"].apply(lambda x: pickle.loads(eval(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a17ac96-eb96-4a60-8776-ff6c71074256",
   "metadata": {},
   "source": [
    "#### Delete those examples, where both methods gave a timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b71ca29c-bbbc-4975-8935-fbbdb92f47fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bench</th>\n",
       "      <th>query</th>\n",
       "      <th>orig/rewr(mean)</th>\n",
       "      <th>orig/rewr+rewr(mean)</th>\n",
       "      <th>orig mean</th>\n",
       "      <th>rewr mean</th>\n",
       "      <th>rewr mean+rewr</th>\n",
       "      <th>diff rewr-orig</th>\n",
       "      <th>diff rewr+rewr-orig</th>\n",
       "      <th>#relations</th>\n",
       "      <th>...</th>\n",
       "      <th>max(branching factors)</th>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <th>median(branching factors)</th>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <th>balancedness factor</th>\n",
       "      <th>container counts list</th>\n",
       "      <th>branching factors list</th>\n",
       "      <th>hypergraph</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>patents-path08</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 2]</td>\n",
       "      <td>Hypergraph(num_v=18, num_e=9)</td>\n",
       "      <td>select MIN(p1.toNode) from patents p1, patents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>patents-path08-augA1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 2]</td>\n",
       "      <td>Hypergraph(num_v=18, num_e=9)</td>\n",
       "      <td>select MIN(p2.fromnode) from patents p1, paten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>patents-path08-augA2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 2]</td>\n",
       "      <td>Hypergraph(num_v=18, num_e=9)</td>\n",
       "      <td>select MIN(p3.fromnode) from patents p1, paten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>patents-path08-augA3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 2]</td>\n",
       "      <td>Hypergraph(num_v=18, num_e=9)</td>\n",
       "      <td>select MIN(p4.fromnode) from patents p1, paten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>patents-path08-augA4</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 2]</td>\n",
       "      <td>Hypergraph(num_v=18, num_e=9)</td>\n",
       "      <td>select MIN(p5.fromnode) from patents p1, paten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>wiki-tree03-augA3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=8)</td>\n",
       "      <td>select MIN(p3b.fromnode) from wiki p1, wiki p2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>wiki-tree03-augA4</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 1, 4]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=8)</td>\n",
       "      <td>select MIN(p4a.fromnode) from wiki p1, wiki p2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>wiki-tree03-augA5</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 1, 3]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=8)</td>\n",
       "      <td>select MIN(p4b.fromnode) from wiki p1, wiki p2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>wiki-tree03-augA6</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[1, 1, 3, 2]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=8)</td>\n",
       "      <td>select MIN(p5a.fromnode) from wiki p1, wiki p2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>wiki-tree03-augA7</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]</td>\n",
       "      <td>[2, 1, 2, 2]</td>\n",
       "      <td>Hypergraph(num_v=16, num_e=8)</td>\n",
       "      <td>select MIN(p5b.fromnode) from wiki p1, wiki p2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bench                 query orig/rewr(mean) orig/rewr+rewr(mean)  \\\n",
       "2031  SNAP        patents-path08               -                    -   \n",
       "2032  SNAP  patents-path08-augA1               -                    -   \n",
       "2033  SNAP  patents-path08-augA2               -                    -   \n",
       "2034  SNAP  patents-path08-augA3               -                    -   \n",
       "2035  SNAP  patents-path08-augA4               -                    -   \n",
       "...    ...                   ...             ...                  ...   \n",
       "2115  SNAP     wiki-tree03-augA3               -                    -   \n",
       "2116  SNAP     wiki-tree03-augA4               -                    -   \n",
       "2117  SNAP     wiki-tree03-augA5               -                    -   \n",
       "2118  SNAP     wiki-tree03-augA6               -                    -   \n",
       "2119  SNAP     wiki-tree03-augA7               -                    -   \n",
       "\n",
       "      orig mean  rewr mean  rewr mean+rewr  diff rewr-orig  \\\n",
       "2031      100.0      100.0           100.0             0.0   \n",
       "2032      100.0      100.0           100.0             0.0   \n",
       "2033      100.0      100.0           100.0             0.0   \n",
       "2034      100.0      100.0           100.0             0.0   \n",
       "2035      100.0      100.0           100.0             0.0   \n",
       "...         ...        ...             ...             ...   \n",
       "2115      100.0      100.0           100.0             0.0   \n",
       "2116      100.0      100.0           100.0             0.0   \n",
       "2117      100.0      100.0           100.0             0.0   \n",
       "2118      100.0      100.0           100.0             0.0   \n",
       "2119      100.0      100.0           100.0             0.0   \n",
       "\n",
       "      diff rewr+rewr-orig  #relations  ...  max(branching factors)  \\\n",
       "2031                  0.0           9  ...                       2   \n",
       "2032                  0.0           9  ...                       2   \n",
       "2033                  0.0           9  ...                       2   \n",
       "2034                  0.0           9  ...                       2   \n",
       "2035                  0.0           9  ...                       2   \n",
       "...                   ...         ...  ...                     ...   \n",
       "2115                  0.0           8  ...                       4   \n",
       "2116                  0.0           8  ...                       4   \n",
       "2117                  0.0           8  ...                       3   \n",
       "2118                  0.0           8  ...                       3   \n",
       "2119                  0.0           8  ...                       2   \n",
       "\n",
       "      mean(branching factors)  median(branching factors)  \\\n",
       "2031                 1.142857                        1.0   \n",
       "2032                 1.142857                        1.0   \n",
       "2033                 1.142857                        1.0   \n",
       "2034                 1.142857                        1.0   \n",
       "2035                 1.142857                        1.0   \n",
       "...                       ...                        ...   \n",
       "2115                 1.750000                        1.0   \n",
       "2116                 1.750000                        1.0   \n",
       "2117                 1.750000                        1.5   \n",
       "2118                 1.750000                        1.5   \n",
       "2119                 1.750000                        2.0   \n",
       "\n",
       "      q25(branching factors)  q75(branching factors)  balancedness factor  \\\n",
       "2031                    1.00                    1.00             1.000000   \n",
       "2032                    1.00                    1.00             1.000000   \n",
       "2033                    1.00                    1.00             1.000000   \n",
       "2034                    1.00                    1.00             1.000000   \n",
       "2035                    1.00                    1.00             1.000000   \n",
       "...                      ...                     ...                  ...   \n",
       "2115                    1.00                    1.75             1.000000   \n",
       "2116                    1.00                    1.75             1.000000   \n",
       "2117                    1.00                    2.25             0.666667   \n",
       "2118                    1.00                    2.25             0.625000   \n",
       "2119                    1.75                    2.00             0.511111   \n",
       "\n",
       "                                  container counts list  \\\n",
       "2031  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2032  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2033  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2034  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2035  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "2115            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2116            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2117            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2118            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "2119            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]   \n",
       "\n",
       "      branching factors list                     hypergraph  \\\n",
       "2031   [1, 1, 1, 1, 1, 1, 2]  Hypergraph(num_v=18, num_e=9)   \n",
       "2032   [1, 1, 1, 1, 1, 1, 2]  Hypergraph(num_v=18, num_e=9)   \n",
       "2033   [1, 1, 1, 1, 1, 1, 2]  Hypergraph(num_v=18, num_e=9)   \n",
       "2034   [1, 1, 1, 1, 1, 1, 2]  Hypergraph(num_v=18, num_e=9)   \n",
       "2035   [1, 1, 1, 1, 1, 1, 2]  Hypergraph(num_v=18, num_e=9)   \n",
       "...                      ...                            ...   \n",
       "2115            [1, 1, 1, 4]  Hypergraph(num_v=16, num_e=8)   \n",
       "2116            [1, 1, 1, 4]  Hypergraph(num_v=16, num_e=8)   \n",
       "2117            [2, 1, 1, 3]  Hypergraph(num_v=16, num_e=8)   \n",
       "2118            [1, 1, 3, 2]  Hypergraph(num_v=16, num_e=8)   \n",
       "2119            [2, 1, 2, 2]  Hypergraph(num_v=16, num_e=8)   \n",
       "\n",
       "                                                   text  \n",
       "2031  select MIN(p1.toNode) from patents p1, patents...  \n",
       "2032  select MIN(p2.fromnode) from patents p1, paten...  \n",
       "2033  select MIN(p3.fromnode) from patents p1, paten...  \n",
       "2034  select MIN(p4.fromnode) from patents p1, paten...  \n",
       "2035  select MIN(p5.fromnode) from patents p1, paten...  \n",
       "...                                                 ...  \n",
       "2115  select MIN(p3b.fromnode) from wiki p1, wiki p2...  \n",
       "2116  select MIN(p4a.fromnode) from wiki p1, wiki p2...  \n",
       "2117  select MIN(p4b.fromnode) from wiki p1, wiki p2...  \n",
       "2118  select MIN(p5a.fromnode) from wiki p1, wiki p2...  \n",
       "2119  select MIN(p5b.fromnode) from wiki p1, wiki p2...  \n",
       "\n",
       "[75 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"orig/rewr(mean)\"] == \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c2c1f-0061-469e-b69e-5e75d817971a",
   "metadata": {},
   "source": [
    "For the SNAP dataset the wiki-path06, wiki-path07, wiki-path08 and wiki-tree03 (for all augmentation cases) did not finish the evaluation within our timeout (100 sec). Therefore, we cannot conclude which variante is the better one and we delete those 32 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfd9e955-6bdd-45d8-87d7-38a43f7a29f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2861, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"orig/rewr(mean)\"] != \"-\"]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e2a1a-b513-4bd9-a009-4a197c91f4e1",
   "metadata": {},
   "source": [
    "#### Get the feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051cdd4-5edf-4f3e-a0c8-06f3a5e0b275",
   "metadata": {},
   "source": [
    "Get the features matrix X and the response variables y1 and y1, where once the rewritting time and the evaluation time are taken into consideration and once only the evaluation time. Additionally the response variables have to have numbers in it and we assign 1 = rewr and 0 = orig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9705deff-9dac-4389-9793-0ca787300662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#relations</th>\n",
       "      <th>#conditions</th>\n",
       "      <th>#filters</th>\n",
       "      <th>#joins</th>\n",
       "      <th>depth</th>\n",
       "      <th>min(container counts)</th>\n",
       "      <th>max(container counts)</th>\n",
       "      <th>mean(container counts)</th>\n",
       "      <th>q25(container counts)</th>\n",
       "      <th>median(container counts)</th>\n",
       "      <th>q75(container counts)</th>\n",
       "      <th>min(branching factors)</th>\n",
       "      <th>max(branching factors)</th>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <th>median(branching factors)</th>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #relations  #conditions  #filters  #joins  depth  min(container counts)  \\\n",
       "0           3            7         5       2      1                      1   \n",
       "1           3            7         5       2      2                      1   \n",
       "2           3            7         5       2      2                      1   \n",
       "3           3            7         5       2      1                      1   \n",
       "4           3            7         5       2      2                      1   \n",
       "\n",
       "   max(container counts)  mean(container counts)  q25(container counts)  \\\n",
       "0                      3                1.133333                    1.0   \n",
       "1                      3                1.133333                    1.0   \n",
       "2                      3                1.133333                    1.0   \n",
       "3                      3                1.133333                    1.0   \n",
       "4                      3                1.133333                    1.0   \n",
       "\n",
       "   median(container counts)  q75(container counts)  min(branching factors)  \\\n",
       "0                       1.0                    1.0                       2   \n",
       "1                       1.0                    1.0                       1   \n",
       "2                       1.0                    1.0                       1   \n",
       "3                       1.0                    1.0                       2   \n",
       "4                       1.0                    1.0                       1   \n",
       "\n",
       "   max(branching factors)  mean(branching factors)  median(branching factors)  \\\n",
       "0                       2                      2.0                        2.0   \n",
       "1                       1                      1.0                        1.0   \n",
       "2                       1                      1.0                        1.0   \n",
       "3                       2                      2.0                        2.0   \n",
       "4                       1                      1.0                        1.0   \n",
       "\n",
       "   q25(branching factors)  q75(branching factors)  \n",
       "0                     2.0                     2.0  \n",
       "1                     1.0                     1.0  \n",
       "2                     1.0                     1.0  \n",
       "3                     2.0                     2.0  \n",
       "4                     1.0                     1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 9:26]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b1b77f-8f98-43c9-bba2-47a0578364f4",
   "metadata": {},
   "source": [
    "Get the feature matrix, which additionally includes the hypergraph information/representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77b07433-fea3-4534-afe5-4c533884d15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#relations</th>\n",
       "      <th>#conditions</th>\n",
       "      <th>#filters</th>\n",
       "      <th>#joins</th>\n",
       "      <th>depth</th>\n",
       "      <th>min(container counts)</th>\n",
       "      <th>max(container counts)</th>\n",
       "      <th>mean(container counts)</th>\n",
       "      <th>q25(container counts)</th>\n",
       "      <th>median(container counts)</th>\n",
       "      <th>q75(container counts)</th>\n",
       "      <th>min(branching factors)</th>\n",
       "      <th>max(branching factors)</th>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <th>median(branching factors)</th>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <th>hypergraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hypergraph(num_v=17, num_e=3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #relations  #conditions  #filters  #joins  depth  min(container counts)  \\\n",
       "0           3            7         5       2      1                      1   \n",
       "1           3            7         5       2      2                      1   \n",
       "2           3            7         5       2      2                      1   \n",
       "3           3            7         5       2      1                      1   \n",
       "4           3            7         5       2      2                      1   \n",
       "\n",
       "   max(container counts)  mean(container counts)  q25(container counts)  \\\n",
       "0                      3                1.133333                    1.0   \n",
       "1                      3                1.133333                    1.0   \n",
       "2                      3                1.133333                    1.0   \n",
       "3                      3                1.133333                    1.0   \n",
       "4                      3                1.133333                    1.0   \n",
       "\n",
       "   median(container counts)  q75(container counts)  min(branching factors)  \\\n",
       "0                       1.0                    1.0                       2   \n",
       "1                       1.0                    1.0                       1   \n",
       "2                       1.0                    1.0                       1   \n",
       "3                       1.0                    1.0                       2   \n",
       "4                       1.0                    1.0                       1   \n",
       "\n",
       "   max(branching factors)  mean(branching factors)  median(branching factors)  \\\n",
       "0                       2                      2.0                        2.0   \n",
       "1                       1                      1.0                        1.0   \n",
       "2                       1                      1.0                        1.0   \n",
       "3                       2                      2.0                        2.0   \n",
       "4                       1                      1.0                        1.0   \n",
       "\n",
       "   q25(branching factors)  q75(branching factors)  \\\n",
       "0                     2.0                     2.0   \n",
       "1                     1.0                     1.0   \n",
       "2                     1.0                     1.0   \n",
       "3                     2.0                     2.0   \n",
       "4                     1.0                     1.0   \n",
       "\n",
       "                      hypergraph  \n",
       "0  Hypergraph(num_v=17, num_e=3)  \n",
       "1  Hypergraph(num_v=17, num_e=3)  \n",
       "2  Hypergraph(num_v=17, num_e=3)  \n",
       "3  Hypergraph(num_v=17, num_e=3)  \n",
       "4  Hypergraph(num_v=17, num_e=3)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hg = pd.concat([X, df.iloc[:,29]], axis = 1)\n",
    "X_hg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cfe523",
   "metadata": {},
   "source": [
    "#### Log-transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9181de3-7d58-4f5f-a636-993cd9410ff9",
   "metadata": {},
   "source": [
    "This basic features do not need log transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "924ce8ed-0ac2-46d3-afb0-6a500537e4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#relations</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#conditions</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#filters</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#joins</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depth</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min(container counts)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max(container counts)</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean(container counts)</th>\n",
       "      <td>1.047619</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.552381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q25(container counts)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median(container counts)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q75(container counts)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q25(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q75(branching factors)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Min   Max       Diff\n",
       "#relations                 2.000000  11.0   9.000000\n",
       "#conditions                2.000000  20.0  18.000000\n",
       "#filters                   0.000000  16.0  16.000000\n",
       "#joins                     1.000000  12.0  11.000000\n",
       "depth                      1.000000   7.0   6.000000\n",
       "min(container counts)      1.000000   1.0   0.000000\n",
       "max(container counts)      2.000000   5.0   3.000000\n",
       "mean(container counts)     1.047619   1.6   0.552381\n",
       "q25(container counts)      1.000000   1.0   0.000000\n",
       "median(container counts)   1.000000   1.0   0.000000\n",
       "q75(container counts)      1.000000   1.0   0.000000\n",
       "min(branching factors)     1.000000   6.0   5.000000\n",
       "max(branching factors)     1.000000   6.0   5.000000\n",
       "mean(branching factors)    1.000000   6.0   5.000000\n",
       "median(branching factors)  1.000000   6.0   5.000000\n",
       "q25(branching factors)     1.000000   6.0   5.000000\n",
       "q75(branching factors)     1.000000   6.0   5.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_values = X.min()\n",
    "max_values = X.max()\n",
    "diff = max_values-min_values\n",
    "\n",
    "pd.DataFrame({'Min': min_values, 'Max': max_values, 'Diff': diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "859f1fb1-725a-4c2e-b7ba-53a84946f954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2500 with 33 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.hist(layout=(11, 3), figsize=(20, 25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c64d7-8ae9-4958-80b0-459e6b9dc269",
   "metadata": {},
   "source": [
    "#### Boxplots of running times for both cases (either original or rewritten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "028d16a2-be30-48b4-849d-7075488c566a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_orig = df[df['orig/rewr(mean)'] == 'orig']\n",
    "df_rewr = df[df['orig/rewr(mean)'] == 'rewr']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "sns.boxplot(y='orig mean', data=df, ax=axes[0,0])\n",
    "axes[0,0].set_title(f'Boxplot for orig')\n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df, ax=axes[0,1])\n",
    "axes[0,1].set_title(f'Boxplot for rewr')\n",
    "\n",
    "sns.boxplot(y='orig mean', data=df_orig, ax=axes[1,0])\n",
    "axes[1,0].set_title(f'Boxplot for orig if \"orig\"')\n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df_rewr, ax=axes[1,1])\n",
    "axes[1,1].set_title(f'Boxplot for rewr if \"rewr\"')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d876a-cba4-444a-964d-6c8333730182",
   "metadata": {},
   "source": [
    "The runtimes are highly skewed. Therefore, we log transform them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a68388f2-759e-4d72-b5ef-a3cf151254eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_log = df.copy()\n",
    "df_log[\"orig mean\"] = np.log(df_log[\"orig mean\"])\n",
    "df_log[\"rewr mean\"] = np.log(df_log[\"rewr mean\"])\n",
    "\n",
    "df_orig = df_log[df_log['orig/rewr(mean)'] == 'orig']\n",
    "df_rewr = df_log[df_log['orig/rewr(mean)'] == 'rewr']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12,7))\n",
    "\n",
    "sns.boxplot(y='orig mean', data=df_log, ax=axes[0,0])\n",
    "axes[0,0].set_title(f'log(runtimes for original queries)')\n",
    "axes[0,0].set_ylabel(\"log(mean original runtime)\")\n",
    "axes[0,0].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df_log, ax=axes[0,1])\n",
    "axes[0,1].set_title(f'log(runtimes for rewritten queries)')\n",
    "axes[0,1].set_ylabel(\"log(mean rewritten runtime)\")\n",
    "axes[0,1].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='orig mean', data=df_orig, ax=axes[1,0])\n",
    "axes[1,0].set_title(f'log(runtimes for original queries) if \"orig\"')\n",
    "axes[1,0].set_ylabel(\"log(mean original runtime)\")\n",
    "axes[1,0].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df_rewr, ax=axes[1,1])\n",
    "axes[1,1].set_title(f'log(runtimes for rewritten queries) if \"rewr\"')\n",
    "axes[1,1].set_ylabel(\"log(mean rewritten runtime)\")\n",
    "axes[1,1].set_ylim(-8, 6) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26bb11d8-54b5-41b1-9d5c-58319eed0546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_log = df.copy()\n",
    "df_log[\"orig mean\"] = np.log(df_log[\"orig mean\"])\n",
    "df_log[\"rewr mean\"] = np.log(df_log[\"rewr mean\"])\n",
    "\n",
    "df_orig = df_log[df_log['orig/rewr(mean)'] == 'orig']\n",
    "df_rewr = df_log[df_log['orig/rewr(mean)'] == 'rewr']\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(15,4))\n",
    "\n",
    "sns.boxplot(y='orig mean', data=df_log, ax=axes[0])\n",
    "axes[0].set_title(f'log(runtimes for original queries)')\n",
    "axes[0].set_ylabel(\"log(mean original runtime)\")\n",
    "axes[0].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df_log, ax=axes[1])\n",
    "axes[1].set_title(f'log(runtimes for rewritten queries)')\n",
    "axes[1].set_ylabel(\"log(mean rewritten runtime)\")\n",
    "axes[1].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='orig mean', data=df_orig, ax=axes[2])\n",
    "axes[2].set_title(f'log(runtimes for original queries) if \"orig\"')\n",
    "axes[2].set_ylabel(\"log(mean original runtime)\")\n",
    "axes[2].set_ylim(-8, 6) \n",
    "\n",
    "sns.boxplot(y='rewr mean', data=df_rewr, ax=axes[3])\n",
    "axes[3].set_title(f'log(runtimes for rewritten queries) if \"rewr\"')\n",
    "axes[3].set_ylabel(\"log(mean rewritten runtime)\")\n",
    "axes[3].set_ylim(-8, 6) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c2d0a8-40ce-491c-9c2d-ccfa025da321",
   "metadata": {},
   "source": [
    "#### Scatterplot of running times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75f9c32f-53a7-4964-b987-25d1d1bd165d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=\"orig mean\", y=\"rewr mean\", data=df)\n",
    "sns.regplot(x=\"orig mean\", y=\"rewr mean\", data=df) \n",
    "\n",
    "plt.xlabel(\"original\")\n",
    "plt.ylabel(\"rewritten\")\n",
    "plt.title(f'Running times')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9364cbe-722c-495e-b3f2-6d115eb118f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=\"orig mean\", y=\"rewr mean\", data=df_log)\n",
    "sns.regplot(x=\"orig mean\", y=\"rewr mean\", data=df_log) \n",
    "\n",
    "plt.xlabel(\"original\")\n",
    "plt.ylabel(\"rewritten\")\n",
    "plt.title(f'Running times')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab4756-1755-4f8e-b098-47eabebf67bb",
   "metadata": {},
   "source": [
    "#### Classification response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43482284-5f2c-409e-83a6-70f86c2b6c75",
   "metadata": {},
   "source": [
    "Get the column(s) where we have \"orig\" or \"rewr\", depending on which method was faster. We now want to encode this as 0 (evaluating the original query faster) and 1 (evaluating the rewritten query faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7f20f22-c2dc-4124-848a-358bd736f54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: orig/rewr(mean), dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {'orig': 0, 'rewr': 1}\n",
    "y1 = df['orig/rewr(mean)'].map(mapping)\n",
    "y1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe610bf9-f34c-48f4-8cea-0a0916f82544",
   "metadata": {},
   "source": [
    "The number of appearances of original and rewritten is very balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdeaa90b-2268-467f-85d7-d0d934f557ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orig/rewr(mean)\n",
       "0    1542\n",
       "1    1319\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0380130-a50b-449a-9f1f-89905b6d7f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orig     1319\n",
       "rewr     1542\n",
       "equal       -\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = y1.value_counts().tolist()[::-1] + [\"-\"]\n",
    "count = pd.Series(count)\n",
    "count.index = [\"orig\", \"rewr\", \"equal\"]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73f73e0e-4bf0-461b-ba44-a391422285ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orig/rewr(mean)\n",
       "orig    1542\n",
       "rewr    1319\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"orig/rewr(mean)\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9d951",
   "metadata": {},
   "source": [
    "#### Classification response with three cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcbb5f18-bed4-452b-8e04-63b3c8856c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = abs(df[\"diff rewr-orig\"]) < 0.5\n",
    "df[\"orig/rewr/equal 0.5\"] = df[\"orig/rewr(mean)\"]\n",
    "df.loc[condition, 'orig/rewr/equal 0.5'] = 'equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f016c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = abs(df[\"diff rewr-orig\"]) < 0.1\n",
    "df[\"orig/rewr/equal 0.1\"] = df[\"orig/rewr(mean)\"]\n",
    "df.loc[condition, 'orig/rewr/equal 0.1'] = 'equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12ba1cc1-840b-4e38-86dd-770cbfd8fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = abs(df[\"diff rewr-orig\"]) < 0.05\n",
    "df[\"orig/rewr/equal 0.05\"] = df[\"orig/rewr(mean)\"]\n",
    "df.loc[condition, 'orig/rewr/equal 0.05'] = 'equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27259c2b-7ed2-49d4-b7da-072ddaf6ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = abs(df[\"diff rewr-orig\"]) < 0.01\n",
    "df[\"orig/rewr/equal 0.01\"] = df[\"orig/rewr(mean)\"]\n",
    "df.loc[condition, 'orig/rewr/equal 0.01'] = 'equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fed583b-c5f2-41ee-a51f-7e2565c35531",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_05 = df[\"orig/rewr/equal 0.5\"].value_counts()\n",
    "count_01 = df[\"orig/rewr/equal 0.1\"].value_counts()\n",
    "count_005 = df[\"orig/rewr/equal 0.05\"].value_counts()\n",
    "count_001 = df[\"orig/rewr/equal 0.01\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8b56a22-ce06-421b-b91d-d757b91ef823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orig/rewr/equal 0.01\n",
       "orig     1503\n",
       "rewr     1276\n",
       "equal      82\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d9916a3-cd4d-457d-80f6-92bf9beeecf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2 classes</th>\n",
       "      <th>3 classes (0.01)</th>\n",
       "      <th>3 classes (0.05)</th>\n",
       "      <th>3 classes (0.1)</th>\n",
       "      <th>3 classes (0.5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orig</th>\n",
       "      <td>1319</td>\n",
       "      <td>1276</td>\n",
       "      <td>1113</td>\n",
       "      <td>1009</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rewr</th>\n",
       "      <td>1542</td>\n",
       "      <td>1503</td>\n",
       "      <td>1292</td>\n",
       "      <td>1100</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal</th>\n",
       "      <td>-</td>\n",
       "      <td>82</td>\n",
       "      <td>456</td>\n",
       "      <td>752</td>\n",
       "      <td>1515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2 classes  3 classes (0.01)  3 classes (0.05)  3 classes (0.1)  \\\n",
       "orig       1319              1276              1113             1009   \n",
       "rewr       1542              1503              1292             1100   \n",
       "equal         -                82               456              752   \n",
       "\n",
       "       3 classes (0.5)  \n",
       "orig               797  \n",
       "rewr               549  \n",
       "equal             1515  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.concat([count_001, count_005, count_01, count_05], axis = 1)\n",
    "counts.iloc[[0, 1]] = counts.iloc[[1, 0]].values\n",
    "counts.index = [\"orig\", \"rewr\", \"equal\"]\n",
    "counts = pd.concat([count, counts], axis = 1)\n",
    "counts.columns = [\"2 classes\", \"3 classes (0.01)\", \"3 classes (0.05)\", \"3 classes (0.1)\", \"3 classes (0.5)\"]\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d408dfb-744c-4d1a-87d7-17b2a1d8db97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: orig/rewr/equal 0.5, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping1 = {'orig': -1, 'rewr': 1, 'equal': 0}\n",
    "y1_equal_05 = df['orig/rewr/equal 0.5'].map(mapping1)\n",
    "y1_equal_05.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "deb2d1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: orig/rewr/equal 0.1, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping1 = {'orig': -1, 'rewr': 1, 'equal': 0}\n",
    "y1_equal_01 = df['orig/rewr/equal 0.1'].map(mapping1)\n",
    "y1_equal_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f46f329-1b16-4eaf-b4ca-9de8397ebe6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: orig/rewr/equal 0.05, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping1 = {'orig': -1, 'rewr': 1, 'equal': 0}\n",
    "y1_equal_005 = df['orig/rewr/equal 0.05'].map(mapping1)\n",
    "y1_equal_005.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83649da4-7654-401d-9ad7-531bf0131699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2   -1\n",
       "3   -1\n",
       "4    1\n",
       "Name: orig/rewr/equal 0.01, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping1 = {'orig': -1, 'rewr': 1, 'equal': 0}\n",
    "y1_equal_001 = df['orig/rewr/equal 0.01'].map(mapping1)\n",
    "y1_equal_001.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f36e3c7-f02a-4839-a2c1-44ef230fca30",
   "metadata": {},
   "source": [
    "#### Regression response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3500e7-c23e-4260-91de-28f12692ccce",
   "metadata": {},
   "source": [
    "We also have the time differences between the original and rewritten method and we want to use that as numerical response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67b9da20-d496-465e-8908-e33912027a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_diff = df[\"diff rewr-orig\"]\n",
    "#y1_diff = df[\"diff rewr+rewr-orig\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1956a25f-ceda-4e69-8f6e-8a237c02bb0a",
   "metadata": {},
   "source": [
    "We can see that the time difference has a wide range of values (or is skewed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea0abb17-d02c-471b-b167-4ddcc396abfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y1_diff.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d418aa-e1e5-47d6-a903-c1a83f9667d0",
   "metadata": {},
   "source": [
    "Therefore, we are going to transform it. As before with the features, we would like to apply a log transformation. Neverthless, since we have negative values this cannot be applied directly. We are going to multiple to log of the absolute values with the sign they had before. Additionally, since we have a lot of values close to zero, which leads to very low log values, we add 1 to the absolute values, which is a common method.   \n",
    "$x = sgn(x) * log(|x| + 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88002661-c5ff-4368-8bcb-d256457b72ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y1_diff_log = np.sign(y1_diff) * np.log(abs(y1_diff) +1)\n",
    "y1_diff_log.hist(bins = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc35a4c8-f8ce-49ce-bdcc-6911a920c5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAGGCAYAAACqvTJ0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACFHUlEQVR4nOzdeVwW5f7/8fcNsgkCogKSimtu4RKWkWtK4pLl0epUprikZaippebJ3RTTStOvZXUKrfRYdtLKTMXdFE0pyi1S07AELBXIjXV+f/hjTreAAsLN9no+HvOQueaamc81c8N9+ZmZayyGYRgCAAAAAAAAbMiupAMAAAAAAABAxUNSCgAAAAAAADZHUgoAAAAAAAA2R1IKAAAAAAAANkdSCgAAAAAAADZHUgoAAAAAAAA2R1IKAAAAAAAANkdSCgAAAAAAADZHUgoAAAAAAAA2R1IKKCF169bVoEGDSjqMcm/+/PmqX7++7O3t1apVqwKvf+rUKVksFi1btqzIYytq13+mtm/fLovFou3bt1vV+/DDD9WkSRM5ODjI09PTLL/VYwUAKDn0K2yjPH5XZmRkaMKECapdu7bs7OzUp0+fkg6pyNzq78X06dNlsViKLqBiklufb9CgQapbt65VvYsXL+qpp56Sr6+vLBaLxowZI0lKTEzUww8/rGrVqslisWjhwoU2ix0gKQUUgWXLlslisejAgQO5Lu/cubPuuOOOW97P+vXrNX369FveTkWxadMmTZgwQe3atVNERITmzJmTZ92VK1dWiC/gn376SYMGDVKDBg307rvv6p133pFUsGMFAChe9CtKp/Lar3j//fc1f/58Pfzww1q+fLnGjh1b0iHZ1OXLlzV9+vQcF/HKozlz5mjZsmUaMWKEPvzwQw0YMECSNHbsWG3cuFGTJk3Shx9+qO7du5dwpKhIKpV0AEBFFRsbKzu7guWF169fryVLltCBzKetW7fKzs5O7733nhwdHW9Yd+XKlTp06JB5xSibv7+/rly5IgcHh2KMtHh07NhRV65csWr79u3blZWVpTfeeEMNGzY0ywtyrAAApQ/9iuJXFP2K0mjr1q267bbbtGDBgpIOpURcvnxZM2bMkHQt4ft3kydP1osvvlgCUd26d999V1lZWVZlW7du1T333KNp06blKH/ooYf0wgsv2DJEQBJ3SgElxsnJqcwlOi5dulTSIRTI2bNn5eLicktJFovFImdnZ9nb2xdhZLZhZ2cnZ2dnq/+knD17VpKsHtvLLr/VY3W9y5cvF9m2AAA3Rr+i+BXHd6UkXb16NUfywJbOnj2bo19wK7KysnT16tUi215JqlSpkpydnUs6jEJxcHCQk5OTVVle57qoPwMZGRlKS0srsu2hfCMpBZSQ659xT09P14wZM9SoUSM5OzurWrVqat++vSIjIyVdey58yZIlkq4lSrKnbJcuXdLzzz+v2rVry8nJSY0bN9arr74qwzCs9nvlyhWNHj1a1atXV5UqVfTggw/q999/l8VisbpSmv0M/ZEjR/TEE0+oatWqat++vSTpxx9/1KBBg1S/fn05OzvL19dXQ4YM0blz56z2lb2Nn3/+WU8++aQ8PDxUo0YNTZkyRYZh6PTp03rooYfk7u4uX19fvfbaa/k6dhkZGZo1a5YaNGggJycn1a1bV//617+Umppq1rFYLIqIiNClS5fMY5XXuFCdO3fWV199pV9//dWsm/0Mfm5jSg0aNEhubm6Ki4vTAw88IDc3N912223m+Tl48KC6dOkiV1dX+fv7a+XKlTn2mZSUpDFjxpjnq2HDhnrllVfy1Sk1DEMvv/yyatWqpcqVK+u+++7T4cOHc9S7fnyBunXrmlfGatSoYZ7zmx2rjz76SIGBgXJxcZGXl5cee+wxnT59OscxvOOOOxQdHa2OHTuqcuXK+te//iVJSk1N1bRp09SwYUM5OTmpdu3amjBhgtX5kq6ds5EjR2rt2rW644475OTkpObNm2vDhg052vb7779r6NCh8vPzk5OTk+rVq6cRI0ZYdYDye4xXrVqlwMBAValSRe7u7goICNAbb7xx0/MAAKUJ/Yqy0a/I/m5etWqVJk+erNtuu02VK1dWSkqKzp8/rxdeeEEBAQFyc3OTu7u7evTooR9++MFq+9nb+OSTTzR79mzVqlVLzs7O6tq1q44fP25V99ixY+rXr598fX3l7OysWrVq6bHHHlNycrLZx9m2bZsOHz5sxprdb8jvZyD7+3vFihVq3ry5nJyctGHDBvMx1G+++UajR49WjRo15OnpqaefflppaWlKSkrSwIEDVbVqVVWtWlUTJkzIse2srCwtXLhQzZs3l7Ozs3x8fPT000/rwoULVvXy2ze63qlTp1SjRg1J0owZM8xjkP3ZzW1Mqez2rl69Ws2aNZOLi4uCgoJ08OBBSdLbb7+thg0bytnZWZ07d9apU6dy7Hffvn3q3r27PDw8VLlyZXXq1Em7d+++abyS9Ntvv6lPnz5ydXWVt7e3xo4dm6NPJVmPKZX9mTl58qS++uorq8+wxWKRYRhasmRJjr8D+elLZX+OXn31VS1cuND8PTpy5Iika0NHPPzww/Ly8pKzs7PatGmjL774wirW7Dh2796tcePGqUaNGnJ1ddU//vEP/fHHHzna9vXXX6tTp05m3+2uu+7K0d/OzzH+66+/NGbMGNWtW1dOTk7y9vbW/fffr++++y5f5wJFg8f3gCKUnJysP//8M0d5enr6TdedPn26wsPD9dRTT+nuu+9WSkqKDhw4oO+++07333+/nn76aZ05c0aRkZH68MMPrdY1DEMPPvigtm3bpqFDh6pVq1bauHGjxo8fr99//93qduxBgwbpk08+0YABA3TPPfdox44d6tWrV55xPfLII2rUqJHmzJljdhQiIyP1yy+/aPDgwfL19dXhw4f1zjvv6PDhw9q7d2+OL+9//vOfatq0qebOnauvvvpKL7/8sry8vPT222+rS5cueuWVV7RixQq98MILuuuuu9SxY8cbHqunnnpKy5cv18MPP6znn39e+/btU3h4uI4ePao1a9ZIujaY9zvvvKNvv/1W//73vyVJ9957b67be+mll5ScnKzffvvNPFZubm43jCEzM1M9evRQx44dNW/ePK1YsUIjR46Uq6urXnrpJfXv3199+/bV0qVLNXDgQAUFBalevXqSrt1B1KlTJ/3+++96+umnVadOHe3Zs0eTJk1SfHz8TcegmDp1ql5++WX17NlTPXv21Hfffadu3brd9IrUwoUL9cEHH2jNmjV666235ObmphYtWqhhw4Z5HqvZs2drypQpevTRR/XUU0/pjz/+0OLFi9WxY0d9//33VlfVzp07px49euixxx7Tk08+KR8fH2VlZenBBx/UN998o+HDh6tp06Y6ePCgFixYoJ9//llr1661ivGbb77RZ599pmeffVZVqlTRokWL1K9fP8XFxalatWqSpDNnzujuu+9WUlKShg8friZNmuj333/Xp59+qsuXL8vR0THfxzgyMlKPP/64unbtqldeeUWSdPToUe3evVvPPffcDY8nABQ3+hXlt18xa9YsOTo66oUXXlBqaqocHR115MgRrV27Vo888ojq1aunxMREvf322+rUqZOOHDkiPz8/q23MnTtXdnZ2euGFF5ScnKx58+apf//+2rdvnyQpLS1NISEhSk1N1ahRo+Tr66vff/9d69atU1JSkmrUqKEPP/xQs2fP1sWLFxUeHi5Jatq0aYE+A9K1x78++eQTjRw5UtWrV1fdunUVExMjSea+Z8yYob179+qdd96Rp6en9uzZozp16mjOnDlav3695s+frzvuuEMDBw40t/v0009r2bJlGjx4sEaPHq2TJ0/q//7v//T9999r9+7d5t2Bhe0b1ahRQ2+99ZZGjBihf/zjH+rbt68kqUWLFjdcb9euXfriiy8UFhYmSQoPD9cDDzygCRMm6M0339Szzz6rCxcuaN68eRoyZIi2bt1qdax69OihwMBATZs2TXZ2doqIiFCXLl20a9cu3X333Xnu98qVK+ratavi4uI0evRo+fn56cMPP7Tafm6aNm2qDz/8UGPHjlWtWrX0/PPPS5Jat25tji11//33Wx37gvZXIyIidPXqVQ0fPlxOTk7y8vLS4cOH1a5dO91222168cUX5erqqk8++UR9+vTRf//7X/3jH/+w2saoUaNUtWpVTZs2TadOndLChQs1cuRIffzxx2adZcuWaciQIWrevLkmTZokT09Pff/999qwYYOeeOKJAh3jZ555Rp9++qlGjhypZs2a6dy5c/rmm2909OhR3XnnnTc8pihCBoBbFhERYUi64dS8eXOrdfz9/Y3Q0FBzvmXLlkavXr1uuJ+wsDAjt1/btWvXGpKMl19+2ar84YcfNiwWi3H8+HHDMAwjOjrakGSMGTPGqt6gQYMMSca0adPMsmnTphmSjMcffzzH/i5fvpyj7D//+Y8hydi5c2eObQwfPtwsy8jIMGrVqmVYLBZj7ty5ZvmFCxcMFxcXq2OSm5iYGEOS8dRTT1mVv/DCC4YkY+vWrWZZaGio4erqesPtZevVq5fh7++fo/zkyZOGJCMiIsJqu5KMOXPm5IjfYrEYq1atMst/+umnHMd21qxZhqurq/Hzzz9b7evFF1807O3tjbi4uDzjPHv2rOHo6Gj06tXLyMrKMsv/9a9/GZKsjt+2bdsMSca2bdvMsuxz8scff1htN7djderUKcPe3t6YPXu2VfnBgweNSpUqWZV36tTJkGQsXbrUqu6HH35o2NnZGbt27bIqX7p0qSHJ2L17t1kmyXB0dDQ/r4ZhGD/88IMhyVi8eLFZNnDgQMPOzs7Yv39/juOTfUzye4yfe+45w93d3cjIyMixLQAoKfQrym+/Ivu7uX79+jnaffXqVSMzM9Oq7OTJk4aTk5Mxc+bMHNto2rSpkZqaapa/8cYbhiTj4MGDhmEYxvfff29IMlavXn3DWDt16pTj85Tfz4BhXPv+trOzMw4fPmxVN/tzHBISYtVnCQoKMiwWi/HMM8+YZdnnsVOnTmbZrl27DEnGihUrrLa7YcMGq/KC9I1y88cff+T4vGbL/sz9nSTDycnJOHnypFn29ttvG5IMX19fIyUlxSyfNGmSIcmsm5WVZTRq1CjHMbl8+bJRr1494/77779hrAsXLjQkGZ988olZdunSJaNhw4Y5+nyhoaE5PoP+/v65/l2QZISFhVmV5bcvld1Xdnd3N86ePWtVt2vXrkZAQIBx9epVsywrK8u49957jUaNGpll2Z+V4OBgq+MyduxYw97e3khKSjIMwzCSkpKMKlWqGG3btjWuXLlita/s9QpyjD08PHK0G7bH43tAEVqyZIkiIyNzTDe72iJdG+Pn8OHDOnbsWIH3u379etnb22v06NFW5c8//7wMw9DXX38tSeZjUM8++6xVvVGjRuW57WeeeSZHmYuLi/nz1atX9eeff+qee+6RpFxvd33qqafMn+3t7dWmTRsZhqGhQ4ea5Z6enmrcuLF++eWXPGORrrVVksaNG2dVnn3F56uvvrrh+kXp7+3Kjt/V1VWPPvqoWd64cWN5enpatWv16tXq0KGDqlatqj///NOcgoODlZmZqZ07d+a5z82bNystLU2jRo2yunJcHAOpfvbZZ8rKytKjjz5qFaevr68aNWqkbdu2WdV3cnLS4MGDrcpWr16tpk2bqkmTJlbb6NKliyTl2EZwcLAaNGhgzrdo0ULu7u7m8cvKytLatWvVu3dvtWnTJkfM2cckv8fY09NTly5dMh9nAYDShH5F+e1XhIaGWrVbuvY9mj0OZGZmps6dOyc3Nzc1btw41+MwePBgq/GtOnToIElmmz08PCRJGzduLPA4j/n9DGTr1KmTmjVrluu2hg4datVnadu2bY7zlX0er+8veXh46P7777f6Lg8MDJSbm5vZh7Bl3yhb165dzUfjstskSf369VOVKlVylGe3KyYmRseOHdMTTzyhc+fOmW26dOmSunbtqp07d95wKIf169erZs2aevjhh82yypUra/jw4UXZPEkF76/269fPfBRSks6fP6+tW7fq0Ucf1V9//WWuf+7cOYWEhOjYsWP6/fffrbYxfPhwq3PYoUMHZWZm6tdff5V07a7Kv/76Sy+++GKOsb6y1yvIMfb09NS+fft05syZojtwKDAe3wOK0N13353rf5Sz/5jfyMyZM/XQQw/p9ttv1x133KHu3btrwIAB+ep4/vrrr/Lz87P6EpSu3aqbvTz7Xzs7O/Mxsmx/fwvb9a6vK137kpkxY4ZWrVplDpydLTk5OUf9OnXqWM17eHjI2dlZ1atXz1F+/fgR18tuw/Ux+/r6ytPT02xrcXN2drb64pWuxV+rVq0cjxl4eHhYjX1w7Ngx/fjjjznWz3b9Mf277PY1atTIqrxGjRqqWrVqgdpwM8eOHZNhGDn2le36AXVvu+22HIO/Hjt2TEePHs13W6//rEjXfn+yj98ff/yhlJSUm74KPb/H+Nlnn9Unn3yiHj166LbbblO3bt306KOP8ipkAKUC/Yry26/I7Thkvx33zTff1MmTJ5WZmWkuy36E/e+uPw7Z/YDs78x69epp3Lhxev3117VixQp16NBBDz74oDke143k9zNwo/bkFWf2vmvXrp2j/Pr+UnJysry9vXPdbvZnxZZ9o2wFaZP0v3OSnSQODQ3Nc9vJycl5xv3rr7+qYcOGOfqajRs3LkD0+VPQ/ur1n4Hjx4/LMAxNmTJFU6ZMyXMbt912mzl/s8/0iRMnJOmG/cCCHON58+YpNDRUtWvXVmBgoHr27KmBAweqfv36ea6LokdSCiglOnbsqBMnTujzzz/Xpk2b9O9//1sLFizQ0qVLra4I2tr1V/Ek6dFHH9WePXs0fvx4tWrVSm5ubsrKylL37t1zvbqT25vr8nqbnXHdAJd5uf7L2Nbyij8/7crKytL999+vCRMm5Fr39ttvv/UAi0BWVpYsFou+/vrrXNt1/fgYuX1WsrKyFBAQoNdffz3XfVzfebvVz8Xf95ufY+zt7a2YmBht3LhRX3/9tb7++mtFRERo4MCBWr58eYH2CQClCf2Ka0prvyK34zBnzhxNmTJFQ4YM0axZs+Tl5SU7OzuNGTMm38dBsm7za6+9pkGDBpmfg9GjRys8PFx79+5VrVq1irU9N4szt/Lr+0ve3t5asWJFruvnlSyxhcL2A7PP4/z589WqVatc695sXFNbKWh/9frPQHZbX3jhBYWEhOS6jeuTwUXRDyzIMX700UfVoUMHrVmzRps2bdL8+fP1yiuv6LPPPlOPHj3yvU/cGpJSQCni5eWlwYMHa/Dgwbp48aI6duyo6dOnm53HvDpM/v7+2rx5s/766y+rK1o//fSTuTz736ysLJ08edLqatL1b2q5kQsXLmjLli2aMWOGpk6dapYX5vGAwshuw7Fjx8yrdZKUmJiopKQks60FZcvOaIMGDXTx4kUFBwcXeN3s9h07dszqKs4ff/yR4000t6pBgwYyDEP16tUrdKKsQYMG+uGHH9S1a9ciOcY1atSQu7u7Dh06dNP95vcYOzo6qnfv3urdu7eysrL07LPP6u2339aUKVNueLUfAEo7+hU3V5r6FZ9++qnuu+8+vffee1blSUlJOe4CK4iAgAAFBARo8uTJ2rNnj9q1a6elS5fq5ZdfznOd/H4GilODBg20efNmtWvX7oZJr1vtG9m6DyhJ7u7uhe4HHjp0SIZhWMUdGxtbZDFmu5X+qiTzXDg4OBR6G7nFJEmHDh3Ks49W0GNcs2ZNPfvss3r22Wd19uxZ3XnnnZo9ezZJKRtiTCmglLj+9nI3Nzc1bNjQ6hWvrq6ukq51Tv6uZ8+eyszM1P/93/9ZlS9YsEAWi8X8o5p9leLNN9+0qrd48eJ8x5l9BeP6KxY3e2NcUenZs2eu+8u+E+dGb/y5EVdX11wfESgOjz76qKKiorRx48Ycy5KSkpSRkZHnusHBwXJwcNDixYutzkFxHP++ffvK3t5eM2bMyHG+DcO46SMR0rW2/v7773r33XdzLLty5YouXbpUoJjs7OzUp08fffnllzpw4ECO5dlx5vcYX98GOzs789GW3F6vDABlBf2K/ClN/Qp7e/scx2H16tU5xt3Jr5SUlBx9ioCAANnZ2d30Oy6/n4Hi9OijjyozM1OzZs3KsSwjI8P83N5q36hy5cqScv4eFIfAwEA1aNBAr776qi5evJhj+R9//HHD9Xv27KkzZ87o008/NcsuX76sd955p8hjvZX+qnTtbvTOnTvr7bffVnx8fI7lN2trbrp166YqVaooPDxcV69etVqWfe7ze4wzMzNz/I56e3vLz8+PPqCNcacUUEo0a9ZMnTt3VmBgoLy8vHTgwAHzFaXZAgMDJUmjR49WSEiI7O3t9dhjj6l3796677779NJLL+nUqVNq2bKlNm3apM8//1xjxowxrxgEBgaqX79+Wrhwoc6dO2e+uvnnn3+WlL8rRe7u7urYsaPmzZun9PR03Xbbbdq0aZNOnjxZDEclp5YtWyo0NFTvvPOOkpKS1KlTJ3377bdavny5+vTpo/vuu69Q2w0MDNTHH3+scePG6a677pKbm5t69+5dxNFfM378eH3xxRd64IEHNGjQIAUGBurSpUs6ePCgPv30U506dSrPK6I1atTQCy+8YL56uGfPnvr+++/19ddf39JV1Nw0aNBAL7/8siZNmqRTp06pT58+qlKlik6ePKk1a9Zo+PDheuGFF264jQEDBuiTTz7RM888o23btqldu3bKzMzUTz/9pE8++UQbN27MdbyUG5kzZ442bdqkTp06afjw4WratKni4+O1evVqffPNN/L09Mz3MX7qqad0/vx5denSRbVq1dKvv/6qxYsXq1WrVlZXzAGgrKFfkT+lqV/xwAMPaObMmRo8eLDuvfdeHTx4UCtWrCj0+DZbt27VyJEj9cgjj+j2229XRkaGPvzwQ9nb26tfv343XDe/n4Hi1KlTJz399NMKDw9XTEyMunXrJgcHBx07dkyrV6/WG2+8oYcffviW+0YuLi5q1qyZPv74Y91+++3y8vLSHXfccdPxKwvDzs5O//73v9WjRw81b95cgwcP1m233abff/9d27Ztk7u7u7788ss81x82bJj+7//+TwMHDlR0dLRq1qypDz/80EysFaVb6a9mW7Jkidq3b6+AgAANGzZM9evXV2JioqKiovTbb7/phx9+KFBM7u7uWrBggZ566indddddeuKJJ1S1alX98MMPunz5spYvX57vY/zXX3+pVq1aevjhh9WyZUu5ublp8+bN2r9/v1577bVbOXQoKBu95Q8o17JfY5rbK+oNI/dX7V7/6uaXX37ZuPvuuw1PT0/DxcXFaNKkiTF79mwjLS3NrJORkWGMGjXKqFGjhmGxWKxeUfvXX38ZY8eONfz8/AwHBwejUaNGxvz5861ehWoY114bGxYWZnh5eRlubm5Gnz59jNjYWEOS1auUs1+B+8cff+Roz2+//Wb84x//MDw9PQ0PDw/jkUceMc6cOZPn65+v30Zer1TO7TjlJj093ZgxY4ZRr149w8HBwahdu7YxadIkq9fN3mg/ubl48aLxxBNPGJ6enoYk8xW62a+5jYiIKHT8ub1+96+//jImTZpkNGzY0HB0dDSqV69u3Hvvvcarr75qdc5zk5mZacyYMcOoWbOm4eLiYnTu3Nk4dOhQjs9U9iuj//564IKeE8MwjP/+979G+/btDVdXV8PV1dVo0qSJERYWZsTGxt607YZhGGlpacYrr7xiNG/e3HBycjKqVq1qBAYGGjNmzDCSk5PNesrldcSGkfN3xTAM49dffzUGDhxo1KhRw3BycjLq169vhIWFWb0aOz/H+NNPPzW6detmeHt7G46OjkadOnWMp59+2oiPj8+1LQBgC/Qrym+/Ivu7efXq1TnWuXr1qvH888+b3+/t2rUzoqKijE6dOhmdOnUy6+W1jev7LL/88osxZMgQo0GDBoazs7Ph5eVl3HfffcbmzZut1svrOOX3M5DX93den+OCnsd33nnHCAwMNFxcXIwqVaoYAQEBxoQJE4wzZ86YdfLbN8rLnj17jMDAQMPR0dHqc5cd683am33s58+fb1We17n6/vvvjb59+xrVqlUznJycDH9/f+PRRx81tmzZctNYf/31V+PBBx80KleubFSvXt147rnnjA0bNuTo84WGhpqfu2y59UnzapNh5K8vlVfbs504ccIYOHCg4evrazg4OBi33Xab8cADDxiffvqpWSevz0pufVnDMIwvvvjCuPfeew0XFxfD3d3duPvuu43//Oc/VnVudoxTU1ON8ePHGy1btjSqVKliuLq6Gi1btjTefPPNXNuB4mMxjAKOHgug3ImJiVHr1q310UcfqX///iUdDgAAKMPoVwAA8osxpYAK5sqVKznKFi5cKDs7O3Xs2LEEIgIAAGUV/QoAwK1gTCmggpk3b56io6N13333qVKlSvr666/19ddfa/jw4apdu3ZJhwcAAMoQ+hUAgFvB43tABRMZGakZM2boyJEjunjxourUqaMBAwbopZdeUqVK5KkBAED+0a8AANwKklIAAAAAAACwOcaUAgAAAAAAgM2RlAIAAAAAAIDN8aB3PmRlZenMmTOqUqWKLBZLSYcDAABKkGEY+uuvv+Tn5yc7O67v/R19JgAAIOW/v0RSKh/OnDnD20MAAICV06dPq1atWiUdRqlCnwkAAPzdzfpLJKXyoUqVKpKuHUx3d/cSjgYAAJSklJQU1a5d2+wf4H/oMwEAACn//SWSUvmQffu5u7s7HSwAACBJPJ6WC/pMAADg727WX2IgBAAAAAAAANgcSSkAAAAAAADYHEkpAAAAAAAA2BxJKQAAAAAAANgcSSkAAAAAAADYHEkpAAAAAAAA2BxJKQAAAAAAANgcSSkAAAAAAADYHEkpAAAAAAAA2BxJKQAAAAAAANgcSSkAAAAAAADYXKWSDgAAypK4uDj9+eef+a5fvXp11alTpxgjAgAAKF3oLwHIL5JSAJBPcXFxatykqa5euZzvdZxdKiv2p6N0tAAAQIVAfwlAQZCUAoB8+vPPP3X1ymVVe+B5OVSrfdP66edO69y61/Tnn3/SyQIAABUC/SUABUFSCgAKyKFabTn5NizpMAAAAEot+ksA8oOBzgEAAAAAAGBzJKUAAAAAAABgcySlAAAAAAAAYHMkpQAAAAAAAGBzJKUAAAAAAABgcyWalNq5c6d69+4tPz8/WSwWrV271mq5xWLJdZo/f75Zp27dujmWz50712o7P/74ozp06CBnZ2fVrl1b8+bNs0XzAAAAAAAAkIcSTUpdunRJLVu21JIlS3JdHh8fbzW9//77slgs6tevn1W9mTNnWtUbNWqUuSwlJUXdunWTv7+/oqOjNX/+fE2fPl3vvPNOsbYNAADAFjIzMzVlyhTVq1dPLi4uatCggWbNmiXDMMw6hmFo6tSpqlmzplxcXBQcHKxjx45Zbef8+fPq37+/3N3d5enpqaFDh+rixYu2bg4AAKhAKpXkznv06KEePXrkudzX19dq/vPPP9d9992n+vXrW5VXqVIlR91sK1asUFpamt5//305OjqqefPmiomJ0euvv67hw4ffeiMAAABK0CuvvKK33npLy5cvV/PmzXXgwAENHjxYHh4eGj16tCRp3rx5WrRokZYvX6569eppypQpCgkJ0ZEjR+Ts7CxJ6t+/v+Lj4xUZGan09HQNHjxYw4cP18qVK0uyeQAAoBwrM2NKJSYm6quvvtLQoUNzLJs7d66qVaum1q1ba/78+crIyDCXRUVFqWPHjnJ0dDTLQkJCFBsbqwsXLtgkdgAAgOKyZ88ePfTQQ+rVq5fq1q2rhx9+WN26ddO3334r6dpdUgsXLtTkyZP10EMPqUWLFvrggw905swZc+iEo0ePasOGDfr3v/+ttm3bqn379lq8eLFWrVqlM2fOlGDrAABAeVZmklLLly9XlSpV1LdvX6vy0aNHa9WqVdq2bZuefvppzZkzRxMmTDCXJyQkyMfHx2qd7PmEhIRc95WamqqUlBSrCQAAoDS69957tWXLFv3888+SpB9++EHffPONeTf6yZMnlZCQoODgYHMdDw8PtW3bVlFRUZKuXcTz9PRUmzZtzDrBwcGys7PTvn37bNgaAABQkZTo43sF8f7776t///7mLebZxo0bZ/7cokULOTo66umnn1Z4eLicnJwKta/w8HDNmDHjluIFAACwhRdffFEpKSlq0qSJ7O3tlZmZqdmzZ6t///6S/ncRLreLdNnLEhIS5O3tbbW8UqVK8vLyyvMinnTtQl5qaqo5z4U8AABQEGXiTqldu3YpNjZWTz311E3rtm3bVhkZGTp16pSka+NSJSYmWtXJns9rHKpJkyYpOTnZnE6fPn1rDQAAACgmn3zyiVasWKGVK1fqu+++0/Lly/Xqq69q+fLlxb7v8PBweXh4mFPt2rWLfZ8AAKD8KBNJqffee0+BgYFq2bLlTevGxMTIzs7OvNoXFBSknTt3Kj093awTGRmpxo0bq2rVqrluw8nJSe7u7lYTAABAaTR+/Hi9+OKLeuyxxxQQEKABAwZo7NixCg8Pl/S/i3C5XaTLXubr66uzZ89aLc/IyND58+fzvIgncSEPAADcmhJNSl28eFExMTGKiYmRdG3Mg5iYGMXFxZl1UlJStHr16lzvkoqKitLChQv1ww8/6JdfftGKFSs0duxYPfnkk2bC6YknnpCjo6OGDh2qw4cP6+OPP9Ybb7xh9dgfAABAWXX58mXZ2Vl36ezt7ZWVlSVJqlevnnx9fbVlyxZzeUpKivbt26egoCBJ1y7iJSUlKTo62qyzdetWZWVlqW3btnnumwt5AADgVpTomFIHDhzQfffdZ85nJ4pCQ0O1bNkySdKqVatkGIYef/zxHOs7OTlp1apVmj59ulJTU1WvXj2NHTvWKuHk4eGhTZs2KSwsTIGBgapevbqmTp2q4cOHF2/jAAAAbKB3796aPXu26tSpo+bNm+v777/X66+/riFDhkiSLBaLxowZo5dfflmNGjVSvXr1NGXKFPn5+alPnz6SpKZNm6p79+4aNmyYli5dqvT0dI0cOVKPPfaY/Pz8SrB1AACgPCvRpFTnzp1lGMYN6wwfPjzPBNKdd96pvXv33nQ/LVq00K5duwoVIwAAQGm2ePFiTZkyRc8++6zOnj0rPz8/Pf3005o6dapZZ8KECbp06ZKGDx+upKQktW/fXhs2bLB6gcyKFSs0cuRIde3aVXZ2durXr58WLVpUEk0CAAAVRJl5+x4AAAByqlKlihYuXKiFCxfmWcdisWjmzJmaOXNmnnW8vLy0cuXKYogQAAAgd2VioHMAAAAAAACULySlAAAAAAAAYHMkpQAAAAAAAGBzJKUAAAAAAABgcySlAAAAAAAAYHMkpQAAAAAAAGBzJKUAAAAAAABgcySlAAAAAAAAYHMkpQAAAAAAAGBzJKUAAAAAAABgcySlAAAAAAAAYHMkpQAAAAAAAGBzJKUAAAAAAABgcySlAAAAAAAAYHMkpQAAAAAAAGBzJKUAAAAAAABgcySlAAAAAAAAYHMkpQAAAAAAAGBzJKUAAAAAAABgcySlAAAAAAAAYHMkpQAAAAAAAGBzJKUAAAAAAABgcySlAAAAAAAAYHMkpQAAAAAAAGBzJKUAAADKuLp168piseSYwsLCJElXr15VWFiYqlWrJjc3N/Xr10+JiYlW24iLi1OvXr1UuXJleXt7a/z48crIyCiJ5gAAgAqCpBQAAEAZt3//fsXHx5tTZGSkJOmRRx6RJI0dO1ZffvmlVq9erR07dujMmTPq27evuX5mZqZ69eqltLQ07dmzR8uXL9eyZcs0derUEmkPAACoGEhKAQAAlHE1atSQr6+vOa1bt04NGjRQp06dlJycrPfee0+vv/66unTposDAQEVERGjPnj3au3evJGnTpk06cuSIPvroI7Vq1Uo9evTQrFmztGTJEqWlpZVw6wAAQHlFUgoAAKAcSUtL00cffaQhQ4bIYrEoOjpa6enpCg4ONus0adJEderUUVRUlCQpKipKAQEB8vHxMeuEhIQoJSVFhw8fznNfqampSklJsZoAAADyq0STUjt37lTv3r3l5+cni8WitWvXWi0fNGhQjrERunfvblXn/Pnz6t+/v9zd3eXp6amhQ4fq4sWLVnV+/PFHdejQQc7Ozqpdu7bmzZtX3E0DAAAoEWvXrlVSUpIGDRokSUpISJCjo6M8PT2t6vn4+CghIcGs8/eEVPby7GV5CQ8Pl4eHhznVrl276BoCAADKvRJNSl26dEktW7bUkiVL8qzTvXt3qzES/vOf/1gt79+/vw4fPqzIyEitW7dOO3fu1PDhw83lKSkp6tatm/z9/RUdHa358+dr+vTpeuedd4qtXQAAACXlvffeU48ePeTn51fs+5o0aZKSk5PN6fTp08W+TwAAUH5UKsmd9+jRQz169LhhHScnJ/n6+ua67OjRo9qwYYP279+vNm3aSJIWL16snj176tVXX5Wfn59WrFihtLQ0vf/++3J0dFTz5s0VExOj119/3Sp5BQAAUNb9+uuv2rx5sz777DOzzNfXV2lpaUpKSrK6WyoxMdHsY/n6+urbb7+12lb22/ny6odJ1/ppTk5ORdgCAABQkZT6MaW2b98ub29vNW7cWCNGjNC5c+fMZVFRUfL09DQTUpIUHBwsOzs77du3z6zTsWNHOTo6mnVCQkIUGxurCxcu5LpPxkcAAABlUUREhLy9vdWrVy+zLDAwUA4ODtqyZYtZFhsbq7i4OAUFBUmSgoKCdPDgQZ09e9asExkZKXd3dzVr1sx2DQAAABVKqU5Kde/eXR988IG2bNmiV155RTt27FCPHj2UmZkp6doYB97e3lbrVKpUSV5eXrc0RgLjIwAAgLImKytLERERCg0NVaVK/7sZ3sPDQ0OHDtW4ceO0bds2RUdHa/DgwQoKCtI999wjSerWrZuaNWumAQMG6IcfftDGjRs1efJkhYWFcScUAAAoNiX6+N7NPPbYY+bPAQEBatGihRo0aKDt27era9euxbbfSZMmady4ceZ8SkoKiSkAAFCqbd68WXFxcRoyZEiOZQsWLJCdnZ369eun1NRUhYSE6M033zSX29vba926dRoxYoSCgoLk6uqq0NBQzZw505ZNAAAAFUypTkpdr379+qpevbqOHz+url27ytfX1+o2c0nKyMjQ+fPnrcZIyB4TIdvNxkhgfAQAAFDWdOvWTYZh5LrM2dlZS5YsueHLZfz9/bV+/friCg8AACCHUv343vV+++03nTt3TjVr1pR0bfyDpKQkRUdHm3W2bt2qrKwstW3b1qyzc+dOpaenm3UiIyPVuHFjVa1a1bYNAAAAAAAAgKQSTkpdvHhRMTExiomJkSSdPHlSMTExiouL08WLFzV+/Hjt3btXp06d0pYtW/TQQw+pYcOGCgkJkSQ1bdpU3bt317Bhw/Ttt99q9+7dGjlypB577DHzNchPPPGEHB0dNXToUB0+fFgff/yx3njjDavH8wAAAAAAAGBbJZqUOnDggFq3bq3WrVtLksaNG6fWrVtr6tSpsre3148//qgHH3xQt99+u4YOHarAwEDt2rXL6tG6FStWqEmTJuratat69uyp9u3b65133jGXe3h4aNOmTTp58qQCAwP1/PPPa+rUqRo+fLjN2wsAAAAAAIBrSnRMqc6dO+c59oEkbdy48abb8PLy0sqVK29Yp0WLFtq1a1eB4wMAAAAAAEDxKFNjSgEAAAAAAKB8ICkFAAAAAAAAmyMpBQAAAAAAAJsjKQUAAAAAAACbIykFAAAAAAAAmyMpBQAAAAAAAJsjKQUAAAAAAACbIykFAAAAAAAAmyMpBQAAAAAAAJsjKQUAAAAAAACbIykFAAAAAAAAmyMpBQAAAAAAAJsjKQUAAAAAAACbIykFAAAAAAAAmyMpBQAAAAAAAJsjKQUAAAAAAACbIykFAAAAAAAAmyMpBQAAAAAAAJsjKQUAAAAAAACbIykFAABQxv3+++968sknVa1aNbm4uCggIEAHDhwwlxuGoalTp6pmzZpycXFRcHCwjh07ZrWN8+fPq3///nJ3d5enp6eGDh2qixcv2ropAACgAiEpBQAAUIZduHBB7dq1k4ODg77++msdOXJEr732mqpWrWrWmTdvnhYtWqSlS5dq3759cnV1VUhIiK5evWrW6d+/vw4fPqzIyEitW7dOO3fu1PDhw0uiSQAAoIKoVNIBAAAAoPBeeeUV1a5dWxEREWZZvXr1zJ8Nw9DChQs1efJkPfTQQ5KkDz74QD4+Plq7dq0ee+wxHT16VBs2bND+/fvVpk0bSdLixYvVs2dPvfrqq/Lz87NtowAAQIXAnVIAAABl2BdffKE2bdrokUcekbe3t1q3bq13333XXH7y5EklJCQoODjYLPPw8FDbtm0VFRUlSYqKipKnp6eZkJKk4OBg2dnZad++fXnuOzU1VSkpKVYTAABAfpGUAgAAKMN++eUXvfXWW2rUqJE2btyoESNGaPTo0Vq+fLkkKSEhQZLk4+NjtZ6Pj4+5LCEhQd7e3lbLK1WqJC8vL7NObsLDw+Xh4WFOtWvXLsqmAQCAco6kFAAAQBmWlZWlO++8U3PmzFHr1q01fPhwDRs2TEuXLi32fU+aNEnJycnmdPr06WLfJwAAKD9ISgEAAJRhNWvWVLNmzazKmjZtqri4OEmSr6+vJCkxMdGqTmJiornM19dXZ8+etVqekZGh8+fPm3Vy4+TkJHd3d6sJAAAgv0hKAQAAlGHt2rVTbGysVdnPP/8sf39/SdcGPff19dWWLVvM5SkpKdq3b5+CgoIkSUFBQUpKSlJ0dLRZZ+vWrcrKylLbtm1t0AoAAFAR8fY9AACAMmzs2LG69957NWfOHD366KP69ttv9c477+idd96RJFksFo0ZM0Yvv/yyGjVqpHr16mnKlCny8/NTnz59JF27s6p79+7mY3/p6ekaOXKkHnvsMd68BwAAik2J3im1c+dO9e7dW35+frJYLFq7dq25LD09XRMnTlRAQIBcXV3l5+engQMH6syZM1bbqFu3riwWi9U0d+5cqzo//vijOnToIGdnZ9WuXVvz5s2zRfMAAACK3V133aU1a9boP//5j+644w7NmjVLCxcuVP/+/c06EyZM0KhRozR8+HDdddddunjxojZs2CBnZ2ezzooVK9SkSRN17dpVPXv2VPv27c3EFgAAQHEo0TulLl26pJYtW2rIkCHq27ev1bLLly/ru+++05QpU9SyZUtduHBBzz33nB588EEdOHDAqu7MmTM1bNgwc75KlSrmzykpKerWrZuCg4O1dOlSHTx4UEOGDJGnp6eGDx9evA0EAACwgQceeEAPPPBAnsstFotmzpypmTNn5lnHy8tLK1euLI7wAAAAclWiSakePXqoR48euS7z8PBQZGSkVdn//d//6e6771ZcXJzq1KljllepUiXPQThXrFihtLQ0vf/++3J0dFTz5s0VExOj119/naQUAAAAAABACSlTA50nJyfLYrHI09PTqnzu3LmqVq2aWrdurfnz5ysjI8NcFhUVpY4dO8rR0dEsCwkJUWxsrC5cuGCr0AEAAAAAAPA3ZWag86tXr2rixIl6/PHHrV43PHr0aN15553y8vLSnj17NGnSJMXHx+v111+XJCUkJKhevXpW2/Lx8TGXVa1aNce+UlNTlZqaas6npKQUR5MAAAAAAAAqrDKRlEpPT9ejjz4qwzD01ltvWS0bN26c+XOLFi3k6Oiop59+WuHh4XJycirU/sLDwzVjxoxbihkAAAAAAAB5K/WP72UnpH799VdFRkZa3SWVm7Zt2yojI0OnTp2SJPn6+ioxMdGqTvZ8XuNQTZo0ScnJyeZ0+vTpW28IAAAAAAAATKU6KZWdkDp27Jg2b96satWq3XSdmJgY2dnZydvbW5IUFBSknTt3Kj093awTGRmpxo0b5/roniQ5OTnJ3d3dagIAAAAAAEDRKdHH9y5evKjjx4+b8ydPnlRMTIy8vLxUs2ZNPfzww/ruu++0bt06ZWZmKiEhQdK1VxY7OjoqKipK+/bt03333acqVaooKipKY8eO1ZNPPmkmnJ544gnNmDFDQ4cO1cSJE3Xo0CG98cYbWrBgQYm0GQAAAAAAACWclDpw4IDuu+8+cz57fKjQ0FBNnz5dX3zxhSSpVatWVutt27ZNnTt3lpOTk1atWqXp06crNTVV9erV09ixY63GmfLw8NCmTZsUFhamwMBAVa9eXVOnTtXw4cOLv4EAAAAAAADIVYkmpTp37izDMPJcfqNlknTnnXdq7969N91PixYttGvXrgLHBwAAAAAAgOJRqseUAgAAAAAAQPlEUgoAAAAAAAA2R1IKAAAAAAAANkdSCgAAAAAAADZHUgoAAAAAAAA2R1IKAAAAAAAANkdSCgAAAAAAADZHUgoAAAAAAAA2R1IKAAAAAAAANkdSCgAAAAAAADZHUgoAAAAAAAA2R1IKAAAAAAAANkdSCgAAAAAAADZHUgoAAAAAAAA2R1IKAACgjJs+fbosFovV1KRJE3P51atXFRYWpmrVqsnNzU39+vVTYmKi1Tbi4uLUq1cvVa5cWd7e3ho/frwyMjJs3RQAAFCBVCrpAAAAAHDrmjdvrs2bN5vzlSr9r5s3duxYffXVV1q9erU8PDw0cuRI9e3bV7t375YkZWZmqlevXvL19dWePXsUHx+vgQMHysHBQXPmzLF5WwAAQMVAUgoAAKAcqFSpknx9fXOUJycn67333tPKlSvVpUsXSVJERISaNm2qvXv36p577tGmTZt05MgRbd68WT4+PmrVqpVmzZqliRMnavr06XJ0dLR1cwAAQAXA43sAAADlwLFjx+Tn56f69eurf//+iouLkyRFR0crPT1dwcHBZt0mTZqoTp06ioqKkiRFRUUpICBAPj4+Zp2QkBClpKTo8OHDtm0IAACoMLhTCgAAoIxr27atli1bpsaNGys+Pl4zZsxQhw4ddOjQISUkJMjR0VGenp5W6/j4+CghIUGSlJCQYJWQyl6evSwvqampSk1NNedTUlKKqEUAAKAiICkFAABQxvXo0cP8uUWLFmrbtq38/f31ySefyMXFpdj2Gx4erhkzZhTb9gEAQPnG43sAAADljKenp26//XYdP35cvr6+SktLU1JSklWdxMREcwwqX1/fHG/jy57PbZyqbJMmTVJycrI5nT59umgbAgAAyjWSUgAAAOXMxYsXdeLECdWsWVOBgYFycHDQli1bzOWxsbGKi4tTUFCQJCkoKEgHDx7U2bNnzTqRkZFyd3dXs2bN8tyPk5OT3N3drSYAAID8KlRSqkuXLjmutknXxhHIfqsLAAAAbqyo+lQvvPCCduzYoVOnTmnPnj36xz/+IXt7ez3++OPy8PDQ0KFDNW7cOG3btk3R0dEaPHiwgoKCdM8990iSunXrpmbNmmnAgAH64YcftHHjRk2ePFlhYWFycnIqquYCAABYKdSYUtu3b1daWlqO8qtXr2rXrl23HBQAAEBFUFR9qt9++02PP/64zp07pxo1aqh9+/bau3evatSoIUlasGCB7Ozs1K9fP6WmpiokJERvvvmmub69vb3WrVunESNGKCgoSK6urgoNDdXMmTNvvZEAAAB5KFBS6scffzR/PnLkiNXbWDIzM7VhwwbddtttRRcdAABAOVTUfapVq1bdcLmzs7OWLFmiJUuW5FnH399f69evz/c+AQAAblWBklKtWrWSxWKRxWLJ9ZZyFxcXLV68uMiCAwAAKI/oUwEAABQwKXXy5EkZhqH69evr22+/NW8JlyRHR0d5e3vL3t6+yIMEAAAoT+hTAQAAFDAp5e/vL0nKysoqlmAAAAAqAvpUAAAAhRzoXJKOHTumbdu26ezZszk6VFOnTr3lwAAAACoC+lQAAKCisivMSu+++66aNm2qqVOn6tNPP9WaNWvMae3atfnezs6dO9W7d2/5+fnJYrHkWNcwDE2dOlU1a9aUi4uLgoODdezYMas658+fV//+/eXu7i5PT08NHTpUFy9etKrz448/qkOHDnJ2dlbt2rU1b968wjQbAACgSBVVnwoAAKAsKtSdUi+//LJmz56tiRMn3tLOL126pJYtW2rIkCHq27dvjuXz5s3TokWLtHz5ctWrV09TpkxRSEiIjhw5ImdnZ0lS//79FR8fr8jISKWnp2vw4MEaPny4Vq5cKUlKSUlRt27dFBwcrKVLl+rgwYMaMmSIPD09NXz48FuKHwAA4FYUVZ8KAACgLCpUUurChQt65JFHbnnnPXr0UI8ePXJdZhiGFi5cqMmTJ+uhhx6SJH3wwQfy8fHR2rVr9dhjj+no0aPasGGD9u/frzZt2kiSFi9erJ49e+rVV1+Vn5+fVqxYobS0NL3//vtydHRU8+bNFRMTo9dff52kFAAAKFFF1acCAAAoiwr1+N4jjzyiTZs2FXUsVk6ePKmEhAQFBwebZR4eHmrbtq2ioqIkSVFRUfL09DQTUpIUHBwsOzs77du3z6zTsWNHOTo6mnVCQkIUGxurCxcu5Lrv1NRUpaSkWE0AAABFzRZ9KgAAgNKqUHdKNWzYUFOmTNHevXsVEBAgBwcHq+WjR4++5cASEhIkST4+PlblPj4+5rKEhAR5e3tbLa9UqZK8vLys6tSrVy/HNrKXVa1aNce+w8PDNWPGjFtuAwAAwI3Yok8FAABQWhUqKfXOO+/Izc1NO3bs0I4dO6yWWSyWMt+BmjRpksaNG2fOp6SkqHbt2iUYEQAAKI/Ke58KAADgRgqVlDp58mRRx5GDr6+vJCkxMVE1a9Y0yxMTE9WqVSuzztmzZ63Wy8jI0Pnz5831fX19lZiYaFUnez67zvWcnJzk5ORUJO0AAADIiy36VAAAAKVVocaUsoV69erJ19dXW7ZsMctSUlK0b98+BQUFSZKCgoKUlJSk6Ohos87WrVuVlZWltm3bmnV27typ9PR0s05kZKQaN26c66N7AAAAAAAAKH6FulNqyJAhN1z+/vvv52s7Fy9e1PHjx835kydPKiYmRl5eXqpTp47GjBmjl19+WY0aNVK9evU0ZcoU+fn5qU+fPpKkpk2bqnv37ho2bJiWLl2q9PR0jRw5Uo899pj8/PwkSU888YRmzJihoUOHauLEiTp06JDeeOMNLViwoDBNBwAAKDJF1acCAAAoiwqVlLr+rXXp6ek6dOiQkpKS1KVLl3xv58CBA7rvvvvM+exxnEJDQ7Vs2TJNmDBBly5d0vDhw5WUlKT27dtrw4YNcnZ2NtdZsWKFRo4cqa5du8rOzk79+vXTokWLzOUeHh7atGmTwsLCFBgYqOrVq2vq1KkaPnx4YZoOAABQZIqqTwUAAFAWFSoptWbNmhxlWVlZGjFihBo0aJDv7XTu3FmGYeS53GKxaObMmZo5c2aedby8vLRy5cob7qdFixbatWtXvuMCAACwhaLqUwEAAJRFRTamlJ2dncaNG8djcQAAALeAPhUAAKgoinSg8xMnTigjI6MoNwkAAFDh0KcCAAAVQaEe38se+ymbYRiKj4/XV199pdDQ0CIJDAAAoLyjTwUAACqyQiWlvv/+e6t5Ozs71ahRQ6+99tpN3yIDAACAa+hTAQCAiqxQSalt27YVdRwAAAAVDn0qAABQkRUqKZXtjz/+UGxsrCSpcePGqlGjRpEEBQAAUJHQpwIAABVRoQY6v3TpkoYMGaKaNWuqY8eO6tixo/z8/DR06FBdvny5qGMEAAAol+hTAQCAiqzQA53v2LFDX375pdq1aydJ+uabbzR69Gg9//zzeuutt4o0SAAAgPKIPhWAsiIuLk5//vnnTesdPXrUBtEAKC8KlZT673//q08//VSdO3c2y3r27CkXFxc9+uijdKAAAADygT4VgLIgLi5OjZs01dUr3MEJoGgV6vG9y5cvy8fHJ0e5t7c3t5oDAADkU3H0qebOnSuLxaIxY8aYZVevXlVYWJiqVasmNzc39evXT4mJiVbrxcXFqVevXqpcubK8vb01fvx4ZWRkFCoGAOXLn3/+qatXLqvaA8/LN3ThDSePDk+WdLgAypBCJaWCgoI0bdo0Xb161Sy7cuWKZsyYoaCgoCILDgAAoDwr6j7V/v379fbbb6tFixZW5WPHjtWXX36p1atXa8eOHTpz5oz69u1rLs/MzFSvXr2UlpamPXv2aPny5Vq2bJmmTp1a+MYBKHccqtWWk2/DG06VPHIm2gEgL4V6fG/hwoXq3r27atWqpZYtW0qSfvjhBzk5OWnTpk1FGiAAAEB5VZR9qosXL6p///5699139fLLL5vlycnJeu+997Ry5Up16dJFkhQREaGmTZtq7969uueee7Rp0yYdOXJEmzdvlo+Pj1q1aqVZs2Zp4sSJmj59uhwdHYuu0QAAAP9foe6UCggI0LFjxxQeHq5WrVqpVatWmjt3ro4fP67mzZsXdYwAAADlUlH2qcLCwtSrVy8FBwdblUdHRys9Pd2qvEmTJqpTp46ioqIkSVFRUQoICLB6lDAkJEQpKSk6fPhwnvtMTU1VSkqK1QQAAJBfhbpTKjw8XD4+Pho2bJhV+fvvv68//vhDEydOLJLgAAAAyrOi6lOtWrVK3333nfbv359jWUJCghwdHeXp6WlV7uPjo4SEBLPO9WNbZc9n18kr/hkzZuQrRgAAgOsV6k6pt99+W02aNMlR3rx5cy1duvSWgwIAAKgIiqJPdfr0aT333HNasWKFnJ2dizrEG5o0aZKSk5PN6fTp0zbdPwAAKNsKlZRKSEhQzZo1c5TXqFFD8fHxtxwUAABARVAUfaro6GidPXtWd955pypVqqRKlSppx44dWrRokSpVqiQfHx+lpaUpKSnJar3ExET5+vpKknx9fXO8jS97PrtObpycnOTu7m41AQAA5FehklK1a9fW7t27c5Tv3r1bfn5+txwUAABARVAUfaquXbvq4MGDiomJMac2bdqof//+5s8ODg7asmWLuU5sbKzi4uLMN/wFBQXp4MGDOnv2rFknMjJS7u7uatas2S22EgAAIHeFGlNq2LBhGjNmjNLT0823uGzZskUTJkzQ888/X6QBAgAAlFdF0aeqUqWK7rjjDqsyV1dXVatWzSwfOnSoxo0bJy8vL7m7u2vUqFEKCgrSPffcI0nq1q2bmjVrpgEDBmjevHlKSEjQ5MmTFRYWJicnpyJsMQAAwP8UKik1fvx4nTt3Ts8++6zS0tIkSc7Ozpo4caImTZpUpAECAACUV7bqUy1YsEB2dnbq16+fUlNTFRISojfffNNcbm9vr3Xr1mnEiBEKCgqSq6urQkNDNXPmzCKLAQAA4HqFSkpZLBa98sormjJlio4ePSoXFxc1atSIK2kAAAAFUFx9qu3bt1vNOzs7a8mSJVqyZEme6/j7+2v9+vW3tF8AAICCKFRSKpubm5vuuuuuoooFAACgQqJPBQAAKqJCDXQOAAAAAAAA3AqSUgAAAAAAALA5klIAAAAAAACwOZJSAAAAAAAAsDmSUgAAAAAAALA5klIAAAAAAACwOZJSAAAAAAAAsLlSn5SqW7euLBZLjiksLEyS1Llz5xzLnnnmGattxMXFqVevXqpcubK8vb01fvx4ZWRklERzAAAAAAAAIKlSSQdwM/v371dmZqY5f+jQId1///165JFHzLJhw4Zp5syZ5nzlypXNnzMzM9WrVy/5+vpqz549io+P18CBA+Xg4KA5c+bYphEAAAAAAACwUuqTUjVq1LCanzt3rho0aKBOnTqZZZUrV5avr2+u62/atElHjhzR5s2b5ePjo1atWmnWrFmaOHGipk+fLkdHx2KNHwAAAAAAADmV+sf3/i4tLU0fffSRhgwZIovFYpavWLFC1atX1x133KFJkybp8uXL5rKoqCgFBATIx8fHLAsJCVFKSooOHz5s0/gBAAAAAABwTam/U+rv1q5dq6SkJA0aNMgse+KJJ+Tv7y8/Pz/9+OOPmjhxomJjY/XZZ59JkhISEqwSUpLM+YSEhFz3k5qaqtTUVHM+JSWliFsCAAAAAABQsZWppNR7772nHj16yM/PzywbPny4+XNAQIBq1qyprl276sSJE2rQoEGh9hMeHq4ZM2bccrwAAAAAAADIXZl5fO/XX3/V5s2b9dRTT92wXtu2bSVJx48flyT5+voqMTHRqk72fF7jUE2aNEnJycnmdPr06VsNHwAAAAAAAH9TZpJSERER8vb2Vq9evW5YLyYmRpJUs2ZNSVJQUJAOHjyos2fPmnUiIyPl7u6uZs2a5boNJycnubu7W00AAAAAAAAoOmXi8b2srCxFREQoNDRUlSr9L+QTJ05o5cqV6tmzp6pVq6Yff/xRY8eOVceOHdWiRQtJUrdu3dSsWTMNGDBA8+bNU0JCgiZPnqywsDA5OTmVVJMAAAAAAAAqtDKRlNq8ebPi4uI0ZMgQq3JHR0dt3rxZCxcu1KVLl1S7dm3169dPkydPNuvY29tr3bp1GjFihIKCguTq6qrQ0FDNnDnT1s0AAAAAAADA/1cmklLdunWTYRg5ymvXrq0dO3bcdH1/f3+tX7++OEIDAAAAAABAIZSZMaUAAAAAAABQfpCUAgAAAAAAgM2RlAIAAAAAAIDNkZQCAAAAAACAzZGUAgAAKOPeeusttWjRQu7u7nJ3d1dQUJC+/vprc/nVq1cVFhamatWqyc3NTf369VNiYqLVNuLi4tSrVy9VrlxZ3t7eGj9+vDIyMmzdFAAAUIGQlAIAACjjatWqpblz5yo6OloHDhxQly5d9NBDD+nw4cOSpLFjx+rLL7/U6tWrtWPHDp05c0Z9+/Y118/MzFSvXr2UlpamPXv2aPny5Vq2bJmmTp1aUk0CAAAVQKWSDgAAAAC3pnfv3lbzs2fP1ltvvaW9e/eqVq1aeu+997Ry5Up16dJFkhQREaGmTZtq7969uueee7Rp0yYdOXJEmzdvlo+Pj1q1aqVZs2Zp4sSJmj59uhwdHUuiWQAAoJzjTikAAIByJDMzU6tWrdKlS5cUFBSk6OhopaenKzg42KzTpEkT1alTR1FRUZKkqKgoBQQEyMfHx6wTEhKilJQU824rAACAosadUgAAAOXAwYMHFRQUpKtXr8rNzU1r1qxRs2bNFBMTI0dHR3l6elrV9/HxUUJCgiQpISHBKiGVvTx7WV5SU1OVmppqzqekpBRRawAAQEXAnVIAAADlQOPGjRUTE6N9+/ZpxIgRCg0N1ZEjR4p1n+Hh4fLw8DCn2rVrF+v+AABA+UJSCgAAoBxwdHRUw4YNFRgYqPDwcLVs2VJvvPGGfH19lZaWpqSkJKv6iYmJ8vX1lST5+vrmeBtf9nx2ndxMmjRJycnJ5nT69OmibRQAACjXSEoBAACUQ1lZWUpNTVVgYKAcHBy0ZcsWc1lsbKzi4uIUFBQkSQoKCtLBgwd19uxZs05kZKTc3d3VrFmzPPfh5OQkd3d3qwkAACC/GFMKAACgjJs0aZJ69OihOnXq6K+//tLKlSu1fft2bdy4UR4eHho6dKjGjRsnLy8vubu7a9SoUQoKCtI999wjSerWrZuaNWumAQMGaN68eUpISNDkyZMVFhYmJyenEm4dAAAor0hKAQAAlHFnz57VwIEDFR8fLw8PD7Vo0UIbN27U/fffL0lasGCB7Ozs1K9fP6WmpiokJERvvvmmub69vb3WrVunESNGKCgoSK6urgoNDdXMmTNLqkkAAKACICkFAABQxr333ns3XO7s7KwlS5ZoyZIledbx9/fX+vXrizo0AACAPDGmFAAAAAAAAGyOpBQAAAAAAABsjqQUAAAAAAAAbI6kFAAAAAAAAGyOpBQAAAAAAABsjqQUAAAAAAAAbI6kFAAAAAAAAGyOpBQAAAAAAABsjqQUAAAAAAAAbI6kFAAAAAAAAGyOpBQAAAAAAABsjqQUAAAAAAAAbI6kFAAAAAAAAGyOpBQAAAAAAABsrlQnpaZPny6LxWI1NWnSxFx+9epVhYWFqVq1anJzc1O/fv2UmJhotY24uDj16tVLlStXlre3t8aPH6+MjAxbNwUAAAAAAAB/U6mkA7iZ5s2ba/PmzeZ8pUr/C3ns2LH66quvtHr1anl4eGjkyJHq27evdu/eLUnKzMxUr1695Ovrqz179ig+Pl4DBw6Ug4OD5syZY/O2AAAAAAAA4JpSn5SqVKmSfH19c5QnJyfrvffe08qVK9WlSxdJUkREhJo2baq9e/fqnnvu0aZNm3TkyBFt3rxZPj4+atWqlWbNmqWJEydq+vTpcnR0tHVzAAAAAAAAoFL++J4kHTt2TH5+fqpfv7769++vuLg4SVJ0dLTS09MVHBxs1m3SpInq1KmjqKgoSVJUVJQCAgLk4+Nj1gkJCVFKSooOHz6c5z5TU1OVkpJiNQEAAAAAAKDolOqkVNu2bbVs2TJt2LBBb731lk6ePKkOHTror7/+UkJCghwdHeXp6Wm1jo+PjxISEiRJCQkJVgmp7OXZy/ISHh4uDw8Pc6pdu3bRNgwAAAAAAKCCK9WP7/Xo0cP8uUWLFmrbtq38/f31ySefyMXFpdj2O2nSJI0bN86cT0lJITEFAAAAAABQhEr1nVLX8/T01O23367jx4/L19dXaWlpSkpKsqqTmJhojkHl6+ub42182fO5jVOVzcnJSe7u7lYTAAAAAAAAik6ZSkpdvHhRJ06cUM2aNRUYGCgHBwdt2bLFXB4bG6u4uDgFBQVJkoKCgnTw4EGdPXvWrBMZGSl3d3c1a9bM5vEDAAAAAADgmlL9+N4LL7yg3r17y9/fX2fOnNG0adNkb2+vxx9/XB4eHho6dKjGjRsnLy8vubu7a9SoUQoKCtI999wjSerWrZuaNWumAQMGaN68eUpISNDkyZMVFhYmJyenEm4dAAAAAABAxVWqk1K//fabHn/8cZ07d041atRQ+/bttXfvXtWoUUOStGDBAtnZ2alfv35KTU1VSEiI3nzzTXN9e3t7rVu3TiNGjFBQUJBcXV0VGhqqmTNnllSTAAAAAAAAoFL++N6qVat05swZpaam6rffftOqVavUoEEDc7mzs7OWLFmi8+fP69KlS/rss89yjBXl7++v9evX6/Lly/rjjz/06quvqlKlUp2LAwAAKJDw8HDdddddqlKliry9vdWnTx/FxsZa1bl69arCwsJUrVo1ubm5qV+/fjnG3oyLi1OvXr1UuXJleXt7a/z48crIyLBlUwAAQAVCdgYAAKCM27Fjh8LCwnTXXXcpIyND//rXv9StWzcdOXJErq6ukqSxY8fqq6++0urVq+Xh4aGRI0eqb9++2r17tyQpMzNTvXr1kq+vr/bs2aP4+HgNHDhQDg4OmjNnTkk2D0AFcPTo0XzXrV69uurUqVOM0QCwFZJSAAAAZdyGDRus5pctWyZvb29FR0erY8eOSk5O1nvvvaeVK1eqS5cukqSIiAg1bdpUe/fu1T333KNNmzbpyJEj2rx5s3x8fNSqVSvNmjVLEydO1PTp0+Xo6FgSTQNQzmVevCBZLHryySfzvY6zS2XF/nSUxBRQDpCUAgAAKGeSk5MlSV5eXpKk6OhopaenKzg42KzTpEkT1alTR1FRUbrnnnsUFRWlgIAA+fj4mHVCQkI0YsQIHT58WK1bt86xn9TUVKWmpprzKSkpxdUkAOVUVupFyTBU7YHn5VCt9k3rp587rXPrXtOff/5JUgooB0hKAQAAlCNZWVkaM2aM2rVrpzvuuEOSlJCQIEdHR3l6elrV9fHxUUJCglnn7wmp7OXZy3ITHh6uGTNmFHELAFREDtVqy8m3YUmHAcDGSvVA5wAAACiYsLAwHTp0SKtWrSr2fU2aNEnJycnmdPr06WLfJwAAKD+4UwoAAKCcGDlypNatW6edO3eqVq1aZrmvr6/S0tKUlJRkdbdUYmKi+eZiX19fffvtt1bby3473/VvN87m5OQkJyenIm4FAACoKLhTCgAAoIwzDEMjR47UmjVrtHXrVtWrV89qeWBgoBwcHLRlyxazLDY2VnFxcQoKCpIkBQUF6eDBgzp79qxZJzIyUu7u7mrWrJltGgIAACoU7pQCAAAo48LCwrRy5Up9/vnnqlKlijkGlIeHh1xcXOTh4aGhQ4dq3Lhx8vLykru7u0aNGqWgoCDdc889kqRu3bqpWbNmGjBggObNm6eEhARNnjxZYWFh3A0FAACKBUkpAACAMu6tt96SJHXu3NmqPCIiQoMGDZIkLViwQHZ2durXr59SU1MVEhKiN99806xrb2+vdevWacSIEQoKCpKrq6tCQ0M1c+ZMWzUDAABUMCSlAAAAyjjDMG5ax9nZWUuWLNGSJUvyrOPv76/169cXZWgAAAB5YkwpAAAAAAAA2BxJKQAAAAAAANgcSSkAAAAAAADYHEkpAAAAAAAA2BxJKQAAAAAAANgcSSkAAAAAAADYHEkpAAAAAAAA2BxJKQAAAAAAANgcSSkAAAAAAADYHEkpAAAAAAAA2BxJKQAAAAAAANgcSSkAAAAAAADYHEkpAAAAAAAA2BxJKQAAAAAAANgcSSkAAAAAAADYHEkpAAAAAAAA2BxJKQAAAAAAANhcpZIOAABKUlxcnP7888981T169GgxRwMAAAAAFUepTkqFh4frs88+008//SQXFxfde++9euWVV9S4cWOzTufOnbVjxw6r9Z5++mktXbrUnI+Li9OIESO0bds2ubm5KTQ0VOHh4apUqVQ3H0Axi4uLU+MmTXX1yuWSDgUAAAAAKpxSnZXZsWOHwsLCdNdddykjI0P/+te/1K1bNx05ckSurq5mvWHDhmnmzJnmfOXKlc2fMzMz1atXL/n6+mrPnj2Kj4/XwIED5eDgoDlz5ti0PQBKlz///FNXr1xWtQeel0O12jetf+WXA0re9ZENIgMAAACA8q9UJ6U2bNhgNb9s2TJ5e3srOjpaHTt2NMsrV64sX1/fXLexadMmHTlyRJs3b5aPj49atWqlWbNmaeLEiZo+fbocHR2LtQ0ASj+HarXl5NvwpvXSz522QTQAAAAAUDGU6qTU9ZKTkyVJXl5eVuUrVqzQRx99JF9fX/Xu3VtTpkwx75aKiopSQECAfHx8zPohISEaMWKEDh8+rNatW9uuAQAAAACAW1aQsT6rV6+uOnXqFGM0AAqrzCSlsrKyNGbMGLVr10533HGHWf7EE0/I399ffn5++vHHHzVx4kTFxsbqs88+kyQlJCRYJaQkmfMJCQm57is1NVWpqanmfEpKSlE3BwAAAABQQJkXL0gWi5588sl8r+PsUlmxPx0lMQWUQmUmKRUWFqZDhw7pm2++sSofPny4+XNAQIBq1qyprl276sSJE2rQoEGh9hUeHq4ZM2bcUrwAAAC2snPnTs2fP1/R0dGKj4/XmjVr1KdPH3O5YRiaNm2a3n33XSUlJaldu3Z666231KhRI7PO+fPnNWrUKH355Zeys7NTv3799MYbb8jNza0EWgQAuctKvSgZRr7HBE0/d1rn1r2mP//8k6QUUArZlXQA+TFy5EitW7dO27ZtU61atW5Yt23btpKk48ePS5J8fX2VmJhoVSd7Pq9xqCZNmqTk5GRzOn2acWQAAEDpdenSJbVs2VJLlizJdfm8efO0aNEiLV26VPv27ZOrq6tCQkJ09epVs07//v11+PBhRUZGat26ddq5c6fVxT8AKE2yxwS92ZSfxBWAklOq75QyDEOjRo3SmjVrtH37dtWrV++m68TExEiSatasKUkKCgrS7NmzdfbsWXl7e0uSIiMj5e7urmbNmuW6DScnJzk5ORVNIwAAAIpZjx491KNHj1yXGYahhQsXavLkyXrooYckSR988IF8fHy0du1aPfbYYzp69Kg2bNig/fv3q02bNpKkxYsXq2fPnnr11Vfl5+dns7YAAICKo1TfKRUWFqaPPvpIK1euVJUqVZSQkKCEhARduXJFknTixAnNmjVL0dHROnXqlL744gsNHDhQHTt2VIsWLSRJ3bp1U7NmzTRgwAD98MMP2rhxoyZPnqywsDASTwAAoNw7efKkEhISFBwcbJZ5eHiobdu2ioqKknTtxTCenp5mQkqSgoODZWdnp3379tk8ZgAAUDGU6jul3nrrLUlS586drcojIiI0aNAgOTo6avPmzVq4cKEuXbqk2rVrq1+/fpo8ebJZ197eXuvWrdOIESMUFBQkV1dXhYaGaubMmbZsCgAAQInIfrFLbi9+yV6WkJBg3lGerVKlSvLy8srzxTCS7V8OExcXpz///DPf9XnjFpC3gvw+FeRNdwBQEKU6KWUYxg2X165dWzt27Ljpdvz9/bV+/fqiCgsAAACy7cth4uLi1LhJU129cjnf6/DGLSB3hfl9Kuvym1gjmQ3YVqlOSgEAAODWZL/YJTEx0RxzM3u+VatWZp2zZ89arZeRkaHz58/n+WIY6drLYcaNG2fOp6SkqHbt4hlU+M8//9TVK5d54xZQBAr6+3TllwNK3vWRDSIrepkXL0gWi5588sl81SeZDdgWSSkAAIByrF69evL19dWWLVvMJFRKSor27dunESNGSLr2YpikpCRFR0crMDBQkrR161ZlZWWZbzbOTUm8HCb7jVsAbl1+f5/Sz5Xdt5FnpV6UDCNfCTiS2YDtkZQCAAAo4y5evKjjx4+b8ydPnlRMTIy8vLxUp04djRkzRi+//LIaNWqkevXqacqUKfLz81OfPn0kSU2bNlX37t01bNgwLV26VOnp6Ro5cqQee+wx3rwHlBDGUCtaJLSB0omkFAAAQBl34MAB3XfffeZ89iN1oaGhWrZsmSZMmKBLly5p+PDhSkpKUvv27bVhwwY5Ozub66xYsUIjR45U165dZWdnp379+mnRokU2bwsAxlADUHGQlAIAACjjOnfufMMXxFgsFs2cOfOGbx/28vLSypUriyM8AAXEGGoAKgqSUgAAAABQCvHIGYDyzq6kAwAAAAAAAEDFQ1IKAAAAAAAANsfjewAAAABKTEHeMscb5gCgfCEpBaDcyW/n9ujRozaIBgAA5KWgb5njDXMAUL6QlAJQrhTmFcoAAKBkFOQtc7xhDgDKH5JSAMqVgnRur/xyQMm7PrJRZAAAIC+8Za5o5PcucO4WB1BakJQCUC7lp3Obfu60jaIBAAAoPpkXL0gWi5588smSDgUACoSkFAAAAIAyoyB3+ZSmgdELMqB7Qe9kykq9KBlGvu4Ul7hbHCjPytrLI0hKAQAAACj1CnM3UGkZGN1WY17m9zFI7hYHyqey+PIIklIAAAAASr2C3g1UmgZGL8iYlxJ3MgEonLL48giSUgAAAADKjLI8KDp3MgGwhbL0d5KkFAAAAAAA/19ZHbcMKItISgEAAADIU0EGzZWk1NRUOTk55atuQQf0BopTWR63DCirSEoBAAAAyFWhBui22ElGVvEFBRSTsjxuGcqv4nxzZ2lAUgoAAAAoZQp6d1JxPUJU2AG6GdAbZVlZGo8H5Zut3txZkkhKAQAAoNwqyFXjgjx2VpzjyBTmPyFOTs76738/Vc2aNW9atzCxF3SAbgb0Bkq/0pL8Rt4qwps7SUoBQDFjsEwAsL3CjA1TkMfOinMcmYL+J+Tqb4eVtPXfeuCBB/K1/YIksMrioyAAbq4wyW/GzyoahXkcrzwn+klKlRJkqYG8ldXnqBksEwBKTkHHhinIY2fZ48js2rVLTZs2zVc8xX53Uj7bWtAEFoDyqaDJb8bPKhoV4XG8giIpVQqQpQbyVpb/cDNYJgCUvOJ47KwwFx1scXdSfmIvSAJLKpuPgtwKLhSjLCvOO3CuXy8/+P3IqSI8jldQJKVKAbLUQN7Kwx9uBssEikZBOtt0hFGcCnrRoTTenVSeHwUpLC4UozTK73dffHy8+j38iFKvXimWOHgCoGjxN/h/SEqVIvzHFcgbf7iBiq2g/1mkIwxbKI7H66TSeYGlIijsheL8PMZZmoYXQNlRmERpcf2d4QkAFBeSUmVYfr/cuFqMwijIHQkFeVtRQetXxE4cv9vlC4+CFI2C/GeRjjBKKy6wlIz8fq8W9HGmQg2mjwqvoI/Y5fe7LzvJVNx/Z7iRAkWNpFQZVNAvQK4Wo6AKfFWmAG8rKlT9CoLf7fKHR0GKHp1hAPlV3Emjgtw5wt1vkAo/Vmq+x4srhbjYipupUEmpJUuWaP78+UpISFDLli21ePFi3X333SUdVoEV5AuQq8XIVtxXZYrj7UZ/r18R8Ltd/hTnoyDZ6MShqJWX/hJQ2DcwFlRZThjAtsrDWKn5xcVW5FeFSUp9/PHHGjdunJYuXaq2bdtq4cKFCgkJUWxsrLy9vUs6vEIpLVeLS9OjKQWNpaCPnRU09uJ8BK4gsdjiqkxxvN3o7/UrktLyu42iU5yPghTkjV4SSSzcWHnsLwH0OVDaVITPJBdbkV8VJin1+uuva9iwYRo8eLAkaenSpfrqq6/0/vvv68UXXyzh6EqXgiRSCvOWh4L8B6ogiZpCvXGigI+RFST2AsdTjLEU5M4nqWxflQHKMlu80YsrkbgR+ksAUHAFHbesIimrF1t546/tVIikVFpamqKjozVp0iSzzM7OTsHBwYqKispRPzU1VampqeZ8cnKyJCklJaVY4rt48eK1/SYcV1ba1ZvWz86Y56d++vnfJEnR0dHmfm4kMTFRTw4YqLTUm8fxd+539ZW9R42b1kv/45Qu/rCxAP+BskgyiiWWtDM/69KRbcUYe/7jsVUsWemp+fqMGRlpkvL5GSvA57G01S9NsRS0fkF/t6Vrf/eysvKf+CzO+qUpluKsHxsbK6ngn4H8/q5mXU6WDCPffzsyk/9Qyv7PtHHjRjVu3Pim9UvLcZQKdiyzfz8uXrxYLN/d2ds0jIJ9P5V2Be0vSbbtMxVnf6mg9UvT90FB65emWApavzTFUtD6pSmW4q5fmmIpaP2Cbjv1zLUkU0HHLSsNsZem+qWtX1vQ/xM7Ojnrow8/kI+Pz03rFrZvWJzHvcT7S0YF8PvvvxuSjD179liVjx8/3rj77rtz1J82bZqha5kQJiYmJiYmJqZcp9OnT9uqK2MTBe0vGQZ9JiYmJiYmJqYbTzfrL1WIO6UKatKkSRo3bpw5n5WVpfPnz6tatWqyWCxFuq+UlBTVrl1bp0+flru7e5FuuzSqSO2lreVTRWqrVLHaS1vLp+Joq2EY+uuvv+Tn51ck2yvLbNlnKkkV6XemLOG8lF6cm9KJ81I6ldfzkt/+UoVISlWvXl329vZKTEy0Kk9MTJSvr2+O+k5OTjnGMfL09CzOEOXu7l6uPoA3U5HaS1vLp4rUVqlitZe2lk9F3VYPD48i21ZpUdD+klQyfaaSVJF+Z8oSzkvpxbkpnTgvpVN5PC/56S/Z2SCOEufo6KjAwEBt2bLFLMvKytKWLVsUFBRUgpEBAACUDvSXAACArVWIO6Ukady4cQoNDVWbNm109913a+HChbp06ZL5dhkAAICKjv4SAACwpQqTlPrnP/+pP/74Q1OnTlVCQoJatWqlDRs25GuE/OLk5OSkadOm5bj1vbyqSO2lreVTRWqrVLHaS1vLp4rU1qJQWvtLJY3PUenEeSm9ODelE+eldKro58ViGOXsfcYAAAAAAAAo9SrEmFIAAAAAAAAoXUhKAQAAAAAAwOZISgEAAAAAAMDmSEoBAAAAAADA5khK2dDs2bN17733qnLlyvL09My1TlxcnHr16qXKlSvL29tb48ePV0ZGhlWd7du3684775STk5MaNmyoZcuWFX/wt2D79u2yWCy5Tvv375cknTp1Ktfle/fuLeHoC6du3bo52jJ37lyrOj/++KM6dOggZ2dn1a5dW/PmzSuhaAvv1KlTGjp0qOrVqycXFxc1aNBA06ZNU1pamlWd8nRulyxZorp168rZ2Vlt27bVt99+W9Ih3bLw8HDdddddqlKliry9vdWnTx/FxsZa1encuXOOc/jMM8+UUMSFN3369BztaNKkibn86tWrCgsLU7Vq1eTm5qZ+/fopMTGxBCMuvNz+DlksFoWFhUkq++d0586d6t27t/z8/GSxWLR27Vqr5YZhaOrUqapZs6ZcXFwUHBysY8eOWdU5f/68+vfvL3d3d3l6emro0KG6ePGiDVuBsi41NVWtWrWSxWJRTExMSYdToeWnTwLbKI99pbIsP/08lLy5c+fKYrFozJgxJR2KzZGUsqG0tDQ98sgjGjFiRK7LMzMz1atXL6WlpWnPnj1avny5li1bpqlTp5p1Tp48qV69eum+++5TTEyMxowZo6eeekobN260VTMK7N5771V8fLzV9NRTT6levXpq06aNVd3Nmzdb1QsMDCyhqG/dzJkzrdoyatQoc1lKSoq6desmf39/RUdHa/78+Zo+fbreeeedEoy44H766SdlZWXp7bff1uHDh7VgwQItXbpU//rXv3LULQ/n9uOPP9a4ceM0bdo0fffdd2rZsqVCQkJ09uzZkg7tluzYsUNhYWHau3evIiMjlZ6erm7duunSpUtW9YYNG2Z1DstiIlWSmjdvbtWOb775xlw2duxYffnll1q9erV27NihM2fOqG/fviUYbeHt37/fqp2RkZGSpEceecSsU5bP6aVLl9SyZUstWbIk1+Xz5s3TokWLtHTpUu3bt0+urq4KCQnR1atXzTr9+/fX4cOHFRkZqXXr1mnnzp0aPny4rZqAcmDChAny8/Mr6TCggvVJUHzKa1+pLMtvPw8lZ//+/Xr77bfVokWLkg6lZBiwuYiICMPDwyNH+fr16w07OzsjISHBLHvrrbcMd3d3IzU11TAMw5gwYYLRvHlzq/X++c9/GiEhIcUac1FKS0szatSoYcycOdMsO3nypCHJ+P7770susCLk7+9vLFiwIM/lb775plG1alXzvBqGYUycONFo3LixDaIrXvPmzTPq1atnzpenc3v33XcbYWFh5nxmZqbh5+dnhIeHl2BURe/s2bOGJGPHjh1mWadOnYznnnuu5IIqItOmTTNatmyZ67KkpCTDwcHBWL16tVl29OhRQ5IRFRVlowiLz3PPPWc0aNDAyMrKMgyj/JxTwzAMScaaNWvM+aysLMPX19eYP3++WZaUlGQ4OTkZ//nPfwzDMIwjR44Ykoz9+/ebdb7++mvDYrEYv//+u81iR9m1fv16o0mTJsbhw4fLzfdceXN9nwTFr6L0lcqy3Pp5KDl//fWX0ahRIyMyMrJc9c0KgjulSpGoqCgFBATIx8fHLAsJCVFKSooOHz5s1gkODrZaLyQkRFFRUTaN9VZ88cUXOnfunAYPHpxj2YMPPihvb2+1b99eX3zxRQlEV3Tmzp2ratWqqXXr1po/f77VY5hRUVHq2LGjHB0dzbKQkBDFxsbqwoULJRFukUlOTpaXl1eO8rJ+btPS0hQdHW31+2dnZ6fg4OAy9fuXH8nJyZKU4zyuWLFC1atX1x133KFJkybp8uXLJRHeLTt27Jj8/PxUv3599e/fX3FxcZKk6OhopaenW53jJk2aqE6dOmX+HKelpemjjz7SkCFDZLFYzPLyck6vd/LkSSUkJFidSw8PD7Vt29Y8l1FRUfL09LS6Yzc4OFh2dnbat2+fzWNG2ZKYmKhhw4bpww8/VOXKlUs6HOQhrz4JikdF6iuVZXn181AywsLC1KtXrxz/x69IKpV0APifhIQEq4SUJHM+ISHhhnVSUlJ05coVubi42CbYW/Dee+8pJCREtWrVMsvc3Nz02muvqV27drKzs9N///tf9enTR2vXrtWDDz5YgtEWzujRo3XnnXfKy8tLe/bs0aRJkxQfH6/XX39d0rXzWK9ePat1/n6uq1atavOYi8Lx48e1ePFivfrqq2ZZeTm3f/75pzIzM3P9/fvpp59KKKqil5WVpTFjxqhdu3a64447zPInnnhC/v7+8vPz048//qiJEycqNjZWn332WQlGW3Bt27bVsmXL1LhxY8XHx2vGjBnq0KGDDh06pISEBDk6OuYY88/Hx8f8G1xWrV27VklJSRo0aJBZVl7OaW6yz1duv69//z719va2Wl6pUiV5eXmV+fON4mUYhgYNGqRnnnlGbdq00alTp0o6JOQitz4JildF6SuVZXn181AyVq1ape+++84cZ7miIil1i1588UW98sorN6xz9OhRq4F0y4vCtP23337Txo0b9cknn1jVq169usaNG2fO33XXXTpz5ozmz59fahIXBWnv39vSokULOTo66umnn1Z4eLicnJyKO9RbVphz+/vvv6t79+565JFHNGzYMLO8LJxb/E9YWJgOHTpkNc6SJKtxdgICAlSzZk117dpVJ06cUIMGDWwdZqH16NHD/LlFixZq27at/P399cknn5SJpH5hvffee+rRo4fV2Dfl5ZwCRSW/332bNm3SX3/9pUmTJtkosoqtKPskQEWXVz8Ptnf69Gk999xzioyMlLOzc0mHU6JISt2i559/3urKc27q16+fr235+vrmeDtF9luffH19zX+vfxNUYmKi3N3dbf4fqsK0PSIiQtWqVctXMqJt27bmwLylwa2c67Zt2yojI0OnTp1S48aN8zyP0v/OdUkqaFvPnDmj++67T/fee2++Bmsvbec2P6pXry57e/tcz1tpOGdFYeTIkeZgz3+/kzE3bdu2lXTtSnRZTmB4enrq9ttv1/Hjx3X//fcrLS1NSUlJVndLlfVz/Ouvv2rz5s03vQOqvJxT6X9/RxMTE1WzZk2zPDExUa1atTLrXD/wbkZGhs6fP1+mzzcKL7/ffVu3blVUVFSOi0xt2rRR//79tXz58mKMsuIp7j4Jik5F6CuVZQXp56H4RUdH6+zZs7rzzjvNsszMTO3cuVP/93//p9TUVNnb25dghLZDUuoW1ahRQzVq1CiSbQUFBWn27Nk6e/as+UhBZGSk3N3d1axZM7PO+vXrrdaLjIxUUFBQkcRQEAVtu2EYioiI0MCBA+Xg4HDT+jExMVb/mShpt3KuY2JiZGdnZ57XoKAgvfTSS0pPTzePRWRkpBo3blwqHt0rSFt///133XfffQoMDFRERITs7G4+VF1pO7f54ejoqMDAQG3ZskV9+vSRdO0W6C1btmjkyJElG9wtMgxDo0aN0po1a7R9+/Ycj5bmJvvV52XtPF7v4sWLOnHihAYMGKDAwEA5ODhoy5Yt6tevnyQpNjZWcXFxJfI3tqhERETI29tbvXr1umG98nJOJalevXry9fXVli1bzCRUSkqK9u3bZ74BNygoSElJSYqOjjbfBrp161ZlZWWZCTpULPn97lu0aJFefvllc/7MmTMKCQnRxx9/zGenGBR3nwRFpzz3lcqywvTzUPy6du2qgwcPWpUNHjxYTZo00cSJEytMQkoSb9+zpV9//dX4/vvvjRkzZhhubm7G999/b3z//ffGX3/9ZRiGYWRkZBh33HGH0a1bNyMmJsbYsGGDUaNGDWPSpEnmNn755RejcuXKxvjx442jR48aS5YsMezt7Y0NGzaUVLPybfPmzYYk4+jRozmWLVu2zFi5cqVx9OhR4+jRo8bs2bMNOzs74/333y+BSG/Nnj17jAULFhgxMTHGiRMnjI8++sioUaOGMXDgQLNOUlKS4ePjYwwYMMA4dOiQsWrVKqNy5crG22+/XYKRF9xvv/1mNGzY0Ojatavx22+/GfHx8eaUrTyd21WrVhlOTk7GsmXLjCNHjhjDhw83PD09rd6YWRaNGDHC8PDwMLZv3251Di9fvmwYhmEcP37cmDlzpnHgwAHj5MmTxueff27Ur1/f6NixYwlHXnDPP/+8sX37duPkyZPG7t27jeDgYKN69erG2bNnDcMwjGeeecaoU6eOsXXrVuPAgQNGUFCQERQUVMJRF15mZqZRp04dY+LEiVbl5eGc/vXXX+b3qCTj9ddfN77//nvj119/NQzDMObOnWt4enoan3/+ufHjjz8aDz30kFGvXj3jypUr5ja6d+9utG7d2ti3b5/xzTffGI0aNTIef/zxkmoSyqjy9JbZsiw/fRIUv/LaVyrLbtbPQ+lRUd++R1LKhkJDQw1JOaZt27aZdU6dOmX06NHDcHFxMapXr248//zzRnp6utV2tm3bZrRq1cpwdHQ06tevb0RERNi2IYX0+OOPG/fee2+uy5YtW2Y0bdrUqFy5suHu7m7cfffdVq9lL0uio6ONtm3bGh4eHoazs7PRtGlTY86cOcbVq1et6v3www9G+/btDScnJ+O2224z5s6dW0IRF15ERESun+m/57vL07k1DMNYvHixUadOHcPR0dG4++67jb1795Z0SLcsr3OY/bclLi7O6Nixo+Hl5WU4OTkZDRs2NMaPH28kJyeXbOCF8M9//tOoWbOm4ejoaNx2223GP//5T+P48ePm8itXrhjPPvusUbVqVaNy5crGP/7xjzL9H5qNGzcakozY2Fir8vJwTrdt25br5zY0NNQwDMPIysoypkyZYvj4+BhOTk5G165dcxyHc+fOGY8//rjh5uZmuLu7G4MHDzYvFAH5RVKqdMhPnwS2UR77SmXZzfp5KD0qalLKYhiGUYw3YgEAAAAAAAA58KA1AAAAAAAAbI6kFAAAAAAAAGyOpBQAAAAAAABsjqQUAAAAAAAAbI6kFAAAAAAAAGyOpBQAAAAAAABsjqQUAAAAAAAAbI6kFAAAAAAAAGyOpBRQgjp37qwxY8aY83Xr1tXChQvN+YSEBN1///1ydXWVp6dnnmXlyfTp09WqVauSDsNmCtPe6z83JRVHcSuNMQEAUBy2bNmipk2bKjMzM886138vDho0SH369DHnDcPQ8OHD5eXlJYvFopiYmFzLHnvsMb322mv5jm3ZsmXF1ud877331K1bN3P+1KlTslgsN13PYrFo7dq1VuvExMSYy3fv3q2AgAA5ODiYxyi3ss6dO2vZsmVF1JrC2bBhg1q1aqWsrKwSjQMoKSSlgFJk//79Gj58uDm/YMECxcfHKyYmRj///HOeZeXJCy+8oC1btpjz13e4pNw7H2XV9e3Nj88++0yzZs0qpohKxt87l9kKc2wAACiLJkyYoMmTJ8ve3j7f67zxxhtWCZUNGzZo2bJlWrduneLj43XHHXfkWjZ58mTNnj1bycnJObY5ffp0bd++vQhadHNXr17VlClTNG3atFvaTu3atc22ZRs3bpxatWqlkydPmscotzJbGD16tAIDA+Xk5JTrxbbu3bvLwcFBK1assFlMQGlCUgooRWrUqKHKlSub8ydOnFBgYKAaNWokb2/vPMuKW1paWrHvwzAMZWRkyM3NTdWqVSv2/ZW0W2mvl5eXqlSpUkyR5U92/MWponwWAAAV2zfffKMTJ06oX79+BVrPw8PD6g6mEydOqGbNmrr33nvl6+urSpUq5Vp2xx13qEGDBvroo48kSenp6XrttdeUnp5ubuvs2bN6++23i6R9efn000/l7u6udu3a3dJ27O3tzbZlO3HihLp06aJatWqZxyi3soLavn276tatW+D1hgwZon/+8595Lh80aJAWLVpUqJiAso6kFGAjly5d0sCBA+Xm5qaaNWvmetv03x/fq1u3rv773//qgw8+kMVi0aBBg3ItKw7ZdyfNnj1bfn5+aty4sSTp9OnTevTRR+Xp6SkvLy899NBDOnXqlCTp0KFDsrOz0x9//CFJOn/+vOzs7PTYY4+Z23355ZfVvn17Sde+1C0Wi77++mvz6tE333xjdWv69OnTtXz5cn3++eeyWCyyWCzavn276tWrJ0lq3bq1LBaLOnfubO7j3//+t5o2bSpnZ2c1adJEb775prks+w6rzz77TPfdd58qV66sli1bKioq6paPWWpqqkaPHi1vb285Ozurffv22r9/v7k8P+2VpIyMDI0ePVqenp6qVq2aJk6cqNDQUKu7xXJ77HPOnDkaMmSIqlSpojp16uidd96xim/ixIm6/fbbVblyZdWvX19Tpkyx6nzeTF7x53Yn25gxY6zOSefOnTV69GhNmDBBXl5e8vX11fTp063il6R//OMfslgs5nxejynMmTNHPj4+8vT01MyZM5WRkaHx48fLy8tLtWrVUkREhFU8N/rcAgBwI59++qkCAgLk4uKiatWqKTg4WJcuXZKU/+/sG30HStKqVat0//33y9nZ2ap87ty58vHxUZUqVTR06FBdvXrVavnfv4MHDRqkUaNGKS4uzvwuza0sW+/evbVq1SpJMh+X69Kliw4fPqw1a9aod+/eqlWrVp7H5a233lKDBg3k6Oioxo0b68MPP7Ra/tNPP6l9+/ZydnZWs2bNtHnz5hx3Ra9atUq9e/fOcx/Zjh07po4dO5rbioyMtFr+9zvos38+d+6chgwZIovFomXLluVaZiuLFi1SWFiY6tevn2ed3r1768CBAzpx4oTN4gJKC5JSgI2MHz9eO3bs0Oeff65NmzZp+/bt+u677/Ksv3//fnXv3l2PPvqo4uPj9cYbb+RalpsVK1bIzc3thtOuXbtuGO+WLVsUGxuryMhIrVu3Tunp6QoJCVGVKlW0a9cu7d69W25uburevbvS0tLUvHlzVatWTTt27JAk7dq1y2peknbs2GGVrJCkF198UXPnztXRo0fVokULq2UvvPCCHn30UXXv3l3x8fGKj4/Xvffeq2+//VaStHnzZsXHx+uzzz4z2z116lTNnj1bR48e1Zw5czRlyhQtX77carsvvfSSXnjhBcXExOj222/X448/fst3/UyYMEH//e9/tXz5cn333Xdq2LChQkJCdP78+Xy3V5JeeeUVrVixQhEREdq9e7dSUlJyPNaWm9dee01t2rTR999/r2effVYjRoxQbGysubxKlSpatmyZjhw5ojfeeEPvvvuuFixYUOB23iz+vCxfvlyurq7at2+f5s2bp5kzZ5qdyuzkXUREhOLj462SedfbunWrzpw5o507d+r111/XtGnT9MADD6hq1arat2+fnnnmGT399NP67bffJOmmn1sAAPISHx+vxx9/XEOGDNHRo0e1fft29e3bV4ZhSMr/d/aNvgOla32mNm3aWK3zySefaPr06ZozZ44OHDigmjVrWl1ou94bb7yhmTNnqlatWuZ3aW5l2e6++259++23Sk1NVaVKlfT8889r0aJFWr9+vTZt2qRNmzapV69eue5rzZo1eu655/T888/r0KFDevrppzV48GBt27ZNkpSZmak+ffqocuXK2rdvn9555x299NJLObbzzTff5Gj39bKystS3b185Ojpq3759Wrp0qSZOnJhn/exH+dzd3bVw4ULFx8frkUceyVF2o7uWSkKdOnXk4+Nz0/45UC4ZAIrdX3/9ZTg6OhqffPKJWXbu3DnDxcXFeO6558wyf39/Y8GCBeb8Qw89ZISGhlptK7ey66WkpBjHjh274XT58uU81w8NDTV8fHyM1NRUs+zDDz80GjdubGRlZZllqamphouLi7Fx40bDMAyjb9++RlhYmGEYhjFmzBhj/PjxRtWqVY2jR48aaWlpRuXKlY1NmzYZhmEY27ZtMyQZa9eutdr3tGnTjJYtW1rF8tBDD1nVOXnypCHJ+P77763KGzRoYKxcudKqbNasWUZQUJDVev/+97/N5YcPHzYkGUePHs3zeNzMxYsXDQcHB2PFihVmWVpamuHn52fMmzfPMIz8t9fHx8eYP3++OZ+RkWHUqVPH6hh06tQpx+fmySefNOezsrIMb29v46233soz5vnz5xuBgYF5xnG9vOLP7fw899xzRqdOnazibd++vVWdu+66y5g4caI5L8lYs2aNVZ3cPgv+/v5GZmamWda4cWOjQ4cO5nxGRobh6upq/Oc//zEMI3+fWwAAchMdHW1IMk6dOpXr8vx+Z9/sO9DDw8P44IMPrOoEBQUZzz77rFVZ27Ztb9hHWrBggeHv72+1Tm5lhmEYP/zwg9m2jIwMY+HChUb79u2Nhx9+2Bg9erRxzz33GF9//bVhGIYRERFheHh4mOvee++9xrBhw6y298gjjxg9e/Y0DMMwvv76a6NSpUpGfHy8uTwyMtLqu/7ChQuGJGPnzp1W28nuq2XbuHGjUalSJeP33383y77++murbeXWL/Tw8DAiIiKstp1bWadOnXKU3ci2bdtyPZ75cbO+VuvWrY3p06cXattAWVYpt0QVgKJ14sQJpaWlqW3btmaZl5eX+VhcUatSpcotjzkUEBAgR0dHc/6HH37Q8ePHc2z36tWr5q3GnTp1Mh8b27Fjh+bMmaOff/5Z27dv1/nz55Wenp5j3ICbXSHLr0uXLunEiRMaOnSohg0bZpZnZGTIw8PDqu7f7/CpWbOmpGtjJzRp0iTHdp955hlzzAVJunjxYo46J06cyNE2BwcH3X333Tp69KhV3Ru1Nzk5WYmJibr77rvNMnt7ewUGBt70jSx/b5PFYpGvr6/Onj1rln388cdatGiRTpw4oYsXLyojI0Pu7u433GZuCnu+rr+rqmbNmlbx5Vfz5s1lZ/e/m3x9fHysBja1t7dXtWrVzG3n53MLAEBuWrZsqa5duyogIEAhISHq1q2bHn74YVWtWrVA39k3+w68cuVKjkf3jh49qmeeecaqLCgoyLwb6Va5uLhIki5fvqysrCylp6dry5YtmjNnjjp37qx//etfWrNmTa7rHj161OrFPJLUrl078w7+2NhY1a5dW76+vubyvx8n6VqbJeVod277ql27tvz8/MyyoKCgfLayaLi5uZk/Z2ZmKjU11arsySef1NKlS295Py4uLrp8+fItbwcoa0hKAeXQihUr9PTTT9+wztdff60OHTrkudzV1dVq/uLFiwoMDMz1zSA1atSQ9L+xjo4dO6YjR46offv2+umnn7R9+3ZduHBBbdq0sRrIPbf9FFZ2sujdd9+1Sv5JyvEmGwcHB/Pn7HEU8kr6zJw5Uy+88EKRxCgVXXuv9/c2Sdfald2mqKgo9e/fXzNmzFBISIg8PDy0atWqAr0OOtv18dvZ2ZmPMWTLbayqG8VXELlt50bbzs/nFgCA3Njb2ysyMlJ79uzRpk2btHjxYr300kvat2+fvLy88r2dm30HVq9eXRcuXCiyuPMje3iBGjVqyMHBIUdfx8fHJ0dSrChVq1ZNFovF5u0ujL+/7Xnfvn2aOHGi1RsKC3ORLzfnz5+nb4IKiaQUYAMNGjSQg4OD9u3bpzp16kiSLly4oJ9//lmdOnUq8v09+OCDORIz17vtttsKtM0777xTH3/8sby9vfP88g0ICFDVqlX18ssvq1WrVnJzc1Pnzp31yiuv6MKFCznGk8oPR0dHZWZm5iiTZFXu4+MjPz8//fLLL+rfv3+B95MXb2/vm77lMHugz927d8vf31/StcTM/v37rQYkvxkPDw/5+Pho//796tixo6Rrbfzuu+9yfYVwfu3Zs0f+/v5W4zn8+uuvhd7e39WoUUOHDh2yKouJicnRAb8ZBweHHOe5KOTncwsAQF4sFovatWundu3aaerUqfL399eaNWs0bty4IvvObt26tY4cOWJV1rRpU+3bt08DBw40y/bu3XvL7cl26NAh1apVS9WrV7cqv34Q9tw0bdpUu3fvVmhoqFm2e/duNWvWTJLUuHFjnT59WomJifLx8ZGkHONFOjo6qlmzZjpy5Ii6det2w32dPn1a8fHx5t3tRXkc8qNhw4bmz7/99psqVapkVVYUsu/gbt26dZFuFygLGOgcsAE3NzcNHTpU48eP19atW3Xo0CENGjTI6jGkolSlShU1bNjwhlP2bdv51b9/f1WvXl0PPfSQdu3apZMnT2r79u0aPXq0Oai0xWJRx44dtWLFCjMB1aJFC6WmpmrLli2FSsDVrVtXP/74o2JjY/Xnn38qPT1d3t7ecnFx0YYNG5SYmKjk5GRJ0owZMxQeHq5Fixbp559/1sGDBxUREaHXX3+9wPstCFdXV40YMULjx4/Xhg0bdOTIEQ0bNkyXL1/W0KFDC7StUaNGKTw8XJ9//rliY2P13HPP6cKFC+YdXYXRqFEjxcXFadWqVTpx4oQWLVqU5y35BdWlSxcdOHBAH3zwgY4dO6Zp06blSFLlR926dbVlyxYlJCQU6VXT/HxuAQDIzb59+8yBxuPi4vTZZ5/pjz/+UNOmTSUV3Xd2SEiIvvnmG6uy5557Tu+//74iIiL0888/a9q0aTp8+HCRtW3Xrl03TAbdyPjx47Vs2TK99dZbOnbsmF5//XV99tln5t1W999/vxo0aKDQ0FD9+OOP2r17tyZPnixJVscmt3ZfLzg4WLfffrtCQ0P1ww8/aNeuXbkOml6aHT9+XDExMUpISNCVK1cUExOjmJgYqxeu7N27V05OTjZ/NBEoDUhKATYyf/58dejQQb1791ZwcLDat2+vwMDAkg4r3ypXrqydO3eqTp066tu3r5o2bWq+nvjvd6B06tRJmZmZZlLKzs5OHTt2NK80FtSwYcPUuHFjtWnTRjVq1NDu3btVqVIlLVq0SG+//bb8/Pz00EMPSZKeeuop/fvf/1ZERIQCAgLUqVOn/9fe/YTCFsZhHH8u2U1KbC0mIbGYMxolioWaWEjJ34mmnI1SskBiVqhZmCIanZXJxnKmlDJ2ipUlG02ZoawshMJm3MXtzuX+cd1r5pjy/SxPM+f9zenUOz3vOb9XkUhETqczK9fgNcFgUN3d3RoaGpLb7VYikdDu7q5KSkr+6TzT09MaGBjQ8PCwGhsb5XA45PV6/9pz4TWdnZ2amJjQ2NiYXC6XDg8PFQgE/vt8z3m9XgUCAU1NTcnj8ej29vbFqu5bhUIh7e3tqby8PKurhG+9bwEA+FlxcbH29/fV0dGhqqoqzc3NKRQKqb29XVL25myfz6eTk5MXu+b29fVl5tf6+nqlUimNjo5m5Xc9PDwoFou96MH5L7q6urSysqKlpSXV1tbKsixtbGxk/vsVFhYqFovp7u5OHo9HpmlmgqTn12ZkZEQ7OzuZxcXfKSgoUDQa1f39vRoaGmSaphYXF/+r7o9imqYMw5BlWTo9PZVhGDIMQ5eXl5nPbG1tyefz/dLmAvgMvjz93AwEAJA30um0ampq1Nvbq/n5+Y8uBwAA/MF75uzJyUnd3NzIsqwcVffD+vq6otGo4vF4zsf67uDgQM3NzUokEqqoqMgc7+npkdvt1szMjCQpmUzK6XT+0q8yV1pbW+X3++X3+20Z73eurq5UXV2to6MjWxZSgXxDTykAyCOpVErxeFwtLS16fHzU2tqazs7ONDg4+NGlAQCAZ7I5Z8/OziocDiudTuesvcN3RUVFWl1dzekY0WhUDodDlZWVSiQSGh8fV1NT04tASvr2JsH29nZOa8l3yWRS4XCYQAqfFk9KAUAeubi4UH9/v46Pj/X09KS6ujoFg8FME1UAAJAfmLP/bHNzUwsLCzo/P1dZWZna2toUCoVUWlr66vc+45NSwGdHKAUAAAAA+HDX19daXl5+0y6A2RCJRORyud61yzGA9yGUAgAAAAAAgO3YfQ8AAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANiOUAoAAAAAAAC2I5QCAAAAAACA7QilAAAAAAAAYDtCKQAAAAAAANjuK0w/c65ZAvgiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axs[0].hist(y1_diff, bins=40, edgecolor='black')\n",
    "axs[0].set_title('Histogram of time differences')\n",
    "axs[0].set_ylabel(\"count\")\n",
    "axs[0].set_xlabel(\"diff = rewritten - original runtime\")\n",
    "\n",
    "# Create the second histogram\n",
    "y1_diff_log = np.sign(y1_diff) * np.log(abs(y1_diff) + 1)\n",
    "axs[1].hist(y1_diff_log, bins=40, edgecolor='black')\n",
    "axs[1].set_title('Histogram of transformed time differences')\n",
    "axs[1].set_ylabel(\"count\")\n",
    "axs[1].set_xlabel(\"sgn(diff)*log(|diff| + 1)\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c889d62-8988-4035-bc5d-e0848b0d2419",
   "metadata": {},
   "source": [
    "#### Train-validation-test split\n",
    "\n",
    "We split the dataset such that each benchmark dataset is represented in the train and in the test set (stratification). We do a 80% train, 10% validation and 10% test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b1cd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, stratify=df[\"bench\"], random_state=20)\n",
    "X_val, X_test, y1_val, y1_test = train_test_split(X_test, y1_test, test_size=0.5, stratify=df.loc[X_test.index][\"bench\"], random_state=20)\n",
    "X_train_hg = X_hg.loc[X_train.index]\n",
    "X_val_hg = X_hg.loc[X_val.index]\n",
    "X_test_hg = X_hg.loc[X_test.index]\n",
    "y1_diff_log_train = y1_diff_log.loc[y1_train.index]\n",
    "y1_diff_log_val = y1_diff_log.loc[y1_val.index]\n",
    "y1_diff_log_test = y1_diff_log.loc[y1_test.index]\n",
    "y1_equal_05_train = y1_equal_05.loc[y1_train.index]\n",
    "y1_equal_05_val = y1_equal_05.loc[y1_val.index]\n",
    "y1_equal_05_test = y1_equal_05.loc[y1_test.index]\n",
    "y1_equal_01_train = y1_equal_01.loc[y1_train.index]\n",
    "y1_equal_01_val = y1_equal_01.loc[y1_val.index]\n",
    "y1_equal_01_test = y1_equal_01.loc[y1_test.index]\n",
    "y1_equal_005_train = y1_equal_005.loc[y1_train.index]\n",
    "y1_equal_005_val = y1_equal_005.loc[y1_val.index]\n",
    "y1_equal_005_test = y1_equal_005.loc[y1_test.index]\n",
    "y1_equal_001_train = y1_equal_001.loc[y1_train.index]\n",
    "y1_equal_001_val = y1_equal_001.loc[y1_val.index]\n",
    "y1_equal_001_test = y1_equal_001.loc[y1_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c648a4-e43a-45f6-a56a-df0480393a06",
   "metadata": {},
   "source": [
    "#### Cross-validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66407e3d-f2dd-42f7-9edb-86e5df40b921",
   "metadata": {},
   "source": [
    "We take the same 10% as test set and use the rest for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1284040-9bee-418d-8553-00b841f28694",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv = pd.concat([X_train, X_val], axis = 0)\n",
    "y1_train_cv = pd.concat([y1_train, y1_val], axis = 0)\n",
    "y1_diff_log_train_cv = pd.concat([y1_diff_log_train, y1_diff_log_val], axis = 0)\n",
    "y1_equal_05_train_cv = pd.concat([y1_equal_05_train, y1_equal_05_val], axis = 0)\n",
    "y1_equal_01_train_cv = pd.concat([y1_equal_01_train, y1_equal_01_val], axis = 0)\n",
    "y1_equal_005_train_cv = pd.concat([y1_equal_005_train, y1_equal_005_val], axis = 0)\n",
    "y1_equal_001_train_cv = pd.concat([y1_equal_001_train, y1_equal_001_val], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c447d54-2e48-47da-af1c-2c578a627db8",
   "metadata": {},
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "008e826a-c25c-419c-bf68-ed3c4a85c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2_classes = pd.DataFrame(columns=['acc', 'rec', 'acc', 'rec'])\n",
    "table_3_classes = pd.DataFrame(columns=['acc', 'rec-mic', 'rec_mac', 'acc', 'rec-mic', 'rec-mac'])\n",
    "table_time_diff = pd.DataFrame(columns=['MSE', 'MAE', 'R2', 'MSE', 'MAE', 'R2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95a2a9",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors with two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f047a-d888-48e8-9a39-44e31a51892f",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "549c3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_knn = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfb81a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[134,  22],\n",
       "       [ 30, 100]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_knn)\n",
    "recall = recall_score(y1_val, y1_pred_knn)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_knn)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fe0b7-d2ec-4e4f-8af2-b95ebd54bcb3",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb8232b4-8aa7-4bb2-90b9-e45449fae536",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_knn_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b78ec316-4464-4854-9034-44543fb90508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1149,  245],\n",
       "       [ 241,  939]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_knn_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_knn_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_knn_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3557599-f1ae-4b81-9a45-3eb34f8c7dc6",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6920f54d-d596-43e2-9d37-fc442b5458e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc       rec       acc       rec\n",
       "5-NN  0.818182  0.769231  0.811189  0.795763"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"5-NN\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50994022",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors with three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb561e-b438-467b-b835-3e22595e39b0",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e539db7e-1f89-475d-ab27-f7a05e749182",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e525178e-dd05-40b8-9e5d-bd0f5cd795f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_knn = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d25216c6-910f-43d1-9dae-66a2f5484894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 34,  18,   0],\n",
       "       [ 10, 135,  14],\n",
       "       [  2,  21,  52]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_knn)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_knn, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_knn, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_knn)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd6634b-080b-43b5-9ed7-de8dd80463a1",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5e345c7-419f-4130-a3f1-2da1b90603ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_knn_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2858828-5522-499c-8575-2203842855aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 299,  162,   28],\n",
       "       [  69, 1175,  118],\n",
       "       [  15,  138,  570]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_knn_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_knn_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_knn_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_knn_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb769a-9ca3-4865-b3f0-6046a953d658",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03e253cd-99bd-4fe6-a558-85aad20cf030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5  0.772727  0.772727  0.732079  0.794095  0.794095  0.754179"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"5-NN 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a35d4-d8c3-4d19-a149-46cd16a107b4",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b7eb4d-8762-4016-a910-abc63b8d451f",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ce1349f-788d-41f5-9039-385dd7a7c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_knn = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0aecff0-c1b5-40d1-af2d-64bf9aae5b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87, 21,  4],\n",
       "       [28, 35, 15],\n",
       "       [21, 12, 63]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_knn)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_knn, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_knn, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_knn)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7feaf-bdab-44bf-a3fd-d30e2b25457d",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "873cdaf4-8c75-48fc-a0f7-3b1e44b4c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_knn_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8de27d3b-b9e9-4b04-9f0a-927bc269331e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[767, 128, 101],\n",
       "       [240, 337,  91],\n",
       "       [115,  89, 706]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_knn_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_knn_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_knn_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_knn_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab7287-3f3f-4b98-a173-913e5b286bf7",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36670193-8560-4def-a17e-a0f8e3bf4b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5  0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1  0.646853  0.646853  0.627251  0.703186  0.703186  0.683465"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"5-NN 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11a8dba-0c77-4f31-86ca-1093dbdd350e",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c064be4-8289-4d63-a029-399f8586d992",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f18dfad5-9d52-4bec-93ff-d450c86cd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_knn = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36ec92c7-2d00-4465-96c9-18b69e2ca7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105,  16,  10],\n",
       "       [ 21,  16,  10],\n",
       "       [ 24,   7,  77]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_knn)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_knn, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_knn, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_knn)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7374c-64de-41bf-8033-2b4fc06b8009",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8a4cb63-aeab-4740-b7da-4c99f8900831",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_knn_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "59214179-d93d-4271-b7e3-2313714f78d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[943,  90, 133],\n",
       "       [179, 161,  66],\n",
       "       [163,  46, 793]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_knn_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_knn_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_knn_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_knn_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755e11e-0c73-4e24-8f0e-69d5fde1f0d5",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1e57d9c-cdd6-492f-a67e-e2112d125860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5   0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1   0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05  0.692308  0.692308  0.618305  0.736985  0.736985  0.665572"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"5-NN 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b955cd1-efd4-4df6-a887-e4672718fdc1",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15394473-e9d1-48b9-94d3-f79c01dbceb0",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef690209-d337-4d82-8ac0-7aea96ee3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_knn = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "663cdbc8-d71c-4539-99b6-160910866125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[136,   0,  17],\n",
       "       [  3,   0,   4],\n",
       "       [ 30,   0,  96]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_knn)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_knn, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_knn, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_knn)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21829c-5744-4fbc-84fe-95ea6132340b",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a2e6757f-946e-4612-b125-abb8859bbb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_knn_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "771d2e3c-85ce-479a-8dc1-26137d9c9d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1146,    3,  209],\n",
       "       [  47,    2,   27],\n",
       "       [ 236,    3,  901]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_knn_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_knn_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_knn_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_knn_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a1ba4-8715-491b-a259-f40d960145ec",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1bee0255-a527-4249-b44d-fdc3a56e3cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5   0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1   0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05  0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01  0.811189  0.811189  0.550265  0.796037  0.796037  0.553518"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"5-NN 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd9f80-53b6-4095-bcbc-51530dcb4f4c",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors with time difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6bd5f-3193-46da-9ec9-6627643c6300",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "402c0739-ac3f-402a-8388-623cab859950",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_knn = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf455b8e-c6e1-4446-ae9a-7179cb7df189",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_knn)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_knn)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7148db38-5f2e-49ea-93df-ec53366bd921",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "810e4e11-28e1-408b-a794-8a8d3a75393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_knn_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b7cbd17-354c-4f13-ab49-ee9357782d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_knn_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_knn_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_knn_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787fd7b-79e8-410a-8478-dc8c70956709",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "890f3948-906c-4730-ab96-fc7c07eee05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.587345</td>\n",
       "      <td>0.486148</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.480216</td>\n",
       "      <td>0.79731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MSE       MAE        R2       MSE       MAE       R2\n",
       "5-NN  0.587345  0.486148  0.793722  0.640365  0.480216  0.79731"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"5-NN\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69224a",
   "metadata": {},
   "source": [
    "### Decision tree with two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedbfff2",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21c7c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8f88c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137,  19],\n",
       "       [ 29, 101]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_dec_tree)\n",
    "recall = recall_score(y1_val, y1_pred_dec_tree)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1ed32",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f6d11479",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_dec_tree_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "decd8e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1185,  209],\n",
       "       [ 235,  945]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_dec_tree_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_dec_tree_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_dec_tree_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e41d8",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9895b035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec       acc       rec\n",
       "5-NN           0.818182  0.769231  0.811189  0.795763\n",
       "Decision tree  0.832168  0.776923  0.827506  0.800847"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"Decision tree\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52c066f",
   "metadata": {},
   "source": [
    "### Decision tree with three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f076d0",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e96e2a0",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8da0f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "67fda59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 32,  20,   0],\n",
       "       [  9, 140,  10],\n",
       "       [  2,  14,  59]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a3636",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd58b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_dec_tree_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6fb22ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 287,  174,   28],\n",
       "       [  63, 1204,   95],\n",
       "       [  17,  127,  579]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_dec_tree_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_dec_tree_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_dec_tree_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_dec_tree_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5effedd",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0db9ddb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5           0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1           0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05          0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01          0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5  0.807692  0.807692  0.760851  0.804196  0.804196  0.757245"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Decision tree 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6473a751",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54970263",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ce33a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69ceb943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91, 19,  2],\n",
       "       [27, 37, 14],\n",
       "       [12, 10, 74]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b4d29f",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "261f97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_dec_tree_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bf4d3099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[802,  96,  98],\n",
       "       [222, 366,  80],\n",
       "       [ 80,  92, 738]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_dec_tree_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_dec_tree_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_dec_tree_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_dec_tree_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b291c",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f4946d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5           0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1           0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05          0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01          0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5  0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1  0.706294  0.706294  0.685897  0.740482  0.740482  0.721371"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Decision tree 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084a60a",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff152136",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "80cd9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad05202a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,  11,   8],\n",
       "       [ 20,  17,  10],\n",
       "       [ 20,   7,  81]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb17d3f0",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e9cf6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_dec_tree_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3e7d46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[957,  72, 137],\n",
       "       [160, 183,  63],\n",
       "       [142,  42, 818]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_dec_tree_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_dec_tree_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_dec_tree_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_dec_tree_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49849f3",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af035c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Decision tree 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa462d",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c4484",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0bf5d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b72adefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[140,   0,  13],\n",
       "       [  3,   0,   4],\n",
       "       [ 28,   0,  98]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58082cb",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba9fad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_dec_tree_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "789681b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1165,    7,  186],\n",
       "       [  46,    4,   26],\n",
       "       [ 211,    3,  926]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_dec_tree_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_dec_tree_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_dec_tree_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_dec_tree_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2608ed3",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8dd861b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Decision tree 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de38015",
   "metadata": {},
   "source": [
    "### Decision tree with time difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f05b04",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "27a24832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(random_state = 20)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_dec_tree = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6cfcd96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_dec_tree)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_dec_tree)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_dec_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f0890",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1eaa6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_dec_tree_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7fa3e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_dec_tree_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_dec_tree_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_dec_tree_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e75ea",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8b05c814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.587345</td>\n",
       "      <td>0.486148</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.480216</td>\n",
       "      <td>0.797310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.490544</td>\n",
       "      <td>0.447684</td>\n",
       "      <td>0.827719</td>\n",
       "      <td>0.591385</td>\n",
       "      <td>0.455429</td>\n",
       "      <td>0.812813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN           0.587345  0.486148  0.793722  0.640365  0.480216  0.797310\n",
       "Decision tree  0.490544  0.447684  0.827719  0.591385  0.455429  0.812813"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"Decision tree\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf012823",
   "metadata": {},
   "source": [
    "### Random forest with two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e7ee1",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "43d8499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_rand_forest = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fe578b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[136,  20],\n",
       "       [ 27, 103]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_rand_forest)\n",
    "recall = recall_score(y1_val, y1_pred_rand_forest)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_rand_forest)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c685a0",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "44180d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_rand_forest_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1d82834b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1165,  229],\n",
       "       [ 216,  964]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_rand_forest_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_rand_forest_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_rand_forest_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1878260",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "023ddc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.827117</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec       acc       rec\n",
       "5-NN           0.818182  0.769231  0.811189  0.795763\n",
       "Decision tree  0.832168  0.776923  0.827506  0.800847\n",
       "Random forest  0.835664  0.792308  0.827117  0.816949"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"Random forest\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd1964",
   "metadata": {},
   "source": [
    "### Random forest with three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb244462",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f3cb44",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7747758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_rand_forest = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4772f656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 31,  21,   0],\n",
       "       [  6, 142,  11],\n",
       "       [  2,  13,  60]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_rand_forest)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6d899",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b3fe8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_rand_forest_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e70993ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 275,  182,   32],\n",
       "       [  48, 1209,  105],\n",
       "       [  14,  115,  594]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_rand_forest_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_rand_forest_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_rand_forest_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_rand_forest_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9317f",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aba63737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Random forest 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bda627",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c60d4d",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "15f0f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_rand_forest = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "96bac3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87, 23,  2],\n",
       "       [26, 38, 14],\n",
       "       [12, 10, 74]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_rand_forest)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd8d848",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e392246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_rand_forest_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8053740c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[773, 119, 104],\n",
       "       [211, 367,  90],\n",
       "       [ 71,  83, 756]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_rand_forest_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_rand_forest_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_rand_forest_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_rand_forest_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695bd14c",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f2ed5d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Random forest 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40de7fa",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f22a80",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "03a894d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_rand_forest = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "33f64bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109,  11,  11],\n",
       "       [ 17,  18,  12],\n",
       "       [ 19,   8,  81]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_rand_forest)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0257dd",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "05f0841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_rand_forest_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "93919c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[932,  85, 149],\n",
       "       [143, 192,  71],\n",
       "       [124,  41, 837]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_rand_forest_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_rand_forest_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_rand_forest_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_rand_forest_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae7e38",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "06f21a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Random forest 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89574b2f",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1c58c",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6129267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_rand_forest = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d01209d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137,   0,  16],\n",
       "       [  3,   0,   4],\n",
       "       [ 25,   0, 101]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_rand_forest)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106a24e",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "06f48990",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_rand_forest_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9050b8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1143,   11,  204],\n",
       "       [  44,    4,   28],\n",
       "       [ 195,    2,  943]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_rand_forest_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_rand_forest_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_rand_forest_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_rand_forest_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac611a5",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3c62c35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"Random forest 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa7cbd",
   "metadata": {},
   "source": [
    "### Random forest with time difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c32b59",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8f10dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=20)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_rand_forest = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "47796c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_rand_forest)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_rand_forest)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_rand_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076c87e",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "02da296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_rand_forest_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "77d813d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_rand_forest_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_rand_forest_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_rand_forest_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b18c80",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6f8f98ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.587345</td>\n",
       "      <td>0.486148</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.480216</td>\n",
       "      <td>0.797310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.490544</td>\n",
       "      <td>0.447684</td>\n",
       "      <td>0.827719</td>\n",
       "      <td>0.591385</td>\n",
       "      <td>0.455429</td>\n",
       "      <td>0.812813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.489989</td>\n",
       "      <td>0.448514</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.573214</td>\n",
       "      <td>0.453536</td>\n",
       "      <td>0.818565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN           0.587345  0.486148  0.793722  0.640365  0.480216  0.797310\n",
       "Decision tree  0.490544  0.447684  0.827719  0.591385  0.455429  0.812813\n",
       "Random forest  0.489989  0.448514  0.827914  0.573214  0.453536  0.818565"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"Random forest\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df977162",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine) with two classes, linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae0792",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6061e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "515ee3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115,  41],\n",
       "       [ 54,  76]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_svm_linear)\n",
    "recall = recall_score(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499c898",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "73a8fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4dd37701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[927, 467],\n",
       "       [445, 735]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8d45b4",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5bd51ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.827117</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.667832</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.645688</td>\n",
       "      <td>0.622881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec       acc       rec\n",
       "5-NN           0.818182  0.769231  0.811189  0.795763\n",
       "Decision tree  0.832168  0.776923  0.827506  0.800847\n",
       "Random forest  0.835664  0.792308  0.827117  0.816949\n",
       "SVM linear     0.667832  0.584615  0.645688  0.622881"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"SVM linear\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac95aca3",
   "metadata": {},
   "source": [
    "### SVM with three classes, linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec8d115",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0bb07",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "036a1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e568c9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26,  19,   7],\n",
       "       [  5, 152,   2],\n",
       "       [  1,  46,  28]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596a5660",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "af042cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d8310d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 242,  200,   47],\n",
       "       [  51, 1272,   39],\n",
       "       [  20,  451,  252]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde943a",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b5d415e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM linear 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c10d737",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c7b463",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "476b5239",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ca871091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52, 37, 23],\n",
       "       [18, 36, 24],\n",
       "       [16, 18, 62]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625e00e",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cc161cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d845f896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[438, 288, 270],\n",
       "       [133, 365, 170],\n",
       "       [151, 117, 642]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22d23c",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a582c918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452\n",
       "SVM linear 0.1      0.524476  0.524476  0.523886  0.561383  0.561383  0.563887"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM linear 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d9566",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7b781",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "51611518",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c265e101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,   0,  30],\n",
       "       [ 29,   0,  18],\n",
       "       [ 41,   0,  67]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b1b29",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "46cdfdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d92aa701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[807,   0, 359],\n",
       "       [277,   5, 124],\n",
       "       [330,   0, 672]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af38c11",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7b0028b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452\n",
       "SVM linear 0.1      0.524476  0.524476  0.523886  0.561383  0.561383  0.563887\n",
       "SVM linear 0.05     0.587413  0.587413  0.463788  0.576535  0.576535  0.458361"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM linear 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae534cf",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d71a1b",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "52e7615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e26bab46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115,   0,  38],\n",
       "       [  3,   0,   4],\n",
       "       [ 48,   0,  78]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ac34c",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d95d652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6c0f56ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[921,   0, 437],\n",
       "       [ 43,   0,  33],\n",
       "       [429,   0, 711]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294b1f3",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "073f136d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452\n",
       "SVM linear 0.1      0.524476  0.524476  0.523886  0.561383  0.561383  0.563887\n",
       "SVM linear 0.05     0.587413  0.587413  0.463788  0.576535  0.576535  0.458361\n",
       "SVM linear 0.01     0.674825  0.674825  0.456894  0.634033  0.634033  0.433962"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM linear 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ada10",
   "metadata": {},
   "source": [
    "### SVM with time difference, linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef859e",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7a457dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR(kernel='linear')\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_svm_linear = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "63c02e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_svm_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f718d5c",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "12b7e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7f044b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_svm_linear_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676d5cf",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bb9d28d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.587345</td>\n",
       "      <td>0.486148</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.480216</td>\n",
       "      <td>0.797310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.490544</td>\n",
       "      <td>0.447684</td>\n",
       "      <td>0.827719</td>\n",
       "      <td>0.591385</td>\n",
       "      <td>0.455429</td>\n",
       "      <td>0.812813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.489989</td>\n",
       "      <td>0.448514</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.573214</td>\n",
       "      <td>0.453536</td>\n",
       "      <td>0.818565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>1.696579</td>\n",
       "      <td>0.788013</td>\n",
       "      <td>0.404154</td>\n",
       "      <td>1.859457</td>\n",
       "      <td>0.828425</td>\n",
       "      <td>0.411439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN           0.587345  0.486148  0.793722  0.640365  0.480216  0.797310\n",
       "Decision tree  0.490544  0.447684  0.827719  0.591385  0.455429  0.812813\n",
       "Random forest  0.489989  0.448514  0.827914  0.573214  0.453536  0.818565\n",
       "SVM linear     1.696579  0.788013  0.404154  1.859457  0.828425  0.411439"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"SVM linear\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e330f9",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine) with two classes, polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee9ccdc",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cb542248",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a0072fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139,  17],\n",
       "       [ 64,  66]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_svm_linear)\n",
    "recall = recall_score(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5856416b",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fe010f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7139f422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1177,  217],\n",
       "       [ 626,  554]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08a8fc",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f84369a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.827117</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.667832</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.645688</td>\n",
       "      <td>0.622881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.672494</td>\n",
       "      <td>0.469492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec       acc       rec\n",
       "5-NN           0.818182  0.769231  0.811189  0.795763\n",
       "Decision tree  0.832168  0.776923  0.827506  0.800847\n",
       "Random forest  0.835664  0.792308  0.827117  0.816949\n",
       "SVM linear     0.667832  0.584615  0.645688  0.622881\n",
       "SVM poly       0.716783  0.507692  0.672494  0.469492"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"SVM poly\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49f5851",
   "metadata": {},
   "source": [
    "### SVM with three classes, polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a89846",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683caca",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6c62a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "17cee68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 24,  26,   2],\n",
       "       [  3, 151,   5],\n",
       "       [  1,  41,  33]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b8e00",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "21902402",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8967d924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 204,  263,   22],\n",
       "       [  40, 1263,   59],\n",
       "       [   7,  403,  313]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae0b85",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "af6ceabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.592470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452\n",
       "SVM linear 0.1      0.524476  0.524476  0.523886  0.561383  0.561383  0.563887\n",
       "SVM linear 0.05     0.587413  0.587413  0.463788  0.576535  0.576535  0.458361\n",
       "SVM linear 0.01     0.674825  0.674825  0.456894  0.634033  0.634033  0.433962\n",
       "SVM poly 0.5        0.727273  0.727273  0.617075  0.691531  0.691531  0.592470"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM poly 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e108394",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e5147",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8d13ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "35814096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70, 30, 12],\n",
       "       [39, 25, 14],\n",
       "       [33, 11, 52]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060482c8",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e12d60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "72484821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[690, 134, 172],\n",
       "       [410, 167,  91],\n",
       "       [343,  46, 521]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e8d34",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1e249e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.592470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.505100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452\n",
       "SVM linear 0.1      0.524476  0.524476  0.523886  0.561383  0.561383  0.563887\n",
       "SVM linear 0.05     0.587413  0.587413  0.463788  0.576535  0.576535  0.458361\n",
       "SVM linear 0.01     0.674825  0.674825  0.456894  0.634033  0.634033  0.433962\n",
       "SVM poly 0.5        0.727273  0.727273  0.617075  0.691531  0.691531  0.592470\n",
       "SVM poly 0.1        0.513986  0.513986  0.495726  0.535354  0.535354  0.505100"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM poly 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b65de",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d1381",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1a98c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f5200b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120,   0,  11],\n",
       "       [ 34,   3,  10],\n",
       "       [ 48,   0,  60]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13ac6c",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "54bc1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3cfd77ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[979,   3, 184],\n",
       "       [323,  30,  53],\n",
       "       [451,  11, 540]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004318f1",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6c449f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.592470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.505100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.511805</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.484145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452\n",
       "SVM linear 0.1      0.524476  0.524476  0.523886  0.561383  0.561383  0.563887\n",
       "SVM linear 0.05     0.587413  0.587413  0.463788  0.576535  0.576535  0.458361\n",
       "SVM linear 0.01     0.674825  0.674825  0.456894  0.634033  0.634033  0.433962\n",
       "SVM poly 0.5        0.727273  0.727273  0.617075  0.691531  0.691531  0.592470\n",
       "SVM poly 0.1        0.513986  0.513986  0.495726  0.535354  0.535354  0.505100\n",
       "SVM poly 0.05       0.639860  0.639860  0.511805  0.601787  0.601787  0.484145"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM poly 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a5b968",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75471ae4",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "81555e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "28f053b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139,   0,  14],\n",
       "       [  5,   0,   2],\n",
       "       [ 62,   0,  64]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e525fc2",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "08a8b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "36cdb9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1152,    0,  206],\n",
       "       [  58,    0,   18],\n",
       "       [ 597,    0,  543]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758fa1d",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bc10466d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.592470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.505100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.511805</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.484145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.472144</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.441541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452\n",
       "SVM linear 0.1      0.524476  0.524476  0.523886  0.561383  0.561383  0.563887\n",
       "SVM linear 0.05     0.587413  0.587413  0.463788  0.576535  0.576535  0.458361\n",
       "SVM linear 0.01     0.674825  0.674825  0.456894  0.634033  0.634033  0.433962\n",
       "SVM poly 0.5        0.727273  0.727273  0.617075  0.691531  0.691531  0.592470\n",
       "SVM poly 0.1        0.513986  0.513986  0.495726  0.535354  0.535354  0.505100\n",
       "SVM poly 0.05       0.639860  0.639860  0.511805  0.601787  0.601787  0.484145\n",
       "SVM poly 0.01       0.709790  0.709790  0.472144  0.658508  0.658508  0.441541"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM poly 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2937d580",
   "metadata": {},
   "source": [
    "### SVM with time difference, polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb681d91",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "86beae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR(kernel='poly')\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_svm_linear = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c2d344dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_svm_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f206e",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7b0ad86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0462dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_svm_linear_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2786a",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4fdd9672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.587345</td>\n",
       "      <td>0.486148</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.480216</td>\n",
       "      <td>0.797310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.490544</td>\n",
       "      <td>0.447684</td>\n",
       "      <td>0.827719</td>\n",
       "      <td>0.591385</td>\n",
       "      <td>0.455429</td>\n",
       "      <td>0.812813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.489989</td>\n",
       "      <td>0.448514</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.573214</td>\n",
       "      <td>0.453536</td>\n",
       "      <td>0.818565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>1.696579</td>\n",
       "      <td>0.788013</td>\n",
       "      <td>0.404154</td>\n",
       "      <td>1.859457</td>\n",
       "      <td>0.828425</td>\n",
       "      <td>0.411439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.741289</td>\n",
       "      <td>0.752971</td>\n",
       "      <td>0.388452</td>\n",
       "      <td>1.829105</td>\n",
       "      <td>0.784481</td>\n",
       "      <td>0.421047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN           0.587345  0.486148  0.793722  0.640365  0.480216  0.797310\n",
       "Decision tree  0.490544  0.447684  0.827719  0.591385  0.455429  0.812813\n",
       "Random forest  0.489989  0.448514  0.827914  0.573214  0.453536  0.818565\n",
       "SVM linear     1.696579  0.788013  0.404154  1.859457  0.828425  0.411439\n",
       "SVM poly       1.741289  0.752971  0.388452  1.829105  0.784481  0.421047"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"SVM poly\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc26c83",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine) with two classes, rbf kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e2590",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4ed81170",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8a95296b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133,  23],\n",
       "       [ 57,  73]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_svm_linear)\n",
    "recall = recall_score(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix = confusion_matrix(y1_val, y1_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd8a06b",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5503f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7ecfaec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1087,  307],\n",
       "       [ 562,  618]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "recall_cv = recall_score(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv = confusion_matrix(y1_train_cv, y1_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84bf4a6",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8a451a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.827117</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.667832</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.645688</td>\n",
       "      <td>0.622881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.672494</td>\n",
       "      <td>0.469492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.662393</td>\n",
       "      <td>0.523729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec       acc       rec\n",
       "5-NN           0.818182  0.769231  0.811189  0.795763\n",
       "Decision tree  0.832168  0.776923  0.827506  0.800847\n",
       "Random forest  0.835664  0.792308  0.827117  0.816949\n",
       "SVM linear     0.667832  0.584615  0.645688  0.622881\n",
       "SVM poly       0.716783  0.507692  0.672494  0.469492\n",
       "SVM rbf        0.720280  0.561538  0.662393  0.523729"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes.loc[\"SVM rbf\"] = [accuracy, recall, accuracy_cv, recall_cv]\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece3011",
   "metadata": {},
   "source": [
    "### SVM with three classes, rbf kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11581960",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb5551f",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "69d516c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e76a46dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26,  24,   2],\n",
       "       [  4, 152,   3],\n",
       "       [  0,  41,  34]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_val, y1_equal_05_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75d156",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a3a7ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_05_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6671733a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 270,  200,   19],\n",
       "       [  83, 1251,   28],\n",
       "       [  12,  422,  289]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_05_train_cv, y1_equal_05_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628896f8",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e35b66f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.592470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.505100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.511805</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.484145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.472144</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.441541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.5</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.636436</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.623458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452\n",
       "SVM linear 0.1      0.524476  0.524476  0.523886  0.561383  0.561383  0.563887\n",
       "SVM linear 0.05     0.587413  0.587413  0.463788  0.576535  0.576535  0.458361\n",
       "SVM linear 0.01     0.674825  0.674825  0.456894  0.634033  0.634033  0.433962\n",
       "SVM poly 0.5        0.727273  0.727273  0.617075  0.691531  0.691531  0.592470\n",
       "SVM poly 0.1        0.513986  0.513986  0.495726  0.535354  0.535354  0.505100\n",
       "SVM poly 0.05       0.639860  0.639860  0.511805  0.601787  0.601787  0.484145\n",
       "SVM poly 0.01       0.709790  0.709790  0.472144  0.658508  0.658508  0.441541\n",
       "SVM rbf 0.5         0.741259  0.741259  0.636436  0.703186  0.703186  0.623458"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM rbf 0.5\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f081aea",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3ae28c",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "113c5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a2118c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[68, 23, 21],\n",
       "       [38, 20, 20],\n",
       "       [25, 13, 58]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_val, y1_equal_01_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bcb3ef",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dbece742",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_01_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "366e57e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[644, 124, 228],\n",
       "       [349, 165, 154],\n",
       "       [304,  54, 552]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_01_train_cv, y1_equal_01_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74095c",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "97fb29ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.592470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.505100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.511805</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.484145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.472144</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.441541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.5</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.636436</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.623458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.1</th>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.489240</td>\n",
       "      <td>0.528749</td>\n",
       "      <td>0.528749</td>\n",
       "      <td>0.500062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452\n",
       "SVM linear 0.1      0.524476  0.524476  0.523886  0.561383  0.561383  0.563887\n",
       "SVM linear 0.05     0.587413  0.587413  0.463788  0.576535  0.576535  0.458361\n",
       "SVM linear 0.01     0.674825  0.674825  0.456894  0.634033  0.634033  0.433962\n",
       "SVM poly 0.5        0.727273  0.727273  0.617075  0.691531  0.691531  0.592470\n",
       "SVM poly 0.1        0.513986  0.513986  0.495726  0.535354  0.535354  0.505100\n",
       "SVM poly 0.05       0.639860  0.639860  0.511805  0.601787  0.601787  0.484145\n",
       "SVM poly 0.01       0.709790  0.709790  0.472144  0.658508  0.658508  0.441541\n",
       "SVM rbf 0.5         0.741259  0.741259  0.636436  0.703186  0.703186  0.623458\n",
       "SVM rbf 0.1         0.510490  0.510490  0.489240  0.528749  0.528749  0.500062"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM rbf 0.1\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753595c",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb38aba",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "66ca6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f448b2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116,   0,  15],\n",
       "       [ 32,   2,  13],\n",
       "       [ 45,   0,  63]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_val, y1_equal_005_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd550db",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cc9a335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_005_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c49d3cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[912,   0, 254],\n",
       "       [275,  16, 115],\n",
       "       [424,   3, 575]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_005_train_cv, y1_equal_005_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d8bdf",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ab8b349c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.592470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.505100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.511805</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.484145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.472144</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.441541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.5</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.636436</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.623458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.1</th>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.489240</td>\n",
       "      <td>0.528749</td>\n",
       "      <td>0.528749</td>\n",
       "      <td>0.500062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.05</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.503794</td>\n",
       "      <td>0.583916</td>\n",
       "      <td>0.583916</td>\n",
       "      <td>0.465141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452\n",
       "SVM linear 0.1      0.524476  0.524476  0.523886  0.561383  0.561383  0.563887\n",
       "SVM linear 0.05     0.587413  0.587413  0.463788  0.576535  0.576535  0.458361\n",
       "SVM linear 0.01     0.674825  0.674825  0.456894  0.634033  0.634033  0.433962\n",
       "SVM poly 0.5        0.727273  0.727273  0.617075  0.691531  0.691531  0.592470\n",
       "SVM poly 0.1        0.513986  0.513986  0.495726  0.535354  0.535354  0.505100\n",
       "SVM poly 0.05       0.639860  0.639860  0.511805  0.601787  0.601787  0.484145\n",
       "SVM poly 0.01       0.709790  0.709790  0.472144  0.658508  0.658508  0.441541\n",
       "SVM rbf 0.5         0.741259  0.741259  0.636436  0.703186  0.703186  0.623458\n",
       "SVM rbf 0.1         0.510490  0.510490  0.489240  0.528749  0.528749  0.500062\n",
       "SVM rbf 0.05        0.632867  0.632867  0.503794  0.583916  0.583916  0.465141"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM rbf 0.05\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04453aa",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d94eda2",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "317cc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_svm_linear = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "581c6c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[132,   0,  21],\n",
       "       [  3,   0,   4],\n",
       "       [ 56,   0,  70]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "recall_micro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_val, y1_equal_001_pred_svm_linear, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_svm_linear)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c9ef36",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a72a400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_pred_svm_linear_cv = cross_val_predict(clf, X_train_cv, y1_equal_001_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bca61f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1070,    0,  288],\n",
       "       [  50,    0,   26],\n",
       "       [ 547,    0,  593]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cv = accuracy_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "recall_micro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='micro')\n",
    "recall_macro_cv = recall_score(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv, average='macro')\n",
    "conf_matrix_cv = confusion_matrix(y1_equal_001_train_cv, y1_equal_001_pred_svm_linear_cv)\n",
    "conf_matrix_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64edf7cd",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6a49411c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.592470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.505100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.511805</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.484145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.472144</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.441541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.5</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.636436</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.623458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.1</th>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.489240</td>\n",
       "      <td>0.528749</td>\n",
       "      <td>0.528749</td>\n",
       "      <td>0.500062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.05</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.503794</td>\n",
       "      <td>0.583916</td>\n",
       "      <td>0.583916</td>\n",
       "      <td>0.465141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.01</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.472767</td>\n",
       "      <td>0.646076</td>\n",
       "      <td>0.646076</td>\n",
       "      <td>0.436033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac       acc   rec-mic   rec-mac\n",
       "5-NN 0.5            0.772727  0.772727  0.732079  0.794095  0.794095  0.754179\n",
       "5-NN 0.1            0.646853  0.646853  0.627251  0.703186  0.703186  0.683465\n",
       "5-NN 0.05           0.692308  0.692308  0.618305  0.736985  0.736985  0.665572\n",
       "5-NN 0.01           0.811189  0.811189  0.550265  0.796037  0.796037  0.553518\n",
       "Decision tree 0.5   0.807692  0.807692  0.760851  0.804196  0.804196  0.757245\n",
       "Decision tree 0.1   0.706294  0.706294  0.685897  0.740482  0.740482  0.721371\n",
       "Decision tree 0.05  0.734266  0.734266  0.655555  0.760684  0.760684  0.695954\n",
       "Decision tree 0.01  0.832168  0.832168  0.564270  0.813908  0.813908  0.574264\n",
       "Random forest 0.5   0.814685  0.814685  0.763079  0.807304  0.807304  0.757205\n",
       "Random forest 0.1   0.695804  0.695804  0.678266  0.736597  0.736597  0.718758\n",
       "Random forest 0.05  0.727273  0.727273  0.655013  0.761849  0.761849  0.702517\n",
       "Random forest 0.01  0.832168  0.832168  0.565671  0.811966  0.811966  0.573835\n",
       "SVM linear 0.5      0.720280  0.720280  0.609769  0.686092  0.686092  0.592452\n",
       "SVM linear 0.1      0.524476  0.524476  0.523886  0.561383  0.561383  0.563887\n",
       "SVM linear 0.05     0.587413  0.587413  0.463788  0.576535  0.576535  0.458361\n",
       "SVM linear 0.01     0.674825  0.674825  0.456894  0.634033  0.634033  0.433962\n",
       "SVM poly 0.5        0.727273  0.727273  0.617075  0.691531  0.691531  0.592470\n",
       "SVM poly 0.1        0.513986  0.513986  0.495726  0.535354  0.535354  0.505100\n",
       "SVM poly 0.05       0.639860  0.639860  0.511805  0.601787  0.601787  0.484145\n",
       "SVM poly 0.01       0.709790  0.709790  0.472144  0.658508  0.658508  0.441541\n",
       "SVM rbf 0.5         0.741259  0.741259  0.636436  0.703186  0.703186  0.623458\n",
       "SVM rbf 0.1         0.510490  0.510490  0.489240  0.528749  0.528749  0.500062\n",
       "SVM rbf 0.05        0.632867  0.632867  0.503794  0.583916  0.583916  0.465141\n",
       "SVM rbf 0.01        0.706294  0.706294  0.472767  0.646076  0.646076  0.436033"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes.loc[\"SVM rbf 0.01\"] = [accuracy, recall_micro, recall_macro, accuracy_cv, recall_micro_cv, recall_macro_cv]\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d33926",
   "metadata": {},
   "source": [
    "### SVM with time difference, rbf kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08098924",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0a5f6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR(kernel='rbf')\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_svm_linear = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "29ef7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "mae = mean_absolute_error(y1_diff_log_val, y1_pred_svm_linear)\n",
    "r2 = r2_score(y1_diff_log_val, y1_pred_svm_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a31d26c",
   "metadata": {},
   "source": [
    "CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "42654a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_svm_linear_cv = cross_val_predict(model, X_train_cv, y1_diff_log_train_cv, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "62801a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cv = mean_squared_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "mae_cv = mean_absolute_error(y1_diff_log_train_cv, y1_pred_svm_linear_cv)\n",
    "r2_cv = r2_score(y1_diff_log_train_cv, y1_pred_svm_linear_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380bc3f3",
   "metadata": {},
   "source": [
    "Adding the values to the result table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0e1c7b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.587345</td>\n",
       "      <td>0.486148</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.480216</td>\n",
       "      <td>0.797310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.490544</td>\n",
       "      <td>0.447684</td>\n",
       "      <td>0.827719</td>\n",
       "      <td>0.591385</td>\n",
       "      <td>0.455429</td>\n",
       "      <td>0.812813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.489989</td>\n",
       "      <td>0.448514</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.573214</td>\n",
       "      <td>0.453536</td>\n",
       "      <td>0.818565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>1.696579</td>\n",
       "      <td>0.788013</td>\n",
       "      <td>0.404154</td>\n",
       "      <td>1.859457</td>\n",
       "      <td>0.828425</td>\n",
       "      <td>0.411439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.741289</td>\n",
       "      <td>0.752971</td>\n",
       "      <td>0.388452</td>\n",
       "      <td>1.829105</td>\n",
       "      <td>0.784481</td>\n",
       "      <td>0.421047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.618412</td>\n",
       "      <td>0.724068</td>\n",
       "      <td>0.431607</td>\n",
       "      <td>1.792327</td>\n",
       "      <td>0.772814</td>\n",
       "      <td>0.432687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN           0.587345  0.486148  0.793722  0.640365  0.480216  0.797310\n",
       "Decision tree  0.490544  0.447684  0.827719  0.591385  0.455429  0.812813\n",
       "Random forest  0.489989  0.448514  0.827914  0.573214  0.453536  0.818565\n",
       "SVM linear     1.696579  0.788013  0.404154  1.859457  0.828425  0.411439\n",
       "SVM poly       1.741289  0.752971  0.388452  1.829105  0.784481  0.421047\n",
       "SVM rbf        1.618412  0.724068  0.431607  1.792327  0.772814  0.432687"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff.loc[\"SVM rbf\"] = [mse, mae, r2, mse_cv, mae_cv, r2_cv]\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923b6a7-26ef-4965-9d52-7c87cf822b61",
   "metadata": {},
   "source": [
    "### Deep MLP with two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ccff145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.values).float()  # Convert DataFrame to tensor\n",
    "        self.y = torch.from_numpy(y.values).float()  # Convert DataFrame to tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d8e1e7dd-6de4-4b65-8ffe-3be825213b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_classification(X_training, y_training, X_validation, y_validation, type, text):\n",
    "    custom_dataset = CustomDataset(X_training, y_training)\n",
    "    trainloader = DataLoader(custom_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "    mlp = MLPClassifier(random_seed=20)\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()  \n",
    "        \n",
    "    optimizer = torch.optim.Adagrad(mlp.parameters(), lr=0.1)\n",
    "\n",
    "    val_data = torch.tensor(X_validation.values, dtype=torch.float32)\n",
    "    val_targets = torch.tensor(y_validation.values, dtype=torch.float32)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(300):\n",
    "        print(f'Starting Epoch {epoch+1}')\n",
    "    \n",
    "        current_loss = 0.0\n",
    "    \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, targets = data\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = mlp(inputs)\n",
    "    \n",
    "            targets = targets.long()  # Convert target tensor to torch.long data type\n",
    "            loss = loss_function(outputs, targets)\n",
    "    \n",
    "            loss.backward()\n",
    "    \n",
    "            optimizer.step()\n",
    "    \n",
    "            current_loss += loss.item()\n",
    "    \n",
    "        print(current_loss/len(trainloader))\n",
    "    \n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = mlp(val_data).squeeze()\n",
    "            val_targets = val_targets.long()\n",
    "            val_loss = loss_function(val_outputs, val_targets).item()\n",
    "            #print(f'Validation loss: {val_loss}')\n",
    "    \n",
    "        # Check if this is the best model so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = deepcopy(mlp.state_dict())\n",
    "            print(f'New best model found at epoch {epoch+1} with validation loss {best_val_loss}')\n",
    "    \n",
    "    print(\"Training has completed\")\n",
    "\n",
    "\n",
    "    mlp2 = MLPClassifier(random_seed=20)\n",
    "    mlp2.load_state_dict(best_model_state)\n",
    "    \n",
    "    mlp2.eval() \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = mlp2(val_data).squeeze()\n",
    "        predicted_labels = torch.argmax(outputs, dim=1).numpy()\n",
    "    \n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    val_targets = np.array(val_targets)\n",
    "\n",
    "    if type == \"2_class\":\n",
    "        accuracy = accuracy_score(val_targets, predicted_labels)\n",
    "        recall = recall_score(val_targets, predicted_labels)\n",
    "        conf_matrix = confusion_matrix(val_targets, predicted_labels)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_2_classes.loc[text] = [accuracy, recall, \"-\", \"-\"]\n",
    "\n",
    "    if type == \"3_class\":\n",
    "        accuracy = accuracy_score(val_targets, predicted_labels)\n",
    "        recall_micro = recall_score(val_targets, predicted_labels, average='micro')\n",
    "        recall_macro = recall_score(val_targets, predicted_labels, average='macro')\n",
    "        conf_matrix = confusion_matrix(val_targets, predicted_labels)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_3_classes.loc[text] = [accuracy, recall_micro, recall_macro, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1e502",
   "metadata": {},
   "source": [
    "#### 3-layer MLP\n",
    "*  Loss: Cross-Entropy\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd7ff9",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 1\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 5 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c3826161-f841-4258-8583-3e8587111eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 2)\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0ea35f07-5887-40ce-9361-3eebac924761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.8133384611295618\n",
      "New best model found at epoch 1 with validation loss 0.6539586186408997\n",
      "Starting Epoch 2\n",
      "0.6572251449460569\n",
      "New best model found at epoch 2 with validation loss 0.642664909362793\n",
      "Starting Epoch 3\n",
      "0.649490053239076\n",
      "New best model found at epoch 3 with validation loss 0.6302491426467896\n",
      "Starting Epoch 4\n",
      "0.6419217949328215\n",
      "New best model found at epoch 4 with validation loss 0.6237388253211975\n",
      "Starting Epoch 5\n",
      "0.6343243225761082\n",
      "New best model found at epoch 5 with validation loss 0.616034209728241\n",
      "Starting Epoch 6\n",
      "0.6313253667043603\n",
      "New best model found at epoch 6 with validation loss 0.610986053943634\n",
      "Starting Epoch 7\n",
      "0.6243960598240728\n",
      "New best model found at epoch 7 with validation loss 0.6052023768424988\n",
      "Starting Epoch 8\n",
      "0.6193454809810804\n",
      "Starting Epoch 9\n",
      "0.6153599257054536\n",
      "New best model found at epoch 9 with validation loss 0.5980369448661804\n",
      "Starting Epoch 10\n",
      "0.6145659555559573\n",
      "New best model found at epoch 10 with validation loss 0.5955740809440613\n",
      "Starting Epoch 11\n",
      "0.606786020424055\n",
      "New best model found at epoch 11 with validation loss 0.5910962224006653\n",
      "Starting Epoch 12\n",
      "0.6053016626316569\n",
      "Starting Epoch 13\n",
      "0.6017389971276988\n",
      "New best model found at epoch 13 with validation loss 0.5882547497749329\n",
      "Starting Epoch 14\n",
      "0.6011175746503084\n",
      "New best model found at epoch 14 with validation loss 0.5880868434906006\n",
      "Starting Epoch 15\n",
      "0.5996226124141527\n",
      "New best model found at epoch 15 with validation loss 0.5871919989585876\n",
      "Starting Epoch 16\n",
      "0.5989705194597659\n",
      "New best model found at epoch 16 with validation loss 0.584825873374939\n",
      "Starting Epoch 17\n",
      "0.5969474859859633\n",
      "New best model found at epoch 17 with validation loss 0.5831655263900757\n",
      "Starting Epoch 18\n",
      "0.5985874404077944\n",
      "New best model found at epoch 18 with validation loss 0.5826067924499512\n",
      "Starting Epoch 19\n",
      "0.5938918331395024\n",
      "Starting Epoch 20\n",
      "0.5905833995860555\n",
      "New best model found at epoch 20 with validation loss 0.5822010636329651\n",
      "Starting Epoch 21\n",
      "0.5907796776813009\n",
      "Starting Epoch 22\n",
      "0.5927933765494305\n",
      "New best model found at epoch 22 with validation loss 0.5818750262260437\n",
      "Starting Epoch 23\n",
      "0.5898034287535626\n",
      "Starting Epoch 24\n",
      "0.5924481697704481\n",
      "Starting Epoch 25\n",
      "0.5889355307040007\n",
      "New best model found at epoch 25 with validation loss 0.5784294605255127\n",
      "Starting Epoch 26\n",
      "0.5891399383544922\n",
      "Starting Epoch 27\n",
      "0.5929655873257181\n",
      "New best model found at epoch 27 with validation loss 0.5779790282249451\n",
      "Starting Epoch 28\n",
      "0.5887067395707836\n",
      "Starting Epoch 29\n",
      "0.5874638142793075\n",
      "Starting Epoch 30\n",
      "0.5874708165293154\n",
      "Starting Epoch 31\n",
      "0.586928683778514\n",
      "Starting Epoch 32\n",
      "0.5849346129790597\n",
      "Starting Epoch 33\n",
      "0.5843074762302897\n",
      "Starting Epoch 34\n",
      "0.5851891351782758\n",
      "New best model found at epoch 34 with validation loss 0.5768868327140808\n",
      "Starting Epoch 35\n",
      "0.5846974797870802\n",
      "New best model found at epoch 35 with validation loss 0.5758993029594421\n",
      "Starting Epoch 36\n",
      "0.5870014506837596\n",
      "Starting Epoch 37\n",
      "0.5845554807911748\n",
      "Starting Epoch 38\n",
      "0.5845328543497168\n",
      "Starting Epoch 39\n",
      "0.582814626071764\n",
      "Starting Epoch 40\n",
      "0.5829273203144902\n",
      "Starting Epoch 41\n",
      "0.5827244766380476\n",
      "New best model found at epoch 41 with validation loss 0.574908971786499\n",
      "Starting Epoch 42\n",
      "0.5835611638815507\n",
      "Starting Epoch 43\n",
      "0.5809671127277872\n",
      "Starting Epoch 44\n",
      "0.5828517999338068\n",
      "Starting Epoch 45\n",
      "0.5803515444631162\n",
      "Starting Epoch 46\n",
      "0.5814414166885874\n",
      "Starting Epoch 47\n",
      "0.5810498672982921\n",
      "Starting Epoch 48\n",
      "0.5824431466019672\n",
      "New best model found at epoch 48 with validation loss 0.57440584897995\n",
      "Starting Epoch 49\n",
      "0.5804786086082458\n",
      "Starting Epoch 50\n",
      "0.5828965098961539\n",
      "Starting Epoch 51\n",
      "0.580328995766847\n",
      "Starting Epoch 52\n",
      "0.5796441358068715\n",
      "Starting Epoch 53\n",
      "0.5813027102014293\n",
      "Starting Epoch 54\n",
      "0.5791125375291576\n",
      "Starting Epoch 55\n",
      "0.5794999936352605\n",
      "New best model found at epoch 55 with validation loss 0.5739359855651855\n",
      "Starting Epoch 56\n",
      "0.5795764029026031\n",
      "Starting Epoch 57\n",
      "0.5805802280488221\n",
      "Starting Epoch 58\n",
      "0.5809787615485813\n",
      "Starting Epoch 59\n",
      "0.5811441203822261\n",
      "Starting Epoch 60\n",
      "0.5786253550778264\n",
      "New best model found at epoch 60 with validation loss 0.5730232000350952\n",
      "Starting Epoch 61\n",
      "0.5802717312522556\n",
      "Starting Epoch 62\n",
      "0.5782684929992842\n",
      "Starting Epoch 63\n",
      "0.5797226066174714\n",
      "New best model found at epoch 63 with validation loss 0.5729695558547974\n",
      "Starting Epoch 64\n",
      "0.5785451350004777\n",
      "Starting Epoch 65\n",
      "0.5806319609932278\n",
      "Starting Epoch 66\n",
      "0.5789614682612212\n",
      "Starting Epoch 67\n",
      "0.5798411136088164\n",
      "New best model found at epoch 67 with validation loss 0.5724161267280579\n",
      "Starting Epoch 68\n",
      "0.5784681737422943\n",
      "Starting Epoch 69\n",
      "0.5772783937661544\n",
      "New best model found at epoch 69 with validation loss 0.5722236633300781\n",
      "Starting Epoch 70\n",
      "0.5773909428845281\n",
      "Starting Epoch 71\n",
      "0.5779401400814885\n",
      "Starting Epoch 72\n",
      "0.5793125357316888\n",
      "New best model found at epoch 72 with validation loss 0.5715344548225403\n",
      "Starting Epoch 73\n",
      "0.5785321593284607\n",
      "Starting Epoch 74\n",
      "0.5793977289096169\n",
      "Starting Epoch 75\n",
      "0.5780303607816282\n",
      "New best model found at epoch 75 with validation loss 0.5708698630332947\n",
      "Starting Epoch 76\n",
      "0.5777333508367124\n",
      "Starting Epoch 77\n",
      "0.579804785873579\n",
      "Starting Epoch 78\n",
      "0.5799394029638042\n",
      "Starting Epoch 79\n",
      "0.5779292894446332\n",
      "New best model found at epoch 79 with validation loss 0.5708482265472412\n",
      "Starting Epoch 80\n",
      "0.5780562473380048\n",
      "New best model found at epoch 80 with validation loss 0.5705319046974182\n",
      "Starting Epoch 81\n",
      "0.577117128216702\n",
      "Starting Epoch 82\n",
      "0.5761597454547882\n",
      "New best model found at epoch 82 with validation loss 0.5698273181915283\n",
      "Starting Epoch 83\n",
      "0.5755908489227295\n",
      "Starting Epoch 84\n",
      "0.574909164853718\n",
      "Starting Epoch 85\n",
      "0.5761908396430637\n",
      "Starting Epoch 86\n",
      "0.576660244361214\n",
      "Starting Epoch 87\n",
      "0.5752520872199017\n",
      "Starting Epoch 88\n",
      "0.5760436524515566\n",
      "Starting Epoch 89\n",
      "0.5763715078001437\n",
      "Starting Epoch 90\n",
      "0.57643788534662\n",
      "New best model found at epoch 90 with validation loss 0.5695635676383972\n",
      "Starting Epoch 91\n",
      "0.5760176777839661\n",
      "Starting Epoch 92\n",
      "0.5763297495634659\n",
      "Starting Epoch 93\n",
      "0.5763433290564496\n",
      "New best model found at epoch 93 with validation loss 0.5690436363220215\n",
      "Starting Epoch 94\n",
      "0.5769200143606766\n",
      "Starting Epoch 95\n",
      "0.5768403981042944\n",
      "Starting Epoch 96\n",
      "0.5758261162301769\n",
      "Starting Epoch 97\n",
      "0.5750604647657146\n",
      "Starting Epoch 98\n",
      "0.5758127958878226\n",
      "New best model found at epoch 98 with validation loss 0.5685979723930359\n",
      "Starting Epoch 99\n",
      "0.576228564200194\n",
      "Starting Epoch 100\n",
      "0.5739920553953751\n",
      "Starting Epoch 101\n",
      "0.5756104847659236\n",
      "Starting Epoch 102\n",
      "0.5734277367591858\n",
      "Starting Epoch 103\n",
      "0.5757641222165979\n",
      "Starting Epoch 104\n",
      "0.5747702976931697\n",
      "Starting Epoch 105\n",
      "0.57397994917372\n",
      "Starting Epoch 106\n",
      "0.573409431654474\n",
      "Starting Epoch 107\n",
      "0.5742077671963236\n",
      "Starting Epoch 108\n",
      "0.5759099670078444\n",
      "Starting Epoch 109\n",
      "0.5744138878324757\n",
      "Starting Epoch 110\n",
      "0.5753618064134017\n",
      "New best model found at epoch 110 with validation loss 0.567287266254425\n",
      "Starting Epoch 111\n",
      "0.5721871995407602\n",
      "Starting Epoch 112\n",
      "0.5736803153286809\n",
      "Starting Epoch 113\n",
      "0.5740548812824747\n",
      "Starting Epoch 114\n",
      "0.573800600093344\n",
      "Starting Epoch 115\n",
      "0.5742684214011483\n",
      "New best model found at epoch 115 with validation loss 0.5671308040618896\n",
      "Starting Epoch 116\n",
      "0.5719099692676378\n",
      "New best model found at epoch 116 with validation loss 0.5670893788337708\n",
      "Starting Epoch 117\n",
      "0.5738755140615546\n",
      "Starting Epoch 118\n",
      "0.5738412932209347\n",
      "New best model found at epoch 118 with validation loss 0.5658028721809387\n",
      "Starting Epoch 119\n",
      "0.5734427804532258\n",
      "Starting Epoch 120\n",
      "0.5712986860586249\n",
      "Starting Epoch 121\n",
      "0.5711089230102041\n",
      "Starting Epoch 122\n",
      "0.5716875247333361\n",
      "Starting Epoch 123\n",
      "0.5719703643218331\n",
      "Starting Epoch 124\n",
      "0.5722618906394296\n",
      "Starting Epoch 125\n",
      "0.5725110108437745\n",
      "Starting Epoch 126\n",
      "0.5747742471487626\n",
      "Starting Epoch 127\n",
      "0.5717149739680083\n",
      "Starting Epoch 128\n",
      "0.572039052196171\n",
      "New best model found at epoch 128 with validation loss 0.5655836462974548\n",
      "Starting Epoch 129\n",
      "0.5717850340449292\n",
      "New best model found at epoch 129 with validation loss 0.564517617225647\n",
      "Starting Epoch 130\n",
      "0.5705802544303562\n",
      "Starting Epoch 131\n",
      "0.5722302898116733\n",
      "Starting Epoch 132\n",
      "0.5718809495801511\n",
      "Starting Epoch 133\n",
      "0.5722055176030034\n",
      "Starting Epoch 134\n",
      "0.5712889873463175\n",
      "Starting Epoch 135\n",
      "0.5724570543869681\n",
      "New best model found at epoch 135 with validation loss 0.5639325976371765\n",
      "Starting Epoch 136\n",
      "0.5712543544561967\n",
      "Starting Epoch 137\n",
      "0.5719220379124517\n",
      "Starting Epoch 138\n",
      "0.571041780969371\n",
      "Starting Epoch 139\n",
      "0.570412401271903\n",
      "Starting Epoch 140\n",
      "0.571444438851398\n",
      "New best model found at epoch 140 with validation loss 0.5636851191520691\n",
      "Starting Epoch 141\n",
      "0.5712131106335184\n",
      "Starting Epoch 142\n",
      "0.5716657794040182\n",
      "Starting Epoch 143\n",
      "0.5713135807410531\n",
      "Starting Epoch 144\n",
      "0.569772913404133\n",
      "Starting Epoch 145\n",
      "0.5702983724034351\n",
      "New best model found at epoch 145 with validation loss 0.5632715225219727\n",
      "Starting Epoch 146\n",
      "0.5713940716308096\n",
      "New best model found at epoch 146 with validation loss 0.5628176331520081\n",
      "Starting Epoch 147\n",
      "0.5695848387220631\n",
      "Starting Epoch 148\n",
      "0.5704791869806207\n",
      "New best model found at epoch 148 with validation loss 0.5627031922340393\n",
      "Starting Epoch 149\n",
      "0.5708679634591808\n",
      "Starting Epoch 150\n",
      "0.5690013584883317\n",
      "Starting Epoch 151\n",
      "0.5693668671276259\n",
      "New best model found at epoch 151 with validation loss 0.5622453689575195\n",
      "Starting Epoch 152\n",
      "0.5704088249932164\n",
      "Starting Epoch 153\n",
      "0.5711802840232849\n",
      "New best model found at epoch 153 with validation loss 0.5619439482688904\n",
      "Starting Epoch 154\n",
      "0.5715142436649489\n",
      "Starting Epoch 155\n",
      "0.568568670231363\n",
      "Starting Epoch 156\n",
      "0.5695439680762913\n",
      "Starting Epoch 157\n",
      "0.5701573361521182\n",
      "New best model found at epoch 157 with validation loss 0.5617021918296814\n",
      "Starting Epoch 158\n",
      "0.5695408945498259\n",
      "New best model found at epoch 158 with validation loss 0.561286449432373\n",
      "Starting Epoch 159\n",
      "0.5692674232565839\n",
      "Starting Epoch 160\n",
      "0.5704904159773951\n",
      "Starting Epoch 161\n",
      "0.5712017883425173\n",
      "New best model found at epoch 161 with validation loss 0.5611273050308228\n",
      "Starting Epoch 162\n",
      "0.567465224991674\n",
      "Starting Epoch 163\n",
      "0.569680050663326\n",
      "Starting Epoch 164\n",
      "0.5703159505906312\n",
      "Starting Epoch 165\n",
      "0.5697852191717728\n",
      "Starting Epoch 166\n",
      "0.5691920752110688\n",
      "Starting Epoch 167\n",
      "0.5676624826762987\n",
      "Starting Epoch 168\n",
      "0.570972494457079\n",
      "New best model found at epoch 168 with validation loss 0.560916006565094\n",
      "Starting Epoch 169\n",
      "0.5714085775872936\n",
      "New best model found at epoch 169 with validation loss 0.5608727931976318\n",
      "Starting Epoch 170\n",
      "0.5695664986320164\n",
      "Starting Epoch 171\n",
      "0.5698922872543335\n",
      "Starting Epoch 172\n",
      "0.5691304815852124\n",
      "New best model found at epoch 172 with validation loss 0.5602390170097351\n",
      "Starting Epoch 173\n",
      "0.5674781332845273\n",
      "Starting Epoch 174\n",
      "0.5689597674038099\n",
      "Starting Epoch 175\n",
      "0.5687286840832751\n",
      "Starting Epoch 176\n",
      "0.5684399954650713\n",
      "Starting Epoch 177\n",
      "0.5690826255342235\n",
      "Starting Epoch 178\n",
      "0.5687692307907602\n",
      "Starting Epoch 179\n",
      "0.5675035378207332\n",
      "Starting Epoch 180\n",
      "0.5683381376059159\n",
      "Starting Epoch 181\n",
      "0.5676146033017532\n",
      "New best model found at epoch 181 with validation loss 0.560003399848938\n",
      "Starting Epoch 182\n",
      "0.5674475833125736\n",
      "New best model found at epoch 182 with validation loss 0.5598629713058472\n",
      "Starting Epoch 183\n",
      "0.5682686748711959\n",
      "Starting Epoch 184\n",
      "0.5677452709363855\n",
      "New best model found at epoch 184 with validation loss 0.5591592788696289\n",
      "Starting Epoch 185\n",
      "0.5666458567847377\n",
      "Starting Epoch 186\n",
      "0.5671682487363401\n",
      "Starting Epoch 187\n",
      "0.5697634686594424\n",
      "New best model found at epoch 187 with validation loss 0.5587964653968811\n",
      "Starting Epoch 188\n",
      "0.5681301238744155\n",
      "Starting Epoch 189\n",
      "0.5669859453387882\n",
      "Starting Epoch 190\n",
      "0.5674569865931636\n",
      "Starting Epoch 191\n",
      "0.5683033608871958\n",
      "Starting Epoch 192\n",
      "0.5683532694111699\n",
      "Starting Epoch 193\n",
      "0.5679637297340061\n",
      "New best model found at epoch 193 with validation loss 0.5582364797592163\n",
      "Starting Epoch 194\n",
      "0.5681706148645153\n",
      "Starting Epoch 195\n",
      "0.5665051004161006\n",
      "New best model found at epoch 195 with validation loss 0.55795818567276\n",
      "Starting Epoch 196\n",
      "0.5664278890775598\n",
      "Starting Epoch 197\n",
      "0.5663346181745115\n",
      "Starting Epoch 198\n",
      "0.5656661378300708\n",
      "Starting Epoch 199\n",
      "0.5669312528941942\n",
      "Starting Epoch 200\n",
      "0.5674952605496282\n",
      "Starting Epoch 201\n",
      "0.566796081221622\n",
      "Starting Epoch 202\n",
      "0.5662973160329072\n",
      "Starting Epoch 203\n",
      "0.5661061224730118\n",
      "New best model found at epoch 203 with validation loss 0.5575920343399048\n",
      "Starting Epoch 204\n",
      "0.5668040578779967\n",
      "Starting Epoch 205\n",
      "0.566758930683136\n",
      "Starting Epoch 206\n",
      "0.5676764573739923\n",
      "New best model found at epoch 206 with validation loss 0.5574324131011963\n",
      "Starting Epoch 207\n",
      "0.5669985905937527\n",
      "New best model found at epoch 207 with validation loss 0.557347297668457\n",
      "Starting Epoch 208\n",
      "0.5674377109693445\n",
      "Starting Epoch 209\n",
      "0.5655665112578351\n",
      "New best model found at epoch 209 with validation loss 0.5568715929985046\n",
      "Starting Epoch 210\n",
      "0.5655908791915231\n",
      "Starting Epoch 211\n",
      "0.5665439082228619\n",
      "Starting Epoch 212\n",
      "0.5676762047021285\n",
      "Starting Epoch 213\n",
      "0.5682139344837355\n",
      "Starting Epoch 214\n",
      "0.5668201874131742\n",
      "Starting Epoch 215\n",
      "0.5654939166877581\n",
      "Starting Epoch 216\n",
      "0.566922216311745\n",
      "New best model found at epoch 216 with validation loss 0.5564189553260803\n",
      "Starting Epoch 217\n",
      "0.5657108711159747\n",
      "Starting Epoch 218\n",
      "0.5655466318130493\n",
      "Starting Epoch 219\n",
      "0.5652780481006788\n",
      "Starting Epoch 220\n",
      "0.5653093146241229\n",
      "Starting Epoch 221\n",
      "0.5658148682635763\n",
      "Starting Epoch 222\n",
      "0.5666915385619454\n",
      "Starting Epoch 223\n",
      "0.5657062621220298\n",
      "Starting Epoch 224\n",
      "0.5652548800344053\n",
      "New best model found at epoch 224 with validation loss 0.5561884045600891\n",
      "Starting Epoch 225\n",
      "0.5661840387012648\n",
      "Starting Epoch 226\n",
      "0.5658202326816061\n",
      "New best model found at epoch 226 with validation loss 0.5558818578720093\n",
      "Starting Epoch 227\n",
      "0.566247679617094\n",
      "Starting Epoch 228\n",
      "0.5660280403883561\n",
      "Starting Epoch 229\n",
      "0.5652787503988846\n",
      "New best model found at epoch 229 with validation loss 0.5553464889526367\n",
      "Starting Epoch 230\n",
      "0.5646388038345005\n",
      "Starting Epoch 231\n",
      "0.5651859874310701\n",
      "Starting Epoch 232\n",
      "0.5645957550276881\n",
      "Starting Epoch 233\n",
      "0.564372929541961\n",
      "Starting Epoch 234\n",
      "0.5656914801701255\n",
      "Starting Epoch 235\n",
      "0.5655338777148206\n",
      "Starting Epoch 236\n",
      "0.5639475869095844\n",
      "Starting Epoch 237\n",
      "0.5660551294036533\n",
      "Starting Epoch 238\n",
      "0.5633778377719547\n",
      "Starting Epoch 239\n",
      "0.56483811787937\n",
      "New best model found at epoch 239 with validation loss 0.5551078915596008\n",
      "Starting Epoch 240\n",
      "0.5660519807235055\n",
      "Starting Epoch 241\n",
      "0.5637638555920642\n",
      "Starting Epoch 242\n",
      "0.5650106150171031\n",
      "Starting Epoch 243\n",
      "0.5652071522629779\n",
      "New best model found at epoch 243 with validation loss 0.5545707941055298\n",
      "Starting Epoch 244\n",
      "0.566435834635859\n",
      "Starting Epoch 245\n",
      "0.5642834538998811\n",
      "Starting Epoch 246\n",
      "0.5630833415881448\n",
      "Starting Epoch 247\n",
      "0.5647200916124426\n",
      "Starting Epoch 248\n",
      "0.5652950963248378\n",
      "Starting Epoch 249\n",
      "0.5644742794658827\n",
      "New best model found at epoch 249 with validation loss 0.5545231699943542\n",
      "Starting Epoch 250\n",
      "0.5631955240083777\n",
      "Starting Epoch 251\n",
      "0.5659294970657515\n",
      "Starting Epoch 252\n",
      "0.5647452771663666\n",
      "Starting Epoch 253\n",
      "0.564830649158229\n",
      "Starting Epoch 254\n",
      "0.5654493013153905\n",
      "Starting Epoch 255\n",
      "0.5631575986095096\n",
      "New best model found at epoch 255 with validation loss 0.5539098381996155\n",
      "Starting Epoch 256\n",
      "0.5635657802872036\n",
      "Starting Epoch 257\n",
      "0.564788651207219\n",
      "Starting Epoch 258\n",
      "0.5650819643684055\n",
      "Starting Epoch 259\n",
      "0.5644969434841819\n",
      "New best model found at epoch 259 with validation loss 0.5538120269775391\n",
      "Starting Epoch 260\n",
      "0.5643968530323195\n",
      "Starting Epoch 261\n",
      "0.5653734103493069\n",
      "Starting Epoch 262\n",
      "0.5633366004280422\n",
      "Starting Epoch 263\n",
      "0.5649174503658129\n",
      "Starting Epoch 264\n",
      "0.5631381389887437\n",
      "Starting Epoch 265\n",
      "0.5645611597144086\n",
      "Starting Epoch 266\n",
      "0.5637988888699076\n",
      "Starting Epoch 267\n",
      "0.5645333165707795\n",
      "Starting Epoch 268\n",
      "0.564107323470323\n",
      "New best model found at epoch 268 with validation loss 0.5536289811134338\n",
      "Starting Epoch 269\n",
      "0.5632776319980621\n",
      "Starting Epoch 270\n",
      "0.5643281716367473\n",
      "New best model found at epoch 270 with validation loss 0.5530467629432678\n",
      "Starting Epoch 271\n",
      "0.5640246323917223\n",
      "Starting Epoch 272\n",
      "0.5641184708346492\n",
      "Starting Epoch 273\n",
      "0.5635947209337483\n",
      "Starting Epoch 274\n",
      "0.5647442029870074\n",
      "Starting Epoch 275\n",
      "0.5637484788894653\n",
      "Starting Epoch 276\n",
      "0.5625413630319678\n",
      "Starting Epoch 277\n",
      "0.5633185065310934\n",
      "Starting Epoch 278\n",
      "0.5643417822278064\n",
      "Starting Epoch 279\n",
      "0.5642639165339263\n",
      "New best model found at epoch 279 with validation loss 0.5526909232139587\n",
      "Starting Epoch 280\n",
      "0.5644950452058212\n",
      "Starting Epoch 281\n",
      "0.5646488524001577\n",
      "Starting Epoch 282\n",
      "0.563930895017541\n",
      "Starting Epoch 283\n",
      "0.5632488779399706\n",
      "Starting Epoch 284\n",
      "0.5656639324582141\n",
      "Starting Epoch 285\n",
      "0.56443139521972\n",
      "Starting Epoch 286\n",
      "0.5639223223147185\n",
      "Starting Epoch 287\n",
      "0.562988641469375\n",
      "Starting Epoch 288\n",
      "0.5643774348756542\n",
      "Starting Epoch 289\n",
      "0.5631210207939148\n",
      "Starting Epoch 290\n",
      "0.5629688799381256\n",
      "Starting Epoch 291\n",
      "0.563399199558341\n",
      "Starting Epoch 292\n",
      "0.5636928664601367\n",
      "Starting Epoch 293\n",
      "0.5639178804729296\n",
      "New best model found at epoch 293 with validation loss 0.552207887172699\n",
      "Starting Epoch 294\n",
      "0.5634726078613944\n",
      "New best model found at epoch 294 with validation loss 0.5521600842475891\n",
      "Starting Epoch 295\n",
      "0.5625546237696772\n",
      "Starting Epoch 296\n",
      "0.5632060481154401\n",
      "Starting Epoch 297\n",
      "0.5644740384557972\n",
      "Starting Epoch 298\n",
      "0.5617943289487258\n",
      "Starting Epoch 299\n",
      "0.5629636774892393\n",
      "Starting Epoch 300\n",
      "0.5626744990763457\n",
      "New best model found at epoch 300 with validation loss 0.5518826246261597\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-5-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a4253",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 2\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 10 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7a2250d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "cd5431a3-d32b-4fb0-9907-8adf99ca7338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.6970291163610376\n",
      "New best model found at epoch 1 with validation loss 0.6871519088745117\n",
      "Starting Epoch 2\n",
      "0.686880103919817\n",
      "New best model found at epoch 2 with validation loss 0.6824237704277039\n",
      "Starting Epoch 3\n",
      "0.6810923996179\n",
      "New best model found at epoch 3 with validation loss 0.6771054267883301\n",
      "Starting Epoch 4\n",
      "0.6744619556095289\n",
      "New best model found at epoch 4 with validation loss 0.6736710667610168\n",
      "Starting Epoch 5\n",
      "0.6688369460727858\n",
      "New best model found at epoch 5 with validation loss 0.6709988713264465\n",
      "Starting Epoch 6\n",
      "0.6624059184737827\n",
      "New best model found at epoch 6 with validation loss 0.6641414761543274\n",
      "Starting Epoch 7\n",
      "0.657385237838911\n",
      "New best model found at epoch 7 with validation loss 0.6618032455444336\n",
      "Starting Epoch 8\n",
      "0.6540401474289272\n",
      "New best model found at epoch 8 with validation loss 0.6577649712562561\n",
      "Starting Epoch 9\n",
      "0.6529508544051129\n",
      "New best model found at epoch 9 with validation loss 0.6556533575057983\n",
      "Starting Epoch 10\n",
      "0.6493981947069583\n",
      "New best model found at epoch 10 with validation loss 0.6545249819755554\n",
      "Starting Epoch 11\n",
      "0.6472676370454871\n",
      "New best model found at epoch 11 with validation loss 0.653884768486023\n",
      "Starting Epoch 12\n",
      "0.6451305539711661\n",
      "New best model found at epoch 12 with validation loss 0.6534518599510193\n",
      "Starting Epoch 13\n",
      "0.6434541681538457\n",
      "Starting Epoch 14\n",
      "0.6425608344700026\n",
      "Starting Epoch 15\n",
      "0.6426293020663054\n",
      "Starting Epoch 16\n",
      "0.6415168254271798\n",
      "New best model found at epoch 16 with validation loss 0.653079628944397\n",
      "Starting Epoch 17\n",
      "0.6414969615314318\n",
      "Starting Epoch 18\n",
      "0.6400526243707408\n",
      "Starting Epoch 19\n",
      "0.6404062872347625\n",
      "Starting Epoch 20\n",
      "0.6402048572250034\n",
      "Starting Epoch 21\n",
      "0.640661719052688\n",
      "Starting Epoch 22\n",
      "0.6400765387908273\n",
      "Starting Epoch 23\n",
      "0.6397754472234974\n",
      "Starting Epoch 24\n",
      "0.6394638108170551\n",
      "Starting Epoch 25\n",
      "0.6399948415548905\n",
      "Starting Epoch 26\n",
      "0.6393398357474286\n",
      "Starting Epoch 27\n",
      "0.6392630701479705\n",
      "Starting Epoch 28\n",
      "0.6385609922201737\n",
      "New best model found at epoch 28 with validation loss 0.6530146598815918\n",
      "Starting Epoch 29\n",
      "0.6391703305037125\n",
      "Starting Epoch 30\n",
      "0.6386660026467365\n",
      "Starting Epoch 31\n",
      "0.6385905250259067\n",
      "Starting Epoch 32\n",
      "0.6390619122463724\n",
      "Starting Epoch 33\n",
      "0.6388884575470634\n",
      "Starting Epoch 34\n",
      "0.6385490997977878\n",
      "Starting Epoch 35\n",
      "0.6384815521862196\n",
      "New best model found at epoch 35 with validation loss 0.6529258489608765\n",
      "Starting Epoch 36\n",
      "0.6392990350723267\n",
      "Starting Epoch 37\n",
      "0.6380650271540103\n",
      "New best model found at epoch 37 with validation loss 0.6526837944984436\n",
      "Starting Epoch 38\n",
      "0.638252387876096\n",
      "New best model found at epoch 38 with validation loss 0.6526806950569153\n",
      "Starting Epoch 39\n",
      "0.6384218983028246\n",
      "Starting Epoch 40\n",
      "0.6376312375068665\n",
      "Starting Epoch 41\n",
      "0.6388218636098115\n",
      "New best model found at epoch 41 with validation loss 0.6524533629417419\n",
      "Starting Epoch 42\n",
      "0.6386760499166406\n",
      "Starting Epoch 43\n",
      "0.6379299578459366\n",
      "Starting Epoch 44\n",
      "0.6377968606741532\n",
      "Starting Epoch 45\n",
      "0.6378397578778474\n",
      "Starting Epoch 46\n",
      "0.6376835185548534\n",
      "Starting Epoch 47\n",
      "0.6378157346144967\n",
      "Starting Epoch 48\n",
      "0.6379921980526136\n",
      "Starting Epoch 49\n",
      "0.6384848770887955\n",
      "Starting Epoch 50\n",
      "0.6378857622975889\n",
      "New best model found at epoch 50 with validation loss 0.6523998975753784\n",
      "Starting Epoch 51\n",
      "0.6373825565628384\n",
      "Starting Epoch 52\n",
      "0.6374598249145176\n",
      "New best model found at epoch 52 with validation loss 0.6522201299667358\n",
      "Starting Epoch 53\n",
      "0.6374668193900067\n",
      "Starting Epoch 54\n",
      "0.6374689858892689\n",
      "Starting Epoch 55\n",
      "0.6373793223629827\n",
      "Starting Epoch 56\n",
      "0.637541317421457\n",
      "New best model found at epoch 56 with validation loss 0.6520297527313232\n",
      "Starting Epoch 57\n",
      "0.637022992838984\n",
      "Starting Epoch 58\n",
      "0.6368179502694503\n",
      "Starting Epoch 59\n",
      "0.6366885097130485\n",
      "Starting Epoch 60\n",
      "0.6368634001068447\n",
      "Starting Epoch 61\n",
      "0.637121459712153\n",
      "Starting Epoch 62\n",
      "0.6367138857426851\n",
      "New best model found at epoch 62 with validation loss 0.6518470048904419\n",
      "Starting Epoch 63\n",
      "0.6369126724160236\n",
      "Starting Epoch 64\n",
      "0.6370926136555879\n",
      "New best model found at epoch 64 with validation loss 0.6515628099441528\n",
      "Starting Epoch 65\n",
      "0.6367921492327815\n",
      "Starting Epoch 66\n",
      "0.6367621680964595\n",
      "New best model found at epoch 66 with validation loss 0.6514718532562256\n",
      "Starting Epoch 67\n",
      "0.6365565087484277\n",
      "New best model found at epoch 67 with validation loss 0.6514040231704712\n",
      "Starting Epoch 68\n",
      "0.6367074976796689\n",
      "New best model found at epoch 68 with validation loss 0.6513540744781494\n",
      "Starting Epoch 69\n",
      "0.6369861468024876\n",
      "Starting Epoch 70\n",
      "0.6364902931710948\n",
      "Starting Epoch 71\n",
      "0.6366437906804292\n",
      "Starting Epoch 72\n",
      "0.6368836708690809\n",
      "Starting Epoch 73\n",
      "0.6369341119475986\n",
      "Starting Epoch 74\n",
      "0.6365142749703449\n",
      "New best model found at epoch 74 with validation loss 0.6510595679283142\n",
      "Starting Epoch 75\n",
      "0.6365254288134368\n",
      "Starting Epoch 76\n",
      "0.6364855040674624\n",
      "Starting Epoch 77\n",
      "0.635912185129912\n",
      "New best model found at epoch 77 with validation loss 0.6509701013565063\n",
      "Starting Epoch 78\n",
      "0.6367706423220427\n",
      "Starting Epoch 79\n",
      "0.6366714394610861\n",
      "Starting Epoch 80\n",
      "0.6362634871316992\n",
      "Starting Epoch 81\n",
      "0.6361612884894662\n",
      "Starting Epoch 82\n",
      "0.6357476711273193\n",
      "Starting Epoch 83\n",
      "0.6362360923186593\n",
      "Starting Epoch 84\n",
      "0.636231875937918\n",
      "Starting Epoch 85\n",
      "0.6366354330726292\n",
      "New best model found at epoch 85 with validation loss 0.6508943438529968\n",
      "Starting Epoch 86\n",
      "0.6358395555745\n",
      "New best model found at epoch 86 with validation loss 0.6506105065345764\n",
      "Starting Epoch 87\n",
      "0.6362553834915161\n",
      "Starting Epoch 88\n",
      "0.636281114557515\n",
      "Starting Epoch 89\n",
      "0.6356962711914725\n",
      "Starting Epoch 90\n",
      "0.6362475778745569\n",
      "Starting Epoch 91\n",
      "0.6355605255002561\n",
      "Starting Epoch 92\n",
      "0.6360689842182657\n",
      "Starting Epoch 93\n",
      "0.6359403392542964\n",
      "Starting Epoch 94\n",
      "0.6355246046315068\n",
      "New best model found at epoch 94 with validation loss 0.650588870048523\n",
      "Starting Epoch 95\n",
      "0.6356456720310709\n",
      "Starting Epoch 96\n",
      "0.6354328445766283\n",
      "Starting Epoch 97\n",
      "0.635699476884759\n",
      "Starting Epoch 98\n",
      "0.635573394920515\n",
      "Starting Epoch 99\n",
      "0.6355721976446069\n",
      "Starting Epoch 100\n",
      "0.6355744315230328\n",
      "Starting Epoch 101\n",
      "0.6357219685678897\n",
      "Starting Epoch 102\n",
      "0.6350787126499674\n",
      "Starting Epoch 103\n",
      "0.6354029619175455\n",
      "New best model found at epoch 103 with validation loss 0.6502667665481567\n",
      "Starting Epoch 104\n",
      "0.6355754240699436\n",
      "Starting Epoch 105\n",
      "0.6349514593248782\n",
      "Starting Epoch 106\n",
      "0.6353166699409485\n",
      "Starting Epoch 107\n",
      "0.6352137016213458\n",
      "Starting Epoch 108\n",
      "0.6354480904081593\n",
      "Starting Epoch 109\n",
      "0.6346342952355094\n",
      "Starting Epoch 110\n",
      "0.6353939071945522\n",
      "Starting Epoch 111\n",
      "0.6350641898486925\n",
      "New best model found at epoch 111 with validation loss 0.650096595287323\n",
      "Starting Epoch 112\n",
      "0.6354712092358134\n",
      "Starting Epoch 113\n",
      "0.6351725744164508\n",
      "New best model found at epoch 113 with validation loss 0.6498190760612488\n",
      "Starting Epoch 114\n",
      "0.6348668259123097\n",
      "Starting Epoch 115\n",
      "0.6351178184799526\n",
      "Starting Epoch 116\n",
      "0.6350301763285762\n",
      "New best model found at epoch 116 with validation loss 0.6497635841369629\n",
      "Starting Epoch 117\n",
      "0.6351294387941775\n",
      "Starting Epoch 118\n",
      "0.6347785825314729\n",
      "New best model found at epoch 118 with validation loss 0.6496668457984924\n",
      "Starting Epoch 119\n",
      "0.6347158628961315\n",
      "Starting Epoch 120\n",
      "0.6348049899806147\n",
      "Starting Epoch 121\n",
      "0.6350003662316696\n",
      "Starting Epoch 122\n",
      "0.6346379363018534\n",
      "Starting Epoch 123\n",
      "0.6352207867995553\n",
      "New best model found at epoch 123 with validation loss 0.6493889093399048\n",
      "Starting Epoch 124\n",
      "0.6350035822909811\n",
      "Starting Epoch 125\n",
      "0.6344272546146227\n",
      "Starting Epoch 126\n",
      "0.6344550822092139\n",
      "Starting Epoch 127\n",
      "0.6345940698748049\n",
      "Starting Epoch 128\n",
      "0.6347137197204258\n",
      "Starting Epoch 129\n",
      "0.6351467500562253\n",
      "Starting Epoch 130\n",
      "0.6347608669944431\n",
      "Starting Epoch 131\n",
      "0.6342871785163879\n",
      "Starting Epoch 132\n",
      "0.6351406677909519\n",
      "Starting Epoch 133\n",
      "0.6346377237983372\n",
      "Starting Epoch 134\n",
      "0.6350655296574468\n",
      "Starting Epoch 135\n",
      "0.634584146997203\n",
      "Starting Epoch 136\n",
      "0.6345681910929473\n",
      "New best model found at epoch 136 with validation loss 0.6490300893783569\n",
      "Starting Epoch 137\n",
      "0.6338997975639675\n",
      "Starting Epoch 138\n",
      "0.634691456089849\n",
      "Starting Epoch 139\n",
      "0.6346777029659437\n",
      "Starting Epoch 140\n",
      "0.6347003423649332\n",
      "Starting Epoch 141\n",
      "0.6342897985292517\n",
      "Starting Epoch 142\n",
      "0.6337636994278949\n",
      "Starting Epoch 143\n",
      "0.6349591768306234\n",
      "Starting Epoch 144\n",
      "0.6344548930292544\n",
      "Starting Epoch 145\n",
      "0.6344255053478739\n",
      "Starting Epoch 146\n",
      "0.6342576586681864\n",
      "Starting Epoch 147\n",
      "0.6343098360559215\n",
      "Starting Epoch 148\n",
      "0.6346791282944058\n",
      "New best model found at epoch 148 with validation loss 0.6489538550376892\n",
      "Starting Epoch 149\n",
      "0.6343949437141418\n",
      "Starting Epoch 150\n",
      "0.6340610799582108\n",
      "Starting Epoch 151\n",
      "0.6341472397679868\n",
      "Starting Epoch 152\n",
      "0.6346559809601825\n",
      "Starting Epoch 153\n",
      "0.6338326930999756\n",
      "New best model found at epoch 153 with validation loss 0.6487327814102173\n",
      "Starting Epoch 154\n",
      "0.6343102532884349\n",
      "New best model found at epoch 154 with validation loss 0.6487027406692505\n",
      "Starting Epoch 155\n",
      "0.633999368418818\n",
      "Starting Epoch 156\n",
      "0.6341837644577026\n",
      "Starting Epoch 157\n",
      "0.6339909926704739\n",
      "Starting Epoch 158\n",
      "0.6339435888373334\n",
      "Starting Epoch 159\n",
      "0.6339015183241471\n",
      "New best model found at epoch 159 with validation loss 0.6482288241386414\n",
      "Starting Epoch 160\n",
      "0.6342761620231296\n",
      "Starting Epoch 161\n",
      "0.6337244717971139\n",
      "Starting Epoch 162\n",
      "0.6338902271312216\n",
      "Starting Epoch 163\n",
      "0.6337081323499265\n",
      "Starting Epoch 164\n",
      "0.6336950219195822\n",
      "New best model found at epoch 164 with validation loss 0.648097813129425\n",
      "Starting Epoch 165\n",
      "0.6334018240804258\n",
      "Starting Epoch 166\n",
      "0.6339775893999182\n",
      "Starting Epoch 167\n",
      "0.6338589839313341\n",
      "New best model found at epoch 167 with validation loss 0.6480074524879456\n",
      "Starting Epoch 168\n",
      "0.6338928963827051\n",
      "Starting Epoch 169\n",
      "0.6336835985598357\n",
      "New best model found at epoch 169 with validation loss 0.6479634642601013\n",
      "Starting Epoch 170\n",
      "0.6334444776825283\n",
      "Starting Epoch 171\n",
      "0.6334385146265444\n",
      "New best model found at epoch 171 with validation loss 0.6478695273399353\n",
      "Starting Epoch 172\n",
      "0.633687947107398\n",
      "Starting Epoch 173\n",
      "0.6333214951598126\n",
      "Starting Epoch 174\n",
      "0.6337745863458385\n",
      "Starting Epoch 175\n",
      "0.6335819778235062\n",
      "Starting Epoch 176\n",
      "0.6335798398308132\n",
      "Starting Epoch 177\n",
      "0.6333792961162069\n",
      "Starting Epoch 178\n",
      "0.6333591756613358\n",
      "New best model found at epoch 178 with validation loss 0.6477271914482117\n",
      "Starting Epoch 179\n",
      "0.6330295282861461\n",
      "Starting Epoch 180\n",
      "0.6337153263714003\n",
      "Starting Epoch 181\n",
      "0.6335312024406765\n",
      "New best model found at epoch 181 with validation loss 0.6476812958717346\n",
      "Starting Epoch 182\n",
      "0.6339282212050065\n",
      "New best model found at epoch 182 with validation loss 0.6475542187690735\n",
      "Starting Epoch 183\n",
      "0.6337094695671744\n",
      "Starting Epoch 184\n",
      "0.6327942661617113\n",
      "New best model found at epoch 184 with validation loss 0.6474291682243347\n",
      "Starting Epoch 185\n",
      "0.633007666339045\n",
      "Starting Epoch 186\n",
      "0.6330977056337439\n",
      "Starting Epoch 187\n",
      "0.63331088035003\n",
      "New best model found at epoch 187 with validation loss 0.6472598314285278\n",
      "Starting Epoch 188\n",
      "0.6329347387604092\n",
      "Starting Epoch 189\n",
      "0.6331093492715255\n",
      "Starting Epoch 190\n",
      "0.6330664909404257\n",
      "New best model found at epoch 190 with validation loss 0.6471115350723267\n",
      "Starting Epoch 191\n",
      "0.6333721461503402\n",
      "Starting Epoch 192\n",
      "0.6331415228221727\n",
      "Starting Epoch 193\n",
      "0.6329483752665312\n",
      "Starting Epoch 194\n",
      "0.6330024470453677\n",
      "Starting Epoch 195\n",
      "0.6329564763152081\n",
      "Starting Epoch 196\n",
      "0.6329784211905106\n",
      "Starting Epoch 197\n",
      "0.6327745940374292\n",
      "Starting Epoch 198\n",
      "0.6329579171927079\n",
      "Starting Epoch 199\n",
      "0.6331801595895187\n",
      "New best model found at epoch 199 with validation loss 0.6469788551330566\n",
      "Starting Epoch 200\n",
      "0.6328901700351549\n",
      "New best model found at epoch 200 with validation loss 0.6469537615776062\n",
      "Starting Epoch 201\n",
      "0.6329941334931747\n",
      "Starting Epoch 202\n",
      "0.6331462704617045\n",
      "New best model found at epoch 202 with validation loss 0.6468596458435059\n",
      "Starting Epoch 203\n",
      "0.6328384772590969\n",
      "New best model found at epoch 203 with validation loss 0.6468393206596375\n",
      "Starting Epoch 204\n",
      "0.6329206487406855\n",
      "New best model found at epoch 204 with validation loss 0.6467902064323425\n",
      "Starting Epoch 205\n",
      "0.6326340670170991\n",
      "Starting Epoch 206\n",
      "0.632692637650863\n",
      "Starting Epoch 207\n",
      "0.6326324602831965\n",
      "Starting Epoch 208\n",
      "0.6331896445025569\n",
      "Starting Epoch 209\n",
      "0.6329418161640996\n",
      "New best model found at epoch 209 with validation loss 0.6466087102890015\n",
      "Starting Epoch 210\n",
      "0.6334217398062997\n",
      "Starting Epoch 211\n",
      "0.6322475697683252\n",
      "Starting Epoch 212\n",
      "0.632716539113418\n",
      "New best model found at epoch 212 with validation loss 0.6465263366699219\n",
      "Starting Epoch 213\n",
      "0.6321387912916101\n",
      "Starting Epoch 214\n",
      "0.6324966135232345\n",
      "New best model found at epoch 214 with validation loss 0.6464604735374451\n",
      "Starting Epoch 215\n",
      "0.6324806835340417\n",
      "Starting Epoch 216\n",
      "0.6322486115538556\n",
      "Starting Epoch 217\n",
      "0.6327531726463981\n",
      "Starting Epoch 218\n",
      "0.6330374919849894\n",
      "Starting Epoch 219\n",
      "0.632615133472111\n",
      "New best model found at epoch 219 with validation loss 0.6462529301643372\n",
      "Starting Epoch 220\n",
      "0.6321569966233295\n",
      "Starting Epoch 221\n",
      "0.632287719975347\n",
      "Starting Epoch 222\n",
      "0.6324131255564482\n",
      "Starting Epoch 223\n",
      "0.6326076103293378\n",
      "Starting Epoch 224\n",
      "0.6323640553847604\n",
      "Starting Epoch 225\n",
      "0.6320860308149586\n",
      "Starting Epoch 226\n",
      "0.6325225208116614\n",
      "New best model found at epoch 226 with validation loss 0.6460782289505005\n",
      "Starting Epoch 227\n",
      "0.6322344826615375\n",
      "Starting Epoch 228\n",
      "0.6322971478752468\n",
      "Starting Epoch 229\n",
      "0.6329016840976217\n",
      "Starting Epoch 230\n",
      "0.632024524004563\n",
      "New best model found at epoch 230 with validation loss 0.6460440754890442\n",
      "Starting Epoch 231\n",
      "0.63195916880732\n",
      "Starting Epoch 232\n",
      "0.6323238533476124\n",
      "New best model found at epoch 232 with validation loss 0.645969569683075\n",
      "Starting Epoch 233\n",
      "0.6315376732660376\n",
      "New best model found at epoch 233 with validation loss 0.6459556818008423\n",
      "Starting Epoch 234\n",
      "0.6321181473524674\n",
      "Starting Epoch 235\n",
      "0.6328845438749894\n",
      "Starting Epoch 236\n",
      "0.632704830687979\n",
      "New best model found at epoch 236 with validation loss 0.6458730101585388\n",
      "Starting Epoch 237\n",
      "0.6316717448441879\n",
      "New best model found at epoch 237 with validation loss 0.6456716656684875\n",
      "Starting Epoch 238\n",
      "0.6320227021756379\n",
      "Starting Epoch 239\n",
      "0.6319956364838973\n",
      "New best model found at epoch 239 with validation loss 0.6456509232521057\n",
      "Starting Epoch 240\n",
      "0.6319128404492917\n",
      "Starting Epoch 241\n",
      "0.6320968995923582\n",
      "Starting Epoch 242\n",
      "0.6318613083466239\n",
      "New best model found at epoch 242 with validation loss 0.6456106901168823\n",
      "Starting Epoch 243\n",
      "0.6321642683899921\n",
      "New best model found at epoch 243 with validation loss 0.6455503106117249\n",
      "Starting Epoch 244\n",
      "0.6318529066832169\n",
      "New best model found at epoch 244 with validation loss 0.645513653755188\n",
      "Starting Epoch 245\n",
      "0.632098887277686\n",
      "Starting Epoch 246\n",
      "0.6321152137673419\n",
      "New best model found at epoch 246 with validation loss 0.6454491019248962\n",
      "Starting Epoch 247\n",
      "0.6318565918051678\n",
      "New best model found at epoch 247 with validation loss 0.6453930735588074\n",
      "Starting Epoch 248\n",
      "0.6319224860357202\n",
      "New best model found at epoch 248 with validation loss 0.6452738046646118\n",
      "Starting Epoch 249\n",
      "0.6319649685984072\n",
      "New best model found at epoch 249 with validation loss 0.6452448964118958\n",
      "Starting Epoch 250\n",
      "0.6321794572083846\n",
      "New best model found at epoch 250 with validation loss 0.6452162861824036\n",
      "Starting Epoch 251\n",
      "0.6316385113674662\n",
      "Starting Epoch 252\n",
      "0.6320532508518385\n",
      "Starting Epoch 253\n",
      "0.6318048782970594\n",
      "Starting Epoch 254\n",
      "0.6318050700685253\n",
      "Starting Epoch 255\n",
      "0.6320203775944917\n",
      "Starting Epoch 256\n",
      "0.6317991977152617\n",
      "Starting Epoch 257\n",
      "0.6319258342618528\n",
      "New best model found at epoch 257 with validation loss 0.6450992226600647\n",
      "Starting Epoch 258\n",
      "0.6315327597701031\n",
      "Starting Epoch 259\n",
      "0.6315411847570668\n",
      "Starting Epoch 260\n",
      "0.632005688936814\n",
      "Starting Epoch 261\n",
      "0.6317297790361487\n",
      "Starting Epoch 262\n",
      "0.6317669723344885\n",
      "Starting Epoch 263\n",
      "0.6317507857861726\n",
      "Starting Epoch 264\n",
      "0.6314448014549587\n",
      "Starting Epoch 265\n",
      "0.6314743783162988\n",
      "Starting Epoch 266\n",
      "0.6319737849028214\n",
      "New best model found at epoch 266 with validation loss 0.6448337435722351\n",
      "Starting Epoch 267\n",
      "0.6316179581310438\n",
      "Starting Epoch 268\n",
      "0.6316166571948839\n",
      "Starting Epoch 269\n",
      "0.6316672926363738\n",
      "Starting Epoch 270\n",
      "0.6314908525218135\n",
      "New best model found at epoch 270 with validation loss 0.6448144912719727\n",
      "Starting Epoch 271\n",
      "0.6317577543465988\n",
      "New best model found at epoch 271 with validation loss 0.6447809338569641\n",
      "Starting Epoch 272\n",
      "0.6317281463871831\n",
      "New best model found at epoch 272 with validation loss 0.6447414755821228\n",
      "Starting Epoch 273\n",
      "0.6313065782837246\n",
      "Starting Epoch 274\n",
      "0.6312923638716988\n",
      "New best model found at epoch 274 with validation loss 0.6446241140365601\n",
      "Starting Epoch 275\n",
      "0.6320125512454821\n",
      "Starting Epoch 276\n",
      "0.631386707658353\n",
      "Starting Epoch 277\n",
      "0.6317928718483966\n",
      "New best model found at epoch 277 with validation loss 0.6445869207382202\n",
      "Starting Epoch 278\n",
      "0.631183782349462\n",
      "Starting Epoch 279\n",
      "0.6311929433242135\n",
      "Starting Epoch 280\n",
      "0.6313844038092572\n",
      "New best model found at epoch 280 with validation loss 0.6445338726043701\n",
      "Starting Epoch 281\n",
      "0.6313211917877197\n",
      "Starting Epoch 282\n",
      "0.6315202505692191\n",
      "Starting Epoch 283\n",
      "0.6317571401596069\n",
      "New best model found at epoch 283 with validation loss 0.6443952918052673\n",
      "Starting Epoch 284\n",
      "0.6314506712167159\n",
      "Starting Epoch 285\n",
      "0.6308073116385419\n",
      "New best model found at epoch 285 with validation loss 0.6443459391593933\n",
      "Starting Epoch 286\n",
      "0.6310393706611965\n",
      "Starting Epoch 287\n",
      "0.6313874669696974\n",
      "Starting Epoch 288\n",
      "0.6310073215028514\n",
      "New best model found at epoch 288 with validation loss 0.6443034410476685\n",
      "Starting Epoch 289\n",
      "0.6308309798655303\n",
      "Starting Epoch 290\n",
      "0.631179172059764\n",
      "Starting Epoch 291\n",
      "0.6311187744140625\n",
      "Starting Epoch 292\n",
      "0.6315752034601958\n",
      "Starting Epoch 293\n",
      "0.6312323108963345\n",
      "Starting Epoch 294\n",
      "0.6314788201580877\n",
      "New best model found at epoch 294 with validation loss 0.6440911293029785\n",
      "Starting Epoch 295\n",
      "0.6313403067381486\n",
      "Starting Epoch 296\n",
      "0.6311338466146718\n",
      "Starting Epoch 297\n",
      "0.6309696384098219\n",
      "Starting Epoch 298\n",
      "0.6309071442355281\n",
      "Starting Epoch 299\n",
      "0.6310403917146765\n",
      "New best model found at epoch 299 with validation loss 0.6440375447273254\n",
      "Starting Epoch 300\n",
      "0.6310544558193373\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-10-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb5bc2",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 3\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 20 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f136368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7a80c31c-648c-4d21-b93f-2d18462989a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.8811179373575293\n",
      "New best model found at epoch 1 with validation loss 0.6653730869293213\n",
      "Starting Epoch 2\n",
      "0.6647238031677578\n",
      "New best model found at epoch 2 with validation loss 0.6503564119338989\n",
      "Starting Epoch 3\n",
      "0.6525335052739019\n",
      "New best model found at epoch 3 with validation loss 0.6413072943687439\n",
      "Starting Epoch 4\n",
      "0.6424628573915233\n",
      "New best model found at epoch 4 with validation loss 0.625279426574707\n",
      "Starting Epoch 5\n",
      "0.6333994087965592\n",
      "New best model found at epoch 5 with validation loss 0.618532121181488\n",
      "Starting Epoch 6\n",
      "0.6247317972390548\n",
      "Starting Epoch 7\n",
      "0.6203756928443909\n",
      "New best model found at epoch 7 with validation loss 0.6108922362327576\n",
      "Starting Epoch 8\n",
      "0.6148803389590719\n",
      "New best model found at epoch 8 with validation loss 0.6073248982429504\n",
      "Starting Epoch 9\n",
      "0.6118931148363196\n",
      "Starting Epoch 10\n",
      "0.609056540157484\n",
      "New best model found at epoch 10 with validation loss 0.6051598787307739\n",
      "Starting Epoch 11\n",
      "0.6077425039332846\n",
      "New best model found at epoch 11 with validation loss 0.6012324094772339\n",
      "Starting Epoch 12\n",
      "0.6037632434264474\n",
      "New best model found at epoch 12 with validation loss 0.5993555784225464\n",
      "Starting Epoch 13\n",
      "0.601705877677254\n",
      "Starting Epoch 14\n",
      "0.6007062170816504\n",
      "New best model found at epoch 14 with validation loss 0.5930847525596619\n",
      "Starting Epoch 15\n",
      "0.5994359669478043\n",
      "New best model found at epoch 15 with validation loss 0.5914190411567688\n",
      "Starting Epoch 16\n",
      "0.5968329414077427\n",
      "New best model found at epoch 16 with validation loss 0.5908371806144714\n",
      "Starting Epoch 17\n",
      "0.5966178800748743\n",
      "Starting Epoch 18\n",
      "0.5946307622868082\n",
      "New best model found at epoch 18 with validation loss 0.5861221551895142\n",
      "Starting Epoch 19\n",
      "0.59315039800561\n",
      "New best model found at epoch 19 with validation loss 0.5856899619102478\n",
      "Starting Epoch 20\n",
      "0.5931309046952621\n",
      "Starting Epoch 21\n",
      "0.591890565727068\n",
      "New best model found at epoch 21 with validation loss 0.5856574773788452\n",
      "Starting Epoch 22\n",
      "0.5885293172753375\n",
      "New best model found at epoch 22 with validation loss 0.5827447175979614\n",
      "Starting Epoch 23\n",
      "0.5894221119258715\n",
      "New best model found at epoch 23 with validation loss 0.579878032207489\n",
      "Starting Epoch 24\n",
      "0.5888101134611212\n",
      "New best model found at epoch 24 with validation loss 0.5770710110664368\n",
      "Starting Epoch 25\n",
      "0.586359749669614\n",
      "Starting Epoch 26\n",
      "0.5868787013966105\n",
      "Starting Epoch 27\n",
      "0.5839205487914707\n",
      "New best model found at epoch 27 with validation loss 0.5747334957122803\n",
      "Starting Epoch 28\n",
      "0.5835242090017899\n",
      "Starting Epoch 29\n",
      "0.581732029500215\n",
      "New best model found at epoch 29 with validation loss 0.5738919973373413\n",
      "Starting Epoch 30\n",
      "0.5835040600403495\n",
      "Starting Epoch 31\n",
      "0.5813402390998342\n",
      "New best model found at epoch 31 with validation loss 0.5701929926872253\n",
      "Starting Epoch 32\n",
      "0.5826289550117825\n",
      "New best model found at epoch 32 with validation loss 0.5696349740028381\n",
      "Starting Epoch 33\n",
      "0.5839915599512018\n",
      "Starting Epoch 34\n",
      "0.5811344333316969\n",
      "New best model found at epoch 34 with validation loss 0.5693409442901611\n",
      "Starting Epoch 35\n",
      "0.5824260504349418\n",
      "New best model found at epoch 35 with validation loss 0.5681596994400024\n",
      "Starting Epoch 36\n",
      "0.5772556131300719\n",
      "New best model found at epoch 36 with validation loss 0.5674600005149841\n",
      "Starting Epoch 37\n",
      "0.5796892655932385\n",
      "Starting Epoch 38\n",
      "0.5798537420189899\n",
      "Starting Epoch 39\n",
      "0.5801738759745723\n",
      "New best model found at epoch 39 with validation loss 0.565264105796814\n",
      "Starting Epoch 40\n",
      "0.5793452638646831\n",
      "New best model found at epoch 40 with validation loss 0.5652445554733276\n",
      "Starting Epoch 41\n",
      "0.5757998642714127\n",
      "Starting Epoch 42\n",
      "0.5779583026533541\n",
      "Starting Epoch 43\n",
      "0.5770431834718456\n",
      "New best model found at epoch 43 with validation loss 0.562938928604126\n",
      "Starting Epoch 44\n",
      "0.5767213961352473\n",
      "New best model found at epoch 44 with validation loss 0.5624893307685852\n",
      "Starting Epoch 45\n",
      "0.5730270847030308\n",
      "New best model found at epoch 45 with validation loss 0.5619215369224548\n",
      "Starting Epoch 46\n",
      "0.5729009586831798\n",
      "Starting Epoch 47\n",
      "0.5729551833608876\n",
      "Starting Epoch 48\n",
      "0.572449399077374\n",
      "Starting Epoch 49\n",
      "0.5731816758280215\n",
      "Starting Epoch 50\n",
      "0.5725242223428644\n",
      "New best model found at epoch 50 with validation loss 0.5601798892021179\n",
      "Starting Epoch 51\n",
      "0.5755988618601924\n",
      "New best model found at epoch 51 with validation loss 0.5598868727684021\n",
      "Starting Epoch 52\n",
      "0.5714885333310002\n",
      "Starting Epoch 53\n",
      "0.5708462557067042\n",
      "New best model found at epoch 53 with validation loss 0.5560188293457031\n",
      "Starting Epoch 54\n",
      "0.5706749299298162\n",
      "New best model found at epoch 54 with validation loss 0.554859459400177\n",
      "Starting Epoch 55\n",
      "0.5694124361743098\n",
      "Starting Epoch 56\n",
      "0.5704445320626964\n",
      "New best model found at epoch 56 with validation loss 0.5543330311775208\n",
      "Starting Epoch 57\n",
      "0.5707328189974246\n",
      "New best model found at epoch 57 with validation loss 0.5540037751197815\n",
      "Starting Epoch 58\n",
      "0.569103409414706\n",
      "Starting Epoch 59\n",
      "0.567894987438036\n",
      "Starting Epoch 60\n",
      "0.5692083304343016\n",
      "Starting Epoch 61\n",
      "0.5681134954742764\n",
      "Starting Epoch 62\n",
      "0.5660625203796055\n",
      "New best model found at epoch 62 with validation loss 0.5528985857963562\n",
      "Starting Epoch 63\n",
      "0.5679612781690515\n",
      "Starting Epoch 64\n",
      "0.5664271867793539\n",
      "Starting Epoch 65\n",
      "0.5674061891825303\n",
      "New best model found at epoch 65 with validation loss 0.5510614514350891\n",
      "Starting Epoch 66\n",
      "0.5666580070619998\n",
      "Starting Epoch 67\n",
      "0.5658928959266\n",
      "Starting Epoch 68\n",
      "0.5666544385578322\n",
      "Starting Epoch 69\n",
      "0.5631612189438032\n",
      "New best model found at epoch 69 with validation loss 0.5500279068946838\n",
      "Starting Epoch 70\n",
      "0.5636209236538928\n",
      "New best model found at epoch 70 with validation loss 0.5496202707290649\n",
      "Starting Epoch 71\n",
      "0.5659908211749533\n",
      "New best model found at epoch 71 with validation loss 0.544955849647522\n",
      "Starting Epoch 72\n",
      "0.5638031622637873\n",
      "Starting Epoch 73\n",
      "0.5650352084118387\n",
      "New best model found at epoch 73 with validation loss 0.5445908904075623\n",
      "Starting Epoch 74\n",
      "0.5632179483123447\n",
      "Starting Epoch 75\n",
      "0.5642910625623621\n",
      "Starting Epoch 76\n",
      "0.5620385071505671\n",
      "Starting Epoch 77\n",
      "0.5625095250813857\n",
      "Starting Epoch 78\n",
      "0.5661770986474078\n",
      "New best model found at epoch 78 with validation loss 0.5429217219352722\n",
      "Starting Epoch 79\n",
      "0.5631151212298352\n",
      "New best model found at epoch 79 with validation loss 0.5414151549339294\n",
      "Starting Epoch 80\n",
      "0.559847865415656\n",
      "Starting Epoch 81\n",
      "0.5611752038416655\n",
      "Starting Epoch 82\n",
      "0.5613068134888358\n",
      "Starting Epoch 83\n",
      "0.562048112568648\n",
      "New best model found at epoch 83 with validation loss 0.5393717885017395\n",
      "Starting Epoch 84\n",
      "0.5602099869562231\n",
      "Starting Epoch 85\n",
      "0.5609627314235853\n",
      "Starting Epoch 86\n",
      "0.5615720412005549\n",
      "Starting Epoch 87\n",
      "0.5559314385704373\n",
      "Starting Epoch 88\n",
      "0.5598728216212728\n",
      "Starting Epoch 89\n",
      "0.5603263715039128\n",
      "Starting Epoch 90\n",
      "0.5581680121629135\n",
      "Starting Epoch 91\n",
      "0.5572157411471658\n",
      "Starting Epoch 92\n",
      "0.5569891903711401\n",
      "Starting Epoch 93\n",
      "0.5600150771763014\n",
      "New best model found at epoch 93 with validation loss 0.5384294390678406\n",
      "Starting Epoch 94\n",
      "0.5588047128656636\n",
      "New best model found at epoch 94 with validation loss 0.5381516814231873\n",
      "Starting Epoch 95\n",
      "0.561257004737854\n",
      "Starting Epoch 96\n",
      "0.5596612277238265\n",
      "Starting Epoch 97\n",
      "0.5568029530670332\n",
      "Starting Epoch 98\n",
      "0.5555300531180009\n",
      "New best model found at epoch 98 with validation loss 0.5372291803359985\n",
      "Starting Epoch 99\n",
      "0.5567143585370935\n",
      "New best model found at epoch 99 with validation loss 0.5369185209274292\n",
      "Starting Epoch 100\n",
      "0.5570405928984933\n",
      "Starting Epoch 101\n",
      "0.5565239540908647\n",
      "New best model found at epoch 101 with validation loss 0.5357682704925537\n",
      "Starting Epoch 102\n",
      "0.5567736003709876\n",
      "Starting Epoch 103\n",
      "0.5558362331079401\n",
      "Starting Epoch 104\n",
      "0.5542854420516802\n",
      "New best model found at epoch 104 with validation loss 0.5335431098937988\n",
      "Starting Epoch 105\n",
      "0.5549912608188131\n",
      "Starting Epoch 106\n",
      "0.5551650213158649\n",
      "Starting Epoch 107\n",
      "0.5531997667706531\n",
      "Starting Epoch 108\n",
      "0.5556030921314074\n",
      "Starting Epoch 109\n",
      "0.553370528894922\n",
      "New best model found at epoch 109 with validation loss 0.531868577003479\n",
      "Starting Epoch 110\n",
      "0.5539922351422517\n",
      "Starting Epoch 111\n",
      "0.5537629632846169\n",
      "Starting Epoch 112\n",
      "0.5570817149203756\n",
      "Starting Epoch 113\n",
      "0.5541163255339083\n",
      "New best model found at epoch 113 with validation loss 0.5317023396492004\n",
      "Starting Epoch 114\n",
      "0.5526602864265442\n",
      "New best model found at epoch 114 with validation loss 0.5305004119873047\n",
      "Starting Epoch 115\n",
      "0.552454658176588\n",
      "Starting Epoch 116\n",
      "0.5526277267414591\n",
      "Starting Epoch 117\n",
      "0.554715642462606\n",
      "Starting Epoch 118\n",
      "0.5542682642522065\n",
      "New best model found at epoch 118 with validation loss 0.5300107598304749\n",
      "Starting Epoch 119\n",
      "0.5545993460261304\n",
      "Starting Epoch 120\n",
      "0.5528932304485984\n",
      "New best model found at epoch 120 with validation loss 0.528846800327301\n",
      "Starting Epoch 121\n",
      "0.5509221722250399\n",
      "New best model found at epoch 121 with validation loss 0.5281603932380676\n",
      "Starting Epoch 122\n",
      "0.5514259623444598\n",
      "Starting Epoch 123\n",
      "0.5515795116839202\n",
      "Starting Epoch 124\n",
      "0.5510199601235597\n",
      "Starting Epoch 125\n",
      "0.5509113423202349\n",
      "Starting Epoch 126\n",
      "0.5513613172199415\n",
      "Starting Epoch 127\n",
      "0.5504146296045055\n",
      "Starting Epoch 128\n",
      "0.5497617591982302\n",
      "New best model found at epoch 128 with validation loss 0.526140570640564\n",
      "Starting Epoch 129\n",
      "0.5495956553065259\n",
      "Starting Epoch 130\n",
      "0.5504122467144675\n",
      "Starting Epoch 131\n",
      "0.5531547004761903\n",
      "New best model found at epoch 131 with validation loss 0.5247597098350525\n",
      "Starting Epoch 132\n",
      "0.551030748564264\n",
      "Starting Epoch 133\n",
      "0.5505863039389901\n",
      "Starting Epoch 134\n",
      "0.5499162207479062\n",
      "New best model found at epoch 134 with validation loss 0.5236431956291199\n",
      "Starting Epoch 135\n",
      "0.5480810002140377\n",
      "Starting Epoch 136\n",
      "0.5487292421900708\n",
      "Starting Epoch 137\n",
      "0.5512307260347449\n",
      "Starting Epoch 138\n",
      "0.5524475989134415\n",
      "Starting Epoch 139\n",
      "0.5503689620805823\n",
      "Starting Epoch 140\n",
      "0.5468102447364641\n",
      "New best model found at epoch 140 with validation loss 0.5233051180839539\n",
      "Starting Epoch 141\n",
      "0.550273764392604\n",
      "Starting Epoch 142\n",
      "0.5478005461070848\n",
      "Starting Epoch 143\n",
      "0.5475785343543343\n",
      "Starting Epoch 144\n",
      "0.5476222556570302\n",
      "Starting Epoch 145\n",
      "0.5481880371985228\n",
      "Starting Epoch 146\n",
      "0.5497537112754324\n",
      "Starting Epoch 147\n",
      "0.5490374150483505\n",
      "Starting Epoch 148\n",
      "0.5479696574418441\n",
      "Starting Epoch 149\n",
      "0.5479969615521638\n",
      "New best model found at epoch 149 with validation loss 0.5216054320335388\n",
      "Starting Epoch 150\n",
      "0.548606954191042\n",
      "Starting Epoch 151\n",
      "0.5466469267140264\n",
      "Starting Epoch 152\n",
      "0.5488246653390967\n",
      "New best model found at epoch 152 with validation loss 0.52012038230896\n",
      "Starting Epoch 153\n",
      "0.5470297751219376\n",
      "Starting Epoch 154\n",
      "0.5482173924860747\n",
      "Starting Epoch 155\n",
      "0.5456232752489008\n",
      "Starting Epoch 156\n",
      "0.5469834597214408\n",
      "Starting Epoch 157\n",
      "0.5461318220781244\n",
      "Starting Epoch 158\n",
      "0.545992339434831\n",
      "Starting Epoch 159\n",
      "0.5476640773856122\n",
      "Starting Epoch 160\n",
      "0.5464549738427867\n",
      "Starting Epoch 161\n",
      "0.5441183706988459\n",
      "Starting Epoch 162\n",
      "0.5466147842614547\n",
      "Starting Epoch 163\n",
      "0.5443646661613298\n",
      "Starting Epoch 164\n",
      "0.5461676833422288\n",
      "New best model found at epoch 164 with validation loss 0.5175111889839172\n",
      "Starting Epoch 165\n",
      "0.5475309452284938\n",
      "Starting Epoch 166\n",
      "0.5450828541880068\n",
      "Starting Epoch 167\n",
      "0.5452527883260146\n",
      "Starting Epoch 168\n",
      "0.5457254194695017\n",
      "Starting Epoch 169\n",
      "0.547096312046051\n",
      "Starting Epoch 170\n",
      "0.5448464103367018\n",
      "Starting Epoch 171\n",
      "0.5439220161541648\n",
      "Starting Epoch 172\n",
      "0.5455856711968131\n",
      "Starting Epoch 173\n",
      "0.5462390262147655\n",
      "New best model found at epoch 173 with validation loss 0.5166738629341125\n",
      "Starting Epoch 174\n",
      "0.5437408802301987\n",
      "Starting Epoch 175\n",
      "0.5430079568987307\n",
      "Starting Epoch 176\n",
      "0.5452768426874409\n",
      "Starting Epoch 177\n",
      "0.5441529776739038\n",
      "Starting Epoch 178\n",
      "0.5451566253019415\n",
      "Starting Epoch 179\n",
      "0.5451204115929811\n",
      "Starting Epoch 180\n",
      "0.5431495866049891\n",
      "New best model found at epoch 180 with validation loss 0.5133287906646729\n",
      "Starting Epoch 181\n",
      "0.5439012853995614\n",
      "Starting Epoch 182\n",
      "0.5462816292824952\n",
      "Starting Epoch 183\n",
      "0.5441652976948282\n",
      "Starting Epoch 184\n",
      "0.5435579496881237\n",
      "Starting Epoch 185\n",
      "0.5452277880647908\n",
      "Starting Epoch 186\n",
      "0.5471943694612255\n",
      "Starting Epoch 187\n",
      "0.5435181286024011\n",
      "Starting Epoch 188\n",
      "0.5452964059684587\n",
      "Starting Epoch 189\n",
      "0.5424726696118064\n",
      "Starting Epoch 190\n",
      "0.5458615448163904\n",
      "Starting Epoch 191\n",
      "0.5436572004919467\n",
      "Starting Epoch 192\n",
      "0.5445817151795262\n",
      "Starting Epoch 193\n",
      "0.541899095410886\n",
      "Starting Epoch 194\n",
      "0.5419722406760507\n",
      "Starting Epoch 195\n",
      "0.5430944328722747\n",
      "New best model found at epoch 195 with validation loss 0.5131909251213074\n",
      "Starting Epoch 196\n",
      "0.5431261801201365\n",
      "Starting Epoch 197\n",
      "0.5441081640513047\n",
      "Starting Epoch 198\n",
      "0.5440468788146973\n",
      "New best model found at epoch 198 with validation loss 0.5131856203079224\n",
      "Starting Epoch 199\n",
      "0.5432933879935223\n",
      "Starting Epoch 200\n",
      "0.5439142157202181\n",
      "Starting Epoch 201\n",
      "0.5412589920603711\n",
      "Starting Epoch 202\n",
      "0.5432554042857626\n",
      "Starting Epoch 203\n",
      "0.542250694140144\n",
      "Starting Epoch 204\n",
      "0.5430013394874075\n",
      "New best model found at epoch 204 with validation loss 0.5119709372520447\n",
      "Starting Epoch 205\n",
      "0.5438968150512032\n",
      "Starting Epoch 206\n",
      "0.543389116940291\n",
      "Starting Epoch 207\n",
      "0.5429570959961932\n",
      "Starting Epoch 208\n",
      "0.5425500921581102\n",
      "Starting Epoch 209\n",
      "0.543087793433148\n",
      "Starting Epoch 210\n",
      "0.5446125502171724\n",
      "Starting Epoch 211\n",
      "0.5430052824642347\n",
      "Starting Epoch 212\n",
      "0.5418266628099524\n",
      "Starting Epoch 213\n",
      "0.5431609529515972\n",
      "Starting Epoch 214\n",
      "0.5412070919638095\n",
      "Starting Epoch 215\n",
      "0.542243286319401\n",
      "Starting Epoch 216\n",
      "0.54101318768833\n",
      "Starting Epoch 217\n",
      "0.5419184423011282\n",
      "Starting Epoch 218\n",
      "0.542147019635076\n",
      "Starting Epoch 219\n",
      "0.5410623835480731\n",
      "New best model found at epoch 219 with validation loss 0.5100916028022766\n",
      "Starting Epoch 220\n",
      "0.540124994257222\n",
      "Starting Epoch 221\n",
      "0.5408382869285085\n",
      "Starting Epoch 222\n",
      "0.5418048863825591\n",
      "New best model found at epoch 222 with validation loss 0.5095641016960144\n",
      "Starting Epoch 223\n",
      "0.5392084186491759\n",
      "Starting Epoch 224\n",
      "0.5417720351530158\n",
      "New best model found at epoch 224 with validation loss 0.5090314149856567\n",
      "Starting Epoch 225\n",
      "0.5405239009338877\n",
      "New best model found at epoch 225 with validation loss 0.5088491439819336\n",
      "Starting Epoch 226\n",
      "0.5406185181244559\n",
      "Starting Epoch 227\n",
      "0.5405004413231559\n",
      "Starting Epoch 228\n",
      "0.5377788401168325\n",
      "Starting Epoch 229\n",
      "0.540491627610248\n",
      "New best model found at epoch 229 with validation loss 0.5088345408439636\n",
      "Starting Epoch 230\n",
      "0.5396297988684281\n",
      "Starting Epoch 231\n",
      "0.5395072569017825\n",
      "New best model found at epoch 231 with validation loss 0.5088207721710205\n",
      "Starting Epoch 232\n",
      "0.5388977657193723\n",
      "Starting Epoch 233\n",
      "0.5413318030212236\n",
      "New best model found at epoch 233 with validation loss 0.5079618096351624\n",
      "Starting Epoch 234\n",
      "0.5404913373615431\n",
      "Starting Epoch 235\n",
      "0.5386732505715411\n",
      "Starting Epoch 236\n",
      "0.5388238676216291\n",
      "Starting Epoch 237\n",
      "0.5379037261009216\n",
      "Starting Epoch 238\n",
      "0.538038836873096\n",
      "Starting Epoch 239\n",
      "0.537612532791884\n",
      "Starting Epoch 240\n",
      "0.538513139538143\n",
      "Starting Epoch 241\n",
      "0.5392791291941768\n",
      "Starting Epoch 242\n",
      "0.5397761192010797\n",
      "Starting Epoch 243\n",
      "0.5381126494511314\n",
      "Starting Epoch 244\n",
      "0.5402042619560076\n",
      "New best model found at epoch 244 with validation loss 0.5065218806266785\n",
      "Starting Epoch 245\n",
      "0.537590751181478\n",
      "Starting Epoch 246\n",
      "0.537344735601674\n",
      "Starting Epoch 247\n",
      "0.5374186945998151\n",
      "Starting Epoch 248\n",
      "0.5369315691616224\n",
      "Starting Epoch 249\n",
      "0.5365158682284148\n",
      "Starting Epoch 250\n",
      "0.5370350881763126\n",
      "Starting Epoch 251\n",
      "0.5367119843545167\n",
      "Starting Epoch 252\n",
      "0.5376057184260824\n",
      "Starting Epoch 253\n",
      "0.5371073808359064\n",
      "Starting Epoch 254\n",
      "0.5379120966662532\n",
      "Starting Epoch 255\n",
      "0.5368824367937834\n",
      "New best model found at epoch 255 with validation loss 0.5064665675163269\n",
      "Starting Epoch 256\n",
      "0.5380469612453295\n",
      "Starting Epoch 257\n",
      "0.537202801393426\n",
      "Starting Epoch 258\n",
      "0.5399907062882963\n",
      "Starting Epoch 259\n",
      "0.5373274748739989\n",
      "Starting Epoch 260\n",
      "0.5368806680907374\n",
      "Starting Epoch 261\n",
      "0.5366805688194607\n",
      "Starting Epoch 262\n",
      "0.5378489403621011\n",
      "Starting Epoch 263\n",
      "0.5374242261700009\n",
      "New best model found at epoch 263 with validation loss 0.5051312446594238\n",
      "Starting Epoch 264\n",
      "0.5352786403635273\n",
      "Starting Epoch 265\n",
      "0.5347648586915887\n",
      "Starting Epoch 266\n",
      "0.5371270866497703\n",
      "Starting Epoch 267\n",
      "0.5364279397155928\n",
      "Starting Epoch 268\n",
      "0.5362233662086985\n",
      "New best model found at epoch 268 with validation loss 0.5048799514770508\n",
      "Starting Epoch 269\n",
      "0.5360333349393762\n",
      "Starting Epoch 270\n",
      "0.5354144093783005\n",
      "Starting Epoch 271\n",
      "0.5368608145610146\n",
      "Starting Epoch 272\n",
      "0.5329101940859919\n",
      "New best model found at epoch 272 with validation loss 0.5033276677131653\n",
      "Starting Epoch 273\n",
      "0.5352138954660167\n",
      "Starting Epoch 274\n",
      "0.5353627930516782\n",
      "Starting Epoch 275\n",
      "0.5365069378977236\n",
      "Starting Epoch 276\n",
      "0.5338978236136229\n",
      "Starting Epoch 277\n",
      "0.534808988156526\n",
      "Starting Epoch 278\n",
      "0.5352636588656384\n",
      "New best model found at epoch 278 with validation loss 0.5029341578483582\n",
      "Starting Epoch 279\n",
      "0.5336909954962523\n",
      "New best model found at epoch 279 with validation loss 0.502623975276947\n",
      "Starting Epoch 280\n",
      "0.5342353167741195\n",
      "Starting Epoch 281\n",
      "0.5345142678074215\n",
      "Starting Epoch 282\n",
      "0.5357625406721364\n",
      "Starting Epoch 283\n",
      "0.5339980591898379\n",
      "Starting Epoch 284\n",
      "0.5340921619664067\n",
      "Starting Epoch 285\n",
      "0.5363227543623551\n",
      "New best model found at epoch 285 with validation loss 0.502612829208374\n",
      "Starting Epoch 286\n",
      "0.5346197732116865\n",
      "Starting Epoch 287\n",
      "0.5335761412330295\n",
      "Starting Epoch 288\n",
      "0.5348297266856484\n",
      "Starting Epoch 289\n",
      "0.5331717612950698\n",
      "New best model found at epoch 289 with validation loss 0.5025449991226196\n",
      "Starting Epoch 290\n",
      "0.5337695751501166\n",
      "Starting Epoch 291\n",
      "0.5338511117126631\n",
      "Starting Epoch 292\n",
      "0.5325422092624332\n",
      "Starting Epoch 293\n",
      "0.5330857854822407\n",
      "New best model found at epoch 293 with validation loss 0.5010247230529785\n",
      "Starting Epoch 294\n",
      "0.5362353493338046\n",
      "Starting Epoch 295\n",
      "0.5332214663857999\n",
      "New best model found at epoch 295 with validation loss 0.5008243322372437\n",
      "Starting Epoch 296\n",
      "0.5317505947921587\n",
      "Starting Epoch 297\n",
      "0.5335475284120311\n",
      "Starting Epoch 298\n",
      "0.533267308836398\n",
      "Starting Epoch 299\n",
      "0.5330401153668113\n",
      "Starting Epoch 300\n",
      "0.5343574959298839\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-20-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a92759",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 4\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 25 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "927d5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a8765711-27a0-44fb-9644-1157f2252731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.0110779663790828\n",
      "New best model found at epoch 1 with validation loss 0.6806857585906982\n",
      "Starting Epoch 2\n",
      "0.6756438898003619\n",
      "New best model found at epoch 2 with validation loss 0.6697691679000854\n",
      "Starting Epoch 3\n",
      "0.6671799835951432\n",
      "New best model found at epoch 3 with validation loss 0.6629930734634399\n",
      "Starting Epoch 4\n",
      "0.6595563344333483\n",
      "New best model found at epoch 4 with validation loss 0.6581054329872131\n",
      "Starting Epoch 5\n",
      "0.6522328957267429\n",
      "Starting Epoch 6\n",
      "0.646145900954371\n",
      "New best model found at epoch 6 with validation loss 0.6559619903564453\n",
      "Starting Epoch 7\n",
      "0.6371365370957748\n",
      "Starting Epoch 8\n",
      "0.6317752029584802\n",
      "New best model found at epoch 8 with validation loss 0.631101667881012\n",
      "Starting Epoch 9\n",
      "0.6202158616936725\n",
      "New best model found at epoch 9 with validation loss 0.6275027394294739\n",
      "Starting Epoch 10\n",
      "0.6162938086882882\n",
      "New best model found at epoch 10 with validation loss 0.614938497543335\n",
      "Starting Epoch 11\n",
      "0.611045998075734\n",
      "New best model found at epoch 11 with validation loss 0.607387900352478\n",
      "Starting Epoch 12\n",
      "0.6051220479218856\n",
      "Starting Epoch 13\n",
      "0.6052862094796222\n",
      "Starting Epoch 14\n",
      "0.5979852287665658\n",
      "New best model found at epoch 14 with validation loss 0.5984653234481812\n",
      "Starting Epoch 15\n",
      "0.5961795734322589\n",
      "Starting Epoch 16\n",
      "0.5947033659271572\n",
      "New best model found at epoch 16 with validation loss 0.5937912464141846\n",
      "Starting Epoch 17\n",
      "0.597464522589808\n",
      "Starting Epoch 18\n",
      "0.5946221792179606\n",
      "New best model found at epoch 18 with validation loss 0.592567503452301\n",
      "Starting Epoch 19\n",
      "0.5930690869041111\n",
      "New best model found at epoch 19 with validation loss 0.5921580195426941\n",
      "Starting Epoch 20\n",
      "0.5889618604079537\n",
      "New best model found at epoch 20 with validation loss 0.591516375541687\n",
      "Starting Epoch 21\n",
      "0.5883281593737395\n",
      "New best model found at epoch 21 with validation loss 0.5881125330924988\n",
      "Starting Epoch 22\n",
      "0.587330522744552\n",
      "Starting Epoch 23\n",
      "0.5888030814087909\n",
      "New best model found at epoch 23 with validation loss 0.5877828598022461\n",
      "Starting Epoch 24\n",
      "0.5876424493996993\n",
      "Starting Epoch 25\n",
      "0.587161000656045\n",
      "Starting Epoch 26\n",
      "0.5884011582187985\n",
      "New best model found at epoch 26 with validation loss 0.5841009616851807\n",
      "Starting Epoch 27\n",
      "0.5858807473079019\n",
      "Starting Epoch 28\n",
      "0.5895630769107653\n",
      "Starting Epoch 29\n",
      "0.5855401624803958\n",
      "Starting Epoch 30\n",
      "0.5824268797169561\n",
      "New best model found at epoch 30 with validation loss 0.5833407640457153\n",
      "Starting Epoch 31\n",
      "0.5837058347204457\n",
      "Starting Epoch 32\n",
      "0.5848888521609099\n",
      "Starting Epoch 33\n",
      "0.5819939815479777\n",
      "Starting Epoch 34\n",
      "0.580010800257973\n",
      "Starting Epoch 35\n",
      "0.5808611512184143\n",
      "Starting Epoch 36\n",
      "0.5814597865809565\n",
      "New best model found at epoch 36 with validation loss 0.5829440355300903\n",
      "Starting Epoch 37\n",
      "0.5792552284572435\n",
      "Starting Epoch 38\n",
      "0.5778807919958363\n",
      "New best model found at epoch 38 with validation loss 0.5778257846832275\n",
      "Starting Epoch 39\n",
      "0.5777865466864213\n",
      "New best model found at epoch 39 with validation loss 0.5763139724731445\n",
      "Starting Epoch 40\n",
      "0.5796224682227425\n",
      "New best model found at epoch 40 with validation loss 0.5752449035644531\n",
      "Starting Epoch 41\n",
      "0.5775916705960813\n",
      "Starting Epoch 42\n",
      "0.577632170656453\n",
      "Starting Epoch 43\n",
      "0.5769318212633547\n",
      "Starting Epoch 44\n",
      "0.5763035468433214\n",
      "Starting Epoch 45\n",
      "0.5764724158722422\n",
      "New best model found at epoch 45 with validation loss 0.5736932158470154\n",
      "Starting Epoch 46\n",
      "0.5778354665507441\n",
      "New best model found at epoch 46 with validation loss 0.5733929872512817\n",
      "Starting Epoch 47\n",
      "0.5759701884311178\n",
      "New best model found at epoch 47 with validation loss 0.5727463960647583\n",
      "Starting Epoch 48\n",
      "0.5750727498013041\n",
      "New best model found at epoch 48 with validation loss 0.5720744132995605\n",
      "Starting Epoch 49\n",
      "0.5778643229733342\n",
      "New best model found at epoch 49 with validation loss 0.5714219212532043\n",
      "Starting Epoch 50\n",
      "0.572965031084807\n",
      "Starting Epoch 51\n",
      "0.5744044314260068\n",
      "Starting Epoch 52\n",
      "0.5739115852376689\n",
      "Starting Epoch 53\n",
      "0.5763851974321448\n",
      "New best model found at epoch 53 with validation loss 0.5714132785797119\n",
      "Starting Epoch 54\n",
      "0.5768091082572937\n",
      "Starting Epoch 55\n",
      "0.5722235700358516\n",
      "New best model found at epoch 55 with validation loss 0.5710934996604919\n",
      "Starting Epoch 56\n",
      "0.5730815529823303\n",
      "Starting Epoch 57\n",
      "0.575262743493785\n",
      "Starting Epoch 58\n",
      "0.57435084944186\n",
      "Starting Epoch 59\n",
      "0.57427077708037\n",
      "Starting Epoch 60\n",
      "0.5744904253793799\n",
      "Starting Epoch 61\n",
      "0.5768384726151176\n",
      "New best model found at epoch 61 with validation loss 0.5697124600410461\n",
      "Starting Epoch 62\n",
      "0.5710214894750844\n",
      "Starting Epoch 63\n",
      "0.573760317719501\n",
      "New best model found at epoch 63 with validation loss 0.5686148405075073\n",
      "Starting Epoch 64\n",
      "0.5740603921206101\n",
      "Starting Epoch 65\n",
      "0.5742412701897\n",
      "Starting Epoch 66\n",
      "0.5725328714951224\n",
      "Starting Epoch 67\n",
      "0.5700867901677671\n",
      "Starting Epoch 68\n",
      "0.5746345131293588\n",
      "Starting Epoch 69\n",
      "0.5744643379812655\n",
      "Starting Epoch 70\n",
      "0.5727683020674664\n",
      "Starting Epoch 71\n",
      "0.5729223956232485\n",
      "Starting Epoch 72\n",
      "0.5727979748145394\n",
      "Starting Epoch 73\n",
      "0.5716158229371776\n",
      "Starting Epoch 74\n",
      "0.5721268070780713\n",
      "New best model found at epoch 74 with validation loss 0.5685727596282959\n",
      "Starting Epoch 75\n",
      "0.5703860210335773\n",
      "Starting Epoch 76\n",
      "0.5699974259604579\n",
      "New best model found at epoch 76 with validation loss 0.5669698715209961\n",
      "Starting Epoch 77\n",
      "0.5706302653188291\n",
      "Starting Epoch 78\n",
      "0.5720501943774845\n",
      "Starting Epoch 79\n",
      "0.5686084692892821\n",
      "Starting Epoch 80\n",
      "0.5690886637438899\n",
      "Starting Epoch 81\n",
      "0.5684597738411116\n",
      "Starting Epoch 82\n",
      "0.5704594708007314\n",
      "New best model found at epoch 82 with validation loss 0.5668606162071228\n",
      "Starting Epoch 83\n",
      "0.5689812224844227\n",
      "Starting Epoch 84\n",
      "0.5697902777920598\n",
      "New best model found at epoch 84 with validation loss 0.566789984703064\n",
      "Starting Epoch 85\n",
      "0.5680273252984752\n",
      "Starting Epoch 86\n",
      "0.5689298342103544\n",
      "Starting Epoch 87\n",
      "0.5698650194251019\n",
      "New best model found at epoch 87 with validation loss 0.5651349425315857\n",
      "Starting Epoch 88\n",
      "0.5685204124968984\n",
      "Starting Epoch 89\n",
      "0.568893586811812\n",
      "Starting Epoch 90\n",
      "0.5686420150425123\n",
      "Starting Epoch 91\n",
      "0.569178318199904\n",
      "Starting Epoch 92\n",
      "0.5703256272751352\n",
      "New best model found at epoch 92 with validation loss 0.5650891661643982\n",
      "Starting Epoch 93\n",
      "0.5702149971671726\n",
      "Starting Epoch 94\n",
      "0.5691642217014147\n",
      "Starting Epoch 95\n",
      "0.5678377734578174\n",
      "New best model found at epoch 95 with validation loss 0.5645257830619812\n",
      "Starting Epoch 96\n",
      "0.5667544784753219\n",
      "Starting Epoch 97\n",
      "0.5668055765006853\n",
      "Starting Epoch 98\n",
      "0.5662584887898486\n",
      "Starting Epoch 99\n",
      "0.5676384490469227\n",
      "Starting Epoch 100\n",
      "0.5701230103554933\n",
      "Starting Epoch 101\n",
      "0.5676823439805404\n",
      "Starting Epoch 102\n",
      "0.5682695689408676\n",
      "New best model found at epoch 102 with validation loss 0.5643960237503052\n",
      "Starting Epoch 103\n",
      "0.5674472503040148\n",
      "Starting Epoch 104\n",
      "0.5664520082266434\n",
      "Starting Epoch 105\n",
      "0.5671984838402789\n",
      "Starting Epoch 106\n",
      "0.5671912431716919\n",
      "Starting Epoch 107\n",
      "0.5684483932412189\n",
      "Starting Epoch 108\n",
      "0.5682590059612108\n",
      "New best model found at epoch 108 with validation loss 0.5628612637519836\n",
      "Starting Epoch 109\n",
      "0.5657350291376528\n",
      "New best model found at epoch 109 with validation loss 0.5620056986808777\n",
      "Starting Epoch 110\n",
      "0.5647053109562915\n",
      "Starting Epoch 111\n",
      "0.5676438976889071\n",
      "Starting Epoch 112\n",
      "0.5667795111303744\n",
      "Starting Epoch 113\n",
      "0.5671378296354542\n",
      "New best model found at epoch 113 with validation loss 0.5611515045166016\n",
      "Starting Epoch 114\n",
      "0.5661716707374739\n",
      "New best model found at epoch 114 with validation loss 0.560815691947937\n",
      "Starting Epoch 115\n",
      "0.5649411548738894\n",
      "New best model found at epoch 115 with validation loss 0.5605758428573608\n",
      "Starting Epoch 116\n",
      "0.5676261160684668\n",
      "Starting Epoch 117\n",
      "0.564895194509755\n",
      "Starting Epoch 118\n",
      "0.5651949229447738\n",
      "New best model found at epoch 118 with validation loss 0.5605606436729431\n",
      "Starting Epoch 119\n",
      "0.5649250719858252\n",
      "Starting Epoch 120\n",
      "0.5643567663172017\n",
      "New best model found at epoch 120 with validation loss 0.5605125427246094\n",
      "Starting Epoch 121\n",
      "0.5641247928142548\n",
      "Starting Epoch 122\n",
      "0.5658833203108414\n",
      "Starting Epoch 123\n",
      "0.5652690646441086\n",
      "Starting Epoch 124\n",
      "0.5639573076496953\n",
      "Starting Epoch 125\n",
      "0.5652925903382509\n",
      "Starting Epoch 126\n",
      "0.5641676602156266\n",
      "Starting Epoch 127\n",
      "0.5646593220855879\n",
      "New best model found at epoch 127 with validation loss 0.5594190359115601\n",
      "Starting Epoch 128\n",
      "0.5652678427488907\n",
      "New best model found at epoch 128 with validation loss 0.559352695941925\n",
      "Starting Epoch 129\n",
      "0.5632795095443726\n",
      "New best model found at epoch 129 with validation loss 0.5591448545455933\n",
      "Starting Epoch 130\n",
      "0.5624193367750748\n",
      "Starting Epoch 131\n",
      "0.5636246619017228\n",
      "New best model found at epoch 131 with validation loss 0.5585952401161194\n",
      "Starting Epoch 132\n",
      "0.5625849975192029\n",
      "New best model found at epoch 132 with validation loss 0.5584626793861389\n",
      "Starting Epoch 133\n",
      "0.5637337384016617\n",
      "Starting Epoch 134\n",
      "0.5643153644126394\n",
      "Starting Epoch 135\n",
      "0.5640063868916553\n",
      "Starting Epoch 136\n",
      "0.5614965195241182\n",
      "Starting Epoch 137\n",
      "0.56442990899086\n",
      "Starting Epoch 138\n",
      "0.5616982475571011\n",
      "Starting Epoch 139\n",
      "0.5629138661467511\n",
      "New best model found at epoch 139 with validation loss 0.5580965876579285\n",
      "Starting Epoch 140\n",
      "0.563473078219787\n",
      "Starting Epoch 141\n",
      "0.5617650254912998\n",
      "New best model found at epoch 141 with validation loss 0.5580452680587769\n",
      "Starting Epoch 142\n",
      "0.5635034234627433\n",
      "Starting Epoch 143\n",
      "0.563498977733695\n",
      "Starting Epoch 144\n",
      "0.5634260216484899\n",
      "Starting Epoch 145\n",
      "0.5623857754728069\n",
      "Starting Epoch 146\n",
      "0.5610376350257708\n",
      "New best model found at epoch 146 with validation loss 0.5575354695320129\n",
      "Starting Epoch 147\n",
      "0.5635426174039426\n",
      "Starting Epoch 148\n",
      "0.5623983585316202\n",
      "Starting Epoch 149\n",
      "0.5628721804722495\n",
      "Starting Epoch 150\n",
      "0.5607633798018746\n",
      "Starting Epoch 151\n",
      "0.5629619528418002\n",
      "New best model found at epoch 151 with validation loss 0.5568159222602844\n",
      "Starting Epoch 152\n",
      "0.5618687479392342\n",
      "Starting Epoch 153\n",
      "0.5619159392688585\n",
      "Starting Epoch 154\n",
      "0.5635116450164629\n",
      "Starting Epoch 155\n",
      "0.5606266830278479\n",
      "New best model found at epoch 155 with validation loss 0.5566377639770508\n",
      "Starting Epoch 156\n",
      "0.5607530681983285\n",
      "Starting Epoch 157\n",
      "0.5613155390905298\n",
      "Starting Epoch 158\n",
      "0.5623362738153209\n",
      "New best model found at epoch 158 with validation loss 0.5559962391853333\n",
      "Starting Epoch 159\n",
      "0.5615718520205953\n",
      "Starting Epoch 160\n",
      "0.5601231818613799\n",
      "Starting Epoch 161\n",
      "0.5624105619347614\n",
      "New best model found at epoch 161 with validation loss 0.5558553338050842\n",
      "Starting Epoch 162\n",
      "0.5607892883860547\n",
      "Starting Epoch 163\n",
      "0.5624287011830703\n",
      "Starting Epoch 164\n",
      "0.5602309613124185\n",
      "Starting Epoch 165\n",
      "0.5621669136959574\n",
      "New best model found at epoch 165 with validation loss 0.5556908249855042\n",
      "Starting Epoch 166\n",
      "0.5611989096454952\n",
      "Starting Epoch 167\n",
      "0.5603186980537747\n",
      "Starting Epoch 168\n",
      "0.5606717117454695\n",
      "New best model found at epoch 168 with validation loss 0.555525004863739\n",
      "Starting Epoch 169\n",
      "0.5601415737815525\n",
      "Starting Epoch 170\n",
      "0.5606695128523785\n",
      "New best model found at epoch 170 with validation loss 0.5553723573684692\n",
      "Starting Epoch 171\n",
      "0.5596264186112777\n",
      "Starting Epoch 172\n",
      "0.5609592795372009\n",
      "Starting Epoch 173\n",
      "0.5602416305438332\n",
      "Starting Epoch 174\n",
      "0.5613962502583213\n",
      "New best model found at epoch 174 with validation loss 0.5551128387451172\n",
      "Starting Epoch 175\n",
      "0.5607214375682499\n",
      "Starting Epoch 176\n",
      "0.5592678863069286\n",
      "Starting Epoch 177\n",
      "0.5604662143665812\n",
      "Starting Epoch 178\n",
      "0.5612646924412769\n",
      "Starting Epoch 179\n",
      "0.5611198596332384\n",
      "New best model found at epoch 179 with validation loss 0.5547211766242981\n",
      "Starting Epoch 180\n",
      "0.5599897400192593\n",
      "Starting Epoch 181\n",
      "0.5604819901611494\n",
      "Starting Epoch 182\n",
      "0.559259005214857\n",
      "Starting Epoch 183\n",
      "0.5590992194154988\n",
      "Starting Epoch 184\n",
      "0.5615067624527476\n",
      "Starting Epoch 185\n",
      "0.5609187717023103\n",
      "Starting Epoch 186\n",
      "0.5601636132468348\n",
      "New best model found at epoch 186 with validation loss 0.553992748260498\n",
      "Starting Epoch 187\n",
      "0.558869991613471\n",
      "Starting Epoch 188\n",
      "0.5606679346250452\n",
      "New best model found at epoch 188 with validation loss 0.5539084672927856\n",
      "Starting Epoch 189\n",
      "0.5588470010653787\n",
      "Starting Epoch 190\n",
      "0.5592322919679724\n",
      "Starting Epoch 191\n",
      "0.5598526817301045\n",
      "New best model found at epoch 191 with validation loss 0.553695797920227\n",
      "Starting Epoch 192\n",
      "0.5598547018092611\n",
      "Starting Epoch 193\n",
      "0.5600887835025787\n",
      "Starting Epoch 194\n",
      "0.5593827392743982\n",
      "Starting Epoch 195\n",
      "0.5588584555232007\n",
      "New best model found at epoch 195 with validation loss 0.5535922050476074\n",
      "Starting Epoch 196\n",
      "0.5597052820350813\n",
      "Starting Epoch 197\n",
      "0.5610906559488048\n",
      "Starting Epoch 198\n",
      "0.5584427196046581\n",
      "Starting Epoch 199\n",
      "0.5599153028882068\n",
      "Starting Epoch 200\n",
      "0.5584593104279559\n",
      "Starting Epoch 201\n",
      "0.5598307601783586\n",
      "Starting Epoch 202\n",
      "0.5600138617598492\n",
      "Starting Epoch 203\n",
      "0.5588169331135957\n",
      "Starting Epoch 204\n",
      "0.557821150707162\n",
      "Starting Epoch 205\n",
      "0.5588995995728866\n",
      "Starting Epoch 206\n",
      "0.558291636083437\n",
      "Starting Epoch 207\n",
      "0.5585545664248259\n",
      "Starting Epoch 208\n",
      "0.5588295926218447\n",
      "Starting Epoch 209\n",
      "0.5594663062821263\n",
      "Starting Epoch 210\n",
      "0.557574793048527\n",
      "New best model found at epoch 210 with validation loss 0.5532174706459045\n",
      "Starting Epoch 211\n",
      "0.5579030461933302\n",
      "New best model found at epoch 211 with validation loss 0.5527580380439758\n",
      "Starting Epoch 212\n",
      "0.55866688101188\n",
      "New best model found at epoch 212 with validation loss 0.552117109298706\n",
      "Starting Epoch 213\n",
      "0.5583343259666277\n",
      "Starting Epoch 214\n",
      "0.5570015790669814\n",
      "Starting Epoch 215\n",
      "0.5567960609560427\n",
      "Starting Epoch 216\n",
      "0.5583912911622421\n",
      "New best model found at epoch 216 with validation loss 0.5519205331802368\n",
      "Starting Epoch 217\n",
      "0.5588973475539166\n",
      "Starting Epoch 218\n",
      "0.5577373919279679\n",
      "Starting Epoch 219\n",
      "0.5582856354506119\n",
      "Starting Epoch 220\n",
      "0.5586845045504363\n",
      "Starting Epoch 221\n",
      "0.5570232220318007\n",
      "Starting Epoch 222\n",
      "0.5579463295314623\n",
      "Starting Epoch 223\n",
      "0.5573206297729326\n",
      "Starting Epoch 224\n",
      "0.5574978823247163\n",
      "Starting Epoch 225\n",
      "0.5566545089949733\n",
      "Starting Epoch 226\n",
      "0.5566139558087224\n",
      "Starting Epoch 227\n",
      "0.5586854452672212\n",
      "Starting Epoch 228\n",
      "0.5598721789277118\n",
      "Starting Epoch 229\n",
      "0.5569749293120011\n",
      "Starting Epoch 230\n",
      "0.5573840672555177\n",
      "Starting Epoch 231\n",
      "0.5580495816210042\n",
      "New best model found at epoch 231 with validation loss 0.5511109232902527\n",
      "Starting Epoch 232\n",
      "0.5570891395859097\n",
      "Starting Epoch 233\n",
      "0.5612082001955613\n",
      "Starting Epoch 234\n",
      "0.557254846977151\n",
      "Starting Epoch 235\n",
      "0.5577423598455347\n",
      "Starting Epoch 236\n",
      "0.556474524995555\n",
      "Starting Epoch 237\n",
      "0.5584699628145798\n",
      "Starting Epoch 238\n",
      "0.5581299118373705\n",
      "Starting Epoch 239\n",
      "0.5566234925518865\n",
      "Starting Epoch 240\n",
      "0.5562799663647361\n",
      "New best model found at epoch 240 with validation loss 0.5507920980453491\n",
      "Starting Epoch 241\n",
      "0.5568807734095532\n",
      "Starting Epoch 242\n",
      "0.5573467016220093\n",
      "Starting Epoch 243\n",
      "0.5586258185946423\n",
      "Starting Epoch 244\n",
      "0.5564199673092883\n",
      "Starting Epoch 245\n",
      "0.5576579894708551\n",
      "Starting Epoch 246\n",
      "0.5571168129858763\n",
      "Starting Epoch 247\n",
      "0.5562583052593729\n",
      "Starting Epoch 248\n",
      "0.5565042534600133\n",
      "Starting Epoch 249\n",
      "0.5554940881936447\n",
      "Starting Epoch 250\n",
      "0.5573610222857931\n",
      "Starting Epoch 251\n",
      "0.5560402468494747\n",
      "Starting Epoch 252\n",
      "0.5564775324386099\n",
      "New best model found at epoch 252 with validation loss 0.5503343939781189\n",
      "Starting Epoch 253\n",
      "0.5558426626350569\n",
      "New best model found at epoch 253 with validation loss 0.5500361919403076\n",
      "Starting Epoch 254\n",
      "0.5556591813978942\n",
      "New best model found at epoch 254 with validation loss 0.5500276684761047\n",
      "Starting Epoch 255\n",
      "0.5560163648232169\n",
      "New best model found at epoch 255 with validation loss 0.5499138236045837\n",
      "Starting Epoch 256\n",
      "0.5563263037930364\n",
      "Starting Epoch 257\n",
      "0.5562155376309934\n",
      "New best model found at epoch 257 with validation loss 0.5496575236320496\n",
      "Starting Epoch 258\n",
      "0.5561687700126482\n",
      "Starting Epoch 259\n",
      "0.556171935537587\n",
      "Starting Epoch 260\n",
      "0.5563402162945789\n",
      "Starting Epoch 261\n",
      "0.5563623982927074\n",
      "New best model found at epoch 261 with validation loss 0.549095094203949\n",
      "Starting Epoch 262\n",
      "0.5564306818920634\n",
      "Starting Epoch 263\n",
      "0.5559975025446519\n",
      "Starting Epoch 264\n",
      "0.5557497960069905\n",
      "New best model found at epoch 264 with validation loss 0.5490740537643433\n",
      "Starting Epoch 265\n",
      "0.5555417706137118\n",
      "New best model found at epoch 265 with validation loss 0.5486266613006592\n",
      "Starting Epoch 266\n",
      "0.5564484712870225\n",
      "Starting Epoch 267\n",
      "0.5545476195604905\n",
      "Starting Epoch 268\n",
      "0.5560767650604248\n",
      "Starting Epoch 269\n",
      "0.5561517826888872\n",
      "Starting Epoch 270\n",
      "0.5555876376836196\n",
      "Starting Epoch 271\n",
      "0.5553158651227537\n",
      "New best model found at epoch 271 with validation loss 0.548547089099884\n",
      "Starting Epoch 272\n",
      "0.5553100394166034\n",
      "Starting Epoch 273\n",
      "0.5548336998276089\n",
      "New best model found at epoch 273 with validation loss 0.5481880307197571\n",
      "Starting Epoch 274\n",
      "0.555118906757106\n",
      "Starting Epoch 275\n",
      "0.5570262916710066\n",
      "Starting Epoch 276\n",
      "0.556292025939278\n",
      "Starting Epoch 277\n",
      "0.5559559555157371\n",
      "Starting Epoch 278\n",
      "0.5553520166355631\n",
      "Starting Epoch 279\n",
      "0.5555590909460316\n",
      "Starting Epoch 280\n",
      "0.5558533059514087\n",
      "New best model found at epoch 280 with validation loss 0.5481553673744202\n",
      "Starting Epoch 281\n",
      "0.5575636042201001\n",
      "Starting Epoch 282\n",
      "0.5542861767437147\n",
      "Starting Epoch 283\n",
      "0.5553044171436973\n",
      "Starting Epoch 284\n",
      "0.5562097417271655\n",
      "Starting Epoch 285\n",
      "0.5550117985061978\n",
      "Starting Epoch 286\n",
      "0.5568855314151101\n",
      "Starting Epoch 287\n",
      "0.556660981281944\n",
      "Starting Epoch 288\n",
      "0.5550734361876613\n",
      "New best model found at epoch 288 with validation loss 0.5481508374214172\n",
      "Starting Epoch 289\n",
      "0.5552238212979358\n",
      "New best model found at epoch 289 with validation loss 0.547869086265564\n",
      "Starting Epoch 290\n",
      "0.553250227285468\n",
      "Starting Epoch 291\n",
      "0.5557510256767273\n",
      "Starting Epoch 292\n",
      "0.5554747140925863\n",
      "Starting Epoch 293\n",
      "0.5558543075685916\n",
      "Starting Epoch 294\n",
      "0.5539002081622248\n",
      "Starting Epoch 295\n",
      "0.554798987896546\n",
      "Starting Epoch 296\n",
      "0.5546930846960648\n",
      "New best model found at epoch 296 with validation loss 0.5475339293479919\n",
      "Starting Epoch 297\n",
      "0.5559955291126085\n",
      "New best model found at epoch 297 with validation loss 0.5474637150764465\n",
      "Starting Epoch 298\n",
      "0.5555857147859491\n",
      "New best model found at epoch 298 with validation loss 0.5474423766136169\n",
      "Starting Epoch 299\n",
      "0.5548378566037053\n",
      "Starting Epoch 300\n",
      "0.5550432995609615\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-25-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc213ca",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 5\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 40 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9349cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "983da5a7-0ce7-4477-b50a-d0549e013c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.2083052448604419\n",
      "New best model found at epoch 1 with validation loss 0.6996686458587646\n",
      "Starting Epoch 2\n",
      "0.6928817940794904\n",
      "Starting Epoch 3\n",
      "0.6946007479792056\n",
      "New best model found at epoch 3 with validation loss 0.6873995661735535\n",
      "Starting Epoch 4\n",
      "0.687904928041541\n",
      "New best model found at epoch 4 with validation loss 0.6826596260070801\n",
      "Starting Epoch 5\n",
      "0.6855809351672297\n",
      "New best model found at epoch 5 with validation loss 0.6814745664596558\n",
      "Starting Epoch 6\n",
      "0.6824121345644412\n",
      "New best model found at epoch 6 with validation loss 0.6787884831428528\n",
      "Starting Epoch 7\n",
      "0.6809614637623662\n",
      "Starting Epoch 8\n",
      "0.6798748270325039\n",
      "Starting Epoch 9\n",
      "0.6783255779224894\n",
      "Starting Epoch 10\n",
      "0.6743484269017759\n",
      "Starting Epoch 11\n",
      "0.6745366143143695\n",
      "New best model found at epoch 11 with validation loss 0.6641679406166077\n",
      "Starting Epoch 12\n",
      "0.6739169825678286\n",
      "Starting Epoch 13\n",
      "0.6716519360956938\n",
      "New best model found at epoch 13 with validation loss 0.6601064205169678\n",
      "Starting Epoch 14\n",
      "0.6674835059953772\n",
      "Starting Epoch 15\n",
      "0.669027724991674\n",
      "New best model found at epoch 15 with validation loss 0.658772349357605\n",
      "Starting Epoch 16\n",
      "0.6594188938970151\n",
      "Starting Epoch 17\n",
      "0.6621315738429194\n",
      "New best model found at epoch 17 with validation loss 0.650969922542572\n",
      "Starting Epoch 18\n",
      "0.658930128035338\n",
      "New best model found at epoch 18 with validation loss 0.6477478742599487\n",
      "Starting Epoch 19\n",
      "0.6571156434390856\n",
      "Starting Epoch 20\n",
      "0.6595416043115698\n",
      "New best model found at epoch 20 with validation loss 0.6450217962265015\n",
      "Starting Epoch 21\n",
      "0.6544561360193335\n",
      "New best model found at epoch 21 with validation loss 0.6438651084899902\n",
      "Starting Epoch 22\n",
      "0.6499997973442078\n",
      "Starting Epoch 23\n",
      "0.6491854709127675\n",
      "New best model found at epoch 23 with validation loss 0.6393419504165649\n",
      "Starting Epoch 24\n",
      "0.6474266078161157\n",
      "New best model found at epoch 24 with validation loss 0.6363144516944885\n",
      "Starting Epoch 25\n",
      "0.6558917138887488\n",
      "Starting Epoch 26\n",
      "0.645109034102896\n",
      "New best model found at epoch 26 with validation loss 0.6345068216323853\n",
      "Starting Epoch 27\n",
      "0.6464842117351034\n",
      "Starting Epoch 28\n",
      "0.6394594544949739\n",
      "New best model found at epoch 28 with validation loss 0.6294435262680054\n",
      "Starting Epoch 29\n",
      "0.6385406981343809\n",
      "Starting Epoch 30\n",
      "0.6384842447612596\n",
      "Starting Epoch 31\n",
      "0.6439955415933029\n",
      "New best model found at epoch 31 with validation loss 0.6279243230819702\n",
      "Starting Epoch 32\n",
      "0.6361105027406112\n",
      "Starting Epoch 33\n",
      "0.6350104756977247\n",
      "New best model found at epoch 33 with validation loss 0.6236649751663208\n",
      "Starting Epoch 34\n",
      "0.6338901675265768\n",
      "Starting Epoch 35\n",
      "0.627947625906571\n",
      "New best model found at epoch 35 with validation loss 0.6225765943527222\n",
      "Starting Epoch 36\n",
      "0.6340197946714319\n",
      "Starting Epoch 37\n",
      "0.631194091361502\n",
      "Starting Epoch 38\n",
      "0.6367077905198802\n",
      "New best model found at epoch 38 with validation loss 0.6213485598564148\n",
      "Starting Epoch 39\n",
      "0.6291197486545729\n",
      "Starting Epoch 40\n",
      "0.6276300704997518\n",
      "New best model found at epoch 40 with validation loss 0.614363431930542\n",
      "Starting Epoch 41\n",
      "0.629304447899694\n",
      "Starting Epoch 42\n",
      "0.6237355600232664\n",
      "Starting Epoch 43\n",
      "0.6305350531702456\n",
      "Starting Epoch 44\n",
      "0.6236304303874141\n",
      "Starting Epoch 45\n",
      "0.625259658564692\n",
      "New best model found at epoch 45 with validation loss 0.6093056201934814\n",
      "Starting Epoch 46\n",
      "0.6225916872853818\n",
      "Starting Epoch 47\n",
      "0.6254918186560922\n",
      "Starting Epoch 48\n",
      "0.6242088183112766\n",
      "Starting Epoch 49\n",
      "0.6255292866540991\n",
      "New best model found at epoch 49 with validation loss 0.6064359545707703\n",
      "Starting Epoch 50\n",
      "0.6211288467697476\n",
      "Starting Epoch 51\n",
      "0.6244048813114995\n",
      "Starting Epoch 52\n",
      "0.6258111803427987\n",
      "Starting Epoch 53\n",
      "0.6182886284330616\n",
      "Starting Epoch 54\n",
      "0.6222559550534124\n",
      "Starting Epoch 55\n",
      "0.61982043929722\n",
      "New best model found at epoch 55 with validation loss 0.6056150794029236\n",
      "Starting Epoch 56\n",
      "0.6158573549726735\n",
      "Starting Epoch 57\n",
      "0.6132248665975488\n",
      "Starting Epoch 58\n",
      "0.6197820228079091\n",
      "Starting Epoch 59\n",
      "0.6220588554506716\n",
      "Starting Epoch 60\n",
      "0.6160345725391222\n",
      "Starting Epoch 61\n",
      "0.6142534354458684\n",
      "New best model found at epoch 61 with validation loss 0.6018363237380981\n",
      "Starting Epoch 62\n",
      "0.6141780122466709\n",
      "Starting Epoch 63\n",
      "0.6119087208872256\n",
      "Starting Epoch 64\n",
      "0.6162197512129078\n",
      "Starting Epoch 65\n",
      "0.6129431180332018\n",
      "Starting Epoch 66\n",
      "0.6145015177519425\n",
      "New best model found at epoch 66 with validation loss 0.60051029920578\n",
      "Starting Epoch 67\n",
      "0.6129514730494955\n",
      "Starting Epoch 68\n",
      "0.6090335820032202\n",
      "Starting Epoch 69\n",
      "0.6089520065680795\n",
      "New best model found at epoch 69 with validation loss 0.597868025302887\n",
      "Starting Epoch 70\n",
      "0.6126847474471383\n",
      "Starting Epoch 71\n",
      "0.6063450678535129\n",
      "Starting Epoch 72\n",
      "0.6093601169793502\n",
      "Starting Epoch 73\n",
      "0.6090436370476432\n",
      "New best model found at epoch 73 with validation loss 0.5960949063301086\n",
      "Starting Epoch 74\n",
      "0.6068235868993013\n",
      "New best model found at epoch 74 with validation loss 0.5956127643585205\n",
      "Starting Epoch 75\n",
      "0.6069062689076299\n",
      "Starting Epoch 76\n",
      "0.6085892915725708\n",
      "Starting Epoch 77\n",
      "0.6078332014705824\n",
      "Starting Epoch 78\n",
      "0.6061488286308621\n",
      "Starting Epoch 79\n",
      "0.604270629260851\n",
      "Starting Epoch 80\n",
      "0.6023599712745004\n",
      "New best model found at epoch 80 with validation loss 0.5917848944664001\n",
      "Starting Epoch 81\n",
      "0.6033588855162911\n",
      "New best model found at epoch 81 with validation loss 0.5904051065444946\n",
      "Starting Epoch 82\n",
      "0.6040322262307872\n",
      "Starting Epoch 83\n",
      "0.6036419557488483\n",
      "Starting Epoch 84\n",
      "0.6006457805633545\n",
      "Starting Epoch 85\n",
      "0.6008794178133425\n",
      "New best model found at epoch 85 with validation loss 0.5875534415245056\n",
      "Starting Epoch 86\n",
      "0.5996310581331667\n",
      "New best model found at epoch 86 with validation loss 0.5872167348861694\n",
      "Starting Epoch 87\n",
      "0.5963043155877487\n",
      "Starting Epoch 88\n",
      "0.6030400939609694\n",
      "Starting Epoch 89\n",
      "0.5949545735898225\n",
      "Starting Epoch 90\n",
      "0.5985332597856936\n",
      "Starting Epoch 91\n",
      "0.5984354407890983\n",
      "Starting Epoch 92\n",
      "0.5948072490484818\n",
      "Starting Epoch 93\n",
      "0.5922903962757277\n",
      "New best model found at epoch 93 with validation loss 0.5861485004425049\n",
      "Starting Epoch 94\n",
      "0.5941868139349896\n",
      "New best model found at epoch 94 with validation loss 0.5847694277763367\n",
      "Starting Epoch 95\n",
      "0.5923874093138654\n",
      "New best model found at epoch 95 with validation loss 0.5826966166496277\n",
      "Starting Epoch 96\n",
      "0.5903848979784094\n",
      "Starting Epoch 97\n",
      "0.593096137046814\n",
      "Starting Epoch 98\n",
      "0.5887676373772\n",
      "Starting Epoch 99\n",
      "0.589598121850387\n",
      "Starting Epoch 100\n",
      "0.590809482595195\n",
      "Starting Epoch 101\n",
      "0.586701706699703\n",
      "New best model found at epoch 101 with validation loss 0.5812605023384094\n",
      "Starting Epoch 102\n",
      "0.5888499021530151\n",
      "Starting Epoch 103\n",
      "0.5858306236889051\n",
      "Starting Epoch 104\n",
      "0.5880828758944636\n",
      "New best model found at epoch 104 with validation loss 0.5781903862953186\n",
      "Starting Epoch 105\n",
      "0.589304955109306\n",
      "Starting Epoch 106\n",
      "0.5858102337173794\n",
      "Starting Epoch 107\n",
      "0.582846690779147\n",
      "New best model found at epoch 107 with validation loss 0.5760641098022461\n",
      "Starting Epoch 108\n",
      "0.5830071412998697\n",
      "Starting Epoch 109\n",
      "0.5866698130317356\n",
      "Starting Epoch 110\n",
      "0.5843422516532566\n",
      "Starting Epoch 111\n",
      "0.5812998854595682\n",
      "New best model found at epoch 111 with validation loss 0.5754066705703735\n",
      "Starting Epoch 112\n",
      "0.5814217678878618\n",
      "Starting Epoch 113\n",
      "0.5805395090061686\n",
      "Starting Epoch 114\n",
      "0.5789663687996243\n",
      "Starting Epoch 115\n",
      "0.581506830194722\n",
      "Starting Epoch 116\n",
      "0.5799191101737644\n",
      "New best model found at epoch 116 with validation loss 0.5734836459159851\n",
      "Starting Epoch 117\n",
      "0.5816742000372513\n",
      "New best model found at epoch 117 with validation loss 0.5721195936203003\n",
      "Starting Epoch 118\n",
      "0.5782028151595074\n",
      "Starting Epoch 119\n",
      "0.579912050910618\n",
      "Starting Epoch 120\n",
      "0.5783870453419893\n",
      "Starting Epoch 121\n",
      "0.5778017640113831\n",
      "New best model found at epoch 121 with validation loss 0.5705898404121399\n",
      "Starting Epoch 122\n",
      "0.5797063500984855\n",
      "Starting Epoch 123\n",
      "0.575446016114691\n",
      "New best model found at epoch 123 with validation loss 0.569892406463623\n",
      "Starting Epoch 124\n",
      "0.5811512586863145\n",
      "Starting Epoch 125\n",
      "0.5751977342626323\n",
      "New best model found at epoch 125 with validation loss 0.5695675611495972\n",
      "Starting Epoch 126\n",
      "0.5762192943821782\n",
      "Starting Epoch 127\n",
      "0.5763425334640171\n",
      "New best model found at epoch 127 with validation loss 0.5676780343055725\n",
      "Starting Epoch 128\n",
      "0.5731745154961295\n",
      "Starting Epoch 129\n",
      "0.5754387650800787\n",
      "Starting Epoch 130\n",
      "0.575176811736563\n",
      "Starting Epoch 131\n",
      "0.5740423228429712\n",
      "Starting Epoch 132\n",
      "0.573961211287457\n",
      "Starting Epoch 133\n",
      "0.5726494452227717\n",
      "Starting Epoch 134\n",
      "0.5756837000017581\n",
      "Starting Epoch 135\n",
      "0.5723925440207772\n",
      "Starting Epoch 136\n",
      "0.5716383379438649\n",
      "Starting Epoch 137\n",
      "0.5723195568374966\n",
      "Starting Epoch 138\n",
      "0.57282271851664\n",
      "Starting Epoch 139\n",
      "0.5701625191647074\n",
      "Starting Epoch 140\n",
      "0.5699359385863595\n",
      "New best model found at epoch 140 with validation loss 0.5666088461875916\n",
      "Starting Epoch 141\n",
      "0.5706219388091046\n",
      "Starting Epoch 142\n",
      "0.5718344268591508\n",
      "Starting Epoch 143\n",
      "0.5698398364626843\n",
      "Starting Epoch 144\n",
      "0.5718618903471075\n",
      "Starting Epoch 145\n",
      "0.5710909029711848\n",
      "Starting Epoch 146\n",
      "0.5698454963124316\n",
      "Starting Epoch 147\n",
      "0.5700059818184894\n",
      "Starting Epoch 148\n",
      "0.5690489761207415\n",
      "Starting Epoch 149\n",
      "0.5686460798201354\n",
      "Starting Epoch 150\n",
      "0.5690211705539537\n",
      "New best model found at epoch 150 with validation loss 0.5652763247489929\n",
      "Starting Epoch 151\n",
      "0.5678724361502606\n",
      "Starting Epoch 152\n",
      "0.5702810261560523\n",
      "Starting Epoch 153\n",
      "0.5706903364347375\n",
      "Starting Epoch 154\n",
      "0.5671606141587963\n",
      "Starting Epoch 155\n",
      "0.567574442728706\n",
      "Starting Epoch 156\n",
      "0.5688291010649308\n",
      "New best model found at epoch 156 with validation loss 0.5636975169181824\n",
      "Starting Epoch 157\n",
      "0.5658902629562046\n",
      "New best model found at epoch 157 with validation loss 0.5625582337379456\n",
      "Starting Epoch 158\n",
      "0.5718590733797654\n",
      "Starting Epoch 159\n",
      "0.5671384762162748\n",
      "Starting Epoch 160\n",
      "0.5665417702301688\n",
      "Starting Epoch 161\n",
      "0.5661056404528411\n",
      "Starting Epoch 162\n",
      "0.5665422341097957\n",
      "New best model found at epoch 162 with validation loss 0.5601457357406616\n",
      "Starting Epoch 163\n",
      "0.5665874947672305\n",
      "New best model found at epoch 163 with validation loss 0.559782862663269\n",
      "Starting Epoch 164\n",
      "0.5644089579582214\n",
      "Starting Epoch 165\n",
      "0.5635673844296\n",
      "Starting Epoch 166\n",
      "0.5647001992101255\n",
      "Starting Epoch 167\n",
      "0.5655175654784493\n",
      "Starting Epoch 168\n",
      "0.5650734979173412\n",
      "Starting Epoch 169\n",
      "0.5630111046459364\n",
      "Starting Epoch 170\n",
      "0.5641121384890183\n",
      "New best model found at epoch 170 with validation loss 0.559714674949646\n",
      "Starting Epoch 171\n",
      "0.5636754839316659\n",
      "Starting Epoch 172\n",
      "0.561997519887012\n",
      "New best model found at epoch 172 with validation loss 0.5536860823631287\n",
      "Starting Epoch 173\n",
      "0.5631535960280377\n",
      "Starting Epoch 174\n",
      "0.5614114196404166\n",
      "Starting Epoch 175\n",
      "0.5629428314126056\n",
      "Starting Epoch 176\n",
      "0.5609799182933309\n",
      "Starting Epoch 177\n",
      "0.5606031469676805\n",
      "Starting Epoch 178\n",
      "0.5599621728710507\n",
      "Starting Epoch 179\n",
      "0.5599048643008523\n",
      "New best model found at epoch 179 with validation loss 0.553159236907959\n",
      "Starting Epoch 180\n",
      "0.5606192272642384\n",
      "Starting Epoch 181\n",
      "0.5601624276327051\n",
      "Starting Epoch 182\n",
      "0.5592163853023363\n",
      "Starting Epoch 183\n",
      "0.5607962686082592\n",
      "Starting Epoch 184\n",
      "0.5601266531840615\n",
      "Starting Epoch 185\n",
      "0.558965574140134\n",
      "Starting Epoch 186\n",
      "0.5593321608460468\n",
      "Starting Epoch 187\n",
      "0.5590208911377451\n",
      "Starting Epoch 188\n",
      "0.5599293864291647\n",
      "Starting Epoch 189\n",
      "0.5586054752702299\n",
      "Starting Epoch 190\n",
      "0.5581141749153966\n",
      "Starting Epoch 191\n",
      "0.5584444896034573\n",
      "Starting Epoch 192\n",
      "0.5560717569745105\n",
      "New best model found at epoch 192 with validation loss 0.5530387163162231\n",
      "Starting Epoch 193\n",
      "0.5584000556365304\n",
      "New best model found at epoch 193 with validation loss 0.5517451763153076\n",
      "Starting Epoch 194\n",
      "0.5584084883980129\n",
      "Starting Epoch 195\n",
      "0.5562127336211826\n",
      "Starting Epoch 196\n",
      "0.5551494061946869\n",
      "Starting Epoch 197\n",
      "0.5564602341340936\n",
      "Starting Epoch 198\n",
      "0.5551569954208706\n",
      "Starting Epoch 199\n",
      "0.555587491263514\n",
      "Starting Epoch 200\n",
      "0.5571454815242601\n",
      "Starting Epoch 201\n",
      "0.55779880673989\n",
      "Starting Epoch 202\n",
      "0.5556669546210248\n",
      "New best model found at epoch 202 with validation loss 0.5502679944038391\n",
      "Starting Epoch 203\n",
      "0.5547151423018911\n",
      "Starting Epoch 204\n",
      "0.5566792993441873\n",
      "Starting Epoch 205\n",
      "0.5563634880211042\n",
      "New best model found at epoch 205 with validation loss 0.549260675907135\n",
      "Starting Epoch 206\n",
      "0.5593288320562114\n",
      "Starting Epoch 207\n",
      "0.553336324899093\n",
      "Starting Epoch 208\n",
      "0.55444252361422\n",
      "Starting Epoch 209\n",
      "0.5556473252565964\n",
      "Starting Epoch 210\n",
      "0.5533356135306151\n",
      "Starting Epoch 211\n",
      "0.5543493654416956\n",
      "New best model found at epoch 211 with validation loss 0.5481160283088684\n",
      "Starting Epoch 212\n",
      "0.5535566910453464\n",
      "New best model found at epoch 212 with validation loss 0.5479084253311157\n",
      "Starting Epoch 213\n",
      "0.5525242854719576\n",
      "Starting Epoch 214\n",
      "0.5529614570348159\n",
      "Starting Epoch 215\n",
      "0.5521843757318414\n",
      "Starting Epoch 216\n",
      "0.5524800562340281\n",
      "Starting Epoch 217\n",
      "0.552592598873636\n",
      "Starting Epoch 218\n",
      "0.5536215175753054\n",
      "New best model found at epoch 218 with validation loss 0.5472948551177979\n",
      "Starting Epoch 219\n",
      "0.5509279681288678\n",
      "New best model found at epoch 219 with validation loss 0.5461516380310059\n",
      "Starting Epoch 220\n",
      "0.550302460141804\n",
      "Starting Epoch 221\n",
      "0.5505952187206434\n",
      "New best model found at epoch 221 with validation loss 0.5455189943313599\n",
      "Starting Epoch 222\n",
      "0.5536002283510955\n",
      "Starting Epoch 223\n",
      "0.5523291541182477\n",
      "Starting Epoch 224\n",
      "0.5515261745971182\n",
      "Starting Epoch 225\n",
      "0.5518628566161446\n",
      "Starting Epoch 226\n",
      "0.5502553672894187\n",
      "New best model found at epoch 226 with validation loss 0.5455116629600525\n",
      "Starting Epoch 227\n",
      "0.5500975678796354\n",
      "Starting Epoch 228\n",
      "0.5505156231963116\n",
      "New best model found at epoch 228 with validation loss 0.5438960790634155\n",
      "Starting Epoch 229\n",
      "0.5503577551116114\n",
      "New best model found at epoch 229 with validation loss 0.5432312488555908\n",
      "Starting Epoch 230\n",
      "0.5518570969934049\n",
      "Starting Epoch 231\n",
      "0.5509405848772629\n",
      "Starting Epoch 232\n",
      "0.5510209423044453\n",
      "Starting Epoch 233\n",
      "0.5484253569789554\n",
      "Starting Epoch 234\n",
      "0.5486787868582684\n",
      "Starting Epoch 235\n",
      "0.548887920120488\n",
      "New best model found at epoch 235 with validation loss 0.5423725843429565\n",
      "Starting Epoch 236\n",
      "0.5495551902314891\n",
      "Starting Epoch 237\n",
      "0.5506222235119861\n",
      "Starting Epoch 238\n",
      "0.5481558882671854\n",
      "Starting Epoch 239\n",
      "0.5475270022516665\n",
      "Starting Epoch 240\n",
      "0.5485320933487104\n",
      "Starting Epoch 241\n",
      "0.5476179615311001\n",
      "Starting Epoch 242\n",
      "0.5488105027571969\n",
      "Starting Epoch 243\n",
      "0.5475265953851782\n",
      "Starting Epoch 244\n",
      "0.5476990756781205\n",
      "Starting Epoch 245\n",
      "0.5458974566148675\n",
      "Starting Epoch 246\n",
      "0.5471331917721293\n",
      "New best model found at epoch 246 with validation loss 0.5411837697029114\n",
      "Starting Epoch 247\n",
      "0.5463058922601782\n",
      "New best model found at epoch 247 with validation loss 0.5404523611068726\n",
      "Starting Epoch 248\n",
      "0.5460853680320408\n",
      "Starting Epoch 249\n",
      "0.5469541238701862\n",
      "Starting Epoch 250\n",
      "0.5446158621622168\n",
      "New best model found at epoch 250 with validation loss 0.5386794209480286\n",
      "Starting Epoch 251\n",
      "0.5482085671113885\n",
      "Starting Epoch 252\n",
      "0.549345586610877\n",
      "Starting Epoch 253\n",
      "0.5457823898481287\n",
      "Starting Epoch 254\n",
      "0.5484610329503599\n",
      "Starting Epoch 255\n",
      "0.5474094346813534\n",
      "Starting Epoch 256\n",
      "0.5477186519166698\n",
      "Starting Epoch 257\n",
      "0.5460971749347189\n",
      "New best model found at epoch 257 with validation loss 0.5373932719230652\n",
      "Starting Epoch 258\n",
      "0.5452838306841643\n",
      "Starting Epoch 259\n",
      "0.5466621984606204\n",
      "Starting Epoch 260\n",
      "0.5468856601611428\n",
      "Starting Epoch 261\n",
      "0.5464584956998411\n",
      "New best model found at epoch 261 with validation loss 0.5373484492301941\n",
      "Starting Epoch 262\n",
      "0.5452991827674534\n",
      "Starting Epoch 263\n",
      "0.5454957575901694\n",
      "Starting Epoch 264\n",
      "0.5470799531625665\n",
      "Starting Epoch 265\n",
      "0.5459571506666101\n",
      "Starting Epoch 266\n",
      "0.5447697807913241\n",
      "Starting Epoch 267\n",
      "0.5450984213663184\n",
      "Starting Epoch 268\n",
      "0.5469646894413492\n",
      "Starting Epoch 269\n",
      "0.5466054561345474\n",
      "Starting Epoch 270\n",
      "0.548227767581525\n",
      "Starting Epoch 271\n",
      "0.5442677930645321\n",
      "Starting Epoch 272\n",
      "0.544557651747828\n",
      "New best model found at epoch 272 with validation loss 0.5358921885490417\n",
      "Starting Epoch 273\n",
      "0.5440904627675596\n",
      "Starting Epoch 274\n",
      "0.5456112480681875\n",
      "Starting Epoch 275\n",
      "0.5452721403992694\n",
      "Starting Epoch 276\n",
      "0.5443555285101351\n",
      "Starting Epoch 277\n",
      "0.5434456065945004\n",
      "Starting Epoch 278\n",
      "0.5448778051397075\n",
      "Starting Epoch 279\n",
      "0.5431849917639857\n",
      "Starting Epoch 280\n",
      "0.5423805532248124\n",
      "Starting Epoch 281\n",
      "0.5443675038607224\n",
      "Starting Epoch 282\n",
      "0.5429474115371704\n",
      "Starting Epoch 283\n",
      "0.5443197968213455\n",
      "Starting Epoch 284\n",
      "0.5452849528063899\n",
      "Starting Epoch 285\n",
      "0.5449851025705752\n",
      "Starting Epoch 286\n",
      "0.5438146902167279\n",
      "Starting Epoch 287\n",
      "0.5437376654666403\n",
      "New best model found at epoch 287 with validation loss 0.5358061194419861\n",
      "Starting Epoch 288\n",
      "0.5423075841820758\n",
      "New best model found at epoch 288 with validation loss 0.5355049967765808\n",
      "Starting Epoch 289\n",
      "0.5432220995426178\n",
      "Starting Epoch 290\n",
      "0.5450868204883907\n",
      "Starting Epoch 291\n",
      "0.542585551738739\n",
      "Starting Epoch 292\n",
      "0.5443848436293395\n",
      "Starting Epoch 293\n",
      "0.5428063299344934\n",
      "Starting Epoch 294\n",
      "0.5422701965207639\n",
      "Starting Epoch 295\n",
      "0.542647413585497\n",
      "Starting Epoch 296\n",
      "0.543097418287526\n",
      "Starting Epoch 297\n",
      "0.5421482557835786\n",
      "New best model found at epoch 297 with validation loss 0.5334476828575134\n",
      "Starting Epoch 298\n",
      "0.5421465453894242\n",
      "Starting Epoch 299\n",
      "0.5432140244090039\n",
      "Starting Epoch 300\n",
      "0.541638970375061\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-40-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b03b14",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 6\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 60 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9461fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "320c063b-7853-4a9d-8b8a-64c6135b2d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.5806171064791472\n",
      "New best model found at epoch 1 with validation loss 0.6815069913864136\n",
      "Starting Epoch 2\n",
      "0.6858274470204893\n",
      "Starting Epoch 3\n",
      "0.6854273547296938\n",
      "New best model found at epoch 3 with validation loss 0.6698161959648132\n",
      "Starting Epoch 4\n",
      "0.6888850512711898\n",
      "New best model found at epoch 4 with validation loss 0.6580167412757874\n",
      "Starting Epoch 5\n",
      "0.6796563889669336\n",
      "New best model found at epoch 5 with validation loss 0.6507411003112793\n",
      "Starting Epoch 6\n",
      "0.6636663623478102\n",
      "New best model found at epoch 6 with validation loss 0.6481473445892334\n",
      "Starting Epoch 7\n",
      "0.6589321882828422\n",
      "New best model found at epoch 7 with validation loss 0.6351153254508972\n",
      "Starting Epoch 8\n",
      "0.6524283056673796\n",
      "Starting Epoch 9\n",
      "0.6650816798210144\n",
      "Starting Epoch 10\n",
      "0.6370159802229508\n",
      "Starting Epoch 11\n",
      "0.6392259908759076\n",
      "New best model found at epoch 11 with validation loss 0.6190764904022217\n",
      "Starting Epoch 12\n",
      "0.6343059591625048\n",
      "New best model found at epoch 12 with validation loss 0.605984091758728\n",
      "Starting Epoch 13\n",
      "0.6188401683517124\n",
      "New best model found at epoch 13 with validation loss 0.6049227714538574\n",
      "Starting Epoch 14\n",
      "0.6173825056656547\n",
      "Starting Epoch 15\n",
      "0.6227358346400054\n",
      "Starting Epoch 16\n",
      "0.6144637828287871\n",
      "New best model found at epoch 16 with validation loss 0.5899991989135742\n",
      "Starting Epoch 17\n",
      "0.6163827621418497\n",
      "New best model found at epoch 17 with validation loss 0.5856856107711792\n",
      "Starting Epoch 18\n",
      "0.6055939715841542\n",
      "Starting Epoch 19\n",
      "0.602434850257376\n",
      "New best model found at epoch 19 with validation loss 0.5820408463478088\n",
      "Starting Epoch 20\n",
      "0.5996912303178207\n",
      "New best model found at epoch 20 with validation loss 0.5769844055175781\n",
      "Starting Epoch 21\n",
      "0.5966793557871943\n",
      "New best model found at epoch 21 with validation loss 0.5768937468528748\n",
      "Starting Epoch 22\n",
      "0.6013274011404618\n",
      "Starting Epoch 23\n",
      "0.5903343247330707\n",
      "New best model found at epoch 23 with validation loss 0.5735186338424683\n",
      "Starting Epoch 24\n",
      "0.6017290872076283\n",
      "New best model found at epoch 24 with validation loss 0.5730072259902954\n",
      "Starting Epoch 25\n",
      "0.5839673980422642\n",
      "New best model found at epoch 25 with validation loss 0.5714977979660034\n",
      "Starting Epoch 26\n",
      "0.590399980545044\n",
      "New best model found at epoch 26 with validation loss 0.5672444701194763\n",
      "Starting Epoch 27\n",
      "0.5869187764499498\n",
      "New best model found at epoch 27 with validation loss 0.567046046257019\n",
      "Starting Epoch 28\n",
      "0.5796029593633569\n",
      "Starting Epoch 29\n",
      "0.5847316604593525\n",
      "Starting Epoch 30\n",
      "0.5845883436824965\n",
      "Starting Epoch 31\n",
      "0.5851520248081373\n",
      "New best model found at epoch 31 with validation loss 0.5634167790412903\n",
      "Starting Epoch 32\n",
      "0.5806075192016104\n",
      "Starting Epoch 33\n",
      "0.5865818054779716\n",
      "New best model found at epoch 33 with validation loss 0.561165452003479\n",
      "Starting Epoch 34\n",
      "0.5912101605664128\n",
      "Starting Epoch 35\n",
      "0.5766515498575957\n",
      "Starting Epoch 36\n",
      "0.5831786731015081\n",
      "Starting Epoch 37\n",
      "0.5732031464576721\n",
      "New best model found at epoch 37 with validation loss 0.5570206642150879\n",
      "Starting Epoch 38\n",
      "0.5793488388476165\n",
      "Starting Epoch 39\n",
      "0.5712165184642958\n",
      "Starting Epoch 40\n",
      "0.5774128877598307\n",
      "Starting Epoch 41\n",
      "0.5749832884125088\n",
      "Starting Epoch 42\n",
      "0.5766153737254764\n",
      "New best model found at epoch 42 with validation loss 0.5541605353355408\n",
      "Starting Epoch 43\n",
      "0.571713501992433\n",
      "Starting Epoch 44\n",
      "0.5819287351939989\n",
      "Starting Epoch 45\n",
      "0.5718720425730166\n",
      "New best model found at epoch 45 with validation loss 0.552476704120636\n",
      "Starting Epoch 46\n",
      "0.572768597499184\n",
      "Starting Epoch 47\n",
      "0.5683781388013259\n",
      "Starting Epoch 48\n",
      "0.570502379666204\n",
      "Starting Epoch 49\n",
      "0.5667832662229952\n",
      "New best model found at epoch 49 with validation loss 0.5504109263420105\n",
      "Starting Epoch 50\n",
      "0.5717049927815147\n",
      "New best model found at epoch 50 with validation loss 0.5494065284729004\n",
      "Starting Epoch 51\n",
      "0.5695684966833695\n",
      "Starting Epoch 52\n",
      "0.5704239127428635\n",
      "Starting Epoch 53\n",
      "0.5698274425838304\n",
      "Starting Epoch 54\n",
      "0.572683326576067\n",
      "Starting Epoch 55\n",
      "0.5680845587149911\n",
      "Starting Epoch 56\n",
      "0.5772956195084945\n",
      "Starting Epoch 57\n",
      "0.5643267605615698\n",
      "New best model found at epoch 57 with validation loss 0.5485106706619263\n",
      "Starting Epoch 58\n",
      "0.5778491497039795\n",
      "Starting Epoch 59\n",
      "0.5718241865220277\n",
      "Starting Epoch 60\n",
      "0.5666917717975118\n",
      "Starting Epoch 61\n",
      "0.5654106256754502\n",
      "Starting Epoch 62\n",
      "0.5687864941099415\n",
      "New best model found at epoch 62 with validation loss 0.5458966493606567\n",
      "Starting Epoch 63\n",
      "0.5649277852929157\n",
      "New best model found at epoch 63 with validation loss 0.5451754331588745\n",
      "Starting Epoch 64\n",
      "0.5619676527769669\n",
      "Starting Epoch 65\n",
      "0.5615556589935137\n",
      "Starting Epoch 66\n",
      "0.5655497182970461\n",
      "Starting Epoch 67\n",
      "0.5655856339827828\n",
      "Starting Epoch 68\n",
      "0.5637535686078279\n",
      "New best model found at epoch 68 with validation loss 0.5428925156593323\n",
      "Starting Epoch 69\n",
      "0.5630088448524475\n",
      "Starting Epoch 70\n",
      "0.5618766766527424\n",
      "Starting Epoch 71\n",
      "0.5651266263878864\n",
      "Starting Epoch 72\n",
      "0.5573746898899907\n",
      "New best model found at epoch 72 with validation loss 0.5398070812225342\n",
      "Starting Epoch 73\n",
      "0.5583693203718766\n",
      "Starting Epoch 74\n",
      "0.5609342222628386\n",
      "New best model found at epoch 74 with validation loss 0.5397971272468567\n",
      "Starting Epoch 75\n",
      "0.5599887461765952\n",
      "Starting Epoch 76\n",
      "0.5551405238068622\n",
      "Starting Epoch 77\n",
      "0.5567681802355725\n",
      "Starting Epoch 78\n",
      "0.5584527422552523\n",
      "New best model found at epoch 78 with validation loss 0.5397874116897583\n",
      "Starting Epoch 79\n",
      "0.5560555963412576\n",
      "New best model found at epoch 79 with validation loss 0.5389383435249329\n",
      "Starting Epoch 80\n",
      "0.5570571772430254\n",
      "Starting Epoch 81\n",
      "0.5559737941493159\n",
      "Starting Epoch 82\n",
      "0.5588434429272361\n",
      "Starting Epoch 83\n",
      "0.5594132011351378\n",
      "Starting Epoch 84\n",
      "0.5574648794920548\n",
      "Starting Epoch 85\n",
      "0.5581653377284175\n",
      "Starting Epoch 86\n",
      "0.5556821421436642\n",
      "New best model found at epoch 86 with validation loss 0.5367102026939392\n",
      "Starting Epoch 87\n",
      "0.5527434724828472\n",
      "Starting Epoch 88\n",
      "0.5554948786030645\n",
      "Starting Epoch 89\n",
      "0.5546590258245883\n",
      "New best model found at epoch 89 with validation loss 0.5333369970321655\n",
      "Starting Epoch 90\n",
      "0.5559113129325535\n",
      "Starting Epoch 91\n",
      "0.556164977343186\n",
      "Starting Epoch 92\n",
      "0.5502874630948772\n",
      "Starting Epoch 93\n",
      "0.555438220500946\n",
      "Starting Epoch 94\n",
      "0.5582232851049175\n",
      "Starting Epoch 95\n",
      "0.5515806208486143\n",
      "New best model found at epoch 95 with validation loss 0.5330491662025452\n",
      "Starting Epoch 96\n",
      "0.5485487450724063\n",
      "Starting Epoch 97\n",
      "0.5511735574058865\n",
      "New best model found at epoch 97 with validation loss 0.5322939157485962\n",
      "Starting Epoch 98\n",
      "0.552400652481162\n",
      "Starting Epoch 99\n",
      "0.5525922360627548\n",
      "Starting Epoch 100\n",
      "0.552892355815224\n",
      "New best model found at epoch 100 with validation loss 0.5308790802955627\n",
      "Starting Epoch 101\n",
      "0.5544243454933167\n",
      "Starting Epoch 102\n",
      "0.5508556651032489\n",
      "Starting Epoch 103\n",
      "0.5512848315031632\n",
      "Starting Epoch 104\n",
      "0.556208065022593\n",
      "Starting Epoch 105\n",
      "0.5546242465143618\n",
      "Starting Epoch 106\n",
      "0.5598147057968638\n",
      "Starting Epoch 107\n",
      "0.5481790083905925\n",
      "Starting Epoch 108\n",
      "0.5519939997921819\n",
      "Starting Epoch 109\n",
      "0.550924038109572\n",
      "Starting Epoch 110\n",
      "0.5466031134128571\n",
      "Starting Epoch 111\n",
      "0.5513551144496255\n",
      "Starting Epoch 112\n",
      "0.5502726370873658\n",
      "New best model found at epoch 112 with validation loss 0.528628945350647\n",
      "Starting Epoch 113\n",
      "0.5458287467127261\n",
      "New best model found at epoch 113 with validation loss 0.5281393527984619\n",
      "Starting Epoch 114\n",
      "0.5497982139172761\n",
      "Starting Epoch 115\n",
      "0.5468739750592605\n",
      "Starting Epoch 116\n",
      "0.5483566354150358\n",
      "New best model found at epoch 116 with validation loss 0.5265429615974426\n",
      "Starting Epoch 117\n",
      "0.5451535880565643\n",
      "Starting Epoch 118\n",
      "0.547021614468616\n",
      "Starting Epoch 119\n",
      "0.5441646135371664\n",
      "New best model found at epoch 119 with validation loss 0.5252814292907715\n",
      "Starting Epoch 120\n",
      "0.5425665611806123\n",
      "New best model found at epoch 120 with validation loss 0.5248725414276123\n",
      "Starting Epoch 121\n",
      "0.5439751640610073\n",
      "New best model found at epoch 121 with validation loss 0.5238623023033142\n",
      "Starting Epoch 122\n",
      "0.5516206894231879\n",
      "Starting Epoch 123\n",
      "0.5466567174248074\n",
      "Starting Epoch 124\n",
      "0.5438449136588884\n",
      "New best model found at epoch 124 with validation loss 0.5230950713157654\n",
      "Starting Epoch 125\n",
      "0.5475530831710153\n",
      "Starting Epoch 126\n",
      "0.5405740789745165\n",
      "Starting Epoch 127\n",
      "0.544123482445012\n",
      "Starting Epoch 128\n",
      "0.5439332412636798\n",
      "Starting Epoch 129\n",
      "0.5421522337457408\n",
      "New best model found at epoch 129 with validation loss 0.5190536379814148\n",
      "Starting Epoch 130\n",
      "0.5464873586011969\n",
      "Starting Epoch 131\n",
      "0.5448934111906134\n",
      "New best model found at epoch 131 with validation loss 0.5171024203300476\n",
      "Starting Epoch 132\n",
      "0.5478422615839087\n",
      "Starting Epoch 133\n",
      "0.5442458572595016\n",
      "Starting Epoch 134\n",
      "0.543989905844564\n",
      "Starting Epoch 135\n",
      "0.5439883250257244\n",
      "Starting Epoch 136\n",
      "0.5466088237969772\n",
      "Starting Epoch 137\n",
      "0.5440216505009196\n",
      "Starting Epoch 138\n",
      "0.5417742547781571\n",
      "Starting Epoch 139\n",
      "0.5386969226857891\n",
      "New best model found at epoch 139 with validation loss 0.5163093209266663\n",
      "Starting Epoch 140\n",
      "0.5416106555772864\n",
      "Starting Epoch 141\n",
      "0.5404472843460415\n",
      "Starting Epoch 142\n",
      "0.543085823888364\n",
      "Starting Epoch 143\n",
      "0.5406199240166208\n",
      "Starting Epoch 144\n",
      "0.5401133894920349\n",
      "New best model found at epoch 144 with validation loss 0.5134526491165161\n",
      "Starting Epoch 145\n",
      "0.5389367277207582\n",
      "Starting Epoch 146\n",
      "0.5415402158446934\n",
      "New best model found at epoch 146 with validation loss 0.513422966003418\n",
      "Starting Epoch 147\n",
      "0.5425051761710126\n",
      "Starting Epoch 148\n",
      "0.5391571288523467\n",
      "Starting Epoch 149\n",
      "0.5396363670411317\n",
      "Starting Epoch 150\n",
      "0.5372975105824678\n",
      "Starting Epoch 151\n",
      "0.5393137905908667\n",
      "Starting Epoch 152\n",
      "0.5389573133510092\n",
      "New best model found at epoch 152 with validation loss 0.5110939741134644\n",
      "Starting Epoch 153\n",
      "0.5369265170201011\n",
      "Starting Epoch 154\n",
      "0.5422000936839891\n",
      "Starting Epoch 155\n",
      "0.5400744378566742\n",
      "Starting Epoch 156\n",
      "0.5415209220803302\n",
      "New best model found at epoch 156 with validation loss 0.5100588202476501\n",
      "Starting Epoch 157\n",
      "0.5366960349290267\n",
      "Starting Epoch 158\n",
      "0.5373126294301904\n",
      "Starting Epoch 159\n",
      "0.5363157443378282\n",
      "New best model found at epoch 159 with validation loss 0.5087384581565857\n",
      "Starting Epoch 160\n",
      "0.5402625242005223\n",
      "Starting Epoch 161\n",
      "0.5422210317590962\n",
      "Starting Epoch 162\n",
      "0.5357512468877046\n",
      "Starting Epoch 163\n",
      "0.5356940549352894\n",
      "New best model found at epoch 163 with validation loss 0.5053212642669678\n",
      "Starting Epoch 164\n",
      "0.5371557577796604\n",
      "Starting Epoch 165\n",
      "0.5349005421866542\n",
      "Starting Epoch 166\n",
      "0.5351068325664686\n",
      "Starting Epoch 167\n",
      "0.5356297389320706\n",
      "Starting Epoch 168\n",
      "0.5385322674461033\n",
      "Starting Epoch 169\n",
      "0.5356505461361097\n",
      "Starting Epoch 170\n",
      "0.5438924172650212\n",
      "New best model found at epoch 170 with validation loss 0.5052433013916016\n",
      "Starting Epoch 171\n",
      "0.5334365627040034\n",
      "Starting Epoch 172\n",
      "0.5340332285217617\n",
      "Starting Epoch 173\n",
      "0.5353717959445455\n",
      "Starting Epoch 174\n",
      "0.5345601569051328\n",
      "Starting Epoch 175\n",
      "0.5342174003953519\n",
      "New best model found at epoch 175 with validation loss 0.5030559301376343\n",
      "Starting Epoch 176\n",
      "0.5346847655980483\n",
      "Starting Epoch 177\n",
      "0.5353088702844537\n",
      "Starting Epoch 178\n",
      "0.5356647618438887\n",
      "New best model found at epoch 178 with validation loss 0.5024622082710266\n",
      "Starting Epoch 179\n",
      "0.532221002423245\n",
      "Starting Epoch 180\n",
      "0.5327048988445945\n",
      "Starting Epoch 181\n",
      "0.5366485416889191\n",
      "New best model found at epoch 181 with validation loss 0.5022579431533813\n",
      "Starting Epoch 182\n",
      "0.5318727894969608\n",
      "Starting Epoch 183\n",
      "0.5376024583111638\n",
      "Starting Epoch 184\n",
      "0.5386285302431687\n",
      "Starting Epoch 185\n",
      "0.5360847024813943\n",
      "Starting Epoch 186\n",
      "0.5342690750308658\n",
      "Starting Epoch 187\n",
      "0.532695112021073\n",
      "Starting Epoch 188\n",
      "0.5313391815061155\n",
      "New best model found at epoch 188 with validation loss 0.5000403523445129\n",
      "Starting Epoch 189\n",
      "0.5338408610095149\n",
      "New best model found at epoch 189 with validation loss 0.4978652000427246\n",
      "Starting Epoch 190\n",
      "0.5356561165788899\n",
      "Starting Epoch 191\n",
      "0.5323260867077372\n",
      "Starting Epoch 192\n",
      "0.5341121165648751\n",
      "New best model found at epoch 192 with validation loss 0.49638131260871887\n",
      "Starting Epoch 193\n",
      "0.530705988407135\n",
      "Starting Epoch 194\n",
      "0.5323320510594741\n",
      "Starting Epoch 195\n",
      "0.5336948866429536\n",
      "Starting Epoch 196\n",
      "0.5325294253618821\n",
      "Starting Epoch 197\n",
      "0.5307170502517534\n",
      "Starting Epoch 198\n",
      "0.5305859109629756\n",
      "Starting Epoch 199\n",
      "0.531148901452189\n",
      "Starting Epoch 200\n",
      "0.5305515229701996\n",
      "Starting Epoch 201\n",
      "0.5350730432116467\n",
      "Starting Epoch 202\n",
      "0.5287339700304944\n",
      "Starting Epoch 203\n",
      "0.5344538222188535\n",
      "Starting Epoch 204\n",
      "0.5286837025828983\n",
      "Starting Epoch 205\n",
      "0.5309451364952585\n",
      "Starting Epoch 206\n",
      "0.5294976623161979\n",
      "Starting Epoch 207\n",
      "0.5287499350050221\n",
      "New best model found at epoch 207 with validation loss 0.49578338861465454\n",
      "Starting Epoch 208\n",
      "0.5309019529301188\n",
      "Starting Epoch 209\n",
      "0.5322787606197855\n",
      "Starting Epoch 210\n",
      "0.5293498155863389\n",
      "Starting Epoch 211\n",
      "0.5308687298194222\n",
      "Starting Epoch 212\n",
      "0.5306822191114011\n",
      "New best model found at epoch 212 with validation loss 0.4943631589412689\n",
      "Starting Epoch 213\n",
      "0.5286211915638136\n",
      "Starting Epoch 214\n",
      "0.5285071445548016\n",
      "Starting Epoch 215\n",
      "0.5311843765818555\n",
      "Starting Epoch 216\n",
      "0.5280893393184828\n",
      "Starting Epoch 217\n",
      "0.5275711222835209\n",
      "New best model found at epoch 217 with validation loss 0.49416467547416687\n",
      "Starting Epoch 218\n",
      "0.5285548580729443\n",
      "New best model found at epoch 218 with validation loss 0.4931667447090149\n",
      "Starting Epoch 219\n",
      "0.5291455737922502\n",
      "Starting Epoch 220\n",
      "0.528909805028335\n",
      "Starting Epoch 221\n",
      "0.5298262057097062\n",
      "Starting Epoch 222\n",
      "0.5325536831565525\n",
      "New best model found at epoch 222 with validation loss 0.4918469488620758\n",
      "Starting Epoch 223\n",
      "0.5256204410739567\n",
      "Starting Epoch 224\n",
      "0.5301926563615385\n",
      "Starting Epoch 225\n",
      "0.5255973274293153\n",
      "Starting Epoch 226\n",
      "0.5298036064790643\n",
      "Starting Epoch 227\n",
      "0.5268502818501514\n",
      "Starting Epoch 228\n",
      "0.5264239583326422\n",
      "Starting Epoch 229\n",
      "0.5272902885208959\n",
      "Starting Epoch 230\n",
      "0.5289699072423188\n",
      "Starting Epoch 231\n",
      "0.5309697234112284\n",
      "Starting Epoch 232\n",
      "0.5256481066994045\n",
      "Starting Epoch 233\n",
      "0.5265448145244432\n",
      "Starting Epoch 234\n",
      "0.5269795254520748\n",
      "Starting Epoch 235\n",
      "0.5322834927102794\n",
      "New best model found at epoch 235 with validation loss 0.4907701313495636\n",
      "Starting Epoch 236\n",
      "0.5240174817002338\n",
      "Starting Epoch 237\n",
      "0.5285213771073715\n",
      "Starting Epoch 238\n",
      "0.5266940062460692\n",
      "Starting Epoch 239\n",
      "0.5262903493383656\n",
      "Starting Epoch 240\n",
      "0.5302359150803607\n",
      "Starting Epoch 241\n",
      "0.5250298665917438\n",
      "Starting Epoch 242\n",
      "0.5258146006128063\n",
      "Starting Epoch 243\n",
      "0.5296419340631237\n",
      "Starting Epoch 244\n",
      "0.527759655662205\n",
      "Starting Epoch 245\n",
      "0.5261641261370286\n",
      "New best model found at epoch 245 with validation loss 0.48996803164482117\n",
      "Starting Epoch 246\n",
      "0.5240900827490765\n",
      "Starting Epoch 247\n",
      "0.5242992393348528\n",
      "New best model found at epoch 247 with validation loss 0.4878125488758087\n",
      "Starting Epoch 248\n",
      "0.5243854937346085\n",
      "Starting Epoch 249\n",
      "0.5247030944927878\n",
      "Starting Epoch 250\n",
      "0.5296789900116299\n",
      "Starting Epoch 251\n",
      "0.5251426567202029\n",
      "Starting Epoch 252\n",
      "0.52591472864151\n",
      "Starting Epoch 253\n",
      "0.5289405273354572\n",
      "Starting Epoch 254\n",
      "0.5245322377785392\n",
      "Starting Epoch 255\n",
      "0.5216913767482924\n",
      "Starting Epoch 256\n",
      "0.524750213260236\n",
      "Starting Epoch 257\n",
      "0.5253738864608433\n",
      "Starting Epoch 258\n",
      "0.5223151458346326\n",
      "Starting Epoch 259\n",
      "0.5241288698237875\n",
      "New best model found at epoch 259 with validation loss 0.4874348044395447\n",
      "Starting Epoch 260\n",
      "0.5256935202557108\n",
      "Starting Epoch 261\n",
      "0.523888911889947\n",
      "New best model found at epoch 261 with validation loss 0.48684126138687134\n",
      "Starting Epoch 262\n",
      "0.5234467762967815\n",
      "Starting Epoch 263\n",
      "0.5254905405251876\n",
      "Starting Epoch 264\n",
      "0.5250199333481167\n",
      "New best model found at epoch 264 with validation loss 0.48552432656288147\n",
      "Starting Epoch 265\n",
      "0.5232644197733506\n",
      "Starting Epoch 266\n",
      "0.5239458783813145\n",
      "Starting Epoch 267\n",
      "0.5249312584814818\n",
      "New best model found at epoch 267 with validation loss 0.4841068387031555\n",
      "Starting Epoch 268\n",
      "0.5234664743361266\n",
      "Starting Epoch 269\n",
      "0.5241135617961055\n",
      "Starting Epoch 270\n",
      "0.5254007150297579\n",
      "Starting Epoch 271\n",
      "0.5225139208461927\n",
      "Starting Epoch 272\n",
      "0.5228634800599969\n",
      "Starting Epoch 273\n",
      "0.5255884009858837\n",
      "Starting Epoch 274\n",
      "0.5309083371058755\n",
      "Starting Epoch 275\n",
      "0.5245973377124123\n",
      "Starting Epoch 276\n",
      "0.5247435686380967\n",
      "Starting Epoch 277\n",
      "0.5252307808917501\n",
      "Starting Epoch 278\n",
      "0.523903612209403\n",
      "Starting Epoch 279\n",
      "0.5229439709497534\n",
      "Starting Epoch 280\n",
      "0.5224953812101613\n",
      "Starting Epoch 281\n",
      "0.5210729798545009\n",
      "Starting Epoch 282\n",
      "0.5265457422836967\n",
      "Starting Epoch 283\n",
      "0.5223740261533986\n",
      "Starting Epoch 284\n",
      "0.5247471358465112\n",
      "New best model found at epoch 284 with validation loss 0.4836317002773285\n",
      "Starting Epoch 285\n",
      "0.5249953814174818\n",
      "Starting Epoch 286\n",
      "0.5234477675479391\n",
      "Starting Epoch 287\n",
      "0.5220383962859279\n",
      "Starting Epoch 288\n",
      "0.5252981237743212\n",
      "Starting Epoch 289\n",
      "0.523199755212535\n",
      "Starting Epoch 290\n",
      "0.5225278372349946\n",
      "New best model found at epoch 290 with validation loss 0.48278525471687317\n",
      "Starting Epoch 291\n",
      "0.523643099743387\n",
      "Starting Epoch 292\n",
      "0.5225143743597943\n",
      "Starting Epoch 293\n",
      "0.521737981101741\n",
      "New best model found at epoch 293 with validation loss 0.4827546775341034\n",
      "Starting Epoch 294\n",
      "0.521557568208031\n",
      "Starting Epoch 295\n",
      "0.5235772223576255\n",
      "Starting Epoch 296\n",
      "0.5213118856367858\n",
      "Starting Epoch 297\n",
      "0.5216422249441561\n",
      "Starting Epoch 298\n",
      "0.5212723612785339\n",
      "Starting Epoch 299\n",
      "0.5241982444472935\n",
      "Starting Epoch 300\n",
      "0.5225714937500332\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-60-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22521a0c",
   "metadata": {},
   "source": [
    "#### 4-layer MLP\n",
    "*  Loss: Cross-entropy\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0db3a",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 10 - 5 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8d4f8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "28015467-5c7a-495d-af6c-cdc18d31e3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.7395112540410913\n",
      "New best model found at epoch 1 with validation loss 0.6919909119606018\n",
      "Starting Epoch 2\n",
      "0.6939559863961261\n",
      "New best model found at epoch 2 with validation loss 0.6899633407592773\n",
      "Starting Epoch 3\n",
      "0.6905948519706726\n",
      "New best model found at epoch 3 with validation loss 0.6890098452568054\n",
      "Starting Epoch 4\n",
      "0.6898230055104131\n",
      "New best model found at epoch 4 with validation loss 0.6885190606117249\n",
      "Starting Epoch 5\n",
      "0.6894072501555734\n",
      "New best model found at epoch 5 with validation loss 0.68768709897995\n",
      "Starting Epoch 6\n",
      "0.6892524206120035\n",
      "New best model found at epoch 6 with validation loss 0.6874482035636902\n",
      "Starting Epoch 7\n",
      "0.6875144320985546\n",
      "New best model found at epoch 7 with validation loss 0.6855035424232483\n",
      "Starting Epoch 8\n",
      "0.6860357263813848\n",
      "Starting Epoch 9\n",
      "0.6826230443042257\n",
      "New best model found at epoch 9 with validation loss 0.6792924404144287\n",
      "Starting Epoch 10\n",
      "0.6764037013053894\n",
      "New best model found at epoch 10 with validation loss 0.6720842719078064\n",
      "Starting Epoch 11\n",
      "0.6844800762508226\n",
      "New best model found at epoch 11 with validation loss 0.6676979064941406\n",
      "Starting Epoch 12\n",
      "0.671590374863666\n",
      "New best model found at epoch 12 with validation loss 0.664071798324585\n",
      "Starting Epoch 13\n",
      "0.6665197973665984\n",
      "New best model found at epoch 13 with validation loss 0.657686173915863\n",
      "Starting Epoch 14\n",
      "0.6621892141259235\n",
      "New best model found at epoch 14 with validation loss 0.6513452529907227\n",
      "Starting Epoch 15\n",
      "0.6552625402160313\n",
      "Starting Epoch 16\n",
      "0.6495335646297621\n",
      "New best model found at epoch 16 with validation loss 0.651100218296051\n",
      "Starting Epoch 17\n",
      "0.6488762394241665\n",
      "New best model found at epoch 17 with validation loss 0.6461992859840393\n",
      "Starting Epoch 18\n",
      "0.645295166450998\n",
      "Starting Epoch 19\n",
      "0.6419907678728518\n",
      "New best model found at epoch 19 with validation loss 0.6458980441093445\n",
      "Starting Epoch 20\n",
      "0.6370645631914553\n",
      "Starting Epoch 21\n",
      "0.6404646816460983\n",
      "New best model found at epoch 21 with validation loss 0.6388009786605835\n",
      "Starting Epoch 22\n",
      "0.6339960176011791\n",
      "New best model found at epoch 22 with validation loss 0.6334503889083862\n",
      "Starting Epoch 23\n",
      "0.6315285459808682\n",
      "Starting Epoch 24\n",
      "0.6365006410557291\n",
      "New best model found at epoch 24 with validation loss 0.6315455436706543\n",
      "Starting Epoch 25\n",
      "0.6333853731984678\n",
      "New best model found at epoch 25 with validation loss 0.6219268441200256\n",
      "Starting Epoch 26\n",
      "0.6295424207397129\n",
      "New best model found at epoch 26 with validation loss 0.6186795830726624\n",
      "Starting Epoch 27\n",
      "0.628187718598739\n",
      "Starting Epoch 28\n",
      "0.626875322798024\n",
      "New best model found at epoch 28 with validation loss 0.6166774034500122\n",
      "Starting Epoch 29\n",
      "0.6286765958951868\n",
      "New best model found at epoch 29 with validation loss 0.6164531707763672\n",
      "Starting Epoch 30\n",
      "0.6327918456948322\n",
      "Starting Epoch 31\n",
      "0.6286262144213137\n",
      "New best model found at epoch 31 with validation loss 0.6125750541687012\n",
      "Starting Epoch 32\n",
      "0.6251128730566605\n",
      "Starting Epoch 33\n",
      "0.6204893407614335\n",
      "New best model found at epoch 33 with validation loss 0.6113688945770264\n",
      "Starting Epoch 34\n",
      "0.6214502065078072\n",
      "New best model found at epoch 34 with validation loss 0.6098887324333191\n",
      "Starting Epoch 35\n",
      "0.6213800337003625\n",
      "Starting Epoch 36\n",
      "0.6205686227135037\n",
      "Starting Epoch 37\n",
      "0.6246814753698267\n",
      "Starting Epoch 38\n",
      "0.6187263079311537\n",
      "Starting Epoch 39\n",
      "0.6199419679849044\n",
      "Starting Epoch 40\n",
      "0.6189835512119791\n",
      "New best model found at epoch 40 with validation loss 0.604328453540802\n",
      "Starting Epoch 41\n",
      "0.61867028993109\n",
      "New best model found at epoch 41 with validation loss 0.6035410165786743\n",
      "Starting Epoch 42\n",
      "0.6174266079197759\n",
      "Starting Epoch 43\n",
      "0.6149304820143658\n",
      "New best model found at epoch 43 with validation loss 0.6034696102142334\n",
      "Starting Epoch 44\n",
      "0.6139034447462662\n",
      "Starting Epoch 45\n",
      "0.6182043681973997\n",
      "Starting Epoch 46\n",
      "0.6149377382319906\n",
      "New best model found at epoch 46 with validation loss 0.6001306176185608\n",
      "Starting Epoch 47\n",
      "0.6156940926676211\n",
      "Starting Epoch 48\n",
      "0.613848890947259\n",
      "Starting Epoch 49\n",
      "0.6142026134159254\n",
      "Starting Epoch 50\n",
      "0.6150875920834749\n",
      "Starting Epoch 51\n",
      "0.6126103245693705\n",
      "Starting Epoch 52\n",
      "0.6157931529957316\n",
      "Starting Epoch 53\n",
      "0.6106827699619791\n",
      "Starting Epoch 54\n",
      "0.6108884008034415\n",
      "New best model found at epoch 54 with validation loss 0.5949463844299316\n",
      "Starting Epoch 55\n",
      "0.6082365357357523\n",
      "Starting Epoch 56\n",
      "0.6088896316030751\n",
      "Starting Epoch 57\n",
      "0.6068123760430709\n",
      "Starting Epoch 58\n",
      "0.6076690062232639\n",
      "New best model found at epoch 58 with validation loss 0.5918356776237488\n",
      "Starting Epoch 59\n",
      "0.607442223507425\n",
      "New best model found at epoch 59 with validation loss 0.5881834626197815\n",
      "Starting Epoch 60\n",
      "0.6048742921456046\n",
      "Starting Epoch 61\n",
      "0.6092628758886586\n",
      "Starting Epoch 62\n",
      "0.6047703416451163\n",
      "Starting Epoch 63\n",
      "0.603423421797545\n",
      "New best model found at epoch 63 with validation loss 0.5871696472167969\n",
      "Starting Epoch 64\n",
      "0.6007415133973827\n",
      "Starting Epoch 65\n",
      "0.6030586128649504\n",
      "Starting Epoch 66\n",
      "0.6055953969126162\n",
      "Starting Epoch 67\n",
      "0.6054913246113321\n",
      "Starting Epoch 68\n",
      "0.601454250190569\n",
      "Starting Epoch 69\n",
      "0.6054675967796989\n",
      "Starting Epoch 70\n",
      "0.6019413004750791\n",
      "New best model found at epoch 70 with validation loss 0.5858511328697205\n",
      "Starting Epoch 71\n",
      "0.6012888058372166\n",
      "Starting Epoch 72\n",
      "0.6021902794423311\n",
      "Starting Epoch 73\n",
      "0.6032316192336704\n",
      "Starting Epoch 74\n",
      "0.5996540681175564\n",
      "Starting Epoch 75\n",
      "0.6001163746999658\n",
      "Starting Epoch 76\n",
      "0.6025589678598486\n",
      "New best model found at epoch 76 with validation loss 0.5855438113212585\n",
      "Starting Epoch 77\n",
      "0.600760861583378\n",
      "New best model found at epoch 77 with validation loss 0.5855115056037903\n",
      "Starting Epoch 78\n",
      "0.6004508526428886\n",
      "New best model found at epoch 78 with validation loss 0.5809110999107361\n",
      "Starting Epoch 79\n",
      "0.5983901827231698\n",
      "Starting Epoch 80\n",
      "0.5988379094911658\n",
      "Starting Epoch 81\n",
      "0.5959946590921154\n",
      "Starting Epoch 82\n",
      "0.5958388784657354\n",
      "Starting Epoch 83\n",
      "0.5979752048202183\n",
      "Starting Epoch 84\n",
      "0.5957356846850851\n",
      "Starting Epoch 85\n",
      "0.5971906755281531\n",
      "Starting Epoch 86\n",
      "0.5973042431085006\n",
      "New best model found at epoch 86 with validation loss 0.5795851945877075\n",
      "Starting Epoch 87\n",
      "0.5964499686075293\n",
      "Starting Epoch 88\n",
      "0.5974279642105103\n",
      "Starting Epoch 89\n",
      "0.5984621073888696\n",
      "Starting Epoch 90\n",
      "0.5951986649762029\n",
      "Starting Epoch 91\n",
      "0.5925571581591731\n",
      "Starting Epoch 92\n",
      "0.5924709776173467\n",
      "Starting Epoch 93\n",
      "0.5937966911689095\n",
      "Starting Epoch 94\n",
      "0.5916041887324789\n",
      "Starting Epoch 95\n",
      "0.5950599079546721\n",
      "Starting Epoch 96\n",
      "0.59448068038277\n",
      "New best model found at epoch 96 with validation loss 0.5777544379234314\n",
      "Starting Epoch 97\n",
      "0.590836561244467\n",
      "New best model found at epoch 97 with validation loss 0.5777366161346436\n",
      "Starting Epoch 98\n",
      "0.5917566340902577\n",
      "Starting Epoch 99\n",
      "0.5910216829051143\n",
      "Starting Epoch 100\n",
      "0.5915789966997893\n",
      "Starting Epoch 101\n",
      "0.5928950206093166\n",
      "Starting Epoch 102\n",
      "0.5920175858165907\n",
      "Starting Epoch 103\n",
      "0.5916698289954144\n",
      "Starting Epoch 104\n",
      "0.590362354465153\n",
      "Starting Epoch 105\n",
      "0.5940728602202042\n",
      "Starting Epoch 106\n",
      "0.5898273172585861\n",
      "Starting Epoch 107\n",
      "0.5916523311449133\n",
      "Starting Epoch 108\n",
      "0.5926055985948314\n",
      "Starting Epoch 109\n",
      "0.5911042120145715\n",
      "Starting Epoch 110\n",
      "0.5910410751467166\n",
      "Starting Epoch 111\n",
      "0.5892986292424409\n",
      "New best model found at epoch 111 with validation loss 0.5776573419570923\n",
      "Starting Epoch 112\n",
      "0.588369141454282\n",
      "Starting Epoch 113\n",
      "0.589437730934309\n",
      "Starting Epoch 114\n",
      "0.5878150774085004\n",
      "Starting Epoch 115\n",
      "0.5906378160352292\n",
      "New best model found at epoch 115 with validation loss 0.5776215195655823\n",
      "Starting Epoch 116\n",
      "0.5863150487775388\n",
      "Starting Epoch 117\n",
      "0.5865239552829576\n",
      "New best model found at epoch 117 with validation loss 0.5751581788063049\n",
      "Starting Epoch 118\n",
      "0.5917874911557073\n",
      "Starting Epoch 119\n",
      "0.5870059961858003\n",
      "Starting Epoch 120\n",
      "0.584138362304024\n",
      "New best model found at epoch 120 with validation loss 0.5745850801467896\n",
      "Starting Epoch 121\n",
      "0.5850760548011117\n",
      "Starting Epoch 122\n",
      "0.5866738376410111\n",
      "Starting Epoch 123\n",
      "0.5872373114461484\n",
      "Starting Epoch 124\n",
      "0.5886615151944368\n",
      "Starting Epoch 125\n",
      "0.5863932345224463\n",
      "New best model found at epoch 125 with validation loss 0.5736309289932251\n",
      "Starting Epoch 126\n",
      "0.5838718906692837\n",
      "Starting Epoch 127\n",
      "0.5866701758426168\n",
      "Starting Epoch 128\n",
      "0.5857496287511743\n",
      "New best model found at epoch 128 with validation loss 0.5733339786529541\n",
      "Starting Epoch 129\n",
      "0.5857118108998174\n",
      "Starting Epoch 130\n",
      "0.5849399592565454\n",
      "Starting Epoch 131\n",
      "0.5836854810300081\n",
      "Starting Epoch 132\n",
      "0.5830399601355843\n",
      "Starting Epoch 133\n",
      "0.5860898105994515\n",
      "New best model found at epoch 133 with validation loss 0.5731155276298523\n",
      "Starting Epoch 134\n",
      "0.5853856724241505\n",
      "Starting Epoch 135\n",
      "0.5853517094384069\n",
      "New best model found at epoch 135 with validation loss 0.5728466510772705\n",
      "Starting Epoch 136\n",
      "0.5829232853391896\n",
      "New best model found at epoch 136 with validation loss 0.5712084174156189\n",
      "Starting Epoch 137\n",
      "0.583307040774304\n",
      "Starting Epoch 138\n",
      "0.5826684988063314\n",
      "Starting Epoch 139\n",
      "0.5873658372008282\n",
      "New best model found at epoch 139 with validation loss 0.5708274245262146\n",
      "Starting Epoch 140\n",
      "0.5811620769293412\n",
      "Starting Epoch 141\n",
      "0.5831169045489767\n",
      "Starting Epoch 142\n",
      "0.5828720460767332\n",
      "Starting Epoch 143\n",
      "0.5825370718603549\n",
      "Starting Epoch 144\n",
      "0.5806054032367208\n",
      "New best model found at epoch 144 with validation loss 0.5698049068450928\n",
      "Starting Epoch 145\n",
      "0.5831430580305017\n",
      "Starting Epoch 146\n",
      "0.5789760895397352\n",
      "Starting Epoch 147\n",
      "0.5824434238931407\n",
      "Starting Epoch 148\n",
      "0.5830907199693762\n",
      "Starting Epoch 149\n",
      "0.5804846494094186\n",
      "Starting Epoch 150\n",
      "0.5793320225632709\n",
      "New best model found at epoch 150 with validation loss 0.5692217350006104\n",
      "Starting Epoch 151\n",
      "0.585316292617632\n",
      "Starting Epoch 152\n",
      "0.5803318256917207\n",
      "Starting Epoch 153\n",
      "0.579806159371915\n",
      "Starting Epoch 154\n",
      "0.5804860332737798\n",
      "Starting Epoch 155\n",
      "0.5814190195954364\n",
      "Starting Epoch 156\n",
      "0.5795868453772172\n",
      "Starting Epoch 157\n",
      "0.5817969519159069\n",
      "Starting Epoch 158\n",
      "0.578794469004092\n",
      "Starting Epoch 159\n",
      "0.5792172965796097\n",
      "Starting Epoch 160\n",
      "0.5784368774165278\n",
      "Starting Epoch 161\n",
      "0.5782446265220642\n",
      "Starting Epoch 162\n",
      "0.5797191339990367\n",
      "Starting Epoch 163\n",
      "0.5788132911143096\n",
      "Starting Epoch 164\n",
      "0.5785087632096332\n",
      "New best model found at epoch 164 with validation loss 0.5685259699821472\n",
      "Starting Epoch 165\n",
      "0.5795447670895121\n",
      "Starting Epoch 166\n",
      "0.5824213831321053\n",
      "Starting Epoch 167\n",
      "0.579347911088363\n",
      "Starting Epoch 168\n",
      "0.5772434356419937\n",
      "Starting Epoch 169\n",
      "0.5801961110985797\n",
      "Starting Epoch 170\n",
      "0.5767477698948072\n",
      "Starting Epoch 171\n",
      "0.5820074314656465\n",
      "New best model found at epoch 171 with validation loss 0.5675757527351379\n",
      "Starting Epoch 172\n",
      "0.579386742218681\n",
      "Starting Epoch 173\n",
      "0.5781320670376653\n",
      "Starting Epoch 174\n",
      "0.5769987624624501\n",
      "Starting Epoch 175\n",
      "0.5782908745433973\n",
      "Starting Epoch 176\n",
      "0.5774700071500696\n",
      "Starting Epoch 177\n",
      "0.5760629928630331\n",
      "Starting Epoch 178\n",
      "0.5771223177080569\n",
      "Starting Epoch 179\n",
      "0.5778357062650763\n",
      "Starting Epoch 180\n",
      "0.5772435820620992\n",
      "Starting Epoch 181\n",
      "0.5754123511521713\n",
      "Starting Epoch 182\n",
      "0.5781036744947019\n",
      "Starting Epoch 183\n",
      "0.5765662607939347\n",
      "Starting Epoch 184\n",
      "0.5754343323085619\n",
      "Starting Epoch 185\n",
      "0.5745316588360331\n",
      "Starting Epoch 186\n",
      "0.5774068884227587\n",
      "Starting Epoch 187\n",
      "0.5745796198430269\n",
      "Starting Epoch 188\n",
      "0.5772146660348644\n",
      "Starting Epoch 189\n",
      "0.5766386882118557\n",
      "New best model found at epoch 189 with validation loss 0.5669400691986084\n",
      "Starting Epoch 190\n",
      "0.5749948646711267\n",
      "Starting Epoch 191\n",
      "0.5770089056180872\n",
      "Starting Epoch 192\n",
      "0.5769332673238672\n",
      "Starting Epoch 193\n",
      "0.5764604003533073\n",
      "Starting Epoch 194\n",
      "0.5767480627350186\n",
      "New best model found at epoch 194 with validation loss 0.5656694173812866\n",
      "Starting Epoch 195\n",
      "0.5766149163246155\n",
      "Starting Epoch 196\n",
      "0.5756436430889628\n",
      "Starting Epoch 197\n",
      "0.5771787011105082\n",
      "Starting Epoch 198\n",
      "0.5764255394106326\n",
      "Starting Epoch 199\n",
      "0.5743399469748788\n",
      "Starting Epoch 200\n",
      "0.5754408914109935\n",
      "Starting Epoch 201\n",
      "0.5745180689770243\n",
      "Starting Epoch 202\n",
      "0.5739211699236995\n",
      "Starting Epoch 203\n",
      "0.5779665760371996\n",
      "Starting Epoch 204\n",
      "0.5744529807049296\n",
      "Starting Epoch 205\n",
      "0.5745851138363713\n",
      "Starting Epoch 206\n",
      "0.5743246959603351\n",
      "Starting Epoch 207\n",
      "0.5753007582996202\n",
      "Starting Epoch 208\n",
      "0.5740288288696952\n",
      "Starting Epoch 209\n",
      "0.5734447292659594\n",
      "Starting Epoch 210\n",
      "0.5769718496695809\n",
      "Starting Epoch 211\n",
      "0.5740212227987207\n",
      "Starting Epoch 212\n",
      "0.5780456014301466\n",
      "Starting Epoch 213\n",
      "0.5744281748066777\n",
      "Starting Epoch 214\n",
      "0.5764161179894987\n",
      "Starting Epoch 215\n",
      "0.5747868548268857\n",
      "New best model found at epoch 215 with validation loss 0.5649963617324829\n",
      "Starting Epoch 216\n",
      "0.5747822484244471\n",
      "Starting Epoch 217\n",
      "0.5737618803977966\n",
      "Starting Epoch 218\n",
      "0.5741835573445195\n",
      "Starting Epoch 219\n",
      "0.5728131623371787\n",
      "Starting Epoch 220\n",
      "0.5750669033631034\n",
      "Starting Epoch 221\n",
      "0.5730510924173438\n",
      "Starting Epoch 222\n",
      "0.5730762689009957\n",
      "Starting Epoch 223\n",
      "0.5739361980687017\n",
      "Starting Epoch 224\n",
      "0.5723339163738749\n",
      "Starting Epoch 225\n",
      "0.5738786070243173\n",
      "Starting Epoch 226\n",
      "0.573821238849474\n",
      "Starting Epoch 227\n",
      "0.5743361504181571\n",
      "Starting Epoch 228\n",
      "0.5736364722251892\n",
      "Starting Epoch 229\n",
      "0.57203557698623\n",
      "Starting Epoch 230\n",
      "0.5724080956500509\n",
      "Starting Epoch 231\n",
      "0.5754334045493085\n",
      "Starting Epoch 232\n",
      "0.5736030158789261\n",
      "Starting Epoch 233\n",
      "0.5717146526212278\n",
      "Starting Epoch 234\n",
      "0.5730763803357664\n",
      "Starting Epoch 235\n",
      "0.5727876696897589\n",
      "Starting Epoch 236\n",
      "0.5753864607085353\n",
      "Starting Epoch 237\n",
      "0.5737604187882465\n",
      "Starting Epoch 238\n",
      "0.5719247123469478\n",
      "Starting Epoch 239\n",
      "0.5728982168695201\n",
      "Starting Epoch 240\n",
      "0.5732959508895874\n",
      "Starting Epoch 241\n",
      "0.5732578246489816\n",
      "New best model found at epoch 241 with validation loss 0.5642483830451965\n",
      "Starting Epoch 242\n",
      "0.5746993292932925\n",
      "Starting Epoch 243\n",
      "0.5725422294243522\n",
      "Starting Epoch 244\n",
      "0.5745247757953146\n",
      "Starting Epoch 245\n",
      "0.5732543701710908\n",
      "Starting Epoch 246\n",
      "0.574272887862247\n",
      "Starting Epoch 247\n",
      "0.5718298826528632\n",
      "Starting Epoch 248\n",
      "0.5729857113050378\n",
      "Starting Epoch 249\n",
      "0.5747356285219607\n",
      "Starting Epoch 250\n",
      "0.5730199191881262\n",
      "Starting Epoch 251\n",
      "0.5750667686047761\n",
      "Starting Epoch 252\n",
      "0.5729782322178716\n",
      "Starting Epoch 253\n",
      "0.5719293485517087\n",
      "Starting Epoch 254\n",
      "0.5724471042985502\n",
      "Starting Epoch 255\n",
      "0.5757567053255828\n",
      "Starting Epoch 256\n",
      "0.5733630890431611\n",
      "Starting Epoch 257\n",
      "0.5729589980581532\n",
      "Starting Epoch 258\n",
      "0.5719747297141863\n",
      "Starting Epoch 259\n",
      "0.5749164716057156\n",
      "Starting Epoch 260\n",
      "0.5736999926359757\n",
      "Starting Epoch 261\n",
      "0.5711884446766066\n",
      "Starting Epoch 262\n",
      "0.5727504984192227\n",
      "Starting Epoch 263\n",
      "0.5723853759143663\n",
      "Starting Epoch 264\n",
      "0.5876716634501582\n",
      "Starting Epoch 265\n",
      "0.572986188142196\n",
      "Starting Epoch 266\n",
      "0.573008884554324\n",
      "Starting Epoch 267\n",
      "0.5709860013878864\n",
      "Starting Epoch 268\n",
      "0.5742327881895978\n",
      "Starting Epoch 269\n",
      "0.5713192250417627\n",
      "Starting Epoch 270\n",
      "0.5722729382307633\n",
      "Starting Epoch 271\n",
      "0.5718582376189854\n",
      "New best model found at epoch 271 with validation loss 0.5633298754692078\n",
      "Starting Epoch 272\n",
      "0.5721081028813901\n",
      "Starting Epoch 273\n",
      "0.5729049340538357\n",
      "Starting Epoch 274\n",
      "0.5713442019794298\n",
      "Starting Epoch 275\n",
      "0.5716953899549402\n",
      "Starting Epoch 276\n",
      "0.57254308073417\n",
      "Starting Epoch 277\n",
      "0.5716408517049707\n",
      "Starting Epoch 278\n",
      "0.5735087187393851\n",
      "Starting Epoch 279\n",
      "0.5716265232666679\n",
      "Starting Epoch 280\n",
      "0.5715776137683702\n",
      "Starting Epoch 281\n",
      "0.5716710479363151\n",
      "Starting Epoch 282\n",
      "0.5704779288043147\n",
      "Starting Epoch 283\n",
      "0.5717139658720597\n",
      "Starting Epoch 284\n",
      "0.571372187655905\n",
      "Starting Epoch 285\n",
      "0.5736151752264603\n",
      "Starting Epoch 286\n",
      "0.5714012928630995\n",
      "Starting Epoch 287\n",
      "0.5728850390600122\n",
      "Starting Epoch 288\n",
      "0.5720534959565038\n",
      "Starting Epoch 289\n",
      "0.5726365978303163\n",
      "Starting Epoch 290\n",
      "0.5713938733805781\n",
      "Starting Epoch 291\n",
      "0.5703396771265112\n",
      "Starting Epoch 292\n",
      "0.5708774820618008\n",
      "Starting Epoch 293\n",
      "0.5711985282275988\n",
      "Starting Epoch 294\n",
      "0.5690266697303109\n",
      "Starting Epoch 295\n",
      "0.5713006283925928\n",
      "Starting Epoch 296\n",
      "0.5705752269081448\n",
      "Starting Epoch 297\n",
      "0.5712315595668295\n",
      "Starting Epoch 298\n",
      "0.5719440268433612\n",
      "Starting Epoch 299\n",
      "0.5713693732800691\n",
      "Starting Epoch 300\n",
      "0.5702666420003643\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-10-5-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ebe52e",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 20 - 10 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "da03fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "fbf53daa-38f2-4741-8496-30425a43ef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.027826938940131\n",
      "New best model found at epoch 1 with validation loss 0.6828819513320923\n",
      "Starting Epoch 2\n",
      "0.6827207363170126\n",
      "New best model found at epoch 2 with validation loss 0.6809898018836975\n",
      "Starting Epoch 3\n",
      "0.6799971850022025\n",
      "New best model found at epoch 3 with validation loss 0.6807399392127991\n",
      "Starting Epoch 4\n",
      "0.6768741840901582\n",
      "New best model found at epoch 4 with validation loss 0.6759650111198425\n",
      "Starting Epoch 5\n",
      "0.672912201155787\n",
      "New best model found at epoch 5 with validation loss 0.6695201396942139\n",
      "Starting Epoch 6\n",
      "0.6664225381353627\n",
      "New best model found at epoch 6 with validation loss 0.6623732447624207\n",
      "Starting Epoch 7\n",
      "0.6559122463931208\n",
      "New best model found at epoch 7 with validation loss 0.6581753492355347\n",
      "Starting Epoch 8\n",
      "0.647746653660484\n",
      "New best model found at epoch 8 with validation loss 0.6415077447891235\n",
      "Starting Epoch 9\n",
      "0.6349070072174072\n",
      "Starting Epoch 10\n",
      "0.6259774643441905\n",
      "New best model found at epoch 10 with validation loss 0.6238752007484436\n",
      "Starting Epoch 11\n",
      "0.6146788363871367\n",
      "New best model found at epoch 11 with validation loss 0.6137962341308594\n",
      "Starting Epoch 12\n",
      "0.612672753956007\n",
      "New best model found at epoch 12 with validation loss 0.6011172533035278\n",
      "Starting Epoch 13\n",
      "0.6036579401596732\n",
      "Starting Epoch 14\n",
      "0.600362909876782\n",
      "New best model found at epoch 14 with validation loss 0.5966138243675232\n",
      "Starting Epoch 15\n",
      "0.600921120332635\n",
      "New best model found at epoch 15 with validation loss 0.5945869088172913\n",
      "Starting Epoch 16\n",
      "0.5963027062623397\n",
      "Starting Epoch 17\n",
      "0.5920144189958987\n",
      "Starting Epoch 18\n",
      "0.5894367863302645\n",
      "New best model found at epoch 18 with validation loss 0.5876771807670593\n",
      "Starting Epoch 19\n",
      "0.5817669034004211\n",
      "New best model found at epoch 19 with validation loss 0.5861988067626953\n",
      "Starting Epoch 20\n",
      "0.5863826456277267\n",
      "Starting Epoch 21\n",
      "0.5775413435438405\n",
      "New best model found at epoch 21 with validation loss 0.5847597718238831\n",
      "Starting Epoch 22\n",
      "0.5777922635493071\n",
      "New best model found at epoch 22 with validation loss 0.5770652294158936\n",
      "Starting Epoch 23\n",
      "0.5801479453625886\n",
      "Starting Epoch 24\n",
      "0.5750810141148774\n",
      "Starting Epoch 25\n",
      "0.5772222047266753\n",
      "Starting Epoch 26\n",
      "0.573119554830634\n",
      "New best model found at epoch 26 with validation loss 0.5736463069915771\n",
      "Starting Epoch 27\n",
      "0.5760604272718015\n",
      "Starting Epoch 28\n",
      "0.5733400933120562\n",
      "Starting Epoch 29\n",
      "0.5730421413546023\n",
      "New best model found at epoch 29 with validation loss 0.5709754824638367\n",
      "Starting Epoch 30\n",
      "0.5727231580278148\n",
      "New best model found at epoch 30 with validation loss 0.5703712701797485\n",
      "Starting Epoch 31\n",
      "0.5677500846593276\n",
      "Starting Epoch 32\n",
      "0.5695091874703117\n",
      "Starting Epoch 33\n",
      "0.5675009566804637\n",
      "Starting Epoch 34\n",
      "0.5676139035950536\n",
      "New best model found at epoch 34 with validation loss 0.5677511692047119\n",
      "Starting Epoch 35\n",
      "0.5653687832148179\n",
      "Starting Epoch 36\n",
      "0.5680663935516191\n",
      "Starting Epoch 37\n",
      "0.5655357539653778\n",
      "Starting Epoch 38\n",
      "0.564025096271349\n",
      "New best model found at epoch 38 with validation loss 0.5634579062461853\n",
      "Starting Epoch 39\n",
      "0.5679801935734956\n",
      "New best model found at epoch 39 with validation loss 0.5603541135787964\n",
      "Starting Epoch 40\n",
      "0.5620249069255331\n",
      "Starting Epoch 41\n",
      "0.5655345411404319\n",
      "Starting Epoch 42\n",
      "0.5637057151483453\n",
      "Starting Epoch 43\n",
      "0.5601745260798413\n",
      "Starting Epoch 44\n",
      "0.5632336606150088\n",
      "Starting Epoch 45\n",
      "0.560046655976254\n",
      "Starting Epoch 46\n",
      "0.557907012493714\n",
      "Starting Epoch 47\n",
      "0.5602480173110962\n",
      "Starting Epoch 48\n",
      "0.5575458109378815\n",
      "Starting Epoch 49\n",
      "0.5597136577834254\n",
      "Starting Epoch 50\n",
      "0.5595715253249459\n",
      "Starting Epoch 51\n",
      "0.5589257906312528\n",
      "New best model found at epoch 51 with validation loss 0.5535234212875366\n",
      "Starting Epoch 52\n",
      "0.5558172723521357\n",
      "Starting Epoch 53\n",
      "0.556806541007498\n",
      "Starting Epoch 54\n",
      "0.555369048014931\n",
      "Starting Epoch 55\n",
      "0.5577956710172736\n",
      "New best model found at epoch 55 with validation loss 0.5507815480232239\n",
      "Starting Epoch 56\n",
      "0.5543739160765773\n",
      "New best model found at epoch 56 with validation loss 0.5507805347442627\n",
      "Starting Epoch 57\n",
      "0.5572532609752987\n",
      "Starting Epoch 58\n",
      "0.5545186581818954\n",
      "Starting Epoch 59\n",
      "0.5557094229304272\n",
      "New best model found at epoch 59 with validation loss 0.5502723455429077\n",
      "Starting Epoch 60\n",
      "0.5556486857974011\n",
      "Starting Epoch 61\n",
      "0.5547518730163574\n",
      "Starting Epoch 62\n",
      "0.5542106770950815\n",
      "Starting Epoch 63\n",
      "0.5507652591104093\n",
      "Starting Epoch 64\n",
      "0.5519033942533575\n",
      "New best model found at epoch 64 with validation loss 0.549789309501648\n",
      "Starting Epoch 65\n",
      "0.5523153465727101\n",
      "New best model found at epoch 65 with validation loss 0.5439750552177429\n",
      "Starting Epoch 66\n",
      "0.5523671326429948\n",
      "Starting Epoch 67\n",
      "0.5506993091624716\n",
      "Starting Epoch 68\n",
      "0.5513879643834155\n",
      "Starting Epoch 69\n",
      "0.5514657691768978\n",
      "Starting Epoch 70\n",
      "0.5543057257714479\n",
      "Starting Epoch 71\n",
      "0.5482453509517338\n",
      "Starting Epoch 72\n",
      "0.5513227452402529\n",
      "Starting Epoch 73\n",
      "0.5500195039355237\n",
      "Starting Epoch 74\n",
      "0.5497199996657993\n",
      "New best model found at epoch 74 with validation loss 0.5436676740646362\n",
      "Starting Epoch 75\n",
      "0.5508773002935492\n",
      "Starting Epoch 76\n",
      "0.5488480821899746\n",
      "Starting Epoch 77\n",
      "0.5486921084963757\n",
      "Starting Epoch 78\n",
      "0.5495867742144543\n",
      "Starting Epoch 79\n",
      "0.5515418350696564\n",
      "Starting Epoch 80\n",
      "0.5504134167795596\n",
      "New best model found at epoch 80 with validation loss 0.5414780378341675\n",
      "Starting Epoch 81\n",
      "0.5486050805319911\n",
      "New best model found at epoch 81 with validation loss 0.539929986000061\n",
      "Starting Epoch 82\n",
      "0.547844242790471\n",
      "Starting Epoch 83\n",
      "0.5474025218383126\n",
      "New best model found at epoch 83 with validation loss 0.5396490097045898\n",
      "Starting Epoch 84\n",
      "0.548342808433201\n",
      "Starting Epoch 85\n",
      "0.548211465711179\n",
      "Starting Epoch 86\n",
      "0.5473753848801488\n",
      "Starting Epoch 87\n",
      "0.5455688976723215\n",
      "Starting Epoch 88\n",
      "0.5473213947337606\n",
      "Starting Epoch 89\n",
      "0.5481001138687134\n",
      "Starting Epoch 90\n",
      "0.5481138449648152\n",
      "Starting Epoch 91\n",
      "0.5465811154116755\n",
      "Starting Epoch 92\n",
      "0.5475349724292755\n",
      "Starting Epoch 93\n",
      "0.5472927223081174\n",
      "Starting Epoch 94\n",
      "0.5473349301711373\n",
      "Starting Epoch 95\n",
      "0.5458663170752318\n",
      "New best model found at epoch 95 with validation loss 0.5366671681404114\n",
      "Starting Epoch 96\n",
      "0.5456241641355597\n",
      "Starting Epoch 97\n",
      "0.5466185510158539\n",
      "Starting Epoch 98\n",
      "0.5491949941800989\n",
      "New best model found at epoch 98 with validation loss 0.5359824895858765\n",
      "Starting Epoch 99\n",
      "0.5471028154310973\n",
      "Starting Epoch 100\n",
      "0.5480102145153544\n",
      "Starting Epoch 101\n",
      "0.5457537498163141\n",
      "Starting Epoch 102\n",
      "0.5444245040416718\n",
      "New best model found at epoch 102 with validation loss 0.5359591841697693\n",
      "Starting Epoch 103\n",
      "0.5427576679250469\n",
      "New best model found at epoch 103 with validation loss 0.533839762210846\n",
      "Starting Epoch 104\n",
      "0.5448182069736979\n",
      "Starting Epoch 105\n",
      "0.548357931168183\n",
      "Starting Epoch 106\n",
      "0.5455605387687683\n",
      "Starting Epoch 107\n",
      "0.5456873139609462\n",
      "Starting Epoch 108\n",
      "0.5453148536060167\n",
      "Starting Epoch 109\n",
      "0.5466555033041083\n",
      "Starting Epoch 110\n",
      "0.5454010445138683\n",
      "Starting Epoch 111\n",
      "0.5464992911919303\n",
      "Starting Epoch 112\n",
      "0.5455650518769803\n",
      "Starting Epoch 113\n",
      "0.5435679049595542\n",
      "Starting Epoch 114\n",
      "0.5472302786681963\n",
      "Starting Epoch 115\n",
      "0.5428807774315709\n",
      "Starting Epoch 116\n",
      "0.5446664392948151\n",
      "Starting Epoch 117\n",
      "0.5437676958415819\n",
      "Starting Epoch 118\n",
      "0.5446989588115526\n",
      "Starting Epoch 119\n",
      "0.5468333933664404\n",
      "Starting Epoch 120\n",
      "0.5441863523877185\n",
      "Starting Epoch 121\n",
      "0.5436641560948413\n",
      "New best model found at epoch 121 with validation loss 0.5332963466644287\n",
      "Starting Epoch 122\n",
      "0.5444937633431476\n",
      "Starting Epoch 123\n",
      "0.5457410099713699\n",
      "Starting Epoch 124\n",
      "0.5422996282577515\n",
      "Starting Epoch 125\n",
      "0.5428312343099843\n",
      "Starting Epoch 126\n",
      "0.54318407955377\n",
      "Starting Epoch 127\n",
      "0.5453099128992661\n",
      "Starting Epoch 128\n",
      "0.5442837360112563\n",
      "Starting Epoch 129\n",
      "0.5446630470130754\n",
      "Starting Epoch 130\n",
      "0.5461432700571807\n",
      "Starting Epoch 131\n",
      "0.5419417075488878\n",
      "Starting Epoch 132\n",
      "0.5434041671130968\n",
      "New best model found at epoch 132 with validation loss 0.5329450368881226\n",
      "Starting Epoch 133\n",
      "0.5410590275474216\n",
      "Starting Epoch 134\n",
      "0.5418694382128508\n",
      "Starting Epoch 135\n",
      "0.5409044467884562\n",
      "New best model found at epoch 135 with validation loss 0.5321344137191772\n",
      "Starting Epoch 136\n",
      "0.5416144314019576\n",
      "New best model found at epoch 136 with validation loss 0.5318096280097961\n",
      "Starting Epoch 137\n",
      "0.5421479486900828\n",
      "Starting Epoch 138\n",
      "0.542313391747682\n",
      "Starting Epoch 139\n",
      "0.5432278630526169\n",
      "Starting Epoch 140\n",
      "0.54307178310726\n",
      "Starting Epoch 141\n",
      "0.5412548676781033\n",
      "Starting Epoch 142\n",
      "0.5417029637357463\n",
      "Starting Epoch 143\n",
      "0.5433581717636274\n",
      "Starting Epoch 144\n",
      "0.5415439281774603\n",
      "Starting Epoch 145\n",
      "0.5400506452373837\n",
      "New best model found at epoch 145 with validation loss 0.5309402942657471\n",
      "Starting Epoch 146\n",
      "0.5410840161468672\n",
      "Starting Epoch 147\n",
      "0.54050117990245\n",
      "Starting Epoch 148\n",
      "0.5411780048971591\n",
      "Starting Epoch 149\n",
      "0.5401037594546443\n",
      "Starting Epoch 150\n",
      "0.541391512622004\n",
      "Starting Epoch 151\n",
      "0.5409215636875319\n",
      "Starting Epoch 152\n",
      "0.5412112642889437\n",
      "Starting Epoch 153\n",
      "0.5403764144234036\n",
      "Starting Epoch 154\n",
      "0.5408102934775145\n",
      "Starting Epoch 155\n",
      "0.540033704560736\n",
      "Starting Epoch 156\n",
      "0.5399836781232253\n",
      "Starting Epoch 157\n",
      "0.5411775941434114\n",
      "Starting Epoch 158\n",
      "0.5394507270792256\n",
      "New best model found at epoch 158 with validation loss 0.5295940637588501\n",
      "Starting Epoch 159\n",
      "0.5404033531313357\n",
      "Starting Epoch 160\n",
      "0.5392597395440807\n",
      "New best model found at epoch 160 with validation loss 0.5279458165168762\n",
      "Starting Epoch 161\n",
      "0.5408234103866245\n",
      "Starting Epoch 162\n",
      "0.5410876351854076\n",
      "Starting Epoch 163\n",
      "0.5408187132814656\n",
      "Starting Epoch 164\n",
      "0.5387754751288373\n",
      "Starting Epoch 165\n",
      "0.5427564227062723\n",
      "Starting Epoch 166\n",
      "0.5398251440214075\n",
      "Starting Epoch 167\n",
      "0.5387553779975228\n",
      "Starting Epoch 168\n",
      "0.5415288663428762\n",
      "Starting Epoch 169\n",
      "0.5383012566877448\n",
      "Starting Epoch 170\n",
      "0.5392478237981382\n",
      "Starting Epoch 171\n",
      "0.5431280693282252\n",
      "Starting Epoch 172\n",
      "0.5379972626333651\n",
      "New best model found at epoch 172 with validation loss 0.527493417263031\n",
      "Starting Epoch 173\n",
      "0.5398436473763507\n",
      "Starting Epoch 174\n",
      "0.5398053008577098\n",
      "Starting Epoch 175\n",
      "0.5397309725699218\n",
      "Starting Epoch 176\n",
      "0.5383726021517878\n",
      "Starting Epoch 177\n",
      "0.5393070228721785\n",
      "Starting Epoch 178\n",
      "0.537328330071076\n",
      "Starting Epoch 179\n",
      "0.5388887019261069\n",
      "New best model found at epoch 179 with validation loss 0.5271300673484802\n",
      "Starting Epoch 180\n",
      "0.5368286461933799\n",
      "Starting Epoch 181\n",
      "0.5380089671715446\n",
      "Starting Epoch 182\n",
      "0.5381968073222948\n",
      "Starting Epoch 183\n",
      "0.5395263018815414\n",
      "Starting Epoch 184\n",
      "0.5397854693557905\n",
      "Starting Epoch 185\n",
      "0.5374756481336511\n",
      "Starting Epoch 186\n",
      "0.5381567050581393\n",
      "Starting Epoch 187\n",
      "0.5373525671336962\n",
      "New best model found at epoch 187 with validation loss 0.5271067023277283\n",
      "Starting Epoch 188\n",
      "0.5397572854290837\n",
      "Starting Epoch 189\n",
      "0.5373251308565554\n",
      "Starting Epoch 190\n",
      "0.5364663069662841\n",
      "Starting Epoch 191\n",
      "0.5393511549286221\n",
      "New best model found at epoch 191 with validation loss 0.5260978937149048\n",
      "Starting Epoch 192\n",
      "0.5379565863505654\n",
      "Starting Epoch 193\n",
      "0.5384424458379331\n",
      "Starting Epoch 194\n",
      "0.5399009961148967\n",
      "Starting Epoch 195\n",
      "0.5376637111539426\n",
      "Starting Epoch 196\n",
      "0.5358867956244427\n",
      "Starting Epoch 197\n",
      "0.5387164807837942\n",
      "Starting Epoch 198\n",
      "0.5379106583802596\n",
      "New best model found at epoch 198 with validation loss 0.5240055322647095\n",
      "Starting Epoch 199\n",
      "0.5378933769205342\n",
      "Starting Epoch 200\n",
      "0.5384422942348148\n",
      "Starting Epoch 201\n",
      "0.5365721725899241\n",
      "Starting Epoch 202\n",
      "0.5374193411806355\n",
      "Starting Epoch 203\n",
      "0.5365903688513715\n",
      "Starting Epoch 204\n",
      "0.5375682063724684\n",
      "Starting Epoch 205\n",
      "0.5361607243185458\n",
      "Starting Epoch 206\n",
      "0.5362845127997191\n",
      "New best model found at epoch 206 with validation loss 0.5239202976226807\n",
      "Starting Epoch 207\n",
      "0.5389084194017493\n",
      "Starting Epoch 208\n",
      "0.5376937013605366\n",
      "Starting Epoch 209\n",
      "0.5359380050845768\n",
      "Starting Epoch 210\n",
      "0.5373995031999506\n",
      "Starting Epoch 211\n",
      "0.5365949091703995\n",
      "Starting Epoch 212\n",
      "0.5364939337191375\n",
      "Starting Epoch 213\n",
      "0.5377310734728108\n",
      "Starting Epoch 214\n",
      "0.5369928194128949\n",
      "Starting Epoch 215\n",
      "0.5373477845088296\n",
      "Starting Epoch 216\n",
      "0.5367396784865338\n",
      "Starting Epoch 217\n",
      "0.5371454539506332\n",
      "Starting Epoch 218\n",
      "0.5393010235351064\n",
      "Starting Epoch 219\n",
      "0.5369700582131095\n",
      "Starting Epoch 220\n",
      "0.53602116652157\n",
      "Starting Epoch 221\n",
      "0.5367313325405121\n",
      "Starting Epoch 222\n",
      "0.5370981576650039\n",
      "Starting Epoch 223\n",
      "0.5377132594585419\n",
      "Starting Epoch 224\n",
      "0.5361575043719747\n",
      "Starting Epoch 225\n",
      "0.5357127137806105\n",
      "Starting Epoch 226\n",
      "0.5364059235738672\n",
      "Starting Epoch 227\n",
      "0.5395180349764617\n",
      "Starting Epoch 228\n",
      "0.5362553855647212\n",
      "Starting Epoch 229\n",
      "0.5362951768481213\n",
      "New best model found at epoch 229 with validation loss 0.5235314965248108\n",
      "Starting Epoch 230\n",
      "0.5355522541896157\n",
      "Starting Epoch 231\n",
      "0.5360934928707455\n",
      "Starting Epoch 232\n",
      "0.5343122443427211\n",
      "Starting Epoch 233\n",
      "0.5368407614853071\n",
      "Starting Epoch 234\n",
      "0.5361008423825969\n",
      "Starting Epoch 235\n",
      "0.5358744613502336\n",
      "Starting Epoch 236\n",
      "0.5375814658144246\n",
      "New best model found at epoch 236 with validation loss 0.522783637046814\n",
      "Starting Epoch 237\n",
      "0.5363172227921693\n",
      "Starting Epoch 238\n",
      "0.5343449685884558\n",
      "New best model found at epoch 238 with validation loss 0.5225200653076172\n",
      "Starting Epoch 239\n",
      "0.5361755360727725\n",
      "Starting Epoch 240\n",
      "0.5358993799790092\n",
      "Starting Epoch 241\n",
      "0.535619142262832\n",
      "Starting Epoch 242\n",
      "0.5350754014823748\n",
      "Starting Epoch 243\n",
      "0.5367341002692347\n",
      "Starting Epoch 244\n",
      "0.5356632419254469\n",
      "Starting Epoch 245\n",
      "0.5366907961990522\n",
      "Starting Epoch 246\n",
      "0.5358780946420587\n",
      "Starting Epoch 247\n",
      "0.5353602974311166\n",
      "Starting Epoch 248\n",
      "0.5338102138560751\n",
      "Starting Epoch 249\n",
      "0.5358406745869181\n",
      "Starting Epoch 250\n",
      "0.535141303487446\n",
      "Starting Epoch 251\n",
      "0.5350589907687643\n",
      "Starting Epoch 252\n",
      "0.5380146425703297\n",
      "Starting Epoch 253\n",
      "0.534856202809707\n",
      "Starting Epoch 254\n",
      "0.5358425599077473\n",
      "Starting Epoch 255\n",
      "0.5342351612837418\n",
      "Starting Epoch 256\n",
      "0.5352345303348873\n",
      "Starting Epoch 257\n",
      "0.53465201932451\n",
      "Starting Epoch 258\n",
      "0.5349331653636434\n",
      "Starting Epoch 259\n",
      "0.5351573526859283\n",
      "New best model found at epoch 259 with validation loss 0.5211212635040283\n",
      "Starting Epoch 260\n",
      "0.5348327133966528\n",
      "Starting Epoch 261\n",
      "0.5354698987110801\n",
      "Starting Epoch 262\n",
      "0.5360157541606737\n",
      "Starting Epoch 263\n",
      "0.5363712284875952\n",
      "Starting Epoch 264\n",
      "0.5352436809436135\n",
      "Starting Epoch 265\n",
      "0.53440414045168\n",
      "Starting Epoch 266\n",
      "0.5335054242092631\n",
      "Starting Epoch 267\n",
      "0.5335980692635411\n",
      "Starting Epoch 268\n",
      "0.5330223544784214\n",
      "Starting Epoch 269\n",
      "0.536513872768568\n",
      "Starting Epoch 270\n",
      "0.532954136962476\n",
      "Starting Epoch 271\n",
      "0.536245505446973\n",
      "Starting Epoch 272\n",
      "0.5337767134542051\n",
      "Starting Epoch 273\n",
      "0.5346079170703888\n",
      "Starting Epoch 274\n",
      "0.5343799254168635\n",
      "New best model found at epoch 274 with validation loss 0.5202370285987854\n",
      "Starting Epoch 275\n",
      "0.5333932366060175\n",
      "Starting Epoch 276\n",
      "0.5331938992375913\n",
      "Starting Epoch 277\n",
      "0.5348218070424121\n",
      "Starting Epoch 278\n",
      "0.5333109977452651\n",
      "Starting Epoch 279\n",
      "0.5340185994687288\n",
      "Starting Epoch 280\n",
      "0.5351771854836008\n",
      "Starting Epoch 281\n",
      "0.5345880998217541\n",
      "Starting Epoch 282\n",
      "0.5336914088415063\n",
      "Starting Epoch 283\n",
      "0.533316389374111\n",
      "Starting Epoch 284\n",
      "0.5331549566725026\n",
      "Starting Epoch 285\n",
      "0.5338120343892471\n",
      "Starting Epoch 286\n",
      "0.5338286472403485\n",
      "Starting Epoch 287\n",
      "0.5327839177587758\n",
      "Starting Epoch 288\n",
      "0.5326819108880084\n",
      "Starting Epoch 289\n",
      "0.5340648254622584\n",
      "Starting Epoch 290\n",
      "0.5327830068443132\n",
      "New best model found at epoch 290 with validation loss 0.5197736024856567\n",
      "Starting Epoch 291\n",
      "0.5333943833475527\n",
      "Starting Epoch 292\n",
      "0.5340613165627355\n",
      "Starting Epoch 293\n",
      "0.5347109100093013\n",
      "Starting Epoch 294\n",
      "0.5326400658358699\n",
      "Starting Epoch 295\n",
      "0.533221352359523\n",
      "Starting Epoch 296\n",
      "0.5341731996639915\n",
      "Starting Epoch 297\n",
      "0.5325344438138215\n",
      "Starting Epoch 298\n",
      "0.5332630561745685\n",
      "Starting Epoch 299\n",
      "0.5332982462385426\n",
      "Starting Epoch 300\n",
      "0.5327848584755607\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-20-10-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a290800",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 3\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 20 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "76869e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fca0f798-2d8e-4036-ac9c-f5ce03a02a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.0562448268351348\n",
      "New best model found at epoch 1 with validation loss 0.6766653656959534\n",
      "Starting Epoch 2\n",
      "0.6664834825888925\n",
      "New best model found at epoch 2 with validation loss 0.6562923789024353\n",
      "Starting Epoch 3\n",
      "0.6484429706697878\n",
      "New best model found at epoch 3 with validation loss 0.6407659649848938\n",
      "Starting Epoch 4\n",
      "0.6342703259509542\n",
      "New best model found at epoch 4 with validation loss 0.6212389469146729\n",
      "Starting Epoch 5\n",
      "0.6222171291061069\n",
      "New best model found at epoch 5 with validation loss 0.6208279132843018\n",
      "Starting Epoch 6\n",
      "0.6198395879372306\n",
      "New best model found at epoch 6 with validation loss 0.6079207062721252\n",
      "Starting Epoch 7\n",
      "0.6026260049446769\n",
      "New best model found at epoch 7 with validation loss 0.5977591872215271\n",
      "Starting Epoch 8\n",
      "0.5984781980514526\n",
      "New best model found at epoch 8 with validation loss 0.5939120054244995\n",
      "Starting Epoch 9\n",
      "0.5930955487748851\n",
      "Starting Epoch 10\n",
      "0.5892110363296841\n",
      "New best model found at epoch 10 with validation loss 0.5781546831130981\n",
      "Starting Epoch 11\n",
      "0.5970328579778257\n",
      "Starting Epoch 12\n",
      "0.5748897946399191\n",
      "Starting Epoch 13\n",
      "0.5726382032684658\n",
      "Starting Epoch 14\n",
      "0.5776626415874647\n",
      "New best model found at epoch 14 with validation loss 0.569640576839447\n",
      "Starting Epoch 15\n",
      "0.5661595373050027\n",
      "New best model found at epoch 15 with validation loss 0.5683555603027344\n",
      "Starting Epoch 16\n",
      "0.5724338785461758\n",
      "New best model found at epoch 16 with validation loss 0.5568267107009888\n",
      "Starting Epoch 17\n",
      "0.5661123680031818\n",
      "New best model found at epoch 17 with validation loss 0.5473711490631104\n",
      "Starting Epoch 18\n",
      "0.5606610399225483\n",
      "New best model found at epoch 18 with validation loss 0.5404354929924011\n",
      "Starting Epoch 19\n",
      "0.5611367510712665\n",
      "Starting Epoch 20\n",
      "0.5577587381653164\n",
      "Starting Epoch 21\n",
      "0.5554850334706514\n",
      "Starting Epoch 22\n",
      "0.5551941809446915\n",
      "Starting Epoch 23\n",
      "0.5569283210712931\n",
      "New best model found at epoch 23 with validation loss 0.5385039448738098\n",
      "Starting Epoch 24\n",
      "0.549126570639403\n",
      "New best model found at epoch 24 with validation loss 0.533136785030365\n",
      "Starting Epoch 25\n",
      "0.5490108767281408\n",
      "Starting Epoch 26\n",
      "0.5510559989058453\n",
      "Starting Epoch 27\n",
      "0.5536369720230931\n",
      "Starting Epoch 28\n",
      "0.5534337953380917\n",
      "Starting Epoch 29\n",
      "0.5478491536948992\n",
      "Starting Epoch 30\n",
      "0.5512329676876897\n",
      "Starting Epoch 31\n",
      "0.5443766168926073\n",
      "New best model found at epoch 31 with validation loss 0.5318681001663208\n",
      "Starting Epoch 32\n",
      "0.5475041905175084\n",
      "New best model found at epoch 32 with validation loss 0.5303896069526672\n",
      "Starting Epoch 33\n",
      "0.5507536673027537\n",
      "New best model found at epoch 33 with validation loss 0.5284036993980408\n",
      "Starting Epoch 34\n",
      "0.5446845979794211\n",
      "New best model found at epoch 34 with validation loss 0.5231476426124573\n",
      "Starting Epoch 35\n",
      "0.5473048609236012\n",
      "Starting Epoch 36\n",
      "0.5478736356548641\n",
      "Starting Epoch 37\n",
      "0.5472850371962008\n",
      "Starting Epoch 38\n",
      "0.5446889400482178\n",
      "Starting Epoch 39\n",
      "0.5452438294887543\n",
      "Starting Epoch 40\n",
      "0.5418356268302255\n",
      "Starting Epoch 41\n",
      "0.5434386328510616\n",
      "Starting Epoch 42\n",
      "0.5459313418554224\n",
      "New best model found at epoch 42 with validation loss 0.5207447409629822\n",
      "Starting Epoch 43\n",
      "0.5417410770188207\n",
      "Starting Epoch 44\n",
      "0.5417396348455678\n",
      "New best model found at epoch 44 with validation loss 0.5186684131622314\n",
      "Starting Epoch 45\n",
      "0.543889440920042\n",
      "Starting Epoch 46\n",
      "0.5394622424374456\n",
      "Starting Epoch 47\n",
      "0.5431468616361204\n",
      "Starting Epoch 48\n",
      "0.5415126292601876\n",
      "Starting Epoch 49\n",
      "0.5398897450903187\n",
      "Starting Epoch 50\n",
      "0.5380135567291923\n",
      "Starting Epoch 51\n",
      "0.5403739887735118\n",
      "New best model found at epoch 51 with validation loss 0.5178928971290588\n",
      "Starting Epoch 52\n",
      "0.539447009563446\n",
      "New best model found at epoch 52 with validation loss 0.5149521231651306\n",
      "Starting Epoch 53\n",
      "0.5392689536447111\n",
      "Starting Epoch 54\n",
      "0.5391568088013193\n",
      "Starting Epoch 55\n",
      "0.5370831359987673\n",
      "Starting Epoch 56\n",
      "0.5392413243003513\n",
      "Starting Epoch 57\n",
      "0.5387284017127493\n",
      "Starting Epoch 58\n",
      "0.5385485809782277\n",
      "New best model found at epoch 58 with validation loss 0.5125205516815186\n",
      "Starting Epoch 59\n",
      "0.5386119458986365\n",
      "Starting Epoch 60\n",
      "0.5391945929630942\n",
      "Starting Epoch 61\n",
      "0.5381047829337742\n",
      "New best model found at epoch 61 with validation loss 0.5116939544677734\n",
      "Starting Epoch 62\n",
      "0.537788485703261\n",
      "New best model found at epoch 62 with validation loss 0.5104461312294006\n",
      "Starting Epoch 63\n",
      "0.535288182289704\n",
      "Starting Epoch 64\n",
      "0.5370212469411932\n",
      "Starting Epoch 65\n",
      "0.5369340077690457\n",
      "Starting Epoch 66\n",
      "0.5396639989769977\n",
      "Starting Epoch 67\n",
      "0.5332369208335876\n",
      "Starting Epoch 68\n",
      "0.5361730352691982\n",
      "Starting Epoch 69\n",
      "0.5345728863840518\n",
      "Starting Epoch 70\n",
      "0.5338089155114215\n",
      "Starting Epoch 71\n",
      "0.5321813847707666\n",
      "Starting Epoch 72\n",
      "0.534044307211171\n",
      "Starting Epoch 73\n",
      "0.5356845454029415\n",
      "Starting Epoch 74\n",
      "0.5351684948672419\n",
      "New best model found at epoch 74 with validation loss 0.5076062679290771\n",
      "Starting Epoch 75\n",
      "0.5364974361398945\n",
      "Starting Epoch 76\n",
      "0.53197167230689\n",
      "Starting Epoch 77\n",
      "0.5303245627361796\n",
      "Starting Epoch 78\n",
      "0.5318700036276942\n",
      "Starting Epoch 79\n",
      "0.5303226178107054\n",
      "Starting Epoch 80\n",
      "0.5303993834101636\n",
      "Starting Epoch 81\n",
      "0.5330026642135952\n",
      "Starting Epoch 82\n",
      "0.5325542208941086\n",
      "Starting Epoch 83\n",
      "0.5289762525454812\n",
      "New best model found at epoch 83 with validation loss 0.507128119468689\n",
      "Starting Epoch 84\n",
      "0.5284543439098026\n",
      "Starting Epoch 85\n",
      "0.5275710510170978\n",
      "Starting Epoch 86\n",
      "0.5292433694652889\n",
      "Starting Epoch 87\n",
      "0.5273979241433351\n",
      "Starting Epoch 88\n",
      "0.5275910768819891\n",
      "Starting Epoch 89\n",
      "0.5304722034412882\n",
      "Starting Epoch 90\n",
      "0.5289199248604153\n",
      "Starting Epoch 91\n",
      "0.5302061218282451\n",
      "Starting Epoch 92\n",
      "0.5287979906019957\n",
      "New best model found at epoch 92 with validation loss 0.5038633942604065\n",
      "Starting Epoch 93\n",
      "0.5266905776832415\n",
      "Starting Epoch 94\n",
      "0.5270689363064973\n",
      "Starting Epoch 95\n",
      "0.5289423621219137\n",
      "New best model found at epoch 95 with validation loss 0.503831148147583\n",
      "Starting Epoch 96\n",
      "0.5247413697450057\n",
      "Starting Epoch 97\n",
      "0.5261320238528044\n",
      "Starting Epoch 98\n",
      "0.5248273935007013\n",
      "Starting Epoch 99\n",
      "0.525705802699794\n",
      "Starting Epoch 100\n",
      "0.523822695016861\n",
      "Starting Epoch 101\n",
      "0.525268923977147\n",
      "Starting Epoch 102\n",
      "0.5226006313510563\n",
      "New best model found at epoch 102 with validation loss 0.5014820694923401\n",
      "Starting Epoch 103\n",
      "0.5250622565331666\n",
      "Starting Epoch 104\n",
      "0.5259458811386771\n",
      "Starting Epoch 105\n",
      "0.5229119878748189\n",
      "Starting Epoch 106\n",
      "0.5264763015767803\n",
      "New best model found at epoch 106 with validation loss 0.501127302646637\n",
      "Starting Epoch 107\n",
      "0.5215968865415325\n",
      "Starting Epoch 108\n",
      "0.5248770363952803\n",
      "Starting Epoch 109\n",
      "0.5210091782652814\n",
      "New best model found at epoch 109 with validation loss 0.49911749362945557\n",
      "Starting Epoch 110\n",
      "0.5246003943940868\n",
      "Starting Epoch 111\n",
      "0.5217540510322737\n",
      "Starting Epoch 112\n",
      "0.5207104449686797\n",
      "Starting Epoch 113\n",
      "0.5228673673194387\n",
      "Starting Epoch 114\n",
      "0.5238319298495417\n",
      "Starting Epoch 115\n",
      "0.5214160810346189\n",
      "Starting Epoch 116\n",
      "0.5219628694264785\n",
      "Starting Epoch 117\n",
      "0.5205696069675944\n",
      "Starting Epoch 118\n",
      "0.5207680619281271\n",
      "Starting Epoch 119\n",
      "0.5216381536877673\n",
      "Starting Epoch 120\n",
      "0.5210622510184413\n",
      "New best model found at epoch 120 with validation loss 0.49556460976600647\n",
      "Starting Epoch 121\n",
      "0.5207153312537981\n",
      "Starting Epoch 122\n",
      "0.5207224501215894\n",
      "Starting Epoch 123\n",
      "0.5208114152369292\n",
      "Starting Epoch 124\n",
      "0.5213062504063481\n",
      "Starting Epoch 125\n",
      "0.5207313778607742\n",
      "Starting Epoch 126\n",
      "0.5223733199679333\n",
      "Starting Epoch 127\n",
      "0.5230237621328105\n",
      "Starting Epoch 128\n",
      "0.5182408677495044\n",
      "Starting Epoch 129\n",
      "0.5246693880661674\n",
      "Starting Epoch 130\n",
      "0.5171366411706676\n",
      "Starting Epoch 131\n",
      "0.5194959588672804\n",
      "Starting Epoch 132\n",
      "0.5173482506171517\n",
      "Starting Epoch 133\n",
      "0.5171026470868484\n",
      "Starting Epoch 134\n",
      "0.5175327853016232\n",
      "Starting Epoch 135\n",
      "0.5201120467289634\n",
      "Starting Epoch 136\n",
      "0.5188517389090165\n",
      "Starting Epoch 137\n",
      "0.5165256197037904\n",
      "New best model found at epoch 137 with validation loss 0.49217432737350464\n",
      "Starting Epoch 138\n",
      "0.5180947910184446\n",
      "Starting Epoch 139\n",
      "0.5177807121173196\n",
      "Starting Epoch 140\n",
      "0.5179019207539766\n",
      "Starting Epoch 141\n",
      "0.5161036032697429\n",
      "Starting Epoch 142\n",
      "0.515618455150853\n",
      "Starting Epoch 143\n",
      "0.5147043583185776\n",
      "Starting Epoch 144\n",
      "0.5171059758766837\n",
      "Starting Epoch 145\n",
      "0.5155125208522963\n",
      "Starting Epoch 146\n",
      "0.5143614825995072\n",
      "Starting Epoch 147\n",
      "0.5140429372372834\n",
      "Starting Epoch 148\n",
      "0.515047664227693\n",
      "Starting Epoch 149\n",
      "0.514739075432653\n",
      "Starting Epoch 150\n",
      "0.5127398203248563\n",
      "Starting Epoch 151\n",
      "0.5142370112564253\n",
      "Starting Epoch 152\n",
      "0.5103515425454015\n",
      "Starting Epoch 153\n",
      "0.5132945503877557\n",
      "Starting Epoch 154\n",
      "0.5160048979779949\n",
      "Starting Epoch 155\n",
      "0.5172254365423451\n",
      "Starting Epoch 156\n",
      "0.5103625227575717\n",
      "Starting Epoch 157\n",
      "0.5123170653115148\n",
      "Starting Epoch 158\n",
      "0.5130573549996251\n",
      "Starting Epoch 159\n",
      "0.5117484201555667\n",
      "Starting Epoch 160\n",
      "0.5097126261047695\n",
      "Starting Epoch 161\n",
      "0.5095926082652548\n",
      "Starting Epoch 162\n",
      "0.5086482750332874\n",
      "Starting Epoch 163\n",
      "0.5126576268154642\n",
      "Starting Epoch 164\n",
      "0.5106214427429697\n",
      "Starting Epoch 165\n",
      "0.5091281235218048\n",
      "Starting Epoch 166\n",
      "0.505999365578527\n",
      "Starting Epoch 167\n",
      "0.5068275462026182\n",
      "Starting Epoch 168\n",
      "0.5093587572159974\n",
      "Starting Epoch 169\n",
      "0.5084773587143939\n",
      "Starting Epoch 170\n",
      "0.5071569927360701\n",
      "Starting Epoch 171\n",
      "0.5095414571140123\n",
      "Starting Epoch 172\n",
      "0.508126270511876\n",
      "Starting Epoch 173\n",
      "0.5042420871879744\n",
      "Starting Epoch 174\n",
      "0.5063054535699927\n",
      "Starting Epoch 175\n",
      "0.50827073921328\n",
      "Starting Epoch 176\n",
      "0.5046147289483444\n",
      "Starting Epoch 177\n",
      "0.5029677567274674\n",
      "Starting Epoch 178\n",
      "0.5068270926890166\n",
      "New best model found at epoch 178 with validation loss 0.4877118766307831\n",
      "Starting Epoch 179\n",
      "0.5075753810613052\n",
      "Starting Epoch 180\n",
      "0.5095350418401801\n",
      "New best model found at epoch 180 with validation loss 0.48699283599853516\n",
      "Starting Epoch 181\n",
      "0.502555611340896\n",
      "Starting Epoch 182\n",
      "0.5010411195133043\n",
      "Starting Epoch 183\n",
      "0.5003312346727952\n",
      "Starting Epoch 184\n",
      "0.5030430982942167\n",
      "Starting Epoch 185\n",
      "0.503225265637688\n",
      "Starting Epoch 186\n",
      "0.5056606906911602\n",
      "New best model found at epoch 186 with validation loss 0.4858342409133911\n",
      "Starting Epoch 187\n",
      "0.5030612660490948\n",
      "Starting Epoch 188\n",
      "0.5056550476862036\n",
      "Starting Epoch 189\n",
      "0.5005205701226774\n",
      "Starting Epoch 190\n",
      "0.5001496685587842\n",
      "Starting Epoch 191\n",
      "0.5015230658261672\n",
      "Starting Epoch 192\n",
      "0.4969893434773321\n",
      "Starting Epoch 193\n",
      "0.4994901872199515\n",
      "Starting Epoch 194\n",
      "0.5000554945157922\n",
      "Starting Epoch 195\n",
      "0.4989742921746295\n",
      "Starting Epoch 196\n",
      "0.49533128220102063\n",
      "Starting Epoch 197\n",
      "0.5014771274898363\n",
      "New best model found at epoch 197 with validation loss 0.4854243993759155\n",
      "Starting Epoch 198\n",
      "0.49390426148539\n",
      "New best model found at epoch 198 with validation loss 0.4817740023136139\n",
      "Starting Epoch 199\n",
      "0.5001773186351942\n",
      "Starting Epoch 200\n",
      "0.49453693887461786\n",
      "New best model found at epoch 200 with validation loss 0.4813297986984253\n",
      "Starting Epoch 201\n",
      "0.4979777102885039\n",
      "Starting Epoch 202\n",
      "0.49893646784450696\n",
      "Starting Epoch 203\n",
      "0.49351474254027655\n",
      "Starting Epoch 204\n",
      "0.4944179874399434\n",
      "Starting Epoch 205\n",
      "0.49851530401603034\n",
      "Starting Epoch 206\n",
      "0.493285262066385\n",
      "Starting Epoch 207\n",
      "0.49864064092221466\n",
      "Starting Epoch 208\n",
      "0.49039913778719696\n",
      "Starting Epoch 209\n",
      "0.49428403895834216\n",
      "Starting Epoch 210\n",
      "0.49123961251714954\n",
      "Starting Epoch 211\n",
      "0.49495513413263403\n",
      "Starting Epoch 212\n",
      "0.497396654408911\n",
      "Starting Epoch 213\n",
      "0.4915765407292739\n",
      "Starting Epoch 214\n",
      "0.4942743376545284\n",
      "Starting Epoch 215\n",
      "0.4954186341036921\n",
      "Starting Epoch 216\n",
      "0.49106729808061017\n",
      "Starting Epoch 217\n",
      "0.49443953063177026\n",
      "Starting Epoch 218\n",
      "0.49011896097141766\n",
      "Starting Epoch 219\n",
      "0.4905495863893758\n",
      "Starting Epoch 220\n",
      "0.4927730042001475\n",
      "Starting Epoch 221\n",
      "0.4882385886233786\n",
      "Starting Epoch 222\n",
      "0.4876069698644721\n",
      "Starting Epoch 223\n",
      "0.4921053660952527\n",
      "Starting Epoch 224\n",
      "0.49063406949457916\n",
      "Starting Epoch 225\n",
      "0.4875959507797075\n",
      "Starting Epoch 226\n",
      "0.494042237167773\n",
      "Starting Epoch 227\n",
      "0.4888667282850846\n",
      "Starting Epoch 228\n",
      "0.4878004517244256\n",
      "Starting Epoch 229\n",
      "0.48457657254260517\n",
      "Starting Epoch 230\n",
      "0.4896670268929523\n",
      "Starting Epoch 231\n",
      "0.4937046299809995\n",
      "Starting Epoch 232\n",
      "0.49057895852171857\n",
      "Starting Epoch 233\n",
      "0.4886860782685487\n",
      "Starting Epoch 234\n",
      "0.488074805425561\n",
      "Starting Epoch 235\n",
      "0.48730444519416144\n",
      "Starting Epoch 236\n",
      "0.4879329204559326\n",
      "Starting Epoch 237\n",
      "0.48882796453393024\n",
      "Starting Epoch 238\n",
      "0.4866979744123376\n",
      "Starting Epoch 239\n",
      "0.48639970758686896\n",
      "Starting Epoch 240\n",
      "0.48910108856532886\n",
      "Starting Epoch 241\n",
      "0.48767082069231116\n",
      "Starting Epoch 242\n",
      "0.48661612557328265\n",
      "Starting Epoch 243\n",
      "0.48373031875361566\n",
      "Starting Epoch 244\n",
      "0.486439383548239\n",
      "Starting Epoch 245\n",
      "0.49098742656085803\n",
      "Starting Epoch 246\n",
      "0.4878646031669948\n",
      "New best model found at epoch 246 with validation loss 0.47718843817710876\n",
      "Starting Epoch 247\n",
      "0.4889689476593681\n",
      "Starting Epoch 248\n",
      "0.4878188825171927\n",
      "Starting Epoch 249\n",
      "0.4870327853638193\n",
      "Starting Epoch 250\n",
      "0.4929093485293181\n",
      "Starting Epoch 251\n",
      "0.487556340901748\n",
      "Starting Epoch 252\n",
      "0.4859859606494074\n",
      "Starting Epoch 253\n",
      "0.4857081200765527\n",
      "Starting Epoch 254\n",
      "0.48357641049053357\n",
      "Starting Epoch 255\n",
      "0.4864675363768702\n",
      "Starting Epoch 256\n",
      "0.48840001743772754\n",
      "Starting Epoch 257\n",
      "0.4871578449788301\n",
      "Starting Epoch 258\n",
      "0.4864032851613086\n",
      "Starting Epoch 259\n",
      "0.48811078330744867\n",
      "Starting Epoch 260\n",
      "0.48510420192842896\n",
      "Starting Epoch 261\n",
      "0.48309562776399695\n",
      "Starting Epoch 262\n",
      "0.48760673533315246\n",
      "Starting Epoch 263\n",
      "0.48562504675077356\n",
      "Starting Epoch 264\n",
      "0.48573577663172846\n",
      "Starting Epoch 265\n",
      "0.4855836228184078\n",
      "Starting Epoch 266\n",
      "0.4814688796582429\n",
      "Starting Epoch 267\n",
      "0.48518274141394574\n",
      "Starting Epoch 268\n",
      "0.48631036022435065\n",
      "Starting Epoch 269\n",
      "0.4862898536350416\n",
      "Starting Epoch 270\n",
      "0.4806269977403724\n",
      "Starting Epoch 271\n",
      "0.48636033353598224\n",
      "Starting Epoch 272\n",
      "0.4856308646824049\n",
      "Starting Epoch 273\n",
      "0.48514103630314703\n",
      "Starting Epoch 274\n",
      "0.48382930133653723\n",
      "Starting Epoch 275\n",
      "0.48551661294439563\n",
      "Starting Epoch 276\n",
      "0.4841115720894026\n",
      "Starting Epoch 277\n",
      "0.4846140884834787\n",
      "Starting Epoch 278\n",
      "0.4819871342700461\n",
      "Starting Epoch 279\n",
      "0.4832596778869629\n",
      "Starting Epoch 280\n",
      "0.48442923245222674\n",
      "Starting Epoch 281\n",
      "0.4832106141940407\n",
      "Starting Epoch 282\n",
      "0.4827144690181898\n",
      "Starting Epoch 283\n",
      "0.48730549734571704\n",
      "Starting Epoch 284\n",
      "0.4826375880967016\n",
      "Starting Epoch 285\n",
      "0.4837814077087071\n",
      "Starting Epoch 286\n",
      "0.4819268014120019\n",
      "Starting Epoch 287\n",
      "0.4851563974567082\n",
      "Starting Epoch 288\n",
      "0.48195307280706323\n",
      "Starting Epoch 289\n",
      "0.48432891265205713\n",
      "Starting Epoch 290\n",
      "0.4833924744440162\n",
      "Starting Epoch 291\n",
      "0.48153799124386\n",
      "Starting Epoch 292\n",
      "0.4831161550853563\n",
      "Starting Epoch 293\n",
      "0.48358375611512555\n",
      "Starting Epoch 294\n",
      "0.4799410687840503\n",
      "Starting Epoch 295\n",
      "0.4823627718116926\n",
      "Starting Epoch 296\n",
      "0.48106995354528015\n",
      "Starting Epoch 297\n",
      "0.4816070704356484\n",
      "Starting Epoch 298\n",
      "0.482932826747065\n",
      "Starting Epoch 299\n",
      "0.48555957752725354\n",
      "Starting Epoch 300\n",
      "0.4816548668819925\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-40-20-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6abdb9",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 10 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "65d3ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "630846d5-8374-4f68-886b-e26d71862b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.1656261760255564\n",
      "New best model found at epoch 1 with validation loss 0.6800259351730347\n",
      "Starting Epoch 2\n",
      "0.6816489748332811\n",
      "New best model found at epoch 2 with validation loss 0.6738033890724182\n",
      "Starting Epoch 3\n",
      "0.6703351140022278\n",
      "New best model found at epoch 3 with validation loss 0.6500662565231323\n",
      "Starting Epoch 4\n",
      "0.6601533630619878\n",
      "New best model found at epoch 4 with validation loss 0.6488224267959595\n",
      "Starting Epoch 5\n",
      "0.6427919398183408\n",
      "New best model found at epoch 5 with validation loss 0.6226397752761841\n",
      "Starting Epoch 6\n",
      "0.6406679101612257\n",
      "New best model found at epoch 6 with validation loss 0.6157600283622742\n",
      "Starting Epoch 7\n",
      "0.6259613140769626\n",
      "New best model found at epoch 7 with validation loss 0.6098894476890564\n",
      "Starting Epoch 8\n",
      "0.6184266805648804\n",
      "New best model found at epoch 8 with validation loss 0.6088229417800903\n",
      "Starting Epoch 9\n",
      "0.6098996063937312\n",
      "Starting Epoch 10\n",
      "0.6206158555072286\n",
      "Starting Epoch 11\n",
      "0.6120957939521127\n",
      "New best model found at epoch 11 with validation loss 0.6086328029632568\n",
      "Starting Epoch 12\n",
      "0.6044490130051322\n",
      "New best model found at epoch 12 with validation loss 0.5970792770385742\n",
      "Starting Epoch 13\n",
      "0.6078918679900791\n",
      "Starting Epoch 14\n",
      "0.5965347756510195\n",
      "New best model found at epoch 14 with validation loss 0.5931349992752075\n",
      "Starting Epoch 15\n",
      "0.5997762213582578\n",
      "New best model found at epoch 15 with validation loss 0.5881027579307556\n",
      "Starting Epoch 16\n",
      "0.5961206995922587\n",
      "New best model found at epoch 16 with validation loss 0.586083173751831\n",
      "Starting Epoch 17\n",
      "0.5976330663846887\n",
      "New best model found at epoch 17 with validation loss 0.5840001106262207\n",
      "Starting Epoch 18\n",
      "0.5906210749045663\n",
      "Starting Epoch 19\n",
      "0.5918861679408861\n",
      "New best model found at epoch 19 with validation loss 0.579669713973999\n",
      "Starting Epoch 20\n",
      "0.583834681821906\n",
      "New best model found at epoch 20 with validation loss 0.5783287286758423\n",
      "Starting Epoch 21\n",
      "0.5878811452699744\n",
      "New best model found at epoch 21 with validation loss 0.5743967890739441\n",
      "Starting Epoch 22\n",
      "0.5831100681553716\n",
      "Starting Epoch 23\n",
      "0.5829463834347932\n",
      "New best model found at epoch 23 with validation loss 0.5679527521133423\n",
      "Starting Epoch 24\n",
      "0.5775315839311351\n",
      "Starting Epoch 25\n",
      "0.5843236731446307\n",
      "New best model found at epoch 25 with validation loss 0.5663399696350098\n",
      "Starting Epoch 26\n",
      "0.5759970131127731\n",
      "New best model found at epoch 26 with validation loss 0.5603951811790466\n",
      "Starting Epoch 27\n",
      "0.5745164246662803\n",
      "Starting Epoch 28\n",
      "0.5756860945535742\n",
      "New best model found at epoch 28 with validation loss 0.5589684844017029\n",
      "Starting Epoch 29\n",
      "0.5695524358231089\n",
      "New best model found at epoch 29 with validation loss 0.5549483299255371\n",
      "Starting Epoch 30\n",
      "0.5736617575521055\n",
      "New best model found at epoch 30 with validation loss 0.5508691072463989\n",
      "Starting Epoch 31\n",
      "0.5783377471177474\n",
      "Starting Epoch 32\n",
      "0.5671157836914062\n",
      "New best model found at epoch 32 with validation loss 0.5485109686851501\n",
      "Starting Epoch 33\n",
      "0.5654981369557588\n",
      "Starting Epoch 34\n",
      "0.5666880400284476\n",
      "Starting Epoch 35\n",
      "0.5656694666199062\n",
      "New best model found at epoch 35 with validation loss 0.5444333553314209\n",
      "Starting Epoch 36\n",
      "0.5651471951733464\n",
      "Starting Epoch 37\n",
      "0.5663117001885953\n",
      "Starting Epoch 38\n",
      "0.5597366690635681\n",
      "Starting Epoch 39\n",
      "0.5614978036154872\n",
      "New best model found at epoch 39 with validation loss 0.5383841395378113\n",
      "Starting Epoch 40\n",
      "0.558245529299197\n",
      "Starting Epoch 41\n",
      "0.5575033322624539\n",
      "New best model found at epoch 41 with validation loss 0.537481963634491\n",
      "Starting Epoch 42\n",
      "0.5601824522018433\n",
      "Starting Epoch 43\n",
      "0.5599616014439127\n",
      "New best model found at epoch 43 with validation loss 0.5361473560333252\n",
      "Starting Epoch 44\n",
      "0.5599036968272665\n",
      "Starting Epoch 45\n",
      "0.5574051193569017\n",
      "Starting Epoch 46\n",
      "0.5526431487954181\n",
      "New best model found at epoch 46 with validation loss 0.5357913374900818\n",
      "Starting Epoch 47\n",
      "0.556776982286702\n",
      "New best model found at epoch 47 with validation loss 0.535144031047821\n",
      "Starting Epoch 48\n",
      "0.5567986122939897\n",
      "Starting Epoch 49\n",
      "0.5530263833377672\n",
      "Starting Epoch 50\n",
      "0.5512896918732187\n",
      "New best model found at epoch 50 with validation loss 0.5349384546279907\n",
      "Starting Epoch 51\n",
      "0.5543387000975402\n",
      "New best model found at epoch 51 with validation loss 0.5306010246276855\n",
      "Starting Epoch 52\n",
      "0.5542629827623782\n",
      "New best model found at epoch 52 with validation loss 0.5299642086029053\n",
      "Starting Epoch 53\n",
      "0.5575501568939375\n",
      "Starting Epoch 54\n",
      "0.5621366617472275\n",
      "New best model found at epoch 54 with validation loss 0.5259564518928528\n",
      "Starting Epoch 55\n",
      "0.5511850494405498\n",
      "Starting Epoch 56\n",
      "0.5482100300166918\n",
      "Starting Epoch 57\n",
      "0.5513426233892855\n",
      "Starting Epoch 58\n",
      "0.5491659226624862\n",
      "Starting Epoch 59\n",
      "0.5502802755521692\n",
      "New best model found at epoch 59 with validation loss 0.5243583917617798\n",
      "Starting Epoch 60\n",
      "0.548259973526001\n",
      "New best model found at epoch 60 with validation loss 0.5228238105773926\n",
      "Starting Epoch 61\n",
      "0.5452499817246976\n",
      "Starting Epoch 62\n",
      "0.5467810656713403\n",
      "New best model found at epoch 62 with validation loss 0.5195194482803345\n",
      "Starting Epoch 63\n",
      "0.545081316129021\n",
      "New best model found at epoch 63 with validation loss 0.5173368453979492\n",
      "Starting Epoch 64\n",
      "0.5464884703573973\n",
      "Starting Epoch 65\n",
      "0.5462216812631359\n",
      "Starting Epoch 66\n",
      "0.5443807153598123\n",
      "Starting Epoch 67\n",
      "0.5496310889720917\n",
      "Starting Epoch 68\n",
      "0.5452745660491611\n",
      "Starting Epoch 69\n",
      "0.5464057598424994\n",
      "Starting Epoch 70\n",
      "0.5446336373038914\n",
      "Starting Epoch 71\n",
      "0.5457850020864735\n",
      "New best model found at epoch 71 with validation loss 0.5141220092773438\n",
      "Starting Epoch 72\n",
      "0.5441839215548142\n",
      "Starting Epoch 73\n",
      "0.5453717553097269\n",
      "New best model found at epoch 73 with validation loss 0.5140535235404968\n",
      "Starting Epoch 74\n",
      "0.5438718044239542\n",
      "Starting Epoch 75\n",
      "0.5436605526053387\n",
      "New best model found at epoch 75 with validation loss 0.5113348364830017\n",
      "Starting Epoch 76\n",
      "0.545287048039229\n",
      "Starting Epoch 77\n",
      "0.5429524429466414\n",
      "Starting Epoch 78\n",
      "0.5481314076029736\n",
      "Starting Epoch 79\n",
      "0.5441408818182738\n",
      "New best model found at epoch 79 with validation loss 0.5112544894218445\n",
      "Starting Epoch 80\n",
      "0.5398793337137803\n",
      "Starting Epoch 81\n",
      "0.5397856339164402\n",
      "Starting Epoch 82\n",
      "0.5440524648065153\n",
      "Starting Epoch 83\n",
      "0.5401038488616114\n",
      "New best model found at epoch 83 with validation loss 0.5101441740989685\n",
      "Starting Epoch 84\n",
      "0.5419995603354081\n",
      "Starting Epoch 85\n",
      "0.5401036972584932\n",
      "New best model found at epoch 85 with validation loss 0.508123517036438\n",
      "Starting Epoch 86\n",
      "0.5400004827457926\n",
      "Starting Epoch 87\n",
      "0.5429626690304797\n",
      "Starting Epoch 88\n",
      "0.5418709788633429\n",
      "Starting Epoch 89\n",
      "0.5377779253151106\n",
      "Starting Epoch 90\n",
      "0.5385989702266195\n",
      "Starting Epoch 91\n",
      "0.5389474112054576\n",
      "Starting Epoch 92\n",
      "0.53774719134621\n",
      "Starting Epoch 93\n",
      "0.5363514695478522\n",
      "Starting Epoch 94\n",
      "0.5400445914786794\n",
      "Starting Epoch 95\n",
      "0.5408732424611631\n",
      "Starting Epoch 96\n",
      "0.538914873548176\n",
      "Starting Epoch 97\n",
      "0.5367526606373165\n",
      "Starting Epoch 98\n",
      "0.5349910051926322\n",
      "Starting Epoch 99\n",
      "0.5365074030731035\n",
      "Starting Epoch 100\n",
      "0.5375873252101566\n",
      "Starting Epoch 101\n",
      "0.5379393010035806\n",
      "Starting Epoch 102\n",
      "0.5348613352879233\n",
      "Starting Epoch 103\n",
      "0.5364774206410283\n",
      "Starting Epoch 104\n",
      "0.5369787008866019\n",
      "Starting Epoch 105\n",
      "0.5380864946738534\n",
      "Starting Epoch 106\n",
      "0.5369949003924495\n",
      "New best model found at epoch 106 with validation loss 0.5062255263328552\n",
      "Starting Epoch 107\n",
      "0.5367020251958267\n",
      "Starting Epoch 108\n",
      "0.5327829822250034\n",
      "New best model found at epoch 108 with validation loss 0.5055315494537354\n",
      "Starting Epoch 109\n",
      "0.534691747116006\n",
      "Starting Epoch 110\n",
      "0.5343964501567509\n",
      "Starting Epoch 111\n",
      "0.5353426674137944\n",
      "Starting Epoch 112\n",
      "0.5377343413622483\n",
      "New best model found at epoch 112 with validation loss 0.5053040981292725\n",
      "Starting Epoch 113\n",
      "0.5359530345253323\n",
      "Starting Epoch 114\n",
      "0.5355969006600587\n",
      "Starting Epoch 115\n",
      "0.5329870698244675\n",
      "Starting Epoch 116\n",
      "0.5333993357160817\n",
      "Starting Epoch 117\n",
      "0.5348326486089955\n",
      "Starting Epoch 118\n",
      "0.5328479940476625\n",
      "Starting Epoch 119\n",
      "0.5338063745394998\n",
      "New best model found at epoch 119 with validation loss 0.5039538145065308\n",
      "Starting Epoch 120\n",
      "0.5337796496308368\n",
      "Starting Epoch 121\n",
      "0.5330558924571328\n",
      "Starting Epoch 122\n",
      "0.5336147598598314\n",
      "Starting Epoch 123\n",
      "0.5343736073245173\n",
      "New best model found at epoch 123 with validation loss 0.5030535459518433\n",
      "Starting Epoch 124\n",
      "0.5327421750711359\n",
      "Starting Epoch 125\n",
      "0.5328829379185386\n",
      "Starting Epoch 126\n",
      "0.531229818644731\n",
      "Starting Epoch 127\n",
      "0.5307284347389055\n",
      "Starting Epoch 128\n",
      "0.5286024148049562\n",
      "Starting Epoch 129\n",
      "0.5363984729932703\n",
      "Starting Epoch 130\n",
      "0.5312566342561141\n",
      "Starting Epoch 131\n",
      "0.5326692513797594\n",
      "Starting Epoch 132\n",
      "0.5322755652925243\n",
      "Starting Epoch 133\n",
      "0.5330815794675247\n",
      "Starting Epoch 134\n",
      "0.5297961779262709\n",
      "Starting Epoch 135\n",
      "0.5304845584475476\n",
      "Starting Epoch 136\n",
      "0.5301774986412214\n",
      "Starting Epoch 137\n",
      "0.5296669265498286\n",
      "Starting Epoch 138\n",
      "0.5299054138038469\n",
      "New best model found at epoch 138 with validation loss 0.5002120733261108\n",
      "Starting Epoch 139\n",
      "0.5304273159607596\n",
      "Starting Epoch 140\n",
      "0.5308087571807529\n",
      "Starting Epoch 141\n",
      "0.5316355306169261\n",
      "Starting Epoch 142\n",
      "0.5291120824606522\n",
      "Starting Epoch 143\n",
      "0.5292606107566667\n",
      "Starting Epoch 144\n",
      "0.5284658812958262\n",
      "Starting Epoch 145\n",
      "0.5294257544952891\n",
      "Starting Epoch 146\n",
      "0.5297384624895842\n",
      "Starting Epoch 147\n",
      "0.5279667999433435\n",
      "Starting Epoch 148\n",
      "0.5289434388927792\n",
      "Starting Epoch 149\n",
      "0.5285091037335603\n",
      "Starting Epoch 150\n",
      "0.5276554680388906\n",
      "Starting Epoch 151\n",
      "0.5295716964680216\n",
      "Starting Epoch 152\n",
      "0.5289203161778657\n",
      "Starting Epoch 153\n",
      "0.5291768999203391\n",
      "Starting Epoch 154\n",
      "0.5256002778592317\n",
      "Starting Epoch 155\n",
      "0.527749864951424\n",
      "Starting Epoch 156\n",
      "0.5288574151370836\n",
      "Starting Epoch 157\n",
      "0.5262006624885227\n",
      "Starting Epoch 158\n",
      "0.5282353149807971\n",
      "Starting Epoch 159\n",
      "0.5265943071116572\n",
      "Starting Epoch 160\n",
      "0.5274736414784971\n",
      "Starting Epoch 161\n",
      "0.5261060867620551\n",
      "Starting Epoch 162\n",
      "0.5273086726665497\n",
      "Starting Epoch 163\n",
      "0.5271375399568806\n",
      "Starting Epoch 164\n",
      "0.5275168976058131\n",
      "Starting Epoch 165\n",
      "0.5240116171214891\n",
      "Starting Epoch 166\n",
      "0.5262011367341747\n",
      "Starting Epoch 167\n",
      "0.5270914552004441\n",
      "Starting Epoch 168\n",
      "0.5261506801066191\n",
      "Starting Epoch 169\n",
      "0.5278664956922117\n",
      "Starting Epoch 170\n",
      "0.5251247403414353\n",
      "Starting Epoch 171\n",
      "0.5253262688284335\n",
      "Starting Epoch 172\n",
      "0.5254570699256399\n",
      "New best model found at epoch 172 with validation loss 0.49998265504837036\n",
      "Starting Epoch 173\n",
      "0.5248906780844149\n",
      "Starting Epoch 174\n",
      "0.5244968067044797\n",
      "Starting Epoch 175\n",
      "0.5244634592014811\n",
      "Starting Epoch 176\n",
      "0.524577936400538\n",
      "Starting Epoch 177\n",
      "0.5240683853626251\n",
      "Starting Epoch 178\n",
      "0.524802010992299\n",
      "Starting Epoch 179\n",
      "0.5241859658904697\n",
      "Starting Epoch 180\n",
      "0.5252455952374832\n",
      "New best model found at epoch 180 with validation loss 0.49991345405578613\n",
      "Starting Epoch 181\n",
      "0.5226804925047833\n",
      "Starting Epoch 182\n",
      "0.5243019966975503\n",
      "Starting Epoch 183\n",
      "0.522426267033038\n",
      "New best model found at epoch 183 with validation loss 0.4996127188205719\n",
      "Starting Epoch 184\n",
      "0.5235649684201116\n",
      "Starting Epoch 185\n",
      "0.5236661447131116\n",
      "Starting Epoch 186\n",
      "0.5226664063723191\n",
      "Starting Epoch 187\n",
      "0.5237691039624421\n",
      "Starting Epoch 188\n",
      "0.5268298361612402\n",
      "Starting Epoch 189\n",
      "0.5227289083211318\n",
      "Starting Epoch 190\n",
      "0.5226436412852743\n",
      "Starting Epoch 191\n",
      "0.5206534486749897\n",
      "Starting Epoch 192\n",
      "0.52365090276884\n",
      "Starting Epoch 193\n",
      "0.5225976161334825\n",
      "Starting Epoch 194\n",
      "0.5210416044877924\n",
      "Starting Epoch 195\n",
      "0.5221138661322386\n",
      "Starting Epoch 196\n",
      "0.5219046836313994\n",
      "Starting Epoch 197\n",
      "0.5216414306474768\n",
      "Starting Epoch 198\n",
      "0.5233455300331116\n",
      "New best model found at epoch 198 with validation loss 0.49925705790519714\n",
      "Starting Epoch 199\n",
      "0.5204126485016035\n",
      "Starting Epoch 200\n",
      "0.5201651415099269\n",
      "Starting Epoch 201\n",
      "0.5207374756750853\n",
      "Starting Epoch 202\n",
      "0.5232973940994429\n",
      "Starting Epoch 203\n",
      "0.5211226046085358\n",
      "Starting Epoch 204\n",
      "0.5201012103453927\n",
      "Starting Epoch 205\n",
      "0.5197256311126377\n",
      "Starting Epoch 206\n",
      "0.5214697640875111\n",
      "Starting Epoch 207\n",
      "0.5229751752770465\n",
      "Starting Epoch 208\n",
      "0.5192834553511246\n",
      "Starting Epoch 209\n",
      "0.5195696444615073\n",
      "Starting Epoch 210\n",
      "0.5195946550887564\n",
      "New best model found at epoch 210 with validation loss 0.4984263777732849\n",
      "Starting Epoch 211\n",
      "0.5198068800179855\n",
      "Starting Epoch 212\n",
      "0.5208015739917755\n",
      "Starting Epoch 213\n",
      "0.520416206639746\n",
      "Starting Epoch 214\n",
      "0.520110011100769\n",
      "Starting Epoch 215\n",
      "0.5197057361188142\n",
      "Starting Epoch 216\n",
      "0.5178850591182709\n",
      "Starting Epoch 217\n",
      "0.519597703995912\n",
      "Starting Epoch 218\n",
      "0.5181239104789236\n",
      "Starting Epoch 219\n",
      "0.5185831590839054\n",
      "Starting Epoch 220\n",
      "0.5189335268476735\n",
      "Starting Epoch 221\n",
      "0.5166471393212028\n",
      "Starting Epoch 222\n",
      "0.518572800833246\n",
      "Starting Epoch 223\n",
      "0.5185184945230898\n",
      "Starting Epoch 224\n",
      "0.5168346723784571\n",
      "Starting Epoch 225\n",
      "0.5162276832953744\n",
      "Starting Epoch 226\n",
      "0.5194254789663397\n",
      "Starting Epoch 227\n",
      "0.5172544497510662\n",
      "Starting Epoch 228\n",
      "0.517733352339786\n",
      "Starting Epoch 229\n",
      "0.5163168790547744\n",
      "Starting Epoch 230\n",
      "0.5181901545628257\n",
      "Starting Epoch 231\n",
      "0.5167366408783457\n",
      "Starting Epoch 232\n",
      "0.5166642743608226\n",
      "Starting Epoch 233\n",
      "0.5168577626995419\n",
      "New best model found at epoch 233 with validation loss 0.4969419538974762\n",
      "Starting Epoch 234\n",
      "0.5168139027512592\n",
      "Starting Epoch 235\n",
      "0.5173470857350723\n",
      "Starting Epoch 236\n",
      "0.5157530230024586\n",
      "Starting Epoch 237\n",
      "0.5175637097462363\n",
      "Starting Epoch 238\n",
      "0.516120441581892\n",
      "Starting Epoch 239\n",
      "0.5152853364529817\n",
      "Starting Epoch 240\n",
      "0.5158819854259491\n",
      "Starting Epoch 241\n",
      "0.5138759807400082\n",
      "Starting Epoch 242\n",
      "0.5154878199100494\n",
      "Starting Epoch 243\n",
      "0.5162042832892874\n",
      "Starting Epoch 244\n",
      "0.5155390099338863\n",
      "Starting Epoch 245\n",
      "0.5160919985045558\n",
      "Starting Epoch 246\n",
      "0.5156559801619985\n",
      "Starting Epoch 247\n",
      "0.5134260123190673\n",
      "Starting Epoch 248\n",
      "0.5145422505295795\n",
      "Starting Epoch 249\n",
      "0.5161181610563527\n",
      "Starting Epoch 250\n",
      "0.5135578448357789\n",
      "Starting Epoch 251\n",
      "0.5144521917985834\n",
      "Starting Epoch 252\n",
      "0.5143330239731333\n",
      "Starting Epoch 253\n",
      "0.5144556333189425\n",
      "Starting Epoch 254\n",
      "0.5139318575029788\n",
      "Starting Epoch 255\n",
      "0.5127094543498495\n",
      "Starting Epoch 256\n",
      "0.5148770666640737\n",
      "Starting Epoch 257\n",
      "0.5124683120976323\n",
      "Starting Epoch 258\n",
      "0.5141098525213159\n",
      "Starting Epoch 259\n",
      "0.5144880491754283\n",
      "Starting Epoch 260\n",
      "0.5141886058061019\n",
      "Starting Epoch 261\n",
      "0.5146294845187146\n",
      "Starting Epoch 262\n",
      "0.5119252347427866\n",
      "Starting Epoch 263\n",
      "0.5121131021043529\n",
      "Starting Epoch 264\n",
      "0.5131721703902535\n",
      "Starting Epoch 265\n",
      "0.514172850743584\n",
      "Starting Epoch 266\n",
      "0.5129795074462891\n",
      "Starting Epoch 267\n",
      "0.5118501173413318\n",
      "Starting Epoch 268\n",
      "0.5116370994111766\n",
      "Starting Epoch 269\n",
      "0.5120856684187184\n",
      "Starting Epoch 270\n",
      "0.5115770593933437\n",
      "Starting Epoch 271\n",
      "0.5112327868523805\n",
      "Starting Epoch 272\n",
      "0.5116951076880746\n",
      "Starting Epoch 273\n",
      "0.5110499470130258\n",
      "Starting Epoch 274\n",
      "0.5120361460291821\n",
      "Starting Epoch 275\n",
      "0.5127569359281788\n",
      "Starting Epoch 276\n",
      "0.5120702813500944\n",
      "Starting Epoch 277\n",
      "0.5106501812520234\n",
      "Starting Epoch 278\n",
      "0.511402233787205\n",
      "Starting Epoch 279\n",
      "0.5116946334424226\n",
      "Starting Epoch 280\n",
      "0.5126664625561755\n",
      "Starting Epoch 281\n",
      "0.5135956225187882\n",
      "Starting Epoch 282\n",
      "0.5096360276574674\n",
      "New best model found at epoch 282 with validation loss 0.4954693019390106\n",
      "Starting Epoch 283\n",
      "0.510971372542174\n",
      "Starting Epoch 284\n",
      "0.5117214075897051\n",
      "Starting Epoch 285\n",
      "0.5105132447636646\n",
      "New best model found at epoch 285 with validation loss 0.4952051043510437\n",
      "Starting Epoch 286\n",
      "0.5118352032226064\n",
      "Starting Epoch 287\n",
      "0.5128494099430416\n",
      "Starting Epoch 288\n",
      "0.51267344277838\n",
      "Starting Epoch 289\n",
      "0.5096477762512539\n",
      "Starting Epoch 290\n",
      "0.5103830617407094\n",
      "Starting Epoch 291\n",
      "0.5117739659288655\n",
      "Starting Epoch 292\n",
      "0.5126981812974681\n",
      "Starting Epoch 293\n",
      "0.5104225355645885\n",
      "Starting Epoch 294\n",
      "0.5130032521227131\n",
      "Starting Epoch 295\n",
      "0.5101905789064325\n",
      "New best model found at epoch 295 with validation loss 0.4947318136692047\n",
      "Starting Epoch 296\n",
      "0.5107547472352567\n",
      "Starting Epoch 297\n",
      "0.5084599178770314\n",
      "Starting Epoch 298\n",
      "0.511146781237229\n",
      "Starting Epoch 299\n",
      "0.5100277312423872\n",
      "Starting Epoch 300\n",
      "0.5101134906644407\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-40-10-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00186d",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 40 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "85d99099-71db-4b80-86df-1d1916222bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "48953fd3-3b82-4cbe-82e8-947531e6169b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.8038870459017546\n",
      "New best model found at epoch 1 with validation loss 0.6836519837379456\n",
      "Starting Epoch 2\n",
      "0.6801919030106586\n",
      "New best model found at epoch 2 with validation loss 0.6695854663848877\n",
      "Starting Epoch 3\n",
      "0.6684030942294908\n",
      "New best model found at epoch 3 with validation loss 0.6564418077468872\n",
      "Starting Epoch 4\n",
      "0.6541107452434042\n",
      "New best model found at epoch 4 with validation loss 0.6438436508178711\n",
      "Starting Epoch 5\n",
      "0.6383971364601798\n",
      "Starting Epoch 6\n",
      "0.6376791104026462\n",
      "New best model found at epoch 6 with validation loss 0.6250697374343872\n",
      "Starting Epoch 7\n",
      "0.6246713918188344\n",
      "Starting Epoch 8\n",
      "0.6087799175925876\n",
      "New best model found at epoch 8 with validation loss 0.6240353584289551\n",
      "Starting Epoch 9\n",
      "0.6102672374766805\n",
      "New best model found at epoch 9 with validation loss 0.6026795506477356\n",
      "Starting Epoch 10\n",
      "0.609222720498624\n",
      "Starting Epoch 11\n",
      "0.608684892239778\n",
      "New best model found at epoch 11 with validation loss 0.6021995544433594\n",
      "Starting Epoch 12\n",
      "0.5939906420915023\n",
      "New best model found at epoch 12 with validation loss 0.5912116169929504\n",
      "Starting Epoch 13\n",
      "0.5916254753651826\n",
      "Starting Epoch 14\n",
      "0.5972271432047305\n",
      "New best model found at epoch 14 with validation loss 0.586715817451477\n",
      "Starting Epoch 15\n",
      "0.5902240250421606\n",
      "Starting Epoch 16\n",
      "0.5872796592505082\n",
      "New best model found at epoch 16 with validation loss 0.5766739249229431\n",
      "Starting Epoch 17\n",
      "0.5861135047415028\n",
      "Starting Epoch 18\n",
      "0.5864297851272251\n",
      "New best model found at epoch 18 with validation loss 0.5764866471290588\n",
      "Starting Epoch 19\n",
      "0.5772494803304258\n",
      "New best model found at epoch 19 with validation loss 0.5732073783874512\n",
      "Starting Epoch 20\n",
      "0.5801032911176267\n",
      "New best model found at epoch 20 with validation loss 0.5656557679176331\n",
      "Starting Epoch 21\n",
      "0.5775211893993876\n",
      "Starting Epoch 22\n",
      "0.5809496770734373\n",
      "Starting Epoch 23\n",
      "0.5729723974414493\n",
      "Starting Epoch 24\n",
      "0.5776372344597526\n",
      "Starting Epoch 25\n",
      "0.5720101789287899\n",
      "Starting Epoch 26\n",
      "0.573832436748173\n",
      "Starting Epoch 27\n",
      "0.576298695543538\n",
      "Starting Epoch 28\n",
      "0.5770524960497151\n",
      "New best model found at epoch 28 with validation loss 0.5639225840568542\n",
      "Starting Epoch 29\n",
      "0.5712302949117578\n",
      "New best model found at epoch 29 with validation loss 0.5559465289115906\n",
      "Starting Epoch 30\n",
      "0.5720838113971378\n",
      "Starting Epoch 31\n",
      "0.5717422806698343\n",
      "Starting Epoch 32\n",
      "0.5735775608083477\n",
      "Starting Epoch 33\n",
      "0.5680494774942813\n",
      "Starting Epoch 34\n",
      "0.5706380022608716\n",
      "Starting Epoch 35\n",
      "0.5666466484899106\n",
      "New best model found at epoch 35 with validation loss 0.5542066097259521\n",
      "Starting Epoch 36\n",
      "0.5654614736204562\n",
      "New best model found at epoch 36 with validation loss 0.5505596399307251\n",
      "Starting Epoch 37\n",
      "0.570453800584959\n",
      "Starting Epoch 38\n",
      "0.5683360009089761\n",
      "New best model found at epoch 38 with validation loss 0.5501784682273865\n",
      "Starting Epoch 39\n",
      "0.5673602327056553\n",
      "Starting Epoch 40\n",
      "0.5688898369022037\n",
      "New best model found at epoch 40 with validation loss 0.5459812879562378\n",
      "Starting Epoch 41\n",
      "0.5584721357926078\n",
      "Starting Epoch 42\n",
      "0.5662437884703927\n",
      "New best model found at epoch 42 with validation loss 0.5440309643745422\n",
      "Starting Epoch 43\n",
      "0.5629925339118295\n",
      "Starting Epoch 44\n",
      "0.559524346952853\n",
      "Starting Epoch 45\n",
      "0.5620403548945552\n",
      "New best model found at epoch 45 with validation loss 0.538475751876831\n",
      "Starting Epoch 46\n",
      "0.5598405599594116\n",
      "Starting Epoch 47\n",
      "0.561265239249105\n",
      "Starting Epoch 48\n",
      "0.5578244574691938\n",
      "Starting Epoch 49\n",
      "0.5650425579236902\n",
      "Starting Epoch 50\n",
      "0.5633988250856814\n",
      "Starting Epoch 51\n",
      "0.5554660856723785\n",
      "Starting Epoch 52\n",
      "0.5540289645609648\n",
      "Starting Epoch 53\n",
      "0.5538078403991201\n",
      "New best model found at epoch 53 with validation loss 0.5347870588302612\n",
      "Starting Epoch 54\n",
      "0.5566487338231958\n",
      "Starting Epoch 55\n",
      "0.5541818725026172\n",
      "Starting Epoch 56\n",
      "0.5537525894849197\n",
      "New best model found at epoch 56 with validation loss 0.5346376895904541\n",
      "Starting Epoch 57\n",
      "0.5510338816953742\n",
      "Starting Epoch 58\n",
      "0.5507918272329413\n",
      "New best model found at epoch 58 with validation loss 0.5315458178520203\n",
      "Starting Epoch 59\n",
      "0.5485185838263967\n",
      "Starting Epoch 60\n",
      "0.5617234927156697\n",
      "Starting Epoch 61\n",
      "0.5541233588819918\n",
      "Starting Epoch 62\n",
      "0.5524934685748556\n",
      "Starting Epoch 63\n",
      "0.5467373352983723\n",
      "Starting Epoch 64\n",
      "0.5489294749239216\n",
      "Starting Epoch 65\n",
      "0.5484594171461852\n",
      "Starting Epoch 66\n",
      "0.5510287945685179\n",
      "New best model found at epoch 66 with validation loss 0.5293169617652893\n",
      "Starting Epoch 67\n",
      "0.5483883632266003\n",
      "Starting Epoch 68\n",
      "0.5512046593686809\n",
      "New best model found at epoch 68 with validation loss 0.5234462022781372\n",
      "Starting Epoch 69\n",
      "0.5446845163469729\n",
      "Starting Epoch 70\n",
      "0.5480643420115762\n",
      "Starting Epoch 71\n",
      "0.5438262561093206\n",
      "Starting Epoch 72\n",
      "0.544754182514937\n",
      "Starting Epoch 73\n",
      "0.5460221132506495\n",
      "Starting Epoch 74\n",
      "0.549763191005458\n",
      "Starting Epoch 75\n",
      "0.5417189520338307\n",
      "Starting Epoch 76\n",
      "0.5423797174640324\n",
      "Starting Epoch 77\n",
      "0.5427769033805184\n",
      "Starting Epoch 78\n",
      "0.5440548658370972\n",
      "Starting Epoch 79\n",
      "0.5413894964301068\n",
      "Starting Epoch 80\n",
      "0.5397843951764314\n",
      "Starting Epoch 81\n",
      "0.5383195345816405\n",
      "New best model found at epoch 81 with validation loss 0.5188010931015015\n",
      "Starting Epoch 82\n",
      "0.5405617641366046\n",
      "Starting Epoch 83\n",
      "0.5448048658992933\n",
      "Starting Epoch 84\n",
      "0.5352256790451382\n",
      "Starting Epoch 85\n",
      "0.5385791464992191\n",
      "Starting Epoch 86\n",
      "0.5386957720569943\n",
      "Starting Epoch 87\n",
      "0.5380876764007236\n",
      "Starting Epoch 88\n",
      "0.536172532516977\n",
      "Starting Epoch 89\n",
      "0.5392468999261442\n",
      "Starting Epoch 90\n",
      "0.5374960640202397\n",
      "Starting Epoch 91\n",
      "0.5362070915491685\n",
      "Starting Epoch 92\n",
      "0.5388337425563646\n",
      "New best model found at epoch 92 with validation loss 0.518204927444458\n",
      "Starting Epoch 93\n",
      "0.5355863700742307\n",
      "Starting Epoch 94\n",
      "0.5440028866995936\n",
      "Starting Epoch 95\n",
      "0.5338826684848123\n",
      "Starting Epoch 96\n",
      "0.5368550756703252\n",
      "Starting Epoch 97\n",
      "0.5364835767642312\n",
      "New best model found at epoch 97 with validation loss 0.5173656344413757\n",
      "Starting Epoch 98\n",
      "0.5356429348821226\n",
      "Starting Epoch 99\n",
      "0.5327409285566082\n",
      "Starting Epoch 100\n",
      "0.5347867348919744\n",
      "Starting Epoch 101\n",
      "0.5298017198624818\n",
      "Starting Epoch 102\n",
      "0.5305095094701519\n",
      "Starting Epoch 103\n",
      "0.5350320429905601\n",
      "Starting Epoch 104\n",
      "0.5390971302986145\n",
      "Starting Epoch 105\n",
      "0.5345466823681541\n",
      "Starting Epoch 106\n",
      "0.5348386557205863\n",
      "Starting Epoch 107\n",
      "0.5342493394146794\n",
      "Starting Epoch 108\n",
      "0.5339996685152468\n",
      "Starting Epoch 109\n",
      "0.5348453443983326\n",
      "Starting Epoch 110\n",
      "0.5314036672529967\n",
      "Starting Epoch 111\n",
      "0.5325440583021744\n",
      "Starting Epoch 112\n",
      "0.5302418677703195\n",
      "Starting Epoch 113\n",
      "0.5257975783037103\n",
      "New best model found at epoch 113 with validation loss 0.5152564644813538\n",
      "Starting Epoch 114\n",
      "0.5280551871527797\n",
      "Starting Epoch 115\n",
      "0.526075207668802\n",
      "Starting Epoch 116\n",
      "0.5300817476666492\n",
      "Starting Epoch 117\n",
      "0.5260154838147371\n",
      "Starting Epoch 118\n",
      "0.5291968273079913\n",
      "Starting Epoch 119\n",
      "0.5264864563941956\n",
      "New best model found at epoch 119 with validation loss 0.5133327841758728\n",
      "Starting Epoch 120\n",
      "0.5252189364122308\n",
      "Starting Epoch 121\n",
      "0.5295915227869282\n",
      "Starting Epoch 122\n",
      "0.5271045747010604\n",
      "Starting Epoch 123\n",
      "0.5286909950816113\n",
      "Starting Epoch 124\n",
      "0.5266847740048948\n",
      "Starting Epoch 125\n",
      "0.5253939123257346\n",
      "Starting Epoch 126\n",
      "0.5262228431908981\n",
      "Starting Epoch 127\n",
      "0.524173388014669\n",
      "Starting Epoch 128\n",
      "0.5276989263036976\n",
      "New best model found at epoch 128 with validation loss 0.5128993988037109\n",
      "Starting Epoch 129\n",
      "0.5259657942730448\n",
      "Starting Epoch 130\n",
      "0.5221100047878597\n",
      "Starting Epoch 131\n",
      "0.5268519611462302\n",
      "Starting Epoch 132\n",
      "0.5267979399017666\n",
      "New best model found at epoch 132 with validation loss 0.5123618245124817\n",
      "Starting Epoch 133\n",
      "0.5212889482145724\n",
      "Starting Epoch 134\n",
      "0.5227128979952439\n",
      "Starting Epoch 135\n",
      "0.52350013670714\n",
      "Starting Epoch 136\n",
      "0.5245757284371749\n",
      "Starting Epoch 137\n",
      "0.531233672214591\n",
      "Starting Epoch 138\n",
      "0.5212096014748449\n",
      "Starting Epoch 139\n",
      "0.520071980745896\n",
      "Starting Epoch 140\n",
      "0.521086555460225\n",
      "New best model found at epoch 140 with validation loss 0.5117877125740051\n",
      "Starting Epoch 141\n",
      "0.5262893827065177\n",
      "New best model found at epoch 141 with validation loss 0.5094281435012817\n",
      "Starting Epoch 142\n",
      "0.522769033908844\n",
      "Starting Epoch 143\n",
      "0.5207945354606794\n",
      "Starting Epoch 144\n",
      "0.5214933973291646\n",
      "Starting Epoch 145\n",
      "0.5185214268124622\n",
      "Starting Epoch 146\n",
      "0.5207748724066693\n",
      "New best model found at epoch 146 with validation loss 0.5060837864875793\n",
      "Starting Epoch 147\n",
      "0.5200221603331359\n",
      "Starting Epoch 148\n",
      "0.5307048636934032\n",
      "Starting Epoch 149\n",
      "0.5236829882082732\n",
      "Starting Epoch 150\n",
      "0.519290171239687\n",
      "Starting Epoch 151\n",
      "0.5228391082390494\n",
      "Starting Epoch 152\n",
      "0.5171974456828573\n",
      "Starting Epoch 153\n",
      "0.5202783851519875\n",
      "Starting Epoch 154\n",
      "0.5195253698722176\n",
      "Starting Epoch 155\n",
      "0.5168795961400737\n",
      "Starting Epoch 156\n",
      "0.5240471194619718\n",
      "Starting Epoch 157\n",
      "0.5241123826607413\n",
      "Starting Epoch 158\n",
      "0.51852035133735\n",
      "Starting Epoch 159\n",
      "0.5164115649202595\n",
      "Starting Epoch 160\n",
      "0.5199617134488147\n",
      "Starting Epoch 161\n",
      "0.5217143413813218\n",
      "Starting Epoch 162\n",
      "0.5204048765742261\n",
      "Starting Epoch 163\n",
      "0.5177688818910847\n",
      "Starting Epoch 164\n",
      "0.5160808070846226\n",
      "Starting Epoch 165\n",
      "0.516047670789387\n",
      "Starting Epoch 166\n",
      "0.5164710775665615\n",
      "Starting Epoch 167\n",
      "0.5195909466432489\n",
      "Starting Epoch 168\n",
      "0.5188565979833188\n",
      "Starting Epoch 169\n",
      "0.5139858165512914\n",
      "Starting Epoch 170\n",
      "0.5143824556599492\n",
      "Starting Epoch 171\n",
      "0.5160874568897745\n",
      "Starting Epoch 172\n",
      "0.5193820219972859\n",
      "Starting Epoch 173\n",
      "0.5171898201755856\n",
      "Starting Epoch 174\n",
      "0.5146802897038667\n",
      "Starting Epoch 175\n",
      "0.5183223667352096\n",
      "Starting Epoch 176\n",
      "0.5148714547571929\n",
      "Starting Epoch 177\n",
      "0.5139748363391213\n",
      "Starting Epoch 178\n",
      "0.5140300755915435\n",
      "Starting Epoch 179\n",
      "0.5150674179844235\n",
      "New best model found at epoch 179 with validation loss 0.5046645998954773\n",
      "Starting Epoch 180\n",
      "0.5125001241331515\n",
      "Starting Epoch 181\n",
      "0.5122628833936609\n",
      "Starting Epoch 182\n",
      "0.5119204585966857\n",
      "Starting Epoch 183\n",
      "0.512652575969696\n",
      "Starting Epoch 184\n",
      "0.5179285692132037\n",
      "Starting Epoch 185\n",
      "0.513976602450661\n",
      "Starting Epoch 186\n",
      "0.5121320369450942\n",
      "New best model found at epoch 186 with validation loss 0.5042261481285095\n",
      "Starting Epoch 187\n",
      "0.5157944002877111\n",
      "Starting Epoch 188\n",
      "0.512091013400451\n",
      "Starting Epoch 189\n",
      "0.512314639661623\n",
      "Starting Epoch 190\n",
      "0.5132424922093101\n",
      "Starting Epoch 191\n",
      "0.5138562632643658\n",
      "Starting Epoch 192\n",
      "0.5182665223660676\n",
      "Starting Epoch 193\n",
      "0.5138257107009059\n",
      "Starting Epoch 194\n",
      "0.5094746454902317\n",
      "Starting Epoch 195\n",
      "0.5159919754318569\n",
      "Starting Epoch 196\n",
      "0.5135051050911779\n",
      "Starting Epoch 197\n",
      "0.5119156228459399\n",
      "Starting Epoch 198\n",
      "0.5073610699695089\n",
      "Starting Epoch 199\n",
      "0.5107609901739203\n",
      "Starting Epoch 200\n",
      "0.5076191321663235\n",
      "Starting Epoch 201\n",
      "0.5120537540187007\n",
      "Starting Epoch 202\n",
      "0.5161429760248765\n",
      "Starting Epoch 203\n",
      "0.5090772794640582\n",
      "Starting Epoch 204\n",
      "0.509341106466625\n",
      "Starting Epoch 205\n",
      "0.5059018109155737\n",
      "Starting Epoch 206\n",
      "0.5079990210740463\n",
      "Starting Epoch 207\n",
      "0.5061830670937247\n",
      "New best model found at epoch 207 with validation loss 0.5013827085494995\n",
      "Starting Epoch 208\n",
      "0.5066385385782822\n",
      "Starting Epoch 209\n",
      "0.5092286998810975\n",
      "Starting Epoch 210\n",
      "0.5100936280644458\n",
      "Starting Epoch 211\n",
      "0.5068963636522708\n",
      "Starting Epoch 212\n",
      "0.5080903017002604\n",
      "Starting Epoch 213\n",
      "0.5095964838629183\n",
      "New best model found at epoch 213 with validation loss 0.5008316040039062\n",
      "Starting Epoch 214\n",
      "0.5056979034257971\n",
      "Starting Epoch 215\n",
      "0.5099327771560006\n",
      "Starting Epoch 216\n",
      "0.5086206158866053\n",
      "Starting Epoch 217\n",
      "0.5059466945088428\n",
      "Starting Epoch 218\n",
      "0.5071144479772319\n",
      "Starting Epoch 219\n",
      "0.5053220507891282\n",
      "Starting Epoch 220\n",
      "0.5053552635337996\n",
      "Starting Epoch 221\n",
      "0.5080679577329884\n",
      "Starting Epoch 222\n",
      "0.5050705360329669\n",
      "Starting Epoch 223\n",
      "0.5023479928141055\n",
      "Starting Epoch 224\n",
      "0.5077946859857311\n",
      "Starting Epoch 225\n",
      "0.5051749206107595\n",
      "Starting Epoch 226\n",
      "0.5030308301034181\n",
      "New best model found at epoch 226 with validation loss 0.49943968653678894\n",
      "Starting Epoch 227\n",
      "0.5066229960192805\n",
      "Starting Epoch 228\n",
      "0.5049655554087266\n",
      "Starting Epoch 229\n",
      "0.5038758658844492\n",
      "Starting Epoch 230\n",
      "0.5088367501030797\n",
      "Starting Epoch 231\n",
      "0.5071062082829683\n",
      "Starting Epoch 232\n",
      "0.5058160333529763\n",
      "Starting Epoch 233\n",
      "0.5115219445332236\n",
      "Starting Epoch 234\n",
      "0.5007210088812787\n",
      "Starting Epoch 235\n",
      "0.5063452007977859\n",
      "Starting Epoch 236\n",
      "0.5063418486843938\n",
      "Starting Epoch 237\n",
      "0.509205162525177\n",
      "Starting Epoch 238\n",
      "0.506957471370697\n",
      "Starting Epoch 239\n",
      "0.5051513845505922\n",
      "Starting Epoch 240\n",
      "0.5035082944061445\n",
      "Starting Epoch 241\n",
      "0.5038261659767317\n",
      "Starting Epoch 242\n",
      "0.5094209391137828\n",
      "Starting Epoch 243\n",
      "0.5074683337107949\n",
      "Starting Epoch 244\n",
      "0.5013251032518304\n",
      "Starting Epoch 245\n",
      "0.5074956663276838\n",
      "Starting Epoch 246\n",
      "0.5013423976690873\n",
      "Starting Epoch 247\n",
      "0.5026123316391654\n",
      "Starting Epoch 248\n",
      "0.5025082269440526\n",
      "Starting Epoch 249\n",
      "0.502016368119613\n",
      "Starting Epoch 250\n",
      "0.5053135998871016\n",
      "Starting Epoch 251\n",
      "0.49927592018376227\n",
      "Starting Epoch 252\n",
      "0.5026540147221606\n",
      "Starting Epoch 253\n",
      "0.5024279045022052\n",
      "Starting Epoch 254\n",
      "0.5069867800111356\n",
      "Starting Epoch 255\n",
      "0.5017582450224005\n",
      "Starting Epoch 256\n",
      "0.5059012679950051\n",
      "Starting Epoch 257\n",
      "0.5011043276475824\n",
      "Starting Epoch 258\n",
      "0.5001611165378405\n",
      "Starting Epoch 259\n",
      "0.50158505724824\n",
      "Starting Epoch 260\n",
      "0.5019571172154468\n",
      "Starting Epoch 261\n",
      "0.5014545191889224\n",
      "Starting Epoch 262\n",
      "0.5002574285735255\n",
      "Starting Epoch 263\n",
      "0.5048953489117001\n",
      "Starting Epoch 264\n",
      "0.5026753233826678\n",
      "Starting Epoch 265\n",
      "0.5002995055654774\n",
      "Starting Epoch 266\n",
      "0.4998957566593004\n",
      "Starting Epoch 267\n",
      "0.5028270547804625\n",
      "Starting Epoch 268\n",
      "0.5027537099693132\n",
      "Starting Epoch 269\n",
      "0.5016783812771672\n",
      "Starting Epoch 270\n",
      "0.5040068691191466\n",
      "Starting Epoch 271\n",
      "0.4986842365368553\n",
      "Starting Epoch 272\n",
      "0.5053324466166289\n",
      "New best model found at epoch 272 with validation loss 0.4986024796962738\n",
      "Starting Epoch 273\n",
      "0.49833380398542987\n",
      "Starting Epoch 274\n",
      "0.49968975911969726\n",
      "Starting Epoch 275\n",
      "0.500201095705447\n",
      "Starting Epoch 276\n",
      "0.4977727765622346\n",
      "Starting Epoch 277\n",
      "0.5043598892896072\n",
      "Starting Epoch 278\n",
      "0.506098861279695\n",
      "Starting Epoch 279\n",
      "0.5033788162729015\n",
      "Starting Epoch 280\n",
      "0.5023543627365775\n",
      "Starting Epoch 281\n",
      "0.5014452221600906\n",
      "Starting Epoch 282\n",
      "0.4962202841820924\n",
      "Starting Epoch 283\n",
      "0.4994353431722392\n",
      "New best model found at epoch 283 with validation loss 0.49611055850982666\n",
      "Starting Epoch 284\n",
      "0.5066597565360691\n",
      "Starting Epoch 285\n",
      "0.4993237282918847\n",
      "Starting Epoch 286\n",
      "0.49851877274720563\n",
      "Starting Epoch 287\n",
      "0.49710670372714166\n",
      "Starting Epoch 288\n",
      "0.49644949643508246\n",
      "Starting Epoch 289\n",
      "0.4993580463139907\n",
      "Starting Epoch 290\n",
      "0.4964329393013664\n",
      "Starting Epoch 291\n",
      "0.5001948113026826\n",
      "Starting Epoch 292\n",
      "0.5015255536722101\n",
      "Starting Epoch 293\n",
      "0.49747591692468396\n",
      "Starting Epoch 294\n",
      "0.4991388774436453\n",
      "Starting Epoch 295\n",
      "0.49922354972880817\n",
      "Starting Epoch 296\n",
      "0.49438231665155163\n",
      "Starting Epoch 297\n",
      "0.49787489486777264\n",
      "Starting Epoch 298\n",
      "0.49474536595137225\n",
      "Starting Epoch 299\n",
      "0.4984805104525193\n",
      "Starting Epoch 300\n",
      "0.4990596512089605\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-60-40-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c295c-aee2-4f37-a652-ab6ced0226f2",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 6\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 20 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f14f8113-cc0d-40cc-9144-a64e9f6fd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3f12125a-f89a-49fa-b71e-7170a7704732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.3981392513150754\n",
      "New best model found at epoch 1 with validation loss 0.7137548923492432\n",
      "Starting Epoch 2\n",
      "0.6867313747820647\n",
      "New best model found at epoch 2 with validation loss 0.6869031190872192\n",
      "Starting Epoch 3\n",
      "0.6820513035940088\n",
      "New best model found at epoch 3 with validation loss 0.6637668013572693\n",
      "Starting Epoch 4\n",
      "0.6706131644870924\n",
      "New best model found at epoch 4 with validation loss 0.6545762419700623\n",
      "Starting Epoch 5\n",
      "0.6634944262711898\n",
      "Starting Epoch 6\n",
      "0.6539458580639051\n",
      "New best model found at epoch 6 with validation loss 0.6234292387962341\n",
      "Starting Epoch 7\n",
      "0.6456809614015662\n",
      "New best model found at epoch 7 with validation loss 0.6115038394927979\n",
      "Starting Epoch 8\n",
      "0.6347038046173428\n",
      "Starting Epoch 9\n",
      "0.6176452014757239\n",
      "New best model found at epoch 9 with validation loss 0.6038001775741577\n",
      "Starting Epoch 10\n",
      "0.6216278309407441\n",
      "Starting Epoch 11\n",
      "0.6189959204715231\n",
      "New best model found at epoch 11 with validation loss 0.5992636680603027\n",
      "Starting Epoch 12\n",
      "0.6151287607524706\n",
      "New best model found at epoch 12 with validation loss 0.5751153826713562\n",
      "Starting Epoch 13\n",
      "0.6060131321782651\n",
      "Starting Epoch 14\n",
      "0.6141123978987985\n",
      "Starting Epoch 15\n",
      "0.5936599788458451\n",
      "Starting Epoch 16\n",
      "0.5968489232270614\n",
      "Starting Epoch 17\n",
      "0.6033611582673114\n",
      "Starting Epoch 18\n",
      "0.58922671235126\n",
      "New best model found at epoch 18 with validation loss 0.5575814247131348\n",
      "Starting Epoch 19\n",
      "0.5843126981154733\n",
      "Starting Epoch 20\n",
      "0.591309262358624\n",
      "New best model found at epoch 20 with validation loss 0.5544998645782471\n",
      "Starting Epoch 21\n",
      "0.5838470148003619\n",
      "Starting Epoch 22\n",
      "0.5756972769032354\n",
      "New best model found at epoch 22 with validation loss 0.5513827800750732\n",
      "Starting Epoch 23\n",
      "0.5821666030780129\n",
      "New best model found at epoch 23 with validation loss 0.5505357384681702\n",
      "Starting Epoch 24\n",
      "0.5855782783549764\n",
      "Starting Epoch 25\n",
      "0.5878676927607992\n",
      "Starting Epoch 26\n",
      "0.5710544715756956\n",
      "Starting Epoch 27\n",
      "0.5846036439356597\n",
      "Starting Epoch 28\n",
      "0.5720956973407579\n",
      "Starting Epoch 29\n",
      "0.5655876916387806\n",
      "New best model found at epoch 29 with validation loss 0.5454849004745483\n",
      "Starting Epoch 30\n",
      "0.5698817139086516\n",
      "Starting Epoch 31\n",
      "0.5692498398863751\n",
      "Starting Epoch 32\n",
      "0.5706313356109287\n",
      "Starting Epoch 33\n",
      "0.5662604207577913\n",
      "New best model found at epoch 33 with validation loss 0.5441299080848694\n",
      "Starting Epoch 34\n",
      "0.5654395702092544\n",
      "Starting Epoch 35\n",
      "0.5671428584534189\n",
      "Starting Epoch 36\n",
      "0.5674568958904432\n",
      "Starting Epoch 37\n",
      "0.5605544434941333\n",
      "Starting Epoch 38\n",
      "0.5592089684113212\n",
      "New best model found at epoch 38 with validation loss 0.5425101518630981\n",
      "Starting Epoch 39\n",
      "0.5599897750045942\n",
      "Starting Epoch 40\n",
      "0.555558786444042\n",
      "Starting Epoch 41\n",
      "0.5669302460939988\n",
      "Starting Epoch 42\n",
      "0.5656120051508364\n",
      "Starting Epoch 43\n",
      "0.5663696786631709\n",
      "New best model found at epoch 43 with validation loss 0.5358591675758362\n",
      "Starting Epoch 44\n",
      "0.5613392539646315\n",
      "Starting Epoch 45\n",
      "0.5569608652073404\n",
      "Starting Epoch 46\n",
      "0.5539274060207865\n",
      "Starting Epoch 47\n",
      "0.5578901327174642\n",
      "Starting Epoch 48\n",
      "0.5549136141072148\n",
      "Starting Epoch 49\n",
      "0.5571289023627406\n",
      "New best model found at epoch 49 with validation loss 0.5358143448829651\n",
      "Starting Epoch 50\n",
      "0.5478214919567108\n",
      "Starting Epoch 51\n",
      "0.5497435435004856\n",
      "Starting Epoch 52\n",
      "0.5514385181924571\n",
      "Starting Epoch 53\n",
      "0.5573225759941599\n",
      "New best model found at epoch 53 with validation loss 0.5319679379463196\n",
      "Starting Epoch 54\n",
      "0.5479804342207701\n",
      "Starting Epoch 55\n",
      "0.5524480757505997\n",
      "Starting Epoch 56\n",
      "0.5516909309055494\n",
      "Starting Epoch 57\n",
      "0.5499626760897429\n",
      "Starting Epoch 58\n",
      "0.5546306566051815\n",
      "Starting Epoch 59\n",
      "0.5476329520992611\n",
      "Starting Epoch 60\n",
      "0.5471087577550308\n",
      "Starting Epoch 61\n",
      "0.5477942642958268\n",
      "Starting Epoch 62\n",
      "0.549951689398807\n",
      "New best model found at epoch 62 with validation loss 0.5318053364753723\n",
      "Starting Epoch 63\n",
      "0.5452658845030743\n",
      "Starting Epoch 64\n",
      "0.5431742784769639\n",
      "New best model found at epoch 64 with validation loss 0.5286146998405457\n",
      "Starting Epoch 65\n",
      "0.5402141174544459\n",
      "Starting Epoch 66\n",
      "0.5481195294338724\n",
      "Starting Epoch 67\n",
      "0.5497564828914144\n",
      "Starting Epoch 68\n",
      "0.545510233744331\n",
      "Starting Epoch 69\n",
      "0.5455684234266696\n",
      "Starting Epoch 70\n",
      "0.5411766171455383\n",
      "Starting Epoch 71\n",
      "0.5427277256613192\n",
      "New best model found at epoch 71 with validation loss 0.5265488624572754\n",
      "Starting Epoch 72\n",
      "0.5451786038668259\n",
      "Starting Epoch 73\n",
      "0.5453427809736003\n",
      "Starting Epoch 74\n",
      "0.541582712660665\n",
      "Starting Epoch 75\n",
      "0.5388428711372873\n",
      "Starting Epoch 76\n",
      "0.5371235233286152\n",
      "Starting Epoch 77\n",
      "0.5380424312923265\n",
      "Starting Epoch 78\n",
      "0.5465298735577128\n",
      "New best model found at epoch 78 with validation loss 0.5254082083702087\n",
      "Starting Epoch 79\n",
      "0.5397728331710981\n",
      "Starting Epoch 80\n",
      "0.5370844136113706\n",
      "Starting Epoch 81\n",
      "0.5387310048808223\n",
      "Starting Epoch 82\n",
      "0.5405153243438058\n",
      "Starting Epoch 83\n",
      "0.5349070675995039\n",
      "Starting Epoch 84\n",
      "0.5349328647489133\n",
      "Starting Epoch 85\n",
      "0.538715660572052\n",
      "New best model found at epoch 85 with validation loss 0.5228826403617859\n",
      "Starting Epoch 86\n",
      "0.5354392684024313\n",
      "Starting Epoch 87\n",
      "0.5355582029923148\n",
      "Starting Epoch 88\n",
      "0.5340334397295247\n",
      "Starting Epoch 89\n",
      "0.5330995891405188\n",
      "Starting Epoch 90\n",
      "0.5358105262984401\n",
      "Starting Epoch 91\n",
      "0.5344249243321626\n",
      "Starting Epoch 92\n",
      "0.533334871997004\n",
      "New best model found at epoch 92 with validation loss 0.5220555067062378\n",
      "Starting Epoch 93\n",
      "0.5386946745540785\n",
      "Starting Epoch 94\n",
      "0.5359119202779687\n",
      "Starting Epoch 95\n",
      "0.5353057319703309\n",
      "Starting Epoch 96\n",
      "0.5390937082145525\n",
      "Starting Epoch 97\n",
      "0.5349800599657971\n",
      "New best model found at epoch 97 with validation loss 0.5188807845115662\n",
      "Starting Epoch 98\n",
      "0.5306834721046946\n",
      "Starting Epoch 99\n",
      "0.5307714550391488\n",
      "Starting Epoch 100\n",
      "0.5331491620644279\n",
      "Starting Epoch 101\n",
      "0.5308616174303967\n",
      "Starting Epoch 102\n",
      "0.5318509327328723\n",
      "Starting Epoch 103\n",
      "0.5310716862263887\n",
      "Starting Epoch 104\n",
      "0.5284939511962559\n",
      "Starting Epoch 105\n",
      "0.5309320403181989\n",
      "Starting Epoch 106\n",
      "0.5307070690652599\n",
      "Starting Epoch 107\n",
      "0.5326930712098661\n",
      "New best model found at epoch 107 with validation loss 0.5188093781471252\n",
      "Starting Epoch 108\n",
      "0.5301722391791965\n",
      "Starting Epoch 109\n",
      "0.5324808203655741\n",
      "Starting Epoch 110\n",
      "0.5308204876339954\n",
      "Starting Epoch 111\n",
      "0.5281428707682568\n",
      "Starting Epoch 112\n",
      "0.534270782833514\n",
      "Starting Epoch 113\n",
      "0.5292374971120254\n",
      "Starting Epoch 114\n",
      "0.5305904590565226\n",
      "Starting Epoch 115\n",
      "0.5310320646866508\n",
      "Starting Epoch 116\n",
      "0.5279824176560277\n",
      "Starting Epoch 117\n",
      "0.5281796351723049\n",
      "Starting Epoch 118\n",
      "0.5302739285904429\n",
      "Starting Epoch 119\n",
      "0.52821741933408\n",
      "New best model found at epoch 119 with validation loss 0.5173661112785339\n",
      "Starting Epoch 120\n",
      "0.5274129004582114\n",
      "Starting Epoch 121\n",
      "0.5280941426753998\n",
      "Starting Epoch 122\n",
      "0.5282737185125765\n",
      "New best model found at epoch 122 with validation loss 0.5171869993209839\n",
      "Starting Epoch 123\n",
      "0.5273446051970773\n",
      "Starting Epoch 124\n",
      "0.5243538786535678\n",
      "New best model found at epoch 124 with validation loss 0.5163183808326721\n",
      "Starting Epoch 125\n",
      "0.526117909213771\n",
      "Starting Epoch 126\n",
      "0.5260354241599208\n",
      "Starting Epoch 127\n",
      "0.5259515811567721\n",
      "Starting Epoch 128\n",
      "0.5262229753577191\n",
      "New best model found at epoch 128 with validation loss 0.5161651968955994\n",
      "Starting Epoch 129\n",
      "0.5246039641940076\n",
      "Starting Epoch 130\n",
      "0.5260971616143766\n",
      "Starting Epoch 131\n",
      "0.5248430021431135\n",
      "Starting Epoch 132\n",
      "0.5245335166868956\n",
      "Starting Epoch 133\n",
      "0.5251486210719399\n",
      "Starting Epoch 134\n",
      "0.5237759429475536\n",
      "Starting Epoch 135\n",
      "0.5263773060363272\n",
      "Starting Epoch 136\n",
      "0.5250940206258193\n",
      "New best model found at epoch 136 with validation loss 0.5128964185714722\n",
      "Starting Epoch 137\n",
      "0.5247130173703899\n",
      "Starting Epoch 138\n",
      "0.5265864159749902\n",
      "Starting Epoch 139\n",
      "0.5272417716358019\n",
      "Starting Epoch 140\n",
      "0.523170442684837\n",
      "Starting Epoch 141\n",
      "0.525170685156532\n",
      "Starting Epoch 142\n",
      "0.5242747729239257\n",
      "Starting Epoch 143\n",
      "0.5247056561967601\n",
      "Starting Epoch 144\n",
      "0.5220799394275831\n",
      "Starting Epoch 145\n",
      "0.5258528033028478\n",
      "Starting Epoch 146\n",
      "0.5244571035322936\n",
      "Starting Epoch 147\n",
      "0.5253068623335465\n",
      "Starting Epoch 148\n",
      "0.5243673480075338\n",
      "Starting Epoch 149\n",
      "0.5262127453866212\n",
      "Starting Epoch 150\n",
      "0.5236381784729336\n",
      "Starting Epoch 151\n",
      "0.5210199407909227\n",
      "Starting Epoch 152\n",
      "0.5225946281267249\n",
      "Starting Epoch 153\n",
      "0.5219732263813848\n",
      "Starting Epoch 154\n",
      "0.5209395885467529\n",
      "Starting Epoch 155\n",
      "0.5229063124760337\n",
      "Starting Epoch 156\n",
      "0.5197499990463257\n",
      "Starting Epoch 157\n",
      "0.520785971828129\n",
      "New best model found at epoch 157 with validation loss 0.5107943415641785\n",
      "Starting Epoch 158\n",
      "0.5211453010206637\n",
      "Starting Epoch 159\n",
      "0.5214324865652167\n",
      "Starting Epoch 160\n",
      "0.5196534887604092\n",
      "Starting Epoch 161\n",
      "0.5212775805722112\n",
      "Starting Epoch 162\n",
      "0.5183228021082671\n",
      "Starting Epoch 163\n",
      "0.5184772338556207\n",
      "Starting Epoch 164\n",
      "0.5196103505466295\n",
      "Starting Epoch 165\n",
      "0.5180297416189442\n",
      "New best model found at epoch 165 with validation loss 0.5104511380195618\n",
      "Starting Epoch 166\n",
      "0.5198260584603185\n",
      "Starting Epoch 167\n",
      "0.5218011309271273\n",
      "Starting Epoch 168\n",
      "0.5179208335669144\n",
      "Starting Epoch 169\n",
      "0.5174076388711515\n",
      "Starting Epoch 170\n",
      "0.5189343055953151\n",
      "Starting Epoch 171\n",
      "0.5170502882936726\n",
      "Starting Epoch 172\n",
      "0.5164644044378529\n",
      "Starting Epoch 173\n",
      "0.5178084477134373\n",
      "Starting Epoch 174\n",
      "0.5168020673420118\n",
      "Starting Epoch 175\n",
      "0.512887267962746\n",
      "Starting Epoch 176\n",
      "0.5166599154472351\n",
      "New best model found at epoch 176 with validation loss 0.5056114196777344\n",
      "Starting Epoch 177\n",
      "0.5123870372772217\n",
      "Starting Epoch 178\n",
      "0.5186352729797363\n",
      "Starting Epoch 179\n",
      "0.5148822885492573\n",
      "Starting Epoch 180\n",
      "0.5139421911343284\n",
      "Starting Epoch 181\n",
      "0.5145786456439806\n",
      "New best model found at epoch 181 with validation loss 0.503902018070221\n",
      "Starting Epoch 182\n",
      "0.51527724577033\n",
      "Starting Epoch 183\n",
      "0.5141827671424203\n",
      "Starting Epoch 184\n",
      "0.5125761330127716\n",
      "New best model found at epoch 184 with validation loss 0.5025942325592041\n",
      "Starting Epoch 185\n",
      "0.514433908721675\n",
      "Starting Epoch 186\n",
      "0.5110300299913987\n",
      "Starting Epoch 187\n",
      "0.5120526435582534\n",
      "Starting Epoch 188\n",
      "0.5114027041455974\n",
      "Starting Epoch 189\n",
      "0.519351989030838\n",
      "Starting Epoch 190\n",
      "0.5123975743418154\n",
      "Starting Epoch 191\n",
      "0.5087694823741913\n",
      "New best model found at epoch 191 with validation loss 0.5013473033905029\n",
      "Starting Epoch 192\n",
      "0.5100604451220968\n",
      "Starting Epoch 193\n",
      "0.5100502060807269\n",
      "New best model found at epoch 193 with validation loss 0.5001816749572754\n",
      "Starting Epoch 194\n",
      "0.5116427722184554\n",
      "Starting Epoch 195\n",
      "0.5096804370050845\n",
      "Starting Epoch 196\n",
      "0.5133120909981106\n",
      "Starting Epoch 197\n",
      "0.5087169227392777\n",
      "Starting Epoch 198\n",
      "0.5105464976766835\n",
      "Starting Epoch 199\n",
      "0.5086043101289998\n",
      "New best model found at epoch 199 with validation loss 0.49905383586883545\n",
      "Starting Epoch 200\n",
      "0.5067633494086887\n",
      "Starting Epoch 201\n",
      "0.5098803043365479\n",
      "Starting Epoch 202\n",
      "0.5088569664436838\n",
      "Starting Epoch 203\n",
      "0.5064540220343549\n",
      "Starting Epoch 204\n",
      "0.5054521146027938\n",
      "New best model found at epoch 204 with validation loss 0.49747055768966675\n",
      "Starting Epoch 205\n",
      "0.5060684706853784\n",
      "Starting Epoch 206\n",
      "0.5112545075623885\n",
      "New best model found at epoch 206 with validation loss 0.49730798602104187\n",
      "Starting Epoch 207\n",
      "0.5073521396388179\n",
      "Starting Epoch 208\n",
      "0.5073590123135111\n",
      "Starting Epoch 209\n",
      "0.5078249210896699\n",
      "Starting Epoch 210\n",
      "0.5055160328097965\n",
      "Starting Epoch 211\n",
      "0.5056951551333718\n",
      "Starting Epoch 212\n",
      "0.5054692859235017\n",
      "Starting Epoch 213\n",
      "0.5041521878346152\n",
      "New best model found at epoch 213 with validation loss 0.49540209770202637\n",
      "Starting Epoch 214\n",
      "0.50629414294077\n",
      "Starting Epoch 215\n",
      "0.5042534276195194\n",
      "Starting Epoch 216\n",
      "0.5026104761206586\n",
      "Starting Epoch 217\n",
      "0.5025666006233381\n",
      "Starting Epoch 218\n",
      "0.5013136215831923\n",
      "Starting Epoch 219\n",
      "0.5049385130405426\n",
      "Starting Epoch 220\n",
      "0.5037038209645645\n",
      "Starting Epoch 221\n",
      "0.5093563043552897\n",
      "Starting Epoch 222\n",
      "0.502759601758874\n",
      "Starting Epoch 223\n",
      "0.5025497869304989\n",
      "Starting Epoch 224\n",
      "0.502415313668873\n",
      "New best model found at epoch 224 with validation loss 0.4936770498752594\n",
      "Starting Epoch 225\n",
      "0.500111012355141\n",
      "Starting Epoch 226\n",
      "0.49915892922359967\n",
      "Starting Epoch 227\n",
      "0.500545947448067\n",
      "Starting Epoch 228\n",
      "0.5022448651168657\n",
      "Starting Epoch 229\n",
      "0.4982097485791082\n",
      "Starting Epoch 230\n",
      "0.4997990908830062\n",
      "Starting Epoch 231\n",
      "0.4984871654406838\n",
      "Starting Epoch 232\n",
      "0.5005902453609135\n",
      "Starting Epoch 233\n",
      "0.4992684657159059\n",
      "Starting Epoch 234\n",
      "0.5007827800253163\n",
      "Starting Epoch 235\n",
      "0.49833456847978674\n",
      "Starting Epoch 236\n",
      "0.5016551315784454\n",
      "Starting Epoch 237\n",
      "0.501347040352614\n",
      "Starting Epoch 238\n",
      "0.5008025091627369\n",
      "Starting Epoch 239\n",
      "0.49716397731200507\n",
      "Starting Epoch 240\n",
      "0.5002655581287716\n",
      "Starting Epoch 241\n",
      "0.4978055617083674\n",
      "Starting Epoch 242\n",
      "0.4983622017114059\n",
      "New best model found at epoch 242 with validation loss 0.4928981065750122\n",
      "Starting Epoch 243\n",
      "0.4987481301245482\n",
      "Starting Epoch 244\n",
      "0.49690008811328723\n",
      "Starting Epoch 245\n",
      "0.5013072957163272\n",
      "Starting Epoch 246\n",
      "0.4979553961235544\n",
      "Starting Epoch 247\n",
      "0.4981290620306264\n",
      "Starting Epoch 248\n",
      "0.49436024997545325\n",
      "Starting Epoch 249\n",
      "0.4982678164606509\n",
      "Starting Epoch 250\n",
      "0.49829375873441284\n",
      "Starting Epoch 251\n",
      "0.5013057498828225\n",
      "Starting Epoch 252\n",
      "0.4987305571203646\n",
      "Starting Epoch 253\n",
      "0.495017075020334\n",
      "Starting Epoch 254\n",
      "0.4920893790929214\n",
      "Starting Epoch 255\n",
      "0.4960957389810811\n",
      "Starting Epoch 256\n",
      "0.49456770912460657\n",
      "New best model found at epoch 256 with validation loss 0.49214795231819153\n",
      "Starting Epoch 257\n",
      "0.49868879110916803\n",
      "Starting Epoch 258\n",
      "0.4999507108460302\n",
      "New best model found at epoch 258 with validation loss 0.49048155546188354\n",
      "Starting Epoch 259\n",
      "0.4986125412194625\n",
      "Starting Epoch 260\n",
      "0.4961851912996043\n",
      "Starting Epoch 261\n",
      "0.4935286589290785\n",
      "Starting Epoch 262\n",
      "0.49518652584241785\n",
      "Starting Epoch 263\n",
      "0.4939206579457159\n",
      "Starting Epoch 264\n",
      "0.4937945189683334\n",
      "Starting Epoch 265\n",
      "0.49389069883719733\n",
      "Starting Epoch 266\n",
      "0.49543962012166565\n",
      "Starting Epoch 267\n",
      "0.49282330663307855\n",
      "Starting Epoch 268\n",
      "0.4926209333150283\n",
      "Starting Epoch 269\n",
      "0.4950433930625086\n",
      "Starting Epoch 270\n",
      "0.4945165165092634\n",
      "Starting Epoch 271\n",
      "0.4932990359223407\n",
      "Starting Epoch 272\n",
      "0.4923234180263851\n",
      "Starting Epoch 273\n",
      "0.49069835439972254\n",
      "Starting Epoch 274\n",
      "0.4945145962030991\n",
      "Starting Epoch 275\n",
      "0.4965964620528014\n",
      "Starting Epoch 276\n",
      "0.4958982480608899\n",
      "Starting Epoch 277\n",
      "0.49752912184466486\n",
      "Starting Epoch 278\n",
      "0.4949435513952504\n",
      "Starting Epoch 279\n",
      "0.4948453371939452\n",
      "Starting Epoch 280\n",
      "0.4899719279745351\n",
      "Starting Epoch 281\n",
      "0.49228857652000757\n",
      "Starting Epoch 282\n",
      "0.4900973387386488\n",
      "Starting Epoch 283\n",
      "0.4922453631525454\n",
      "Starting Epoch 284\n",
      "0.4934750380723373\n",
      "Starting Epoch 285\n",
      "0.49136023288187775\n",
      "Starting Epoch 286\n",
      "0.4926983778891356\n",
      "Starting Epoch 287\n",
      "0.4908771126166634\n",
      "Starting Epoch 288\n",
      "0.4911828779655954\n",
      "Starting Epoch 289\n",
      "0.4943244353584621\n",
      "Starting Epoch 290\n",
      "0.49392181375752325\n",
      "Starting Epoch 291\n",
      "0.49260577429895813\n",
      "Starting Epoch 292\n",
      "0.4965493484683659\n",
      "Starting Epoch 293\n",
      "0.4913960682309192\n",
      "Starting Epoch 294\n",
      "0.4925961740638899\n",
      "Starting Epoch 295\n",
      "0.4901443538458451\n",
      "Starting Epoch 296\n",
      "0.49127336559088336\n",
      "Starting Epoch 297\n",
      "0.4898141505925552\n",
      "Starting Epoch 298\n",
      "0.48745697348014166\n",
      "Starting Epoch 299\n",
      "0.4918461506781371\n",
      "New best model found at epoch 299 with validation loss 0.48946523666381836\n",
      "Starting Epoch 300\n",
      "0.48828360308771546\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-60-20-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ed3fe",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 7\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 80 - 50 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4e741854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "06dabf84-2f16-43d6-be8a-2baaabd03045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.2473901121512703\n",
      "New best model found at epoch 1 with validation loss 0.6674272418022156\n",
      "Starting Epoch 2\n",
      "0.6501548627148503\n",
      "New best model found at epoch 2 with validation loss 0.6454222798347473\n",
      "Starting Epoch 3\n",
      "0.6368112071700718\n",
      "Starting Epoch 4\n",
      "0.6273535723271577\n",
      "New best model found at epoch 4 with validation loss 0.6115542054176331\n",
      "Starting Epoch 5\n",
      "0.6179240890171217\n",
      "New best model found at epoch 5 with validation loss 0.6113774180412292\n",
      "Starting Epoch 6\n",
      "0.5987222946208456\n",
      "New best model found at epoch 6 with validation loss 0.5911775231361389\n",
      "Starting Epoch 7\n",
      "0.6155067915501802\n",
      "New best model found at epoch 7 with validation loss 0.5816092491149902\n",
      "Starting Epoch 8\n",
      "0.5925653589808423\n",
      "New best model found at epoch 8 with validation loss 0.5809639096260071\n",
      "Starting Epoch 9\n",
      "0.5844087522962819\n",
      "New best model found at epoch 9 with validation loss 0.569352924823761\n",
      "Starting Epoch 10\n",
      "0.5875321600748145\n",
      "Starting Epoch 11\n",
      "0.5956388996995013\n",
      "New best model found at epoch 11 with validation loss 0.5676634311676025\n",
      "Starting Epoch 12\n",
      "0.5821716863176097\n",
      "Starting Epoch 13\n",
      "0.581257744975712\n",
      "New best model found at epoch 13 with validation loss 0.5659815669059753\n",
      "Starting Epoch 14\n",
      "0.574089615241341\n",
      "New best model found at epoch 14 with validation loss 0.5656097531318665\n",
      "Starting Epoch 15\n",
      "0.5717074663742728\n",
      "Starting Epoch 16\n",
      "0.5681940770667532\n",
      "Starting Epoch 17\n",
      "0.5809618105059084\n",
      "New best model found at epoch 17 with validation loss 0.5643091201782227\n",
      "Starting Epoch 18\n",
      "0.5724572876225347\n",
      "New best model found at epoch 18 with validation loss 0.5602394938468933\n",
      "Starting Epoch 19\n",
      "0.5773359809232794\n",
      "New best model found at epoch 19 with validation loss 0.5593838095664978\n",
      "Starting Epoch 20\n",
      "0.5625930169354314\n",
      "New best model found at epoch 20 with validation loss 0.5527539849281311\n",
      "Starting Epoch 21\n",
      "0.5610632598400116\n",
      "Starting Epoch 22\n",
      "0.5595689001290695\n",
      "New best model found at epoch 22 with validation loss 0.5456421375274658\n",
      "Starting Epoch 23\n",
      "0.5601367069327313\n",
      "Starting Epoch 24\n",
      "0.5511455380398295\n",
      "Starting Epoch 25\n",
      "0.5634038033692733\n",
      "Starting Epoch 26\n",
      "0.5554077897382819\n",
      "Starting Epoch 27\n",
      "0.5589195774949115\n",
      "Starting Epoch 28\n",
      "0.5506283291008162\n",
      "New best model found at epoch 28 with validation loss 0.5420835018157959\n",
      "Starting Epoch 29\n",
      "0.5594868297162263\n",
      "Starting Epoch 30\n",
      "0.5498592205669569\n",
      "Starting Epoch 31\n",
      "0.554180401822795\n",
      "Starting Epoch 32\n",
      "0.5482808455176975\n",
      "New best model found at epoch 32 with validation loss 0.5268140435218811\n",
      "Starting Epoch 33\n",
      "0.5408470047556836\n",
      "Starting Epoch 34\n",
      "0.5454143233921217\n",
      "Starting Epoch 35\n",
      "0.5411788497282111\n",
      "New best model found at epoch 35 with validation loss 0.5180572867393494\n",
      "Starting Epoch 36\n",
      "0.5445642471313477\n",
      "Starting Epoch 37\n",
      "0.5470363471819006\n",
      "New best model found at epoch 37 with validation loss 0.5156806707382202\n",
      "Starting Epoch 38\n",
      "0.5388075553852579\n",
      "Starting Epoch 39\n",
      "0.5357355138529902\n",
      "Starting Epoch 40\n",
      "0.5417667990145476\n",
      "Starting Epoch 41\n",
      "0.5331687421902366\n",
      "New best model found at epoch 41 with validation loss 0.5131886005401611\n",
      "Starting Epoch 42\n",
      "0.5326799374559651\n",
      "Starting Epoch 43\n",
      "0.5317928246829821\n",
      "New best model found at epoch 43 with validation loss 0.5079138875007629\n",
      "Starting Epoch 44\n",
      "0.5397374448568925\n",
      "Starting Epoch 45\n",
      "0.5307077104630677\n",
      "Starting Epoch 46\n",
      "0.5302624080492102\n",
      "Starting Epoch 47\n",
      "0.5288941264152527\n",
      "Starting Epoch 48\n",
      "0.5254752661870874\n",
      "Starting Epoch 49\n",
      "0.5313000355077826\n",
      "Starting Epoch 50\n",
      "0.5259325037831846\n",
      "Starting Epoch 51\n",
      "0.5242919908917468\n",
      "New best model found at epoch 51 with validation loss 0.5029261112213135\n",
      "Starting Epoch 52\n",
      "0.5250270340753638\n",
      "Starting Epoch 53\n",
      "0.5209901047789532\n",
      "New best model found at epoch 53 with validation loss 0.49340248107910156\n",
      "Starting Epoch 54\n",
      "0.5234003092931665\n",
      "Starting Epoch 55\n",
      "0.5268344360849132\n",
      "Starting Epoch 56\n",
      "0.5242347859818003\n",
      "Starting Epoch 57\n",
      "0.5207325569961382\n",
      "Starting Epoch 58\n",
      "0.519081685854041\n",
      "Starting Epoch 59\n",
      "0.523706456889277\n",
      "New best model found at epoch 59 with validation loss 0.492274671792984\n",
      "Starting Epoch 60\n",
      "0.5190112098403599\n",
      "Starting Epoch 61\n",
      "0.5156880383906157\n",
      "Starting Epoch 62\n",
      "0.5189608659433282\n",
      "Starting Epoch 63\n",
      "0.5168073371700619\n",
      "Starting Epoch 64\n",
      "0.515955810961516\n",
      "New best model found at epoch 64 with validation loss 0.48725444078445435\n",
      "Starting Epoch 65\n",
      "0.5170208358246348\n",
      "New best model found at epoch 65 with validation loss 0.4848168194293976\n",
      "Starting Epoch 66\n",
      "0.5124313468518464\n",
      "Starting Epoch 67\n",
      "0.5218523779641027\n",
      "Starting Epoch 68\n",
      "0.5086754612300707\n",
      "Starting Epoch 69\n",
      "0.5106379001036935\n",
      "Starting Epoch 70\n",
      "0.5126460324163022\n",
      "Starting Epoch 71\n",
      "0.50939047595729\n",
      "Starting Epoch 72\n",
      "0.508143618055012\n",
      "Starting Epoch 73\n",
      "0.5061372855435247\n",
      "New best model found at epoch 73 with validation loss 0.4840365946292877\n",
      "Starting Epoch 74\n",
      "0.5092773320882217\n",
      "Starting Epoch 75\n",
      "0.5070620749307715\n",
      "Starting Epoch 76\n",
      "0.5058157392170118\n",
      "Starting Epoch 77\n",
      "0.5048795977364415\n",
      "New best model found at epoch 77 with validation loss 0.482016384601593\n",
      "Starting Epoch 78\n",
      "0.500801998635997\n",
      "Starting Epoch 79\n",
      "0.4990669113138448\n",
      "New best model found at epoch 79 with validation loss 0.47491252422332764\n",
      "Starting Epoch 80\n",
      "0.5012439774430316\n",
      "Starting Epoch 81\n",
      "0.5044283231963282\n",
      "Starting Epoch 82\n",
      "0.5064275329527648\n",
      "Starting Epoch 83\n",
      "0.4996711844983308\n",
      "Starting Epoch 84\n",
      "0.49220840827278467\n",
      "Starting Epoch 85\n",
      "0.49876464968142303\n",
      "New best model found at epoch 85 with validation loss 0.47329920530319214\n",
      "Starting Epoch 86\n",
      "0.49254006017809326\n",
      "Starting Epoch 87\n",
      "0.4925420763699905\n",
      "Starting Epoch 88\n",
      "0.4946086626985799\n",
      "New best model found at epoch 88 with validation loss 0.47216370701789856\n",
      "Starting Epoch 89\n",
      "0.4935609426187432\n",
      "Starting Epoch 90\n",
      "0.4958856416785199\n",
      "Starting Epoch 91\n",
      "0.49140773260075116\n",
      "Starting Epoch 92\n",
      "0.4953064192896304\n",
      "Starting Epoch 93\n",
      "0.492673828550007\n",
      "Starting Epoch 94\n",
      "0.49340633853622107\n",
      "Starting Epoch 95\n",
      "0.4932987378991168\n",
      "Starting Epoch 96\n",
      "0.4991955251797386\n",
      "Starting Epoch 97\n",
      "0.49136207285134686\n",
      "Starting Epoch 98\n",
      "0.498784170202587\n",
      "New best model found at epoch 98 with validation loss 0.458259642124176\n",
      "Starting Epoch 99\n",
      "0.4882606371589329\n",
      "Starting Epoch 100\n",
      "0.4903762107310088\n",
      "Starting Epoch 101\n",
      "0.491409200689067\n",
      "New best model found at epoch 101 with validation loss 0.4563944339752197\n",
      "Starting Epoch 102\n",
      "0.48659957491833233\n",
      "Starting Epoch 103\n",
      "0.4874388109082761\n",
      "New best model found at epoch 103 with validation loss 0.45575013756752014\n",
      "Starting Epoch 104\n",
      "0.4858839434126149\n",
      "Starting Epoch 105\n",
      "0.49056810011034424\n",
      "Starting Epoch 106\n",
      "0.48640068328898883\n",
      "Starting Epoch 107\n",
      "0.4838859866494718\n",
      "Starting Epoch 108\n",
      "0.4854077567224917\n",
      "Starting Epoch 109\n",
      "0.4842871272045633\n",
      "Starting Epoch 110\n",
      "0.48078924547071045\n",
      "Starting Epoch 111\n",
      "0.4857051528018454\n",
      "Starting Epoch 112\n",
      "0.47973910492399463\n",
      "Starting Epoch 113\n",
      "0.48557545309481415\n",
      "New best model found at epoch 113 with validation loss 0.45537763833999634\n",
      "Starting Epoch 114\n",
      "0.4851622762887374\n",
      "Starting Epoch 115\n",
      "0.49235832432042\n",
      "Starting Epoch 116\n",
      "0.4799808574759442\n",
      "Starting Epoch 117\n",
      "0.4791291757770207\n",
      "Starting Epoch 118\n",
      "0.47746352138726605\n",
      "New best model found at epoch 118 with validation loss 0.4471135437488556\n",
      "Starting Epoch 119\n",
      "0.48136568587759265\n",
      "Starting Epoch 120\n",
      "0.4799007345800814\n",
      "Starting Epoch 121\n",
      "0.4754086901312289\n",
      "Starting Epoch 122\n",
      "0.47735783328180725\n",
      "Starting Epoch 123\n",
      "0.4789975622425909\n",
      "Starting Epoch 124\n",
      "0.4769574416720349\n",
      "Starting Epoch 125\n",
      "0.4796026206534842\n",
      "Starting Epoch 126\n",
      "0.4764357273993285\n",
      "Starting Epoch 127\n",
      "0.47431317360504816\n",
      "Starting Epoch 128\n",
      "0.4777155181635981\n",
      "Starting Epoch 129\n",
      "0.4774485735789589\n",
      "Starting Epoch 130\n",
      "0.4792501965294714\n",
      "Starting Epoch 131\n",
      "0.47583084650661633\n",
      "Starting Epoch 132\n",
      "0.4765061969342439\n",
      "Starting Epoch 133\n",
      "0.47351780663365906\n",
      "Starting Epoch 134\n",
      "0.47004362552062323\n",
      "Starting Epoch 135\n",
      "0.4742113805335501\n",
      "Starting Epoch 136\n",
      "0.4764552673567896\n",
      "Starting Epoch 137\n",
      "0.4729928775973942\n",
      "Starting Epoch 138\n",
      "0.4744562973146853\n",
      "Starting Epoch 139\n",
      "0.4770922064781189\n",
      "Starting Epoch 140\n",
      "0.4698314394639886\n",
      "Starting Epoch 141\n",
      "0.4713040862394416\n",
      "Starting Epoch 142\n",
      "0.4751200598219167\n",
      "Starting Epoch 143\n",
      "0.47479433857876324\n",
      "Starting Epoch 144\n",
      "0.4704696561979211\n",
      "Starting Epoch 145\n",
      "0.47015687045843707\n",
      "Starting Epoch 146\n",
      "0.4665786338889081\n",
      "Starting Epoch 147\n",
      "0.47218261723933014\n",
      "Starting Epoch 148\n",
      "0.46794868811317114\n",
      "Starting Epoch 149\n",
      "0.4699675311212954\n",
      "Starting Epoch 150\n",
      "0.4716884221719659\n",
      "Starting Epoch 151\n",
      "0.4638611777969029\n",
      "Starting Epoch 152\n",
      "0.46397634044937464\n",
      "Starting Epoch 153\n",
      "0.46645602454309876\n",
      "Starting Epoch 154\n",
      "0.4676918789096501\n",
      "Starting Epoch 155\n",
      "0.4633812502674434\n",
      "Starting Epoch 156\n",
      "0.46519619744756946\n",
      "Starting Epoch 157\n",
      "0.4629896011041558\n",
      "Starting Epoch 158\n",
      "0.4615318904752317\n",
      "Starting Epoch 159\n",
      "0.471752326125684\n",
      "Starting Epoch 160\n",
      "0.46601385266884515\n",
      "Starting Epoch 161\n",
      "0.46486233369163843\n",
      "New best model found at epoch 161 with validation loss 0.4407161772251129\n",
      "Starting Epoch 162\n",
      "0.4630490126817123\n",
      "Starting Epoch 163\n",
      "0.45883942686993145\n",
      "Starting Epoch 164\n",
      "0.46504092346067016\n",
      "Starting Epoch 165\n",
      "0.459433253692544\n",
      "New best model found at epoch 165 with validation loss 0.43356630206108093\n",
      "Starting Epoch 166\n",
      "0.463405676510023\n",
      "Starting Epoch 167\n",
      "0.4643569575703662\n",
      "Starting Epoch 168\n",
      "0.45987332126368646\n",
      "Starting Epoch 169\n",
      "0.4578724633092466\n",
      "Starting Epoch 170\n",
      "0.4547615064227063\n",
      "New best model found at epoch 170 with validation loss 0.4319159686565399\n",
      "Starting Epoch 171\n",
      "0.4609359217726666\n",
      "Starting Epoch 172\n",
      "0.46376437207926874\n",
      "Starting Epoch 173\n",
      "0.46257979584776837\n",
      "Starting Epoch 174\n",
      "0.4586848875750666\n",
      "Starting Epoch 175\n",
      "0.46017122398252075\n",
      "Starting Epoch 176\n",
      "0.45952853042146435\n",
      "Starting Epoch 177\n",
      "0.45632261167401855\n",
      "Starting Epoch 178\n",
      "0.456331932026407\n",
      "Starting Epoch 179\n",
      "0.4574858546257019\n",
      "Starting Epoch 180\n",
      "0.4564748121344525\n",
      "Starting Epoch 181\n",
      "0.4575345840143121\n",
      "Starting Epoch 182\n",
      "0.45967943901601044\n",
      "Starting Epoch 183\n",
      "0.4555652037910793\n",
      "Starting Epoch 184\n",
      "0.45343612587970233\n",
      "Starting Epoch 185\n",
      "0.45700963035873743\n",
      "Starting Epoch 186\n",
      "0.45920241008634155\n",
      "Starting Epoch 187\n",
      "0.45682996900185296\n",
      "Starting Epoch 188\n",
      "0.4570793937081876\n",
      "Starting Epoch 189\n",
      "0.457051043925078\n",
      "Starting Epoch 190\n",
      "0.45473801312239276\n",
      "Starting Epoch 191\n",
      "0.45746359358663147\n",
      "Starting Epoch 192\n",
      "0.45276655839837116\n",
      "Starting Epoch 193\n",
      "0.45144894200822583\n",
      "Starting Epoch 194\n",
      "0.458186748235122\n",
      "Starting Epoch 195\n",
      "0.45095623705698096\n",
      "Starting Epoch 196\n",
      "0.45379430185193603\n",
      "Starting Epoch 197\n",
      "0.45194578429926996\n",
      "Starting Epoch 198\n",
      "0.4531225834203803\n",
      "Starting Epoch 199\n",
      "0.4519191669381183\n",
      "Starting Epoch 200\n",
      "0.45194708782693616\n",
      "Starting Epoch 201\n",
      "0.4529605494893115\n",
      "Starting Epoch 202\n",
      "0.45380296396172565\n",
      "Starting Epoch 203\n",
      "0.45061305813167407\n",
      "Starting Epoch 204\n",
      "0.4539087609104488\n",
      "Starting Epoch 205\n",
      "0.44926073240197223\n",
      "Starting Epoch 206\n",
      "0.4549010033192842\n",
      "Starting Epoch 207\n",
      "0.4516356768815414\n",
      "Starting Epoch 208\n",
      "0.4524734719939854\n",
      "Starting Epoch 209\n",
      "0.45383913879809173\n",
      "Starting Epoch 210\n",
      "0.4519711979057478\n",
      "Starting Epoch 211\n",
      "0.45260335958522296\n",
      "Starting Epoch 212\n",
      "0.450229674577713\n",
      "Starting Epoch 213\n",
      "0.45556990607925085\n",
      "Starting Epoch 214\n",
      "0.4500955291416334\n",
      "Starting Epoch 215\n",
      "0.45112803448801453\n",
      "Starting Epoch 216\n",
      "0.45165096288142\n",
      "Starting Epoch 217\n",
      "0.45223497178243555\n",
      "Starting Epoch 218\n",
      "0.45112141707669134\n",
      "Starting Epoch 219\n",
      "0.45355588845584704\n",
      "Starting Epoch 220\n",
      "0.44707149267196655\n",
      "Starting Epoch 221\n",
      "0.45388475967490155\n",
      "Starting Epoch 222\n",
      "0.4500238493732784\n",
      "Starting Epoch 223\n",
      "0.4469921394534733\n",
      "Starting Epoch 224\n",
      "0.45185490276502527\n",
      "Starting Epoch 225\n",
      "0.44552670743154443\n",
      "Starting Epoch 226\n",
      "0.4488860044790351\n",
      "Starting Epoch 227\n",
      "0.45402415161547455\n",
      "Starting Epoch 228\n",
      "0.44522501074749493\n",
      "Starting Epoch 229\n",
      "0.44807145776955976\n",
      "Starting Epoch 230\n",
      "0.4468864837418432\n",
      "Starting Epoch 231\n",
      "0.44120415008586383\n",
      "Starting Epoch 232\n",
      "0.4466015074564063\n",
      "Starting Epoch 233\n",
      "0.4454493742922078\n",
      "Starting Epoch 234\n",
      "0.44563993293306103\n",
      "Starting Epoch 235\n",
      "0.4475582047649052\n",
      "Starting Epoch 236\n",
      "0.44814115373984625\n",
      "Starting Epoch 237\n",
      "0.44660389034644415\n",
      "Starting Epoch 238\n",
      "0.4456683487995811\n",
      "Starting Epoch 239\n",
      "0.4468535107115041\n",
      "Starting Epoch 240\n",
      "0.4480698367823725\n",
      "Starting Epoch 241\n",
      "0.4438549811425416\n",
      "Starting Epoch 242\n",
      "0.44588974895684613\n",
      "Starting Epoch 243\n",
      "0.44314044843549316\n",
      "Starting Epoch 244\n",
      "0.4399644693602686\n",
      "Starting Epoch 245\n",
      "0.44252338746319647\n",
      "Starting Epoch 246\n",
      "0.44525305732436804\n",
      "Starting Epoch 247\n",
      "0.4445949585541435\n",
      "Starting Epoch 248\n",
      "0.44806032465851825\n",
      "Starting Epoch 249\n",
      "0.4404011342836463\n",
      "Starting Epoch 250\n",
      "0.44002562631731446\n",
      "New best model found at epoch 250 with validation loss 0.4297496974468231\n",
      "Starting Epoch 251\n",
      "0.4455609813980434\n",
      "Starting Epoch 252\n",
      "0.4466055644595105\n",
      "Starting Epoch 253\n",
      "0.44545531143312866\n",
      "Starting Epoch 254\n",
      "0.4484400321608004\n",
      "Starting Epoch 255\n",
      "0.4442643212235492\n",
      "Starting Epoch 256\n",
      "0.44055087929186615\n",
      "Starting Epoch 257\n",
      "0.43882429599761963\n",
      "Starting Epoch 258\n",
      "0.43844026715859125\n",
      "Starting Epoch 259\n",
      "0.43733140178348706\n",
      "Starting Epoch 260\n",
      "0.4482248101545417\n",
      "Starting Epoch 261\n",
      "0.44065766619599384\n",
      "Starting Epoch 262\n",
      "0.4415152150651683\n",
      "Starting Epoch 263\n",
      "0.4449356029862943\n",
      "Starting Epoch 264\n",
      "0.4432791963867519\n",
      "Starting Epoch 265\n",
      "0.4418367354766182\n",
      "Starting Epoch 266\n",
      "0.44261257285657135\n",
      "Starting Epoch 267\n",
      "0.4425948352917381\n",
      "Starting Epoch 268\n",
      "0.44135565343110456\n",
      "Starting Epoch 269\n",
      "0.4436497662378394\n",
      "Starting Epoch 270\n",
      "0.44284414726754895\n",
      "Starting Epoch 271\n",
      "0.4428732421087182\n",
      "Starting Epoch 272\n",
      "0.4376081591067107\n",
      "Starting Epoch 273\n",
      "0.43803873658180237\n",
      "New best model found at epoch 273 with validation loss 0.42888349294662476\n",
      "Starting Epoch 274\n",
      "0.43914244097212085\n",
      "Starting Epoch 275\n",
      "0.44520927641702734\n",
      "Starting Epoch 276\n",
      "0.4384899722493213\n",
      "Starting Epoch 277\n",
      "0.43843809547631635\n",
      "Starting Epoch 278\n",
      "0.43777517132137134\n",
      "Starting Epoch 279\n",
      "0.43768232542535535\n",
      "Starting Epoch 280\n",
      "0.4370221689991329\n",
      "Starting Epoch 281\n",
      "0.43761928444323334\n",
      "Starting Epoch 282\n",
      "0.4386973419915075\n",
      "Starting Epoch 283\n",
      "0.4404865943867227\n",
      "Starting Epoch 284\n",
      "0.4400955620019332\n",
      "Starting Epoch 285\n",
      "0.44304112506949384\n",
      "Starting Epoch 286\n",
      "0.4375735586104186\n",
      "New best model found at epoch 286 with validation loss 0.4285891652107239\n",
      "Starting Epoch 287\n",
      "0.43694004805191705\n",
      "Starting Epoch 288\n",
      "0.4380997237951859\n",
      "Starting Epoch 289\n",
      "0.4341643426729285\n",
      "Starting Epoch 290\n",
      "0.44100037605866144\n",
      "Starting Epoch 291\n",
      "0.4356745611066404\n",
      "Starting Epoch 292\n",
      "0.4382155680138132\n",
      "Starting Epoch 293\n",
      "0.43933662383452704\n",
      "Starting Epoch 294\n",
      "0.4360775364481885\n",
      "Starting Epoch 295\n",
      "0.4372010580871416\n",
      "Starting Epoch 296\n",
      "0.4345721485822097\n",
      "Starting Epoch 297\n",
      "0.43415267441583716\n",
      "Starting Epoch 298\n",
      "0.43507635722989624\n",
      "Starting Epoch 299\n",
      "0.4405768746915071\n",
      "Starting Epoch 300\n",
      "0.43903930679611536\n",
      "New best model found at epoch 300 with validation loss 0.42714959383010864\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP: 17-80-50-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "50b89812-3cab-4764-b436-e1818eb78c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.827117</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.667832</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.645688</td>\n",
       "      <td>0.622881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.672494</td>\n",
       "      <td>0.469492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.662393</td>\n",
       "      <td>0.523729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-2</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-2</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-2</th>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-2</th>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-2</th>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-2</th>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-2</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-2</th>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-2</th>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-2</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-2</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-2</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-2</th>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      acc       rec       acc       rec\n",
       "5-NN             0.818182  0.769231  0.811189  0.795763\n",
       "Decision tree    0.832168  0.776923  0.827506  0.800847\n",
       "Random forest    0.835664  0.792308  0.827117  0.816949\n",
       "SVM linear       0.667832  0.584615  0.645688  0.622881\n",
       "SVM poly         0.716783  0.507692  0.672494  0.469492\n",
       "SVM rbf          0.720280  0.561538  0.662393  0.523729\n",
       "MLP: 17-5-2      0.730769  0.669231         -         -\n",
       "MLP: 17-10-2     0.632867  0.215385         -         -\n",
       "MLP: 17-20-2     0.765734  0.761538         -         -\n",
       "MLP: 17-25-2     0.755245  0.761538         -         -\n",
       "MLP: 17-40-2     0.744755  0.738462         -         -\n",
       "MLP: 17-60-2     0.755245  0.738462         -         -\n",
       "MLP: 17-10-5-2   0.706294  0.438462         -         -\n",
       "MLP: 17-20-10-2  0.709790  0.723077         -         -\n",
       "MLP: 17-40-20-2  0.776224  0.753846         -         -\n",
       "MLP: 17-40-10-2  0.741259  0.723077         -         -\n",
       "MLP: 17-60-40-2  0.737762  0.723077         -         -\n",
       "MLP: 17-60-20-2  0.737762  0.753846         -         -\n",
       "MLP: 17-80-50-2  0.783217  0.753846         -         -"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b21b4",
   "metadata": {},
   "source": [
    "best performing model until now: 4 layers, 17-80-50-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15710149",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "171c2874-92c0-4d56-a35e-a2f3aad9ca2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "013580bf-aeae-4724-ab6d-9d4ac2496e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,9,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7416bf76-cc9b-42b5-b8d7-1bc6e55d30b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'median(container counts)', 'median(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f92d276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "383e0973-cf4c-4bf5-9f2e-697e9e1e4b7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.332543945830801\n",
      "New best model found at epoch 1 with validation loss 0.6829561591148376\n",
      "Starting Epoch 2\n",
      "0.6785789080288099\n",
      "New best model found at epoch 2 with validation loss 0.6679105162620544\n",
      "Starting Epoch 3\n",
      "0.6601132154464722\n",
      "New best model found at epoch 3 with validation loss 0.6399825215339661\n",
      "Starting Epoch 4\n",
      "0.6422504419865815\n",
      "New best model found at epoch 4 with validation loss 0.6286071538925171\n",
      "Starting Epoch 5\n",
      "0.6345615594283395\n",
      "New best model found at epoch 5 with validation loss 0.6153460144996643\n",
      "Starting Epoch 6\n",
      "0.6276082448337389\n",
      "New best model found at epoch 6 with validation loss 0.6088282465934753\n",
      "Starting Epoch 7\n",
      "0.6240859549978505\n",
      "New best model found at epoch 7 with validation loss 0.6071967482566833\n",
      "Starting Epoch 8\n",
      "0.6162219773168149\n",
      "New best model found at epoch 8 with validation loss 0.6023298501968384\n",
      "Starting Epoch 9\n",
      "0.6210519127223803\n",
      "Starting Epoch 10\n",
      "0.6177843187166296\n",
      "New best model found at epoch 10 with validation loss 0.5997055768966675\n",
      "Starting Epoch 11\n",
      "0.618342197459677\n",
      "Starting Epoch 12\n",
      "0.6122817578523055\n",
      "Starting Epoch 13\n",
      "0.6076038687125497\n",
      "Starting Epoch 14\n",
      "0.6105966386587723\n",
      "New best model found at epoch 14 with validation loss 0.5910128951072693\n",
      "Starting Epoch 15\n",
      "0.6054278301156085\n",
      "New best model found at epoch 15 with validation loss 0.5870820879936218\n",
      "Starting Epoch 16\n",
      "0.6029328988946002\n",
      "Starting Epoch 17\n",
      "0.6070469851079194\n",
      "Starting Epoch 18\n",
      "0.6042788365612859\n",
      "Starting Epoch 19\n",
      "0.6034269255140553\n",
      "Starting Epoch 20\n",
      "0.6043906963389852\n",
      "Starting Epoch 21\n",
      "0.5989043453465337\n",
      "Starting Epoch 22\n",
      "0.5949748676756154\n",
      "Starting Epoch 23\n",
      "0.5920099901116412\n",
      "Starting Epoch 24\n",
      "0.59214520972708\n",
      "New best model found at epoch 24 with validation loss 0.5839470028877258\n",
      "Starting Epoch 25\n",
      "0.5961094887360282\n",
      "Starting Epoch 26\n",
      "0.5897744142490885\n",
      "Starting Epoch 27\n",
      "0.5890679437181224\n",
      "Starting Epoch 28\n",
      "0.5925973446472831\n",
      "Starting Epoch 29\n",
      "0.5867444665535636\n",
      "Starting Epoch 30\n",
      "0.5899667428887408\n",
      "Starting Epoch 31\n",
      "0.585728222909181\n",
      "Starting Epoch 32\n",
      "0.5890561549559884\n",
      "Starting Epoch 33\n",
      "0.5861968475839366\n",
      "Starting Epoch 34\n",
      "0.5882864076158275\n",
      "Starting Epoch 35\n",
      "0.5916636430698893\n",
      "Starting Epoch 36\n",
      "0.5809197011201278\n",
      "Starting Epoch 37\n",
      "0.5909584086874257\n",
      "Starting Epoch 38\n",
      "0.5837377905845642\n",
      "Starting Epoch 39\n",
      "0.5819747655288033\n",
      "Starting Epoch 40\n",
      "0.5820333387540735\n",
      "Starting Epoch 41\n",
      "0.5836717797362286\n",
      "Starting Epoch 42\n",
      "0.5852064904959305\n",
      "Starting Epoch 43\n",
      "0.5814584027165952\n",
      "Starting Epoch 44\n",
      "0.5827618344970371\n",
      "New best model found at epoch 44 with validation loss 0.5833527445793152\n",
      "Starting Epoch 45\n",
      "0.5862924028997836\n",
      "New best model found at epoch 45 with validation loss 0.5814722180366516\n",
      "Starting Epoch 46\n",
      "0.5789365301961484\n",
      "New best model found at epoch 46 with validation loss 0.5763986110687256\n",
      "Starting Epoch 47\n",
      "0.5805128061253092\n",
      "Starting Epoch 48\n",
      "0.5843509785507036\n",
      "Starting Epoch 49\n",
      "0.5785973875418954\n",
      "Starting Epoch 50\n",
      "0.5788645537003226\n",
      "New best model found at epoch 50 with validation loss 0.5760826468467712\n",
      "Starting Epoch 51\n",
      "0.5762141709742339\n",
      "Starting Epoch 52\n",
      "0.5781949253185935\n",
      "Starting Epoch 53\n",
      "0.575396610342938\n",
      "New best model found at epoch 53 with validation loss 0.5746532082557678\n",
      "Starting Epoch 54\n",
      "0.5780231952667236\n",
      "Starting Epoch 55\n",
      "0.5766934907954672\n",
      "Starting Epoch 56\n",
      "0.574858528116475\n",
      "New best model found at epoch 56 with validation loss 0.5712396502494812\n",
      "Starting Epoch 57\n",
      "0.5824190378189087\n",
      "Starting Epoch 58\n",
      "0.5728995981423751\n",
      "New best model found at epoch 58 with validation loss 0.5705477595329285\n",
      "Starting Epoch 59\n",
      "0.5735891305881998\n",
      "Starting Epoch 60\n",
      "0.5746735567631929\n",
      "Starting Epoch 61\n",
      "0.5735259004261183\n",
      "Starting Epoch 62\n",
      "0.5776404893916586\n",
      "New best model found at epoch 62 with validation loss 0.5698222517967224\n",
      "Starting Epoch 63\n",
      "0.5747370875400045\n",
      "Starting Epoch 64\n",
      "0.5759732282680013\n",
      "Starting Epoch 65\n",
      "0.5739384487919186\n",
      "Starting Epoch 66\n",
      "0.5703346210977306\n",
      "Starting Epoch 67\n",
      "0.5740278803783915\n",
      "Starting Epoch 68\n",
      "0.5725434448408044\n",
      "New best model found at epoch 68 with validation loss 0.5676807761192322\n",
      "Starting Epoch 69\n",
      "0.572763143674187\n",
      "Starting Epoch 70\n",
      "0.5692669308703878\n",
      "Starting Epoch 71\n",
      "0.5708360192568406\n",
      "Starting Epoch 72\n",
      "0.5732193070909252\n",
      "New best model found at epoch 72 with validation loss 0.5640586614608765\n",
      "Starting Epoch 73\n",
      "0.5728397213894388\n",
      "Starting Epoch 74\n",
      "0.5714058383651401\n",
      "Starting Epoch 75\n",
      "0.5709824665733005\n",
      "Starting Epoch 76\n",
      "0.570305681746939\n",
      "Starting Epoch 77\n",
      "0.5721512903337893\n",
      "Starting Epoch 78\n",
      "0.5661937607371289\n",
      "New best model found at epoch 78 with validation loss 0.5610170364379883\n",
      "Starting Epoch 79\n",
      "0.569845077784165\n",
      "Starting Epoch 80\n",
      "0.5694996649804323\n",
      "New best model found at epoch 80 with validation loss 0.5596238374710083\n",
      "Starting Epoch 81\n",
      "0.5717650120672972\n",
      "Starting Epoch 82\n",
      "0.5706610938777095\n",
      "Starting Epoch 83\n",
      "0.5692130197649417\n",
      "Starting Epoch 84\n",
      "0.5695050656795502\n",
      "Starting Epoch 85\n",
      "0.5702539384365082\n",
      "New best model found at epoch 85 with validation loss 0.559512734413147\n",
      "Starting Epoch 86\n",
      "0.5669770823872607\n",
      "Starting Epoch 87\n",
      "0.5682447954364445\n",
      "New best model found at epoch 87 with validation loss 0.5564959049224854\n",
      "Starting Epoch 88\n",
      "0.5685450460599817\n",
      "Starting Epoch 89\n",
      "0.5698710783668186\n",
      "Starting Epoch 90\n",
      "0.566352455512337\n",
      "Starting Epoch 91\n",
      "0.5674848556518555\n",
      "Starting Epoch 92\n",
      "0.569383943858354\n",
      "Starting Epoch 93\n",
      "0.568561491758927\n",
      "Starting Epoch 94\n",
      "0.5651506431724714\n",
      "New best model found at epoch 94 with validation loss 0.5532715320587158\n",
      "Starting Epoch 95\n",
      "0.5656358249809431\n",
      "Starting Epoch 96\n",
      "0.5659428018590679\n",
      "Starting Epoch 97\n",
      "0.5644092339536418\n",
      "Starting Epoch 98\n",
      "0.5656885271487029\n",
      "Starting Epoch 99\n",
      "0.5680715869302335\n",
      "Starting Epoch 100\n",
      "0.5636530039103135\n",
      "Starting Epoch 101\n",
      "0.5634049345617709\n",
      "Starting Epoch 102\n",
      "0.5659427202266195\n",
      "New best model found at epoch 102 with validation loss 0.5512139201164246\n",
      "Starting Epoch 103\n",
      "0.5645027562328007\n",
      "Starting Epoch 104\n",
      "0.5673481329627659\n",
      "Starting Epoch 105\n",
      "0.5658018213251362\n",
      "Starting Epoch 106\n",
      "0.5617586244707522\n",
      "Starting Epoch 107\n",
      "0.5655361128889996\n",
      "Starting Epoch 108\n",
      "0.5644858194434125\n",
      "Starting Epoch 109\n",
      "0.5640951226586881\n",
      "Starting Epoch 110\n",
      "0.5631254989167919\n",
      "Starting Epoch 111\n",
      "0.5672239985155023\n",
      "Starting Epoch 112\n",
      "0.5695758487867273\n",
      "Starting Epoch 113\n",
      "0.562665978203649\n",
      "Starting Epoch 114\n",
      "0.5609299514604651\n",
      "Starting Epoch 115\n",
      "0.5624585955039315\n",
      "New best model found at epoch 115 with validation loss 0.5502691268920898\n",
      "Starting Epoch 116\n",
      "0.5660080572833186\n",
      "Starting Epoch 117\n",
      "0.5657579756301382\n",
      "Starting Epoch 118\n",
      "0.5618122336657151\n",
      "New best model found at epoch 118 with validation loss 0.5498583912849426\n",
      "Starting Epoch 119\n",
      "0.5614862442016602\n",
      "Starting Epoch 120\n",
      "0.5633653467116149\n",
      "Starting Epoch 121\n",
      "0.5666248746540236\n",
      "Starting Epoch 122\n",
      "0.565309657998707\n",
      "Starting Epoch 123\n",
      "0.5621025743691818\n",
      "Starting Epoch 124\n",
      "0.5642814143844272\n",
      "New best model found at epoch 124 with validation loss 0.5486384034156799\n",
      "Starting Epoch 125\n",
      "0.5633160640364108\n",
      "Starting Epoch 126\n",
      "0.5617679033590399\n",
      "Starting Epoch 127\n",
      "0.5601637946522754\n",
      "Starting Epoch 128\n",
      "0.5650586563607921\n",
      "Starting Epoch 129\n",
      "0.5602465168289517\n",
      "Starting Epoch 130\n",
      "0.5649459698925847\n",
      "Starting Epoch 131\n",
      "0.559934499471084\n",
      "Starting Epoch 132\n",
      "0.5638988899148029\n",
      "Starting Epoch 133\n",
      "0.5598688941934834\n",
      "Starting Epoch 134\n",
      "0.5633801662403605\n",
      "Starting Epoch 135\n",
      "0.5608718952407008\n",
      "Starting Epoch 136\n",
      "0.5636683546978495\n",
      "Starting Epoch 137\n",
      "0.5583473729050678\n",
      "New best model found at epoch 137 with validation loss 0.5476662516593933\n",
      "Starting Epoch 138\n",
      "0.5588136937307275\n",
      "New best model found at epoch 138 with validation loss 0.5440285801887512\n",
      "Starting Epoch 139\n",
      "0.5617402740146803\n",
      "Starting Epoch 140\n",
      "0.5625149011611938\n",
      "Starting Epoch 141\n",
      "0.5612475574016571\n",
      "Starting Epoch 142\n",
      "0.5614684301873912\n",
      "Starting Epoch 143\n",
      "0.5623941499253978\n",
      "Starting Epoch 144\n",
      "0.5602075418700343\n",
      "Starting Epoch 145\n",
      "0.5576650059741476\n",
      "Starting Epoch 146\n",
      "0.5592698415984279\n",
      "Starting Epoch 147\n",
      "0.5582212054211161\n",
      "Starting Epoch 148\n",
      "0.562465928170992\n",
      "Starting Epoch 149\n",
      "0.5624699670335521\n",
      "Starting Epoch 150\n",
      "0.5619750411614127\n",
      "Starting Epoch 151\n",
      "0.5616911869982014\n",
      "Starting Epoch 152\n",
      "0.5568967280180558\n",
      "Starting Epoch 153\n",
      "0.5573285377543905\n",
      "Starting Epoch 154\n",
      "0.559339595877606\n",
      "Starting Epoch 155\n",
      "0.5566003555836885\n",
      "Starting Epoch 156\n",
      "0.5585476885671201\n",
      "New best model found at epoch 156 with validation loss 0.5428217649459839\n",
      "Starting Epoch 157\n",
      "0.5603014075237772\n",
      "Starting Epoch 158\n",
      "0.5575916818950487\n",
      "Starting Epoch 159\n",
      "0.5610574807809747\n",
      "Starting Epoch 160\n",
      "0.5575998529143955\n",
      "Starting Epoch 161\n",
      "0.5586473268011342\n",
      "Starting Epoch 162\n",
      "0.5586266673129537\n",
      "Starting Epoch 163\n",
      "0.557134615338367\n",
      "Starting Epoch 164\n",
      "0.5604608395825261\n",
      "Starting Epoch 165\n",
      "0.5563473131345666\n",
      "Starting Epoch 166\n",
      "0.5561239071514296\n",
      "Starting Epoch 167\n",
      "0.5587030001308607\n",
      "Starting Epoch 168\n",
      "0.5580485385397206\n",
      "New best model found at epoch 168 with validation loss 0.542044997215271\n",
      "Starting Epoch 169\n",
      "0.5562864801158076\n",
      "Starting Epoch 170\n",
      "0.5572520429673402\n",
      "Starting Epoch 171\n",
      "0.5573632846707883\n",
      "Starting Epoch 172\n",
      "0.556061775788017\n",
      "Starting Epoch 173\n",
      "0.5540236014386882\n",
      "Starting Epoch 174\n",
      "0.5560011669345524\n",
      "Starting Epoch 175\n",
      "0.5554325606511987\n",
      "New best model found at epoch 175 with validation loss 0.541886031627655\n",
      "Starting Epoch 176\n",
      "0.5568436254625735\n",
      "Starting Epoch 177\n",
      "0.5555584715760272\n",
      "Starting Epoch 178\n",
      "0.5589778319649075\n",
      "Starting Epoch 179\n",
      "0.557467009710229\n",
      "Starting Epoch 180\n",
      "0.5567438291466754\n",
      "Starting Epoch 181\n",
      "0.5567637254362521\n",
      "Starting Epoch 182\n",
      "0.5559744135193203\n",
      "Starting Epoch 183\n",
      "0.5562877836434738\n",
      "Starting Epoch 184\n",
      "0.5551706928273906\n",
      "New best model found at epoch 184 with validation loss 0.5374339818954468\n",
      "Starting Epoch 185\n",
      "0.5533179731472678\n",
      "Starting Epoch 186\n",
      "0.5547336171502653\n",
      "Starting Epoch 187\n",
      "0.5578242255293805\n",
      "Starting Epoch 188\n",
      "0.5548176882059678\n",
      "Starting Epoch 189\n",
      "0.5543987232705821\n",
      "Starting Epoch 190\n",
      "0.5533186896987583\n",
      "Starting Epoch 191\n",
      "0.5523853587067645\n",
      "Starting Epoch 192\n",
      "0.5539380545201509\n",
      "Starting Epoch 193\n",
      "0.5533530478892119\n",
      "Starting Epoch 194\n",
      "0.5533693069997041\n",
      "Starting Epoch 195\n",
      "0.5522591691950093\n",
      "Starting Epoch 196\n",
      "0.5567715621512869\n",
      "Starting Epoch 197\n",
      "0.5539843841739323\n",
      "Starting Epoch 198\n",
      "0.552804752536442\n",
      "Starting Epoch 199\n",
      "0.5541822677073271\n",
      "Starting Epoch 200\n",
      "0.555108227159666\n",
      "Starting Epoch 201\n",
      "0.5537919531697812\n",
      "Starting Epoch 202\n",
      "0.5547137286352075\n",
      "Starting Epoch 203\n",
      "0.5521276722783628\n",
      "Starting Epoch 204\n",
      "0.5522120996661808\n",
      "Starting Epoch 205\n",
      "0.554039988828742\n",
      "New best model found at epoch 205 with validation loss 0.5362545847892761\n",
      "Starting Epoch 206\n",
      "0.5537154687487561\n",
      "Starting Epoch 207\n",
      "0.5528387686480647\n",
      "Starting Epoch 208\n",
      "0.5533524207446886\n",
      "Starting Epoch 209\n",
      "0.552143271850503\n",
      "Starting Epoch 210\n",
      "0.5534481004528378\n",
      "Starting Epoch 211\n",
      "0.552860633186672\n",
      "Starting Epoch 212\n",
      "0.5529322015202564\n",
      "Starting Epoch 213\n",
      "0.552127735770267\n",
      "Starting Epoch 214\n",
      "0.5520132274731345\n",
      "Starting Epoch 215\n",
      "0.5532941973727682\n",
      "Starting Epoch 216\n",
      "0.5504526107207589\n",
      "Starting Epoch 217\n",
      "0.5539896008761033\n",
      "Starting Epoch 218\n",
      "0.5523737124774767\n",
      "Starting Epoch 219\n",
      "0.5513848882654439\n",
      "Starting Epoch 220\n",
      "0.5522320516731428\n",
      "Starting Epoch 221\n",
      "0.5501360452693441\n",
      "Starting Epoch 222\n",
      "0.5522041800229446\n",
      "Starting Epoch 223\n",
      "0.5505041959493057\n",
      "New best model found at epoch 223 with validation loss 0.5359364748001099\n",
      "Starting Epoch 224\n",
      "0.5499471024326656\n",
      "Starting Epoch 225\n",
      "0.5529472931571628\n",
      "Starting Epoch 226\n",
      "0.5500938749831655\n",
      "Starting Epoch 227\n",
      "0.5515227006829303\n",
      "Starting Epoch 228\n",
      "0.550064856591432\n",
      "Starting Epoch 229\n",
      "0.5522865069949109\n",
      "Starting Epoch 230\n",
      "0.5488192905550417\n",
      "Starting Epoch 231\n",
      "0.5495983647263568\n",
      "Starting Epoch 232\n",
      "0.5504153435644896\n",
      "Starting Epoch 233\n",
      "0.5479807309482408\n",
      "Starting Epoch 234\n",
      "0.5479773555112921\n",
      "Starting Epoch 235\n",
      "0.5520755233971969\n",
      "Starting Epoch 236\n",
      "0.55126967119134\n",
      "Starting Epoch 237\n",
      "0.5500730613003606\n",
      "Starting Epoch 238\n",
      "0.5492348658001941\n",
      "Starting Epoch 239\n",
      "0.5498748266178629\n",
      "Starting Epoch 240\n",
      "0.5493683478106623\n",
      "New best model found at epoch 240 with validation loss 0.5339893102645874\n",
      "Starting Epoch 241\n",
      "0.5465993259264075\n",
      "Starting Epoch 242\n",
      "0.5488802803599316\n",
      "Starting Epoch 243\n",
      "0.545886376629705\n",
      "Starting Epoch 244\n",
      "0.5505949725275454\n",
      "Starting Epoch 245\n",
      "0.5477909069994221\n",
      "Starting Epoch 246\n",
      "0.5506945187630861\n",
      "New best model found at epoch 246 with validation loss 0.5331205725669861\n",
      "Starting Epoch 247\n",
      "0.5461451696312946\n",
      "Starting Epoch 248\n",
      "0.5482731150544208\n",
      "Starting Epoch 249\n",
      "0.5479417391445326\n",
      "Starting Epoch 250\n",
      "0.5470592470272727\n",
      "Starting Epoch 251\n",
      "0.5445608250472856\n",
      "Starting Epoch 252\n",
      "0.5454408396845278\n",
      "Starting Epoch 253\n",
      "0.5448906240255936\n",
      "Starting Epoch 254\n",
      "0.5468329968659774\n",
      "New best model found at epoch 254 with validation loss 0.5313212871551514\n",
      "Starting Epoch 255\n",
      "0.5449175497759944\n",
      "Starting Epoch 256\n",
      "0.5469563642273778\n",
      "Starting Epoch 257\n",
      "0.5467051384241685\n",
      "Starting Epoch 258\n",
      "0.5443522696909697\n",
      "Starting Epoch 259\n",
      "0.5444941339285477\n",
      "Starting Epoch 260\n",
      "0.5420451190160669\n",
      "Starting Epoch 261\n",
      "0.5458332105823185\n",
      "Starting Epoch 262\n",
      "0.5431828926438871\n",
      "Starting Epoch 263\n",
      "0.544462369835895\n",
      "Starting Epoch 264\n",
      "0.5490103985952295\n",
      "Starting Epoch 265\n",
      "0.543281588865363\n",
      "Starting Epoch 266\n",
      "0.5434383011382559\n",
      "Starting Epoch 267\n",
      "0.549434657977975\n",
      "Starting Epoch 268\n",
      "0.5437643152216206\n",
      "Starting Epoch 269\n",
      "0.5443539515785549\n",
      "Starting Epoch 270\n",
      "0.5413878430490908\n",
      "Starting Epoch 271\n",
      "0.5434200491594232\n",
      "Starting Epoch 272\n",
      "0.545079310303149\n",
      "Starting Epoch 273\n",
      "0.5414304875809214\n",
      "Starting Epoch 274\n",
      "0.5405743977297908\n",
      "Starting Epoch 275\n",
      "0.5383446048135343\n",
      "Starting Epoch 276\n",
      "0.541361391544342\n",
      "Starting Epoch 277\n",
      "0.5436041264430337\n",
      "Starting Epoch 278\n",
      "0.5398972475010416\n",
      "New best model found at epoch 278 with validation loss 0.530555784702301\n",
      "Starting Epoch 279\n",
      "0.5400021063244861\n",
      "Starting Epoch 280\n",
      "0.5425328936265863\n",
      "Starting Epoch 281\n",
      "0.540393089470656\n",
      "Starting Epoch 282\n",
      "0.542134341986283\n",
      "Starting Epoch 283\n",
      "0.5406028187793234\n",
      "Starting Epoch 284\n",
      "0.5384910028913746\n",
      "Starting Epoch 285\n",
      "0.5422566014787426\n",
      "Starting Epoch 286\n",
      "0.5391523669595304\n",
      "New best model found at epoch 286 with validation loss 0.5304173827171326\n",
      "Starting Epoch 287\n",
      "0.5383601655130801\n",
      "Starting Epoch 288\n",
      "0.5403034622254579\n",
      "Starting Epoch 289\n",
      "0.5410401963669321\n",
      "Starting Epoch 290\n",
      "0.5429899368597113\n",
      "Starting Epoch 291\n",
      "0.5377126698908599\n",
      "Starting Epoch 292\n",
      "0.5393449806648752\n",
      "Starting Epoch 293\n",
      "0.5390251097471818\n",
      "Starting Epoch 294\n",
      "0.5374619338823401\n",
      "Starting Epoch 295\n",
      "0.5376516839732295\n",
      "Starting Epoch 296\n",
      "0.5414137905058654\n",
      "Starting Epoch 297\n",
      "0.5424266988816469\n",
      "Starting Epoch 298\n",
      "0.5397491403247999\n",
      "Starting Epoch 299\n",
      "0.5396572869756947\n",
      "Starting Epoch 300\n",
      "0.5377115140790525\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-median: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa15ffb",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a0ec25ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2db33e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,7,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d69770b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'mean(container counts)', 'mean(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "bff2a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6a24bc12-1ab8-4496-beec-38d33887e78b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.2838315264038416\n",
      "New best model found at epoch 1 with validation loss 0.6862317323684692\n",
      "Starting Epoch 2\n",
      "0.6847171938937643\n",
      "New best model found at epoch 2 with validation loss 0.6754311323165894\n",
      "Starting Epoch 3\n",
      "0.6700911314591117\n",
      "New best model found at epoch 3 with validation loss 0.6527891755104065\n",
      "Starting Epoch 4\n",
      "0.6540480437486068\n",
      "New best model found at epoch 4 with validation loss 0.6340838074684143\n",
      "Starting Epoch 5\n",
      "0.6409072046694548\n",
      "New best model found at epoch 5 with validation loss 0.6213096380233765\n",
      "Starting Epoch 6\n",
      "0.6372340166050455\n",
      "New best model found at epoch 6 with validation loss 0.6092466711997986\n",
      "Starting Epoch 7\n",
      "0.6261333875034166\n",
      "New best model found at epoch 7 with validation loss 0.5981859564781189\n",
      "Starting Epoch 8\n",
      "0.6162887733915577\n",
      "New best model found at epoch 8 with validation loss 0.5979531407356262\n",
      "Starting Epoch 9\n",
      "0.6236704847087031\n",
      "Starting Epoch 10\n",
      "0.6173329120096953\n",
      "New best model found at epoch 10 with validation loss 0.587448239326477\n",
      "Starting Epoch 11\n",
      "0.614681179108827\n",
      "Starting Epoch 12\n",
      "0.6146083681479745\n",
      "Starting Epoch 13\n",
      "0.6011660591415737\n",
      "New best model found at epoch 13 with validation loss 0.5831151604652405\n",
      "Starting Epoch 14\n",
      "0.6045648248299308\n",
      "New best model found at epoch 14 with validation loss 0.5776313543319702\n",
      "Starting Epoch 15\n",
      "0.5963551350261854\n",
      "Starting Epoch 16\n",
      "0.5986434843229211\n",
      "Starting Epoch 17\n",
      "0.5969244941421177\n",
      "New best model found at epoch 17 with validation loss 0.5747050046920776\n",
      "Starting Epoch 18\n",
      "0.5953942200411921\n",
      "New best model found at epoch 18 with validation loss 0.5725837349891663\n",
      "Starting Epoch 19\n",
      "0.5893796500952347\n",
      "New best model found at epoch 19 with validation loss 0.5690698027610779\n",
      "Starting Epoch 20\n",
      "0.5910330622092538\n",
      "Starting Epoch 21\n",
      "0.5868283147397249\n",
      "Starting Epoch 22\n",
      "0.5885779753975247\n",
      "Starting Epoch 23\n",
      "0.584648318912672\n",
      "Starting Epoch 24\n",
      "0.5812971980675407\n",
      "Starting Epoch 25\n",
      "0.5900632842727329\n",
      "New best model found at epoch 25 with validation loss 0.5662114024162292\n",
      "Starting Epoch 26\n",
      "0.586140513420105\n",
      "New best model found at epoch 26 with validation loss 0.5617932081222534\n",
      "Starting Epoch 27\n",
      "0.5796516809774481\n",
      "Starting Epoch 28\n",
      "0.5841402217097904\n",
      "Starting Epoch 29\n",
      "0.5773483074229696\n",
      "Starting Epoch 30\n",
      "0.5781302892643473\n",
      "Starting Epoch 31\n",
      "0.5780213397482167\n",
      "Starting Epoch 32\n",
      "0.5769149738809337\n",
      "Starting Epoch 33\n",
      "0.5761523259722668\n",
      "Starting Epoch 34\n",
      "0.5782171254572661\n",
      "Starting Epoch 35\n",
      "0.5762197012486665\n",
      "New best model found at epoch 35 with validation loss 0.560187578201294\n",
      "Starting Epoch 36\n",
      "0.572467010954152\n",
      "Starting Epoch 37\n",
      "0.575084520422894\n",
      "New best model found at epoch 37 with validation loss 0.558016836643219\n",
      "Starting Epoch 38\n",
      "0.5727533594421719\n",
      "New best model found at epoch 38 with validation loss 0.5561410188674927\n",
      "Starting Epoch 39\n",
      "0.5717649822649749\n",
      "Starting Epoch 40\n",
      "0.5727871656417847\n",
      "Starting Epoch 41\n",
      "0.5716230713802836\n",
      "Starting Epoch 42\n",
      "0.5741226621296095\n",
      "Starting Epoch 43\n",
      "0.5703086878942407\n",
      "Starting Epoch 44\n",
      "0.5717823090760604\n",
      "Starting Epoch 45\n",
      "0.5713760490002839\n",
      "Starting Epoch 46\n",
      "0.5704193724238354\n",
      "Starting Epoch 47\n",
      "0.5683247719122015\n",
      "Starting Epoch 48\n",
      "0.5685323204683221\n",
      "Starting Epoch 49\n",
      "0.5692269257877184\n",
      "Starting Epoch 50\n",
      "0.5682325052178424\n",
      "New best model found at epoch 50 with validation loss 0.5543184876441956\n",
      "Starting Epoch 51\n",
      "0.5677624863127003\n",
      "Starting Epoch 52\n",
      "0.5670463727868121\n",
      "Starting Epoch 53\n",
      "0.566158977539643\n",
      "Starting Epoch 54\n",
      "0.5675448878951694\n",
      "Starting Epoch 55\n",
      "0.5663702669350997\n",
      "New best model found at epoch 55 with validation loss 0.552018404006958\n",
      "Starting Epoch 56\n",
      "0.5661911705265874\n",
      "Starting Epoch 57\n",
      "0.5676854913649352\n",
      "Starting Epoch 58\n",
      "0.5646799297436423\n",
      "Starting Epoch 59\n",
      "0.5632367859716001\n",
      "Starting Epoch 60\n",
      "0.5658981644588968\n",
      "Starting Epoch 61\n",
      "0.5641014627788378\n",
      "New best model found at epoch 61 with validation loss 0.5517684817314148\n",
      "Starting Epoch 62\n",
      "0.5667247500108636\n",
      "Starting Epoch 63\n",
      "0.5634584711945575\n",
      "Starting Epoch 64\n",
      "0.56419779425082\n",
      "Starting Epoch 65\n",
      "0.5649317010589268\n",
      "Starting Epoch 66\n",
      "0.5625703801279482\n",
      "New best model found at epoch 66 with validation loss 0.5517032146453857\n",
      "Starting Epoch 67\n",
      "0.5630335652309916\n",
      "Starting Epoch 68\n",
      "0.5630160518314528\n",
      "Starting Epoch 69\n",
      "0.5638847169668778\n",
      "Starting Epoch 70\n",
      "0.5599001827447311\n",
      "Starting Epoch 71\n",
      "0.5637315913386967\n",
      "Starting Epoch 72\n",
      "0.5641428944857224\n",
      "New best model found at epoch 72 with validation loss 0.5482434630393982\n",
      "Starting Epoch 73\n",
      "0.5607817639475283\n",
      "Starting Epoch 74\n",
      "0.5630805868169536\n",
      "Starting Epoch 75\n",
      "0.5611604581708494\n",
      "Starting Epoch 76\n",
      "0.5617124269837919\n",
      "Starting Epoch 77\n",
      "0.5604858385479968\n",
      "Starting Epoch 78\n",
      "0.560600044934646\n",
      "New best model found at epoch 78 with validation loss 0.5471522808074951\n",
      "Starting Epoch 79\n",
      "0.5611984548361405\n",
      "Starting Epoch 80\n",
      "0.5599119494790616\n",
      "Starting Epoch 81\n",
      "0.5605871560780898\n",
      "Starting Epoch 82\n",
      "0.5634007065192513\n",
      "Starting Epoch 83\n",
      "0.56132315164027\n",
      "Starting Epoch 84\n",
      "0.561465023652367\n",
      "Starting Epoch 85\n",
      "0.5617117506006489\n",
      "Starting Epoch 86\n",
      "0.5576739363048387\n",
      "Starting Epoch 87\n",
      "0.5605648872645005\n",
      "Starting Epoch 88\n",
      "0.5580600020678147\n",
      "Starting Epoch 89\n",
      "0.5589643535406693\n",
      "Starting Epoch 90\n",
      "0.5593481193418088\n",
      "Starting Epoch 91\n",
      "0.5601866841316223\n",
      "Starting Epoch 92\n",
      "0.5587022174959597\n",
      "Starting Epoch 93\n",
      "0.558845043182373\n",
      "New best model found at epoch 93 with validation loss 0.545421302318573\n",
      "Starting Epoch 94\n",
      "0.5583643304265064\n",
      "Starting Epoch 95\n",
      "0.5580360202685647\n",
      "Starting Epoch 96\n",
      "0.5601195705973584\n",
      "Starting Epoch 97\n",
      "0.5576043103052222\n",
      "Starting Epoch 98\n",
      "0.5572990010613981\n",
      "New best model found at epoch 98 with validation loss 0.5452249646186829\n",
      "Starting Epoch 99\n",
      "0.55922597128412\n",
      "Starting Epoch 100\n",
      "0.5590730892575305\n",
      "New best model found at epoch 100 with validation loss 0.5440309047698975\n",
      "Starting Epoch 101\n",
      "0.5558905044327611\n",
      "Starting Epoch 102\n",
      "0.5574855856273485\n",
      "New best model found at epoch 102 with validation loss 0.5426822304725647\n",
      "Starting Epoch 103\n",
      "0.5574876264385555\n",
      "Starting Epoch 104\n",
      "0.5578809795172318\n",
      "Starting Epoch 105\n",
      "0.5555129426976909\n",
      "Starting Epoch 106\n",
      "0.5568905446840369\n",
      "Starting Epoch 107\n",
      "0.5567137275053107\n",
      "Starting Epoch 108\n",
      "0.5570400642312091\n",
      "Starting Epoch 109\n",
      "0.558265780625136\n",
      "New best model found at epoch 109 with validation loss 0.5421088933944702\n",
      "Starting Epoch 110\n",
      "0.555436064367709\n",
      "Starting Epoch 111\n",
      "0.5564103554124418\n",
      "Starting Epoch 112\n",
      "0.5609278432700945\n",
      "Starting Epoch 113\n",
      "0.5558259526024694\n",
      "Starting Epoch 114\n",
      "0.5546967050303584\n",
      "Starting Epoch 115\n",
      "0.5529072725254557\n",
      "New best model found at epoch 115 with validation loss 0.5400905013084412\n",
      "Starting Epoch 116\n",
      "0.5555701851844788\n",
      "New best model found at epoch 116 with validation loss 0.5400698184967041\n",
      "Starting Epoch 117\n",
      "0.5555421567481497\n",
      "Starting Epoch 118\n",
      "0.5536083656808605\n",
      "New best model found at epoch 118 with validation loss 0.5384063720703125\n",
      "Starting Epoch 119\n",
      "0.5544093795444655\n",
      "Starting Epoch 120\n",
      "0.5550613584725753\n",
      "Starting Epoch 121\n",
      "0.559415384479191\n",
      "Starting Epoch 122\n",
      "0.5553434115389119\n",
      "Starting Epoch 123\n",
      "0.5535880456800046\n",
      "Starting Epoch 124\n",
      "0.5556888334129167\n",
      "Starting Epoch 125\n",
      "0.5551993328592052\n",
      "Starting Epoch 126\n",
      "0.5522532035475192\n",
      "Starting Epoch 127\n",
      "0.5546792356864266\n",
      "Starting Epoch 128\n",
      "0.5587063133716583\n",
      "Starting Epoch 129\n",
      "0.5527019785798114\n",
      "Starting Epoch 130\n",
      "0.553735472585844\n",
      "Starting Epoch 131\n",
      "0.5522586327532063\n",
      "Starting Epoch 132\n",
      "0.5556443657564081\n",
      "Starting Epoch 133\n",
      "0.5518114009629125\n",
      "Starting Epoch 134\n",
      "0.5554674462131832\n",
      "Starting Epoch 135\n",
      "0.5523733004279758\n",
      "Starting Epoch 136\n",
      "0.5545518190964408\n",
      "New best model found at epoch 136 with validation loss 0.5372888445854187\n",
      "Starting Epoch 137\n",
      "0.5511426951574243\n",
      "Starting Epoch 138\n",
      "0.5518316535846047\n",
      "New best model found at epoch 138 with validation loss 0.5357280373573303\n",
      "Starting Epoch 139\n",
      "0.5511819124221802\n",
      "Starting Epoch 140\n",
      "0.5530381720999012\n",
      "Starting Epoch 141\n",
      "0.5539362845213517\n",
      "Starting Epoch 142\n",
      "0.5503047030905018\n",
      "Starting Epoch 143\n",
      "0.5534000189408012\n",
      "Starting Epoch 144\n",
      "0.5515879859095034\n",
      "Starting Epoch 145\n",
      "0.550292070793069\n",
      "Starting Epoch 146\n",
      "0.5503187918144724\n",
      "Starting Epoch 147\n",
      "0.5509000874083975\n",
      "Starting Epoch 148\n",
      "0.5542226006155428\n",
      "Starting Epoch 149\n",
      "0.5539449025755343\n",
      "New best model found at epoch 149 with validation loss 0.5354012250900269\n",
      "Starting Epoch 150\n",
      "0.5528281331062317\n",
      "Starting Epoch 151\n",
      "0.5517640865367391\n",
      "Starting Epoch 152\n",
      "0.5481045881043309\n",
      "Starting Epoch 153\n",
      "0.548649673876555\n",
      "New best model found at epoch 153 with validation loss 0.5350397825241089\n",
      "Starting Epoch 154\n",
      "0.5513488611449366\n",
      "New best model found at epoch 154 with validation loss 0.5342808365821838\n",
      "Starting Epoch 155\n",
      "0.5491724791734115\n",
      "Starting Epoch 156\n",
      "0.5524104315301647\n",
      "Starting Epoch 157\n",
      "0.5511372102343518\n",
      "Starting Epoch 158\n",
      "0.5516150127286497\n",
      "Starting Epoch 159\n",
      "0.5509122195451156\n",
      "Starting Epoch 160\n",
      "0.5498916519724805\n",
      "Starting Epoch 161\n",
      "0.5490763265153636\n",
      "Starting Epoch 162\n",
      "0.5529315756714862\n",
      "Starting Epoch 163\n",
      "0.5518666324408158\n",
      "Starting Epoch 164\n",
      "0.5533687174320221\n",
      "Starting Epoch 165\n",
      "0.5490544114423834\n",
      "Starting Epoch 166\n",
      "0.5477878360644631\n",
      "Starting Epoch 167\n",
      "0.5512248446112094\n",
      "New best model found at epoch 167 with validation loss 0.5329076051712036\n",
      "Starting Epoch 168\n",
      "0.5510370161222375\n",
      "Starting Epoch 169\n",
      "0.5490503414817478\n",
      "Starting Epoch 170\n",
      "0.5508848752664484\n",
      "Starting Epoch 171\n",
      "0.5478926560153132\n",
      "Starting Epoch 172\n",
      "0.5491226004517596\n",
      "Starting Epoch 173\n",
      "0.5477333781511887\n",
      "Starting Epoch 174\n",
      "0.5475025837836058\n",
      "Starting Epoch 175\n",
      "0.547584935374882\n",
      "Starting Epoch 176\n",
      "0.5469832524009373\n",
      "Starting Epoch 177\n",
      "0.548571245825809\n",
      "Starting Epoch 178\n",
      "0.5531854409238567\n",
      "Starting Epoch 179\n",
      "0.5498653909434443\n",
      "Starting Epoch 180\n",
      "0.5495773877786554\n",
      "Starting Epoch 181\n",
      "0.5517634451389313\n",
      "Starting Epoch 182\n",
      "0.5496641241985819\n",
      "New best model found at epoch 182 with validation loss 0.5324310660362244\n",
      "Starting Epoch 183\n",
      "0.5476800630921903\n",
      "Starting Epoch 184\n",
      "0.5479778232781783\n",
      "Starting Epoch 185\n",
      "0.5479697701723679\n",
      "Starting Epoch 186\n",
      "0.5486981091292008\n",
      "Starting Epoch 187\n",
      "0.5482927988404813\n",
      "Starting Epoch 188\n",
      "0.5472901631956515\n",
      "Starting Epoch 189\n",
      "0.5509308304475702\n",
      "Starting Epoch 190\n",
      "0.5462439759917881\n",
      "Starting Epoch 191\n",
      "0.546778785145801\n",
      "Starting Epoch 192\n",
      "0.5470192691554194\n",
      "Starting Epoch 193\n",
      "0.546242576578389\n",
      "Starting Epoch 194\n",
      "0.547037405812222\n",
      "Starting Epoch 195\n",
      "0.5470141872115757\n",
      "Starting Epoch 196\n",
      "0.5483526794806771\n",
      "Starting Epoch 197\n",
      "0.5470645064892976\n",
      "Starting Epoch 198\n",
      "0.5466278052848318\n",
      "Starting Epoch 199\n",
      "0.5469211948954541\n",
      "Starting Epoch 200\n",
      "0.5482757065607153\n",
      "Starting Epoch 201\n",
      "0.5476669980132062\n",
      "Starting Epoch 202\n",
      "0.5490009331184885\n",
      "Starting Epoch 203\n",
      "0.545755755642186\n",
      "New best model found at epoch 203 with validation loss 0.5319935083389282\n",
      "Starting Epoch 204\n",
      "0.5461640137693157\n",
      "Starting Epoch 205\n",
      "0.5474994558355083\n",
      "Starting Epoch 206\n",
      "0.5465351887371229\n",
      "Starting Epoch 207\n",
      "0.5450919996137205\n",
      "Starting Epoch 208\n",
      "0.5457696849885194\n",
      "Starting Epoch 209\n",
      "0.5472858003948046\n",
      "Starting Epoch 210\n",
      "0.5468723359315292\n",
      "Starting Epoch 211\n",
      "0.5451412952464559\n",
      "Starting Epoch 212\n",
      "0.5460465926191082\n",
      "Starting Epoch 213\n",
      "0.5458981666875922\n",
      "Starting Epoch 214\n",
      "0.5441953241825104\n",
      "Starting Epoch 215\n",
      "0.5467201043730197\n",
      "Starting Epoch 216\n",
      "0.5455378967782726\n",
      "Starting Epoch 217\n",
      "0.5475664449774701\n",
      "Starting Epoch 218\n",
      "0.545577101085497\n",
      "Starting Epoch 219\n",
      "0.545419727978499\n",
      "Starting Epoch 220\n",
      "0.5445590109928794\n",
      "Starting Epoch 221\n",
      "0.5437238268230272\n",
      "Starting Epoch 222\n",
      "0.5459030024383379\n",
      "New best model found at epoch 222 with validation loss 0.5301356315612793\n",
      "Starting Epoch 223\n",
      "0.5449778567189756\n",
      "Starting Epoch 224\n",
      "0.5438040183938068\n",
      "Starting Epoch 225\n",
      "0.5461665547412374\n",
      "Starting Epoch 226\n",
      "0.5451993048191071\n",
      "Starting Epoch 227\n",
      "0.5439776350622592\n",
      "Starting Epoch 228\n",
      "0.5461719295252925\n",
      "Starting Epoch 229\n",
      "0.5465478054855181\n",
      "Starting Epoch 230\n",
      "0.54253384211789\n",
      "Starting Epoch 231\n",
      "0.54363955622134\n",
      "Starting Epoch 232\n",
      "0.542732412400453\n",
      "Starting Epoch 233\n",
      "0.5426016022329745\n",
      "Starting Epoch 234\n",
      "0.5435793697834015\n",
      "Starting Epoch 235\n",
      "0.5460126944210218\n",
      "New best model found at epoch 235 with validation loss 0.5301238298416138\n",
      "Starting Epoch 236\n",
      "0.5459723265274711\n",
      "Starting Epoch 237\n",
      "0.5448452532291412\n",
      "Starting Epoch 238\n",
      "0.5441239450288855\n",
      "Starting Epoch 239\n",
      "0.5441275446311288\n",
      "Starting Epoch 240\n",
      "0.543341849161231\n",
      "Starting Epoch 241\n",
      "0.5438545916391455\n",
      "Starting Epoch 242\n",
      "0.5448769538298898\n",
      "New best model found at epoch 242 with validation loss 0.5295163989067078\n",
      "Starting Epoch 243\n",
      "0.5409868813079336\n",
      "Starting Epoch 244\n",
      "0.5451121433921482\n",
      "Starting Epoch 245\n",
      "0.5450320943542148\n",
      "Starting Epoch 246\n",
      "0.5453398616417594\n",
      "Starting Epoch 247\n",
      "0.5419367681378904\n",
      "Starting Epoch 248\n",
      "0.5456950133261473\n",
      "Starting Epoch 249\n",
      "0.5445781065070111\n",
      "Starting Epoch 250\n",
      "0.5441131008707959\n",
      "Starting Epoch 251\n",
      "0.5422352228475653\n",
      "Starting Epoch 252\n",
      "0.5434980081475299\n",
      "Starting Epoch 253\n",
      "0.542242143465125\n",
      "Starting Epoch 254\n",
      "0.5475474894046783\n",
      "Starting Epoch 255\n",
      "0.5429978202218595\n",
      "Starting Epoch 256\n",
      "0.5456979520942854\n",
      "Starting Epoch 257\n",
      "0.5430330880310225\n",
      "Starting Epoch 258\n",
      "0.5429889754108761\n",
      "Starting Epoch 259\n",
      "0.5421474886977155\n",
      "New best model found at epoch 259 with validation loss 0.5291210412979126\n",
      "Starting Epoch 260\n",
      "0.5403308829535609\n",
      "Starting Epoch 261\n",
      "0.5439935197000918\n",
      "Starting Epoch 262\n",
      "0.5428369174832883\n",
      "Starting Epoch 263\n",
      "0.5424646385337996\n",
      "Starting Epoch 264\n",
      "0.5454995580341505\n",
      "Starting Epoch 265\n",
      "0.542177052601524\n",
      "Starting Epoch 266\n",
      "0.5410850773686948\n",
      "Starting Epoch 267\n",
      "0.5442091900369396\n",
      "Starting Epoch 268\n",
      "0.541924756506215\n",
      "Starting Epoch 269\n",
      "0.5434901856857798\n",
      "Starting Epoch 270\n",
      "0.5409361875575521\n",
      "Starting Epoch 271\n",
      "0.5417003255823384\n",
      "Starting Epoch 272\n",
      "0.5434159195941427\n",
      "Starting Epoch 273\n",
      "0.5408185837061509\n",
      "Starting Epoch 274\n",
      "0.5411794444789058\n",
      "New best model found at epoch 274 with validation loss 0.5280989408493042\n",
      "Starting Epoch 275\n",
      "0.5399858459182407\n",
      "Starting Epoch 276\n",
      "0.5407691675683727\n",
      "Starting Epoch 277\n",
      "0.5422844394393589\n",
      "Starting Epoch 278\n",
      "0.541025838126307\n",
      "Starting Epoch 279\n",
      "0.5409545924352563\n",
      "Starting Epoch 280\n",
      "0.5434251427650452\n",
      "Starting Epoch 281\n",
      "0.5405294558276301\n",
      "Starting Epoch 282\n",
      "0.5418723329253818\n",
      "Starting Epoch 283\n",
      "0.5411026607389036\n",
      "Starting Epoch 284\n",
      "0.5403209367524022\n",
      "Starting Epoch 285\n",
      "0.5415657525477202\n",
      "Starting Epoch 286\n",
      "0.5406013766060704\n",
      "Starting Epoch 287\n",
      "0.5404501764670663\n",
      "Starting Epoch 288\n",
      "0.541523981353511\n",
      "Starting Epoch 289\n",
      "0.5421833564405856\n",
      "Starting Epoch 290\n",
      "0.5426058834013732\n",
      "Starting Epoch 291\n",
      "0.5391639004582944\n",
      "Starting Epoch 292\n",
      "0.5392650171466495\n",
      "Starting Epoch 293\n",
      "0.5392934369004291\n",
      "Starting Epoch 294\n",
      "0.5412298389103102\n",
      "Starting Epoch 295\n",
      "0.5402708390484685\n",
      "Starting Epoch 296\n",
      "0.5443888941536779\n",
      "Starting Epoch 297\n",
      "0.5419093098329462\n",
      "Starting Epoch 298\n",
      "0.5420356302157693\n",
      "Starting Epoch 299\n",
      "0.5414326540801836\n",
      "Starting Epoch 300\n",
      "0.5408405298772065\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-mean: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31900fe2",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 3\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9bd76e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d88f28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,5,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "54f1900e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'min(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6d4111d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "6bcd284a-0e34-4b79-b394-9007eaad52a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.3039616190868877\n",
      "New best model found at epoch 1 with validation loss 0.6765950918197632\n",
      "Starting Epoch 2\n",
      "0.6696783692940421\n",
      "New best model found at epoch 2 with validation loss 0.6550491452217102\n",
      "Starting Epoch 3\n",
      "0.6526765978854635\n",
      "New best model found at epoch 3 with validation loss 0.6308378577232361\n",
      "Starting Epoch 4\n",
      "0.6437178305957628\n",
      "New best model found at epoch 4 with validation loss 0.6279082298278809\n",
      "Starting Epoch 5\n",
      "0.6347791993099711\n",
      "New best model found at epoch 5 with validation loss 0.6148545742034912\n",
      "Starting Epoch 6\n",
      "0.6302175547765649\n",
      "New best model found at epoch 6 with validation loss 0.6068060994148254\n",
      "Starting Epoch 7\n",
      "0.6282563650089762\n",
      "Starting Epoch 8\n",
      "0.6236989238987798\n",
      "New best model found at epoch 8 with validation loss 0.6061315536499023\n",
      "Starting Epoch 9\n",
      "0.6267518038335054\n",
      "Starting Epoch 10\n",
      "0.6240140588387199\n",
      "New best model found at epoch 10 with validation loss 0.6031379699707031\n",
      "Starting Epoch 11\n",
      "0.6253559045169664\n",
      "Starting Epoch 12\n",
      "0.62453300797421\n",
      "New best model found at epoch 12 with validation loss 0.6028966903686523\n",
      "Starting Epoch 13\n",
      "0.6147439764893573\n",
      "Starting Epoch 14\n",
      "0.6219026290852091\n",
      "New best model found at epoch 14 with validation loss 0.5932707190513611\n",
      "Starting Epoch 15\n",
      "0.6129389482995738\n",
      "Starting Epoch 16\n",
      "0.6220081318979678\n",
      "Starting Epoch 17\n",
      "0.6158092281092769\n",
      "Starting Epoch 18\n",
      "0.6147681215535039\n",
      "Starting Epoch 19\n",
      "0.6109148004780645\n",
      "Starting Epoch 20\n",
      "0.6119036544924197\n",
      "Starting Epoch 21\n",
      "0.6114069586214812\n",
      "Starting Epoch 22\n",
      "0.6111661169839941\n",
      "Starting Epoch 23\n",
      "0.6085195878277654\n",
      "Starting Epoch 24\n",
      "0.6049239324486774\n",
      "New best model found at epoch 24 with validation loss 0.5846734046936035\n",
      "Starting Epoch 25\n",
      "0.6110577712888303\n",
      "Starting Epoch 26\n",
      "0.6057521519453629\n",
      "Starting Epoch 27\n",
      "0.6051239189894303\n",
      "Starting Epoch 28\n",
      "0.6071879449098007\n",
      "Starting Epoch 29\n",
      "0.6041342564251112\n",
      "Starting Epoch 30\n",
      "0.6023254446361376\n",
      "Starting Epoch 31\n",
      "0.60384267050287\n",
      "Starting Epoch 32\n",
      "0.6017783361932506\n",
      "Starting Epoch 33\n",
      "0.6031974631807079\n",
      "Starting Epoch 34\n",
      "0.6022578581519749\n",
      "Starting Epoch 35\n",
      "0.600554909395135\n",
      "Starting Epoch 36\n",
      "0.599511136179385\n",
      "Starting Epoch 37\n",
      "0.5963758256124414\n",
      "Starting Epoch 38\n",
      "0.5987456492755724\n",
      "Starting Epoch 39\n",
      "0.5965055745580922\n",
      "Starting Epoch 40\n",
      "0.598549378954846\n",
      "Starting Epoch 41\n",
      "0.5978986413582511\n",
      "New best model found at epoch 41 with validation loss 0.5845578908920288\n",
      "Starting Epoch 42\n",
      "0.5994814789813497\n",
      "Starting Epoch 43\n",
      "0.6101152119429215\n",
      "New best model found at epoch 43 with validation loss 0.5842477679252625\n",
      "Starting Epoch 44\n",
      "0.5974073202713676\n",
      "New best model found at epoch 44 with validation loss 0.5820719599723816\n",
      "Starting Epoch 45\n",
      "0.5943175450615261\n",
      "Starting Epoch 46\n",
      "0.6008519400721011\n",
      "New best model found at epoch 46 with validation loss 0.581777811050415\n",
      "Starting Epoch 47\n",
      "0.593712259893832\n",
      "Starting Epoch 48\n",
      "0.593450955722643\n",
      "New best model found at epoch 48 with validation loss 0.5779684782028198\n",
      "Starting Epoch 49\n",
      "0.5940837937852611\n",
      "Starting Epoch 50\n",
      "0.5928935978723608\n",
      "Starting Epoch 51\n",
      "0.5929422611775605\n",
      "Starting Epoch 52\n",
      "0.5930577931196793\n",
      "Starting Epoch 53\n",
      "0.5920627479967864\n",
      "Starting Epoch 54\n",
      "0.593490253324094\n",
      "Starting Epoch 55\n",
      "0.5891725939253102\n",
      "New best model found at epoch 55 with validation loss 0.5762646794319153\n",
      "Starting Epoch 56\n",
      "0.5896028228428053\n",
      "Starting Epoch 57\n",
      "0.5928329436675362\n",
      "Starting Epoch 58\n",
      "0.5888834699340488\n",
      "Starting Epoch 59\n",
      "0.5945434544397437\n",
      "Starting Epoch 60\n",
      "0.586965534998023\n",
      "Starting Epoch 61\n",
      "0.5875697693099147\n",
      "Starting Epoch 62\n",
      "0.5879161668860394\n",
      "Starting Epoch 63\n",
      "0.5872417299643807\n",
      "New best model found at epoch 63 with validation loss 0.5735474228858948\n",
      "Starting Epoch 64\n",
      "0.5884179369263027\n",
      "Starting Epoch 65\n",
      "0.5872486000475676\n",
      "Starting Epoch 66\n",
      "0.5851007751796556\n",
      "New best model found at epoch 66 with validation loss 0.5726222991943359\n",
      "Starting Epoch 67\n",
      "0.5861174956611965\n",
      "Starting Epoch 68\n",
      "0.5893080338187839\n",
      "Starting Epoch 69\n",
      "0.5877177119255066\n",
      "Starting Epoch 70\n",
      "0.5836093555326047\n",
      "Starting Epoch 71\n",
      "0.5878541676894479\n",
      "Starting Epoch 72\n",
      "0.5863734483718872\n",
      "New best model found at epoch 72 with validation loss 0.5684813261032104\n",
      "Starting Epoch 73\n",
      "0.5846228055332018\n",
      "Starting Epoch 74\n",
      "0.5883317900740582\n",
      "Starting Epoch 75\n",
      "0.5859129506608715\n",
      "Starting Epoch 76\n",
      "0.5863181922746741\n",
      "Starting Epoch 77\n",
      "0.5857244600420413\n",
      "Starting Epoch 78\n",
      "0.5804860047672106\n",
      "New best model found at epoch 78 with validation loss 0.5675651431083679\n",
      "Starting Epoch 79\n",
      "0.5857561334319736\n",
      "Starting Epoch 80\n",
      "0.5815360027810802\n",
      "Starting Epoch 81\n",
      "0.5808704054873922\n",
      "Starting Epoch 82\n",
      "0.5815236827601558\n",
      "Starting Epoch 83\n",
      "0.5830737896587538\n",
      "New best model found at epoch 83 with validation loss 0.5661670565605164\n",
      "Starting Epoch 84\n",
      "0.5828715718310812\n",
      "Starting Epoch 85\n",
      "0.5898506226746932\n",
      "Starting Epoch 86\n",
      "0.5789731740951538\n",
      "Starting Epoch 87\n",
      "0.5824760302253391\n",
      "New best model found at epoch 87 with validation loss 0.5633938908576965\n",
      "Starting Epoch 88\n",
      "0.5774962720663651\n",
      "Starting Epoch 89\n",
      "0.585221220617709\n",
      "Starting Epoch 90\n",
      "0.5791308024655217\n",
      "Starting Epoch 91\n",
      "0.5800095563349517\n",
      "Starting Epoch 92\n",
      "0.580247119716976\n",
      "Starting Epoch 93\n",
      "0.5798949625181116\n",
      "New best model found at epoch 93 with validation loss 0.55891352891922\n",
      "Starting Epoch 94\n",
      "0.5809674884962\n",
      "Starting Epoch 95\n",
      "0.5801433687624724\n",
      "Starting Epoch 96\n",
      "0.5799934993619504\n",
      "Starting Epoch 97\n",
      "0.5759870228560074\n",
      "Starting Epoch 98\n",
      "0.5764682863069617\n",
      "Starting Epoch 99\n",
      "0.5786508036696393\n",
      "Starting Epoch 100\n",
      "0.5756624211435732\n",
      "Starting Epoch 101\n",
      "0.5773665995701499\n",
      "Starting Epoch 102\n",
      "0.5802934169769287\n",
      "Starting Epoch 103\n",
      "0.576050719489222\n",
      "Starting Epoch 104\n",
      "0.581813615301381\n",
      "Starting Epoch 105\n",
      "0.5752125045527583\n",
      "Starting Epoch 106\n",
      "0.5739916744439498\n",
      "Starting Epoch 107\n",
      "0.5786465950634169\n",
      "Starting Epoch 108\n",
      "0.574503903803618\n",
      "Starting Epoch 109\n",
      "0.5728180343690126\n",
      "Starting Epoch 110\n",
      "0.5728930908700695\n",
      "Starting Epoch 111\n",
      "0.5765091932338217\n",
      "New best model found at epoch 111 with validation loss 0.5557987093925476\n",
      "Starting Epoch 112\n",
      "0.5772569568260856\n",
      "Starting Epoch 113\n",
      "0.5721437594164973\n",
      "Starting Epoch 114\n",
      "0.5704258252745089\n",
      "New best model found at epoch 114 with validation loss 0.5557149052619934\n",
      "Starting Epoch 115\n",
      "0.5690483787785405\n",
      "Starting Epoch 116\n",
      "0.5777108565620754\n",
      "Starting Epoch 117\n",
      "0.5735809492028278\n",
      "New best model found at epoch 117 with validation loss 0.5538675785064697\n",
      "Starting Epoch 118\n",
      "0.5717355544152467\n",
      "Starting Epoch 119\n",
      "0.5730822371399921\n",
      "Starting Epoch 120\n",
      "0.574327404084413\n",
      "Starting Epoch 121\n",
      "0.5728997743648031\n",
      "Starting Epoch 122\n",
      "0.5768521687258845\n",
      "Starting Epoch 123\n",
      "0.5753073355425959\n",
      "Starting Epoch 124\n",
      "0.5699385948803114\n",
      "Starting Epoch 125\n",
      "0.5738901107207589\n",
      "New best model found at epoch 125 with validation loss 0.5527656674385071\n",
      "Starting Epoch 126\n",
      "0.5709550588027291\n",
      "Starting Epoch 127\n",
      "0.5677594983059427\n",
      "Starting Epoch 128\n",
      "0.5754534887230914\n",
      "Starting Epoch 129\n",
      "0.5683099031448364\n",
      "Starting Epoch 130\n",
      "0.5703365932340208\n",
      "Starting Epoch 131\n",
      "0.5687028739763342\n",
      "Starting Epoch 132\n",
      "0.5765557833339857\n",
      "Starting Epoch 133\n",
      "0.5680951890738114\n",
      "New best model found at epoch 133 with validation loss 0.5503889918327332\n",
      "Starting Epoch 134\n",
      "0.5756023733512216\n",
      "Starting Epoch 135\n",
      "0.5691482321075771\n",
      "Starting Epoch 136\n",
      "0.5725543084351913\n",
      "Starting Epoch 137\n",
      "0.5690962024357008\n",
      "Starting Epoch 138\n",
      "0.5646551640137382\n",
      "Starting Epoch 139\n",
      "0.5715813844100289\n",
      "Starting Epoch 140\n",
      "0.5716204798739889\n",
      "Starting Epoch 141\n",
      "0.5685054750546165\n",
      "Starting Epoch 142\n",
      "0.5668351131936779\n",
      "Starting Epoch 143\n",
      "0.5688184862551482\n",
      "Starting Epoch 144\n",
      "0.5633568051068679\n",
      "Starting Epoch 145\n",
      "0.5649601311787315\n",
      "Starting Epoch 146\n",
      "0.5667838259883549\n",
      "Starting Epoch 147\n",
      "0.5647355045961298\n",
      "Starting Epoch 148\n",
      "0.5689035213511923\n",
      "Starting Epoch 149\n",
      "0.5649142913196398\n",
      "Starting Epoch 150\n",
      "0.5658302540364473\n",
      "Starting Epoch 151\n",
      "0.5666405869566876\n",
      "New best model found at epoch 151 with validation loss 0.5486238598823547\n",
      "Starting Epoch 152\n",
      "0.5612230326818384\n",
      "Starting Epoch 153\n",
      "0.5625175367230955\n",
      "Starting Epoch 154\n",
      "0.5734256816946942\n",
      "Starting Epoch 155\n",
      "0.5658081938391146\n",
      "Starting Epoch 156\n",
      "0.5626661855241527\n",
      "Starting Epoch 157\n",
      "0.5688672402630681\n",
      "Starting Epoch 158\n",
      "0.5617182358451511\n",
      "Starting Epoch 159\n",
      "0.5619965247485949\n",
      "Starting Epoch 160\n",
      "0.5673330776069475\n",
      "New best model found at epoch 160 with validation loss 0.5473069548606873\n",
      "Starting Epoch 161\n",
      "0.5636491827342821\n",
      "Starting Epoch 162\n",
      "0.5639933956706006\n",
      "Starting Epoch 163\n",
      "0.5639663636684418\n",
      "Starting Epoch 164\n",
      "0.5704789990964143\n",
      "Starting Epoch 165\n",
      "0.5616524245428003\n",
      "Starting Epoch 166\n",
      "0.5634028276671534\n",
      "New best model found at epoch 166 with validation loss 0.5454075336456299\n",
      "Starting Epoch 167\n",
      "0.5610453019971433\n",
      "Starting Epoch 168\n",
      "0.5625667338785918\n",
      "Starting Epoch 169\n",
      "0.5626100509063058\n",
      "Starting Epoch 170\n",
      "0.5592483800390492\n",
      "Starting Epoch 171\n",
      "0.5588009279707203\n",
      "Starting Epoch 172\n",
      "0.561539421910825\n",
      "Starting Epoch 173\n",
      "0.560809296110402\n",
      "New best model found at epoch 173 with validation loss 0.5450155138969421\n",
      "Starting Epoch 174\n",
      "0.5607093818809675\n",
      "Starting Epoch 175\n",
      "0.5594472911046899\n",
      "Starting Epoch 176\n",
      "0.5607739635135817\n",
      "Starting Epoch 177\n",
      "0.5573515244152235\n",
      "Starting Epoch 178\n",
      "0.562761471323345\n",
      "Starting Epoch 179\n",
      "0.5614315452783004\n",
      "Starting Epoch 180\n",
      "0.5611413639524708\n",
      "Starting Epoch 181\n",
      "0.5583944864895033\n",
      "Starting Epoch 182\n",
      "0.5611058188521344\n",
      "New best model found at epoch 182 with validation loss 0.5403292179107666\n",
      "Starting Epoch 183\n",
      "0.5595668891201848\n",
      "Starting Epoch 184\n",
      "0.5544290011343749\n",
      "Starting Epoch 185\n",
      "0.5589841189591781\n",
      "Starting Epoch 186\n",
      "0.5595966733020284\n",
      "Starting Epoch 187\n",
      "0.5599759830080945\n",
      "Starting Epoch 188\n",
      "0.5617448700510937\n",
      "Starting Epoch 189\n",
      "0.5583029531914255\n",
      "New best model found at epoch 189 with validation loss 0.5391141772270203\n",
      "Starting Epoch 190\n",
      "0.5555408972760906\n",
      "Starting Epoch 191\n",
      "0.5592557632404825\n",
      "Starting Epoch 192\n",
      "0.5536827108134394\n",
      "Starting Epoch 193\n",
      "0.5529666698497274\n",
      "Starting Epoch 194\n",
      "0.5554939832376398\n",
      "Starting Epoch 195\n",
      "0.5560244658718938\n",
      "Starting Epoch 196\n",
      "0.5569380184878474\n",
      "Starting Epoch 197\n",
      "0.5533409196397533\n",
      "Starting Epoch 198\n",
      "0.5514677711155104\n",
      "Starting Epoch 199\n",
      "0.5554213964420817\n",
      "Starting Epoch 200\n",
      "0.5606318077315455\n",
      "Starting Epoch 201\n",
      "0.5584156124488168\n",
      "Starting Epoch 202\n",
      "0.5556235067222429\n",
      "Starting Epoch 203\n",
      "0.5516816857068435\n",
      "Starting Epoch 204\n",
      "0.5523473749990049\n",
      "Starting Epoch 205\n",
      "0.5547036813653033\n",
      "Starting Epoch 206\n",
      "0.5504855073016622\n",
      "New best model found at epoch 206 with validation loss 0.5388072729110718\n",
      "Starting Epoch 207\n",
      "0.550285033557726\n",
      "New best model found at epoch 207 with validation loss 0.5375428199768066\n",
      "Starting Epoch 208\n",
      "0.5523003326809924\n",
      "Starting Epoch 209\n",
      "0.5529530164988145\n",
      "Starting Epoch 210\n",
      "0.5537105591400809\n",
      "Starting Epoch 211\n",
      "0.551382962776267\n",
      "New best model found at epoch 211 with validation loss 0.5369763374328613\n",
      "Starting Epoch 212\n",
      "0.5529274681340093\n",
      "Starting Epoch 213\n",
      "0.5523033064344655\n",
      "Starting Epoch 214\n",
      "0.548674745404202\n",
      "Starting Epoch 215\n",
      "0.5510607232218203\n",
      "Starting Epoch 216\n",
      "0.5505618828794231\n",
      "Starting Epoch 217\n",
      "0.554724756790244\n",
      "Starting Epoch 218\n",
      "0.5506109051082445\n",
      "Starting Epoch 219\n",
      "0.5543692228586777\n",
      "Starting Epoch 220\n",
      "0.5530610447344573\n",
      "Starting Epoch 221\n",
      "0.5496690726798513\n",
      "Starting Epoch 222\n",
      "0.5522053617498149\n",
      "New best model found at epoch 222 with validation loss 0.5365357398986816\n",
      "Starting Epoch 223\n",
      "0.548056818868803\n",
      "New best model found at epoch 223 with validation loss 0.533071756362915\n",
      "Starting Epoch 224\n",
      "0.5474257663540218\n",
      "Starting Epoch 225\n",
      "0.5527224527752918\n",
      "Starting Epoch 226\n",
      "0.5480968498665354\n",
      "Starting Epoch 227\n",
      "0.5473376512527466\n",
      "Starting Epoch 228\n",
      "0.5487227491710497\n",
      "Starting Epoch 229\n",
      "0.5532390734423762\n",
      "Starting Epoch 230\n",
      "0.5481336039045582\n",
      "Starting Epoch 231\n",
      "0.5479663882566534\n",
      "Starting Epoch 232\n",
      "0.5454766504142595\n",
      "Starting Epoch 233\n",
      "0.5468655630298282\n",
      "Starting Epoch 234\n",
      "0.5486823100110759\n",
      "Starting Epoch 235\n",
      "0.5482398880564648\n",
      "Starting Epoch 236\n",
      "0.5489830296972523\n",
      "New best model found at epoch 236 with validation loss 0.5314701199531555\n",
      "Starting Epoch 237\n",
      "0.5509245939876722\n",
      "Starting Epoch 238\n",
      "0.5487532486086306\n",
      "Starting Epoch 239\n",
      "0.5486689624579056\n",
      "Starting Epoch 240\n",
      "0.5457586866358052\n",
      "Starting Epoch 241\n",
      "0.5442017057667607\n",
      "Starting Epoch 242\n",
      "0.5490291351857393\n",
      "New best model found at epoch 242 with validation loss 0.5284857749938965\n",
      "Starting Epoch 243\n",
      "0.5435943629430688\n",
      "Starting Epoch 244\n",
      "0.5460697438405908\n",
      "Starting Epoch 245\n",
      "0.5456283999525983\n",
      "Starting Epoch 246\n",
      "0.5468628380609595\n",
      "Starting Epoch 247\n",
      "0.5441080552080403\n",
      "Starting Epoch 248\n",
      "0.5474928099176158\n",
      "Starting Epoch 249\n",
      "0.546352215435194\n",
      "Starting Epoch 250\n",
      "0.5438698374706766\n",
      "Starting Epoch 251\n",
      "0.5419991690179576\n",
      "Starting Epoch 252\n",
      "0.5425277676271356\n",
      "Starting Epoch 253\n",
      "0.5422894423422606\n",
      "Starting Epoch 254\n",
      "0.5442644189233365\n",
      "Starting Epoch 255\n",
      "0.5425060663534247\n",
      "Starting Epoch 256\n",
      "0.5431890189647675\n",
      "Starting Epoch 257\n",
      "0.5435686215110447\n",
      "Starting Epoch 258\n",
      "0.5421916065008744\n",
      "Starting Epoch 259\n",
      "0.5429013708363408\n",
      "New best model found at epoch 259 with validation loss 0.527111828327179\n",
      "Starting Epoch 260\n",
      "0.5424169185368911\n",
      "Starting Epoch 261\n",
      "0.542818660321443\n",
      "Starting Epoch 262\n",
      "0.5414682406446208\n",
      "Starting Epoch 263\n",
      "0.5434156112048937\n",
      "Starting Epoch 264\n",
      "0.5493602558322574\n",
      "New best model found at epoch 264 with validation loss 0.5267295241355896\n",
      "Starting Epoch 265\n",
      "0.5428535912347876\n",
      "Starting Epoch 266\n",
      "0.5419028453204943\n",
      "Starting Epoch 267\n",
      "0.5463561933973561\n",
      "Starting Epoch 268\n",
      "0.5414937151514966\n",
      "Starting Epoch 269\n",
      "0.5459410444549893\n",
      "Starting Epoch 270\n",
      "0.5390836777894393\n",
      "Starting Epoch 271\n",
      "0.5401652766310651\n",
      "Starting Epoch 272\n",
      "0.5437117568824602\n",
      "Starting Epoch 273\n",
      "0.5404232882935068\n",
      "Starting Epoch 274\n",
      "0.5386597021766331\n",
      "Starting Epoch 275\n",
      "0.5402709206809169\n",
      "Starting Epoch 276\n",
      "0.5389922403770945\n",
      "Starting Epoch 277\n",
      "0.5401974333369214\n",
      "Starting Epoch 278\n",
      "0.5397787210733994\n",
      "New best model found at epoch 278 with validation loss 0.5244514346122742\n",
      "Starting Epoch 279\n",
      "0.5383342115775399\n",
      "Starting Epoch 280\n",
      "0.5430280384810074\n",
      "Starting Epoch 281\n",
      "0.5370890239010686\n",
      "Starting Epoch 282\n",
      "0.5411980320578036\n",
      "Starting Epoch 283\n",
      "0.5422543339107347\n",
      "Starting Epoch 284\n",
      "0.5400317751842997\n",
      "Starting Epoch 285\n",
      "0.5392948039199995\n",
      "Starting Epoch 286\n",
      "0.5379442831744319\n",
      "Starting Epoch 287\n",
      "0.5380955727204032\n",
      "Starting Epoch 288\n",
      "0.5407049915064936\n",
      "Starting Epoch 289\n",
      "0.5410013626451078\n",
      "Starting Epoch 290\n",
      "0.5390635145747144\n",
      "Starting Epoch 291\n",
      "0.5397369006405706\n",
      "Starting Epoch 292\n",
      "0.5375547201737113\n",
      "Starting Epoch 293\n",
      "0.5374449698821359\n",
      "Starting Epoch 294\n",
      "0.5387173178403274\n",
      "Starting Epoch 295\n",
      "0.539057476365048\n",
      "Starting Epoch 296\n",
      "0.544547298680181\n",
      "Starting Epoch 297\n",
      "0.5399998931781106\n",
      "Starting Epoch 298\n",
      "0.5389285489268925\n",
      "Starting Epoch 299\n",
      "0.5401302394659623\n",
      "Starting Epoch 300\n",
      "0.5377386510372162\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-min: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79fd46",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f68c8a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7ad7363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,6,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "30a50646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'max(container counts)', 'max(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "adc37e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2e807b58-d8cc-4794-abd8-bdadae092f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.359803883925728\n",
      "New best model found at epoch 1 with validation loss 0.6891904473304749\n",
      "Starting Epoch 2\n",
      "0.6869403901307479\n",
      "Starting Epoch 3\n",
      "0.6797575225000796\n",
      "New best model found at epoch 3 with validation loss 0.6820470094680786\n",
      "Starting Epoch 4\n",
      "0.6740458141202512\n",
      "New best model found at epoch 4 with validation loss 0.6638175845146179\n",
      "Starting Epoch 5\n",
      "0.6648079286450925\n",
      "New best model found at epoch 5 with validation loss 0.6539337635040283\n",
      "Starting Epoch 6\n",
      "0.6582929777062457\n",
      "New best model found at epoch 6 with validation loss 0.6471114158630371\n",
      "Starting Epoch 7\n",
      "0.6509085478989974\n",
      "New best model found at epoch 7 with validation loss 0.634216845035553\n",
      "Starting Epoch 8\n",
      "0.6458058072173077\n",
      "New best model found at epoch 8 with validation loss 0.6233139634132385\n",
      "Starting Epoch 9\n",
      "0.646480925705122\n",
      "Starting Epoch 10\n",
      "0.6317401554273523\n",
      "New best model found at epoch 10 with validation loss 0.6128538846969604\n",
      "Starting Epoch 11\n",
      "0.6358597460000411\n",
      "Starting Epoch 12\n",
      "0.6348408020060995\n",
      "New best model found at epoch 12 with validation loss 0.6053946614265442\n",
      "Starting Epoch 13\n",
      "0.6193409899006719\n",
      "Starting Epoch 14\n",
      "0.6231563635494398\n",
      "New best model found at epoch 14 with validation loss 0.5945721864700317\n",
      "Starting Epoch 15\n",
      "0.6136963108311528\n",
      "Starting Epoch 16\n",
      "0.6125505566596985\n",
      "Starting Epoch 17\n",
      "0.617911608322807\n",
      "New best model found at epoch 17 with validation loss 0.5832099914550781\n",
      "Starting Epoch 18\n",
      "0.6168991560521333\n",
      "Starting Epoch 19\n",
      "0.609948886477429\n",
      "Starting Epoch 20\n",
      "0.6064058023950328\n",
      "New best model found at epoch 20 with validation loss 0.5763537883758545\n",
      "Starting Epoch 21\n",
      "0.6012533903121948\n",
      "Starting Epoch 22\n",
      "0.5943328297656515\n",
      "Starting Epoch 23\n",
      "0.5968200849450153\n",
      "New best model found at epoch 23 with validation loss 0.5700703859329224\n",
      "Starting Epoch 24\n",
      "0.5964660696361376\n",
      "Starting Epoch 25\n",
      "0.5939575926117275\n",
      "Starting Epoch 26\n",
      "0.5915883468545001\n",
      "Starting Epoch 27\n",
      "0.5917105078697205\n",
      "New best model found at epoch 27 with validation loss 0.5677330493927002\n",
      "Starting Epoch 28\n",
      "0.5954065141470536\n",
      "Starting Epoch 29\n",
      "0.5918818660404371\n",
      "New best model found at epoch 29 with validation loss 0.5611289739608765\n",
      "Starting Epoch 30\n",
      "0.5920526903608571\n",
      "Starting Epoch 31\n",
      "0.5873173138369685\n",
      "Starting Epoch 32\n",
      "0.591156982857248\n",
      "New best model found at epoch 32 with validation loss 0.5595170259475708\n",
      "Starting Epoch 33\n",
      "0.5884715862896132\n",
      "Starting Epoch 34\n",
      "0.589953274830528\n",
      "Starting Epoch 35\n",
      "0.5838358739148015\n",
      "Starting Epoch 36\n",
      "0.5857079599214636\n",
      "Starting Epoch 37\n",
      "0.579314472882644\n",
      "Starting Epoch 38\n",
      "0.5838538408279419\n",
      "New best model found at epoch 38 with validation loss 0.5523755550384521\n",
      "Starting Epoch 39\n",
      "0.5805595491243445\n",
      "Starting Epoch 40\n",
      "0.5776820623356363\n",
      "Starting Epoch 41\n",
      "0.5785022637118464\n",
      "Starting Epoch 42\n",
      "0.5782177901786306\n",
      "Starting Epoch 43\n",
      "0.5787074902783269\n",
      "New best model found at epoch 43 with validation loss 0.5499972105026245\n",
      "Starting Epoch 44\n",
      "0.5884124610735022\n",
      "Starting Epoch 45\n",
      "0.5798609101254008\n",
      "Starting Epoch 46\n",
      "0.5775670797928519\n",
      "Starting Epoch 47\n",
      "0.5762649048929629\n",
      "Starting Epoch 48\n",
      "0.5753799469574638\n",
      "New best model found at epoch 48 with validation loss 0.5475226640701294\n",
      "Starting Epoch 49\n",
      "0.5756175518035889\n",
      "New best model found at epoch 49 with validation loss 0.5465737581253052\n",
      "Starting Epoch 50\n",
      "0.5718241670857305\n",
      "Starting Epoch 51\n",
      "0.5708640010460563\n",
      "Starting Epoch 52\n",
      "0.5676770339841428\n",
      "Starting Epoch 53\n",
      "0.5654249839160753\n",
      "Starting Epoch 54\n",
      "0.5643036469169285\n",
      "New best model found at epoch 54 with validation loss 0.5464230179786682\n",
      "Starting Epoch 55\n",
      "0.5669183834739353\n",
      "Starting Epoch 56\n",
      "0.564767255731251\n",
      "Starting Epoch 57\n",
      "0.567822718101999\n",
      "Starting Epoch 58\n",
      "0.562593382337819\n",
      "New best model found at epoch 58 with validation loss 0.5418428778648376\n",
      "Starting Epoch 59\n",
      "0.5621076951856199\n",
      "Starting Epoch 60\n",
      "0.5650520195131716\n",
      "Starting Epoch 61\n",
      "0.5592529993990193\n",
      "New best model found at epoch 61 with validation loss 0.5364344120025635\n",
      "Starting Epoch 62\n",
      "0.5623705516690793\n",
      "Starting Epoch 63\n",
      "0.5591307645258696\n",
      "New best model found at epoch 63 with validation loss 0.5362205505371094\n",
      "Starting Epoch 64\n",
      "0.5620407332544741\n",
      "Starting Epoch 65\n",
      "0.5590048380520033\n",
      "Starting Epoch 66\n",
      "0.555834482545438\n",
      "Starting Epoch 67\n",
      "0.5570772730785868\n",
      "Starting Epoch 68\n",
      "0.558303678813188\n",
      "Starting Epoch 69\n",
      "0.5581688362619152\n",
      "New best model found at epoch 69 with validation loss 0.5331883430480957\n",
      "Starting Epoch 70\n",
      "0.5560940206050873\n",
      "Starting Epoch 71\n",
      "0.5568578580151433\n",
      "Starting Epoch 72\n",
      "0.5580003611419512\n",
      "New best model found at epoch 72 with validation loss 0.5308843851089478\n",
      "Starting Epoch 73\n",
      "0.5554183889990267\n",
      "Starting Epoch 74\n",
      "0.5572238214637922\n",
      "Starting Epoch 75\n",
      "0.5568196643953738\n",
      "New best model found at epoch 75 with validation loss 0.530841052532196\n",
      "Starting Epoch 76\n",
      "0.5550824300102566\n",
      "Starting Epoch 77\n",
      "0.5538774651029835\n",
      "New best model found at epoch 77 with validation loss 0.5293024778366089\n",
      "Starting Epoch 78\n",
      "0.5505940214447353\n",
      "Starting Epoch 79\n",
      "0.5548594451468923\n",
      "Starting Epoch 80\n",
      "0.5521691402663356\n",
      "New best model found at epoch 80 with validation loss 0.5276802182197571\n",
      "Starting Epoch 81\n",
      "0.5547255886637646\n",
      "New best model found at epoch 81 with validation loss 0.5273599028587341\n",
      "Starting Epoch 82\n",
      "0.5508084608160931\n",
      "Starting Epoch 83\n",
      "0.5526470969552579\n",
      "New best model found at epoch 83 with validation loss 0.5273371338844299\n",
      "Starting Epoch 84\n",
      "0.5511766451856365\n",
      "Starting Epoch 85\n",
      "0.5505671488202136\n",
      "Starting Epoch 86\n",
      "0.5480265319347382\n",
      "Starting Epoch 87\n",
      "0.5526443693948828\n",
      "New best model found at epoch 87 with validation loss 0.5239425301551819\n",
      "Starting Epoch 88\n",
      "0.549447967954304\n",
      "New best model found at epoch 88 with validation loss 0.5218884944915771\n",
      "Starting Epoch 89\n",
      "0.5513943537421848\n",
      "Starting Epoch 90\n",
      "0.5476472921993422\n",
      "Starting Epoch 91\n",
      "0.5484233900256779\n",
      "Starting Epoch 92\n",
      "0.5464308261871338\n",
      "New best model found at epoch 92 with validation loss 0.5213850736618042\n",
      "Starting Epoch 93\n",
      "0.549790646718896\n",
      "New best model found at epoch 93 with validation loss 0.5193544030189514\n",
      "Starting Epoch 94\n",
      "0.5473002946895101\n",
      "Starting Epoch 95\n",
      "0.5460293772427932\n",
      "Starting Epoch 96\n",
      "0.5476394192032192\n",
      "Starting Epoch 97\n",
      "0.5431716480980748\n",
      "Starting Epoch 98\n",
      "0.5436819986156796\n",
      "New best model found at epoch 98 with validation loss 0.5186677575111389\n",
      "Starting Epoch 99\n",
      "0.5460489793964054\n",
      "Starting Epoch 100\n",
      "0.5435344874858856\n",
      "Starting Epoch 101\n",
      "0.5438223986522012\n",
      "Starting Epoch 102\n",
      "0.5464554027370785\n",
      "New best model found at epoch 102 with validation loss 0.5180577039718628\n",
      "Starting Epoch 103\n",
      "0.5434517951115317\n",
      "Starting Epoch 104\n",
      "0.5449110917423082\n",
      "Starting Epoch 105\n",
      "0.542110387397849\n",
      "Starting Epoch 106\n",
      "0.5429791704468105\n",
      "Starting Epoch 107\n",
      "0.5434326140776925\n",
      "New best model found at epoch 107 with validation loss 0.5177810788154602\n",
      "Starting Epoch 108\n",
      "0.5426405240660128\n",
      "New best model found at epoch 108 with validation loss 0.5175659656524658\n",
      "Starting Epoch 109\n",
      "0.5392303142858588\n",
      "New best model found at epoch 109 with validation loss 0.5160760283470154\n",
      "Starting Epoch 110\n",
      "0.5414674567139667\n",
      "Starting Epoch 111\n",
      "0.5415429602498594\n",
      "Starting Epoch 112\n",
      "0.5465008370254351\n",
      "Starting Epoch 113\n",
      "0.5410818716754084\n",
      "Starting Epoch 114\n",
      "0.5375801920890808\n",
      "Starting Epoch 115\n",
      "0.5372895494751309\n",
      "New best model found at epoch 115 with validation loss 0.5126149654388428\n",
      "Starting Epoch 116\n",
      "0.5425482262735781\n",
      "Starting Epoch 117\n",
      "0.5386347757733386\n",
      "Starting Epoch 118\n",
      "0.5397709789483444\n",
      "Starting Epoch 119\n",
      "0.5388032081334487\n",
      "Starting Epoch 120\n",
      "0.5360118967035542\n",
      "Starting Epoch 121\n",
      "0.5395197103852811\n",
      "Starting Epoch 122\n",
      "0.5398682913054591\n",
      "Starting Epoch 123\n",
      "0.5370542031267415\n",
      "Starting Epoch 124\n",
      "0.5358690386233123\n",
      "Starting Epoch 125\n",
      "0.5370040820992511\n",
      "New best model found at epoch 125 with validation loss 0.5108625888824463\n",
      "Starting Epoch 126\n",
      "0.5353077274301777\n",
      "Starting Epoch 127\n",
      "0.5339814618877743\n",
      "Starting Epoch 128\n",
      "0.5402070750360903\n",
      "Starting Epoch 129\n",
      "0.5353315550348033\n",
      "Starting Epoch 130\n",
      "0.5349624636380569\n",
      "Starting Epoch 131\n",
      "0.5311962897362916\n",
      "Starting Epoch 132\n",
      "0.5354936226554539\n",
      "Starting Epoch 133\n",
      "0.532148549090261\n",
      "Starting Epoch 134\n",
      "0.5314229856366697\n",
      "Starting Epoch 135\n",
      "0.5329569798448811\n",
      "Starting Epoch 136\n",
      "0.5336594076260276\n",
      "Starting Epoch 137\n",
      "0.5318604526312455\n",
      "New best model found at epoch 137 with validation loss 0.5084008574485779\n",
      "Starting Epoch 138\n",
      "0.5288339801456617\n",
      "Starting Epoch 139\n",
      "0.5302585207897684\n",
      "Starting Epoch 140\n",
      "0.5297274447005728\n",
      "Starting Epoch 141\n",
      "0.5341559635556262\n",
      "Starting Epoch 142\n",
      "0.5290019706539486\n",
      "Starting Epoch 143\n",
      "0.5305944590464883\n",
      "Starting Epoch 144\n",
      "0.5290140872416289\n",
      "New best model found at epoch 144 with validation loss 0.5073074698448181\n",
      "Starting Epoch 145\n",
      "0.5271984597911006\n",
      "Starting Epoch 146\n",
      "0.5290677625200023\n",
      "Starting Epoch 147\n",
      "0.5303845366706019\n",
      "Starting Epoch 148\n",
      "0.5306227919848069\n",
      "Starting Epoch 149\n",
      "0.5316789422346198\n",
      "Starting Epoch 150\n",
      "0.5309745073318481\n",
      "Starting Epoch 151\n",
      "0.5275139523589093\n",
      "Starting Epoch 152\n",
      "0.5260599436967269\n",
      "Starting Epoch 153\n",
      "0.5285899885322737\n",
      "Starting Epoch 154\n",
      "0.5307421749052794\n",
      "Starting Epoch 155\n",
      "0.5242879261141238\n",
      "Starting Epoch 156\n",
      "0.5301484543344249\n",
      "Starting Epoch 157\n",
      "0.5290223735830059\n",
      "Starting Epoch 158\n",
      "0.5276589626851289\n",
      "New best model found at epoch 158 with validation loss 0.5070119500160217\n",
      "Starting Epoch 159\n",
      "0.5286359385303829\n",
      "Starting Epoch 160\n",
      "0.5277643838654393\n",
      "Starting Epoch 161\n",
      "0.5238717755545741\n",
      "New best model found at epoch 161 with validation loss 0.505474865436554\n",
      "Starting Epoch 162\n",
      "0.5273708053257155\n",
      "Starting Epoch 163\n",
      "0.5276260920192885\n",
      "Starting Epoch 164\n",
      "0.526380251283231\n",
      "Starting Epoch 165\n",
      "0.5248248447542605\n",
      "Starting Epoch 166\n",
      "0.5233423010162686\n",
      "Starting Epoch 167\n",
      "0.5269597405972688\n",
      "Starting Epoch 168\n",
      "0.5255422268224799\n",
      "Starting Epoch 169\n",
      "0.5226634663084279\n",
      "Starting Epoch 170\n",
      "0.526603718166766\n",
      "Starting Epoch 171\n",
      "0.5231207233408223\n",
      "Starting Epoch 172\n",
      "0.5218080437701681\n",
      "Starting Epoch 173\n",
      "0.5204944779043612\n",
      "New best model found at epoch 173 with validation loss 0.5043768882751465\n",
      "Starting Epoch 174\n",
      "0.5201354467350504\n",
      "Starting Epoch 175\n",
      "0.5218228205390598\n",
      "Starting Epoch 176\n",
      "0.5240368868993677\n",
      "Starting Epoch 177\n",
      "0.5195384479087332\n",
      "Starting Epoch 178\n",
      "0.5292325369689775\n",
      "Starting Epoch 179\n",
      "0.5189114770163661\n",
      "Starting Epoch 180\n",
      "0.521889883538951\n",
      "Starting Epoch 181\n",
      "0.5207196253797283\n",
      "Starting Epoch 182\n",
      "0.5201579539672189\n",
      "Starting Epoch 183\n",
      "0.5216380241124526\n",
      "Starting Epoch 184\n",
      "0.5215907576291458\n",
      "New best model found at epoch 184 with validation loss 0.5027403235435486\n",
      "Starting Epoch 185\n",
      "0.5182555810264919\n",
      "Starting Epoch 186\n",
      "0.5185091560301573\n",
      "Starting Epoch 187\n",
      "0.5208432842855868\n",
      "Starting Epoch 188\n",
      "0.5217055794985398\n",
      "Starting Epoch 189\n",
      "0.5187586921712627\n",
      "Starting Epoch 190\n",
      "0.5151132448859836\n",
      "Starting Epoch 191\n",
      "0.5169733166694641\n",
      "Starting Epoch 192\n",
      "0.5170496572618899\n",
      "Starting Epoch 193\n",
      "0.5178245759528616\n",
      "Starting Epoch 194\n",
      "0.5158771859562915\n",
      "Starting Epoch 195\n",
      "0.518745630979538\n",
      "Starting Epoch 196\n",
      "0.5149478705033012\n",
      "Starting Epoch 197\n",
      "0.5147895527922589\n",
      "Starting Epoch 198\n",
      "0.5164069364900175\n",
      "Starting Epoch 199\n",
      "0.5183399812034939\n",
      "Starting Epoch 200\n",
      "0.5160896855851879\n",
      "Starting Epoch 201\n",
      "0.5165197136609451\n",
      "Starting Epoch 202\n",
      "0.5152408700922261\n",
      "New best model found at epoch 202 with validation loss 0.5027203559875488\n",
      "Starting Epoch 203\n",
      "0.5152802052705184\n",
      "Starting Epoch 204\n",
      "0.5137095412482386\n",
      "Starting Epoch 205\n",
      "0.5113370444463647\n",
      "Starting Epoch 206\n",
      "0.5137550908586254\n",
      "Starting Epoch 207\n",
      "0.5150808679020923\n",
      "New best model found at epoch 207 with validation loss 0.5019852519035339\n",
      "Starting Epoch 208\n",
      "0.5129740743533425\n",
      "Starting Epoch 209\n",
      "0.5146919942420461\n",
      "Starting Epoch 210\n",
      "0.5129761488541312\n",
      "Starting Epoch 211\n",
      "0.5135974275029224\n",
      "Starting Epoch 212\n",
      "0.5130502646384032\n",
      "Starting Epoch 213\n",
      "0.5120714164298513\n",
      "Starting Epoch 214\n",
      "0.5114450895267985\n",
      "Starting Epoch 215\n",
      "0.5125419497489929\n",
      "Starting Epoch 216\n",
      "0.5116707151350768\n",
      "Starting Epoch 217\n",
      "0.5152452030907506\n",
      "Starting Epoch 218\n",
      "0.5127283490222433\n",
      "Starting Epoch 219\n",
      "0.513515802829162\n",
      "Starting Epoch 220\n",
      "0.5105122470337412\n",
      "Starting Epoch 221\n",
      "0.5114446671112723\n",
      "Starting Epoch 222\n",
      "0.5120763778686523\n",
      "Starting Epoch 223\n",
      "0.5083535572756892\n",
      "Starting Epoch 224\n",
      "0.5071840519490449\n",
      "Starting Epoch 225\n",
      "0.5099956743095232\n",
      "Starting Epoch 226\n",
      "0.5113515957542087\n",
      "Starting Epoch 227\n",
      "0.5079101220421169\n",
      "Starting Epoch 228\n",
      "0.5112719548785168\n",
      "Starting Epoch 229\n",
      "0.5096697612949039\n",
      "Starting Epoch 230\n",
      "0.5067722862181456\n",
      "Starting Epoch 231\n",
      "0.5091038307417994\n",
      "Starting Epoch 232\n",
      "0.5082441568374634\n",
      "Starting Epoch 233\n",
      "0.505883206491885\n",
      "Starting Epoch 234\n",
      "0.5087820032368535\n",
      "Starting Epoch 235\n",
      "0.5075635391732921\n",
      "Starting Epoch 236\n",
      "0.5076165808283765\n",
      "Starting Epoch 237\n",
      "0.5084073090034983\n",
      "New best model found at epoch 237 with validation loss 0.501334547996521\n",
      "Starting Epoch 238\n",
      "0.50840806313183\n",
      "Starting Epoch 239\n",
      "0.5058744744114254\n",
      "Starting Epoch 240\n",
      "0.5076237826243691\n",
      "Starting Epoch 241\n",
      "0.5025582624518353\n",
      "Starting Epoch 242\n",
      "0.5063035527001256\n",
      "Starting Epoch 243\n",
      "0.5060049735981486\n",
      "Starting Epoch 244\n",
      "0.5082206181857897\n",
      "Starting Epoch 245\n",
      "0.5045292934645778\n",
      "Starting Epoch 246\n",
      "0.5076991073463274\n",
      "Starting Epoch 247\n",
      "0.5031444559926572\n",
      "New best model found at epoch 247 with validation loss 0.5005592107772827\n",
      "Starting Epoch 248\n",
      "0.5074146700941998\n",
      "Starting Epoch 249\n",
      "0.5057098101014676\n",
      "Starting Epoch 250\n",
      "0.5048907230729642\n",
      "Starting Epoch 251\n",
      "0.5032579406448032\n",
      "Starting Epoch 252\n",
      "0.5036732489648073\n",
      "Starting Epoch 253\n",
      "0.5017363999200903\n",
      "Starting Epoch 254\n",
      "0.5029259051965631\n",
      "Starting Epoch 255\n",
      "0.5059429471907408\n",
      "Starting Epoch 256\n",
      "0.5022704484670059\n",
      "Starting Epoch 257\n",
      "0.5050326145213583\n",
      "Starting Epoch 258\n",
      "0.5033744780913644\n",
      "Starting Epoch 259\n",
      "0.50466657721478\n",
      "New best model found at epoch 259 with validation loss 0.4985414445400238\n",
      "Starting Epoch 260\n",
      "0.5014945216800856\n",
      "Starting Epoch 261\n",
      "0.5023878644342008\n",
      "Starting Epoch 262\n",
      "0.5029129709886468\n",
      "Starting Epoch 263\n",
      "0.5033485280430835\n",
      "Starting Epoch 264\n",
      "0.5032465794812078\n",
      "New best model found at epoch 264 with validation loss 0.49798253178596497\n",
      "Starting Epoch 265\n",
      "0.5024363657702571\n",
      "Starting Epoch 266\n",
      "0.4988324875416963\n",
      "Starting Epoch 267\n",
      "0.5072352808454762\n",
      "Starting Epoch 268\n",
      "0.5004241077796273\n",
      "Starting Epoch 269\n",
      "0.49861871548320935\n",
      "Starting Epoch 270\n",
      "0.49467209499815235\n",
      "Starting Epoch 271\n",
      "0.49714153098023456\n",
      "Starting Epoch 272\n",
      "0.500106859466304\n",
      "New best model found at epoch 272 with validation loss 0.49722322821617126\n",
      "Starting Epoch 273\n",
      "0.4977351712143939\n",
      "New best model found at epoch 273 with validation loss 0.4950219988822937\n",
      "Starting Epoch 274\n",
      "0.496847804473794\n",
      "Starting Epoch 275\n",
      "0.4935701282128044\n",
      "Starting Epoch 276\n",
      "0.49675576194472937\n",
      "Starting Epoch 277\n",
      "0.49548419143842615\n",
      "Starting Epoch 278\n",
      "0.49309167654617975\n",
      "New best model found at epoch 278 with validation loss 0.4943681061267853\n",
      "Starting Epoch 279\n",
      "0.49390372504358704\n",
      "Starting Epoch 280\n",
      "0.4977260646612748\n",
      "Starting Epoch 281\n",
      "0.4905176888341489\n",
      "Starting Epoch 282\n",
      "0.49094670363094495\n",
      "Starting Epoch 283\n",
      "0.49276204731153406\n",
      "Starting Epoch 284\n",
      "0.4944821272207343\n",
      "Starting Epoch 285\n",
      "0.4918802445349486\n",
      "New best model found at epoch 285 with validation loss 0.4937399923801422\n",
      "Starting Epoch 286\n",
      "0.4906639068023018\n",
      "Starting Epoch 287\n",
      "0.49024648251740827\n",
      "Starting Epoch 288\n",
      "0.4898740415987761\n",
      "Starting Epoch 289\n",
      "0.4914614674837693\n",
      "Starting Epoch 290\n",
      "0.49479723883711774\n",
      "New best model found at epoch 290 with validation loss 0.49163007736206055\n",
      "Starting Epoch 291\n",
      "0.4851977669674417\n",
      "Starting Epoch 292\n",
      "0.48994620468305505\n",
      "Starting Epoch 293\n",
      "0.49020229215207306\n",
      "Starting Epoch 294\n",
      "0.48994905145271966\n",
      "Starting Epoch 295\n",
      "0.4888994356860285\n",
      "Starting Epoch 296\n",
      "0.4927997887134552\n",
      "Starting Epoch 297\n",
      "0.489264700723731\n",
      "Starting Epoch 298\n",
      "0.49317141330760456\n",
      "Starting Epoch 299\n",
      "0.48862583870473114\n",
      "New best model found at epoch 299 with validation loss 0.48774003982543945\n",
      "Starting Epoch 300\n",
      "0.48805685535721155\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-max: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da889a35",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.25-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "9130c42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "3f05c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,8,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f5668796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'q25(container counts)', 'q25(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2193133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "8f1c41a8-c8cd-48b1-b51b-71e9e3fdfe87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.3816997149716252\n",
      "New best model found at epoch 1 with validation loss 0.6840221285820007\n",
      "Starting Epoch 2\n",
      "0.6839623762213666\n",
      "New best model found at epoch 2 with validation loss 0.6813193559646606\n",
      "Starting Epoch 3\n",
      "0.6740352692811385\n",
      "New best model found at epoch 3 with validation loss 0.6631850600242615\n",
      "Starting Epoch 4\n",
      "0.6597587258919425\n",
      "New best model found at epoch 4 with validation loss 0.6420846581459045\n",
      "Starting Epoch 5\n",
      "0.6492148741431858\n",
      "New best model found at epoch 5 with validation loss 0.6332564949989319\n",
      "Starting Epoch 6\n",
      "0.6394393340401028\n",
      "New best model found at epoch 6 with validation loss 0.6210302710533142\n",
      "Starting Epoch 7\n",
      "0.6357686364132425\n",
      "New best model found at epoch 7 with validation loss 0.6151429414749146\n",
      "Starting Epoch 8\n",
      "0.6299942939177804\n",
      "New best model found at epoch 8 with validation loss 0.6121055483818054\n",
      "Starting Epoch 9\n",
      "0.6379824202993641\n",
      "Starting Epoch 10\n",
      "0.6277386105578878\n",
      "New best model found at epoch 10 with validation loss 0.6080663204193115\n",
      "Starting Epoch 11\n",
      "0.6303653224654819\n",
      "Starting Epoch 12\n",
      "0.6251810918683591\n",
      "Starting Epoch 13\n",
      "0.6171397514965223\n",
      "Starting Epoch 14\n",
      "0.6251221791557644\n",
      "New best model found at epoch 14 with validation loss 0.5890739560127258\n",
      "Starting Epoch 15\n",
      "0.6128749562346417\n",
      "Starting Epoch 16\n",
      "0.6150012249531953\n",
      "Starting Epoch 17\n",
      "0.6106728626334149\n",
      "Starting Epoch 18\n",
      "0.6087116521337758\n",
      "Starting Epoch 19\n",
      "0.6115842487501062\n",
      "Starting Epoch 20\n",
      "0.6133808104888253\n",
      "Starting Epoch 21\n",
      "0.6072863418122997\n",
      "New best model found at epoch 21 with validation loss 0.5868096947669983\n",
      "Starting Epoch 22\n",
      "0.6033155503480331\n",
      "Starting Epoch 23\n",
      "0.6054731063220812\n",
      "New best model found at epoch 23 with validation loss 0.5856066346168518\n",
      "Starting Epoch 24\n",
      "0.5975636451140695\n",
      "New best model found at epoch 24 with validation loss 0.581106424331665\n",
      "Starting Epoch 25\n",
      "0.6096992985061978\n",
      "Starting Epoch 26\n",
      "0.601025446601536\n",
      "New best model found at epoch 26 with validation loss 0.5797727704048157\n",
      "Starting Epoch 27\n",
      "0.5981397421463676\n",
      "Starting Epoch 28\n",
      "0.6047689033591229\n",
      "Starting Epoch 29\n",
      "0.5948438074277795\n",
      "New best model found at epoch 29 with validation loss 0.578188419342041\n",
      "Starting Epoch 30\n",
      "0.594242116679316\n",
      "Starting Epoch 31\n",
      "0.5990088556123816\n",
      "Starting Epoch 32\n",
      "0.5944582275722338\n",
      "Starting Epoch 33\n",
      "0.5943351906278859\n",
      "Starting Epoch 34\n",
      "0.6044011141942895\n",
      "Starting Epoch 35\n",
      "0.5982719763465549\n",
      "Starting Epoch 36\n",
      "0.5904730117839315\n",
      "Starting Epoch 37\n",
      "0.5903220798658289\n",
      "Starting Epoch 38\n",
      "0.5975234456684279\n",
      "Starting Epoch 39\n",
      "0.5880303408788599\n",
      "Starting Epoch 40\n",
      "0.5891391920006793\n",
      "Starting Epoch 41\n",
      "0.5912801778834799\n",
      "Starting Epoch 42\n",
      "0.5919955580130868\n",
      "New best model found at epoch 42 with validation loss 0.5767582058906555\n",
      "Starting Epoch 43\n",
      "0.5913270193597545\n",
      "Starting Epoch 44\n",
      "0.59082590756209\n",
      "Starting Epoch 45\n",
      "0.5926011204719543\n",
      "New best model found at epoch 45 with validation loss 0.5733683705329895\n",
      "Starting Epoch 46\n",
      "0.5882001000901927\n",
      "Starting Epoch 47\n",
      "0.5854577577632406\n",
      "Starting Epoch 48\n",
      "0.5865468538325765\n",
      "Starting Epoch 49\n",
      "0.5859533600185228\n",
      "Starting Epoch 50\n",
      "0.584563250127046\n",
      "Starting Epoch 51\n",
      "0.585789258065431\n",
      "New best model found at epoch 51 with validation loss 0.5712853074073792\n",
      "Starting Epoch 52\n",
      "0.586442293032356\n",
      "Starting Epoch 53\n",
      "0.582454106082087\n",
      "Starting Epoch 54\n",
      "0.5848153389018514\n",
      "Starting Epoch 55\n",
      "0.5822819341783938\n",
      "Starting Epoch 56\n",
      "0.5819095476813938\n",
      "Starting Epoch 57\n",
      "0.5863783359527588\n",
      "Starting Epoch 58\n",
      "0.5781718829403752\n",
      "New best model found at epoch 58 with validation loss 0.56905198097229\n",
      "Starting Epoch 59\n",
      "0.5804736277331477\n",
      "Starting Epoch 60\n",
      "0.5815976106602213\n",
      "Starting Epoch 61\n",
      "0.5829635262489319\n",
      "Starting Epoch 62\n",
      "0.5839841210323832\n",
      "New best model found at epoch 62 with validation loss 0.5683362483978271\n",
      "Starting Epoch 63\n",
      "0.5796851178874141\n",
      "Starting Epoch 64\n",
      "0.5854547619819641\n",
      "Starting Epoch 65\n",
      "0.5807372435279514\n",
      "Starting Epoch 66\n",
      "0.5769257104915121\n",
      "Starting Epoch 67\n",
      "0.578232290952102\n",
      "Starting Epoch 68\n",
      "0.5800318769786669\n",
      "Starting Epoch 69\n",
      "0.5816012724586155\n",
      "Starting Epoch 70\n",
      "0.5759214603382609\n",
      "Starting Epoch 71\n",
      "0.5778527881788171\n",
      "Starting Epoch 72\n",
      "0.5783850213755732\n",
      "New best model found at epoch 72 with validation loss 0.5664962530136108\n",
      "Starting Epoch 73\n",
      "0.5798833214718363\n",
      "Starting Epoch 74\n",
      "0.5780807992686396\n",
      "Starting Epoch 75\n",
      "0.5799482879431351\n",
      "Starting Epoch 76\n",
      "0.5757974204809769\n",
      "Starting Epoch 77\n",
      "0.578866404035817\n",
      "Starting Epoch 78\n",
      "0.5736243569332621\n",
      "Starting Epoch 79\n",
      "0.5747914625250775\n",
      "Starting Epoch 80\n",
      "0.575726515573004\n",
      "Starting Epoch 81\n",
      "0.5792262891064519\n",
      "Starting Epoch 82\n",
      "0.5760488225066144\n",
      "Starting Epoch 83\n",
      "0.5745128781899161\n",
      "New best model found at epoch 83 with validation loss 0.5615112781524658\n",
      "Starting Epoch 84\n",
      "0.5785026511420375\n",
      "Starting Epoch 85\n",
      "0.5763775965441829\n",
      "Starting Epoch 86\n",
      "0.5726586010145105\n",
      "Starting Epoch 87\n",
      "0.574794175832168\n",
      "Starting Epoch 88\n",
      "0.5740344252275384\n",
      "Starting Epoch 89\n",
      "0.5731752411178921\n",
      "Starting Epoch 90\n",
      "0.5725847327190897\n",
      "Starting Epoch 91\n",
      "0.5720864301142485\n",
      "Starting Epoch 92\n",
      "0.5718039585196454\n",
      "Starting Epoch 93\n",
      "0.5749824513559756\n",
      "New best model found at epoch 93 with validation loss 0.5607389211654663\n",
      "Starting Epoch 94\n",
      "0.5720775153325952\n",
      "Starting Epoch 95\n",
      "0.5694021427113077\n",
      "Starting Epoch 96\n",
      "0.5732983920885169\n",
      "Starting Epoch 97\n",
      "0.5693387052287227\n",
      "Starting Epoch 98\n",
      "0.567922415940658\n",
      "Starting Epoch 99\n",
      "0.574024366295856\n",
      "Starting Epoch 100\n",
      "0.5703817891037982\n",
      "Starting Epoch 101\n",
      "0.5694155822629514\n",
      "Starting Epoch 102\n",
      "0.5727219659349193\n",
      "New best model found at epoch 102 with validation loss 0.5602983236312866\n",
      "Starting Epoch 103\n",
      "0.5703121009080306\n",
      "Starting Epoch 104\n",
      "0.5724773847538492\n",
      "Starting Epoch 105\n",
      "0.5695127287636632\n",
      "Starting Epoch 106\n",
      "0.5676226797311202\n",
      "Starting Epoch 107\n",
      "0.5702674000159554\n",
      "New best model found at epoch 107 with validation loss 0.5594491958618164\n",
      "Starting Epoch 108\n",
      "0.5693184759305872\n",
      "Starting Epoch 109\n",
      "0.5695749456467836\n",
      "New best model found at epoch 109 with validation loss 0.5556878447532654\n",
      "Starting Epoch 110\n",
      "0.5665681569472604\n",
      "Starting Epoch 111\n",
      "0.574365364468616\n",
      "Starting Epoch 112\n",
      "0.5778387370316879\n",
      "Starting Epoch 113\n",
      "0.5660542055316593\n",
      "Starting Epoch 114\n",
      "0.5654008932735609\n",
      "Starting Epoch 115\n",
      "0.5658036055772201\n",
      "Starting Epoch 116\n",
      "0.5725323350533195\n",
      "Starting Epoch 117\n",
      "0.5691010615100032\n",
      "Starting Epoch 118\n",
      "0.5653234137141186\n",
      "Starting Epoch 119\n",
      "0.5667643793251204\n",
      "Starting Epoch 120\n",
      "0.5643938831661058\n",
      "Starting Epoch 121\n",
      "0.5694054235582766\n",
      "Starting Epoch 122\n",
      "0.5675515882346941\n",
      "Starting Epoch 123\n",
      "0.5651342454163925\n",
      "Starting Epoch 124\n",
      "0.5658565293187681\n",
      "New best model found at epoch 124 with validation loss 0.5552136898040771\n",
      "Starting Epoch 125\n",
      "0.5692813992500305\n",
      "Starting Epoch 126\n",
      "0.5631537877995035\n",
      "Starting Epoch 127\n",
      "0.5637590781502102\n",
      "Starting Epoch 128\n",
      "0.5708472728729248\n",
      "Starting Epoch 129\n",
      "0.5622914822205253\n",
      "Starting Epoch 130\n",
      "0.5633734037046847\n",
      "New best model found at epoch 130 with validation loss 0.5540964603424072\n",
      "Starting Epoch 131\n",
      "0.5672767408516096\n",
      "New best model found at epoch 131 with validation loss 0.5530741214752197\n",
      "Starting Epoch 132\n",
      "0.5701679794684701\n",
      "Starting Epoch 133\n",
      "0.5632688299469326\n",
      "Starting Epoch 134\n",
      "0.5703906676043635\n",
      "Starting Epoch 135\n",
      "0.5653900400451992\n",
      "Starting Epoch 136\n",
      "0.5649415332338085\n",
      "New best model found at epoch 136 with validation loss 0.5518897175788879\n",
      "Starting Epoch 137\n",
      "0.5604578438012496\n",
      "Starting Epoch 138\n",
      "0.5613808113595714\n",
      "New best model found at epoch 138 with validation loss 0.5499697923660278\n",
      "Starting Epoch 139\n",
      "0.5636646164500195\n",
      "New best model found at epoch 139 with validation loss 0.5499039888381958\n",
      "Starting Epoch 140\n",
      "0.5672220199004464\n",
      "Starting Epoch 141\n",
      "0.5641098735125168\n",
      "Starting Epoch 142\n",
      "0.5642877739408741\n",
      "Starting Epoch 143\n",
      "0.563762067452721\n",
      "Starting Epoch 144\n",
      "0.5599074713561846\n",
      "Starting Epoch 145\n",
      "0.5615245479604473\n",
      "Starting Epoch 146\n",
      "0.5604299047718877\n",
      "Starting Epoch 147\n",
      "0.5612870195637578\n",
      "Starting Epoch 148\n",
      "0.5632800835630168\n",
      "Starting Epoch 149\n",
      "0.5637083597805189\n",
      "Starting Epoch 150\n",
      "0.5632593813149825\n",
      "Starting Epoch 151\n",
      "0.563687933527905\n",
      "Starting Epoch 152\n",
      "0.5592530006947725\n",
      "Starting Epoch 153\n",
      "0.5580144407956497\n",
      "Starting Epoch 154\n",
      "0.566865016584811\n",
      "Starting Epoch 155\n",
      "0.5585951260898424\n",
      "Starting Epoch 156\n",
      "0.5608426941477734\n",
      "Starting Epoch 157\n",
      "0.564391500276068\n",
      "Starting Epoch 158\n",
      "0.5600333032400712\n",
      "Starting Epoch 159\n",
      "0.5601103772287783\n",
      "Starting Epoch 160\n",
      "0.5577866499838622\n",
      "Starting Epoch 161\n",
      "0.5584738798763441\n",
      "Starting Epoch 162\n",
      "0.5617273981156556\n",
      "Starting Epoch 163\n",
      "0.5605883792690609\n",
      "Starting Epoch 164\n",
      "0.5658033956652102\n",
      "Starting Epoch 165\n",
      "0.5582835907521455\n",
      "Starting Epoch 166\n",
      "0.5562177132005277\n",
      "New best model found at epoch 166 with validation loss 0.547171950340271\n",
      "Starting Epoch 167\n",
      "0.559350267700527\n",
      "Starting Epoch 168\n",
      "0.5608265736828679\n",
      "Starting Epoch 169\n",
      "0.5597196998803512\n",
      "Starting Epoch 170\n",
      "0.5577558343825133\n",
      "Starting Epoch 171\n",
      "0.5580989213093467\n",
      "Starting Epoch 172\n",
      "0.5590517793012701\n",
      "Starting Epoch 173\n",
      "0.5577599509902622\n",
      "New best model found at epoch 173 with validation loss 0.5469694137573242\n",
      "Starting Epoch 174\n",
      "0.5560241315675818\n",
      "Starting Epoch 175\n",
      "0.5570176995318868\n",
      "Starting Epoch 176\n",
      "0.5584559932998989\n",
      "Starting Epoch 177\n",
      "0.5554280475429867\n",
      "Starting Epoch 178\n",
      "0.5629451508107393\n",
      "Starting Epoch 179\n",
      "0.5621250323627306\n",
      "Starting Epoch 180\n",
      "0.558700152065443\n",
      "Starting Epoch 181\n",
      "0.5622148047322812\n",
      "Starting Epoch 182\n",
      "0.5587196168692216\n",
      "Starting Epoch 183\n",
      "0.5573851103368013\n",
      "Starting Epoch 184\n",
      "0.5566817133323007\n",
      "New best model found at epoch 184 with validation loss 0.5440325140953064\n",
      "Starting Epoch 185\n",
      "0.5565616164518439\n",
      "Starting Epoch 186\n",
      "0.5551215565722921\n",
      "Starting Epoch 187\n",
      "0.561958820923515\n",
      "Starting Epoch 188\n",
      "0.5582553264887437\n",
      "Starting Epoch 189\n",
      "0.5548936867195627\n",
      "New best model found at epoch 189 with validation loss 0.5429039001464844\n",
      "Starting Epoch 190\n",
      "0.5555469847243765\n",
      "Starting Epoch 191\n",
      "0.5569359452828117\n",
      "Starting Epoch 192\n",
      "0.5572097949359728\n",
      "Starting Epoch 193\n",
      "0.5537905796714451\n",
      "Starting Epoch 194\n",
      "0.5550671608551688\n",
      "Starting Epoch 195\n",
      "0.5539885111477064\n",
      "Starting Epoch 196\n",
      "0.5576453066390493\n",
      "Starting Epoch 197\n",
      "0.5562597603901572\n",
      "Starting Epoch 198\n",
      "0.5549897188725679\n",
      "Starting Epoch 199\n",
      "0.5535192852434905\n",
      "Starting Epoch 200\n",
      "0.559286311916683\n",
      "Starting Epoch 201\n",
      "0.5563530896020972\n",
      "Starting Epoch 202\n",
      "0.5557307937870855\n",
      "Starting Epoch 203\n",
      "0.5543231756790824\n",
      "Starting Epoch 204\n",
      "0.5512455196484275\n",
      "Starting Epoch 205\n",
      "0.5565395316352015\n",
      "New best model found at epoch 205 with validation loss 0.5424322485923767\n",
      "Starting Epoch 206\n",
      "0.5544814298982206\n",
      "Starting Epoch 207\n",
      "0.5538159842076509\n",
      "Starting Epoch 208\n",
      "0.5567102069440095\n",
      "Starting Epoch 209\n",
      "0.5561675818070121\n",
      "Starting Epoch 210\n",
      "0.5570687275865803\n",
      "Starting Epoch 211\n",
      "0.552118885776271\n",
      "New best model found at epoch 211 with validation loss 0.5421419739723206\n",
      "Starting Epoch 212\n",
      "0.5536706343941067\n",
      "Starting Epoch 213\n",
      "0.5545042481111444\n",
      "Starting Epoch 214\n",
      "0.5530548328938691\n",
      "Starting Epoch 215\n",
      "0.5564408457797506\n",
      "Starting Epoch 216\n",
      "0.5523849531360294\n",
      "Starting Epoch 217\n",
      "0.5558805698933809\n",
      "Starting Epoch 218\n",
      "0.5555005475230839\n",
      "Starting Epoch 219\n",
      "0.554063812546108\n",
      "Starting Epoch 220\n",
      "0.5525884511678115\n",
      "Starting Epoch 221\n",
      "0.5501337725183238\n",
      "Starting Epoch 222\n",
      "0.5543052152447079\n",
      "Starting Epoch 223\n",
      "0.5510868520840354\n",
      "New best model found at epoch 223 with validation loss 0.5418525338172913\n",
      "Starting Epoch 224\n",
      "0.5528114697207576\n",
      "Starting Epoch 225\n",
      "0.5535832410273345\n",
      "Starting Epoch 226\n",
      "0.5539591066215349\n",
      "Starting Epoch 227\n",
      "0.5512207927911178\n",
      "Starting Epoch 228\n",
      "0.5516446401243624\n",
      "Starting Epoch 229\n",
      "0.5560076923474021\n",
      "New best model found at epoch 229 with validation loss 0.5414772033691406\n",
      "Starting Epoch 230\n",
      "0.5509833473226299\n",
      "Starting Epoch 231\n",
      "0.5562835659669794\n",
      "Starting Epoch 232\n",
      "0.5515488476856895\n",
      "Starting Epoch 233\n",
      "0.5500407620616581\n",
      "Starting Epoch 234\n",
      "0.55343900685725\n",
      "Starting Epoch 235\n",
      "0.554331599370293\n",
      "Starting Epoch 236\n",
      "0.5546944076600282\n",
      "New best model found at epoch 236 with validation loss 0.538604199886322\n",
      "Starting Epoch 237\n",
      "0.5538671923720319\n",
      "Starting Epoch 238\n",
      "0.5535909131817196\n",
      "Starting Epoch 239\n",
      "0.5566510182359944\n",
      "Starting Epoch 240\n",
      "0.5515086871126423\n",
      "Starting Epoch 241\n",
      "0.5495624943919803\n",
      "Starting Epoch 242\n",
      "0.5537746665270432\n",
      "Starting Epoch 243\n",
      "0.5492818083452142\n",
      "Starting Epoch 244\n",
      "0.5513909303623697\n",
      "Starting Epoch 245\n",
      "0.5515013907266699\n",
      "Starting Epoch 246\n",
      "0.5529637647711713\n",
      "Starting Epoch 247\n",
      "0.5503587748693384\n",
      "Starting Epoch 248\n",
      "0.553542207116666\n",
      "Starting Epoch 249\n",
      "0.5513094987558282\n",
      "Starting Epoch 250\n",
      "0.5501033702622289\n",
      "Starting Epoch 251\n",
      "0.5493545700674471\n",
      "Starting Epoch 252\n",
      "0.5485056560972462\n",
      "New best model found at epoch 252 with validation loss 0.5372602343559265\n",
      "Starting Epoch 253\n",
      "0.55061075091362\n",
      "Starting Epoch 254\n",
      "0.5531414514002593\n",
      "Starting Epoch 255\n",
      "0.549726040466972\n",
      "Starting Epoch 256\n",
      "0.5521793508011362\n",
      "Starting Epoch 257\n",
      "0.5541582068671351\n",
      "Starting Epoch 258\n",
      "0.5490650158861409\n",
      "Starting Epoch 259\n",
      "0.5493377550788547\n",
      "Starting Epoch 260\n",
      "0.5479425852713378\n",
      "Starting Epoch 261\n",
      "0.5507801201032556\n",
      "Starting Epoch 262\n",
      "0.5482896294282831\n",
      "Starting Epoch 263\n",
      "0.5480068468529246\n",
      "Starting Epoch 264\n",
      "0.5555421295373336\n",
      "Starting Epoch 265\n",
      "0.5489108705002329\n",
      "Starting Epoch 266\n",
      "0.546647530534993\n",
      "Starting Epoch 267\n",
      "0.5547788013582644\n",
      "Starting Epoch 268\n",
      "0.5495884897916213\n",
      "Starting Epoch 269\n",
      "0.5516596514245738\n",
      "Starting Epoch 270\n",
      "0.5484485082004381\n",
      "Starting Epoch 271\n",
      "0.5482558063838793\n",
      "Starting Epoch 272\n",
      "0.5523595887681713\n",
      "Starting Epoch 273\n",
      "0.5477995108003202\n",
      "Starting Epoch 274\n",
      "0.548429205365803\n",
      "Starting Epoch 275\n",
      "0.5454802798188251\n",
      "Starting Epoch 276\n",
      "0.5480790617673293\n",
      "Starting Epoch 277\n",
      "0.5486483962639518\n",
      "Starting Epoch 278\n",
      "0.5465085998825405\n",
      "Starting Epoch 279\n",
      "0.5465473480846571\n",
      "Starting Epoch 280\n",
      "0.550461638232936\n",
      "Starting Epoch 281\n",
      "0.5455794710180034\n",
      "Starting Epoch 282\n",
      "0.5486729196880175\n",
      "Starting Epoch 283\n",
      "0.549072309680607\n",
      "Starting Epoch 284\n",
      "0.5489196997621785\n",
      "Starting Epoch 285\n",
      "0.547821748515834\n",
      "Starting Epoch 286\n",
      "0.5466069954892864\n",
      "Starting Epoch 287\n",
      "0.5475606153840604\n",
      "Starting Epoch 288\n",
      "0.5472160642561705\n",
      "Starting Epoch 289\n",
      "0.5499111206635184\n",
      "Starting Epoch 290\n",
      "0.5497547867505447\n",
      "Starting Epoch 291\n",
      "0.548222444627596\n",
      "Starting Epoch 292\n",
      "0.5466590692167697\n",
      "Starting Epoch 293\n",
      "0.5468283179013625\n",
      "Starting Epoch 294\n",
      "0.5471466196619946\n",
      "Starting Epoch 295\n",
      "0.5472461840380793\n",
      "Starting Epoch 296\n",
      "0.5512791522171187\n",
      "Starting Epoch 297\n",
      "0.5472001200136931\n",
      "Starting Epoch 298\n",
      "0.5453660306723221\n",
      "Starting Epoch 299\n",
      "0.5499011355897655\n",
      "Starting Epoch 300\n",
      "0.5465980534968169\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-q25: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c4323",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 6\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.75-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "11d4370d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d0c62f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,10,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "38336583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'q75(container counts)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9c115271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "84769b16-d905-4b1b-bd15-6ebdeaf6e2fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.3130957898886306\n",
      "New best model found at epoch 1 with validation loss 0.683110773563385\n",
      "Starting Epoch 2\n",
      "0.6775911631791488\n",
      "New best model found at epoch 2 with validation loss 0.666249692440033\n",
      "Starting Epoch 3\n",
      "0.6575060512708581\n",
      "New best model found at epoch 3 with validation loss 0.637211263179779\n",
      "Starting Epoch 4\n",
      "0.6403146852617678\n",
      "New best model found at epoch 4 with validation loss 0.6193498373031616\n",
      "Starting Epoch 5\n",
      "0.628991425037384\n",
      "New best model found at epoch 5 with validation loss 0.6033157110214233\n",
      "Starting Epoch 6\n",
      "0.6204992895540984\n",
      "New best model found at epoch 6 with validation loss 0.5986726880073547\n",
      "Starting Epoch 7\n",
      "0.6178602628085924\n",
      "Starting Epoch 8\n",
      "0.6122802184975665\n",
      "New best model found at epoch 8 with validation loss 0.5854399800300598\n",
      "Starting Epoch 9\n",
      "0.615579586961995\n",
      "Starting Epoch 10\n",
      "0.6112350562344426\n",
      "New best model found at epoch 10 with validation loss 0.5848035216331482\n",
      "Starting Epoch 11\n",
      "0.6063497610714125\n",
      "Starting Epoch 12\n",
      "0.6117486953735352\n",
      "Starting Epoch 13\n",
      "0.5991981781047323\n",
      "New best model found at epoch 13 with validation loss 0.5798611640930176\n",
      "Starting Epoch 14\n",
      "0.5997314971426259\n",
      "New best model found at epoch 14 with validation loss 0.5748981237411499\n",
      "Starting Epoch 15\n",
      "0.5959090979202933\n",
      "Starting Epoch 16\n",
      "0.5977769571801891\n",
      "Starting Epoch 17\n",
      "0.5985774708830792\n",
      "Starting Epoch 18\n",
      "0.5921862410462421\n",
      "New best model found at epoch 18 with validation loss 0.5726156830787659\n",
      "Starting Epoch 19\n",
      "0.5895132759343022\n",
      "Starting Epoch 20\n",
      "0.5947883440100629\n",
      "Starting Epoch 21\n",
      "0.5909110877824866\n",
      "Starting Epoch 22\n",
      "0.5901209841603818\n",
      "Starting Epoch 23\n",
      "0.5860343368157096\n",
      "Starting Epoch 24\n",
      "0.5850590104642122\n",
      "Starting Epoch 25\n",
      "0.5904695909956227\n",
      "New best model found at epoch 25 with validation loss 0.5676921010017395\n",
      "Starting Epoch 26\n",
      "0.587240949920986\n",
      "Starting Epoch 27\n",
      "0.5848323987877887\n",
      "Starting Epoch 28\n",
      "0.5891051473824874\n",
      "Starting Epoch 29\n",
      "0.5825466720954232\n",
      "Starting Epoch 30\n",
      "0.5836749206418577\n",
      "Starting Epoch 31\n",
      "0.5848415545795275\n",
      "Starting Epoch 32\n",
      "0.5833535531292791\n",
      "Starting Epoch 33\n",
      "0.5812571787315867\n",
      "Starting Epoch 34\n",
      "0.580994725227356\n",
      "Starting Epoch 35\n",
      "0.5808923918267955\n",
      "Starting Epoch 36\n",
      "0.5790407242982284\n",
      "Starting Epoch 37\n",
      "0.5806287423424099\n",
      "Starting Epoch 38\n",
      "0.5806268298107645\n",
      "Starting Epoch 39\n",
      "0.5806925115378007\n",
      "Starting Epoch 40\n",
      "0.577341976373092\n",
      "Starting Epoch 41\n",
      "0.5782120072323343\n",
      "Starting Epoch 42\n",
      "0.5844445980113485\n",
      "New best model found at epoch 42 with validation loss 0.5633848905563354\n",
      "Starting Epoch 43\n",
      "0.5770083743592967\n",
      "New best model found at epoch 43 with validation loss 0.5632601976394653\n",
      "Starting Epoch 44\n",
      "0.5775726282078287\n",
      "New best model found at epoch 44 with validation loss 0.5614230036735535\n",
      "Starting Epoch 45\n",
      "0.5780617814996968\n",
      "Starting Epoch 46\n",
      "0.577614558779675\n",
      "Starting Epoch 47\n",
      "0.5769843873770341\n",
      "New best model found at epoch 47 with validation loss 0.5613777041435242\n",
      "Starting Epoch 48\n",
      "0.5773636543232462\n",
      "Starting Epoch 49\n",
      "0.5779046597688094\n",
      "Starting Epoch 50\n",
      "0.5749924701193104\n",
      "Starting Epoch 51\n",
      "0.575022148049396\n",
      "New best model found at epoch 51 with validation loss 0.5580300688743591\n",
      "Starting Epoch 52\n",
      "0.5767882971659951\n",
      "Starting Epoch 53\n",
      "0.5732040042462556\n",
      "Starting Epoch 54\n",
      "0.5751872736474742\n",
      "Starting Epoch 55\n",
      "0.5726383328437805\n",
      "New best model found at epoch 55 with validation loss 0.5513975024223328\n",
      "Starting Epoch 56\n",
      "0.5708668024643607\n",
      "Starting Epoch 57\n",
      "0.574766482995904\n",
      "Starting Epoch 58\n",
      "0.5704325489375902\n",
      "Starting Epoch 59\n",
      "0.5719704861226289\n",
      "Starting Epoch 60\n",
      "0.5699297371117965\n",
      "Starting Epoch 61\n",
      "0.5699609336645707\n",
      "Starting Epoch 62\n",
      "0.5723022909268088\n",
      "Starting Epoch 63\n",
      "0.5707871162373087\n",
      "Starting Epoch 64\n",
      "0.5714642431425012\n",
      "Starting Epoch 65\n",
      "0.5723223452982695\n",
      "Starting Epoch 66\n",
      "0.5687260420426078\n",
      "Starting Epoch 67\n",
      "0.5723510488219883\n",
      "Starting Epoch 68\n",
      "0.5680335656456326\n",
      "Starting Epoch 69\n",
      "0.5696037502392478\n",
      "Starting Epoch 70\n",
      "0.5666818903840106\n",
      "Starting Epoch 71\n",
      "0.5688579471214957\n",
      "Starting Epoch 72\n",
      "0.5683775868104852\n",
      "Starting Epoch 73\n",
      "0.5662323702936587\n",
      "New best model found at epoch 73 with validation loss 0.5510407090187073\n",
      "Starting Epoch 74\n",
      "0.5699083364528158\n",
      "Starting Epoch 75\n",
      "0.567847376284392\n",
      "Starting Epoch 76\n",
      "0.5656756201516027\n",
      "Starting Epoch 77\n",
      "0.5662670213243236\n",
      "Starting Epoch 78\n",
      "0.5640913170316945\n",
      "New best model found at epoch 78 with validation loss 0.5415272116661072\n",
      "Starting Epoch 79\n",
      "0.5671177014060642\n",
      "Starting Epoch 80\n",
      "0.5666438405928405\n",
      "Starting Epoch 81\n",
      "0.5666594142499177\n",
      "Starting Epoch 82\n",
      "0.5674647714780725\n",
      "Starting Epoch 83\n",
      "0.5655822896439097\n",
      "Starting Epoch 84\n",
      "0.5672181028386821\n",
      "Starting Epoch 85\n",
      "0.566037197475848\n",
      "Starting Epoch 86\n",
      "0.5627663912980453\n",
      "Starting Epoch 87\n",
      "0.5653045242247374\n",
      "Starting Epoch 88\n",
      "0.5625069763349451\n",
      "Starting Epoch 89\n",
      "0.567565187163975\n",
      "Starting Epoch 90\n",
      "0.5618938777757727\n",
      "Starting Epoch 91\n",
      "0.5646428854569144\n",
      "Starting Epoch 92\n",
      "0.5676608953786932\n",
      "Starting Epoch 93\n",
      "0.5652489636255347\n",
      "Starting Epoch 94\n",
      "0.5628989883091139\n",
      "Starting Epoch 95\n",
      "0.5645265980907108\n",
      "Starting Epoch 96\n",
      "0.562909281772116\n",
      "Starting Epoch 97\n",
      "0.5603331366310949\n",
      "Starting Epoch 98\n",
      "0.5606042043022488\n",
      "Starting Epoch 99\n",
      "0.5639473303504612\n",
      "Starting Epoch 100\n",
      "0.5629235868868621\n",
      "Starting Epoch 101\n",
      "0.5607717140861179\n",
      "Starting Epoch 102\n",
      "0.5613271762495455\n",
      "New best model found at epoch 102 with validation loss 0.5402994155883789\n",
      "Starting Epoch 103\n",
      "0.561185554317806\n",
      "Starting Epoch 104\n",
      "0.5680186567099198\n",
      "Starting Epoch 105\n",
      "0.5596748422021451\n",
      "Starting Epoch 106\n",
      "0.5596643478974052\n",
      "Starting Epoch 107\n",
      "0.5599757523640342\n",
      "Starting Epoch 108\n",
      "0.5610509177912837\n",
      "Starting Epoch 109\n",
      "0.560426255931025\n",
      "Starting Epoch 110\n",
      "0.5612302448438562\n",
      "Starting Epoch 111\n",
      "0.5613031581692074\n",
      "Starting Epoch 112\n",
      "0.5623685730540234\n",
      "Starting Epoch 113\n",
      "0.5632842999437581\n",
      "Starting Epoch 114\n",
      "0.5573482526385266\n",
      "Starting Epoch 115\n",
      "0.5557414371034374\n",
      "Starting Epoch 116\n",
      "0.5591482105462448\n",
      "Starting Epoch 117\n",
      "0.5584080620952274\n",
      "Starting Epoch 118\n",
      "0.5596870015496793\n",
      "Starting Epoch 119\n",
      "0.5566952772762465\n",
      "Starting Epoch 120\n",
      "0.5568132361640101\n",
      "Starting Epoch 121\n",
      "0.5620370118514352\n",
      "Starting Epoch 122\n",
      "0.5577125860297162\n",
      "Starting Epoch 123\n",
      "0.558420030967049\n",
      "Starting Epoch 124\n",
      "0.5609519896299943\n",
      "Starting Epoch 125\n",
      "0.5604391227597776\n",
      "Starting Epoch 126\n",
      "0.5554255298946215\n",
      "Starting Epoch 127\n",
      "0.5550566199033157\n",
      "Starting Epoch 128\n",
      "0.5598066034524337\n",
      "Starting Epoch 129\n",
      "0.5563733448152957\n",
      "Starting Epoch 130\n",
      "0.5571114265400431\n",
      "Starting Epoch 131\n",
      "0.5537356293719747\n",
      "Starting Epoch 132\n",
      "0.5618023392946824\n",
      "Starting Epoch 133\n",
      "0.5561947952146116\n",
      "Starting Epoch 134\n",
      "0.5597850136134935\n",
      "Starting Epoch 135\n",
      "0.5560270340546317\n",
      "Starting Epoch 136\n",
      "0.5587314496869626\n",
      "Starting Epoch 137\n",
      "0.5570187257683795\n",
      "Starting Epoch 138\n",
      "0.5531555232794388\n",
      "New best model found at epoch 138 with validation loss 0.5400064587593079\n",
      "Starting Epoch 139\n",
      "0.5551676750183105\n",
      "Starting Epoch 140\n",
      "0.5554751857467319\n",
      "Starting Epoch 141\n",
      "0.5572790905185367\n",
      "Starting Epoch 142\n",
      "0.5541685573432756\n",
      "Starting Epoch 143\n",
      "0.5541257417720297\n",
      "Starting Epoch 144\n",
      "0.5561729216057322\n",
      "Starting Epoch 145\n",
      "0.5547238575375598\n",
      "Starting Epoch 146\n",
      "0.5545573610326519\n",
      "Starting Epoch 147\n",
      "0.5537164833234705\n",
      "Starting Epoch 148\n",
      "0.5580917583859485\n",
      "Starting Epoch 149\n",
      "0.557727196942205\n",
      "Starting Epoch 150\n",
      "0.5523427595262942\n",
      "Starting Epoch 151\n",
      "0.5586002702298372\n",
      "Starting Epoch 152\n",
      "0.5537620355253634\n",
      "Starting Epoch 153\n",
      "0.5514319007811339\n",
      "New best model found at epoch 153 with validation loss 0.5396807193756104\n",
      "Starting Epoch 154\n",
      "0.552687933911448\n",
      "Starting Epoch 155\n",
      "0.5556979866131492\n",
      "Starting Epoch 156\n",
      "0.5545755210130111\n",
      "Starting Epoch 157\n",
      "0.5539725889330325\n",
      "Starting Epoch 158\n",
      "0.5522246969782788\n",
      "Starting Epoch 159\n",
      "0.5536660901878191\n",
      "Starting Epoch 160\n",
      "0.5530784687270289\n",
      "Starting Epoch 161\n",
      "0.5533165257910023\n",
      "Starting Epoch 162\n",
      "0.5536032435686692\n",
      "Starting Epoch 163\n",
      "0.5546571508697842\n",
      "Starting Epoch 164\n",
      "0.5545655657415804\n",
      "Starting Epoch 165\n",
      "0.5527633350828419\n",
      "Starting Epoch 166\n",
      "0.5502637106439342\n",
      "Starting Epoch 167\n",
      "0.5521942260472671\n",
      "New best model found at epoch 167 with validation loss 0.539625883102417\n",
      "Starting Epoch 168\n",
      "0.5548046360845151\n",
      "New best model found at epoch 168 with validation loss 0.5386794209480286\n",
      "Starting Epoch 169\n",
      "0.5513263137444205\n",
      "Starting Epoch 170\n",
      "0.5542459267637004\n",
      "Starting Epoch 171\n",
      "0.5514879719070767\n",
      "Starting Epoch 172\n",
      "0.5515567129072936\n",
      "Starting Epoch 173\n",
      "0.5503971097262009\n",
      "Starting Epoch 174\n",
      "0.5512282705825308\n",
      "Starting Epoch 175\n",
      "0.5498557427655095\n",
      "New best model found at epoch 175 with validation loss 0.5378685593605042\n",
      "Starting Epoch 176\n",
      "0.5517116331535837\n",
      "Starting Epoch 177\n",
      "0.5499380749204884\n",
      "Starting Epoch 178\n",
      "0.5552995451118635\n",
      "Starting Epoch 179\n",
      "0.5513060261373934\n",
      "Starting Epoch 180\n",
      "0.5540582097094991\n",
      "Starting Epoch 181\n",
      "0.5515114626158839\n",
      "Starting Epoch 182\n",
      "0.5515536588171254\n",
      "Starting Epoch 183\n",
      "0.5509411550086477\n",
      "Starting Epoch 184\n",
      "0.5517917599367059\n",
      "Starting Epoch 185\n",
      "0.5493943172952404\n",
      "New best model found at epoch 185 with validation loss 0.5356582999229431\n",
      "Starting Epoch 186\n",
      "0.5504255722398343\n",
      "Starting Epoch 187\n",
      "0.5538175650264906\n",
      "Starting Epoch 188\n",
      "0.5502035708531089\n",
      "Starting Epoch 189\n",
      "0.551558388316113\n",
      "Starting Epoch 190\n",
      "0.5505613684654236\n",
      "Starting Epoch 191\n",
      "0.5497692538344342\n",
      "Starting Epoch 192\n",
      "0.5495846478835397\n",
      "Starting Epoch 193\n",
      "0.5560460427533025\n",
      "Starting Epoch 194\n",
      "0.5495231047920559\n",
      "Starting Epoch 195\n",
      "0.5500359327896781\n",
      "Starting Epoch 196\n",
      "0.5509583872297535\n",
      "Starting Epoch 197\n",
      "0.5483613312244415\n",
      "Starting Epoch 198\n",
      "0.5487290063629979\n",
      "Starting Epoch 199\n",
      "0.5502088018085646\n",
      "Starting Epoch 200\n",
      "0.5512306677258533\n",
      "Starting Epoch 201\n",
      "0.5523934571639352\n",
      "Starting Epoch 202\n",
      "0.5496674555799236\n",
      "Starting Epoch 203\n",
      "0.5497633620448734\n",
      "Starting Epoch 204\n",
      "0.5490041725013567\n",
      "Starting Epoch 205\n",
      "0.5489041662734487\n",
      "Starting Epoch 206\n",
      "0.5490409900312838\n",
      "Starting Epoch 207\n",
      "0.5498717634574227\n",
      "Starting Epoch 208\n",
      "0.5488413377948429\n",
      "Starting Epoch 209\n",
      "0.550494909286499\n",
      "Starting Epoch 210\n",
      "0.5491600930690765\n",
      "Starting Epoch 211\n",
      "0.5481746002383854\n",
      "Starting Epoch 212\n",
      "0.5507014277188674\n",
      "Starting Epoch 213\n",
      "0.5472293858942778\n",
      "Starting Epoch 214\n",
      "0.546700691399367\n",
      "Starting Epoch 215\n",
      "0.5500498077143794\n",
      "Starting Epoch 216\n",
      "0.5485030632951985\n",
      "Starting Epoch 217\n",
      "0.5492155746273373\n",
      "Starting Epoch 218\n",
      "0.546328912610593\n",
      "Starting Epoch 219\n",
      "0.5467503226321676\n",
      "Starting Epoch 220\n",
      "0.5481376933014911\n",
      "Starting Epoch 221\n",
      "0.5482390769149946\n",
      "Starting Epoch 222\n",
      "0.5473403412362804\n",
      "Starting Epoch 223\n",
      "0.5474233912385028\n",
      "Starting Epoch 224\n",
      "0.5449032019013944\n",
      "Starting Epoch 225\n",
      "0.5486925322076549\n",
      "Starting Epoch 226\n",
      "0.5470465771529985\n",
      "Starting Epoch 227\n",
      "0.5461525061856145\n",
      "Starting Epoch 228\n",
      "0.5476680488690086\n",
      "Starting Epoch 229\n",
      "0.5480662623177404\n",
      "Starting Epoch 230\n",
      "0.5455701610316401\n",
      "Starting Epoch 231\n",
      "0.5452662978483283\n",
      "Starting Epoch 232\n",
      "0.5456512635168822\n",
      "Starting Epoch 233\n",
      "0.5447580386763033\n",
      "Starting Epoch 234\n",
      "0.545153910699098\n",
      "Starting Epoch 235\n",
      "0.5468223898307137\n",
      "Starting Epoch 236\n",
      "0.5467892755632815\n",
      "Starting Epoch 237\n",
      "0.5470301936502042\n",
      "Starting Epoch 238\n",
      "0.5476050454637279\n",
      "Starting Epoch 239\n",
      "0.5447990583336871\n",
      "Starting Epoch 240\n",
      "0.5460044430649799\n",
      "Starting Epoch 241\n",
      "0.5446932380614073\n",
      "Starting Epoch 242\n",
      "0.5462510119313779\n",
      "Starting Epoch 243\n",
      "0.5427709804928821\n",
      "Starting Epoch 244\n",
      "0.5466233129086702\n",
      "Starting Epoch 245\n",
      "0.5451134391452955\n",
      "Starting Epoch 246\n",
      "0.5454205339369567\n",
      "New best model found at epoch 246 with validation loss 0.534412682056427\n",
      "Starting Epoch 247\n",
      "0.5446513800517373\n",
      "Starting Epoch 248\n",
      "0.5452262422312861\n",
      "Starting Epoch 249\n",
      "0.5459581626498181\n",
      "Starting Epoch 250\n",
      "0.5454799869786138\n",
      "Starting Epoch 251\n",
      "0.5429596408553745\n",
      "Starting Epoch 252\n",
      "0.5435607860917631\n",
      "New best model found at epoch 252 with validation loss 0.5339539647102356\n",
      "Starting Epoch 253\n",
      "0.5431844099708225\n",
      "Starting Epoch 254\n",
      "0.5421760639418727\n",
      "Starting Epoch 255\n",
      "0.5447430701359458\n",
      "New best model found at epoch 255 with validation loss 0.5335901379585266\n",
      "Starting Epoch 256\n",
      "0.5453781265279521\n",
      "Starting Epoch 257\n",
      "0.543536425932594\n",
      "Starting Epoch 258\n",
      "0.5430296309616255\n",
      "Starting Epoch 259\n",
      "0.5420090918955596\n",
      "New best model found at epoch 259 with validation loss 0.5316188931465149\n",
      "Starting Epoch 260\n",
      "0.5411259026631065\n",
      "Starting Epoch 261\n",
      "0.542426876399828\n",
      "Starting Epoch 262\n",
      "0.5421091149682584\n",
      "Starting Epoch 263\n",
      "0.5424843002920565\n",
      "Starting Epoch 264\n",
      "0.5438017236149829\n",
      "New best model found at epoch 264 with validation loss 0.5315066576004028\n",
      "Starting Epoch 265\n",
      "0.5429226924543795\n",
      "Starting Epoch 266\n",
      "0.5412739320941593\n",
      "Starting Epoch 267\n",
      "0.5450925852941431\n",
      "Starting Epoch 268\n",
      "0.5421700853368511\n",
      "Starting Epoch 269\n",
      "0.5427533712076105\n",
      "Starting Epoch 270\n",
      "0.5400050308393396\n",
      "Starting Epoch 271\n",
      "0.5412501355876094\n",
      "Starting Epoch 272\n",
      "0.5441581334756769\n",
      "Starting Epoch 273\n",
      "0.5392398186351942\n",
      "New best model found at epoch 273 with validation loss 0.5315043330192566\n",
      "Starting Epoch 274\n",
      "0.5402114313581715\n",
      "New best model found at epoch 274 with validation loss 0.5283039212226868\n",
      "Starting Epoch 275\n",
      "0.5391031218611676\n",
      "Starting Epoch 276\n",
      "0.5403943074786145\n",
      "Starting Epoch 277\n",
      "0.5400954925495646\n",
      "Starting Epoch 278\n",
      "0.5403113740941753\n",
      "Starting Epoch 279\n",
      "0.5393072405587072\n",
      "Starting Epoch 280\n",
      "0.5415618523307468\n",
      "Starting Epoch 281\n",
      "0.5392284095287323\n",
      "Starting Epoch 282\n",
      "0.5384465481923975\n",
      "Starting Epoch 283\n",
      "0.539766647245573\n",
      "Starting Epoch 284\n",
      "0.5392192044983739\n",
      "Starting Epoch 285\n",
      "0.5395296786142432\n",
      "Starting Epoch 286\n",
      "0.5383242861084316\n",
      "Starting Epoch 287\n",
      "0.5384255621744238\n",
      "Starting Epoch 288\n",
      "0.5401738195315652\n",
      "Starting Epoch 289\n",
      "0.5384452666925348\n",
      "Starting Epoch 290\n",
      "0.5403611608173536\n",
      "Starting Epoch 291\n",
      "0.5369253754615784\n",
      "Starting Epoch 292\n",
      "0.5382075219050698\n",
      "Starting Epoch 293\n",
      "0.5372993116793425\n",
      "Starting Epoch 294\n",
      "0.5368248392706332\n",
      "Starting Epoch 295\n",
      "0.5366427315318066\n",
      "Starting Epoch 296\n",
      "0.5405104613822439\n",
      "Starting Epoch 297\n",
      "0.5394827269989512\n",
      "Starting Epoch 298\n",
      "0.5388225044893182\n",
      "Starting Epoch 299\n",
      "0.5374412070149961\n",
      "New best model found at epoch 299 with validation loss 0.5261068940162659\n",
      "Starting Epoch 300\n",
      "0.5388487292372662\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train_small, y1_train, X_val_small, y1_val, \"2_class\", \"MLP, small-q75: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f48ba-fe74-4a4a-b707-924ae5a562d2",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, custom layer\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 2 (best model before)\n",
    "*  Adding a custom layer, where we group all features occuring multiple times together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "7d247ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(X_train, y1_train)\n",
    "trainloader = DataLoader(custom_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1485b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e3499296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 1)  \n",
    "        self.fc2 = nn.Linear(1, 1)  \n",
    "        self.fc3 = nn.Linear(1, 1)  \n",
    "        self.fc4 = nn.Linear(1, 1)  \n",
    "        self.fc5 = nn.Linear(1, 1)  \n",
    "        self.fc6 = nn.Linear(6, 1)  \n",
    "        self.fc7 = nn.Linear(6, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        grouped_features = torch.cat((self.fc1(x[:, 0:1]), self.fc2(x[:, 1:2]), self.fc3(x[:, 2:3]), self.fc4(x[:, 3:4]), \n",
    "                                      self.fc5(x[:, 4:5]), self.fc6(x[:, 5:11]), self.fc7(x[:, 11:17])), dim=1)\n",
    "        \n",
    "        return grouped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "16d45a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.custom_layer = CustomLayer()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.custom_layer(x)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fbb06bf7-d140-4b92-8e0d-046f5396a017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.7498009930486265\n",
      "New best model found at epoch 1 with validation loss 0.63675856590271\n",
      "Starting Epoch 2\n",
      "0.6505411319110704\n",
      "New best model found at epoch 2 with validation loss 0.6170274615287781\n",
      "Starting Epoch 3\n",
      "0.6532448918923087\n",
      "Starting Epoch 4\n",
      "0.6293264549711476\n",
      "New best model found at epoch 4 with validation loss 0.6030109524726868\n",
      "Starting Epoch 5\n",
      "0.6245541702146116\n",
      "Starting Epoch 6\n",
      "0.6316828779552294\n",
      "Starting Epoch 7\n",
      "0.602129560449849\n",
      "New best model found at epoch 7 with validation loss 0.593410074710846\n",
      "Starting Epoch 8\n",
      "0.5995438720868982\n",
      "New best model found at epoch 8 with validation loss 0.5814910531044006\n",
      "Starting Epoch 9\n",
      "0.595838593400043\n",
      "Starting Epoch 10\n",
      "0.5986485740412837\n",
      "Starting Epoch 11\n",
      "0.5846832031789033\n",
      "New best model found at epoch 11 with validation loss 0.5736525654792786\n",
      "Starting Epoch 12\n",
      "0.5812456400498099\n",
      "Starting Epoch 13\n",
      "0.5783249969067781\n",
      "New best model found at epoch 13 with validation loss 0.5683715343475342\n",
      "Starting Epoch 14\n",
      "0.5749872352765955\n",
      "Starting Epoch 15\n",
      "0.5657654093659442\n",
      "New best model found at epoch 15 with validation loss 0.5650782585144043\n",
      "Starting Epoch 16\n",
      "0.5618619776290396\n",
      "Starting Epoch 17\n",
      "0.5630433326182158\n",
      "New best model found at epoch 17 with validation loss 0.5489370226860046\n",
      "Starting Epoch 18\n",
      "0.5593205534893534\n",
      "New best model found at epoch 18 with validation loss 0.5414455533027649\n",
      "Starting Epoch 19\n",
      "0.558905725893767\n",
      "Starting Epoch 20\n",
      "0.5515528321266174\n",
      "Starting Epoch 21\n",
      "0.5534526213355686\n",
      "New best model found at epoch 21 with validation loss 0.5409980416297913\n",
      "Starting Epoch 22\n",
      "0.5488582123880801\n",
      "Starting Epoch 23\n",
      "0.5415192583332891\n",
      "New best model found at epoch 23 with validation loss 0.5293897986412048\n",
      "Starting Epoch 24\n",
      "0.5462981799374456\n",
      "New best model found at epoch 24 with validation loss 0.5191236734390259\n",
      "Starting Epoch 25\n",
      "0.5385831814745198\n",
      "Starting Epoch 26\n",
      "0.5423634207766989\n",
      "Starting Epoch 27\n",
      "0.5465763016887333\n",
      "New best model found at epoch 27 with validation loss 0.5172748565673828\n",
      "Starting Epoch 28\n",
      "0.5387996707273566\n",
      "Starting Epoch 29\n",
      "0.535980303650317\n",
      "Starting Epoch 30\n",
      "0.5282042635523755\n",
      "New best model found at epoch 30 with validation loss 0.5058528184890747\n",
      "Starting Epoch 31\n",
      "0.524066157962965\n",
      "Starting Epoch 32\n",
      "0.5292350170405015\n",
      "New best model found at epoch 32 with validation loss 0.5046167373657227\n",
      "Starting Epoch 33\n",
      "0.5243000699126202\n",
      "Starting Epoch 34\n",
      "0.518985919330431\n",
      "Starting Epoch 35\n",
      "0.5289275983105535\n",
      "Starting Epoch 36\n",
      "0.519044138815092\n",
      "Starting Epoch 37\n",
      "0.5172034877797832\n",
      "New best model found at epoch 37 with validation loss 0.4941726326942444\n",
      "Starting Epoch 38\n",
      "0.521824809520141\n",
      "Starting Epoch 39\n",
      "0.521031282518221\n",
      "Starting Epoch 40\n",
      "0.5189830492372098\n",
      "Starting Epoch 41\n",
      "0.5102868585482888\n",
      "Starting Epoch 42\n",
      "0.517910317234371\n",
      "Starting Epoch 43\n",
      "0.5091931638510331\n",
      "New best model found at epoch 43 with validation loss 0.48935139179229736\n",
      "Starting Epoch 44\n",
      "0.5091973309931548\n",
      "Starting Epoch 45\n",
      "0.5076667821925619\n",
      "Starting Epoch 46\n",
      "0.5070486768432285\n",
      "Starting Epoch 47\n",
      "0.4999661562235459\n",
      "New best model found at epoch 47 with validation loss 0.48802030086517334\n",
      "Starting Epoch 48\n",
      "0.5029281002023945\n",
      "Starting Epoch 49\n",
      "0.5066401491994443\n",
      "Starting Epoch 50\n",
      "0.49989732192910236\n",
      "New best model found at epoch 50 with validation loss 0.48652756214141846\n",
      "Starting Epoch 51\n",
      "0.5076939087847004\n",
      "Starting Epoch 52\n",
      "0.5034239253272181\n",
      "New best model found at epoch 52 with validation loss 0.48165440559387207\n",
      "Starting Epoch 53\n",
      "0.4937171663926995\n",
      "Starting Epoch 54\n",
      "0.4996238933957141\n",
      "New best model found at epoch 54 with validation loss 0.479060560464859\n",
      "Starting Epoch 55\n",
      "0.4909835004288217\n",
      "Starting Epoch 56\n",
      "0.4946696434331977\n",
      "New best model found at epoch 56 with validation loss 0.47591325640678406\n",
      "Starting Epoch 57\n",
      "0.4906539554181306\n",
      "Starting Epoch 58\n",
      "0.493804975696232\n",
      "Starting Epoch 59\n",
      "0.4937852012074512\n",
      "Starting Epoch 60\n",
      "0.4901821561481642\n",
      "New best model found at epoch 60 with validation loss 0.4741855561733246\n",
      "Starting Epoch 61\n",
      "0.49791142085324164\n",
      "Starting Epoch 62\n",
      "0.490502479283706\n",
      "Starting Epoch 63\n",
      "0.489670921926913\n",
      "Starting Epoch 64\n",
      "0.4865675892518914\n",
      "Starting Epoch 65\n",
      "0.4910440846629765\n",
      "New best model found at epoch 65 with validation loss 0.4724148213863373\n",
      "Starting Epoch 66\n",
      "0.488316526879435\n",
      "New best model found at epoch 66 with validation loss 0.4681643545627594\n",
      "Starting Epoch 67\n",
      "0.4829066927018373\n",
      "Starting Epoch 68\n",
      "0.48911153881446173\n",
      "Starting Epoch 69\n",
      "0.490350102600844\n",
      "Starting Epoch 70\n",
      "0.4812797009944916\n",
      "Starting Epoch 71\n",
      "0.48236466879430023\n",
      "Starting Epoch 72\n",
      "0.47708361822625867\n",
      "Starting Epoch 73\n",
      "0.48105236628781195\n",
      "Starting Epoch 74\n",
      "0.4785591869250588\n",
      "Starting Epoch 75\n",
      "0.4820062932760819\n",
      "Starting Epoch 76\n",
      "0.47810020394947217\n",
      "Starting Epoch 77\n",
      "0.4785926860311757\n",
      "Starting Epoch 78\n",
      "0.47856353158536163\n",
      "Starting Epoch 79\n",
      "0.4783755618592967\n",
      "Starting Epoch 80\n",
      "0.4745969681636147\n",
      "Starting Epoch 81\n",
      "0.4808205314304518\n",
      "Starting Epoch 82\n",
      "0.4777993870818097\n",
      "Starting Epoch 83\n",
      "0.47762008983155957\n",
      "Starting Epoch 84\n",
      "0.4688685173573701\n",
      "Starting Epoch 85\n",
      "0.4721917872843535\n",
      "Starting Epoch 86\n",
      "0.4727055106474006\n",
      "New best model found at epoch 86 with validation loss 0.4641742408275604\n",
      "Starting Epoch 87\n",
      "0.47596633434295654\n",
      "New best model found at epoch 87 with validation loss 0.46106767654418945\n",
      "Starting Epoch 88\n",
      "0.4710224076457646\n",
      "Starting Epoch 89\n",
      "0.47090924563615216\n",
      "Starting Epoch 90\n",
      "0.47349818633950275\n",
      "Starting Epoch 91\n",
      "0.4656851835872816\n",
      "Starting Epoch 92\n",
      "0.46716346818467847\n",
      "Starting Epoch 93\n",
      "0.4691396485204282\n",
      "New best model found at epoch 93 with validation loss 0.45754945278167725\n",
      "Starting Epoch 94\n",
      "0.4666457603807035\n",
      "Starting Epoch 95\n",
      "0.46622937269832776\n",
      "Starting Epoch 96\n",
      "0.4716081580390101\n",
      "Starting Epoch 97\n",
      "0.46537305609039636\n",
      "Starting Epoch 98\n",
      "0.46655534920485126\n",
      "Starting Epoch 99\n",
      "0.4636361702628758\n",
      "Starting Epoch 100\n",
      "0.4639049599999967\n",
      "Starting Epoch 101\n",
      "0.4645480915256169\n",
      "Starting Epoch 102\n",
      "0.4633980367494666\n",
      "Starting Epoch 103\n",
      "0.45915809403295105\n",
      "Starting Epoch 104\n",
      "0.4659552561200183\n",
      "Starting Epoch 105\n",
      "0.46400938085887744\n",
      "Starting Epoch 106\n",
      "0.46397633397060895\n",
      "New best model found at epoch 106 with validation loss 0.4559960663318634\n",
      "Starting Epoch 107\n",
      "0.4605701500954835\n",
      "Starting Epoch 108\n",
      "0.4542194384595622\n",
      "Starting Epoch 109\n",
      "0.4575260553670966\n",
      "New best model found at epoch 109 with validation loss 0.4554092288017273\n",
      "Starting Epoch 110\n",
      "0.4600198139315066\n",
      "Starting Epoch 111\n",
      "0.4549271490262902\n",
      "Starting Epoch 112\n",
      "0.45727378648260364\n",
      "Starting Epoch 113\n",
      "0.46058533502661664\n",
      "Starting Epoch 114\n",
      "0.4578950094140094\n",
      "Starting Epoch 115\n",
      "0.4562782761843308\n",
      "Starting Epoch 116\n",
      "0.45728042462597723\n",
      "New best model found at epoch 116 with validation loss 0.45189976692199707\n",
      "Starting Epoch 117\n",
      "0.4538865037586378\n",
      "Starting Epoch 118\n",
      "0.45541938750640204\n",
      "Starting Epoch 119\n",
      "0.45568435477173846\n",
      "New best model found at epoch 119 with validation loss 0.44974225759506226\n",
      "Starting Epoch 120\n",
      "0.455147852068362\n",
      "Starting Epoch 121\n",
      "0.4530915890050971\n",
      "Starting Epoch 122\n",
      "0.45636316874752875\n",
      "Starting Epoch 123\n",
      "0.4504547404206317\n",
      "Starting Epoch 124\n",
      "0.4510601655296657\n",
      "Starting Epoch 125\n",
      "0.4513009268304576\n",
      "Starting Epoch 126\n",
      "0.45015709944393323\n",
      "Starting Epoch 127\n",
      "0.4507290111935657\n",
      "Starting Epoch 128\n",
      "0.4508262717205545\n",
      "Starting Epoch 129\n",
      "0.45036198263582977\n",
      "Starting Epoch 130\n",
      "0.452239233514537\n",
      "New best model found at epoch 130 with validation loss 0.44946423172950745\n",
      "Starting Epoch 131\n",
      "0.4476750842902971\n",
      "Starting Epoch 132\n",
      "0.4472117307393447\n",
      "New best model found at epoch 132 with validation loss 0.4431535601615906\n",
      "Starting Epoch 133\n",
      "0.4469653238420901\n",
      "Starting Epoch 134\n",
      "0.4458831639393516\n",
      "Starting Epoch 135\n",
      "0.4492836426133695\n",
      "Starting Epoch 136\n",
      "0.44377461075782776\n",
      "Starting Epoch 137\n",
      "0.44730572337689606\n",
      "Starting Epoch 138\n",
      "0.4433892511803171\n",
      "Starting Epoch 139\n",
      "0.44336498431537463\n",
      "Starting Epoch 140\n",
      "0.44619130829106207\n",
      "Starting Epoch 141\n",
      "0.4464215908361518\n",
      "Starting Epoch 142\n",
      "0.44490686188573425\n",
      "Starting Epoch 143\n",
      "0.44418029940646625\n",
      "Starting Epoch 144\n",
      "0.44577984576639923\n",
      "New best model found at epoch 144 with validation loss 0.442375123500824\n",
      "Starting Epoch 145\n",
      "0.44062843400499097\n",
      "Starting Epoch 146\n",
      "0.4395177001538484\n",
      "Starting Epoch 147\n",
      "0.4411189659782078\n",
      "Starting Epoch 148\n",
      "0.4377480123354041\n",
      "Starting Epoch 149\n",
      "0.44116170510001806\n",
      "Starting Epoch 150\n",
      "0.4420634896858879\n",
      "Starting Epoch 151\n",
      "0.43855868603872217\n",
      "Starting Epoch 152\n",
      "0.4386602873387544\n",
      "Starting Epoch 153\n",
      "0.4393707863662554\n",
      "Starting Epoch 154\n",
      "0.4427138165287349\n",
      "Starting Epoch 155\n",
      "0.4324687317661617\n",
      "Starting Epoch 156\n",
      "0.43687576962553937\n",
      "Starting Epoch 157\n",
      "0.43475314845209534\n",
      "Starting Epoch 158\n",
      "0.4357854438864667\n",
      "Starting Epoch 159\n",
      "0.4304351288339366\n",
      "Starting Epoch 160\n",
      "0.43545322184977325\n",
      "Starting Epoch 161\n",
      "0.4356943420741869\n",
      "Starting Epoch 162\n",
      "0.4366322989049165\n",
      "Starting Epoch 163\n",
      "0.43169397245282715\n",
      "Starting Epoch 164\n",
      "0.4314261765583702\n",
      "Starting Epoch 165\n",
      "0.4265707899694857\n",
      "Starting Epoch 166\n",
      "0.43241775035858154\n",
      "Starting Epoch 167\n",
      "0.4238730630149012\n",
      "Starting Epoch 168\n",
      "0.4301423585933188\n",
      "New best model found at epoch 168 with validation loss 0.43980079889297485\n",
      "Starting Epoch 169\n",
      "0.4270271257213924\n",
      "Starting Epoch 170\n",
      "0.43111999527267786\n",
      "Starting Epoch 171\n",
      "0.4296172688836637\n",
      "Starting Epoch 172\n",
      "0.4347928231177123\n",
      "Starting Epoch 173\n",
      "0.4271522617858389\n",
      "Starting Epoch 174\n",
      "0.4295804720857869\n",
      "Starting Epoch 175\n",
      "0.4294054896935173\n",
      "Starting Epoch 176\n",
      "0.4255802851656209\n",
      "New best model found at epoch 176 with validation loss 0.43852588534355164\n",
      "Starting Epoch 177\n",
      "0.4306632293307263\n",
      "Starting Epoch 178\n",
      "0.4278607264808986\n",
      "Starting Epoch 179\n",
      "0.42387480450713116\n",
      "New best model found at epoch 179 with validation loss 0.4353383779525757\n",
      "Starting Epoch 180\n",
      "0.42812634810157446\n",
      "Starting Epoch 181\n",
      "0.43045499402543774\n",
      "Starting Epoch 182\n",
      "0.42308779255203577\n",
      "Starting Epoch 183\n",
      "0.4252520916254624\n",
      "Starting Epoch 184\n",
      "0.4216371502565301\n",
      "Starting Epoch 185\n",
      "0.421233541291693\n",
      "Starting Epoch 186\n",
      "0.4206846939480823\n",
      "Starting Epoch 187\n",
      "0.4242825352627298\n",
      "Starting Epoch 188\n",
      "0.4225721501785776\n",
      "Starting Epoch 189\n",
      "0.4222280007341634\n",
      "Starting Epoch 190\n",
      "0.42198930097662884\n",
      "Starting Epoch 191\n",
      "0.4190193738626397\n",
      "Starting Epoch 192\n",
      "0.4215869229772817\n",
      "Starting Epoch 193\n",
      "0.42383325618246326\n",
      "Starting Epoch 194\n",
      "0.4211006605106851\n",
      "Starting Epoch 195\n",
      "0.4195457113825757\n",
      "Starting Epoch 196\n",
      "0.4192801208599754\n",
      "Starting Epoch 197\n",
      "0.419548186271087\n",
      "New best model found at epoch 197 with validation loss 0.4331015348434448\n",
      "Starting Epoch 198\n",
      "0.42124405891998956\n",
      "Starting Epoch 199\n",
      "0.4178493295026862\n",
      "Starting Epoch 200\n",
      "0.4207267307716867\n",
      "Starting Epoch 201\n",
      "0.41820177954176196\n",
      "New best model found at epoch 201 with validation loss 0.4312947392463684\n",
      "Starting Epoch 202\n",
      "0.42099100480908935\n",
      "Starting Epoch 203\n",
      "0.4167858517688254\n",
      "Starting Epoch 204\n",
      "0.41737856294797815\n",
      "Starting Epoch 205\n",
      "0.4169435371523318\n",
      "Starting Epoch 206\n",
      "0.41572584276613983\n",
      "Starting Epoch 207\n",
      "0.4163132335828698\n",
      "Starting Epoch 208\n",
      "0.4138336233470751\n",
      "Starting Epoch 209\n",
      "0.41507780163184455\n",
      "Starting Epoch 210\n",
      "0.41373537804769434\n",
      "New best model found at epoch 210 with validation loss 0.43076950311660767\n",
      "Starting Epoch 211\n",
      "0.4166079111721205\n",
      "Starting Epoch 212\n",
      "0.4150437647881715\n",
      "Starting Epoch 213\n",
      "0.41901282901349274\n",
      "Starting Epoch 214\n",
      "0.41476598381996155\n",
      "Starting Epoch 215\n",
      "0.4160108708817026\n",
      "Starting Epoch 216\n",
      "0.41437593232030456\n",
      "Starting Epoch 217\n",
      "0.415985063366268\n",
      "Starting Epoch 218\n",
      "0.4113201680390731\n",
      "Starting Epoch 219\n",
      "0.4175244504990785\n",
      "Starting Epoch 220\n",
      "0.4143083950747614\n",
      "Starting Epoch 221\n",
      "0.4196677609630253\n",
      "Starting Epoch 222\n",
      "0.418279987314473\n",
      "Starting Epoch 223\n",
      "0.4128323689751003\n",
      "Starting Epoch 224\n",
      "0.4128001448900803\n",
      "Starting Epoch 225\n",
      "0.4166325356649316\n",
      "Starting Epoch 226\n",
      "0.41099393367767334\n",
      "Starting Epoch 227\n",
      "0.4114716221456942\n",
      "Starting Epoch 228\n",
      "0.41625791788101196\n",
      "Starting Epoch 229\n",
      "0.41395412709402\n",
      "Starting Epoch 230\n",
      "0.4122646425081336\n",
      "Starting Epoch 231\n",
      "0.41319386596265045\n",
      "Starting Epoch 232\n",
      "0.4140341307805932\n",
      "Starting Epoch 233\n",
      "0.41131895521412726\n",
      "Starting Epoch 234\n",
      "0.41337674726610596\n",
      "Starting Epoch 235\n",
      "0.4094535293786422\n",
      "Starting Epoch 236\n",
      "0.41001018104345904\n",
      "Starting Epoch 237\n",
      "0.41072337394175323\n",
      "Starting Epoch 238\n",
      "0.4110998122588448\n",
      "Starting Epoch 239\n",
      "0.41132544045862945\n",
      "Starting Epoch 240\n",
      "0.41024456464725995\n",
      "Starting Epoch 241\n",
      "0.4112906909507254\n",
      "Starting Epoch 242\n",
      "0.4119384457235751\n",
      "Starting Epoch 243\n",
      "0.4120472747346629\n",
      "Starting Epoch 244\n",
      "0.4102726060411204\n",
      "Starting Epoch 245\n",
      "0.4089512708394424\n",
      "Starting Epoch 246\n",
      "0.41029143981311633\n",
      "Starting Epoch 247\n",
      "0.40740304667016736\n",
      "Starting Epoch 248\n",
      "0.4073903625426085\n",
      "Starting Epoch 249\n",
      "0.41054915150870447\n",
      "Starting Epoch 250\n",
      "0.41080644467602606\n",
      "Starting Epoch 251\n",
      "0.4072623486104219\n",
      "Starting Epoch 252\n",
      "0.4102278429528941\n",
      "Starting Epoch 253\n",
      "0.4095633198385653\n",
      "Starting Epoch 254\n",
      "0.4081325155237447\n",
      "Starting Epoch 255\n",
      "0.4092100677282914\n",
      "Starting Epoch 256\n",
      "0.406453145586926\n",
      "Starting Epoch 257\n",
      "0.4110460760800735\n",
      "Starting Epoch 258\n",
      "0.40784029079520184\n",
      "New best model found at epoch 258 with validation loss 0.4297044277191162\n",
      "Starting Epoch 259\n",
      "0.4089339025642561\n",
      "Starting Epoch 260\n",
      "0.40836905526078265\n",
      "Starting Epoch 261\n",
      "0.4111291714336561\n",
      "Starting Epoch 262\n",
      "0.4088296073934306\n",
      "Starting Epoch 263\n",
      "0.40650746096735413\n",
      "Starting Epoch 264\n",
      "0.4054854136446248\n",
      "Starting Epoch 265\n",
      "0.41012530352758325\n",
      "Starting Epoch 266\n",
      "0.4083248389803845\n",
      "Starting Epoch 267\n",
      "0.40418540653975116\n",
      "Starting Epoch 268\n",
      "0.40673861037129944\n",
      "Starting Epoch 269\n",
      "0.40477412939071655\n",
      "Starting Epoch 270\n",
      "0.4040258656377378\n",
      "Starting Epoch 271\n",
      "0.40710410994032153\n",
      "Starting Epoch 272\n",
      "0.4065367333267046\n",
      "Starting Epoch 273\n",
      "0.4025405386219854\n",
      "Starting Epoch 274\n",
      "0.4078915792962779\n",
      "Starting Epoch 275\n",
      "0.4054204057092252\n",
      "Starting Epoch 276\n",
      "0.4048924873704496\n",
      "Starting Epoch 277\n",
      "0.40334024118340533\n",
      "Starting Epoch 278\n",
      "0.40484111594117206\n",
      "Starting Epoch 279\n",
      "0.4063041002854057\n",
      "Starting Epoch 280\n",
      "0.401304903237716\n",
      "Starting Epoch 281\n",
      "0.4046203921670499\n",
      "Starting Epoch 282\n",
      "0.40396406857863715\n",
      "Starting Epoch 283\n",
      "0.4026146893915923\n",
      "Starting Epoch 284\n",
      "0.40674677879913995\n",
      "Starting Epoch 285\n",
      "0.4014326165551725\n",
      "Starting Epoch 286\n",
      "0.4005613806455032\n",
      "Starting Epoch 287\n",
      "0.4041954797247182\n",
      "Starting Epoch 288\n",
      "0.4039887954359469\n",
      "Starting Epoch 289\n",
      "0.40402102859123895\n",
      "Starting Epoch 290\n",
      "0.4067745714083962\n",
      "Starting Epoch 291\n",
      "0.4022564227166383\n",
      "Starting Epoch 292\n",
      "0.4037309276021045\n",
      "Starting Epoch 293\n",
      "0.40106598838515906\n",
      "Starting Epoch 294\n",
      "0.4044922784618709\n",
      "Starting Epoch 295\n",
      "0.40257864672204724\n",
      "Starting Epoch 296\n",
      "0.40521200066027435\n",
      "Starting Epoch 297\n",
      "0.4005057850609655\n",
      "Starting Epoch 298\n",
      "0.40243553985720093\n",
      "Starting Epoch 299\n",
      "0.4040229177993277\n",
      "Starting Epoch 300\n",
      "0.400426895722099\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_train, X_val, y1_val, \"2_class\", \"MLP, custom: 7-80-50-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "dfcf6c32-772e-41d6-b08d-c1aac78d36fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.827117</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.667832</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.645688</td>\n",
       "      <td>0.622881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.672494</td>\n",
       "      <td>0.469492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.662393</td>\n",
       "      <td>0.523729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-2</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-2</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-2</th>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-2</th>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-2</th>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-2</th>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-2</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-2</th>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-2</th>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-2</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-2</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-2</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-2</th>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-2</th>\n",
       "      <td>0.713287</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-2</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-2</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-2</th>\n",
       "      <td>0.758741</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-2</th>\n",
       "      <td>0.685315</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-2</th>\n",
       "      <td>0.702797</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-2</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   acc       rec       acc       rec\n",
       "5-NN                          0.818182  0.769231  0.811189  0.795763\n",
       "Decision tree                 0.832168  0.776923  0.827506  0.800847\n",
       "Random forest                 0.835664  0.792308  0.827117  0.816949\n",
       "SVM linear                    0.667832  0.584615  0.645688  0.622881\n",
       "SVM poly                      0.716783  0.507692  0.672494  0.469492\n",
       "SVM rbf                       0.720280  0.561538  0.662393  0.523729\n",
       "MLP: 17-5-2                   0.730769  0.669231         -         -\n",
       "MLP: 17-10-2                  0.632867  0.215385         -         -\n",
       "MLP: 17-20-2                  0.765734  0.761538         -         -\n",
       "MLP: 17-25-2                  0.755245  0.761538         -         -\n",
       "MLP: 17-40-2                  0.744755  0.738462         -         -\n",
       "MLP: 17-60-2                  0.755245  0.738462         -         -\n",
       "MLP: 17-10-5-2                0.706294  0.438462         -         -\n",
       "MLP: 17-20-10-2               0.709790  0.723077         -         -\n",
       "MLP: 17-40-20-2               0.776224  0.753846         -         -\n",
       "MLP: 17-40-10-2               0.741259  0.723077         -         -\n",
       "MLP: 17-60-40-2               0.737762  0.723077         -         -\n",
       "MLP: 17-60-20-2               0.737762  0.753846         -         -\n",
       "MLP: 17-80-50-2               0.783217  0.753846         -         -\n",
       "MLP, small-median: 7-80-50-2  0.713287  0.569231         -         -\n",
       "MLP, small-mean: 7-80-50-2    0.706294  0.584615         -         -\n",
       "MLP, small-min: 7-80-50-2     0.706294  0.623077         -         -\n",
       "MLP, small-max: 7-80-50-2     0.758741  0.776923         -         -\n",
       "MLP, small-q25: 7-80-50-2     0.685315  0.592308         -         -\n",
       "MLP, small-q75: 7-80-50-2     0.702797  0.607692         -         -\n",
       "MLP, custom: 7-80-50-2        0.772727  0.707692         -         -"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d211f-84e7-4572-95ad-7f690c205df5",
   "metadata": {},
   "source": [
    "### Deep MLP with three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "765ed9b7-78c8-4d7d-95b7-a0920245ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_train_mlp = y1_equal_05_train + 1\n",
    "y1_equal_05_val_mlp = y1_equal_05_val + 1\n",
    "y1_equal_01_train_mlp = y1_equal_01_train + 1\n",
    "y1_equal_01_val_mlp = y1_equal_01_val + 1\n",
    "y1_equal_005_train_mlp = y1_equal_005_train + 1\n",
    "y1_equal_005_val_mlp = y1_equal_005_val + 1\n",
    "y1_equal_001_train_mlp = y1_equal_001_train + 1\n",
    "y1_equal_001_val_mlp = y1_equal_001_val + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1b50db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.values).float()  # Convert DataFrame to tensor\n",
    "        self.y = torch.from_numpy(y.values).float()  # Convert DataFrame to tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b23c8",
   "metadata": {},
   "source": [
    "#### 3-layer MLP\n",
    "*  Loss: Cross-Entropy\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4398bde2",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 1, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 5 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ce6e5dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 3)\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6963815a-24bb-47a6-9bec-530befb1b494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.1331541097682456\n",
      "New best model found at epoch 1 with validation loss 0.9857494831085205\n",
      "Starting Epoch 2\n",
      "1.0047486528106357\n",
      "New best model found at epoch 2 with validation loss 0.974884569644928\n",
      "Starting Epoch 3\n",
      "0.9996046164761418\n",
      "New best model found at epoch 3 with validation loss 0.9744153618812561\n",
      "Starting Epoch 4\n",
      "0.9939322134722834\n",
      "New best model found at epoch 4 with validation loss 0.9640389680862427\n",
      "Starting Epoch 5\n",
      "0.9910827823307203\n",
      "New best model found at epoch 5 with validation loss 0.9582012891769409\n",
      "Starting Epoch 6\n",
      "0.9854664958041647\n",
      "New best model found at epoch 6 with validation loss 0.94923335313797\n",
      "Starting Epoch 7\n",
      "0.9788060343783834\n",
      "New best model found at epoch 7 with validation loss 0.9396675229072571\n",
      "Starting Epoch 8\n",
      "0.9735085368156433\n",
      "New best model found at epoch 8 with validation loss 0.9295614957809448\n",
      "Starting Epoch 9\n",
      "0.9677098859911379\n",
      "New best model found at epoch 9 with validation loss 0.921005129814148\n",
      "Starting Epoch 10\n",
      "0.9586026176162388\n",
      "New best model found at epoch 10 with validation loss 0.911675751209259\n",
      "Starting Epoch 11\n",
      "0.9525211479352869\n",
      "New best model found at epoch 11 with validation loss 0.9096372127532959\n",
      "Starting Epoch 12\n",
      "0.9501998243124589\n",
      "New best model found at epoch 12 with validation loss 0.9008100032806396\n",
      "Starting Epoch 13\n",
      "0.9422354801841404\n",
      "New best model found at epoch 13 with validation loss 0.8938878178596497\n",
      "Starting Epoch 14\n",
      "0.9378730654716492\n",
      "New best model found at epoch 14 with validation loss 0.8866937756538391\n",
      "Starting Epoch 15\n",
      "0.9347706463025964\n",
      "New best model found at epoch 15 with validation loss 0.885430097579956\n",
      "Starting Epoch 16\n",
      "0.9294340247693269\n",
      "New best model found at epoch 16 with validation loss 0.8766254186630249\n",
      "Starting Epoch 17\n",
      "0.9270573647125907\n",
      "Starting Epoch 18\n",
      "0.9225273832030918\n",
      "New best model found at epoch 18 with validation loss 0.8685076832771301\n",
      "Starting Epoch 19\n",
      "0.9195450233376544\n",
      "New best model found at epoch 19 with validation loss 0.8663638234138489\n",
      "Starting Epoch 20\n",
      "0.9152075363242108\n",
      "New best model found at epoch 20 with validation loss 0.8635834455490112\n",
      "Starting Epoch 21\n",
      "0.9129604204841282\n",
      "New best model found at epoch 21 with validation loss 0.8604423403739929\n",
      "Starting Epoch 22\n",
      "0.9081057517424874\n",
      "New best model found at epoch 22 with validation loss 0.8589706420898438\n",
      "Starting Epoch 23\n",
      "0.9057761741721112\n",
      "New best model found at epoch 23 with validation loss 0.8512676358222961\n",
      "Starting Epoch 24\n",
      "0.904303605141847\n",
      "New best model found at epoch 24 with validation loss 0.8492445945739746\n",
      "Starting Epoch 25\n",
      "0.900431109511334\n",
      "Starting Epoch 26\n",
      "0.9003971011742301\n",
      "Starting Epoch 27\n",
      "0.8961636501809825\n",
      "New best model found at epoch 27 with validation loss 0.8395877480506897\n",
      "Starting Epoch 28\n",
      "0.8920632445293925\n",
      "New best model found at epoch 28 with validation loss 0.8377752304077148\n",
      "Starting Epoch 29\n",
      "0.8935091106787972\n",
      "Starting Epoch 30\n",
      "0.8897764216298643\n",
      "New best model found at epoch 30 with validation loss 0.8374542593955994\n",
      "Starting Epoch 31\n",
      "0.8902700180592744\n",
      "New best model found at epoch 31 with validation loss 0.8316124081611633\n",
      "Starting Epoch 32\n",
      "0.8865109241527059\n",
      "New best model found at epoch 32 with validation loss 0.829801082611084\n",
      "Starting Epoch 33\n",
      "0.8852029235466666\n",
      "Starting Epoch 34\n",
      "0.8880370181539784\n",
      "New best model found at epoch 34 with validation loss 0.8266628980636597\n",
      "Starting Epoch 35\n",
      "0.8878460630126621\n",
      "Starting Epoch 36\n",
      "0.8856780969578287\n",
      "Starting Epoch 37\n",
      "0.8810473991476971\n",
      "New best model found at epoch 37 with validation loss 0.8242857456207275\n",
      "Starting Epoch 38\n",
      "0.8788406460181527\n",
      "New best model found at epoch 38 with validation loss 0.8223946690559387\n",
      "Starting Epoch 39\n",
      "0.8800275869991468\n",
      "New best model found at epoch 39 with validation loss 0.8206095695495605\n",
      "Starting Epoch 40\n",
      "0.8804137888162032\n",
      "Starting Epoch 41\n",
      "0.8775155725686447\n",
      "New best model found at epoch 41 with validation loss 0.8181731700897217\n",
      "Starting Epoch 42\n",
      "0.8764316776524419\n",
      "New best model found at epoch 42 with validation loss 0.817934513092041\n",
      "Starting Epoch 43\n",
      "0.8770716190338135\n",
      "New best model found at epoch 43 with validation loss 0.8164090514183044\n",
      "Starting Epoch 44\n",
      "0.8705446694208228\n",
      "Starting Epoch 45\n",
      "0.8745608899904334\n",
      "New best model found at epoch 45 with validation loss 0.8141990303993225\n",
      "Starting Epoch 46\n",
      "0.8729363861291305\n",
      "Starting Epoch 47\n",
      "0.870252674040587\n",
      "Starting Epoch 48\n",
      "0.8698083369628243\n",
      "New best model found at epoch 48 with validation loss 0.8117871880531311\n",
      "Starting Epoch 49\n",
      "0.868965524694194\n",
      "Starting Epoch 50\n",
      "0.8672602850457897\n",
      "New best model found at epoch 50 with validation loss 0.8114529252052307\n",
      "Starting Epoch 51\n",
      "0.8697605858678403\n",
      "New best model found at epoch 51 with validation loss 0.8100566864013672\n",
      "Starting Epoch 52\n",
      "0.8691197892893916\n",
      "Starting Epoch 53\n",
      "0.8692122049953627\n",
      "New best model found at epoch 53 with validation loss 0.8097233772277832\n",
      "Starting Epoch 54\n",
      "0.8679999475893767\n",
      "Starting Epoch 55\n",
      "0.8659937614979951\n",
      "New best model found at epoch 55 with validation loss 0.8093592524528503\n",
      "Starting Epoch 56\n",
      "0.863183995951777\n",
      "New best model found at epoch 56 with validation loss 0.8066730499267578\n",
      "Starting Epoch 57\n",
      "0.8658424849095552\n",
      "New best model found at epoch 57 with validation loss 0.8064913153648376\n",
      "Starting Epoch 58\n",
      "0.8647990408151046\n",
      "Starting Epoch 59\n",
      "0.8649621657703234\n",
      "New best model found at epoch 59 with validation loss 0.8054617047309875\n",
      "Starting Epoch 60\n",
      "0.8656376963076384\n",
      "Starting Epoch 61\n",
      "0.8637583799984144\n",
      "Starting Epoch 62\n",
      "0.8638859857683596\n",
      "New best model found at epoch 62 with validation loss 0.8041481375694275\n",
      "Starting Epoch 63\n",
      "0.8623895308245784\n",
      "New best model found at epoch 63 with validation loss 0.8038146495819092\n",
      "Starting Epoch 64\n",
      "0.8632060911344446\n",
      "Starting Epoch 65\n",
      "0.860946844453397\n",
      "Starting Epoch 66\n",
      "0.8626411609027697\n",
      "Starting Epoch 67\n",
      "0.861225338085838\n",
      "New best model found at epoch 67 with validation loss 0.8019285798072815\n",
      "Starting Epoch 68\n",
      "0.860051445339037\n",
      "Starting Epoch 69\n",
      "0.859495891177136\n",
      "New best model found at epoch 69 with validation loss 0.8010788559913635\n",
      "Starting Epoch 70\n",
      "0.8610160402629686\n",
      "Starting Epoch 71\n",
      "0.8604227045307988\n",
      "Starting Epoch 72\n",
      "0.8586952349413997\n",
      "New best model found at epoch 72 with validation loss 0.8006564974784851\n",
      "Starting Epoch 73\n",
      "0.8610269323639248\n",
      "Starting Epoch 74\n",
      "0.8579006972520248\n",
      "Starting Epoch 75\n",
      "0.8626069011895553\n",
      "New best model found at epoch 75 with validation loss 0.7987828254699707\n",
      "Starting Epoch 76\n",
      "0.862692970296611\n",
      "Starting Epoch 77\n",
      "0.8611460250356923\n",
      "Starting Epoch 78\n",
      "0.8583265568899072\n",
      "Starting Epoch 79\n",
      "0.85715157052745\n",
      "Starting Epoch 80\n",
      "0.8553901314735413\n",
      "Starting Epoch 81\n",
      "0.8554651426232379\n",
      "Starting Epoch 82\n",
      "0.8554870097533517\n",
      "New best model found at epoch 82 with validation loss 0.7965827584266663\n",
      "Starting Epoch 83\n",
      "0.8546833136807317\n",
      "Starting Epoch 84\n",
      "0.8539448199064835\n",
      "Starting Epoch 85\n",
      "0.853789860787599\n",
      "New best model found at epoch 85 with validation loss 0.7956648468971252\n",
      "Starting Epoch 86\n",
      "0.8543805039447286\n",
      "Starting Epoch 87\n",
      "0.8547980681709622\n",
      "Starting Epoch 88\n",
      "0.8526660566744597\n",
      "New best model found at epoch 88 with validation loss 0.7954667210578918\n",
      "Starting Epoch 89\n",
      "0.8535299638043279\n",
      "Starting Epoch 90\n",
      "0.8529475849607716\n",
      "New best model found at epoch 90 with validation loss 0.7953332662582397\n",
      "Starting Epoch 91\n",
      "0.852268169755521\n",
      "New best model found at epoch 91 with validation loss 0.7940859198570251\n",
      "Starting Epoch 92\n",
      "0.8496543117191481\n",
      "New best model found at epoch 92 with validation loss 0.794033944606781\n",
      "Starting Epoch 93\n",
      "0.8516108004943185\n",
      "Starting Epoch 94\n",
      "0.8508721745532491\n",
      "Starting Epoch 95\n",
      "0.8506423286769701\n",
      "Starting Epoch 96\n",
      "0.8499129881029543\n",
      "Starting Epoch 97\n",
      "0.8485986357149871\n",
      "New best model found at epoch 97 with validation loss 0.7931398749351501\n",
      "Starting Epoch 98\n",
      "0.8499796209128007\n",
      "Starting Epoch 99\n",
      "0.8504074293634166\n",
      "Starting Epoch 100\n",
      "0.8531864518704622\n",
      "New best model found at epoch 100 with validation loss 0.7925727963447571\n",
      "Starting Epoch 101\n",
      "0.8484822796738666\n",
      "Starting Epoch 102\n",
      "0.8502621598865675\n",
      "Starting Epoch 103\n",
      "0.8514564607454382\n",
      "Starting Epoch 104\n",
      "0.8494744145351908\n",
      "Starting Epoch 105\n",
      "0.8469975564790808\n",
      "New best model found at epoch 105 with validation loss 0.7912697196006775\n",
      "Starting Epoch 106\n",
      "0.8472920656204224\n",
      "New best model found at epoch 106 with validation loss 0.791031539440155\n",
      "Starting Epoch 107\n",
      "0.8502171117326488\n",
      "Starting Epoch 108\n",
      "0.8518665925316189\n",
      "New best model found at epoch 108 with validation loss 0.7905552387237549\n",
      "Starting Epoch 109\n",
      "0.846782940885295\n",
      "Starting Epoch 110\n",
      "0.8463483971098195\n",
      "Starting Epoch 111\n",
      "0.8470255862111631\n",
      "Starting Epoch 112\n",
      "0.8465318887130074\n",
      "Starting Epoch 113\n",
      "0.8459058170733245\n",
      "Starting Epoch 114\n",
      "0.8480159199756124\n",
      "Starting Epoch 115\n",
      "0.8449355700741643\n",
      "New best model found at epoch 115 with validation loss 0.7895830273628235\n",
      "Starting Epoch 116\n",
      "0.8486064335574275\n",
      "Starting Epoch 117\n",
      "0.8504545921864717\n",
      "Starting Epoch 118\n",
      "0.8476459954095923\n",
      "Starting Epoch 119\n",
      "0.8477325802264006\n",
      "Starting Epoch 120\n",
      "0.8460002852522809\n",
      "Starting Epoch 121\n",
      "0.846404132635697\n",
      "Starting Epoch 122\n",
      "0.8484479940455892\n",
      "Starting Epoch 123\n",
      "0.8465618905813798\n",
      "New best model found at epoch 123 with validation loss 0.7888113260269165\n",
      "Starting Epoch 124\n",
      "0.8481033936790798\n",
      "Starting Epoch 125\n",
      "0.8467944782713185\n",
      "Starting Epoch 126\n",
      "0.8464443735454393\n",
      "Starting Epoch 127\n",
      "0.8451342116231504\n",
      "Starting Epoch 128\n",
      "0.8470574954281682\n",
      "Starting Epoch 129\n",
      "0.8458838359169338\n",
      "Starting Epoch 130\n",
      "0.8437957349030868\n",
      "New best model found at epoch 130 with validation loss 0.7887418270111084\n",
      "Starting Epoch 131\n",
      "0.8455896481223728\n",
      "Starting Epoch 132\n",
      "0.8463027114453523\n",
      "New best model found at epoch 132 with validation loss 0.7880119681358337\n",
      "Starting Epoch 133\n",
      "0.8438592838204425\n",
      "New best model found at epoch 133 with validation loss 0.7879124879837036\n",
      "Starting Epoch 134\n",
      "0.8442576657170835\n",
      "Starting Epoch 135\n",
      "0.8456019785093225\n",
      "Starting Epoch 136\n",
      "0.8424986989601798\n",
      "Starting Epoch 137\n",
      "0.8453736175661501\n",
      "Starting Epoch 138\n",
      "0.8443232722904371\n",
      "Starting Epoch 139\n",
      "0.8432405642841173\n",
      "Starting Epoch 140\n",
      "0.8437342358672101\n",
      "New best model found at epoch 140 with validation loss 0.7876076698303223\n",
      "Starting Epoch 141\n",
      "0.8469511063202567\n",
      "Starting Epoch 142\n",
      "0.8476306511008221\n",
      "Starting Epoch 143\n",
      "0.8442724373029626\n",
      "Starting Epoch 144\n",
      "0.8459499167359393\n",
      "Starting Epoch 145\n",
      "0.8423245704692343\n",
      "Starting Epoch 146\n",
      "0.8459378195845563\n",
      "New best model found at epoch 146 with validation loss 0.7874687910079956\n",
      "Starting Epoch 147\n",
      "0.8453307903331259\n",
      "Starting Epoch 148\n",
      "0.8425766385119894\n",
      "Starting Epoch 149\n",
      "0.8432061620380568\n",
      "Starting Epoch 150\n",
      "0.8437968958979067\n",
      "Starting Epoch 151\n",
      "0.846448364465133\n",
      "Starting Epoch 152\n",
      "0.8446930310000544\n",
      "New best model found at epoch 152 with validation loss 0.7869933843612671\n",
      "Starting Epoch 153\n",
      "0.8446362225905709\n",
      "Starting Epoch 154\n",
      "0.8439016627228778\n",
      "Starting Epoch 155\n",
      "0.8430550202079441\n",
      "Starting Epoch 156\n",
      "0.845279335975647\n",
      "Starting Epoch 157\n",
      "0.8424514013787975\n",
      "Starting Epoch 158\n",
      "0.8436704563057941\n",
      "Starting Epoch 159\n",
      "0.8434567295986674\n",
      "New best model found at epoch 159 with validation loss 0.7864540219306946\n",
      "Starting Epoch 160\n",
      "0.8434527853260869\n",
      "Starting Epoch 161\n",
      "0.8445404197858728\n",
      "Starting Epoch 162\n",
      "0.8415882198706918\n",
      "Starting Epoch 163\n",
      "0.8426075448160586\n",
      "Starting Epoch 164\n",
      "0.8438371212586112\n",
      "Starting Epoch 165\n",
      "0.8435286231662916\n",
      "New best model found at epoch 165 with validation loss 0.7862312197685242\n",
      "Starting Epoch 166\n",
      "0.8412478151528732\n",
      "Starting Epoch 167\n",
      "0.8420059110807336\n",
      "Starting Epoch 168\n",
      "0.842419287432795\n",
      "Starting Epoch 169\n",
      "0.8419354739396469\n",
      "Starting Epoch 170\n",
      "0.8416099055953647\n",
      "Starting Epoch 171\n",
      "0.8423419957575591\n",
      "Starting Epoch 172\n",
      "0.8405448664789614\n",
      "Starting Epoch 173\n",
      "0.8417318981626759\n",
      "Starting Epoch 174\n",
      "0.8411256722781969\n",
      "Starting Epoch 175\n",
      "0.8415778745775637\n",
      "Starting Epoch 176\n",
      "0.8410509513772052\n",
      "New best model found at epoch 176 with validation loss 0.7855514883995056\n",
      "Starting Epoch 177\n",
      "0.8431385496388311\n",
      "Starting Epoch 178\n",
      "0.8415412669596465\n",
      "Starting Epoch 179\n",
      "0.8406986931095952\n",
      "New best model found at epoch 179 with validation loss 0.7854184508323669\n",
      "Starting Epoch 180\n",
      "0.8417823547902314\n",
      "Starting Epoch 181\n",
      "0.8385043792102648\n",
      "Starting Epoch 182\n",
      "0.8429413437843323\n",
      "Starting Epoch 183\n",
      "0.8425998065782629\n",
      "Starting Epoch 184\n",
      "0.842086022314818\n",
      "New best model found at epoch 184 with validation loss 0.7849440574645996\n",
      "Starting Epoch 185\n",
      "0.8410026586574056\n",
      "Starting Epoch 186\n",
      "0.843319304611372\n",
      "Starting Epoch 187\n",
      "0.8401843775873599\n",
      "Starting Epoch 188\n",
      "0.8397170331167139\n",
      "Starting Epoch 189\n",
      "0.8409547883531322\n",
      "Starting Epoch 190\n",
      "0.8388321036877839\n",
      "Starting Epoch 191\n",
      "0.8401177681010702\n",
      "Starting Epoch 192\n",
      "0.8387363889942998\n",
      "Starting Epoch 193\n",
      "0.8385697862376338\n",
      "Starting Epoch 194\n",
      "0.838151727033698\n",
      "New best model found at epoch 194 with validation loss 0.7845063805580139\n",
      "Starting Epoch 195\n",
      "0.8385539521341738\n",
      "Starting Epoch 196\n",
      "0.838055405927741\n",
      "Starting Epoch 197\n",
      "0.8407437179399573\n",
      "Starting Epoch 198\n",
      "0.8394623968912207\n",
      "New best model found at epoch 198 with validation loss 0.7844188809394836\n",
      "Starting Epoch 199\n",
      "0.8395349564759628\n",
      "Starting Epoch 200\n",
      "0.8392870348432789\n",
      "Starting Epoch 201\n",
      "0.8399213733880416\n",
      "Starting Epoch 202\n",
      "0.8389207772586657\n",
      "New best model found at epoch 202 with validation loss 0.7841883897781372\n",
      "Starting Epoch 203\n",
      "0.8388188274010367\n",
      "Starting Epoch 204\n",
      "0.8383634038593458\n",
      "New best model found at epoch 204 with validation loss 0.7841776013374329\n",
      "Starting Epoch 205\n",
      "0.8387005666027898\n",
      "Starting Epoch 206\n",
      "0.8383396475211434\n",
      "Starting Epoch 207\n",
      "0.8400308360224185\n",
      "Starting Epoch 208\n",
      "0.8384155164594236\n",
      "Starting Epoch 209\n",
      "0.838965338209401\n",
      "Starting Epoch 210\n",
      "0.8383871083674224\n",
      "Starting Epoch 211\n",
      "0.8400117366210275\n",
      "Starting Epoch 212\n",
      "0.840186603691267\n",
      "Starting Epoch 213\n",
      "0.8381421643754711\n",
      "Starting Epoch 214\n",
      "0.8389203885327214\n",
      "Starting Epoch 215\n",
      "0.838806178258813\n",
      "Starting Epoch 216\n",
      "0.8378076475599537\n",
      "Starting Epoch 217\n",
      "0.8369144279023876\n",
      "Starting Epoch 218\n",
      "0.8362480479737987\n",
      "New best model found at epoch 218 with validation loss 0.7841405272483826\n",
      "Starting Epoch 219\n",
      "0.8357933085897694\n",
      "Starting Epoch 220\n",
      "0.837667439294898\n",
      "Starting Epoch 221\n",
      "0.8379313090573186\n",
      "Starting Epoch 222\n",
      "0.8359615310378696\n",
      "New best model found at epoch 222 with validation loss 0.7838646173477173\n",
      "Starting Epoch 223\n",
      "0.8342427326285321\n",
      "Starting Epoch 224\n",
      "0.8372575122377147\n",
      "Starting Epoch 225\n",
      "0.8372324653293776\n",
      "New best model found at epoch 225 with validation loss 0.7834981083869934\n",
      "Starting Epoch 226\n",
      "0.8408581329428632\n",
      "Starting Epoch 227\n",
      "0.8376966222472813\n",
      "Starting Epoch 228\n",
      "0.8362269868021426\n",
      "Starting Epoch 229\n",
      "0.8352832483208698\n",
      "Starting Epoch 230\n",
      "0.8351308003715847\n",
      "Starting Epoch 231\n",
      "0.8350227812062139\n",
      "Starting Epoch 232\n",
      "0.8380295038223267\n",
      "Starting Epoch 233\n",
      "0.8358350499816563\n",
      "Starting Epoch 234\n",
      "0.8363335288089254\n",
      "Starting Epoch 235\n",
      "0.8355428602384485\n",
      "Starting Epoch 236\n",
      "0.8363928483880084\n",
      "Starting Epoch 237\n",
      "0.8334580426630767\n",
      "Starting Epoch 238\n",
      "0.8339380777400472\n",
      "Starting Epoch 239\n",
      "0.8352381276047748\n",
      "Starting Epoch 240\n",
      "0.8384928081346594\n",
      "New best model found at epoch 240 with validation loss 0.7830222249031067\n",
      "Starting Epoch 241\n",
      "0.8350138249604598\n",
      "New best model found at epoch 241 with validation loss 0.7827942371368408\n",
      "Starting Epoch 242\n",
      "0.8336216081743655\n",
      "Starting Epoch 243\n",
      "0.8354673204214677\n",
      "Starting Epoch 244\n",
      "0.8332403354022814\n",
      "Starting Epoch 245\n",
      "0.8340982898421909\n",
      "Starting Epoch 246\n",
      "0.833729650663293\n",
      "Starting Epoch 247\n",
      "0.8343292189681012\n",
      "New best model found at epoch 247 with validation loss 0.7825821042060852\n",
      "Starting Epoch 248\n",
      "0.8333396419234897\n",
      "New best model found at epoch 248 with validation loss 0.7824261784553528\n",
      "Starting Epoch 249\n",
      "0.8344788965971573\n",
      "Starting Epoch 250\n",
      "0.8334464456724084\n",
      "Starting Epoch 251\n",
      "0.8343878103339154\n",
      "Starting Epoch 252\n",
      "0.8348297113957612\n",
      "Starting Epoch 253\n",
      "0.8338010699852653\n",
      "Starting Epoch 254\n",
      "0.8340136356975721\n",
      "Starting Epoch 255\n",
      "0.8342932177626569\n",
      "Starting Epoch 256\n",
      "0.8322909733523494\n",
      "New best model found at epoch 256 with validation loss 0.7823390960693359\n",
      "Starting Epoch 257\n",
      "0.8322407862414485\n",
      "Starting Epoch 258\n",
      "0.8344976176386294\n",
      "New best model found at epoch 258 with validation loss 0.782302975654602\n",
      "Starting Epoch 259\n",
      "0.8323186428650565\n",
      "Starting Epoch 260\n",
      "0.8316030839215154\n",
      "Starting Epoch 261\n",
      "0.8326165339221125\n",
      "New best model found at epoch 261 with validation loss 0.7818542122840881\n",
      "Starting Epoch 262\n",
      "0.8332348906475565\n",
      "Starting Epoch 263\n",
      "0.8336442009262417\n",
      "Starting Epoch 264\n",
      "0.8346472771271415\n",
      "Starting Epoch 265\n",
      "0.8326022288073665\n",
      "New best model found at epoch 265 with validation loss 0.7817157506942749\n",
      "Starting Epoch 266\n",
      "0.8330610860948977\n",
      "Starting Epoch 267\n",
      "0.8312641511792722\n",
      "New best model found at epoch 267 with validation loss 0.7816186547279358\n",
      "Starting Epoch 268\n",
      "0.8341015318165654\n",
      "Starting Epoch 269\n",
      "0.8333404893460481\n",
      "Starting Epoch 270\n",
      "0.8351140048192895\n",
      "New best model found at epoch 270 with validation loss 0.781455934047699\n",
      "Starting Epoch 271\n",
      "0.833917895089025\n",
      "Starting Epoch 272\n",
      "0.8313157143800155\n",
      "Starting Epoch 273\n",
      "0.8331743090049081\n",
      "Starting Epoch 274\n",
      "0.8323131540547246\n",
      "Starting Epoch 275\n",
      "0.8329122507053873\n",
      "New best model found at epoch 275 with validation loss 0.781187891960144\n",
      "Starting Epoch 276\n",
      "0.8347618424374125\n",
      "New best model found at epoch 276 with validation loss 0.7811070084571838\n",
      "Starting Epoch 277\n",
      "0.8328986867614414\n",
      "Starting Epoch 278\n",
      "0.8329356442327085\n",
      "Starting Epoch 279\n",
      "0.8320742301318956\n",
      "Starting Epoch 280\n",
      "0.8309474924336309\n",
      "Starting Epoch 281\n",
      "0.8309644927149233\n",
      "Starting Epoch 282\n",
      "0.8318409893823706\n",
      "Starting Epoch 283\n",
      "0.8312360411104949\n",
      "Starting Epoch 284\n",
      "0.8320604381353959\n",
      "Starting Epoch 285\n",
      "0.8311810234318608\n",
      "New best model found at epoch 285 with validation loss 0.7808179259300232\n",
      "Starting Epoch 286\n",
      "0.8299562075863713\n",
      "Starting Epoch 287\n",
      "0.8305364665777787\n",
      "Starting Epoch 288\n",
      "0.8311553001403809\n",
      "Starting Epoch 289\n",
      "0.8307484595671945\n",
      "Starting Epoch 290\n",
      "0.8309754055479298\n",
      "Starting Epoch 291\n",
      "0.8302358933117079\n",
      "Starting Epoch 292\n",
      "0.8315090329750724\n",
      "New best model found at epoch 292 with validation loss 0.7805804014205933\n",
      "Starting Epoch 293\n",
      "0.8303767961004506\n",
      "Starting Epoch 294\n",
      "0.8310157397518987\n",
      "Starting Epoch 295\n",
      "0.8310141278349835\n",
      "Starting Epoch 296\n",
      "0.8300609096236851\n",
      "New best model found at epoch 296 with validation loss 0.7805683612823486\n",
      "Starting Epoch 297\n",
      "0.8310484264207922\n",
      "New best model found at epoch 297 with validation loss 0.7803956270217896\n",
      "Starting Epoch 298\n",
      "0.8295867339424465\n",
      "Starting Epoch 299\n",
      "0.8293877373570981\n",
      "Starting Epoch 300\n",
      "0.8309634353803552\n",
      "New best model found at epoch 300 with validation loss 0.780238151550293\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "102caf85-5c58-493f-b537-9e018b8b7c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.2224983443384585\n",
      "New best model found at epoch 1 with validation loss 1.095233678817749\n",
      "Starting Epoch 2\n",
      "1.088328833165376\n",
      "New best model found at epoch 2 with validation loss 1.089245319366455\n",
      "Starting Epoch 3\n",
      "1.0854209298672883\n",
      "New best model found at epoch 3 with validation loss 1.0890159606933594\n",
      "Starting Epoch 4\n",
      "1.0849717855453491\n",
      "Starting Epoch 5\n",
      "1.0850781772447669\n",
      "New best model found at epoch 5 with validation loss 1.0889147520065308\n",
      "Starting Epoch 6\n",
      "1.0847733642743982\n",
      "Starting Epoch 7\n",
      "1.0850546049035115\n",
      "New best model found at epoch 7 with validation loss 1.0888499021530151\n",
      "Starting Epoch 8\n",
      "1.0848282109136167\n",
      "Starting Epoch 9\n",
      "1.0849825143814087\n",
      "Starting Epoch 10\n",
      "1.0848475539165994\n",
      "Starting Epoch 11\n",
      "1.084900949312293\n",
      "Starting Epoch 12\n",
      "1.084921603617461\n",
      "Starting Epoch 13\n",
      "1.0850138249604597\n",
      "New best model found at epoch 13 with validation loss 1.0887607336044312\n",
      "Starting Epoch 14\n",
      "1.084755363671676\n",
      "New best model found at epoch 14 with validation loss 1.0887527465820312\n",
      "Starting Epoch 15\n",
      "1.084862724594448\n",
      "Starting Epoch 16\n",
      "1.0848119725351748\n",
      "Starting Epoch 17\n",
      "1.0848295481308647\n",
      "Starting Epoch 18\n",
      "1.0848323987877888\n",
      "New best model found at epoch 18 with validation loss 1.0887399911880493\n",
      "Starting Epoch 19\n",
      "1.0849464509798132\n",
      "Starting Epoch 20\n",
      "1.0847524456355884\n",
      "Starting Epoch 21\n",
      "1.0848651968914529\n",
      "Starting Epoch 22\n",
      "1.0847544099973596\n",
      "Starting Epoch 23\n",
      "1.0848486475322558\n",
      "Starting Epoch 24\n",
      "1.0849353334178096\n",
      "Starting Epoch 25\n",
      "1.084738270096157\n",
      "Starting Epoch 26\n",
      "1.0849443674087524\n",
      "Starting Epoch 27\n",
      "1.084868301515994\n",
      "Starting Epoch 28\n",
      "1.0847500873648601\n",
      "Starting Epoch 29\n",
      "1.0848710796107417\n",
      "Starting Epoch 30\n",
      "1.0849579158036604\n",
      "Starting Epoch 31\n",
      "1.084857448287632\n",
      "Starting Epoch 32\n",
      "1.084914373314899\n",
      "Starting Epoch 33\n",
      "1.0847267482591711\n",
      "Starting Epoch 34\n",
      "1.0848851203918457\n",
      "Starting Epoch 35\n",
      "1.0847130184588225\n",
      "Starting Epoch 36\n",
      "1.0848457191301428\n",
      "Starting Epoch 37\n",
      "1.0848505807959514\n",
      "Starting Epoch 38\n",
      "1.0847255976303765\n",
      "Starting Epoch 39\n",
      "1.0848232404045437\n",
      "Starting Epoch 40\n",
      "1.0847673156987065\n",
      "Starting Epoch 41\n",
      "1.0848126670588618\n",
      "Starting Epoch 42\n",
      "1.084821747696918\n",
      "Starting Epoch 43\n",
      "1.0849391947621885\n",
      "Starting Epoch 44\n",
      "1.08482041047967\n",
      "Starting Epoch 45\n",
      "1.0847695858582207\n",
      "Starting Epoch 46\n",
      "1.0848547790361487\n",
      "Starting Epoch 47\n",
      "1.0847565505815588\n",
      "Starting Epoch 48\n",
      "1.0847690416418987\n",
      "Starting Epoch 49\n",
      "1.0847982012707253\n",
      "Starting Epoch 50\n",
      "1.084905313408893\n",
      "Starting Epoch 51\n",
      "1.0848231004632038\n",
      "Starting Epoch 52\n",
      "1.0848500262136045\n",
      "Starting Epoch 53\n",
      "1.0847192639889924\n",
      "Starting Epoch 54\n",
      "1.084601023922796\n",
      "Starting Epoch 55\n",
      "1.0846928513568381\n",
      "Starting Epoch 56\n",
      "1.0848573601764182\n",
      "Starting Epoch 57\n",
      "1.0847851141639377\n",
      "Starting Epoch 58\n",
      "1.0847294848898184\n",
      "Starting Epoch 59\n",
      "1.085097074508667\n",
      "Starting Epoch 60\n",
      "1.084517012471738\n",
      "Starting Epoch 61\n",
      "1.0847513727519824\n",
      "Starting Epoch 62\n",
      "1.0846848798834758\n",
      "Starting Epoch 63\n",
      "1.084850585978964\n",
      "Starting Epoch 64\n",
      "1.084856981816499\n",
      "Starting Epoch 65\n",
      "1.0847522124000217\n",
      "Starting Epoch 66\n",
      "1.0845505880272908\n",
      "Starting Epoch 67\n",
      "1.0847534044929172\n",
      "Starting Epoch 68\n",
      "1.0846847088440605\n",
      "Starting Epoch 69\n",
      "1.0845991995023645\n",
      "Starting Epoch 70\n",
      "1.0848138176876565\n",
      "Starting Epoch 71\n",
      "1.0847786820453147\n",
      "Starting Epoch 72\n",
      "1.0848725153052288\n",
      "Starting Epoch 73\n",
      "1.0846142924350242\n",
      "Starting Epoch 74\n",
      "1.0846765611482703\n",
      "Starting Epoch 75\n",
      "1.084583598634471\n",
      "Starting Epoch 76\n",
      "1.0847463244977205\n",
      "Starting Epoch 77\n",
      "1.0847680465034817\n",
      "Starting Epoch 78\n",
      "1.0848528250404026\n",
      "Starting Epoch 79\n",
      "1.0846773489661838\n",
      "Starting Epoch 80\n",
      "1.0847043835598489\n",
      "Starting Epoch 81\n",
      "1.0846472408460535\n",
      "Starting Epoch 82\n",
      "1.084723571072454\n",
      "Starting Epoch 83\n",
      "1.0847189892893252\n",
      "Starting Epoch 84\n",
      "1.0847374304481174\n",
      "Starting Epoch 85\n",
      "1.0847309102182803\n",
      "Starting Epoch 86\n",
      "1.0846192577610845\n",
      "Starting Epoch 87\n",
      "1.0847565764966218\n",
      "Starting Epoch 88\n",
      "1.0846079121465269\n",
      "Starting Epoch 89\n",
      "1.0846538906512053\n",
      "Starting Epoch 90\n",
      "1.0847554310508396\n",
      "Starting Epoch 91\n",
      "1.0846487439197043\n",
      "Starting Epoch 92\n",
      "1.0846342418504797\n",
      "Starting Epoch 93\n",
      "1.0848085102827654\n",
      "Starting Epoch 94\n",
      "1.0847021289493726\n",
      "Starting Epoch 95\n",
      "1.0846957434778628\n",
      "Starting Epoch 96\n",
      "1.0847193780152693\n",
      "Starting Epoch 97\n",
      "1.0849097500676694\n",
      "Starting Epoch 98\n",
      "1.0849552569182024\n",
      "Starting Epoch 99\n",
      "1.0845812818278437\n",
      "Starting Epoch 100\n",
      "1.084668491197669\n",
      "Starting Epoch 101\n",
      "1.0847492995469465\n",
      "Starting Epoch 102\n",
      "1.0847435153048972\n",
      "Starting Epoch 103\n",
      "1.0848179589147153\n",
      "Starting Epoch 104\n",
      "1.0846174177916155\n",
      "Starting Epoch 105\n",
      "1.084603392559549\n",
      "Starting Epoch 106\n",
      "1.0846338790395986\n",
      "Starting Epoch 107\n",
      "1.08466927383257\n",
      "Starting Epoch 108\n",
      "1.08478684010713\n",
      "Starting Epoch 109\n",
      "1.0848636834517769\n",
      "Starting Epoch 110\n",
      "1.0847863891850347\n",
      "Starting Epoch 111\n",
      "1.084789701130079\n",
      "Starting Epoch 112\n",
      "1.0847294330596924\n",
      "Starting Epoch 113\n",
      "1.0846510607263316\n",
      "Starting Epoch 114\n",
      "1.0846748714861663\n",
      "Starting Epoch 115\n",
      "1.0847992326902307\n",
      "Starting Epoch 116\n",
      "1.084668957668802\n",
      "Starting Epoch 117\n",
      "1.084619050440581\n",
      "Starting Epoch 118\n",
      "1.0846474948136702\n",
      "Starting Epoch 119\n",
      "1.0848568107770837\n",
      "Starting Epoch 120\n",
      "1.0846965675768645\n",
      "Starting Epoch 121\n",
      "1.0848048718079277\n",
      "Starting Epoch 122\n",
      "1.0845303794612056\n",
      "Starting Epoch 123\n",
      "1.0845813440239949\n",
      "Starting Epoch 124\n",
      "1.0846331015877102\n",
      "Starting Epoch 125\n",
      "1.084646375282951\n",
      "Starting Epoch 126\n",
      "1.0846957693929258\n",
      "Starting Epoch 127\n",
      "1.0848966266797937\n",
      "Starting Epoch 128\n",
      "1.084779988164487\n",
      "Starting Epoch 129\n",
      "1.0848502387171206\n",
      "Starting Epoch 130\n",
      "1.0847028234730596\n",
      "Starting Epoch 131\n",
      "1.0847368292186572\n",
      "Starting Epoch 132\n",
      "1.0847867364468782\n",
      "Starting Epoch 133\n",
      "1.08473088948623\n",
      "Starting Epoch 134\n",
      "1.0848209235979163\n",
      "Starting Epoch 135\n",
      "1.0846375330634739\n",
      "Starting Epoch 136\n",
      "1.084773784098418\n",
      "Starting Epoch 137\n",
      "1.0848527939423271\n",
      "Starting Epoch 138\n",
      "1.0847038963566655\n",
      "Starting Epoch 139\n",
      "1.0848529183346292\n",
      "Starting Epoch 140\n",
      "1.0846352162568464\n",
      "Starting Epoch 141\n",
      "1.084719092949577\n",
      "Starting Epoch 142\n",
      "1.084643208462259\n",
      "Starting Epoch 143\n",
      "1.0847495794296265\n",
      "Starting Epoch 144\n",
      "1.084699387135713\n",
      "Starting Epoch 145\n",
      "1.0846880778022434\n",
      "Starting Epoch 146\n",
      "1.0845939128295234\n",
      "Starting Epoch 147\n",
      "1.0847491492395815\n",
      "Starting Epoch 148\n",
      "1.084653123565342\n",
      "Starting Epoch 149\n",
      "1.0847629671511443\n",
      "Starting Epoch 150\n",
      "1.0846110375031182\n",
      "Starting Epoch 151\n",
      "1.0846301680025847\n",
      "Starting Epoch 152\n",
      "1.0847802473151165\n",
      "Starting Epoch 153\n",
      "1.0849421438963518\n",
      "Starting Epoch 154\n",
      "1.0845450007397195\n",
      "Starting Epoch 155\n",
      "1.0845510959625244\n",
      "Starting Epoch 156\n",
      "1.0845760107040405\n",
      "Starting Epoch 157\n",
      "1.0848608846249788\n",
      "Starting Epoch 158\n",
      "1.0845090306323508\n",
      "Starting Epoch 159\n",
      "1.0846949919410374\n",
      "Starting Epoch 160\n",
      "1.0847594841666843\n",
      "Starting Epoch 161\n",
      "1.0847500459007595\n",
      "Starting Epoch 162\n",
      "1.0847700264142908\n",
      "Starting Epoch 163\n",
      "1.084549007208451\n",
      "Starting Epoch 164\n",
      "1.084642653879912\n",
      "Starting Epoch 165\n",
      "1.0846707198930823\n",
      "Starting Epoch 166\n",
      "1.0844546193661897\n",
      "Starting Epoch 167\n",
      "1.0846162516137827\n",
      "Starting Epoch 168\n",
      "1.0847580225571343\n",
      "Starting Epoch 169\n",
      "1.08474310066389\n",
      "Starting Epoch 170\n",
      "1.0845358682715374\n",
      "Starting Epoch 171\n",
      "1.0846322774887085\n",
      "Starting Epoch 172\n",
      "1.084644333175991\n",
      "Starting Epoch 173\n",
      "1.0847138010937234\n",
      "Starting Epoch 174\n",
      "1.084644949954489\n",
      "Starting Epoch 175\n",
      "1.0848053434620732\n",
      "Starting Epoch 176\n",
      "1.0847183725108271\n",
      "Starting Epoch 177\n",
      "1.0845681739890056\n",
      "Starting Epoch 178\n",
      "1.0845885535945063\n",
      "Starting Epoch 179\n",
      "1.0846829673518306\n",
      "Starting Epoch 180\n",
      "1.0847028286560723\n",
      "Starting Epoch 181\n",
      "1.084821747696918\n",
      "Starting Epoch 182\n",
      "1.084936852040498\n",
      "Starting Epoch 183\n",
      "1.0847968277723894\n",
      "Starting Epoch 184\n",
      "1.0846745553223982\n",
      "Starting Epoch 185\n",
      "1.0845871127170066\n",
      "Starting Epoch 186\n",
      "1.0844992554706077\n",
      "Starting Epoch 187\n",
      "1.0846460280211077\n",
      "Starting Epoch 188\n",
      "1.0845350234404854\n",
      "Starting Epoch 189\n",
      "1.0846079847087031\n",
      "Starting Epoch 190\n",
      "1.0847473248191501\n",
      "Starting Epoch 191\n",
      "1.0845692261405613\n",
      "Starting Epoch 192\n",
      "1.0846426227818364\n",
      "Starting Epoch 193\n",
      "1.0845592332922893\n",
      "Starting Epoch 194\n",
      "1.0847112976986428\n",
      "Starting Epoch 195\n",
      "1.0845900152040564\n",
      "Starting Epoch 196\n",
      "1.0846783803856892\n",
      "Starting Epoch 197\n",
      "1.084628981092702\n",
      "Starting Epoch 198\n",
      "1.0846161686855813\n",
      "Starting Epoch 199\n",
      "1.0846293490865957\n",
      "Starting Epoch 200\n",
      "1.0847853992296301\n",
      "Starting Epoch 201\n",
      "1.084537298783012\n",
      "Starting Epoch 202\n",
      "1.084706653719363\n",
      "Starting Epoch 203\n",
      "1.084675151368846\n",
      "Starting Epoch 204\n",
      "1.0846631786097651\n",
      "Starting Epoch 205\n",
      "1.0847519584324048\n",
      "Starting Epoch 206\n",
      "1.0846848332363626\n",
      "Starting Epoch 207\n",
      "1.0845767000447148\n",
      "Starting Epoch 208\n",
      "1.0846749595973804\n",
      "Starting Epoch 209\n",
      "1.0848993529444155\n",
      "Starting Epoch 210\n",
      "1.0845664376797883\n",
      "Starting Epoch 211\n",
      "1.084515348724697\n",
      "Starting Epoch 212\n",
      "1.0847475114076033\n",
      "Starting Epoch 213\n",
      "1.084563830624456\n",
      "Starting Epoch 214\n",
      "1.0847293915955916\n",
      "Starting Epoch 215\n",
      "1.0847438625667407\n",
      "Starting Epoch 216\n",
      "1.084653869919155\n",
      "Starting Epoch 217\n",
      "1.0846378647762795\n",
      "Starting Epoch 218\n",
      "1.0848007513129192\n",
      "Starting Epoch 219\n",
      "1.0846239535704902\n",
      "Starting Epoch 220\n",
      "1.0846656923708708\n",
      "Starting Epoch 221\n",
      "1.0846446389737336\n",
      "Starting Epoch 222\n",
      "1.0847614277964053\n",
      "Starting Epoch 223\n",
      "1.0847517200138257\n",
      "Starting Epoch 224\n",
      "1.0844983277113542\n",
      "Starting Epoch 225\n",
      "1.0846517448839934\n",
      "Starting Epoch 226\n",
      "1.084469790044038\n",
      "Starting Epoch 227\n",
      "1.0846531702124553\n",
      "Starting Epoch 228\n",
      "1.084741068922955\n",
      "Starting Epoch 229\n",
      "1.0846674286800881\n",
      "Starting Epoch 230\n",
      "1.084641720937646\n",
      "Starting Epoch 231\n",
      "1.0847586030545442\n",
      "Starting Epoch 232\n",
      "1.0848268529643184\n",
      "Starting Epoch 233\n",
      "1.0846989880437437\n",
      "Starting Epoch 234\n",
      "1.0847354349882707\n",
      "Starting Epoch 235\n",
      "1.084634780883789\n",
      "Starting Epoch 236\n",
      "1.0845872371093086\n",
      "Starting Epoch 237\n",
      "1.084761847620425\n",
      "Starting Epoch 238\n",
      "1.0846805417019387\n",
      "Starting Epoch 239\n",
      "1.0846059840658437\n",
      "Starting Epoch 240\n",
      "1.0847217622010603\n",
      "Starting Epoch 241\n",
      "1.0845763786979343\n",
      "Starting Epoch 242\n",
      "1.084581784580065\n",
      "Starting Epoch 243\n",
      "1.0845061799754268\n",
      "Starting Epoch 244\n",
      "1.0847031655518904\n",
      "Starting Epoch 245\n",
      "1.0845568387404732\n",
      "Starting Epoch 246\n",
      "1.084657591322194\n",
      "Starting Epoch 247\n",
      "1.0847509373789248\n",
      "Starting Epoch 248\n",
      "1.084699236828348\n",
      "Starting Epoch 249\n",
      "1.084725436956986\n",
      "Starting Epoch 250\n",
      "1.0847249082897021\n",
      "Starting Epoch 251\n",
      "1.0845895487329233\n",
      "Starting Epoch 252\n",
      "1.0848367058712503\n",
      "Starting Epoch 253\n",
      "1.0846591980560967\n",
      "Starting Epoch 254\n",
      "1.084644799647124\n",
      "Starting Epoch 255\n",
      "1.084609461867291\n",
      "Starting Epoch 256\n",
      "1.0848580702491428\n",
      "Starting Epoch 257\n",
      "1.084637216899706\n",
      "Starting Epoch 258\n",
      "1.0845841273017551\n",
      "Starting Epoch 259\n",
      "1.0848206385322239\n",
      "Starting Epoch 260\n",
      "1.0847159053968347\n",
      "Starting Epoch 261\n",
      "1.0846760946771372\n",
      "Starting Epoch 262\n",
      "1.0848318390224292\n",
      "Starting Epoch 263\n",
      "1.0846578452898108\n",
      "Starting Epoch 264\n",
      "1.0846493347831394\n",
      "Starting Epoch 265\n",
      "1.084851192391437\n",
      "Starting Epoch 266\n",
      "1.0846561452616816\n",
      "Starting Epoch 267\n",
      "1.0847064930459727\n",
      "Starting Epoch 268\n",
      "1.0846873469974683\n",
      "Starting Epoch 269\n",
      "1.084613157355267\n",
      "Starting Epoch 270\n",
      "1.0846101512079653\n",
      "Starting Epoch 271\n",
      "1.084706451581872\n",
      "Starting Epoch 272\n",
      "1.084564665089483\n",
      "Starting Epoch 273\n",
      "1.0846103481624438\n",
      "Starting Epoch 274\n",
      "1.0845987589462944\n",
      "Starting Epoch 275\n",
      "1.0847231771634973\n",
      "Starting Epoch 276\n",
      "1.0846095810765806\n",
      "Starting Epoch 277\n",
      "1.0845905075902524\n",
      "Starting Epoch 278\n",
      "1.084897948348004\n",
      "Starting Epoch 279\n",
      "1.084653403448022\n",
      "Starting Epoch 280\n",
      "1.0846511281054954\n",
      "Starting Epoch 281\n",
      "1.084691477858502\n",
      "Starting Epoch 282\n",
      "1.084651713785918\n",
      "Starting Epoch 283\n",
      "1.0846346150273862\n",
      "Starting Epoch 284\n",
      "1.0846773541491965\n",
      "Starting Epoch 285\n",
      "1.084720658219379\n",
      "Starting Epoch 286\n",
      "1.0845193759254788\n",
      "Starting Epoch 287\n",
      "1.084669776584791\n",
      "Starting Epoch 288\n",
      "1.0846281362616497\n",
      "Starting Epoch 289\n",
      "1.084874873575957\n",
      "Starting Epoch 290\n",
      "1.0846677033797554\n",
      "Starting Epoch 291\n",
      "1.0847207048664922\n",
      "Starting Epoch 292\n",
      "1.0846293387205705\n",
      "Starting Epoch 293\n",
      "1.0846339205036992\n",
      "Starting Epoch 294\n",
      "1.084680375845536\n",
      "Starting Epoch 295\n",
      "1.0846342677655427\n",
      "Starting Epoch 296\n",
      "1.0847100641416467\n",
      "Starting Epoch 297\n",
      "1.0847206789514292\n",
      "Starting Epoch 298\n",
      "1.084658586460611\n",
      "Starting Epoch 299\n",
      "1.0846949038298235\n",
      "Starting Epoch 300\n",
      "1.0846381083778713\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "dc36c950-5edf-4130-8a77-eaa18de1c894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.208280174628548\n",
      "New best model found at epoch 1 with validation loss 1.0537751913070679\n",
      "Starting Epoch 2\n",
      "1.0360715726147527\n",
      "New best model found at epoch 2 with validation loss 1.0297644138336182\n",
      "Starting Epoch 3\n",
      "1.0221465981524924\n",
      "New best model found at epoch 3 with validation loss 1.0242233276367188\n",
      "Starting Epoch 4\n",
      "1.0184247675149336\n",
      "New best model found at epoch 4 with validation loss 1.0229084491729736\n",
      "Starting Epoch 5\n",
      "1.017644744852315\n",
      "New best model found at epoch 5 with validation loss 1.022580623626709\n",
      "Starting Epoch 6\n",
      "1.0168695190678472\n",
      "New best model found at epoch 6 with validation loss 1.0223270654678345\n",
      "Starting Epoch 7\n",
      "1.0169635544652524\n",
      "Starting Epoch 8\n",
      "1.0167795030967048\n",
      "Starting Epoch 9\n",
      "1.0173254168551902\n",
      "Starting Epoch 10\n",
      "1.0167830949244292\n",
      "Starting Epoch 11\n",
      "1.0169575188470923\n",
      "Starting Epoch 12\n",
      "1.0168678086736929\n",
      "Starting Epoch 13\n",
      "1.016992556012195\n",
      "Starting Epoch 14\n",
      "1.0169110583222432\n",
      "Starting Epoch 15\n",
      "1.0167193516441013\n",
      "Starting Epoch 16\n",
      "1.0167708992958069\n",
      "Starting Epoch 17\n",
      "1.0167477156804956\n",
      "Starting Epoch 18\n",
      "1.0170736520186714\n",
      "Starting Epoch 19\n",
      "1.0168832385021707\n",
      "Starting Epoch 20\n",
      "1.016870765582375\n",
      "Starting Epoch 21\n",
      "1.0169911591903023\n",
      "Starting Epoch 22\n",
      "1.0169304764789084\n",
      "Starting Epoch 23\n",
      "1.0170240557712058\n",
      "Starting Epoch 24\n",
      "1.0170867676320283\n",
      "Starting Epoch 25\n",
      "1.0168448816175046\n",
      "Starting Epoch 26\n",
      "1.0168344041575557\n",
      "Starting Epoch 27\n",
      "1.0168200575787087\n",
      "Starting Epoch 28\n",
      "1.016786261745121\n",
      "Starting Epoch 29\n",
      "1.0168639965679334\n",
      "Starting Epoch 30\n",
      "1.0171143749485845\n",
      "Starting Epoch 31\n",
      "1.0170812814132026\n",
      "Starting Epoch 32\n",
      "1.0168070793151855\n",
      "Starting Epoch 33\n",
      "1.0166862736577573\n",
      "Starting Epoch 34\n",
      "1.0169571534447048\n",
      "Starting Epoch 35\n",
      "1.0166106638701067\n",
      "Starting Epoch 36\n",
      "1.0170379825260327\n",
      "Starting Epoch 37\n",
      "1.0173096501308938\n",
      "Starting Epoch 38\n",
      "1.0167781529219255\n",
      "Starting Epoch 39\n",
      "1.0171197264090828\n",
      "Starting Epoch 40\n",
      "1.016884956670844\n",
      "Starting Epoch 41\n",
      "1.0166025343148604\n",
      "Starting Epoch 42\n",
      "1.0167995587639187\n",
      "Starting Epoch 43\n",
      "1.016985815504323\n",
      "Starting Epoch 44\n",
      "1.0168395949446636\n",
      "Starting Epoch 45\n",
      "1.0167375958484153\n",
      "Starting Epoch 46\n",
      "1.0165944306746773\n",
      "Starting Epoch 47\n",
      "1.0167359528334245\n",
      "Starting Epoch 48\n",
      "1.016748791155608\n",
      "Starting Epoch 49\n",
      "1.0169558188189631\n",
      "Starting Epoch 50\n",
      "1.0169871138489766\n",
      "Starting Epoch 51\n",
      "1.0169447660446167\n",
      "Starting Epoch 52\n",
      "1.0169642308483953\n",
      "Starting Epoch 53\n",
      "1.0165677925814753\n",
      "Starting Epoch 54\n",
      "1.0162813145181406\n",
      "Starting Epoch 55\n",
      "1.016671947810961\n",
      "Starting Epoch 56\n",
      "1.0167866038239521\n",
      "Starting Epoch 57\n",
      "1.0169174904408662\n",
      "Starting Epoch 58\n",
      "1.0164657753446829\n",
      "Starting Epoch 59\n",
      "1.0176622116047402\n",
      "Starting Epoch 60\n",
      "1.016412535439367\n",
      "Starting Epoch 61\n",
      "1.0168838164080745\n",
      "Starting Epoch 62\n",
      "1.0168528945549675\n",
      "Starting Epoch 63\n",
      "1.017053565253382\n",
      "Starting Epoch 64\n",
      "1.0167836339577385\n",
      "Starting Epoch 65\n",
      "1.0167479877886565\n",
      "Starting Epoch 66\n",
      "1.016499628191409\n",
      "Starting Epoch 67\n",
      "1.0168887532275657\n",
      "Starting Epoch 68\n",
      "1.0165648641793623\n",
      "Starting Epoch 69\n",
      "1.0164232176283132\n",
      "Starting Epoch 70\n",
      "1.016892917778181\n",
      "Starting Epoch 71\n",
      "1.0170916578044062\n",
      "Starting Epoch 72\n",
      "1.0170815457468447\n",
      "Starting Epoch 73\n",
      "1.0165944306746773\n",
      "Starting Epoch 74\n",
      "1.0169349831083547\n",
      "Starting Epoch 75\n",
      "1.0165303971456445\n",
      "Starting Epoch 76\n",
      "1.016649163287619\n",
      "Starting Epoch 77\n",
      "1.0168416500091553\n",
      "Starting Epoch 78\n",
      "1.0171106898266336\n",
      "Starting Epoch 79\n",
      "1.0169634663540383\n",
      "Starting Epoch 80\n",
      "1.0169037321339482\n",
      "Starting Epoch 81\n",
      "1.0166250026744346\n",
      "Starting Epoch 82\n",
      "1.016603057799132\n",
      "Starting Epoch 83\n",
      "1.0166974585989248\n",
      "Starting Epoch 84\n",
      "1.016991913318634\n",
      "Starting Epoch 85\n",
      "1.016994323419488\n",
      "Starting Epoch 86\n",
      "1.0166947012362273\n",
      "Starting Epoch 87\n",
      "1.0163409632185232\n",
      "Starting Epoch 88\n",
      "1.0167585870494014\n",
      "Starting Epoch 89\n",
      "1.0168109562086023\n",
      "Starting Epoch 90\n",
      "1.0166158287421516\n",
      "Starting Epoch 91\n",
      "1.0167980064516482\n",
      "Starting Epoch 92\n",
      "1.0166118533714958\n",
      "Starting Epoch 93\n",
      "1.0168003336243008\n",
      "Starting Epoch 94\n",
      "1.0167203493740247\n",
      "Starting Epoch 95\n",
      "1.0167662397674893\n",
      "Starting Epoch 96\n",
      "1.016686991505001\n",
      "Starting Epoch 97\n",
      "1.017244966133781\n",
      "Starting Epoch 98\n",
      "1.017028940760571\n",
      "Starting Epoch 99\n",
      "1.016574061435202\n",
      "Starting Epoch 100\n",
      "1.0165573410365893\n",
      "Starting Epoch 101\n",
      "1.0170067937477776\n",
      "Starting Epoch 102\n",
      "1.0170212051142817\n",
      "Starting Epoch 103\n",
      "1.0166477327761443\n",
      "Starting Epoch 104\n",
      "1.0165575561316118\n",
      "Starting Epoch 105\n",
      "1.0167345611945442\n",
      "Starting Epoch 106\n",
      "1.0164500552674998\n",
      "Starting Epoch 107\n",
      "1.016829234102498\n",
      "Starting Epoch 108\n",
      "1.0168962556382883\n",
      "Starting Epoch 109\n",
      "1.0170693578927412\n",
      "Starting Epoch 110\n",
      "1.0170544930126355\n",
      "Starting Epoch 111\n",
      "1.0167532874190288\n",
      "Starting Epoch 112\n",
      "1.0167499055033145\n",
      "Starting Epoch 113\n",
      "1.0166237121042998\n",
      "Starting Epoch 114\n",
      "1.0165216611779255\n",
      "Starting Epoch 115\n",
      "1.0167815659357153\n",
      "Starting Epoch 116\n",
      "1.0166862607002258\n",
      "Starting Epoch 117\n",
      "1.016696950663691\n",
      "Starting Epoch 118\n",
      "1.0168378197628518\n",
      "Starting Epoch 119\n",
      "1.0168307268101235\n",
      "Starting Epoch 120\n",
      "1.0167623913806418\n",
      "Starting Epoch 121\n",
      "1.0168910156125608\n",
      "Starting Epoch 122\n",
      "1.016472427741341\n",
      "Starting Epoch 123\n",
      "1.0164080288099206\n",
      "Starting Epoch 124\n",
      "1.0167469822842141\n",
      "Starting Epoch 125\n",
      "1.0165905796963235\n",
      "Starting Epoch 126\n",
      "1.0168495618778726\n",
      "Starting Epoch 127\n",
      "1.0167707049328347\n",
      "Starting Epoch 128\n",
      "1.0167950625004976\n",
      "Starting Epoch 129\n",
      "1.016906175924384\n",
      "Starting Epoch 130\n",
      "1.0169781757437664\n",
      "Starting Epoch 131\n",
      "1.0167790495831033\n",
      "Starting Epoch 132\n",
      "1.0168204592621846\n",
      "Starting Epoch 133\n",
      "1.0169533853945525\n",
      "Starting Epoch 134\n",
      "1.017034862352454\n",
      "Starting Epoch 135\n",
      "1.0166869811389758\n",
      "Starting Epoch 136\n",
      "1.0168099299721096\n",
      "Starting Epoch 137\n",
      "1.0168541203374448\n",
      "Starting Epoch 138\n",
      "1.0168246549108755\n",
      "Starting Epoch 139\n",
      "1.0168538119481958\n",
      "Starting Epoch 140\n",
      "1.0164690536001455\n",
      "Starting Epoch 141\n",
      "1.016812599223593\n",
      "Starting Epoch 142\n",
      "1.0165737582289653\n",
      "Starting Epoch 143\n",
      "1.0167233710703643\n",
      "Starting Epoch 144\n",
      "1.0167539016060207\n",
      "Starting Epoch 145\n",
      "1.016574755958889\n",
      "Starting Epoch 146\n",
      "1.0164288230564282\n",
      "Starting Epoch 147\n",
      "1.0168981396633645\n",
      "Starting Epoch 148\n",
      "1.01682812752931\n",
      "Starting Epoch 149\n",
      "1.0165833623512932\n",
      "Starting Epoch 150\n",
      "1.0166942010755124\n",
      "Starting Epoch 151\n",
      "1.0168103886687236\n",
      "Starting Epoch 152\n",
      "1.0170751214027405\n",
      "Starting Epoch 153\n",
      "1.01677849240925\n",
      "Starting Epoch 154\n",
      "1.0165582843448804\n",
      "Starting Epoch 155\n",
      "1.0163711749989053\n",
      "Starting Epoch 156\n",
      "1.0163834457812102\n",
      "Starting Epoch 157\n",
      "1.0170349763787312\n",
      "Starting Epoch 158\n",
      "1.0163870272429094\n",
      "Starting Epoch 159\n",
      "1.0165402604186016\n",
      "Starting Epoch 160\n",
      "1.016935540282208\n",
      "Starting Epoch 161\n",
      "1.0169024778449016\n",
      "Starting Epoch 162\n",
      "1.016746178917263\n",
      "Starting Epoch 163\n",
      "1.0163567921389705\n",
      "Starting Epoch 164\n",
      "1.0168341605559639\n",
      "Starting Epoch 165\n",
      "1.016427244829095\n",
      "Starting Epoch 166\n",
      "1.0162001122599063\n",
      "Starting Epoch 167\n",
      "1.0164682165436123\n",
      "Starting Epoch 168\n",
      "1.0171292398286902\n",
      "Starting Epoch 169\n",
      "1.0168572327365046\n",
      "Starting Epoch 170\n",
      "1.0163468355717866\n",
      "Starting Epoch 171\n",
      "1.0166800929152446\n",
      "Starting Epoch 172\n",
      "1.0165079547011333\n",
      "Starting Epoch 173\n",
      "1.0167612459348596\n",
      "Starting Epoch 174\n",
      "1.0167852769727292\n",
      "Starting Epoch 175\n",
      "1.016901713350545\n",
      "Starting Epoch 176\n",
      "1.016729728035305\n",
      "Starting Epoch 177\n",
      "1.0165351732917454\n",
      "Starting Epoch 178\n",
      "1.0166310719821765\n",
      "Starting Epoch 179\n",
      "1.0166910005652385\n",
      "Starting Epoch 180\n",
      "1.0171153519464575\n",
      "Starting Epoch 181\n",
      "1.0170117435248003\n",
      "Starting Epoch 182\n",
      "1.0170094267181728\n",
      "Starting Epoch 183\n",
      "1.0166420547858528\n",
      "Starting Epoch 184\n",
      "1.0168184301127559\n",
      "Starting Epoch 185\n",
      "1.0166704317797786\n",
      "Starting Epoch 186\n",
      "1.0165806023970894\n",
      "Starting Epoch 187\n",
      "1.016630724720333\n",
      "Starting Epoch 188\n",
      "1.0162608701249827\n",
      "Starting Epoch 189\n",
      "1.0166739795518958\n",
      "Starting Epoch 190\n",
      "1.0166294548822485\n",
      "Starting Epoch 191\n",
      "1.0165556435999663\n",
      "Starting Epoch 192\n",
      "1.016707762427952\n",
      "Starting Epoch 193\n",
      "1.016696318336155\n",
      "Starting Epoch 194\n",
      "1.0166936102120772\n",
      "Starting Epoch 195\n",
      "1.0165193728778674\n",
      "Starting Epoch 196\n",
      "1.0166679102441538\n",
      "Starting Epoch 197\n",
      "1.0163472502127937\n",
      "Starting Epoch 198\n",
      "1.0166719115298728\n",
      "Starting Epoch 199\n",
      "1.0166683119276296\n",
      "Starting Epoch 200\n",
      "1.0168196921763213\n",
      "Starting Epoch 201\n",
      "1.01635888348455\n",
      "Starting Epoch 202\n",
      "1.0164878653443379\n",
      "Starting Epoch 203\n",
      "1.016819285309833\n",
      "Starting Epoch 204\n",
      "1.0168069912039714\n",
      "Starting Epoch 205\n",
      "1.016490145869877\n",
      "Starting Epoch 206\n",
      "1.0169237385625425\n",
      "Starting Epoch 207\n",
      "1.0165392626886782\n",
      "Starting Epoch 208\n",
      "1.0168480665787407\n",
      "Starting Epoch 209\n",
      "1.0172524763190227\n",
      "Starting Epoch 210\n",
      "1.0166644946388577\n",
      "Starting Epoch 211\n",
      "1.016715811646503\n",
      "Starting Epoch 212\n",
      "1.0169442140537759\n",
      "Starting Epoch 213\n",
      "1.0164683176123577\n",
      "Starting Epoch 214\n",
      "1.0167982293211895\n",
      "Starting Epoch 215\n",
      "1.0167431986850242\n",
      "Starting Epoch 216\n",
      "1.0167607742807139\n",
      "Starting Epoch 217\n",
      "1.0165182377981103\n",
      "Starting Epoch 218\n",
      "1.0168697030647942\n",
      "Starting Epoch 219\n",
      "1.0164429389912149\n",
      "Starting Epoch 220\n",
      "1.0169268768766653\n",
      "Starting Epoch 221\n",
      "1.0167750897614851\n",
      "Starting Epoch 222\n",
      "1.0170687255652056\n",
      "Starting Epoch 223\n",
      "1.0165279170741206\n",
      "Starting Epoch 224\n",
      "1.0165319105853206\n",
      "Starting Epoch 225\n",
      "1.0165998261907827\n",
      "Starting Epoch 226\n",
      "1.0163585647292759\n",
      "Starting Epoch 227\n",
      "1.0166039959244106\n",
      "Starting Epoch 228\n",
      "1.016780049904533\n",
      "Starting Epoch 229\n",
      "1.0166290143261785\n",
      "Starting Epoch 230\n",
      "1.016605742599653\n",
      "Starting Epoch 231\n",
      "1.01691393489423\n",
      "Starting Epoch 232\n",
      "1.0169509571531545\n",
      "Starting Epoch 233\n",
      "1.0167692796043728\n",
      "Starting Epoch 234\n",
      "1.016587293666342\n",
      "Starting Epoch 235\n",
      "1.0165849509446516\n",
      "Starting Epoch 236\n",
      "1.0166021922360295\n",
      "Starting Epoch 237\n",
      "1.0169277165247046\n",
      "Starting Epoch 238\n",
      "1.0169830477756003\n",
      "Starting Epoch 239\n",
      "1.0167038233383843\n",
      "Starting Epoch 240\n",
      "1.0167673048765764\n",
      "Starting Epoch 241\n",
      "1.016610482464666\n",
      "Starting Epoch 242\n",
      "1.016538231269173\n",
      "Starting Epoch 243\n",
      "1.0164072772730952\n",
      "Starting Epoch 244\n",
      "1.0169581744981848\n",
      "Starting Epoch 245\n",
      "1.0166592779366865\n",
      "Starting Epoch 246\n",
      "1.0166672442270361\n",
      "Starting Epoch 247\n",
      "1.016966568387073\n",
      "Starting Epoch 248\n",
      "1.0167058421217876\n",
      "Starting Epoch 249\n",
      "1.0170062754465186\n",
      "Starting Epoch 250\n",
      "1.0169210641280464\n",
      "Starting Epoch 251\n",
      "1.0164812284967173\n",
      "Starting Epoch 252\n",
      "1.016883347345435\n",
      "Starting Epoch 253\n",
      "1.0165994296903196\n",
      "Starting Epoch 254\n",
      "1.0164470387541729\n",
      "Starting Epoch 255\n",
      "1.0168013883673626\n",
      "Starting Epoch 256\n",
      "1.016767478507498\n",
      "Starting Epoch 257\n",
      "1.0166646164396536\n",
      "Starting Epoch 258\n",
      "1.0166072923204172\n",
      "Starting Epoch 259\n",
      "1.0170048423435376\n",
      "Starting Epoch 260\n",
      "1.016803212787794\n",
      "Starting Epoch 261\n",
      "1.0165550656940625\n",
      "Starting Epoch 262\n",
      "1.0168120912883594\n",
      "Starting Epoch 263\n",
      "1.0165491907492927\n",
      "Starting Epoch 264\n",
      "1.016842378222424\n",
      "Starting Epoch 265\n",
      "1.0172180792559748\n",
      "Starting Epoch 266\n",
      "1.0169305671816287\n",
      "Starting Epoch 267\n",
      "1.0166065433750981\n",
      "Starting Epoch 268\n",
      "1.01669507700464\n",
      "Starting Epoch 269\n",
      "1.016580397668092\n",
      "Starting Epoch 270\n",
      "1.0166657281958538\n",
      "Starting Epoch 271\n",
      "1.0165397421173428\n",
      "Starting Epoch 272\n",
      "1.0165180252945942\n",
      "Starting Epoch 273\n",
      "1.016571529533552\n",
      "Starting Epoch 274\n",
      "1.0164793626121853\n",
      "Starting Epoch 275\n",
      "1.0166827932648037\n",
      "Starting Epoch 276\n",
      "1.016449899777122\n",
      "Starting Epoch 277\n",
      "1.0164477099543032\n",
      "Starting Epoch 278\n",
      "1.0171078676762788\n",
      "Starting Epoch 279\n",
      "1.016651381617007\n",
      "Starting Epoch 280\n",
      "1.0167345300964687\n",
      "Starting Epoch 281\n",
      "1.0166006269662275\n",
      "Starting Epoch 282\n",
      "1.0167821593906567\n",
      "Starting Epoch 283\n",
      "1.0168163983718208\n",
      "Starting Epoch 284\n",
      "1.0166741117187168\n",
      "Starting Epoch 285\n",
      "1.0170204561689626\n",
      "Starting Epoch 286\n",
      "1.0165728900743567\n",
      "Starting Epoch 287\n",
      "1.016677957514058\n",
      "Starting Epoch 288\n",
      "1.0165929794311523\n",
      "Starting Epoch 289\n",
      "1.0170035206753274\n",
      "Starting Epoch 290\n",
      "1.0167956248573635\n",
      "Starting Epoch 291\n",
      "1.0168513189191404\n",
      "Starting Epoch 292\n",
      "1.0166999645855115\n",
      "Starting Epoch 293\n",
      "1.016587752362956\n",
      "Starting Epoch 294\n",
      "1.0167999863624573\n",
      "Starting Epoch 295\n",
      "1.0166651554729627\n",
      "Starting Epoch 296\n",
      "1.0168851251187532\n",
      "Starting Epoch 297\n",
      "1.0166797560194265\n",
      "Starting Epoch 298\n",
      "1.0167921366898909\n",
      "Starting Epoch 299\n",
      "1.016645382279935\n",
      "Starting Epoch 300\n",
      "1.0167446602945742\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "41c8d7f8-be76-471f-9434-e88c37b6f884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.0900182853574338\n",
      "New best model found at epoch 1 with validation loss 0.8775328397750854\n",
      "Starting Epoch 2\n",
      "0.8647342479747274\n",
      "New best model found at epoch 2 with validation loss 0.8070047497749329\n",
      "Starting Epoch 3\n",
      "0.8025844926419465\n",
      "New best model found at epoch 3 with validation loss 0.7953071594238281\n",
      "Starting Epoch 4\n",
      "0.7915839915690215\n",
      "New best model found at epoch 4 with validation loss 0.7852158546447754\n",
      "Starting Epoch 5\n",
      "0.7911728983340056\n",
      "New best model found at epoch 5 with validation loss 0.772782027721405\n",
      "Starting Epoch 6\n",
      "0.7874746426292087\n",
      "New best model found at epoch 6 with validation loss 0.7713773250579834\n",
      "Starting Epoch 7\n",
      "0.787060779073964\n",
      "Starting Epoch 8\n",
      "0.7847565619841866\n",
      "Starting Epoch 9\n",
      "0.7845737363981165\n",
      "New best model found at epoch 9 with validation loss 0.7698074579238892\n",
      "Starting Epoch 10\n",
      "0.7836398430492567\n",
      "Starting Epoch 11\n",
      "0.7817314526309138\n",
      "New best model found at epoch 11 with validation loss 0.7670484185218811\n",
      "Starting Epoch 12\n",
      "0.7843385442443516\n",
      "Starting Epoch 13\n",
      "0.7797129853912022\n",
      "Starting Epoch 14\n",
      "0.778662409471429\n",
      "New best model found at epoch 14 with validation loss 0.7641236782073975\n",
      "Starting Epoch 15\n",
      "0.7795006036758423\n",
      "Starting Epoch 16\n",
      "0.7767560482025146\n",
      "New best model found at epoch 16 with validation loss 0.7641148567199707\n",
      "Starting Epoch 17\n",
      "0.7766682842503423\n",
      "New best model found at epoch 17 with validation loss 0.7617615461349487\n",
      "Starting Epoch 18\n",
      "0.7756569152292998\n",
      "Starting Epoch 19\n",
      "0.7741225180418595\n",
      "Starting Epoch 20\n",
      "0.7706682993018109\n",
      "New best model found at epoch 20 with validation loss 0.7584800124168396\n",
      "Starting Epoch 21\n",
      "0.7737479443135469\n",
      "New best model found at epoch 21 with validation loss 0.7580106258392334\n",
      "Starting Epoch 22\n",
      "0.7716165470040363\n",
      "Starting Epoch 23\n",
      "0.769589320473049\n",
      "Starting Epoch 24\n",
      "0.7724508539490078\n",
      "Starting Epoch 25\n",
      "0.7726919391880864\n",
      "New best model found at epoch 25 with validation loss 0.7523612976074219\n",
      "Starting Epoch 26\n",
      "0.7675761658212413\n",
      "Starting Epoch 27\n",
      "0.7662165190862573\n",
      "New best model found at epoch 27 with validation loss 0.7505245208740234\n",
      "Starting Epoch 28\n",
      "0.7651652564173159\n",
      "Starting Epoch 29\n",
      "0.7636039982671323\n",
      "New best model found at epoch 29 with validation loss 0.7481468319892883\n",
      "Starting Epoch 30\n",
      "0.7666125219801198\n",
      "New best model found at epoch 30 with validation loss 0.7471879124641418\n",
      "Starting Epoch 31\n",
      "0.7669615123582922\n",
      "Starting Epoch 32\n",
      "0.762985418672147\n",
      "New best model found at epoch 32 with validation loss 0.7462395429611206\n",
      "Starting Epoch 33\n",
      "0.7619039649548738\n",
      "Starting Epoch 34\n",
      "0.7581881492034249\n",
      "New best model found at epoch 34 with validation loss 0.7435532808303833\n",
      "Starting Epoch 35\n",
      "0.763453237388445\n",
      "Starting Epoch 36\n",
      "0.7597927528878917\n",
      "New best model found at epoch 36 with validation loss 0.7419663071632385\n",
      "Starting Epoch 37\n",
      "0.759864752707274\n",
      "Starting Epoch 38\n",
      "0.7600945985835531\n",
      "New best model found at epoch 38 with validation loss 0.7404947280883789\n",
      "Starting Epoch 39\n",
      "0.7561458789783976\n",
      "New best model found at epoch 39 with validation loss 0.7395962476730347\n",
      "Starting Epoch 40\n",
      "0.7626770968022554\n",
      "Starting Epoch 41\n",
      "0.7522785223048666\n",
      "New best model found at epoch 41 with validation loss 0.7393832802772522\n",
      "Starting Epoch 42\n",
      "0.7577527087667714\n",
      "New best model found at epoch 42 with validation loss 0.7389995455741882\n",
      "Starting Epoch 43\n",
      "0.7520327179328256\n",
      "New best model found at epoch 43 with validation loss 0.7373796105384827\n",
      "Starting Epoch 44\n",
      "0.753079266651817\n",
      "New best model found at epoch 44 with validation loss 0.735787034034729\n",
      "Starting Epoch 45\n",
      "0.7511234931323839\n",
      "Starting Epoch 46\n",
      "0.7519360806631006\n",
      "New best model found at epoch 46 with validation loss 0.7336368560791016\n",
      "Starting Epoch 47\n",
      "0.7509004370025967\n",
      "New best model found at epoch 47 with validation loss 0.732752799987793\n",
      "Starting Epoch 48\n",
      "0.7483422574789628\n",
      "Starting Epoch 49\n",
      "0.7516832040703815\n",
      "New best model found at epoch 49 with validation loss 0.7323182821273804\n",
      "Starting Epoch 50\n",
      "0.7488646377687869\n",
      "New best model found at epoch 50 with validation loss 0.7317448854446411\n",
      "Starting Epoch 51\n",
      "0.7481401925501616\n",
      "New best model found at epoch 51 with validation loss 0.7300542593002319\n",
      "Starting Epoch 52\n",
      "0.7453231370967367\n",
      "New best model found at epoch 52 with validation loss 0.7298687100410461\n",
      "Starting Epoch 53\n",
      "0.7474353132040604\n",
      "New best model found at epoch 53 with validation loss 0.7284250259399414\n",
      "Starting Epoch 54\n",
      "0.7459543036377948\n",
      "Starting Epoch 55\n",
      "0.7464430643164593\n",
      "New best model found at epoch 55 with validation loss 0.7268388867378235\n",
      "Starting Epoch 56\n",
      "0.7502602805262026\n",
      "Starting Epoch 57\n",
      "0.7458760842033054\n",
      "Starting Epoch 58\n",
      "0.7464554802231167\n",
      "Starting Epoch 59\n",
      "0.7480590654456097\n",
      "Starting Epoch 60\n",
      "0.7421230129573656\n",
      "New best model found at epoch 60 with validation loss 0.7253893613815308\n",
      "Starting Epoch 61\n",
      "0.7424864224765612\n",
      "Starting Epoch 62\n",
      "0.7439363495163296\n",
      "New best model found at epoch 62 with validation loss 0.7251315712928772\n",
      "Starting Epoch 63\n",
      "0.7472580878630929\n",
      "Starting Epoch 64\n",
      "0.7444839347963748\n",
      "Starting Epoch 65\n",
      "0.7432741367298624\n",
      "Starting Epoch 66\n",
      "0.7417296870895054\n",
      "Starting Epoch 67\n",
      "0.7462508574776028\n",
      "New best model found at epoch 67 with validation loss 0.7250049114227295\n",
      "Starting Epoch 68\n",
      "0.7408615843109463\n",
      "New best model found at epoch 68 with validation loss 0.7216500639915466\n",
      "Starting Epoch 69\n",
      "0.7371355528416841\n",
      "Starting Epoch 70\n",
      "0.7388080177099808\n",
      "Starting Epoch 71\n",
      "0.7386703517126001\n",
      "Starting Epoch 72\n",
      "0.7375367283821106\n",
      "New best model found at epoch 72 with validation loss 0.7197667360305786\n",
      "Starting Epoch 73\n",
      "0.7428246477375859\n",
      "Starting Epoch 74\n",
      "0.7384677607080211\n",
      "Starting Epoch 75\n",
      "0.7385030907133351\n",
      "New best model found at epoch 75 with validation loss 0.7183155417442322\n",
      "Starting Epoch 76\n",
      "0.7417607566584712\n",
      "Starting Epoch 77\n",
      "0.7428006503892981\n",
      "New best model found at epoch 77 with validation loss 0.718230664730072\n",
      "Starting Epoch 78\n",
      "0.7379735267680624\n",
      "New best model found at epoch 78 with validation loss 0.7181485891342163\n",
      "Starting Epoch 79\n",
      "0.7384252470472584\n",
      "New best model found at epoch 79 with validation loss 0.7174645662307739\n",
      "Starting Epoch 80\n",
      "0.7351979380068572\n",
      "Starting Epoch 81\n",
      "0.7341594203658726\n",
      "Starting Epoch 82\n",
      "0.7396685506986536\n",
      "New best model found at epoch 82 with validation loss 0.7172679901123047\n",
      "Starting Epoch 83\n",
      "0.7377341545146444\n",
      "Starting Epoch 84\n",
      "0.7361373953197313\n",
      "Starting Epoch 85\n",
      "0.7378023474112801\n",
      "Starting Epoch 86\n",
      "0.7320867776870728\n",
      "Starting Epoch 87\n",
      "0.739874806093133\n",
      "Starting Epoch 88\n",
      "0.732976610245912\n",
      "New best model found at epoch 88 with validation loss 0.7163939476013184\n",
      "Starting Epoch 89\n",
      "0.7341287110162817\n",
      "Starting Epoch 90\n",
      "0.7354400287503782\n",
      "Starting Epoch 91\n",
      "0.7317993018938147\n",
      "New best model found at epoch 91 with validation loss 0.7141714096069336\n",
      "Starting Epoch 92\n",
      "0.7331322872120402\n",
      "Starting Epoch 93\n",
      "0.7350003719329834\n",
      "Starting Epoch 94\n",
      "0.7367396458335544\n",
      "New best model found at epoch 94 with validation loss 0.7136344313621521\n",
      "Starting Epoch 95\n",
      "0.734264638112939\n",
      "Starting Epoch 96\n",
      "0.7322123128434886\n",
      "New best model found at epoch 96 with validation loss 0.7127216458320618\n",
      "Starting Epoch 97\n",
      "0.7370108132777007\n",
      "Starting Epoch 98\n",
      "0.7344662806262141\n",
      "Starting Epoch 99\n",
      "0.7348613687183546\n",
      "Starting Epoch 100\n",
      "0.7326070873633675\n",
      "Starting Epoch 101\n",
      "0.734324530414913\n",
      "New best model found at epoch 101 with validation loss 0.7114361524581909\n",
      "Starting Epoch 102\n",
      "0.7336110731829768\n",
      "Starting Epoch 103\n",
      "0.7332121133804321\n",
      "Starting Epoch 104\n",
      "0.730322532031847\n",
      "Starting Epoch 105\n",
      "0.732265301372694\n",
      "Starting Epoch 106\n",
      "0.7301078957060109\n",
      "New best model found at epoch 106 with validation loss 0.7106125950813293\n",
      "Starting Epoch 107\n",
      "0.7351731606151747\n",
      "Starting Epoch 108\n",
      "0.7305293342341548\n",
      "Starting Epoch 109\n",
      "0.7314959453499835\n",
      "Starting Epoch 110\n",
      "0.7311394266460253\n",
      "Starting Epoch 111\n",
      "0.7295123882915663\n",
      "Starting Epoch 112\n",
      "0.731102686861287\n",
      "Starting Epoch 113\n",
      "0.7265076481777689\n",
      "Starting Epoch 114\n",
      "0.7326541154280953\n",
      "Starting Epoch 115\n",
      "0.7267319637796154\n",
      "New best model found at epoch 115 with validation loss 0.7094698548316956\n",
      "Starting Epoch 116\n",
      "0.7282779190851294\n",
      "Starting Epoch 117\n",
      "0.7293486672898998\n",
      "New best model found at epoch 117 with validation loss 0.709193229675293\n",
      "Starting Epoch 118\n",
      "0.728702716205431\n",
      "Starting Epoch 119\n",
      "0.7303677589997001\n",
      "New best model found at epoch 119 with validation loss 0.708862841129303\n",
      "Starting Epoch 120\n",
      "0.7294098916261093\n",
      "Starting Epoch 121\n",
      "0.7303349945856177\n",
      "New best model found at epoch 121 with validation loss 0.7086440920829773\n",
      "Starting Epoch 122\n",
      "0.7282412803691366\n",
      "Starting Epoch 123\n",
      "0.7275122715079266\n",
      "New best model found at epoch 123 with validation loss 0.7073379755020142\n",
      "Starting Epoch 124\n",
      "0.7265844630158466\n",
      "Starting Epoch 125\n",
      "0.7287750425546066\n",
      "Starting Epoch 126\n",
      "0.7283789852391118\n",
      "Starting Epoch 127\n",
      "0.7271358033885127\n",
      "Starting Epoch 128\n",
      "0.730721424455228\n",
      "Starting Epoch 129\n",
      "0.7365417661874191\n",
      "New best model found at epoch 129 with validation loss 0.7065240144729614\n",
      "Starting Epoch 130\n",
      "0.7258336310801299\n",
      "Starting Epoch 131\n",
      "0.7283589554869611\n",
      "Starting Epoch 132\n",
      "0.7302961090336675\n",
      "Starting Epoch 133\n",
      "0.7279534184414408\n",
      "Starting Epoch 134\n",
      "0.7310575583706731\n",
      "Starting Epoch 135\n",
      "0.7275012239165928\n",
      "Starting Epoch 136\n",
      "0.7330460833466571\n",
      "New best model found at epoch 136 with validation loss 0.7060254216194153\n",
      "Starting Epoch 137\n",
      "0.7273803690205449\n",
      "Starting Epoch 138\n",
      "0.7246379774549733\n",
      "Starting Epoch 139\n",
      "0.7255765121916066\n",
      "Starting Epoch 140\n",
      "0.7248535804126574\n",
      "Starting Epoch 141\n",
      "0.7293560971384463\n",
      "Starting Epoch 142\n",
      "0.7280128364977629\n",
      "New best model found at epoch 142 with validation loss 0.7053871154785156\n",
      "Starting Epoch 143\n",
      "0.7247456623160321\n",
      "Starting Epoch 144\n",
      "0.72477518475574\n",
      "Starting Epoch 145\n",
      "0.7251221796740657\n",
      "Starting Epoch 146\n",
      "0.7264102878777877\n",
      "Starting Epoch 147\n",
      "0.7258674891098685\n",
      "Starting Epoch 148\n",
      "0.726199852383655\n",
      "New best model found at epoch 148 with validation loss 0.7052822709083557\n",
      "Starting Epoch 149\n",
      "0.7262608979059302\n",
      "Starting Epoch 150\n",
      "0.7311813416688339\n",
      "Starting Epoch 151\n",
      "0.7269573444905488\n",
      "Starting Epoch 152\n",
      "0.7240285614262456\n",
      "Starting Epoch 153\n",
      "0.7247531595437423\n",
      "New best model found at epoch 153 with validation loss 0.7038035988807678\n",
      "Starting Epoch 154\n",
      "0.7273896725281425\n",
      "Starting Epoch 155\n",
      "0.7247165597003439\n",
      "Starting Epoch 156\n",
      "0.7262082721876062\n",
      "Starting Epoch 157\n",
      "0.7225530562193497\n",
      "Starting Epoch 158\n",
      "0.7258538888848346\n",
      "Starting Epoch 159\n",
      "0.725756427516108\n",
      "Starting Epoch 160\n",
      "0.7270604346109473\n",
      "Starting Epoch 161\n",
      "0.7245695176331893\n",
      "Starting Epoch 162\n",
      "0.726410554802936\n",
      "Starting Epoch 163\n",
      "0.7254384756088257\n",
      "Starting Epoch 164\n",
      "0.722836655119191\n",
      "Starting Epoch 165\n",
      "0.7251712679862976\n",
      "Starting Epoch 166\n",
      "0.7245460385861604\n",
      "Starting Epoch 167\n",
      "0.7213188824446305\n",
      "New best model found at epoch 167 with validation loss 0.7033915519714355\n",
      "Starting Epoch 168\n",
      "0.7253497787143873\n",
      "Starting Epoch 169\n",
      "0.7224599382151728\n",
      "Starting Epoch 170\n",
      "0.7234623691310054\n",
      "Starting Epoch 171\n",
      "0.721959456153538\n",
      "Starting Epoch 172\n",
      "0.7235491871833801\n",
      "Starting Epoch 173\n",
      "0.7227168523746988\n",
      "New best model found at epoch 173 with validation loss 0.7030860185623169\n",
      "Starting Epoch 174\n",
      "0.7233262321223384\n",
      "Starting Epoch 175\n",
      "0.7259278167849001\n",
      "Starting Epoch 176\n",
      "0.7244933688122294\n",
      "New best model found at epoch 176 with validation loss 0.7025821805000305\n",
      "Starting Epoch 177\n",
      "0.722698159839796\n",
      "Starting Epoch 178\n",
      "0.7206671419350997\n",
      "Starting Epoch 179\n",
      "0.7258773886639139\n",
      "Starting Epoch 180\n",
      "0.7240732001221698\n",
      "New best model found at epoch 180 with validation loss 0.702083945274353\n",
      "Starting Epoch 181\n",
      "0.7243465366570846\n",
      "Starting Epoch 182\n",
      "0.7261477475580962\n",
      "New best model found at epoch 182 with validation loss 0.7017955183982849\n",
      "Starting Epoch 183\n",
      "0.7234309652577275\n",
      "Starting Epoch 184\n",
      "0.7228901541751364\n",
      "Starting Epoch 185\n",
      "0.7223267788472383\n",
      "Starting Epoch 186\n",
      "0.7220478783483091\n",
      "Starting Epoch 187\n",
      "0.7212343345517698\n",
      "Starting Epoch 188\n",
      "0.7227945224098538\n",
      "Starting Epoch 189\n",
      "0.7232707790706469\n",
      "Starting Epoch 190\n",
      "0.7214251601177714\n",
      "Starting Epoch 191\n",
      "0.7230144894641378\n",
      "Starting Epoch 192\n",
      "0.7206980715627256\n",
      "Starting Epoch 193\n",
      "0.7224765186724456\n",
      "Starting Epoch 194\n",
      "0.7240844368934631\n",
      "Starting Epoch 195\n",
      "0.7205561995506287\n",
      "Starting Epoch 196\n",
      "0.7226438833319623\n",
      "Starting Epoch 197\n",
      "0.7221258153086123\n",
      "Starting Epoch 198\n",
      "0.7197986944862034\n",
      "Starting Epoch 199\n",
      "0.7191358830617822\n",
      "Starting Epoch 200\n",
      "0.7211666392243427\n",
      "Starting Epoch 201\n",
      "0.7221476228340812\n",
      "Starting Epoch 202\n",
      "0.725513289804044\n",
      "Starting Epoch 203\n",
      "0.7208063317381818\n",
      "New best model found at epoch 203 with validation loss 0.7008002996444702\n",
      "Starting Epoch 204\n",
      "0.72239293222842\n",
      "Starting Epoch 205\n",
      "0.7205202786818795\n",
      "Starting Epoch 206\n",
      "0.7227097853370335\n",
      "Starting Epoch 207\n",
      "0.723886295505192\n",
      "Starting Epoch 208\n",
      "0.7198756363080896\n",
      "Starting Epoch 209\n",
      "0.7218536501345427\n",
      "New best model found at epoch 209 with validation loss 0.6998911499977112\n",
      "Starting Epoch 210\n",
      "0.7242334225903386\n",
      "Starting Epoch 211\n",
      "0.7215636994527734\n",
      "Starting Epoch 212\n",
      "0.7231451920841051\n",
      "New best model found at epoch 212 with validation loss 0.6996557712554932\n",
      "Starting Epoch 213\n",
      "0.7218833332476409\n",
      "Starting Epoch 214\n",
      "0.7242555410965629\n",
      "Starting Epoch 215\n",
      "0.7229317089785701\n",
      "Starting Epoch 216\n",
      "0.7195931336154109\n",
      "Starting Epoch 217\n",
      "0.7211997172106868\n",
      "Starting Epoch 218\n",
      "0.7237555902937184\n",
      "New best model found at epoch 218 with validation loss 0.6994792819023132\n",
      "Starting Epoch 219\n",
      "0.721798642821934\n",
      "Starting Epoch 220\n",
      "0.7222326838451884\n",
      "Starting Epoch 221\n",
      "0.719603823578876\n",
      "Starting Epoch 222\n",
      "0.7201582530270452\n",
      "Starting Epoch 223\n",
      "0.7204088309536809\n",
      "New best model found at epoch 223 with validation loss 0.6994243860244751\n",
      "Starting Epoch 224\n",
      "0.7203700775685518\n",
      "Starting Epoch 225\n",
      "0.7200110813845759\n",
      "Starting Epoch 226\n",
      "0.7221034428347712\n",
      "Starting Epoch 227\n",
      "0.7207339587418929\n",
      "Starting Epoch 228\n",
      "0.7198660762413688\n",
      "Starting Epoch 229\n",
      "0.7225108483563298\n",
      "Starting Epoch 230\n",
      "0.7211618138396222\n",
      "Starting Epoch 231\n",
      "0.719978304012962\n",
      "Starting Epoch 232\n",
      "0.7242081061653469\n",
      "Starting Epoch 233\n",
      "0.7199183961619502\n",
      "Starting Epoch 234\n",
      "0.7201862723931022\n",
      "Starting Epoch 235\n",
      "0.7230014101318691\n",
      "Starting Epoch 236\n",
      "0.7219134258187335\n",
      "Starting Epoch 237\n",
      "0.7189267562783282\n",
      "Starting Epoch 238\n",
      "0.718859965386598\n",
      "New best model found at epoch 238 with validation loss 0.6993257999420166\n",
      "Starting Epoch 239\n",
      "0.7193458261697189\n",
      "Starting Epoch 240\n",
      "0.7256144103796586\n",
      "Starting Epoch 241\n",
      "0.720876377561818\n",
      "Starting Epoch 242\n",
      "0.7207319606905398\n",
      "Starting Epoch 243\n",
      "0.7197599203690238\n",
      "New best model found at epoch 243 with validation loss 0.6991268396377563\n",
      "Starting Epoch 244\n",
      "0.7195091092068217\n",
      "Starting Epoch 245\n",
      "0.721113699933757\n",
      "Starting Epoch 246\n",
      "0.7181747374327286\n",
      "Starting Epoch 247\n",
      "0.7195461185082145\n",
      "New best model found at epoch 247 with validation loss 0.6983335614204407\n",
      "Starting Epoch 248\n",
      "0.7188667188520017\n",
      "Starting Epoch 249\n",
      "0.7210581380388011\n",
      "Starting Epoch 250\n",
      "0.7181740092194598\n",
      "Starting Epoch 251\n",
      "0.721430128035338\n",
      "Starting Epoch 252\n",
      "0.7189344089964161\n",
      "Starting Epoch 253\n",
      "0.7200355218804401\n",
      "New best model found at epoch 253 with validation loss 0.6982347965240479\n",
      "Starting Epoch 254\n",
      "0.7188723320546357\n",
      "Starting Epoch 255\n",
      "0.7200818631959998\n",
      "Starting Epoch 256\n",
      "0.7190556189288264\n",
      "Starting Epoch 257\n",
      "0.7187732380369435\n",
      "Starting Epoch 258\n",
      "0.7198414154674696\n",
      "Starting Epoch 259\n",
      "0.719444725824439\n",
      "Starting Epoch 260\n",
      "0.7183299660682678\n",
      "New best model found at epoch 260 with validation loss 0.6981467604637146\n",
      "Starting Epoch 261\n",
      "0.7197003545968429\n",
      "Starting Epoch 262\n",
      "0.7196964517883633\n",
      "Starting Epoch 263\n",
      "0.7182137862495754\n",
      "Starting Epoch 264\n",
      "0.7219902017842168\n",
      "New best model found at epoch 264 with validation loss 0.6981238722801208\n",
      "Starting Epoch 265\n",
      "0.7223755898682968\n",
      "Starting Epoch 266\n",
      "0.7195448279380798\n",
      "Starting Epoch 267\n",
      "0.7214078669962676\n",
      "Starting Epoch 268\n",
      "0.7171445229779119\n",
      "Starting Epoch 269\n",
      "0.7187644087749979\n",
      "Starting Epoch 270\n",
      "0.7178694579912268\n",
      "New best model found at epoch 270 with validation loss 0.6974409818649292\n",
      "Starting Epoch 271\n",
      "0.7192506453265315\n",
      "Starting Epoch 272\n",
      "0.7175000128538712\n",
      "Starting Epoch 273\n",
      "0.7188576615375021\n",
      "New best model found at epoch 273 with validation loss 0.6971260905265808\n",
      "Starting Epoch 274\n",
      "0.7167583289353744\n",
      "Starting Epoch 275\n",
      "0.7186827244965927\n",
      "Starting Epoch 276\n",
      "0.7196179187816122\n",
      "Starting Epoch 277\n",
      "0.7175406943196836\n",
      "Starting Epoch 278\n",
      "0.7213299481765084\n",
      "Starting Epoch 279\n",
      "0.7169966023901234\n",
      "Starting Epoch 280\n",
      "0.7185185240662616\n",
      "Starting Epoch 281\n",
      "0.717193471348804\n",
      "Starting Epoch 282\n",
      "0.7183139376018358\n",
      "Starting Epoch 283\n",
      "0.7209038889926412\n",
      "Starting Epoch 284\n",
      "0.7213151532670726\n",
      "Starting Epoch 285\n",
      "0.7183331017908843\n",
      "Starting Epoch 286\n",
      "0.7183002363080564\n",
      "Starting Epoch 287\n",
      "0.7185295561085576\n",
      "Starting Epoch 288\n",
      "0.7184347043866697\n",
      "Starting Epoch 289\n",
      "0.7205024543015853\n",
      "New best model found at epoch 289 with validation loss 0.6971222162246704\n",
      "Starting Epoch 290\n",
      "0.7158595841863881\n",
      "Starting Epoch 291\n",
      "0.7197795717612557\n",
      "Starting Epoch 292\n",
      "0.7208623756533084\n",
      "New best model found at epoch 292 with validation loss 0.6969241499900818\n",
      "Starting Epoch 293\n",
      "0.7172799602798794\n",
      "Starting Epoch 294\n",
      "0.717540222665538\n",
      "Starting Epoch 295\n",
      "0.7170918506124745\n",
      "Starting Epoch 296\n",
      "0.7175169768540756\n",
      "New best model found at epoch 296 with validation loss 0.6966126561164856\n",
      "Starting Epoch 297\n",
      "0.7181595978529557\n",
      "New best model found at epoch 297 with validation loss 0.6960863471031189\n",
      "Starting Epoch 298\n",
      "0.7172560873238937\n",
      "Starting Epoch 299\n",
      "0.7162581371224445\n",
      "Starting Epoch 300\n",
      "0.7186323119246442\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-5-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ec50d",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 2, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 10 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8fabc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6159e38e-0150-4672-8d4f-65ecf9829b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.0533439387445864\n",
      "New best model found at epoch 1 with validation loss 0.8945792317390442\n",
      "Starting Epoch 2\n",
      "0.9240155064541361\n",
      "New best model found at epoch 2 with validation loss 0.8607720136642456\n",
      "Starting Epoch 3\n",
      "0.9008420265239218\n",
      "New best model found at epoch 3 with validation loss 0.8516408205032349\n",
      "Starting Epoch 4\n",
      "0.910059418367303\n",
      "New best model found at epoch 4 with validation loss 0.8345244526863098\n",
      "Starting Epoch 5\n",
      "0.8852697429449662\n",
      "Starting Epoch 6\n",
      "0.8821031995441603\n",
      "Starting Epoch 7\n",
      "0.8833420743112979\n",
      "New best model found at epoch 7 with validation loss 0.8268954753875732\n",
      "Starting Epoch 8\n",
      "0.8809610397919364\n",
      "New best model found at epoch 8 with validation loss 0.8186146020889282\n",
      "Starting Epoch 9\n",
      "0.8683371699374655\n",
      "Starting Epoch 10\n",
      "0.8748642413512521\n",
      "Starting Epoch 11\n",
      "0.8729407320851865\n",
      "Starting Epoch 12\n",
      "0.8595175432122272\n",
      "Starting Epoch 13\n",
      "0.8639185946920643\n",
      "New best model found at epoch 13 with validation loss 0.8096784353256226\n",
      "Starting Epoch 14\n",
      "0.8595442046289858\n",
      "New best model found at epoch 14 with validation loss 0.8047949075698853\n",
      "Starting Epoch 15\n",
      "0.8569901559663855\n",
      "New best model found at epoch 15 with validation loss 0.7995995879173279\n",
      "Starting Epoch 16\n",
      "0.8532254669977271\n",
      "Starting Epoch 17\n",
      "0.8546476338220679\n",
      "Starting Epoch 18\n",
      "0.852975404780844\n",
      "New best model found at epoch 18 with validation loss 0.7990021705627441\n",
      "Starting Epoch 19\n",
      "0.8525348590767902\n",
      "New best model found at epoch 19 with validation loss 0.7969798445701599\n",
      "Starting Epoch 20\n",
      "0.850347638130188\n",
      "Starting Epoch 21\n",
      "0.8459982690603837\n",
      "New best model found at epoch 21 with validation loss 0.7951688170433044\n",
      "Starting Epoch 22\n",
      "0.8461507403332255\n",
      "Starting Epoch 23\n",
      "0.843127940012061\n",
      "New best model found at epoch 23 with validation loss 0.7889484167098999\n",
      "Starting Epoch 24\n",
      "0.8421724827393241\n",
      "New best model found at epoch 24 with validation loss 0.7867606282234192\n",
      "Starting Epoch 25\n",
      "0.8404220601786738\n",
      "Starting Epoch 26\n",
      "0.8413782456646794\n",
      "Starting Epoch 27\n",
      "0.8362284561862117\n",
      "New best model found at epoch 27 with validation loss 0.7834490537643433\n",
      "Starting Epoch 28\n",
      "0.8375247198602428\n",
      "Starting Epoch 29\n",
      "0.8355345829673435\n",
      "New best model found at epoch 29 with validation loss 0.781440258026123\n",
      "Starting Epoch 30\n",
      "0.8319380361100902\n",
      "New best model found at epoch 30 with validation loss 0.7805672883987427\n",
      "Starting Epoch 31\n",
      "0.8343850140986235\n",
      "Starting Epoch 32\n",
      "0.8318065975023352\n",
      "Starting Epoch 33\n",
      "0.8304820734521617\n",
      "New best model found at epoch 33 with validation loss 0.7779629230499268\n",
      "Starting Epoch 34\n",
      "0.8282193256461102\n",
      "Starting Epoch 35\n",
      "0.8250910328782123\n",
      "New best model found at epoch 35 with validation loss 0.7761630415916443\n",
      "Starting Epoch 36\n",
      "0.8263818310654681\n",
      "New best model found at epoch 36 with validation loss 0.7755332589149475\n",
      "Starting Epoch 37\n",
      "0.8222805728083071\n",
      "Starting Epoch 38\n",
      "0.8225311585094618\n",
      "Starting Epoch 39\n",
      "0.8227391579876775\n",
      "Starting Epoch 40\n",
      "0.8173103202944216\n",
      "New best model found at epoch 40 with validation loss 0.7718099355697632\n",
      "Starting Epoch 41\n",
      "0.818199652692546\n",
      "Starting Epoch 42\n",
      "0.8199064938918404\n",
      "Starting Epoch 43\n",
      "0.8171021134957023\n",
      "Starting Epoch 44\n",
      "0.8157641576684039\n",
      "New best model found at epoch 44 with validation loss 0.7711463570594788\n",
      "Starting Epoch 45\n",
      "0.8156203135200168\n",
      "New best model found at epoch 45 with validation loss 0.7676827311515808\n",
      "Starting Epoch 46\n",
      "0.8148116780363995\n",
      "Starting Epoch 47\n",
      "0.8118051523747651\n",
      "New best model found at epoch 47 with validation loss 0.7658480405807495\n",
      "Starting Epoch 48\n",
      "0.8117928841839666\n",
      "Starting Epoch 49\n",
      "0.8117959758509761\n",
      "New best model found at epoch 49 with validation loss 0.7638371586799622\n",
      "Starting Epoch 50\n",
      "0.8135094279828279\n",
      "New best model found at epoch 50 with validation loss 0.7636293768882751\n",
      "Starting Epoch 51\n",
      "0.8082589351612589\n",
      "Starting Epoch 52\n",
      "0.8065797505171403\n",
      "New best model found at epoch 52 with validation loss 0.7624615430831909\n",
      "Starting Epoch 53\n",
      "0.8084943294525146\n",
      "New best model found at epoch 53 with validation loss 0.7612013220787048\n",
      "Starting Epoch 54\n",
      "0.8094064334164495\n",
      "Starting Epoch 55\n",
      "0.8049018201620682\n",
      "New best model found at epoch 55 with validation loss 0.759641706943512\n",
      "Starting Epoch 56\n",
      "0.8048043276952661\n",
      "Starting Epoch 57\n",
      "0.8068011428998865\n",
      "New best model found at epoch 57 with validation loss 0.7581671476364136\n",
      "Starting Epoch 58\n",
      "0.8006727773210277\n",
      "Starting Epoch 59\n",
      "0.7984425814255424\n",
      "Starting Epoch 60\n",
      "0.7994857041732125\n",
      "Starting Epoch 61\n",
      "0.8005012636599333\n",
      "New best model found at epoch 61 with validation loss 0.7543089985847473\n",
      "Starting Epoch 62\n",
      "0.7977271028186964\n",
      "Starting Epoch 63\n",
      "0.8016659332358319\n",
      "New best model found at epoch 63 with validation loss 0.7533705234527588\n",
      "Starting Epoch 64\n",
      "0.7975746211798295\n",
      "New best model found at epoch 64 with validation loss 0.7525053024291992\n",
      "Starting Epoch 65\n",
      "0.7976093732792399\n",
      "Starting Epoch 66\n",
      "0.7949101225189541\n",
      "New best model found at epoch 66 with validation loss 0.7522591948509216\n",
      "Starting Epoch 67\n",
      "0.7956842158151709\n",
      "New best model found at epoch 67 with validation loss 0.750573456287384\n",
      "Starting Epoch 68\n",
      "0.7935937383900518\n",
      "Starting Epoch 69\n",
      "0.797304542168327\n",
      "New best model found at epoch 69 with validation loss 0.7486483454704285\n",
      "Starting Epoch 70\n",
      "0.7918360855268396\n",
      "Starting Epoch 71\n",
      "0.7979850198911584\n",
      "Starting Epoch 72\n",
      "0.7924065253008967\n",
      "New best model found at epoch 72 with validation loss 0.7486367225646973\n",
      "Starting Epoch 73\n",
      "0.7905167807703433\n",
      "Starting Epoch 74\n",
      "0.7887282682501752\n",
      "Starting Epoch 75\n",
      "0.7904068153837452\n",
      "New best model found at epoch 75 with validation loss 0.7460013628005981\n",
      "Starting Epoch 76\n",
      "0.7885979388071143\n",
      "New best model found at epoch 76 with validation loss 0.7437868118286133\n",
      "Starting Epoch 77\n",
      "0.7906748756118442\n",
      "Starting Epoch 78\n",
      "0.7880673615828805\n",
      "New best model found at epoch 78 with validation loss 0.7409182190895081\n",
      "Starting Epoch 79\n",
      "0.7897007465362549\n",
      "New best model found at epoch 79 with validation loss 0.7404121160507202\n",
      "Starting Epoch 80\n",
      "0.7878019317336704\n",
      "Starting Epoch 81\n",
      "0.7859331524890402\n",
      "New best model found at epoch 81 with validation loss 0.7394335865974426\n",
      "Starting Epoch 82\n",
      "0.785086681013522\n",
      "Starting Epoch 83\n",
      "0.785423263259556\n",
      "New best model found at epoch 83 with validation loss 0.7392518520355225\n",
      "Starting Epoch 84\n",
      "0.7829566312872845\n",
      "Starting Epoch 85\n",
      "0.7861102404801742\n",
      "Starting Epoch 86\n",
      "0.7834799289703369\n",
      "New best model found at epoch 86 with validation loss 0.736987829208374\n",
      "Starting Epoch 87\n",
      "0.7844676142153533\n",
      "New best model found at epoch 87 with validation loss 0.7356519103050232\n",
      "Starting Epoch 88\n",
      "0.7837279983188795\n",
      "New best model found at epoch 88 with validation loss 0.7349283695220947\n",
      "Starting Epoch 89\n",
      "0.7852249119592749\n",
      "Starting Epoch 90\n",
      "0.7817198115846385\n",
      "Starting Epoch 91\n",
      "0.7800657515940459\n",
      "Starting Epoch 92\n",
      "0.7805860353552777\n",
      "Starting Epoch 93\n",
      "0.7785231807957524\n",
      "Starting Epoch 94\n",
      "0.7800098657608032\n",
      "New best model found at epoch 94 with validation loss 0.7311887145042419\n",
      "Starting Epoch 95\n",
      "0.7785788593084916\n",
      "New best model found at epoch 95 with validation loss 0.7308102250099182\n",
      "Starting Epoch 96\n",
      "0.775692571764407\n",
      "New best model found at epoch 96 with validation loss 0.7298057675361633\n",
      "Starting Epoch 97\n",
      "0.7761838073315828\n",
      "Starting Epoch 98\n",
      "0.7780149812283723\n",
      "New best model found at epoch 98 with validation loss 0.7283473610877991\n",
      "Starting Epoch 99\n",
      "0.7774120802464692\n",
      "Starting Epoch 100\n",
      "0.7758946055951326\n",
      "Starting Epoch 101\n",
      "0.7778985889061637\n",
      "New best model found at epoch 101 with validation loss 0.7281926870346069\n",
      "Starting Epoch 102\n",
      "0.7745596870132114\n",
      "New best model found at epoch 102 with validation loss 0.7263845205307007\n",
      "Starting Epoch 103\n",
      "0.7733242926390275\n",
      "New best model found at epoch 103 with validation loss 0.7253839373588562\n",
      "Starting Epoch 104\n",
      "0.7722517692524454\n",
      "Starting Epoch 105\n",
      "0.7766392101412234\n",
      "Starting Epoch 106\n",
      "0.7735812793607297\n",
      "New best model found at epoch 106 with validation loss 0.7235569953918457\n",
      "Starting Epoch 107\n",
      "0.7725434769754824\n",
      "Starting Epoch 108\n",
      "0.7716402955677198\n",
      "New best model found at epoch 108 with validation loss 0.7231539487838745\n",
      "Starting Epoch 109\n",
      "0.7715136201485343\n",
      "Starting Epoch 110\n",
      "0.7726532765056776\n",
      "New best model found at epoch 110 with validation loss 0.7215312719345093\n",
      "Starting Epoch 111\n",
      "0.769149370815443\n",
      "Starting Epoch 112\n",
      "0.7717182169789853\n",
      "Starting Epoch 113\n",
      "0.7700679587281268\n",
      "Starting Epoch 114\n",
      "0.7692051685374716\n",
      "New best model found at epoch 114 with validation loss 0.7204601764678955\n",
      "Starting Epoch 115\n",
      "0.7686625356259553\n",
      "Starting Epoch 116\n",
      "0.7695499451264091\n",
      "Starting Epoch 117\n",
      "0.767952983794005\n",
      "Starting Epoch 118\n",
      "0.7704243841378585\n",
      "Starting Epoch 119\n",
      "0.7665539280227993\n",
      "New best model found at epoch 119 with validation loss 0.7185260057449341\n",
      "Starting Epoch 120\n",
      "0.7677855802618939\n",
      "New best model found at epoch 120 with validation loss 0.7169144749641418\n",
      "Starting Epoch 121\n",
      "0.766450135604195\n",
      "New best model found at epoch 121 with validation loss 0.7163922190666199\n",
      "Starting Epoch 122\n",
      "0.76585839105689\n",
      "Starting Epoch 123\n",
      "0.7642630856970082\n",
      "Starting Epoch 124\n",
      "0.7645695209503174\n",
      "Starting Epoch 125\n",
      "0.7639055485310762\n",
      "New best model found at epoch 125 with validation loss 0.7156850695610046\n",
      "Starting Epoch 126\n",
      "0.7663149678188822\n",
      "Starting Epoch 127\n",
      "0.7633539567822996\n",
      "Starting Epoch 128\n",
      "0.7656756043434143\n",
      "New best model found at epoch 128 with validation loss 0.713854968547821\n",
      "Starting Epoch 129\n",
      "0.7683206045109293\n",
      "Starting Epoch 130\n",
      "0.7628991189210311\n",
      "New best model found at epoch 130 with validation loss 0.7127782702445984\n",
      "Starting Epoch 131\n",
      "0.7633606480515521\n",
      "Starting Epoch 132\n",
      "0.7631857343341993\n",
      "Starting Epoch 133\n",
      "0.7630499394043632\n",
      "New best model found at epoch 133 with validation loss 0.7124438285827637\n",
      "Starting Epoch 134\n",
      "0.7603538554647694\n",
      "New best model found at epoch 134 with validation loss 0.7113086581230164\n",
      "Starting Epoch 135\n",
      "0.7608130807461946\n",
      "Starting Epoch 136\n",
      "0.7605391922204391\n",
      "New best model found at epoch 136 with validation loss 0.7097058296203613\n",
      "Starting Epoch 137\n",
      "0.7636442469513934\n",
      "Starting Epoch 138\n",
      "0.7620148684667505\n",
      "Starting Epoch 139\n",
      "0.7580102682113647\n",
      "New best model found at epoch 139 with validation loss 0.7094079852104187\n",
      "Starting Epoch 140\n",
      "0.7601382032684658\n",
      "Starting Epoch 141\n",
      "0.7595635626627051\n",
      "Starting Epoch 142\n",
      "0.7587280299352563\n",
      "New best model found at epoch 142 with validation loss 0.7071444392204285\n",
      "Starting Epoch 143\n",
      "0.75984453636667\n",
      "Starting Epoch 144\n",
      "0.758894435737444\n",
      "Starting Epoch 145\n",
      "0.7566738076831984\n",
      "Starting Epoch 146\n",
      "0.7588574057040007\n",
      "Starting Epoch 147\n",
      "0.7569110471269359\n",
      "New best model found at epoch 147 with validation loss 0.707076370716095\n",
      "Starting Epoch 148\n",
      "0.7568908877994703\n",
      "New best model found at epoch 148 with validation loss 0.7061380743980408\n",
      "Starting Epoch 149\n",
      "0.756028722161832\n",
      "New best model found at epoch 149 with validation loss 0.7053045630455017\n",
      "Starting Epoch 150\n",
      "0.7542611464210178\n",
      "Starting Epoch 151\n",
      "0.7552829592124276\n",
      "Starting Epoch 152\n",
      "0.7555606676184613\n",
      "Starting Epoch 153\n",
      "0.756548417651135\n",
      "New best model found at epoch 153 with validation loss 0.7043736577033997\n",
      "Starting Epoch 154\n",
      "0.7547233700752258\n",
      "Starting Epoch 155\n",
      "0.7548677325248718\n",
      "Starting Epoch 156\n",
      "0.7566278810086458\n",
      "Starting Epoch 157\n",
      "0.7554316468860792\n",
      "Starting Epoch 158\n",
      "0.7565559148788452\n",
      "Starting Epoch 159\n",
      "0.7534285498702008\n",
      "Starting Epoch 160\n",
      "0.7541011131328085\n",
      "Starting Epoch 161\n",
      "0.7547576401544653\n",
      "New best model found at epoch 161 with validation loss 0.7018447518348694\n",
      "Starting Epoch 162\n",
      "0.7539746916812399\n",
      "New best model found at epoch 162 with validation loss 0.7010225057601929\n",
      "Starting Epoch 163\n",
      "0.7539766819580741\n",
      "Starting Epoch 164\n",
      "0.7545122970705447\n",
      "Starting Epoch 165\n",
      "0.7531382726586383\n",
      "Starting Epoch 166\n",
      "0.752815886684086\n",
      "New best model found at epoch 166 with validation loss 0.7004979252815247\n",
      "Starting Epoch 167\n",
      "0.7528103538181471\n",
      "Starting Epoch 168\n",
      "0.7548194087069967\n",
      "Starting Epoch 169\n",
      "0.7516842536304308\n",
      "Starting Epoch 170\n",
      "0.7523031027420707\n",
      "Starting Epoch 171\n",
      "0.7532418007436006\n",
      "New best model found at epoch 171 with validation loss 0.6995638608932495\n",
      "Starting Epoch 172\n",
      "0.7550273978191874\n",
      "Starting Epoch 173\n",
      "0.7534950893858204\n",
      "Starting Epoch 174\n",
      "0.7504905358604763\n",
      "Starting Epoch 175\n",
      "0.7499506706776826\n",
      "New best model found at epoch 175 with validation loss 0.6992501020431519\n",
      "Starting Epoch 176\n",
      "0.7515732827393905\n",
      "Starting Epoch 177\n",
      "0.7517518945362257\n",
      "New best model found at epoch 177 with validation loss 0.6985535025596619\n",
      "Starting Epoch 178\n",
      "0.7503821383351865\n",
      "New best model found at epoch 178 with validation loss 0.6981357336044312\n",
      "Starting Epoch 179\n",
      "0.7501185847365338\n",
      "Starting Epoch 180\n",
      "0.7500926618990691\n",
      "New best model found at epoch 180 with validation loss 0.6973847150802612\n",
      "Starting Epoch 181\n",
      "0.750306935414024\n",
      "Starting Epoch 182\n",
      "0.7501518881839254\n",
      "New best model found at epoch 182 with validation loss 0.6964486241340637\n",
      "Starting Epoch 183\n",
      "0.7498714509217635\n",
      "Starting Epoch 184\n",
      "0.748802680036296\n",
      "Starting Epoch 185\n",
      "0.7508942951326785\n",
      "Starting Epoch 186\n",
      "0.7505326348802318\n",
      "New best model found at epoch 186 with validation loss 0.6958662271499634\n",
      "Starting Epoch 187\n",
      "0.7523249465486278\n",
      "Starting Epoch 188\n",
      "0.7514869052430858\n",
      "Starting Epoch 189\n",
      "0.7490490571312283\n",
      "New best model found at epoch 189 with validation loss 0.6950468420982361\n",
      "Starting Epoch 190\n",
      "0.748292088508606\n",
      "Starting Epoch 191\n",
      "0.750046237655308\n",
      "New best model found at epoch 191 with validation loss 0.6947248578071594\n",
      "Starting Epoch 192\n",
      "0.7482304573059082\n",
      "Starting Epoch 193\n",
      "0.7487180440322213\n",
      "Starting Epoch 194\n",
      "0.7502129051996314\n",
      "Starting Epoch 195\n",
      "0.7481342346771903\n",
      "Starting Epoch 196\n",
      "0.7470257774643276\n",
      "New best model found at epoch 196 with validation loss 0.6938741207122803\n",
      "Starting Epoch 197\n",
      "0.7476426492566648\n",
      "Starting Epoch 198\n",
      "0.7463476320971614\n",
      "Starting Epoch 199\n",
      "0.747246511604475\n",
      "New best model found at epoch 199 with validation loss 0.6930630803108215\n",
      "Starting Epoch 200\n",
      "0.7473364679709725\n",
      "New best model found at epoch 200 with validation loss 0.692611813545227\n",
      "Starting Epoch 201\n",
      "0.7476045385650967\n",
      "Starting Epoch 202\n",
      "0.7450585909511732\n",
      "Starting Epoch 203\n",
      "0.7461255063181338\n",
      "Starting Epoch 204\n",
      "0.7440200266630753\n",
      "Starting Epoch 205\n",
      "0.7459565971208655\n",
      "New best model found at epoch 205 with validation loss 0.6917539238929749\n",
      "Starting Epoch 206\n",
      "0.7451688336289447\n",
      "Starting Epoch 207\n",
      "0.7455724322277567\n",
      "Starting Epoch 208\n",
      "0.7470019718875056\n",
      "New best model found at epoch 208 with validation loss 0.6911696195602417\n",
      "Starting Epoch 209\n",
      "0.7468803058499875\n",
      "Starting Epoch 210\n",
      "0.7458445377971815\n",
      "Starting Epoch 211\n",
      "0.742644525092581\n",
      "Starting Epoch 212\n",
      "0.742427823336228\n",
      "Starting Epoch 213\n",
      "0.7437583156253981\n",
      "New best model found at epoch 213 with validation loss 0.6909406185150146\n",
      "Starting Epoch 214\n",
      "0.7432529278423475\n",
      "Starting Epoch 215\n",
      "0.744388997554779\n",
      "Starting Epoch 216\n",
      "0.7434219588404116\n",
      "New best model found at epoch 216 with validation loss 0.6894727349281311\n",
      "Starting Epoch 217\n",
      "0.7429308580315631\n",
      "Starting Epoch 218\n",
      "0.7428314504416093\n",
      "Starting Epoch 219\n",
      "0.7421092261438784\n",
      "Starting Epoch 220\n",
      "0.7439646928206735\n",
      "Starting Epoch 221\n",
      "0.7406030660090239\n",
      "Starting Epoch 222\n",
      "0.7433433999185977\n",
      "Starting Epoch 223\n",
      "0.7410143769305685\n",
      "Starting Epoch 224\n",
      "0.743974646796351\n",
      "Starting Epoch 225\n",
      "0.7418633543926737\n",
      "Starting Epoch 226\n",
      "0.7435808440913325\n",
      "Starting Epoch 227\n",
      "0.7423887589703435\n",
      "New best model found at epoch 227 with validation loss 0.6888681054115295\n",
      "Starting Epoch 228\n",
      "0.7404825739238573\n",
      "Starting Epoch 229\n",
      "0.7403024331383083\n",
      "Starting Epoch 230\n",
      "0.742344213568646\n",
      "Starting Epoch 231\n",
      "0.7399076067883036\n",
      "Starting Epoch 232\n",
      "0.7412905407988507\n",
      "Starting Epoch 233\n",
      "0.7406998924587084\n",
      "Starting Epoch 234\n",
      "0.7419015402379243\n",
      "New best model found at epoch 234 with validation loss 0.6883577704429626\n",
      "Starting Epoch 235\n",
      "0.7400604952936587\n",
      "Starting Epoch 236\n",
      "0.7407815948776577\n",
      "Starting Epoch 237\n",
      "0.7411556140236233\n",
      "New best model found at epoch 237 with validation loss 0.6874831914901733\n",
      "Starting Epoch 238\n",
      "0.7416235338086667\n",
      "New best model found at epoch 238 with validation loss 0.686704158782959\n",
      "Starting Epoch 239\n",
      "0.7410387604132943\n",
      "Starting Epoch 240\n",
      "0.7415209568065145\n",
      "Starting Epoch 241\n",
      "0.7404826076134391\n",
      "Starting Epoch 242\n",
      "0.7402154336804929\n",
      "Starting Epoch 243\n",
      "0.7402923444043035\n",
      "Starting Epoch 244\n",
      "0.7415285758350206\n",
      "Starting Epoch 245\n",
      "0.739245575407277\n",
      "Starting Epoch 246\n",
      "0.7394423666207687\n",
      "Starting Epoch 247\n",
      "0.739493841710298\n",
      "Starting Epoch 248\n",
      "0.7387938940006754\n",
      "Starting Epoch 249\n",
      "0.7386656144390935\n",
      "Starting Epoch 250\n",
      "0.7390434897464254\n",
      "Starting Epoch 251\n",
      "0.7372802832852239\n",
      "Starting Epoch 252\n",
      "0.7384099131045134\n",
      "Starting Epoch 253\n",
      "0.738904709401338\n",
      "Starting Epoch 254\n",
      "0.7385577196660249\n",
      "Starting Epoch 255\n",
      "0.7388430807901465\n",
      "Starting Epoch 256\n",
      "0.7394993201546047\n",
      "New best model found at epoch 256 with validation loss 0.6860516667366028\n",
      "Starting Epoch 257\n",
      "0.7395663209583448\n",
      "Starting Epoch 258\n",
      "0.7368892457174219\n",
      "Starting Epoch 259\n",
      "0.7419415867846945\n",
      "Starting Epoch 260\n",
      "0.7386164431986602\n",
      "New best model found at epoch 260 with validation loss 0.6850736141204834\n",
      "Starting Epoch 261\n",
      "0.7380163773246433\n",
      "Starting Epoch 262\n",
      "0.7365209486173547\n",
      "Starting Epoch 263\n",
      "0.7360839947410251\n",
      "Starting Epoch 264\n",
      "0.7396510269330896\n",
      "Starting Epoch 265\n",
      "0.7367984937584918\n",
      "Starting Epoch 266\n",
      "0.7406471345735632\n",
      "Starting Epoch 267\n",
      "0.7374071375183437\n",
      "New best model found at epoch 267 with validation loss 0.6849148273468018\n",
      "Starting Epoch 268\n",
      "0.7376423452211462\n",
      "Starting Epoch 269\n",
      "0.7375595621440721\n",
      "Starting Epoch 270\n",
      "0.7371103737665259\n",
      "New best model found at epoch 270 with validation loss 0.6842784285545349\n",
      "Starting Epoch 271\n",
      "0.7362616217654684\n",
      "Starting Epoch 272\n",
      "0.7371020006096881\n",
      "Starting Epoch 273\n",
      "0.7377995615420134\n",
      "Starting Epoch 274\n",
      "0.7363704261572465\n",
      "Starting Epoch 275\n",
      "0.7367446189341338\n",
      "Starting Epoch 276\n",
      "0.7352133341457533\n",
      "Starting Epoch 277\n",
      "0.7337151014286539\n",
      "Starting Epoch 278\n",
      "0.7374383444371431\n",
      "Starting Epoch 279\n",
      "0.73535541606986\n",
      "Starting Epoch 280\n",
      "0.7377023282258407\n",
      "Starting Epoch 281\n",
      "0.7346174146818079\n",
      "Starting Epoch 282\n",
      "0.741125086079473\n",
      "New best model found at epoch 282 with validation loss 0.6840940117835999\n",
      "Starting Epoch 283\n",
      "0.7358304910037828\n",
      "New best model found at epoch 283 with validation loss 0.6837373971939087\n",
      "Starting Epoch 284\n",
      "0.7352244206096815\n",
      "Starting Epoch 285\n",
      "0.7370158641234689\n",
      "Starting Epoch 286\n",
      "0.7369523281636445\n",
      "Starting Epoch 287\n",
      "0.7366086348243381\n",
      "Starting Epoch 288\n",
      "0.7338758914367013\n",
      "Starting Epoch 289\n",
      "0.7348979685617529\n",
      "New best model found at epoch 289 with validation loss 0.6837345957756042\n",
      "Starting Epoch 290\n",
      "0.7350451505702474\n",
      "New best model found at epoch 290 with validation loss 0.6833261251449585\n",
      "Starting Epoch 291\n",
      "0.7345104969066122\n",
      "Starting Epoch 292\n",
      "0.7349126960920251\n",
      "Starting Epoch 293\n",
      "0.7341150123140087\n",
      "Starting Epoch 294\n",
      "0.735137491122536\n",
      "Starting Epoch 295\n",
      "0.7366113740464916\n",
      "Starting Epoch 296\n",
      "0.7334709763526917\n",
      "Starting Epoch 297\n",
      "0.733851829300756\n",
      "Starting Epoch 298\n",
      "0.7342395186424255\n",
      "Starting Epoch 299\n",
      "0.7371844001438307\n",
      "New best model found at epoch 299 with validation loss 0.6827274560928345\n",
      "Starting Epoch 300\n",
      "0.7340902530628702\n",
      "New best model found at epoch 300 with validation loss 0.6823496222496033\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d650c13e-1701-4bcb-a606-546b44860d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.1160445679789004\n",
      "New best model found at epoch 1 with validation loss 1.0515750646591187\n",
      "Starting Epoch 2\n",
      "1.042870739231939\n",
      "New best model found at epoch 2 with validation loss 1.0467066764831543\n",
      "Starting Epoch 3\n",
      "1.035680742367454\n",
      "New best model found at epoch 3 with validation loss 1.0438190698623657\n",
      "Starting Epoch 4\n",
      "1.025761244089707\n",
      "New best model found at epoch 4 with validation loss 1.0376582145690918\n",
      "Starting Epoch 5\n",
      "1.0240480251934216\n",
      "Starting Epoch 6\n",
      "1.0151919903962507\n",
      "New best model found at epoch 6 with validation loss 1.0343716144561768\n",
      "Starting Epoch 7\n",
      "1.0060183354046033\n",
      "New best model found at epoch 7 with validation loss 1.03213369846344\n",
      "Starting Epoch 8\n",
      "1.006558949532716\n",
      "New best model found at epoch 8 with validation loss 1.0228217840194702\n",
      "Starting Epoch 9\n",
      "1.0000501223232434\n",
      "New best model found at epoch 9 with validation loss 1.0216368436813354\n",
      "Starting Epoch 10\n",
      "0.993754998497341\n",
      "New best model found at epoch 10 with validation loss 1.0092005729675293\n",
      "Starting Epoch 11\n",
      "0.9894676726797352\n",
      "New best model found at epoch 11 with validation loss 1.003165364265442\n",
      "Starting Epoch 12\n",
      "0.9804712067479673\n",
      "New best model found at epoch 12 with validation loss 0.9957248568534851\n",
      "Starting Epoch 13\n",
      "0.9788102274355681\n",
      "New best model found at epoch 13 with validation loss 0.9930757880210876\n",
      "Starting Epoch 14\n",
      "0.9740367842757184\n",
      "Starting Epoch 15\n",
      "0.9728868733281675\n",
      "New best model found at epoch 15 with validation loss 0.9911466240882874\n",
      "Starting Epoch 16\n",
      "0.963030351244885\n",
      "New best model found at epoch 16 with validation loss 0.987840473651886\n",
      "Starting Epoch 17\n",
      "0.9632068820621656\n",
      "Starting Epoch 18\n",
      "0.9643371105194092\n",
      "New best model found at epoch 18 with validation loss 0.9772290587425232\n",
      "Starting Epoch 19\n",
      "0.9586369706236798\n",
      "Starting Epoch 20\n",
      "0.9581004510755124\n",
      "New best model found at epoch 20 with validation loss 0.9746759533882141\n",
      "Starting Epoch 21\n",
      "0.9547257967617201\n",
      "New best model found at epoch 21 with validation loss 0.9690037369728088\n",
      "Starting Epoch 22\n",
      "0.9459028632744498\n",
      "Starting Epoch 23\n",
      "0.9476977120275083\n",
      "Starting Epoch 24\n",
      "0.9492601467215497\n",
      "New best model found at epoch 24 with validation loss 0.9626143574714661\n",
      "Starting Epoch 25\n",
      "0.9422301598217176\n",
      "Starting Epoch 26\n",
      "0.9385762318320896\n",
      "Starting Epoch 27\n",
      "0.940441590288411\n",
      "New best model found at epoch 27 with validation loss 0.9582459926605225\n",
      "Starting Epoch 28\n",
      "0.9414811471234197\n",
      "Starting Epoch 29\n",
      "0.934157845766648\n",
      "Starting Epoch 30\n",
      "0.9430436673371688\n",
      "New best model found at epoch 30 with validation loss 0.9534648656845093\n",
      "Starting Epoch 31\n",
      "0.9454429875249448\n",
      "Starting Epoch 32\n",
      "0.9395146525424459\n",
      "New best model found at epoch 32 with validation loss 0.9500442147254944\n",
      "Starting Epoch 33\n",
      "0.9370740341103595\n",
      "New best model found at epoch 33 with validation loss 0.9461453557014465\n",
      "Starting Epoch 34\n",
      "0.930783924849137\n",
      "Starting Epoch 35\n",
      "0.9335871494334677\n",
      "New best model found at epoch 35 with validation loss 0.9449569582939148\n",
      "Starting Epoch 36\n",
      "0.929537656514541\n",
      "New best model found at epoch 36 with validation loss 0.9441041946411133\n",
      "Starting Epoch 37\n",
      "0.9245792912400287\n",
      "New best model found at epoch 37 with validation loss 0.9433081746101379\n",
      "Starting Epoch 38\n",
      "0.930623489877452\n",
      "New best model found at epoch 38 with validation loss 0.9413005113601685\n",
      "Starting Epoch 39\n",
      "0.938129723072052\n",
      "Starting Epoch 40\n",
      "0.9247471897498422\n",
      "Starting Epoch 41\n",
      "0.9301688100980676\n",
      "Starting Epoch 42\n",
      "0.9296094930690267\n",
      "Starting Epoch 43\n",
      "0.9221767290778782\n",
      "New best model found at epoch 43 with validation loss 0.9388362765312195\n",
      "Starting Epoch 44\n",
      "0.9241205764853436\n",
      "Starting Epoch 45\n",
      "0.9233656784762507\n",
      "Starting Epoch 46\n",
      "0.9251700458319291\n",
      "New best model found at epoch 46 with validation loss 0.938362181186676\n",
      "Starting Epoch 47\n",
      "0.9193271268968997\n",
      "Starting Epoch 48\n",
      "0.9246221728946852\n",
      "Starting Epoch 49\n",
      "0.9209790126137112\n",
      "Starting Epoch 50\n",
      "0.9216529856557432\n",
      "New best model found at epoch 50 with validation loss 0.9349347352981567\n",
      "Starting Epoch 51\n",
      "0.9216009741244109\n",
      "Starting Epoch 52\n",
      "0.9154515940210094\n",
      "Starting Epoch 53\n",
      "0.9186588137046151\n",
      "Starting Epoch 54\n",
      "0.9156618921653085\n",
      "Starting Epoch 55\n",
      "0.9204805182374042\n",
      "New best model found at epoch 55 with validation loss 0.9348494410514832\n",
      "Starting Epoch 56\n",
      "0.9193110284597977\n",
      "Starting Epoch 57\n",
      "0.9176171784815581\n",
      "New best model found at epoch 57 with validation loss 0.9336277842521667\n",
      "Starting Epoch 58\n",
      "0.9141289462213931\n",
      "Starting Epoch 59\n",
      "0.9189006193824436\n",
      "New best model found at epoch 59 with validation loss 0.9321107864379883\n",
      "Starting Epoch 60\n",
      "0.9134974686995797\n",
      "Starting Epoch 61\n",
      "0.9141324317973593\n",
      "Starting Epoch 62\n",
      "0.9139421919117803\n",
      "New best model found at epoch 62 with validation loss 0.9318599104881287\n",
      "Starting Epoch 63\n",
      "0.911727337733559\n",
      "Starting Epoch 64\n",
      "0.9114439487457275\n",
      "Starting Epoch 65\n",
      "0.9163242086120273\n",
      "New best model found at epoch 65 with validation loss 0.9310781955718994\n",
      "Starting Epoch 66\n",
      "0.912471232206925\n",
      "Starting Epoch 67\n",
      "0.9151818933694259\n",
      "Starting Epoch 68\n",
      "0.9080583945564602\n",
      "Starting Epoch 69\n",
      "0.9081701765889707\n",
      "New best model found at epoch 69 with validation loss 0.9301530718803406\n",
      "Starting Epoch 70\n",
      "0.9117509152578271\n",
      "Starting Epoch 71\n",
      "0.9088979467101719\n",
      "Starting Epoch 72\n",
      "0.9087083754332169\n",
      "New best model found at epoch 72 with validation loss 0.9288276433944702\n",
      "Starting Epoch 73\n",
      "0.9094181294026582\n",
      "Starting Epoch 74\n",
      "0.909141587174457\n",
      "Starting Epoch 75\n",
      "0.9135498352672743\n",
      "New best model found at epoch 75 with validation loss 0.9283093810081482\n",
      "Starting Epoch 76\n",
      "0.9083868446557418\n",
      "Starting Epoch 77\n",
      "0.9149842599163884\n",
      "Starting Epoch 78\n",
      "0.9067403129909349\n",
      "New best model found at epoch 78 with validation loss 0.9280285835266113\n",
      "Starting Epoch 79\n",
      "0.9098688649094623\n",
      "Starting Epoch 80\n",
      "0.907908786898074\n",
      "Starting Epoch 81\n",
      "0.9075764935949574\n",
      "Starting Epoch 82\n",
      "0.9158238483511884\n",
      "Starting Epoch 83\n",
      "0.9100839443828749\n",
      "Starting Epoch 84\n",
      "0.906676129154537\n",
      "Starting Epoch 85\n",
      "0.904661880887073\n",
      "Starting Epoch 86\n",
      "0.9053950724394425\n",
      "Starting Epoch 87\n",
      "0.909652697003406\n",
      "New best model found at epoch 87 with validation loss 0.9254109859466553\n",
      "Starting Epoch 88\n",
      "0.9039536351742952\n",
      "Starting Epoch 89\n",
      "0.9092690944671631\n",
      "Starting Epoch 90\n",
      "0.9089108031728993\n",
      "Starting Epoch 91\n",
      "0.9059516217397607\n",
      "Starting Epoch 92\n",
      "0.9048932531605596\n",
      "Starting Epoch 93\n",
      "0.9052165435708087\n",
      "Starting Epoch 94\n",
      "0.9044615963230962\n",
      "Starting Epoch 95\n",
      "0.9053022213604139\n",
      "Starting Epoch 96\n",
      "0.9038259542506674\n",
      "Starting Epoch 97\n",
      "0.900546159433282\n",
      "Starting Epoch 98\n",
      "0.9080015161763066\n",
      "Starting Epoch 99\n",
      "0.9053383676902108\n",
      "Starting Epoch 100\n",
      "0.903899477875751\n",
      "Starting Epoch 101\n",
      "0.902622666047967\n",
      "Starting Epoch 102\n",
      "0.9032335048136504\n",
      "Starting Epoch 103\n",
      "0.9048090810361116\n",
      "Starting Epoch 104\n",
      "0.9027559990468232\n",
      "Starting Epoch 105\n",
      "0.9029229309247888\n",
      "Starting Epoch 106\n",
      "0.9032826890116152\n",
      "Starting Epoch 107\n",
      "0.904443092968153\n",
      "Starting Epoch 108\n",
      "0.8980617056722227\n",
      "Starting Epoch 109\n",
      "0.8992100746735282\n",
      "Starting Epoch 110\n",
      "0.8964177992032922\n",
      "Starting Epoch 111\n",
      "0.9033097521118496\n",
      "Starting Epoch 112\n",
      "0.9057377369507499\n",
      "Starting Epoch 113\n",
      "0.8973748606184254\n",
      "Starting Epoch 114\n",
      "0.9033890496129575\n",
      "Starting Epoch 115\n",
      "0.9009568017462025\n",
      "Starting Epoch 116\n",
      "0.8993285091026969\n",
      "Starting Epoch 117\n",
      "0.8986208983089613\n",
      "Starting Epoch 118\n",
      "0.899590904298036\n",
      "Starting Epoch 119\n",
      "0.8977429115253946\n",
      "Starting Epoch 120\n",
      "0.8981309559034265\n",
      "Starting Epoch 121\n",
      "0.902574114177538\n",
      "New best model found at epoch 121 with validation loss 0.9247304201126099\n",
      "Starting Epoch 122\n",
      "0.9036168533822765\n",
      "Starting Epoch 123\n",
      "0.8995699623356694\n",
      "Starting Epoch 124\n",
      "0.8968006787092789\n",
      "Starting Epoch 125\n",
      "0.8964496462241464\n",
      "Starting Epoch 126\n",
      "0.8983879167100658\n",
      "Starting Epoch 127\n",
      "0.8953308152115863\n",
      "Starting Epoch 128\n",
      "0.8974409310714059\n",
      "Starting Epoch 129\n",
      "0.8999484025913737\n",
      "Starting Epoch 130\n",
      "0.8995165254758752\n",
      "Starting Epoch 131\n",
      "0.9012363838112872\n",
      "New best model found at epoch 131 with validation loss 0.924330472946167\n",
      "Starting Epoch 132\n",
      "0.8981672007104625\n",
      "New best model found at epoch 132 with validation loss 0.9231522679328918\n",
      "Starting Epoch 133\n",
      "0.9007060735122018\n",
      "Starting Epoch 134\n",
      "0.8981449500374172\n",
      "New best model found at epoch 134 with validation loss 0.9230775833129883\n",
      "Starting Epoch 135\n",
      "0.8992258491723434\n",
      "Starting Epoch 136\n",
      "0.8998065487198208\n",
      "Starting Epoch 137\n",
      "0.9001524940780972\n",
      "Starting Epoch 138\n",
      "0.900290001993594\n",
      "Starting Epoch 139\n",
      "0.8985409995783931\n",
      "Starting Epoch 140\n",
      "0.8976381965305494\n",
      "Starting Epoch 141\n",
      "0.8943762727405714\n",
      "Starting Epoch 142\n",
      "0.8986586721047111\n",
      "New best model found at epoch 142 with validation loss 0.9228325486183167\n",
      "Starting Epoch 143\n",
      "0.8959707825080209\n",
      "Starting Epoch 144\n",
      "0.8961994388829106\n",
      "Starting Epoch 145\n",
      "0.894362967947255\n",
      "Starting Epoch 146\n",
      "0.8957546171934708\n",
      "Starting Epoch 147\n",
      "0.8954922816027766\n",
      "New best model found at epoch 147 with validation loss 0.9224533438682556\n",
      "Starting Epoch 148\n",
      "0.8933547683384108\n",
      "Starting Epoch 149\n",
      "0.8957898746366086\n",
      "Starting Epoch 150\n",
      "0.8965014037878617\n",
      "Starting Epoch 151\n",
      "0.8956706523895264\n",
      "Starting Epoch 152\n",
      "0.8978594386059305\n",
      "Starting Epoch 153\n",
      "0.89677436714587\n",
      "Starting Epoch 154\n",
      "0.8941359779109126\n",
      "Starting Epoch 155\n",
      "0.8933406342630801\n",
      "Starting Epoch 156\n",
      "0.8978662620420041\n",
      "Starting Epoch 157\n",
      "0.8992603058400361\n",
      "Starting Epoch 158\n",
      "0.8998489068902057\n",
      "Starting Epoch 159\n",
      "0.8953025107798369\n",
      "Starting Epoch 160\n",
      "0.8957628115363743\n",
      "Starting Epoch 161\n",
      "0.8944206756094227\n",
      "Starting Epoch 162\n",
      "0.8935478485148886\n",
      "New best model found at epoch 162 with validation loss 0.9216892123222351\n",
      "Starting Epoch 163\n",
      "0.8949529554532922\n",
      "Starting Epoch 164\n",
      "0.8950248127398284\n",
      "Starting Epoch 165\n",
      "0.8941217116687609\n",
      "Starting Epoch 166\n",
      "0.8974633942479673\n",
      "Starting Epoch 167\n",
      "0.8968392662380053\n",
      "Starting Epoch 168\n",
      "0.8936574174010236\n",
      "Starting Epoch 169\n",
      "0.8983752986659175\n",
      "Starting Epoch 170\n",
      "0.894311389197474\n",
      "Starting Epoch 171\n",
      "0.896800186323083\n",
      "Starting Epoch 172\n",
      "0.8926961162815923\n",
      "Starting Epoch 173\n",
      "0.8920043369998103\n",
      "Starting Epoch 174\n",
      "0.8946805337200994\n",
      "Starting Epoch 175\n",
      "0.896649692369544\n",
      "Starting Epoch 176\n",
      "0.8970064365345499\n",
      "Starting Epoch 177\n",
      "0.8940154676852019\n",
      "Starting Epoch 178\n",
      "0.8927305859068165\n",
      "Starting Epoch 179\n",
      "0.8919204628985861\n",
      "Starting Epoch 180\n",
      "0.8962273234906404\n",
      "Starting Epoch 181\n",
      "0.8926296260045923\n",
      "Starting Epoch 182\n",
      "0.897596678008204\n",
      "Starting Epoch 183\n",
      "0.8932392571283423\n",
      "Starting Epoch 184\n",
      "0.8937927536342455\n",
      "Starting Epoch 185\n",
      "0.8949825582296952\n",
      "Starting Epoch 186\n",
      "0.8944775669471078\n",
      "Starting Epoch 187\n",
      "0.8947732837303825\n",
      "New best model found at epoch 187 with validation loss 0.9216719269752502\n",
      "Starting Epoch 188\n",
      "0.8912143759105516\n",
      "Starting Epoch 189\n",
      "0.8948899352032206\n",
      "New best model found at epoch 189 with validation loss 0.9215388894081116\n",
      "Starting Epoch 190\n",
      "0.8928349173587301\n",
      "Starting Epoch 191\n",
      "0.8954943055691926\n",
      "Starting Epoch 192\n",
      "0.892361184825068\n",
      "Starting Epoch 193\n",
      "0.8912105586217798\n",
      "Starting Epoch 194\n",
      "0.8928785712822623\n",
      "Starting Epoch 195\n",
      "0.8941072536551434\n",
      "New best model found at epoch 195 with validation loss 0.9215167760848999\n",
      "Starting Epoch 196\n",
      "0.8924935356430386\n",
      "Starting Epoch 197\n",
      "0.8938112647637076\n",
      "Starting Epoch 198\n",
      "0.8953029124633126\n",
      "Starting Epoch 199\n",
      "0.8971119911774345\n",
      "Starting Epoch 200\n",
      "0.8916510628617328\n",
      "Starting Epoch 201\n",
      "0.8902953370757725\n",
      "Starting Epoch 202\n",
      "0.8946621288423953\n",
      "Starting Epoch 203\n",
      "0.8929385491039442\n",
      "Starting Epoch 204\n",
      "0.8912470366643823\n",
      "Starting Epoch 205\n",
      "0.8935668598050657\n",
      "Starting Epoch 206\n",
      "0.8931565543879634\n",
      "Starting Epoch 207\n",
      "0.8925842668699182\n",
      "Starting Epoch 208\n",
      "0.8912105016086412\n",
      "Starting Epoch 209\n",
      "0.8933080512544384\n",
      "Starting Epoch 210\n",
      "0.89133285957834\n",
      "Starting Epoch 211\n",
      "0.8918363426042639\n",
      "Starting Epoch 212\n",
      "0.892213787721551\n",
      "New best model found at epoch 212 with validation loss 0.9214869141578674\n",
      "Starting Epoch 213\n",
      "0.8918552424596704\n",
      "Starting Epoch 214\n",
      "0.8906956263210463\n",
      "Starting Epoch 215\n",
      "0.8918500438980435\n",
      "Starting Epoch 216\n",
      "0.8933391260064166\n",
      "Starting Epoch 217\n",
      "0.8930221355479696\n",
      "Starting Epoch 218\n",
      "0.8924529474714528\n",
      "Starting Epoch 219\n",
      "0.8918384857799696\n",
      "Starting Epoch 220\n",
      "0.8914053776989812\n",
      "Starting Epoch 221\n",
      "0.8922231897063877\n",
      "Starting Epoch 222\n",
      "0.892001774000085\n",
      "Starting Epoch 223\n",
      "0.8897106880727021\n",
      "Starting Epoch 224\n",
      "0.8916333628737408\n",
      "Starting Epoch 225\n",
      "0.8924162050952082\n",
      "Starting Epoch 226\n",
      "0.8890799543131953\n",
      "Starting Epoch 227\n",
      "0.8958671144817186\n",
      "Starting Epoch 228\n",
      "0.8908933323362599\n",
      "Starting Epoch 229\n",
      "0.8898259349491285\n",
      "Starting Epoch 230\n",
      "0.8919909674188365\n",
      "Starting Epoch 231\n",
      "0.8904701264008231\n",
      "Starting Epoch 232\n",
      "0.8927237313726674\n",
      "Starting Epoch 233\n",
      "0.8959384327349456\n",
      "Starting Epoch 234\n",
      "0.8899536754774011\n",
      "New best model found at epoch 234 with validation loss 0.9214268326759338\n",
      "Starting Epoch 235\n",
      "0.8903973076654517\n",
      "Starting Epoch 236\n",
      "0.8910914970480878\n",
      "Starting Epoch 237\n",
      "0.8907748408939528\n",
      "Starting Epoch 238\n",
      "0.8912060882734216\n",
      "Starting Epoch 239\n",
      "0.8918381333351135\n",
      "Starting Epoch 240\n",
      "0.88928491913754\n",
      "Starting Epoch 241\n",
      "0.8893509869990142\n",
      "Starting Epoch 242\n",
      "0.8914334177970886\n",
      "Starting Epoch 243\n",
      "0.8909361284712086\n",
      "Starting Epoch 244\n",
      "0.8903974942539049\n",
      "Starting Epoch 245\n",
      "0.8882324825162473\n",
      "Starting Epoch 246\n",
      "0.8907274292862933\n",
      "Starting Epoch 247\n",
      "0.8894300149834674\n",
      "Starting Epoch 248\n",
      "0.8907375802164492\n",
      "Starting Epoch 249\n",
      "0.8916700611943784\n",
      "New best model found at epoch 249 with validation loss 0.9210315942764282\n",
      "Starting Epoch 250\n",
      "0.8900678494702214\n",
      "Starting Epoch 251\n",
      "0.8882901875869088\n",
      "Starting Epoch 252\n",
      "0.8884669931038566\n",
      "Starting Epoch 253\n",
      "0.8887505142585091\n",
      "Starting Epoch 254\n",
      "0.8897441185039022\n",
      "Starting Epoch 255\n",
      "0.8909583402716595\n",
      "New best model found at epoch 255 with validation loss 0.9206777811050415\n",
      "Starting Epoch 256\n",
      "0.8905074959215911\n",
      "Starting Epoch 257\n",
      "0.8903508497321088\n",
      "Starting Epoch 258\n",
      "0.8903515079747075\n",
      "Starting Epoch 259\n",
      "0.8893790296886278\n",
      "Starting Epoch 260\n",
      "0.8906467064567234\n",
      "New best model found at epoch 260 with validation loss 0.9203894734382629\n",
      "Starting Epoch 261\n",
      "0.8874152276826941\n",
      "Starting Epoch 262\n",
      "0.8915300706158513\n",
      "Starting Epoch 263\n",
      "0.8902526653331259\n",
      "Starting Epoch 264\n",
      "0.8911853614060775\n",
      "Starting Epoch 265\n",
      "0.8915785732476608\n",
      "New best model found at epoch 265 with validation loss 0.9199548363685608\n",
      "Starting Epoch 266\n",
      "0.8888197152510934\n",
      "Starting Epoch 267\n",
      "0.8891391780065454\n",
      "New best model found at epoch 267 with validation loss 0.9195902347564697\n",
      "Starting Epoch 268\n",
      "0.8902021594669508\n",
      "Starting Epoch 269\n",
      "0.89142848616061\n",
      "Starting Epoch 270\n",
      "0.8919049656909445\n",
      "Starting Epoch 271\n",
      "0.8888096446576326\n",
      "Starting Epoch 272\n",
      "0.8910386432772097\n",
      "Starting Epoch 273\n",
      "0.8898362465526747\n",
      "Starting Epoch 274\n",
      "0.8903221125188081\n",
      "Starting Epoch 275\n",
      "0.888713028119958\n",
      "Starting Epoch 276\n",
      "0.8889698956323706\n",
      "Starting Epoch 277\n",
      "0.888166580511176\n",
      "Starting Epoch 278\n",
      "0.8919457948726156\n",
      "Starting Epoch 279\n",
      "0.8907301736914593\n",
      "Starting Epoch 280\n",
      "0.8899040688639102\n",
      "Starting Epoch 281\n",
      "0.8880120153012483\n",
      "Starting Epoch 282\n",
      "0.8890732500864111\n",
      "Starting Epoch 283\n",
      "0.8904425087182418\n",
      "Starting Epoch 284\n",
      "0.8891303098720053\n",
      "Starting Epoch 285\n",
      "0.8894667444021805\n",
      "Starting Epoch 286\n",
      "0.8897541191266931\n",
      "Starting Epoch 287\n",
      "0.8912334882694742\n",
      "Starting Epoch 288\n",
      "0.8917427633119666\n",
      "New best model found at epoch 288 with validation loss 0.9193791747093201\n",
      "Starting Epoch 289\n",
      "0.8879530481670214\n",
      "Starting Epoch 290\n",
      "0.8886420156644739\n",
      "Starting Epoch 291\n",
      "0.8869404274484386\n",
      "Starting Epoch 292\n",
      "0.8883441479309745\n",
      "Starting Epoch 293\n",
      "0.8876801392306453\n",
      "Starting Epoch 294\n",
      "0.8901267077611841\n",
      "Starting Epoch 295\n",
      "0.8908049956611965\n",
      "Starting Epoch 296\n",
      "0.888317100379778\n",
      "Starting Epoch 297\n",
      "0.8899555698685024\n",
      "Starting Epoch 298\n",
      "0.889762054318967\n",
      "Starting Epoch 299\n",
      "0.8887423976607944\n",
      "New best model found at epoch 299 with validation loss 0.9186648726463318\n",
      "Starting Epoch 300\n",
      "0.8881142139434814\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6a6db479-b96f-4577-94d5-3342de39c03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.0475071694539941\n",
      "New best model found at epoch 1 with validation loss 1.0088908672332764\n",
      "Starting Epoch 2\n",
      "0.9864318578139596\n",
      "New best model found at epoch 2 with validation loss 0.9905348420143127\n",
      "Starting Epoch 3\n",
      "0.9770547643951748\n",
      "New best model found at epoch 3 with validation loss 0.9899557828903198\n",
      "Starting Epoch 4\n",
      "0.9713569724041483\n",
      "New best model found at epoch 4 with validation loss 0.9859105944633484\n",
      "Starting Epoch 5\n",
      "0.9703140025553496\n",
      "Starting Epoch 6\n",
      "0.9676305185193601\n",
      "Starting Epoch 7\n",
      "0.9648741483688354\n",
      "Starting Epoch 8\n",
      "0.9653819721678029\n",
      "Starting Epoch 9\n",
      "0.9673341253529424\n",
      "Starting Epoch 10\n",
      "0.9651647054630778\n",
      "Starting Epoch 11\n",
      "0.9634823384492294\n",
      "Starting Epoch 12\n",
      "0.9623846774515898\n",
      "Starting Epoch 13\n",
      "0.9624717727951382\n",
      "Starting Epoch 14\n",
      "0.9630246188329614\n",
      "Starting Epoch 15\n",
      "0.9617148015810095\n",
      "Starting Epoch 16\n",
      "0.9628227197605631\n",
      "Starting Epoch 17\n",
      "0.9616746746975443\n",
      "Starting Epoch 18\n",
      "0.9613055897795636\n",
      "Starting Epoch 19\n",
      "0.9605672696362371\n",
      "Starting Epoch 20\n",
      "0.9604453910952029\n",
      "Starting Epoch 21\n",
      "0.9611982495888419\n",
      "Starting Epoch 22\n",
      "0.9592904370764027\n",
      "Starting Epoch 23\n",
      "0.9579747993013134\n",
      "Starting Epoch 24\n",
      "0.9576819798220759\n",
      "Starting Epoch 25\n",
      "0.9608151783113894\n",
      "Starting Epoch 26\n",
      "0.9595750881277997\n",
      "Starting Epoch 27\n",
      "0.9581111021663832\n",
      "Starting Epoch 28\n",
      "0.9591716709344283\n",
      "Starting Epoch 29\n",
      "0.9578985364540763\n",
      "Starting Epoch 30\n",
      "0.9593112935190615\n",
      "Starting Epoch 31\n",
      "0.9592677510302999\n",
      "Starting Epoch 32\n",
      "0.9582881175953409\n",
      "Starting Epoch 33\n",
      "0.9570571572884269\n",
      "Starting Epoch 34\n",
      "0.9579101775003516\n",
      "Starting Epoch 35\n",
      "0.9573414533034615\n",
      "Starting Epoch 36\n",
      "0.9565880557765132\n",
      "Starting Epoch 37\n",
      "0.9562070913936781\n",
      "Starting Epoch 38\n",
      "0.9573220869769221\n",
      "Starting Epoch 39\n",
      "0.9569988509883052\n",
      "Starting Epoch 40\n",
      "0.9567239595496136\n",
      "Starting Epoch 41\n",
      "0.9566590500914532\n",
      "Starting Epoch 42\n",
      "0.9566309452056885\n",
      "Starting Epoch 43\n",
      "0.9558434926945231\n",
      "Starting Epoch 44\n",
      "0.9559185375338015\n",
      "Starting Epoch 45\n",
      "0.9566706133925397\n",
      "Starting Epoch 46\n",
      "0.9566166556399801\n",
      "Starting Epoch 47\n",
      "0.956239420434703\n",
      "Starting Epoch 48\n",
      "0.9549991358881411\n",
      "Starting Epoch 49\n",
      "0.9552055804625802\n",
      "Starting Epoch 50\n",
      "0.9548020958900452\n",
      "New best model found at epoch 50 with validation loss 0.9857805371284485\n",
      "Starting Epoch 51\n",
      "0.9550991939461749\n",
      "New best model found at epoch 51 with validation loss 0.985670804977417\n",
      "Starting Epoch 52\n",
      "0.9551542012587838\n",
      "Starting Epoch 53\n",
      "0.9559637359950853\n",
      "New best model found at epoch 53 with validation loss 0.9855993390083313\n",
      "Starting Epoch 54\n",
      "0.9544567362121914\n",
      "Starting Epoch 55\n",
      "0.9555345384970956\n",
      "New best model found at epoch 55 with validation loss 0.9855980277061462\n",
      "Starting Epoch 56\n",
      "0.9562400916348333\n",
      "New best model found at epoch 56 with validation loss 0.9852145314216614\n",
      "Starting Epoch 57\n",
      "0.9545506161192189\n",
      "Starting Epoch 58\n",
      "0.955237487088079\n",
      "Starting Epoch 59\n",
      "0.9546655649724214\n",
      "Starting Epoch 60\n",
      "0.9554365847421729\n",
      "Starting Epoch 61\n",
      "0.9546817152396493\n",
      "New best model found at epoch 61 with validation loss 0.9851829409599304\n",
      "Starting Epoch 62\n",
      "0.9542095091031946\n",
      "New best model found at epoch 62 with validation loss 0.984796404838562\n",
      "Starting Epoch 63\n",
      "0.9534898063410884\n",
      "Starting Epoch 64\n",
      "0.9535679609879203\n",
      "New best model found at epoch 64 with validation loss 0.9847032427787781\n",
      "Starting Epoch 65\n",
      "0.952709190223528\n",
      "Starting Epoch 66\n",
      "0.9544101564780526\n",
      "Starting Epoch 67\n",
      "0.9532634149427\n",
      "Starting Epoch 68\n",
      "0.9536578732988109\n",
      "New best model found at epoch 68 with validation loss 0.9845719933509827\n",
      "Starting Epoch 69\n",
      "0.9535376299982485\n",
      "Starting Epoch 70\n",
      "0.9526004350703695\n",
      "Starting Epoch 71\n",
      "0.9524156606715658\n",
      "Starting Epoch 72\n",
      "0.9533557658610137\n",
      "New best model found at epoch 72 with validation loss 0.9843215346336365\n",
      "Starting Epoch 73\n",
      "0.9536443508189657\n",
      "Starting Epoch 74\n",
      "0.9529251482175745\n",
      "New best model found at epoch 74 with validation loss 0.9841905236244202\n",
      "Starting Epoch 75\n",
      "0.9517748329950415\n",
      "Starting Epoch 76\n",
      "0.9525347274282704\n",
      "Starting Epoch 77\n",
      "0.9525648148163505\n",
      "Starting Epoch 78\n",
      "0.9524656637855198\n",
      "Starting Epoch 79\n",
      "0.9525299694227136\n",
      "Starting Epoch 80\n",
      "0.9524507418922756\n",
      "Starting Epoch 81\n",
      "0.9528635999430781\n",
      "New best model found at epoch 81 with validation loss 0.9839334487915039\n",
      "Starting Epoch 82\n",
      "0.9527718606202499\n",
      "Starting Epoch 83\n",
      "0.9524585915648419\n",
      "Starting Epoch 84\n",
      "0.9517245966455211\n",
      "Starting Epoch 85\n",
      "0.9527755794317826\n",
      "Starting Epoch 86\n",
      "0.9523573854695195\n",
      "Starting Epoch 87\n",
      "0.9521628618240356\n",
      "Starting Epoch 88\n",
      "0.9529898322146871\n",
      "Starting Epoch 89\n",
      "0.9531539937724238\n",
      "Starting Epoch 90\n",
      "0.9529041570165883\n",
      "Starting Epoch 91\n",
      "0.9522637880366781\n",
      "Starting Epoch 92\n",
      "0.9520302803620048\n",
      "New best model found at epoch 92 with validation loss 0.9835823774337769\n",
      "Starting Epoch 93\n",
      "0.9520200335461161\n",
      "Starting Epoch 94\n",
      "0.9520668439243151\n",
      "New best model found at epoch 94 with validation loss 0.9835187196731567\n",
      "Starting Epoch 95\n",
      "0.9512779349866121\n",
      "Starting Epoch 96\n",
      "0.9517556377079176\n",
      "Starting Epoch 97\n",
      "0.9514612451843594\n",
      "Starting Epoch 98\n",
      "0.9515766112700753\n",
      "Starting Epoch 99\n",
      "0.9504435347474139\n",
      "Starting Epoch 100\n",
      "0.9512673383173735\n",
      "Starting Epoch 101\n",
      "0.9513047596682673\n",
      "Starting Epoch 102\n",
      "0.9515231018481047\n",
      "New best model found at epoch 102 with validation loss 0.9833977818489075\n",
      "Starting Epoch 103\n",
      "0.9517316766407179\n",
      "New best model found at epoch 103 with validation loss 0.9833676218986511\n",
      "Starting Epoch 104\n",
      "0.9502257808395054\n",
      "Starting Epoch 105\n",
      "0.9528198967809263\n",
      "Starting Epoch 106\n",
      "0.9506295012391132\n",
      "Starting Epoch 107\n",
      "0.9522172471751338\n",
      "Starting Epoch 108\n",
      "0.9499982465868411\n",
      "New best model found at epoch 108 with validation loss 0.9831513166427612\n",
      "Starting Epoch 109\n",
      "0.9506843297377877\n",
      "Starting Epoch 110\n",
      "0.9501824145731719\n",
      "Starting Epoch 111\n",
      "0.9497813686080601\n",
      "Starting Epoch 112\n",
      "0.9513343054315319\n",
      "Starting Epoch 113\n",
      "0.9507567001425702\n",
      "Starting Epoch 114\n",
      "0.9506927935973458\n",
      "New best model found at epoch 114 with validation loss 0.9829872846603394\n",
      "Starting Epoch 115\n",
      "0.9499607552652773\n",
      "Starting Epoch 116\n",
      "0.9500215105388475\n",
      "New best model found at epoch 116 with validation loss 0.9825933575630188\n",
      "Starting Epoch 117\n",
      "0.9503982559494351\n",
      "Starting Epoch 118\n",
      "0.9499577620755071\n",
      "Starting Epoch 119\n",
      "0.9501096943150396\n",
      "Starting Epoch 120\n",
      "0.9500211943750796\n",
      "Starting Epoch 121\n",
      "0.9519394247428231\n",
      "Starting Epoch 122\n",
      "0.9504805259082628\n",
      "Starting Epoch 123\n",
      "0.9502116649047189\n",
      "Starting Epoch 124\n",
      "0.9492960675902988\n",
      "Starting Epoch 125\n",
      "0.9504984850468843\n",
      "New best model found at epoch 125 with validation loss 0.9824827909469604\n",
      "Starting Epoch 126\n",
      "0.9505088303400122\n",
      "Starting Epoch 127\n",
      "0.9490183073541393\n",
      "Starting Epoch 128\n",
      "0.950530072917109\n",
      "Starting Epoch 129\n",
      "0.9506396910418635\n",
      "Starting Epoch 130\n",
      "0.9498730120451554\n",
      "Starting Epoch 131\n",
      "0.9501446200453717\n",
      "Starting Epoch 132\n",
      "0.9493219230485999\n",
      "Starting Epoch 133\n",
      "0.9504494718883348\n",
      "Starting Epoch 134\n",
      "0.9503866460012353\n",
      "Starting Epoch 135\n",
      "0.9498334837996442\n",
      "Starting Epoch 136\n",
      "0.9485791792040286\n",
      "Starting Epoch 137\n",
      "0.9499927085378895\n",
      "Starting Epoch 138\n",
      "0.9499013009278671\n",
      "New best model found at epoch 138 with validation loss 0.9824308156967163\n",
      "Starting Epoch 139\n",
      "0.9495147052018539\n",
      "New best model found at epoch 139 with validation loss 0.9823038578033447\n",
      "Starting Epoch 140\n",
      "0.9506944366123365\n",
      "New best model found at epoch 140 with validation loss 0.9821563959121704\n",
      "Starting Epoch 141\n",
      "0.9496198452037313\n",
      "New best model found at epoch 141 with validation loss 0.9819799065589905\n",
      "Starting Epoch 142\n",
      "0.9487173790517061\n",
      "Starting Epoch 143\n",
      "0.9484033377274222\n",
      "Starting Epoch 144\n",
      "0.9494637535965961\n",
      "Starting Epoch 145\n",
      "0.949456943118054\n",
      "Starting Epoch 146\n",
      "0.948875007422074\n",
      "Starting Epoch 147\n",
      "0.948275511679442\n",
      "Starting Epoch 148\n",
      "0.9485230964163075\n",
      "Starting Epoch 149\n",
      "0.9497016512829325\n",
      "Starting Epoch 150\n",
      "0.9487982858782229\n",
      "Starting Epoch 151\n",
      "0.9490721044333085\n",
      "Starting Epoch 152\n",
      "0.9495433594869531\n",
      "Starting Epoch 153\n",
      "0.9498307419859845\n",
      "Starting Epoch 154\n",
      "0.9487041727356289\n",
      "Starting Epoch 155\n",
      "0.9483318173367045\n",
      "Starting Epoch 156\n",
      "0.9480273075725721\n",
      "Starting Epoch 157\n",
      "0.9487586073253466\n",
      "Starting Epoch 158\n",
      "0.94826122470524\n",
      "Starting Epoch 159\n",
      "0.9485906388448633\n",
      "Starting Epoch 160\n",
      "0.9498769951903302\n",
      "New best model found at epoch 160 with validation loss 0.9818083047866821\n",
      "Starting Epoch 161\n",
      "0.9488299333530924\n",
      "Starting Epoch 162\n",
      "0.9480169933775197\n",
      "Starting Epoch 163\n",
      "0.9491956778194593\n",
      "Starting Epoch 164\n",
      "0.9482646377190299\n",
      "Starting Epoch 165\n",
      "0.9481542317763619\n",
      "Starting Epoch 166\n",
      "0.9481495256009309\n",
      "Starting Epoch 167\n",
      "0.9495883972748466\n",
      "Starting Epoch 168\n",
      "0.948970703975014\n",
      "Starting Epoch 169\n",
      "0.9482905113178751\n",
      "Starting Epoch 170\n",
      "0.9474236757858939\n",
      "Starting Epoch 171\n",
      "0.9475717674130979\n",
      "Starting Epoch 172\n",
      "0.9473766166230907\n",
      "Starting Epoch 173\n",
      "0.948073457116666\n",
      "Starting Epoch 174\n",
      "0.9473660380943961\n",
      "Starting Epoch 175\n",
      "0.94739561236423\n",
      "Starting Epoch 176\n",
      "0.9467538180558578\n",
      "Starting Epoch 177\n",
      "0.9475767923438031\n",
      "Starting Epoch 178\n",
      "0.9472726168839828\n",
      "Starting Epoch 179\n",
      "0.9466652766517971\n",
      "Starting Epoch 180\n",
      "0.9474452941314034\n",
      "Starting Epoch 181\n",
      "0.9468409082163936\n",
      "Starting Epoch 182\n",
      "0.9463451867518218\n",
      "Starting Epoch 183\n",
      "0.9475219171980153\n",
      "Starting Epoch 184\n",
      "0.9474386598752893\n",
      "Starting Epoch 185\n",
      "0.9467768254487411\n",
      "Starting Epoch 186\n",
      "0.9466132262478704\n",
      "Starting Epoch 187\n",
      "0.9467145230459131\n",
      "Starting Epoch 188\n",
      "0.9462142197982125\n",
      "Starting Epoch 189\n",
      "0.9473290987636732\n",
      "Starting Epoch 190\n",
      "0.946264272150786\n",
      "Starting Epoch 191\n",
      "0.9462799611298934\n",
      "Starting Epoch 192\n",
      "0.9458476719648942\n",
      "Starting Epoch 193\n",
      "0.9458242447479911\n",
      "Starting Epoch 194\n",
      "0.9453463787617891\n",
      "Starting Epoch 195\n",
      "0.9465389951415684\n",
      "Starting Epoch 196\n",
      "0.9461493984512661\n",
      "Starting Epoch 197\n",
      "0.945836471474689\n",
      "Starting Epoch 198\n",
      "0.945523933224056\n",
      "Starting Epoch 199\n",
      "0.946579793225164\n",
      "New best model found at epoch 199 with validation loss 0.9817215800285339\n",
      "Starting Epoch 200\n",
      "0.9455949767776157\n",
      "Starting Epoch 201\n",
      "0.9459821504095326\n",
      "New best model found at epoch 201 with validation loss 0.9816673398017883\n",
      "Starting Epoch 202\n",
      "0.946041358553845\n",
      "New best model found at epoch 202 with validation loss 0.9815981388092041\n",
      "Starting Epoch 203\n",
      "0.9467151890630308\n",
      "Starting Epoch 204\n",
      "0.9442677083222762\n",
      "Starting Epoch 205\n",
      "0.9461167221483977\n",
      "Starting Epoch 206\n",
      "0.9449751973152161\n",
      "Starting Epoch 207\n",
      "0.9451427433801733\n",
      "Starting Epoch 208\n",
      "0.9459806343783503\n",
      "New best model found at epoch 208 with validation loss 0.9812325239181519\n",
      "Starting Epoch 209\n",
      "0.9460219378056733\n",
      "Starting Epoch 210\n",
      "0.9444624030071757\n",
      "Starting Epoch 211\n",
      "0.9451431165570798\n",
      "Starting Epoch 212\n",
      "0.9451516711193583\n",
      "New best model found at epoch 212 with validation loss 0.981131374835968\n",
      "Starting Epoch 213\n",
      "0.9444403544716213\n",
      "Starting Epoch 214\n",
      "0.9440108071202817\n",
      "Starting Epoch 215\n",
      "0.9448449741239133\n",
      "New best model found at epoch 215 with validation loss 0.9807339310646057\n",
      "Starting Epoch 216\n",
      "0.9445367533227672\n",
      "Starting Epoch 217\n",
      "0.9444337927776835\n",
      "Starting Epoch 218\n",
      "0.9456670802572499\n",
      "Starting Epoch 219\n",
      "0.9442684261695199\n",
      "Starting Epoch 220\n",
      "0.9437239040499148\n",
      "Starting Epoch 221\n",
      "0.9449673787407253\n",
      "New best model found at epoch 221 with validation loss 0.9804955124855042\n",
      "Starting Epoch 222\n",
      "0.9447421146475751\n",
      "New best model found at epoch 222 with validation loss 0.9804502725601196\n",
      "Starting Epoch 223\n",
      "0.9440138184505961\n",
      "New best model found at epoch 223 with validation loss 0.9802271723747253\n",
      "Starting Epoch 224\n",
      "0.94453422660413\n",
      "Starting Epoch 225\n",
      "0.94393659674603\n",
      "New best model found at epoch 225 with validation loss 0.9801616668701172\n",
      "Starting Epoch 226\n",
      "0.9438253589298414\n",
      "Starting Epoch 227\n",
      "0.9452283382415771\n",
      "Starting Epoch 228\n",
      "0.9438818045284437\n",
      "Starting Epoch 229\n",
      "0.9436496107474618\n",
      "New best model found at epoch 229 with validation loss 0.9798349142074585\n",
      "Starting Epoch 230\n",
      "0.9437988892845486\n",
      "Starting Epoch 231\n",
      "0.9430097082386846\n",
      "Starting Epoch 232\n",
      "0.9433043910109479\n",
      "New best model found at epoch 232 with validation loss 0.9794574975967407\n",
      "Starting Epoch 233\n",
      "0.9439606873885446\n",
      "Starting Epoch 234\n",
      "0.9436990048574365\n",
      "New best model found at epoch 234 with validation loss 0.9792605042457581\n",
      "Starting Epoch 235\n",
      "0.9433329520018204\n",
      "Starting Epoch 236\n",
      "0.9424809580263884\n",
      "Starting Epoch 237\n",
      "0.9429518062135448\n",
      "New best model found at epoch 237 with validation loss 0.9791011214256287\n",
      "Starting Epoch 238\n",
      "0.942888477574224\n",
      "Starting Epoch 239\n",
      "0.9426467859226725\n",
      "Starting Epoch 240\n",
      "0.9437328136485555\n",
      "Starting Epoch 241\n",
      "0.9425525043321692\n",
      "Starting Epoch 242\n",
      "0.9424242714177007\n",
      "Starting Epoch 243\n",
      "0.9428555706272954\n",
      "Starting Epoch 244\n",
      "0.9424280705659286\n",
      "New best model found at epoch 244 with validation loss 0.978745698928833\n",
      "Starting Epoch 245\n",
      "0.9423330918602322\n",
      "New best model found at epoch 245 with validation loss 0.9786834716796875\n",
      "Starting Epoch 246\n",
      "0.9427346328030461\n",
      "Starting Epoch 247\n",
      "0.9431330872618634\n",
      "Starting Epoch 248\n",
      "0.942159116268158\n",
      "Starting Epoch 249\n",
      "0.9422132321026014\n",
      "New best model found at epoch 249 with validation loss 0.9783236384391785\n",
      "Starting Epoch 250\n",
      "0.9420702638833419\n",
      "New best model found at epoch 250 with validation loss 0.9782548546791077\n",
      "Starting Epoch 251\n",
      "0.9420324693555417\n",
      "New best model found at epoch 251 with validation loss 0.978050172328949\n",
      "Starting Epoch 252\n",
      "0.9412936801495759\n",
      "Starting Epoch 253\n",
      "0.9417745859726615\n",
      "Starting Epoch 254\n",
      "0.9421382598254991\n",
      "Starting Epoch 255\n",
      "0.9406053605286971\n",
      "Starting Epoch 256\n",
      "0.9425675661667533\n",
      "New best model found at epoch 256 with validation loss 0.9779692888259888\n",
      "Starting Epoch 257\n",
      "0.9417203301968782\n",
      "New best model found at epoch 257 with validation loss 0.977522611618042\n",
      "Starting Epoch 258\n",
      "0.9415793470714403\n",
      "Starting Epoch 259\n",
      "0.9404295760652294\n",
      "Starting Epoch 260\n",
      "0.9412280839422474\n",
      "New best model found at epoch 260 with validation loss 0.9771565198898315\n",
      "Starting Epoch 261\n",
      "0.9410793314809385\n",
      "Starting Epoch 262\n",
      "0.941301633482394\n",
      "New best model found at epoch 262 with validation loss 0.9771397709846497\n",
      "Starting Epoch 263\n",
      "0.9420073447020157\n",
      "New best model found at epoch 263 with validation loss 0.9769408702850342\n",
      "Starting Epoch 264\n",
      "0.9412273375884347\n",
      "Starting Epoch 265\n",
      "0.9416385293006897\n",
      "New best model found at epoch 265 with validation loss 0.976874053478241\n",
      "Starting Epoch 266\n",
      "0.9406443601069243\n",
      "Starting Epoch 267\n",
      "0.9400387898735378\n",
      "Starting Epoch 268\n",
      "0.9418147646862528\n",
      "Starting Epoch 269\n",
      "0.9416783685269563\n",
      "New best model found at epoch 269 with validation loss 0.9767305850982666\n",
      "Starting Epoch 270\n",
      "0.9423520202222078\n",
      "Starting Epoch 271\n",
      "0.940840394600578\n",
      "New best model found at epoch 271 with validation loss 0.976348340511322\n",
      "Starting Epoch 272\n",
      "0.939822484617648\n",
      "Starting Epoch 273\n",
      "0.9395062301469885\n",
      "New best model found at epoch 273 with validation loss 0.9762392640113831\n",
      "Starting Epoch 274\n",
      "0.9408577110456384\n",
      "Starting Epoch 275\n",
      "0.9402560954508574\n",
      "Starting Epoch 276\n",
      "0.9397030602330747\n",
      "Starting Epoch 277\n",
      "0.9392918503802755\n",
      "Starting Epoch 278\n",
      "0.9402177670727605\n",
      "New best model found at epoch 278 with validation loss 0.9761009812355042\n",
      "Starting Epoch 279\n",
      "0.9390477045722629\n",
      "Starting Epoch 280\n",
      "0.9394321778546209\n",
      "Starting Epoch 281\n",
      "0.9387436975603518\n",
      "Starting Epoch 282\n",
      "0.9390691881594451\n",
      "New best model found at epoch 282 with validation loss 0.9755833745002747\n",
      "Starting Epoch 283\n",
      "0.9389300268629323\n",
      "Starting Epoch 284\n",
      "0.9386443806731183\n",
      "Starting Epoch 285\n",
      "0.9393530954485354\n",
      "Starting Epoch 286\n",
      "0.9395388701687688\n",
      "Starting Epoch 287\n",
      "0.9403924190479777\n",
      "New best model found at epoch 287 with validation loss 0.9751175045967102\n",
      "Starting Epoch 288\n",
      "0.9396848782249119\n",
      "New best model found at epoch 288 with validation loss 0.9747437238693237\n",
      "Starting Epoch 289\n",
      "0.9387634189232535\n",
      "Starting Epoch 290\n",
      "0.9386545601098434\n",
      "New best model found at epoch 290 with validation loss 0.9746928215026855\n",
      "Starting Epoch 291\n",
      "0.938192922136058\n",
      "Starting Epoch 292\n",
      "0.9387996429982393\n",
      "Starting Epoch 293\n",
      "0.9382945480554\n",
      "Starting Epoch 294\n",
      "0.9387905597686768\n",
      "Starting Epoch 295\n",
      "0.9400373904601388\n",
      "New best model found at epoch 295 with validation loss 0.9745170474052429\n",
      "Starting Epoch 296\n",
      "0.9388522194779437\n",
      "New best model found at epoch 296 with validation loss 0.9735924005508423\n",
      "Starting Epoch 297\n",
      "0.9380217583283134\n",
      "Starting Epoch 298\n",
      "0.937997157159059\n",
      "Starting Epoch 299\n",
      "0.9381666572197623\n",
      "Starting Epoch 300\n",
      "0.9375314686609351\n",
      "New best model found at epoch 300 with validation loss 0.9732806086540222\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f60f3222-facb-48fe-b7b1-18620516ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.851817540500475\n",
      "New best model found at epoch 1 with validation loss 0.804873526096344\n",
      "Starting Epoch 2\n",
      "0.8068896091502645\n",
      "New best model found at epoch 2 with validation loss 0.7912222743034363\n",
      "Starting Epoch 3\n",
      "0.8000747509624647\n",
      "Starting Epoch 4\n",
      "0.7979270323463108\n",
      "New best model found at epoch 4 with validation loss 0.7842517495155334\n",
      "Starting Epoch 5\n",
      "0.7960300393726515\n",
      "Starting Epoch 6\n",
      "0.7936038089835126\n",
      "Starting Epoch 7\n",
      "0.7943590335223986\n",
      "Starting Epoch 8\n",
      "0.7949842266414476\n",
      "Starting Epoch 9\n",
      "0.7947161741878676\n",
      "New best model found at epoch 9 with validation loss 0.7811142206192017\n",
      "Starting Epoch 10\n",
      "0.7935397106668224\n",
      "Starting Epoch 11\n",
      "0.7935783759407375\n",
      "Starting Epoch 12\n",
      "0.7942513201547705\n",
      "Starting Epoch 13\n",
      "0.7930368781089783\n",
      "Starting Epoch 14\n",
      "0.7930712933125703\n",
      "Starting Epoch 15\n",
      "0.7925929271656534\n",
      "Starting Epoch 16\n",
      "0.791606605052948\n",
      "Starting Epoch 17\n",
      "0.7913567397905432\n",
      "Starting Epoch 18\n",
      "0.7911671633305757\n",
      "Starting Epoch 19\n",
      "0.7906383301900781\n",
      "Starting Epoch 20\n",
      "0.7921471051547838\n",
      "Starting Epoch 21\n",
      "0.7903459227603414\n",
      "Starting Epoch 22\n",
      "0.7907934810804285\n",
      "New best model found at epoch 22 with validation loss 0.7807591557502747\n",
      "Starting Epoch 23\n",
      "0.7905698314956997\n",
      "Starting Epoch 24\n",
      "0.7913067107615264\n",
      "Starting Epoch 25\n",
      "0.7913147910781528\n",
      "Starting Epoch 26\n",
      "0.7899100702741871\n",
      "Starting Epoch 27\n",
      "0.7909526513970416\n",
      "Starting Epoch 28\n",
      "0.7905703161073767\n",
      "Starting Epoch 29\n",
      "0.790446893028591\n",
      "Starting Epoch 30\n",
      "0.7907734435537587\n",
      "Starting Epoch 31\n",
      "0.7897721529006958\n",
      "New best model found at epoch 31 with validation loss 0.7806052565574646\n",
      "Starting Epoch 32\n",
      "0.7898634957230609\n",
      "Starting Epoch 33\n",
      "0.7904024305550948\n",
      "Starting Epoch 34\n",
      "0.7889789990756823\n",
      "Starting Epoch 35\n",
      "0.7889065379681794\n",
      "Starting Epoch 36\n",
      "0.7888414756111477\n",
      "New best model found at epoch 36 with validation loss 0.7800264358520508\n",
      "Starting Epoch 37\n",
      "0.7879268086474874\n",
      "Starting Epoch 38\n",
      "0.790112510971401\n",
      "Starting Epoch 39\n",
      "0.7890238243600597\n",
      "Starting Epoch 40\n",
      "0.7881874442100525\n",
      "Starting Epoch 41\n",
      "0.7888901000437529\n",
      "New best model found at epoch 41 with validation loss 0.7799769043922424\n",
      "Starting Epoch 42\n",
      "0.7887799195621324\n",
      "Starting Epoch 43\n",
      "0.7890794406766477\n",
      "New best model found at epoch 43 with validation loss 0.7797607779502869\n",
      "Starting Epoch 44\n",
      "0.7873291088187176\n",
      "Starting Epoch 45\n",
      "0.788958401783653\n",
      "Starting Epoch 46\n",
      "0.7886839923651322\n",
      "New best model found at epoch 46 with validation loss 0.7791007161140442\n",
      "Starting Epoch 47\n",
      "0.7877300355745398\n",
      "Starting Epoch 48\n",
      "0.7882156812626383\n",
      "Starting Epoch 49\n",
      "0.7874243337175121\n",
      "New best model found at epoch 49 with validation loss 0.7788785099983215\n",
      "Starting Epoch 50\n",
      "0.7868972576182821\n",
      "New best model found at epoch 50 with validation loss 0.7785497903823853\n",
      "Starting Epoch 51\n",
      "0.7872498709222545\n",
      "Starting Epoch 52\n",
      "0.7867467196091361\n",
      "Starting Epoch 53\n",
      "0.7876026448996171\n",
      "Starting Epoch 54\n",
      "0.7872100446535193\n",
      "Starting Epoch 55\n",
      "0.7863690542138141\n",
      "Starting Epoch 56\n",
      "0.7868324025817539\n",
      "New best model found at epoch 56 with validation loss 0.7779921889305115\n",
      "Starting Epoch 57\n",
      "0.7856684664021367\n",
      "New best model found at epoch 57 with validation loss 0.7779309749603271\n",
      "Starting Epoch 58\n",
      "0.7861174293186354\n",
      "New best model found at epoch 58 with validation loss 0.7778463959693909\n",
      "Starting Epoch 59\n",
      "0.7871745928474094\n",
      "Starting Epoch 60\n",
      "0.7857946442521136\n",
      "Starting Epoch 61\n",
      "0.7857154244961946\n",
      "Starting Epoch 62\n",
      "0.785331842692002\n",
      "Starting Epoch 63\n",
      "0.7844301332598147\n",
      "New best model found at epoch 63 with validation loss 0.7766941785812378\n",
      "Starting Epoch 64\n",
      "0.7851786950360173\n",
      "Starting Epoch 65\n",
      "0.7846262973287831\n",
      "New best model found at epoch 65 with validation loss 0.7765116691589355\n",
      "Starting Epoch 66\n",
      "0.784386246100716\n",
      "Starting Epoch 67\n",
      "0.7851333566333937\n",
      "New best model found at epoch 67 with validation loss 0.7763766646385193\n",
      "Starting Epoch 68\n",
      "0.7841030126032622\n",
      "New best model found at epoch 68 with validation loss 0.7761827707290649\n",
      "Starting Epoch 69\n",
      "0.7837264667386594\n",
      "New best model found at epoch 69 with validation loss 0.7753193974494934\n",
      "Starting Epoch 70\n",
      "0.7833893065867217\n",
      "Starting Epoch 71\n",
      "0.7826904524927554\n",
      "Starting Epoch 72\n",
      "0.7830337907956995\n",
      "New best model found at epoch 72 with validation loss 0.7751213908195496\n",
      "Starting Epoch 73\n",
      "0.7836698008620221\n",
      "New best model found at epoch 73 with validation loss 0.7744340300559998\n",
      "Starting Epoch 74\n",
      "0.7820391603138136\n",
      "Starting Epoch 75\n",
      "0.7817541853241299\n",
      "Starting Epoch 76\n",
      "0.7820638599603073\n",
      "New best model found at epoch 76 with validation loss 0.7735585570335388\n",
      "Starting Epoch 77\n",
      "0.7820380045020062\n",
      "New best model found at epoch 77 with validation loss 0.7731485366821289\n",
      "Starting Epoch 78\n",
      "0.7820108092349508\n",
      "Starting Epoch 79\n",
      "0.7818144041558971\n",
      "New best model found at epoch 79 with validation loss 0.7723767757415771\n",
      "Starting Epoch 80\n",
      "0.7808211601298788\n",
      "Starting Epoch 81\n",
      "0.7809728928234266\n",
      "New best model found at epoch 81 with validation loss 0.7717024683952332\n",
      "Starting Epoch 82\n",
      "0.7805414847705675\n",
      "Starting Epoch 83\n",
      "0.7807119281395621\n",
      "Starting Epoch 84\n",
      "0.7794632082400115\n",
      "New best model found at epoch 84 with validation loss 0.7713201642036438\n",
      "Starting Epoch 85\n",
      "0.7799059023027834\n",
      "New best model found at epoch 85 with validation loss 0.7709922790527344\n",
      "Starting Epoch 86\n",
      "0.778268663779549\n",
      "Starting Epoch 87\n",
      "0.7792056850765062\n",
      "New best model found at epoch 87 with validation loss 0.7696709632873535\n",
      "Starting Epoch 88\n",
      "0.7783222872277965\n",
      "New best model found at epoch 88 with validation loss 0.7689924240112305\n",
      "Starting Epoch 89\n",
      "0.7778149791385817\n",
      "Starting Epoch 90\n",
      "0.7775539211604906\n",
      "New best model found at epoch 90 with validation loss 0.7686785459518433\n",
      "Starting Epoch 91\n",
      "0.7768969406252322\n",
      "New best model found at epoch 91 with validation loss 0.7682662606239319\n",
      "Starting Epoch 92\n",
      "0.7763308623562688\n",
      "Starting Epoch 93\n",
      "0.7757026656814243\n",
      "Starting Epoch 94\n",
      "0.7750939778659655\n",
      "New best model found at epoch 94 with validation loss 0.7664429545402527\n",
      "Starting Epoch 95\n",
      "0.7758074947025465\n",
      "New best model found at epoch 95 with validation loss 0.7658490538597107\n",
      "Starting Epoch 96\n",
      "0.7753267288208008\n",
      "Starting Epoch 97\n",
      "0.7737259605656499\n",
      "New best model found at epoch 97 with validation loss 0.7653365135192871\n",
      "Starting Epoch 98\n",
      "0.7737910358802133\n",
      "Starting Epoch 99\n",
      "0.7739445048829784\n",
      "New best model found at epoch 99 with validation loss 0.7641861438751221\n",
      "Starting Epoch 100\n",
      "0.7729233399681423\n",
      "Starting Epoch 101\n",
      "0.7720252664192863\n",
      "New best model found at epoch 101 with validation loss 0.7629400491714478\n",
      "Starting Epoch 102\n",
      "0.7723729377207549\n",
      "Starting Epoch 103\n",
      "0.7721748481626096\n",
      "New best model found at epoch 103 with validation loss 0.7621452808380127\n",
      "Starting Epoch 104\n",
      "0.7718219938485519\n",
      "Starting Epoch 105\n",
      "0.771607852500418\n",
      "New best model found at epoch 105 with validation loss 0.7611915469169617\n",
      "Starting Epoch 106\n",
      "0.7691714970961862\n",
      "New best model found at epoch 106 with validation loss 0.7608450055122375\n",
      "Starting Epoch 107\n",
      "0.769980479841647\n",
      "New best model found at epoch 107 with validation loss 0.7607150673866272\n",
      "Starting Epoch 108\n",
      "0.7687113803365956\n",
      "Starting Epoch 109\n",
      "0.7684953160907911\n",
      "New best model found at epoch 109 with validation loss 0.7595930099487305\n",
      "Starting Epoch 110\n",
      "0.7685658698496611\n",
      "Starting Epoch 111\n",
      "0.7674449474915214\n",
      "Starting Epoch 112\n",
      "0.7692069178042205\n",
      "New best model found at epoch 112 with validation loss 0.7578954696655273\n",
      "Starting Epoch 113\n",
      "0.7671008732007898\n",
      "New best model found at epoch 113 with validation loss 0.7575094699859619\n",
      "Starting Epoch 114\n",
      "0.7671034025109332\n",
      "New best model found at epoch 114 with validation loss 0.7562046647071838\n",
      "Starting Epoch 115\n",
      "0.7659420656121295\n",
      "New best model found at epoch 115 with validation loss 0.7555606961250305\n",
      "Starting Epoch 116\n",
      "0.7646961263988329\n",
      "New best model found at epoch 116 with validation loss 0.7551010251045227\n",
      "Starting Epoch 117\n",
      "0.7638851507850315\n",
      "New best model found at epoch 117 with validation loss 0.7547400593757629\n",
      "Starting Epoch 118\n",
      "0.7648043865742891\n",
      "New best model found at epoch 118 with validation loss 0.7539349794387817\n",
      "Starting Epoch 119\n",
      "0.7642991439155911\n",
      "Starting Epoch 120\n",
      "0.7650173436040464\n",
      "Starting Epoch 121\n",
      "0.764458109503207\n",
      "New best model found at epoch 121 with validation loss 0.7521462440490723\n",
      "Starting Epoch 122\n",
      "0.7632303548895795\n",
      "New best model found at epoch 122 with validation loss 0.7521052360534668\n",
      "Starting Epoch 123\n",
      "0.7629315205242323\n",
      "New best model found at epoch 123 with validation loss 0.7513301968574524\n",
      "Starting Epoch 124\n",
      "0.7623782183813013\n",
      "Starting Epoch 125\n",
      "0.7617830711862316\n",
      "New best model found at epoch 125 with validation loss 0.7505987286567688\n",
      "Starting Epoch 126\n",
      "0.7604417049366495\n",
      "New best model found at epoch 126 with validation loss 0.7499443888664246\n",
      "Starting Epoch 127\n",
      "0.7594049158303634\n",
      "New best model found at epoch 127 with validation loss 0.7487713098526001\n",
      "Starting Epoch 128\n",
      "0.7594894948212997\n",
      "Starting Epoch 129\n",
      "0.7597000210181527\n",
      "Starting Epoch 130\n",
      "0.7589789084766222\n",
      "Starting Epoch 131\n",
      "0.7597460124803626\n",
      "New best model found at epoch 131 with validation loss 0.7467314004898071\n",
      "Starting Epoch 132\n",
      "0.7592728448950726\n",
      "Starting Epoch 133\n",
      "0.7585054065870203\n",
      "New best model found at epoch 133 with validation loss 0.7459261417388916\n",
      "Starting Epoch 134\n",
      "0.7564591532168181\n",
      "Starting Epoch 135\n",
      "0.7568174859751826\n",
      "Starting Epoch 136\n",
      "0.7564462423324585\n",
      "New best model found at epoch 136 with validation loss 0.7457253932952881\n",
      "Starting Epoch 137\n",
      "0.7566127880759861\n",
      "New best model found at epoch 137 with validation loss 0.7440940737724304\n",
      "Starting Epoch 138\n",
      "0.756821246250816\n",
      "Starting Epoch 139\n",
      "0.7562502933585126\n",
      "Starting Epoch 140\n",
      "0.7564901761386705\n",
      "Starting Epoch 141\n",
      "0.7535064194513403\n",
      "New best model found at epoch 141 with validation loss 0.7422581315040588\n",
      "Starting Epoch 142\n",
      "0.7543045982070591\n",
      "New best model found at epoch 142 with validation loss 0.7416936159133911\n",
      "Starting Epoch 143\n",
      "0.7528500764266305\n",
      "Starting Epoch 144\n",
      "0.7549212678619053\n",
      "New best model found at epoch 144 with validation loss 0.7409368753433228\n",
      "Starting Epoch 145\n",
      "0.7526491051134856\n",
      "Starting Epoch 146\n",
      "0.7539009788761968\n",
      "Starting Epoch 147\n",
      "0.7517073180364526\n",
      "Starting Epoch 148\n",
      "0.7506998025852701\n",
      "Starting Epoch 149\n",
      "0.7524779464887537\n",
      "New best model found at epoch 149 with validation loss 0.7391369938850403\n",
      "Starting Epoch 150\n",
      "0.7500755812810815\n",
      "Starting Epoch 151\n",
      "0.7505791679672573\n",
      "Starting Epoch 152\n",
      "0.7507338783015376\n",
      "New best model found at epoch 152 with validation loss 0.737924337387085\n",
      "Starting Epoch 153\n",
      "0.7499910048816515\n",
      "Starting Epoch 154\n",
      "0.7495220977327098\n",
      "New best model found at epoch 154 with validation loss 0.7367459535598755\n",
      "Starting Epoch 155\n",
      "0.74825519323349\n",
      "Starting Epoch 156\n",
      "0.7500838792842367\n",
      "Starting Epoch 157\n",
      "0.7504309597222701\n",
      "Starting Epoch 158\n",
      "0.7499232940051866\n",
      "Starting Epoch 159\n",
      "0.748087535733762\n",
      "New best model found at epoch 159 with validation loss 0.7362980842590332\n",
      "Starting Epoch 160\n",
      "0.7481538342392963\n",
      "New best model found at epoch 160 with validation loss 0.7359538078308105\n",
      "Starting Epoch 161\n",
      "0.7487989741822948\n",
      "New best model found at epoch 161 with validation loss 0.7348414659500122\n",
      "Starting Epoch 162\n",
      "0.745692561502042\n",
      "New best model found at epoch 162 with validation loss 0.7335668802261353\n",
      "Starting Epoch 163\n",
      "0.7482158049293186\n",
      "Starting Epoch 164\n",
      "0.7464286348094111\n",
      "Starting Epoch 165\n",
      "0.7471096852551335\n",
      "New best model found at epoch 165 with validation loss 0.7334747314453125\n",
      "Starting Epoch 166\n",
      "0.7461595198382502\n",
      "Starting Epoch 167\n",
      "0.7471752451813739\n",
      "New best model found at epoch 167 with validation loss 0.7329001426696777\n",
      "Starting Epoch 168\n",
      "0.7459297542986663\n",
      "New best model found at epoch 168 with validation loss 0.7315416932106018\n",
      "Starting Epoch 169\n",
      "0.7454826779987501\n",
      "Starting Epoch 170\n",
      "0.7452368373456209\n",
      "Starting Epoch 171\n",
      "0.7446415372516798\n",
      "Starting Epoch 172\n",
      "0.7439696607382401\n",
      "Starting Epoch 173\n",
      "0.7426188484482144\n",
      "New best model found at epoch 173 with validation loss 0.7309578657150269\n",
      "Starting Epoch 174\n",
      "0.742181192273679\n",
      "New best model found at epoch 174 with validation loss 0.7296394109725952\n",
      "Starting Epoch 175\n",
      "0.7437472680340642\n",
      "Starting Epoch 176\n",
      "0.7436424493789673\n",
      "Starting Epoch 177\n",
      "0.7435700349185778\n",
      "Starting Epoch 178\n",
      "0.7419319645218228\n",
      "New best model found at epoch 178 with validation loss 0.7290506958961487\n",
      "Starting Epoch 179\n",
      "0.7417142132054204\n",
      "New best model found at epoch 179 with validation loss 0.7288101315498352\n",
      "Starting Epoch 180\n",
      "0.7422222546909166\n",
      "Starting Epoch 181\n",
      "0.7416421641474185\n",
      "Starting Epoch 182\n",
      "0.7431127532668735\n",
      "Starting Epoch 183\n",
      "0.7409117247747339\n",
      "Starting Epoch 184\n",
      "0.7417674375616986\n",
      "Starting Epoch 185\n",
      "0.7420820464258608\n",
      "New best model found at epoch 185 with validation loss 0.7269030213356018\n",
      "Starting Epoch 186\n",
      "0.7408964815347091\n",
      "Starting Epoch 187\n",
      "0.7421093116635862\n",
      "New best model found at epoch 187 with validation loss 0.7264116406440735\n",
      "Starting Epoch 188\n",
      "0.7381904280704\n",
      "Starting Epoch 189\n",
      "0.7404851265575575\n",
      "Starting Epoch 190\n",
      "0.7399845719337463\n",
      "New best model found at epoch 190 with validation loss 0.7260653376579285\n",
      "Starting Epoch 191\n",
      "0.7407057000243146\n",
      "Starting Epoch 192\n",
      "0.7390201791473057\n",
      "Starting Epoch 193\n",
      "0.7392899031224458\n",
      "New best model found at epoch 193 with validation loss 0.7252341508865356\n",
      "Starting Epoch 194\n",
      "0.7385071827017743\n",
      "New best model found at epoch 194 with validation loss 0.7245980501174927\n",
      "Starting Epoch 195\n",
      "0.7400298559147379\n",
      "New best model found at epoch 195 with validation loss 0.7245343327522278\n",
      "Starting Epoch 196\n",
      "0.7387573252553525\n",
      "Starting Epoch 197\n",
      "0.737457503443179\n",
      "New best model found at epoch 197 with validation loss 0.724468469619751\n",
      "Starting Epoch 198\n",
      "0.7383624211601589\n",
      "New best model found at epoch 198 with validation loss 0.7238078713417053\n",
      "Starting Epoch 199\n",
      "0.7398635822793712\n",
      "Starting Epoch 200\n",
      "0.7370154287504114\n",
      "Starting Epoch 201\n",
      "0.7386054396629333\n",
      "Starting Epoch 202\n",
      "0.7373074604117352\n",
      "New best model found at epoch 202 with validation loss 0.722206711769104\n",
      "Starting Epoch 203\n",
      "0.7384248220402262\n",
      "Starting Epoch 204\n",
      "0.7368028319400289\n",
      "New best model found at epoch 204 with validation loss 0.7220258116722107\n",
      "Starting Epoch 205\n",
      "0.7366965905479763\n",
      "Starting Epoch 206\n",
      "0.735801409120145\n",
      "New best model found at epoch 206 with validation loss 0.7217263579368591\n",
      "Starting Epoch 207\n",
      "0.7372684763825458\n",
      "New best model found at epoch 207 with validation loss 0.7215036749839783\n",
      "Starting Epoch 208\n",
      "0.7358652716097625\n",
      "New best model found at epoch 208 with validation loss 0.7214392423629761\n",
      "Starting Epoch 209\n",
      "0.7366191848464634\n",
      "Starting Epoch 210\n",
      "0.7368436041085616\n",
      "New best model found at epoch 210 with validation loss 0.7203196287155151\n",
      "Starting Epoch 211\n",
      "0.7346302633700164\n",
      "Starting Epoch 212\n",
      "0.7363126122433207\n",
      "Starting Epoch 213\n",
      "0.7345644909402599\n",
      "New best model found at epoch 213 with validation loss 0.7202269434928894\n",
      "Starting Epoch 214\n",
      "0.7348872811897941\n",
      "Starting Epoch 215\n",
      "0.7342755068903384\n",
      "Starting Epoch 216\n",
      "0.7346075799154199\n",
      "New best model found at epoch 216 with validation loss 0.7201919555664062\n",
      "Starting Epoch 217\n",
      "0.7342467022978741\n",
      "Starting Epoch 218\n",
      "0.7355522435644398\n",
      "Starting Epoch 219\n",
      "0.7340232263440671\n",
      "New best model found at epoch 219 with validation loss 0.7194043397903442\n",
      "Starting Epoch 220\n",
      "0.7348252275715703\n",
      "Starting Epoch 221\n",
      "0.733666541783706\n",
      "Starting Epoch 222\n",
      "0.7345960243888523\n",
      "New best model found at epoch 222 with validation loss 0.7185615301132202\n",
      "Starting Epoch 223\n",
      "0.7333805301915044\n",
      "Starting Epoch 224\n",
      "0.7349884199059528\n",
      "Starting Epoch 225\n",
      "0.7334967255592346\n",
      "Starting Epoch 226\n",
      "0.731972424880318\n",
      "Starting Epoch 227\n",
      "0.7344426020332004\n",
      "New best model found at epoch 227 with validation loss 0.7185104489326477\n",
      "Starting Epoch 228\n",
      "0.7319087878517483\n",
      "Starting Epoch 229\n",
      "0.7324076735455057\n",
      "New best model found at epoch 229 with validation loss 0.7182204127311707\n",
      "Starting Epoch 230\n",
      "0.7344814927681632\n",
      "Starting Epoch 231\n",
      "0.7318690341451893\n",
      "New best model found at epoch 231 with validation loss 0.7180807590484619\n",
      "Starting Epoch 232\n",
      "0.7335573408914648\n",
      "Starting Epoch 233\n",
      "0.7340147547099901\n",
      "New best model found at epoch 233 with validation loss 0.7173014283180237\n",
      "Starting Epoch 234\n",
      "0.7311238905657893\n",
      "New best model found at epoch 234 with validation loss 0.7163873314857483\n",
      "Starting Epoch 235\n",
      "0.7319370067637899\n",
      "Starting Epoch 236\n",
      "0.7314009640527808\n",
      "Starting Epoch 237\n",
      "0.7330862516942231\n",
      "Starting Epoch 238\n",
      "0.7315604919972627\n",
      "Starting Epoch 239\n",
      "0.734331348667974\n",
      "Starting Epoch 240\n",
      "0.7324370690014051\n",
      "Starting Epoch 241\n",
      "0.7312791839889858\n",
      "New best model found at epoch 241 with validation loss 0.7160877585411072\n",
      "Starting Epoch 242\n",
      "0.7310421078101449\n",
      "Starting Epoch 243\n",
      "0.7301216851110044\n",
      "Starting Epoch 244\n",
      "0.7308272097421729\n",
      "New best model found at epoch 244 with validation loss 0.7150903940200806\n",
      "Starting Epoch 245\n",
      "0.7296613169753033\n",
      "Starting Epoch 246\n",
      "0.7309131907380145\n",
      "New best model found at epoch 246 with validation loss 0.7150506973266602\n",
      "Starting Epoch 247\n",
      "0.7311028397601583\n",
      "Starting Epoch 248\n",
      "0.7310749784759853\n",
      "New best model found at epoch 248 with validation loss 0.7147248983383179\n",
      "Starting Epoch 249\n",
      "0.7307378235070602\n",
      "New best model found at epoch 249 with validation loss 0.7145383954048157\n",
      "Starting Epoch 250\n",
      "0.7299127656480541\n",
      "Starting Epoch 251\n",
      "0.7295647522677546\n",
      "Starting Epoch 252\n",
      "0.7289190033207769\n",
      "Starting Epoch 253\n",
      "0.729825276395549\n",
      "New best model found at epoch 253 with validation loss 0.7144187688827515\n",
      "Starting Epoch 254\n",
      "0.729340576607248\n",
      "Starting Epoch 255\n",
      "0.7293882655060809\n",
      "New best model found at epoch 255 with validation loss 0.713505744934082\n",
      "Starting Epoch 256\n",
      "0.7321917699730914\n",
      "Starting Epoch 257\n",
      "0.7318149520003278\n",
      "Starting Epoch 258\n",
      "0.729625631933627\n",
      "Starting Epoch 259\n",
      "0.7277970650921697\n",
      "Starting Epoch 260\n",
      "0.728479071803715\n",
      "New best model found at epoch 260 with validation loss 0.7127870917320251\n",
      "Starting Epoch 261\n",
      "0.7286337173503378\n",
      "Starting Epoch 262\n",
      "0.7291457756705906\n",
      "Starting Epoch 263\n",
      "0.72854636285616\n",
      "Starting Epoch 264\n",
      "0.728931214498437\n",
      "Starting Epoch 265\n",
      "0.7293754116348599\n",
      "Starting Epoch 266\n",
      "0.7286174737888834\n",
      "New best model found at epoch 266 with validation loss 0.7125875949859619\n",
      "Starting Epoch 267\n",
      "0.7278616609780685\n",
      "New best model found at epoch 267 with validation loss 0.7123613953590393\n",
      "Starting Epoch 268\n",
      "0.7295994266219761\n",
      "Starting Epoch 269\n",
      "0.7299179175625676\n",
      "Starting Epoch 270\n",
      "0.7299851360528365\n",
      "Starting Epoch 271\n",
      "0.7288497064424597\n",
      "Starting Epoch 272\n",
      "0.7282512498938519\n",
      "New best model found at epoch 272 with validation loss 0.7122207880020142\n",
      "Starting Epoch 273\n",
      "0.7281349612318951\n",
      "Starting Epoch 274\n",
      "0.7300196419591489\n",
      "Starting Epoch 275\n",
      "0.7268118340036144\n",
      "Starting Epoch 276\n",
      "0.7272134863811991\n",
      "Starting Epoch 277\n",
      "0.7272035609120908\n",
      "New best model found at epoch 277 with validation loss 0.7117265462875366\n",
      "Starting Epoch 278\n",
      "0.7283473066661669\n",
      "Starting Epoch 279\n",
      "0.7282293620316879\n",
      "New best model found at epoch 279 with validation loss 0.7113949656486511\n",
      "Starting Epoch 280\n",
      "0.7278342843055725\n",
      "Starting Epoch 281\n",
      "0.7291596013566722\n",
      "Starting Epoch 282\n",
      "0.7270935773849487\n",
      "New best model found at epoch 282 with validation loss 0.7110856175422668\n",
      "Starting Epoch 283\n",
      "0.7271214879077413\n",
      "Starting Epoch 284\n",
      "0.7267767838809801\n",
      "Starting Epoch 285\n",
      "0.7277487334997758\n",
      "Starting Epoch 286\n",
      "0.7284828217133231\n",
      "Starting Epoch 287\n",
      "0.7286055813664976\n",
      "New best model found at epoch 287 with validation loss 0.7107038497924805\n",
      "Starting Epoch 288\n",
      "0.7272188507992289\n",
      "New best model found at epoch 288 with validation loss 0.710483968257904\n",
      "Starting Epoch 289\n",
      "0.7263546275055927\n",
      "Starting Epoch 290\n",
      "0.7281591477601425\n",
      "Starting Epoch 291\n",
      "0.7252493422964345\n",
      "Starting Epoch 292\n",
      "0.7266625606495402\n",
      "Starting Epoch 293\n",
      "0.7273049639618915\n",
      "Starting Epoch 294\n",
      "0.7283455962720125\n",
      "New best model found at epoch 294 with validation loss 0.7103422284126282\n",
      "Starting Epoch 295\n",
      "0.72727813668873\n",
      "Starting Epoch 296\n",
      "0.7286332275556482\n",
      "Starting Epoch 297\n",
      "0.7270054065662882\n",
      "New best model found at epoch 297 with validation loss 0.7096335291862488\n",
      "Starting Epoch 298\n",
      "0.7269959916239199\n",
      "New best model found at epoch 298 with validation loss 0.7095064520835876\n",
      "Starting Epoch 299\n",
      "0.7264855659526327\n",
      "New best model found at epoch 299 with validation loss 0.709184467792511\n",
      "Starting Epoch 300\n",
      "0.7261333050935165\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-10-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6f9b1",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 3, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 20 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1951e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "56cd3f01-4cc1-4ce1-9439-135b87ea7097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.1368726906569109\n",
      "New best model found at epoch 1 with validation loss 0.8727197647094727\n",
      "Starting Epoch 2\n",
      "0.8975292962530385\n",
      "New best model found at epoch 2 with validation loss 0.8335787653923035\n",
      "Starting Epoch 3\n",
      "0.8847028664920641\n",
      "New best model found at epoch 3 with validation loss 0.8174129724502563\n",
      "Starting Epoch 4\n",
      "0.868504506090413\n",
      "New best model found at epoch 4 with validation loss 0.8043999671936035\n",
      "Starting Epoch 5\n",
      "0.8536936614824377\n",
      "New best model found at epoch 5 with validation loss 0.7940356731414795\n",
      "Starting Epoch 6\n",
      "0.8369229435920715\n",
      "Starting Epoch 7\n",
      "0.8191681841145391\n",
      "New best model found at epoch 7 with validation loss 0.7589688897132874\n",
      "Starting Epoch 8\n",
      "0.8113778907319774\n",
      "Starting Epoch 9\n",
      "0.8009432191434114\n",
      "New best model found at epoch 9 with validation loss 0.7349103689193726\n",
      "Starting Epoch 10\n",
      "0.7959103169648544\n",
      "Starting Epoch 11\n",
      "0.7812006084815316\n",
      "New best model found at epoch 11 with validation loss 0.7346389293670654\n",
      "Starting Epoch 12\n",
      "0.7756414594857589\n",
      "New best model found at epoch 12 with validation loss 0.7144112586975098\n",
      "Starting Epoch 13\n",
      "0.7719612121582031\n",
      "New best model found at epoch 13 with validation loss 0.7111846804618835\n",
      "Starting Epoch 14\n",
      "0.7711535925450532\n",
      "Starting Epoch 15\n",
      "0.7601069652515909\n",
      "Starting Epoch 16\n",
      "0.7496957338374594\n",
      "New best model found at epoch 16 with validation loss 0.7091637849807739\n",
      "Starting Epoch 17\n",
      "0.7595975476762523\n",
      "Starting Epoch 18\n",
      "0.7470923532610354\n",
      "Starting Epoch 19\n",
      "0.7442162607027136\n",
      "New best model found at epoch 19 with validation loss 0.69296795129776\n",
      "Starting Epoch 20\n",
      "0.7418338319529658\n",
      "Starting Epoch 21\n",
      "0.7440266427786454\n",
      "New best model found at epoch 21 with validation loss 0.6861172914505005\n",
      "Starting Epoch 22\n",
      "0.7412762097690416\n",
      "Starting Epoch 23\n",
      "0.7362646356872891\n",
      "Starting Epoch 24\n",
      "0.7360458296278248\n",
      "Starting Epoch 25\n",
      "0.7465157768000728\n",
      "Starting Epoch 26\n",
      "0.7439639957054801\n",
      "New best model found at epoch 26 with validation loss 0.6812054514884949\n",
      "Starting Epoch 27\n",
      "0.7313688656558162\n",
      "Starting Epoch 28\n",
      "0.7299048693283744\n",
      "Starting Epoch 29\n",
      "0.7383698406426803\n",
      "Starting Epoch 30\n",
      "0.7319936752319336\n",
      "Starting Epoch 31\n",
      "0.7281142991522084\n",
      "Starting Epoch 32\n",
      "0.7334357163180476\n",
      "Starting Epoch 33\n",
      "0.7241992639458698\n",
      "Starting Epoch 34\n",
      "0.7274228852728138\n",
      "New best model found at epoch 34 with validation loss 0.6718060374259949\n",
      "Starting Epoch 35\n",
      "0.7231318199116251\n",
      "Starting Epoch 36\n",
      "0.7263541169788527\n",
      "Starting Epoch 37\n",
      "0.7269013057584348\n",
      "New best model found at epoch 37 with validation loss 0.6716234683990479\n",
      "Starting Epoch 38\n",
      "0.7265231402023978\n",
      "Starting Epoch 39\n",
      "0.7229736965635548\n",
      "Starting Epoch 40\n",
      "0.7218888738880986\n",
      "Starting Epoch 41\n",
      "0.721102686032005\n",
      "Starting Epoch 42\n",
      "0.7202552608821703\n",
      "Starting Epoch 43\n",
      "0.7220202995383221\n",
      "New best model found at epoch 43 with validation loss 0.670289158821106\n",
      "Starting Epoch 44\n",
      "0.7168480909388998\n",
      "New best model found at epoch 44 with validation loss 0.6693285703659058\n",
      "Starting Epoch 45\n",
      "0.7148932192636572\n",
      "Starting Epoch 46\n",
      "0.7148297480914904\n",
      "New best model found at epoch 46 with validation loss 0.6681422591209412\n",
      "Starting Epoch 47\n",
      "0.7136554070141005\n",
      "Starting Epoch 48\n",
      "0.7173789661863575\n",
      "New best model found at epoch 48 with validation loss 0.6646942496299744\n",
      "Starting Epoch 49\n",
      "0.7159876227378845\n",
      "Starting Epoch 50\n",
      "0.7164255562035934\n",
      "Starting Epoch 51\n",
      "0.7183014750480652\n",
      "Starting Epoch 52\n",
      "0.7151467074518618\n",
      "New best model found at epoch 52 with validation loss 0.6627106666564941\n",
      "Starting Epoch 53\n",
      "0.7133355788562609\n",
      "Starting Epoch 54\n",
      "0.7109486538430919\n",
      "Starting Epoch 55\n",
      "0.7130803828654082\n",
      "Starting Epoch 56\n",
      "0.7124280022538226\n",
      "Starting Epoch 57\n",
      "0.7100211589232736\n",
      "Starting Epoch 58\n",
      "0.711324603661247\n",
      "Starting Epoch 59\n",
      "0.7093778045281119\n",
      "Starting Epoch 60\n",
      "0.7121252909950588\n",
      "Starting Epoch 61\n",
      "0.714443590330041\n",
      "Starting Epoch 62\n",
      "0.7099794045738552\n",
      "Starting Epoch 63\n",
      "0.7108819951181826\n",
      "Starting Epoch 64\n",
      "0.7131140724472378\n",
      "Starting Epoch 65\n",
      "0.711246265017468\n",
      "Starting Epoch 66\n",
      "0.7093601900598278\n",
      "New best model found at epoch 66 with validation loss 0.6626355051994324\n",
      "Starting Epoch 67\n",
      "0.7067212151444476\n",
      "Starting Epoch 68\n",
      "0.7096682657366213\n",
      "Starting Epoch 69\n",
      "0.7072781453961912\n",
      "Starting Epoch 70\n",
      "0.7096525715745013\n",
      "Starting Epoch 71\n",
      "0.7101607918739319\n",
      "Starting Epoch 72\n",
      "0.7073783019314641\n",
      "New best model found at epoch 72 with validation loss 0.6619701981544495\n",
      "Starting Epoch 73\n",
      "0.7077779951302902\n",
      "New best model found at epoch 73 with validation loss 0.6573597192764282\n",
      "Starting Epoch 74\n",
      "0.7066966917203821\n",
      "Starting Epoch 75\n",
      "0.7082714542098667\n",
      "Starting Epoch 76\n",
      "0.7041799788889678\n",
      "Starting Epoch 77\n",
      "0.7056247773377792\n",
      "Starting Epoch 78\n",
      "0.7056509671003922\n",
      "Starting Epoch 79\n",
      "0.7015550162481226\n",
      "Starting Epoch 80\n",
      "0.7059948444366455\n",
      "Starting Epoch 81\n",
      "0.7038814347723256\n",
      "Starting Epoch 82\n",
      "0.706198821897092\n",
      "Starting Epoch 83\n",
      "0.7039836126825084\n",
      "Starting Epoch 84\n",
      "0.7050945085027943\n",
      "Starting Epoch 85\n",
      "0.7034544063651044\n",
      "Starting Epoch 86\n",
      "0.7034637694773467\n",
      "Starting Epoch 87\n",
      "0.7030152134273363\n",
      "New best model found at epoch 87 with validation loss 0.655280351638794\n",
      "Starting Epoch 88\n",
      "0.7013479756272357\n",
      "Starting Epoch 89\n",
      "0.7019645882689435\n",
      "Starting Epoch 90\n",
      "0.7066637381263401\n",
      "Starting Epoch 91\n",
      "0.7041147895481276\n",
      "Starting Epoch 92\n",
      "0.7024026409439419\n",
      "Starting Epoch 93\n",
      "0.7031832985256029\n",
      "Starting Epoch 94\n",
      "0.7065622365993002\n",
      "Starting Epoch 95\n",
      "0.7053151985873347\n",
      "Starting Epoch 96\n",
      "0.7021057398422904\n",
      "Starting Epoch 97\n",
      "0.7006266609482144\n",
      "Starting Epoch 98\n",
      "0.7004831303720889\n",
      "Starting Epoch 99\n",
      "0.7005305601202924\n",
      "Starting Epoch 100\n",
      "0.7008253387782885\n",
      "Starting Epoch 101\n",
      "0.6983317551405533\n",
      "Starting Epoch 102\n",
      "0.6989366567653158\n",
      "Starting Epoch 103\n",
      "0.7015564934067104\n",
      "Starting Epoch 104\n",
      "0.699999881827313\n",
      "Starting Epoch 105\n",
      "0.7013437255569126\n",
      "Starting Epoch 106\n",
      "0.7004722279051075\n",
      "Starting Epoch 107\n",
      "0.7023578908132471\n",
      "Starting Epoch 108\n",
      "0.701405203860739\n",
      "Starting Epoch 109\n",
      "0.6991968284482541\n",
      "Starting Epoch 110\n",
      "0.6992953575175741\n",
      "Starting Epoch 111\n",
      "0.6993175900500753\n",
      "Starting Epoch 112\n",
      "0.7009563653365426\n",
      "Starting Epoch 113\n",
      "0.6986777108648549\n",
      "Starting Epoch 114\n",
      "0.7019980161086373\n",
      "Starting Epoch 115\n",
      "0.6983863504036613\n",
      "Starting Epoch 116\n",
      "0.6972927347473477\n",
      "Starting Epoch 117\n",
      "0.6972012571666552\n",
      "Starting Epoch 118\n",
      "0.6966591581054355\n",
      "Starting Epoch 119\n",
      "0.6994905342226443\n",
      "Starting Epoch 120\n",
      "0.6974014043807983\n",
      "Starting Epoch 121\n",
      "0.6972511177477629\n",
      "New best model found at epoch 121 with validation loss 0.6545690298080444\n",
      "Starting Epoch 122\n",
      "0.6986263938572096\n",
      "New best model found at epoch 122 with validation loss 0.6543777585029602\n",
      "Starting Epoch 123\n",
      "0.6951900150464929\n",
      "New best model found at epoch 123 with validation loss 0.6538002490997314\n",
      "Starting Epoch 124\n",
      "0.699446976184845\n",
      "New best model found at epoch 124 with validation loss 0.6510345339775085\n",
      "Starting Epoch 125\n",
      "0.700303448283154\n",
      "Starting Epoch 126\n",
      "0.6968764740487804\n",
      "Starting Epoch 127\n",
      "0.6973587300466455\n",
      "Starting Epoch 128\n",
      "0.6960491563962854\n",
      "Starting Epoch 129\n",
      "0.6955456681873488\n",
      "Starting Epoch 130\n",
      "0.6975833151651465\n",
      "Starting Epoch 131\n",
      "0.6957623803097269\n",
      "Starting Epoch 132\n",
      "0.6945485498594202\n",
      "Starting Epoch 133\n",
      "0.6958435125972914\n",
      "Starting Epoch 134\n",
      "0.6958952183308809\n",
      "Starting Epoch 135\n",
      "0.6949917829555013\n",
      "Starting Epoch 136\n",
      "0.696635787901671\n",
      "Starting Epoch 137\n",
      "0.6925982470097749\n",
      "Starting Epoch 138\n",
      "0.6954787010731904\n",
      "Starting Epoch 139\n",
      "0.6939974453138269\n",
      "Starting Epoch 140\n",
      "0.6961042829181837\n",
      "Starting Epoch 141\n",
      "0.6935401947601981\n",
      "Starting Epoch 142\n",
      "0.6953427480614703\n",
      "Starting Epoch 143\n",
      "0.6945269626119862\n",
      "Starting Epoch 144\n",
      "0.6938971073731132\n",
      "Starting Epoch 145\n",
      "0.692575542823128\n",
      "Starting Epoch 146\n",
      "0.6933843441631483\n",
      "Starting Epoch 147\n",
      "0.6937996563704117\n",
      "Starting Epoch 148\n",
      "0.6915635233340056\n",
      "Starting Epoch 149\n",
      "0.6928147544031558\n",
      "Starting Epoch 150\n",
      "0.6920048905455548\n",
      "Starting Epoch 151\n",
      "0.6946050732032113\n",
      "Starting Epoch 152\n",
      "0.6957094513851664\n",
      "Starting Epoch 153\n",
      "0.6906970376553743\n",
      "New best model found at epoch 153 with validation loss 0.6494991779327393\n",
      "Starting Epoch 154\n",
      "0.695234793683757\n",
      "Starting Epoch 155\n",
      "0.6944785895554916\n",
      "Starting Epoch 156\n",
      "0.6919397167537523\n",
      "Starting Epoch 157\n",
      "0.6905302560847738\n",
      "Starting Epoch 158\n",
      "0.6908348824666894\n",
      "New best model found at epoch 158 with validation loss 0.6493293046951294\n",
      "Starting Epoch 159\n",
      "0.6945152049479277\n",
      "Starting Epoch 160\n",
      "0.6929788330326909\n",
      "Starting Epoch 161\n",
      "0.6924690163653829\n",
      "Starting Epoch 162\n",
      "0.6916098516920338\n",
      "Starting Epoch 163\n",
      "0.6919536642406298\n",
      "Starting Epoch 164\n",
      "0.6922916096189747\n",
      "Starting Epoch 165\n",
      "0.690896995689558\n",
      "Starting Epoch 166\n",
      "0.6911684196928273\n",
      "Starting Epoch 167\n",
      "0.6907952324203823\n",
      "New best model found at epoch 167 with validation loss 0.6491591930389404\n",
      "Starting Epoch 168\n",
      "0.6914165227309518\n",
      "Starting Epoch 169\n",
      "0.690790031267249\n",
      "Starting Epoch 170\n",
      "0.6931769510974055\n",
      "Starting Epoch 171\n",
      "0.689356980116471\n",
      "New best model found at epoch 171 with validation loss 0.6490135192871094\n",
      "Starting Epoch 172\n",
      "0.6913441834242448\n",
      "Starting Epoch 173\n",
      "0.6897911092509394\n",
      "New best model found at epoch 173 with validation loss 0.6478623747825623\n",
      "Starting Epoch 174\n",
      "0.6887854078541631\n",
      "Starting Epoch 175\n",
      "0.6918856501579285\n",
      "Starting Epoch 176\n",
      "0.689503330251445\n",
      "Starting Epoch 177\n",
      "0.6910473186036815\n",
      "Starting Epoch 178\n",
      "0.6940944764925085\n",
      "Starting Epoch 179\n",
      "0.6889680572178053\n",
      "Starting Epoch 180\n",
      "0.6887402301249297\n",
      "Starting Epoch 181\n",
      "0.690994584042093\n",
      "Starting Epoch 182\n",
      "0.6913395524024963\n",
      "Starting Epoch 183\n",
      "0.6899477269338525\n",
      "Starting Epoch 184\n",
      "0.6891014446382937\n",
      "Starting Epoch 185\n",
      "0.6891959542813508\n",
      "Starting Epoch 186\n",
      "0.6895803264949633\n",
      "Starting Epoch 187\n",
      "0.6935991152473118\n",
      "Starting Epoch 188\n",
      "0.6907606565434\n",
      "Starting Epoch 189\n",
      "0.6889688864998196\n",
      "New best model found at epoch 189 with validation loss 0.6475298404693604\n",
      "Starting Epoch 190\n",
      "0.689251518767813\n",
      "Starting Epoch 191\n",
      "0.6899079991423566\n",
      "New best model found at epoch 191 with validation loss 0.6467037796974182\n",
      "Starting Epoch 192\n",
      "0.6892164245895718\n",
      "Starting Epoch 193\n",
      "0.6870086737301039\n",
      "New best model found at epoch 193 with validation loss 0.6465200781822205\n",
      "Starting Epoch 194\n",
      "0.6896156435427458\n",
      "Starting Epoch 195\n",
      "0.6877027309459188\n",
      "Starting Epoch 196\n",
      "0.6871418641961139\n",
      "Starting Epoch 197\n",
      "0.6881146171818608\n",
      "New best model found at epoch 197 with validation loss 0.645566463470459\n",
      "Starting Epoch 198\n",
      "0.6892894895180411\n",
      "Starting Epoch 199\n",
      "0.6905215849047122\n",
      "Starting Epoch 200\n",
      "0.6883970602698948\n",
      "Starting Epoch 201\n",
      "0.6875911717829497\n",
      "Starting Epoch 202\n",
      "0.6904257354529008\n",
      "Starting Epoch 203\n",
      "0.6875313028045322\n",
      "Starting Epoch 204\n",
      "0.6884057962376139\n",
      "Starting Epoch 205\n",
      "0.6912216414575991\n",
      "Starting Epoch 206\n",
      "0.6881694223569788\n",
      "New best model found at epoch 206 with validation loss 0.6445091962814331\n",
      "Starting Epoch 207\n",
      "0.689400711785192\n",
      "Starting Epoch 208\n",
      "0.6878284682398257\n",
      "Starting Epoch 209\n",
      "0.6891917093940403\n",
      "Starting Epoch 210\n",
      "0.6872117104737655\n",
      "Starting Epoch 211\n",
      "0.689517187035602\n",
      "Starting Epoch 212\n",
      "0.6881121345188307\n",
      "Starting Epoch 213\n",
      "0.6866708682930988\n",
      "Starting Epoch 214\n",
      "0.6881104500397391\n",
      "Starting Epoch 215\n",
      "0.6853532428326814\n",
      "Starting Epoch 216\n",
      "0.6889606843823972\n",
      "Starting Epoch 217\n",
      "0.6870928303055142\n",
      "Starting Epoch 218\n",
      "0.6871802262637926\n",
      "Starting Epoch 219\n",
      "0.6868851288505222\n",
      "Starting Epoch 220\n",
      "0.6892391624658004\n",
      "Starting Epoch 221\n",
      "0.6893981487854667\n",
      "Starting Epoch 222\n",
      "0.6881919891937919\n",
      "Starting Epoch 223\n",
      "0.6860016610311426\n",
      "Starting Epoch 224\n",
      "0.689723393191462\n",
      "Starting Epoch 225\n",
      "0.687271667563397\n",
      "Starting Epoch 226\n",
      "0.6869405119315438\n",
      "Starting Epoch 227\n",
      "0.6850978628448818\n",
      "Starting Epoch 228\n",
      "0.6868979464406553\n",
      "Starting Epoch 229\n",
      "0.686378230219302\n",
      "Starting Epoch 230\n",
      "0.6881603235783784\n",
      "New best model found at epoch 230 with validation loss 0.6423397064208984\n",
      "Starting Epoch 231\n",
      "0.6858128723890885\n",
      "Starting Epoch 232\n",
      "0.6858698647955189\n",
      "Starting Epoch 233\n",
      "0.6888917580894802\n",
      "Starting Epoch 234\n",
      "0.6875868802485259\n",
      "Starting Epoch 235\n",
      "0.6865342052086539\n",
      "Starting Epoch 236\n",
      "0.686336768710095\n",
      "Starting Epoch 237\n",
      "0.6863727077193882\n",
      "Starting Epoch 238\n",
      "0.6857250177341959\n",
      "Starting Epoch 239\n",
      "0.6842649216237275\n",
      "Starting Epoch 240\n",
      "0.688159660152767\n",
      "Starting Epoch 241\n",
      "0.6859616455824479\n",
      "Starting Epoch 242\n",
      "0.6838263739710269\n",
      "Starting Epoch 243\n",
      "0.6855912986009017\n",
      "Starting Epoch 244\n",
      "0.6864534746045652\n",
      "Starting Epoch 245\n",
      "0.6855054679124252\n",
      "Starting Epoch 246\n",
      "0.685356458891993\n",
      "Starting Epoch 247\n",
      "0.6825368197067924\n",
      "Starting Epoch 248\n",
      "0.6843298544054446\n",
      "Starting Epoch 249\n",
      "0.6836547644241996\n",
      "Starting Epoch 250\n",
      "0.6868738868962163\n",
      "Starting Epoch 251\n",
      "0.6834108414857284\n",
      "Starting Epoch 252\n",
      "0.6867364385853643\n",
      "Starting Epoch 253\n",
      "0.6843265087708182\n",
      "Starting Epoch 254\n",
      "0.6853958368301392\n",
      "New best model found at epoch 254 with validation loss 0.6422841548919678\n",
      "Starting Epoch 255\n",
      "0.6834302518678748\n",
      "Starting Epoch 256\n",
      "0.6853978893031245\n",
      "Starting Epoch 257\n",
      "0.6868130901585454\n",
      "Starting Epoch 258\n",
      "0.6854074908339459\n",
      "Starting Epoch 259\n",
      "0.6857355910798778\n",
      "Starting Epoch 260\n",
      "0.6850872428520866\n",
      "Starting Epoch 261\n",
      "0.6845193142476289\n",
      "Starting Epoch 262\n",
      "0.6824782827626104\n",
      "Starting Epoch 263\n",
      "0.6834894107735675\n",
      "New best model found at epoch 263 with validation loss 0.6422815322875977\n",
      "Starting Epoch 264\n",
      "0.6833136263100997\n",
      "Starting Epoch 265\n",
      "0.683272773804872\n",
      "New best model found at epoch 265 with validation loss 0.6420617699623108\n",
      "Starting Epoch 266\n",
      "0.6848790723344554\n",
      "Starting Epoch 267\n",
      "0.6862242325492527\n",
      "Starting Epoch 268\n",
      "0.6827614799789761\n",
      "New best model found at epoch 268 with validation loss 0.6406103372573853\n",
      "Starting Epoch 269\n",
      "0.6837833627410557\n",
      "Starting Epoch 270\n",
      "0.6828514648520428\n",
      "Starting Epoch 271\n",
      "0.6826551064201023\n",
      "Starting Epoch 272\n",
      "0.6855502491411956\n",
      "Starting Epoch 273\n",
      "0.6825596638347792\n",
      "New best model found at epoch 273 with validation loss 0.6404274106025696\n",
      "Starting Epoch 274\n",
      "0.6819282977477364\n",
      "Starting Epoch 275\n",
      "0.6843928046848463\n",
      "Starting Epoch 276\n",
      "0.6830672595811926\n",
      "Starting Epoch 277\n",
      "0.6811840119569198\n",
      "Starting Epoch 278\n",
      "0.6848197890364606\n",
      "Starting Epoch 279\n",
      "0.683487998402637\n",
      "Starting Epoch 280\n",
      "0.6824919374092765\n",
      "Starting Epoch 281\n",
      "0.6846322132193524\n",
      "Starting Epoch 282\n",
      "0.6825012979300126\n",
      "Starting Epoch 283\n",
      "0.6831801455953846\n",
      "Starting Epoch 284\n",
      "0.6820341011752253\n",
      "Starting Epoch 285\n",
      "0.6829167008399963\n",
      "Starting Epoch 286\n",
      "0.683015183262203\n",
      "Starting Epoch 287\n",
      "0.683994067751843\n",
      "Starting Epoch 288\n",
      "0.682700805042101\n",
      "Starting Epoch 289\n",
      "0.6809740610744642\n",
      "Starting Epoch 290\n",
      "0.6836852897768435\n",
      "Starting Epoch 291\n",
      "0.6813551653986392\n",
      "Starting Epoch 292\n",
      "0.6824946714484174\n",
      "Starting Epoch 293\n",
      "0.6834234076997509\n",
      "Starting Epoch 294\n",
      "0.6818294240080792\n",
      "Starting Epoch 295\n",
      "0.6817208476688551\n",
      "Starting Epoch 296\n",
      "0.6819010636080867\n",
      "Starting Epoch 297\n",
      "0.6818712716517241\n",
      "New best model found at epoch 297 with validation loss 0.6401060819625854\n",
      "Starting Epoch 298\n",
      "0.6822603474492612\n",
      "Starting Epoch 299\n",
      "0.6816379531570103\n",
      "New best model found at epoch 299 with validation loss 0.6392145752906799\n",
      "Starting Epoch 300\n",
      "0.6834226924440135\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "583b7d2e-da52-42ad-a7ee-91c2bb011721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.2771871038105176\n",
      "New best model found at epoch 1 with validation loss 1.0446850061416626\n",
      "Starting Epoch 2\n",
      "1.0348173094832378\n",
      "New best model found at epoch 2 with validation loss 1.0322349071502686\n",
      "Starting Epoch 3\n",
      "1.0286675691604614\n",
      "New best model found at epoch 3 with validation loss 1.0222111940383911\n",
      "Starting Epoch 4\n",
      "1.0243751225264177\n",
      "Starting Epoch 5\n",
      "1.02055301355279\n",
      "New best model found at epoch 5 with validation loss 1.0121690034866333\n",
      "Starting Epoch 6\n",
      "1.016860560230587\n",
      "New best model found at epoch 6 with validation loss 1.0058214664459229\n",
      "Starting Epoch 7\n",
      "1.014433889285378\n",
      "New best model found at epoch 7 with validation loss 1.0046544075012207\n",
      "Starting Epoch 8\n",
      "1.0133024998333142\n",
      "New best model found at epoch 8 with validation loss 1.0012565851211548\n",
      "Starting Epoch 9\n",
      "1.009047552295353\n",
      "New best model found at epoch 9 with validation loss 0.994943380355835\n",
      "Starting Epoch 10\n",
      "1.0045325885648313\n",
      "New best model found at epoch 10 with validation loss 0.9920883774757385\n",
      "Starting Epoch 11\n",
      "1.0005064606666565\n",
      "New best model found at epoch 11 with validation loss 0.9838501214981079\n",
      "Starting Epoch 12\n",
      "0.9948193845541581\n",
      "New best model found at epoch 12 with validation loss 0.9815972447395325\n",
      "Starting Epoch 13\n",
      "0.9895293194314708\n",
      "New best model found at epoch 13 with validation loss 0.9814399480819702\n",
      "Starting Epoch 14\n",
      "0.9886808550876119\n",
      "New best model found at epoch 14 with validation loss 0.9744330048561096\n",
      "Starting Epoch 15\n",
      "0.9842955003614011\n",
      "New best model found at epoch 15 with validation loss 0.9710346460342407\n",
      "Starting Epoch 16\n",
      "0.9802244927572168\n",
      "Starting Epoch 17\n",
      "0.9788050599720167\n",
      "New best model found at epoch 17 with validation loss 0.9631448984146118\n",
      "Starting Epoch 18\n",
      "0.9732022129971049\n",
      "New best model found at epoch 18 with validation loss 0.9601775407791138\n",
      "Starting Epoch 19\n",
      "0.9686193828997405\n",
      "New best model found at epoch 19 with validation loss 0.9560037851333618\n",
      "Starting Epoch 20\n",
      "0.9634197043335956\n",
      "Starting Epoch 21\n",
      "0.9623143647028052\n",
      "Starting Epoch 22\n",
      "0.9590170435283495\n",
      "New best model found at epoch 22 with validation loss 0.9528616666793823\n",
      "Starting Epoch 23\n",
      "0.957375363163326\n",
      "Starting Epoch 24\n",
      "0.9555462028669275\n",
      "New best model found at epoch 24 with validation loss 0.9442771673202515\n",
      "Starting Epoch 25\n",
      "0.9528912383577098\n",
      "Starting Epoch 26\n",
      "0.9509748531424481\n",
      "New best model found at epoch 26 with validation loss 0.9405876398086548\n",
      "Starting Epoch 27\n",
      "0.9469789422076681\n",
      "Starting Epoch 28\n",
      "0.9467733113662057\n",
      "New best model found at epoch 28 with validation loss 0.9398024678230286\n",
      "Starting Epoch 29\n",
      "0.9445792980816053\n",
      "New best model found at epoch 29 with validation loss 0.9369682669639587\n",
      "Starting Epoch 30\n",
      "0.9436838212220565\n",
      "Starting Epoch 31\n",
      "0.9403257784636124\n",
      "New best model found at epoch 31 with validation loss 0.9365646243095398\n",
      "Starting Epoch 32\n",
      "0.9408717259116794\n",
      "New best model found at epoch 32 with validation loss 0.9341484308242798\n",
      "Starting Epoch 33\n",
      "0.9381194296090499\n",
      "Starting Epoch 34\n",
      "0.9354475218316783\n",
      "New best model found at epoch 34 with validation loss 0.9321510791778564\n",
      "Starting Epoch 35\n",
      "0.9332234729891238\n",
      "New best model found at epoch 35 with validation loss 0.9317949414253235\n",
      "Starting Epoch 36\n",
      "0.9357329477434573\n",
      "New best model found at epoch 36 with validation loss 0.9311935305595398\n",
      "Starting Epoch 37\n",
      "0.9325275680293208\n",
      "New best model found at epoch 37 with validation loss 0.9276477098464966\n",
      "Starting Epoch 38\n",
      "0.9309255325275919\n",
      "Starting Epoch 39\n",
      "0.927351036797399\n",
      "Starting Epoch 40\n",
      "0.9254447558651799\n",
      "Starting Epoch 41\n",
      "0.9268706181774968\n",
      "Starting Epoch 42\n",
      "0.9257683831712474\n",
      "New best model found at epoch 42 with validation loss 0.9267915487289429\n",
      "Starting Epoch 43\n",
      "0.9260767102241516\n",
      "Starting Epoch 44\n",
      "0.9234308185784713\n",
      "Starting Epoch 45\n",
      "0.9192225518433944\n",
      "Starting Epoch 46\n",
      "0.9195440748463506\n",
      "New best model found at epoch 46 with validation loss 0.9261465072631836\n",
      "Starting Epoch 47\n",
      "0.9185518104097118\n",
      "Starting Epoch 48\n",
      "0.916863853516786\n",
      "New best model found at epoch 48 with validation loss 0.9233583807945251\n",
      "Starting Epoch 49\n",
      "0.9145402986070384\n",
      "Starting Epoch 50\n",
      "0.9132350527721903\n",
      "Starting Epoch 51\n",
      "0.9141450057859006\n",
      "Starting Epoch 52\n",
      "0.9119826477506886\n",
      "New best model found at epoch 52 with validation loss 0.9223529100418091\n",
      "Starting Epoch 53\n",
      "0.9110501849133036\n",
      "Starting Epoch 54\n",
      "0.9096734808838886\n",
      "New best model found at epoch 54 with validation loss 0.9188746809959412\n",
      "Starting Epoch 55\n",
      "0.9093428331872692\n",
      "Starting Epoch 56\n",
      "0.9089626307072847\n",
      "Starting Epoch 57\n",
      "0.9054390580757804\n",
      "Starting Epoch 58\n",
      "0.9044405273769213\n",
      "Starting Epoch 59\n",
      "0.9048789299052694\n",
      "New best model found at epoch 59 with validation loss 0.9175798892974854\n",
      "Starting Epoch 60\n",
      "0.903198602406875\n",
      "Starting Epoch 61\n",
      "0.9024286036906035\n",
      "New best model found at epoch 61 with validation loss 0.9166501760482788\n",
      "Starting Epoch 62\n",
      "0.900128494138303\n",
      "Starting Epoch 63\n",
      "0.8985408129899398\n",
      "New best model found at epoch 63 with validation loss 0.9142882823944092\n",
      "Starting Epoch 64\n",
      "0.900472148605015\n",
      "Starting Epoch 65\n",
      "0.8947518830714019\n",
      "Starting Epoch 66\n",
      "0.8934772118278171\n",
      "New best model found at epoch 66 with validation loss 0.911530077457428\n",
      "Starting Epoch 67\n",
      "0.8906673685364102\n",
      "Starting Epoch 68\n",
      "0.8913484734037648\n",
      "Starting Epoch 69\n",
      "0.8900928523229517\n",
      "Starting Epoch 70\n",
      "0.8880984705427418\n",
      "Starting Epoch 71\n",
      "0.8893607958503391\n",
      "Starting Epoch 72\n",
      "0.8876041225765062\n",
      "Starting Epoch 73\n",
      "0.8842845481374989\n",
      "Starting Epoch 74\n",
      "0.8860784276672031\n",
      "Starting Epoch 75\n",
      "0.8857640960942144\n",
      "Starting Epoch 76\n",
      "0.8843489496604257\n",
      "New best model found at epoch 76 with validation loss 0.9073225855827332\n",
      "Starting Epoch 77\n",
      "0.8808346831280253\n",
      "Starting Epoch 78\n",
      "0.8796684975209443\n",
      "Starting Epoch 79\n",
      "0.8812830137169879\n",
      "Starting Epoch 80\n",
      "0.883779007455577\n",
      "Starting Epoch 81\n",
      "0.8804210398508154\n",
      "Starting Epoch 82\n",
      "0.8803876275601594\n",
      "Starting Epoch 83\n",
      "0.8781164677246757\n",
      "Starting Epoch 84\n",
      "0.8777764672818391\n",
      "Starting Epoch 85\n",
      "0.8803063268246858\n",
      "Starting Epoch 86\n",
      "0.8773809230845907\n",
      "Starting Epoch 87\n",
      "0.8787240956140601\n",
      "Starting Epoch 88\n",
      "0.8775255058122717\n",
      "Starting Epoch 89\n",
      "0.8756561279296875\n",
      "Starting Epoch 90\n",
      "0.8757378381231556\n",
      "Starting Epoch 91\n",
      "0.8754476464313009\n",
      "Starting Epoch 92\n",
      "0.8749241828918457\n",
      "Starting Epoch 93\n",
      "0.8750040582988573\n",
      "New best model found at epoch 93 with validation loss 0.9073108434677124\n",
      "Starting Epoch 94\n",
      "0.8752321082612743\n",
      "New best model found at epoch 94 with validation loss 0.9044054746627808\n",
      "Starting Epoch 95\n",
      "0.875124076138372\n",
      "Starting Epoch 96\n",
      "0.8719536921252375\n",
      "Starting Epoch 97\n",
      "0.872780978679657\n",
      "Starting Epoch 98\n",
      "0.8712477554445681\n",
      "Starting Epoch 99\n",
      "0.8742879629135132\n",
      "Starting Epoch 100\n",
      "0.8714364741159522\n",
      "Starting Epoch 101\n",
      "0.8705527808355249\n",
      "Starting Epoch 102\n",
      "0.8708514493444691\n",
      "Starting Epoch 103\n",
      "0.8712934903476549\n",
      "New best model found at epoch 103 with validation loss 0.9035277366638184\n",
      "Starting Epoch 104\n",
      "0.8720295066418855\n",
      "New best model found at epoch 104 with validation loss 0.9034342765808105\n",
      "Starting Epoch 105\n",
      "0.8712648619776187\n",
      "Starting Epoch 106\n",
      "0.8704190228296362\n",
      "Starting Epoch 107\n",
      "0.8708231060401254\n",
      "New best model found at epoch 107 with validation loss 0.8992125988006592\n",
      "Starting Epoch 108\n",
      "0.8703108948210011\n",
      "Starting Epoch 109\n",
      "0.8692117540732675\n",
      "New best model found at epoch 109 with validation loss 0.8984911441802979\n",
      "Starting Epoch 110\n",
      "0.8678741688313691\n",
      "Starting Epoch 111\n",
      "0.8682331002276876\n",
      "Starting Epoch 112\n",
      "0.86807054799536\n",
      "Starting Epoch 113\n",
      "0.8703818891359412\n",
      "New best model found at epoch 113 with validation loss 0.8966444134712219\n",
      "Starting Epoch 114\n",
      "0.8675659946773363\n",
      "Starting Epoch 115\n",
      "0.8668532889822255\n",
      "Starting Epoch 116\n",
      "0.8670572560766469\n",
      "Starting Epoch 117\n",
      "0.866921709931415\n",
      "Starting Epoch 118\n",
      "0.8644227489181187\n",
      "Starting Epoch 119\n",
      "0.8658047759014628\n",
      "New best model found at epoch 119 with validation loss 0.8947494626045227\n",
      "Starting Epoch 120\n",
      "0.86505679462267\n",
      "New best model found at epoch 120 with validation loss 0.8942123651504517\n",
      "Starting Epoch 121\n",
      "0.8674844477487647\n",
      "New best model found at epoch 121 with validation loss 0.8899198174476624\n",
      "Starting Epoch 122\n",
      "0.86526750481647\n",
      "Starting Epoch 123\n",
      "0.8620137390883073\n",
      "Starting Epoch 124\n",
      "0.8647972526757614\n",
      "Starting Epoch 125\n",
      "0.8657309283380923\n",
      "Starting Epoch 126\n",
      "0.8637383398802384\n",
      "Starting Epoch 127\n",
      "0.8625804704168568\n",
      "Starting Epoch 128\n",
      "0.8640063042226045\n",
      "Starting Epoch 129\n",
      "0.8610581418742305\n",
      "Starting Epoch 130\n",
      "0.8624322984529578\n",
      "New best model found at epoch 130 with validation loss 0.8888275623321533\n",
      "Starting Epoch 131\n",
      "0.8618886159813922\n",
      "Starting Epoch 132\n",
      "0.8597947307254957\n",
      "Starting Epoch 133\n",
      "0.8590707493864972\n",
      "Starting Epoch 134\n",
      "0.8608339636222176\n",
      "Starting Epoch 135\n",
      "0.8619992499766143\n",
      "Starting Epoch 136\n",
      "0.8603869598844777\n",
      "Starting Epoch 137\n",
      "0.8588190467461295\n",
      "Starting Epoch 138\n",
      "0.8611374160517817\n",
      "Starting Epoch 139\n",
      "0.8591038403303727\n",
      "Starting Epoch 140\n",
      "0.8630789803422015\n",
      "Starting Epoch 141\n",
      "0.8589678303055142\n",
      "New best model found at epoch 141 with validation loss 0.8863808512687683\n",
      "Starting Epoch 142\n",
      "0.8600026628245478\n",
      "Starting Epoch 143\n",
      "0.8583226359408834\n",
      "Starting Epoch 144\n",
      "0.8606174043987108\n",
      "Starting Epoch 145\n",
      "0.8587591492611429\n",
      "Starting Epoch 146\n",
      "0.8603597672089286\n",
      "Starting Epoch 147\n",
      "0.8597878036291703\n",
      "Starting Epoch 148\n",
      "0.8595719207888064\n",
      "Starting Epoch 149\n",
      "0.8588935214540233\n",
      "Starting Epoch 150\n",
      "0.8582916156105374\n",
      "Starting Epoch 151\n",
      "0.8591194386067598\n",
      "Starting Epoch 152\n",
      "0.8585493694181028\n",
      "New best model found at epoch 152 with validation loss 0.8863592147827148\n",
      "Starting Epoch 153\n",
      "0.8594978373983632\n",
      "New best model found at epoch 153 with validation loss 0.8862327337265015\n",
      "Starting Epoch 154\n",
      "0.8609526105549025\n",
      "Starting Epoch 155\n",
      "0.8575247448423634\n",
      "Starting Epoch 156\n",
      "0.8564700950746951\n",
      "Starting Epoch 157\n",
      "0.8556262954421665\n",
      "Starting Epoch 158\n",
      "0.8548642604247384\n",
      "New best model found at epoch 158 with validation loss 0.8842541575431824\n",
      "Starting Epoch 159\n",
      "0.8608643568080404\n",
      "Starting Epoch 160\n",
      "0.8574307871901471\n",
      "Starting Epoch 161\n",
      "0.8578092093053071\n",
      "Starting Epoch 162\n",
      "0.8558541329010673\n",
      "Starting Epoch 163\n",
      "0.8559218852416329\n",
      "Starting Epoch 164\n",
      "0.8543629257575326\n",
      "Starting Epoch 165\n",
      "0.858213502427806\n",
      "Starting Epoch 166\n",
      "0.8577510273974874\n",
      "Starting Epoch 167\n",
      "0.8564270968022554\n",
      "Starting Epoch 168\n",
      "0.8575038547101228\n",
      "Starting Epoch 169\n",
      "0.8558699359064517\n",
      "Starting Epoch 170\n",
      "0.8577323892842168\n",
      "Starting Epoch 171\n",
      "0.8562529294387154\n",
      "Starting Epoch 172\n",
      "0.8560539613599363\n",
      "New best model found at epoch 172 with validation loss 0.8826059103012085\n",
      "Starting Epoch 173\n",
      "0.8530685227850209\n",
      "Starting Epoch 174\n",
      "0.8564758922742761\n",
      "Starting Epoch 175\n",
      "0.8554340523222218\n",
      "Starting Epoch 176\n",
      "0.8570926811384119\n",
      "Starting Epoch 177\n",
      "0.856575248034104\n",
      "Starting Epoch 178\n",
      "0.8586195422255475\n",
      "Starting Epoch 179\n",
      "0.8540716482245404\n",
      "Starting Epoch 180\n",
      "0.8552065673081771\n",
      "Starting Epoch 181\n",
      "0.8546630144119263\n",
      "Starting Epoch 182\n",
      "0.8539158468661101\n",
      "Starting Epoch 183\n",
      "0.8548685104950614\n",
      "Starting Epoch 184\n",
      "0.8573091315186542\n",
      "Starting Epoch 185\n",
      "0.8547428639038749\n",
      "Starting Epoch 186\n",
      "0.8528371453285217\n",
      "Starting Epoch 187\n",
      "0.8556084658788599\n",
      "Starting Epoch 188\n",
      "0.8541721779367198\n",
      "Starting Epoch 189\n",
      "0.855051584865736\n",
      "Starting Epoch 190\n",
      "0.8542146786399509\n",
      "Starting Epoch 191\n",
      "0.8543017791665118\n",
      "Starting Epoch 192\n",
      "0.8547542172929515\n",
      "Starting Epoch 193\n",
      "0.8524142866549285\n",
      "Starting Epoch 194\n",
      "0.8546491446702377\n",
      "Starting Epoch 195\n",
      "0.853671001351398\n",
      "Starting Epoch 196\n",
      "0.8522889018058777\n",
      "Starting Epoch 197\n",
      "0.8522807644761127\n",
      "Starting Epoch 198\n",
      "0.8558343856231027\n",
      "Starting Epoch 199\n",
      "0.8545034864674443\n",
      "Starting Epoch 200\n",
      "0.8547409435977107\n",
      "Starting Epoch 201\n",
      "0.8535335815471151\n",
      "Starting Epoch 202\n",
      "0.8546496215073959\n",
      "Starting Epoch 203\n",
      "0.8513391717620518\n",
      "Starting Epoch 204\n",
      "0.8539381649183191\n",
      "Starting Epoch 205\n",
      "0.8550104835759038\n",
      "Starting Epoch 206\n",
      "0.853412794030231\n",
      "Starting Epoch 207\n",
      "0.8534259692482327\n",
      "Starting Epoch 208\n",
      "0.8527129914449609\n",
      "Starting Epoch 209\n",
      "0.8536256033441295\n",
      "Starting Epoch 210\n",
      "0.8521397994912189\n",
      "Starting Epoch 211\n",
      "0.8533820872721465\n",
      "Starting Epoch 212\n",
      "0.8536962452142135\n",
      "Starting Epoch 213\n",
      "0.8535241329151652\n",
      "Starting Epoch 214\n",
      "0.852017923541691\n",
      "Starting Epoch 215\n",
      "0.8534658603046251\n",
      "Starting Epoch 216\n",
      "0.8525261438411215\n",
      "New best model found at epoch 216 with validation loss 0.8810847997665405\n",
      "Starting Epoch 217\n",
      "0.8525160084600034\n",
      "Starting Epoch 218\n",
      "0.854294258615245\n",
      "Starting Epoch 219\n",
      "0.8544745056525521\n",
      "Starting Epoch 220\n",
      "0.8529588683791782\n",
      "Starting Epoch 221\n",
      "0.8518735714580702\n",
      "Starting Epoch 222\n",
      "0.8533830305804377\n",
      "Starting Epoch 223\n",
      "0.8484594899675121\n",
      "Starting Epoch 224\n",
      "0.8528722654218259\n",
      "Starting Epoch 225\n",
      "0.8534442315930906\n",
      "Starting Epoch 226\n",
      "0.8523758986721868\n",
      "Starting Epoch 227\n",
      "0.8516753626906354\n",
      "Starting Epoch 228\n",
      "0.8509658212247102\n",
      "Starting Epoch 229\n",
      "0.8506961413051771\n",
      "Starting Epoch 230\n",
      "0.8520493896111198\n",
      "New best model found at epoch 230 with validation loss 0.88048255443573\n",
      "Starting Epoch 231\n",
      "0.8525902266087739\n",
      "Starting Epoch 232\n",
      "0.8524404712345289\n",
      "Starting Epoch 233\n",
      "0.8536307993142501\n",
      "Starting Epoch 234\n",
      "0.8526235041411027\n",
      "Starting Epoch 235\n",
      "0.8526512513989988\n",
      "Starting Epoch 236\n",
      "0.8521019038946732\n",
      "Starting Epoch 237\n",
      "0.8509409116662067\n",
      "Starting Epoch 238\n",
      "0.8505980346513831\n",
      "Starting Epoch 239\n",
      "0.8501357410265051\n",
      "Starting Epoch 240\n",
      "0.8531390791353972\n",
      "Starting Epoch 241\n",
      "0.8540439890778583\n",
      "Starting Epoch 242\n",
      "0.8502971348555192\n",
      "Starting Epoch 243\n",
      "0.851023598857548\n",
      "Starting Epoch 244\n",
      "0.8515332911325537\n",
      "Starting Epoch 245\n",
      "0.8501459515613058\n",
      "Starting Epoch 246\n",
      "0.8517060642657073\n",
      "Starting Epoch 247\n",
      "0.849800599657971\n",
      "Starting Epoch 248\n",
      "0.8527566894241001\n",
      "Starting Epoch 249\n",
      "0.8488232311995133\n",
      "Starting Epoch 250\n",
      "0.8496782624203226\n",
      "Starting Epoch 251\n",
      "0.8487477846767592\n",
      "Starting Epoch 252\n",
      "0.8522885856421097\n",
      "Starting Epoch 253\n",
      "0.8522075103676837\n",
      "Starting Epoch 254\n",
      "0.8499017487401548\n",
      "Starting Epoch 255\n",
      "0.8488172474114791\n",
      "Starting Epoch 256\n",
      "0.8511300579361294\n",
      "Starting Epoch 257\n",
      "0.8501030232595361\n",
      "Starting Epoch 258\n",
      "0.8491054643755374\n",
      "Starting Epoch 259\n",
      "0.8495437165965205\n",
      "Starting Epoch 260\n",
      "0.850107086741406\n",
      "New best model found at epoch 260 with validation loss 0.8803020715713501\n",
      "Starting Epoch 261\n",
      "0.8502288875372513\n",
      "Starting Epoch 262\n",
      "0.8494408104730689\n",
      "Starting Epoch 263\n",
      "0.8505126289699388\n",
      "Starting Epoch 264\n",
      "0.8486136794090271\n",
      "Starting Epoch 265\n",
      "0.8505494231763093\n",
      "Starting Epoch 266\n",
      "0.8495209424392037\n",
      "Starting Epoch 267\n",
      "0.851798220821049\n",
      "Starting Epoch 268\n",
      "0.8501584400301394\n",
      "New best model found at epoch 268 with validation loss 0.8797242045402527\n",
      "Starting Epoch 269\n",
      "0.8495457872100498\n",
      "Starting Epoch 270\n",
      "0.8510637490645699\n",
      "Starting Epoch 271\n",
      "0.8502241373062134\n",
      "Starting Epoch 272\n",
      "0.8507617686105811\n",
      "New best model found at epoch 272 with validation loss 0.8795851469039917\n",
      "Starting Epoch 273\n",
      "0.849098405112391\n",
      "Starting Epoch 274\n",
      "0.8500411640042844\n",
      "Starting Epoch 275\n",
      "0.8478664574415787\n",
      "Starting Epoch 276\n",
      "0.8510055878888005\n",
      "Starting Epoch 277\n",
      "0.847505870072738\n",
      "Starting Epoch 278\n",
      "0.8507575237232706\n",
      "Starting Epoch 279\n",
      "0.8500454037085824\n",
      "Starting Epoch 280\n",
      "0.8485805677331012\n",
      "Starting Epoch 281\n",
      "0.8498856010644332\n",
      "Starting Epoch 282\n",
      "0.8496159418769504\n",
      "Starting Epoch 283\n",
      "0.848316604676454\n",
      "Starting Epoch 284\n",
      "0.8492239091707312\n",
      "Starting Epoch 285\n",
      "0.8484043271645255\n",
      "Starting Epoch 286\n",
      "0.8491383220838464\n",
      "Starting Epoch 287\n",
      "0.8489795586337214\n",
      "Starting Epoch 288\n",
      "0.8483885215676349\n",
      "Starting Epoch 289\n",
      "0.8496136976324994\n",
      "Starting Epoch 290\n",
      "0.8499995625537374\n",
      "Starting Epoch 291\n",
      "0.848404031732808\n",
      "Starting Epoch 292\n",
      "0.8498084000919176\n",
      "Starting Epoch 293\n",
      "0.8489830157031184\n",
      "Starting Epoch 294\n",
      "0.848786825719087\n",
      "Starting Epoch 295\n",
      "0.8493499496708745\n",
      "Starting Epoch 296\n",
      "0.8486326492351034\n",
      "New best model found at epoch 296 with validation loss 0.8792673349380493\n",
      "Starting Epoch 297\n",
      "0.8504392038220945\n",
      "Starting Epoch 298\n",
      "0.8489334116811338\n",
      "Starting Epoch 299\n",
      "0.8485810082891713\n",
      "Starting Epoch 300\n",
      "0.8485417547433273\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a13fcc30-22bc-45bc-8f9e-647414de6408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.2477947032969932\n",
      "New best model found at epoch 1 with validation loss 0.9726066589355469\n",
      "Starting Epoch 2\n",
      "0.9490640059761379\n",
      "New best model found at epoch 2 with validation loss 0.95146244764328\n",
      "Starting Epoch 3\n",
      "0.9423593619595403\n",
      "New best model found at epoch 3 with validation loss 0.9436576962471008\n",
      "Starting Epoch 4\n",
      "0.9343279030012048\n",
      "New best model found at epoch 4 with validation loss 0.9392356872558594\n",
      "Starting Epoch 5\n",
      "0.9243079372074293\n",
      "New best model found at epoch 5 with validation loss 0.925079882144928\n",
      "Starting Epoch 6\n",
      "0.9157510088837665\n",
      "New best model found at epoch 6 with validation loss 0.9177337884902954\n",
      "Starting Epoch 7\n",
      "0.9083986282348633\n",
      "New best model found at epoch 7 with validation loss 0.9137654304504395\n",
      "Starting Epoch 8\n",
      "0.9059678367946459\n",
      "Starting Epoch 9\n",
      "0.8976155674975851\n",
      "New best model found at epoch 9 with validation loss 0.8971541523933411\n",
      "Starting Epoch 10\n",
      "0.8873144854669985\n",
      "Starting Epoch 11\n",
      "0.8847908688628155\n",
      "Starting Epoch 12\n",
      "0.8843664812005084\n",
      "New best model found at epoch 12 with validation loss 0.8950943946838379\n",
      "Starting Epoch 13\n",
      "0.8739022223845773\n",
      "Starting Epoch 14\n",
      "0.8751211917918661\n",
      "New best model found at epoch 14 with validation loss 0.8803848624229431\n",
      "Starting Epoch 15\n",
      "0.8676469714745231\n",
      "Starting Epoch 16\n",
      "0.8651230594386226\n",
      "New best model found at epoch 16 with validation loss 0.8770077228546143\n",
      "Starting Epoch 17\n",
      "0.8708703336508378\n",
      "New best model found at epoch 17 with validation loss 0.8690862655639648\n",
      "Starting Epoch 18\n",
      "0.8626166582107544\n",
      "Starting Epoch 19\n",
      "0.8530801068181577\n",
      "New best model found at epoch 19 with validation loss 0.8642131090164185\n",
      "Starting Epoch 20\n",
      "0.8499242533808169\n",
      "Starting Epoch 21\n",
      "0.8530416436817335\n",
      "Starting Epoch 22\n",
      "0.8519256918326669\n",
      "Starting Epoch 23\n",
      "0.8505402647930643\n",
      "New best model found at epoch 23 with validation loss 0.8638399839401245\n",
      "Starting Epoch 24\n",
      "0.8470878134603086\n",
      "New best model found at epoch 24 with validation loss 0.8591753840446472\n",
      "Starting Epoch 25\n",
      "0.8468285177064978\n",
      "Starting Epoch 26\n",
      "0.8459449902824734\n",
      "New best model found at epoch 26 with validation loss 0.8539890050888062\n",
      "Starting Epoch 27\n",
      "0.8450595399607783\n",
      "Starting Epoch 28\n",
      "0.8415692552276279\n",
      "Starting Epoch 29\n",
      "0.8374847095945607\n",
      "Starting Epoch 30\n",
      "0.8394729780114215\n",
      "Starting Epoch 31\n",
      "0.83649364243383\n",
      "Starting Epoch 32\n",
      "0.8397639445636583\n",
      "New best model found at epoch 32 with validation loss 0.8492330312728882\n",
      "Starting Epoch 33\n",
      "0.8393203642057336\n",
      "Starting Epoch 34\n",
      "0.8376025168792062\n",
      "New best model found at epoch 34 with validation loss 0.8486555218696594\n",
      "Starting Epoch 35\n",
      "0.8366191853647647\n",
      "Starting Epoch 36\n",
      "0.8366749234821486\n",
      "Starting Epoch 37\n",
      "0.83463955702989\n",
      "Starting Epoch 38\n",
      "0.8322771917218748\n",
      "New best model found at epoch 38 with validation loss 0.8455507755279541\n",
      "Starting Epoch 39\n",
      "0.8330914559571639\n",
      "New best model found at epoch 39 with validation loss 0.8449434638023376\n",
      "Starting Epoch 40\n",
      "0.83045436506686\n",
      "Starting Epoch 41\n",
      "0.8321789736333101\n",
      "Starting Epoch 42\n",
      "0.8309970653575399\n",
      "New best model found at epoch 42 with validation loss 0.8415068984031677\n",
      "Starting Epoch 43\n",
      "0.8327180095340895\n",
      "Starting Epoch 44\n",
      "0.8291362549947656\n",
      "Starting Epoch 45\n",
      "0.8263999949330869\n",
      "Starting Epoch 46\n",
      "0.8274273690970048\n",
      "Starting Epoch 47\n",
      "0.8257929294005685\n",
      "Starting Epoch 48\n",
      "0.8278392553329468\n",
      "Starting Epoch 49\n",
      "0.826301546200462\n",
      "New best model found at epoch 49 with validation loss 0.8380638957023621\n",
      "Starting Epoch 50\n",
      "0.8251253884771595\n",
      "Starting Epoch 51\n",
      "0.8296212683553281\n",
      "New best model found at epoch 51 with validation loss 0.8364494442939758\n",
      "Starting Epoch 52\n",
      "0.8251799681912297\n",
      "Starting Epoch 53\n",
      "0.8257222434748774\n",
      "Starting Epoch 54\n",
      "0.8241663056871166\n",
      "New best model found at epoch 54 with validation loss 0.8336513638496399\n",
      "Starting Epoch 55\n",
      "0.8218513519867606\n",
      "Starting Epoch 56\n",
      "0.8248744788377181\n",
      "Starting Epoch 57\n",
      "0.8220353541166886\n",
      "Starting Epoch 58\n",
      "0.82352498303289\n",
      "Starting Epoch 59\n",
      "0.8213215703549592\n",
      "New best model found at epoch 59 with validation loss 0.8296421766281128\n",
      "Starting Epoch 60\n",
      "0.8238689743954203\n",
      "Starting Epoch 61\n",
      "0.8251004581866057\n",
      "New best model found at epoch 61 with validation loss 0.8293082118034363\n",
      "Starting Epoch 62\n",
      "0.8221178262130074\n",
      "Starting Epoch 63\n",
      "0.8221434458442356\n",
      "Starting Epoch 64\n",
      "0.8234889714614205\n",
      "Starting Epoch 65\n",
      "0.8211535733679066\n",
      "Starting Epoch 66\n",
      "0.8231252794680388\n",
      "Starting Epoch 67\n",
      "0.8212937919989877\n",
      "Starting Epoch 68\n",
      "0.8221465737923331\n",
      "Starting Epoch 69\n",
      "0.8214649065681126\n",
      "Starting Epoch 70\n",
      "0.8205915145252062\n",
      "Starting Epoch 71\n",
      "0.8228934484979381\n",
      "Starting Epoch 72\n",
      "0.8197636863459712\n",
      "Starting Epoch 73\n",
      "0.8228867390881414\n",
      "New best model found at epoch 73 with validation loss 0.8292480707168579\n",
      "Starting Epoch 74\n",
      "0.8216163153233735\n",
      "Starting Epoch 75\n",
      "0.8193139045134835\n",
      "Starting Epoch 76\n",
      "0.8175198487613512\n",
      "New best model found at epoch 76 with validation loss 0.8282680511474609\n",
      "Starting Epoch 77\n",
      "0.81651654969091\n",
      "Starting Epoch 78\n",
      "0.8151395761448404\n",
      "New best model found at epoch 78 with validation loss 0.8264427781105042\n",
      "Starting Epoch 79\n",
      "0.8190564020820286\n",
      "Starting Epoch 80\n",
      "0.8194034773370494\n",
      "Starting Epoch 81\n",
      "0.8177578190098638\n",
      "New best model found at epoch 81 with validation loss 0.8253988027572632\n",
      "Starting Epoch 82\n",
      "0.817199795142464\n",
      "Starting Epoch 83\n",
      "0.815309983232747\n",
      "Starting Epoch 84\n",
      "0.8164899660193402\n",
      "New best model found at epoch 84 with validation loss 0.8239506483078003\n",
      "Starting Epoch 85\n",
      "0.8171388014503147\n",
      "Starting Epoch 86\n",
      "0.815435238506483\n",
      "Starting Epoch 87\n",
      "0.815739455430404\n",
      "Starting Epoch 88\n",
      "0.815992427908856\n",
      "Starting Epoch 89\n",
      "0.814950080021568\n",
      "Starting Epoch 90\n",
      "0.8141668646231942\n",
      "Starting Epoch 91\n",
      "0.8168908461280491\n",
      "Starting Epoch 92\n",
      "0.8126776166584181\n",
      "Starting Epoch 93\n",
      "0.8166370599166207\n",
      "Starting Epoch 94\n",
      "0.8139465814051421\n",
      "Starting Epoch 95\n",
      "0.8165436050166255\n",
      "Starting Epoch 96\n",
      "0.813852406066397\n",
      "Starting Epoch 97\n",
      "0.8140182987503384\n",
      "Starting Epoch 98\n",
      "0.8120811970337577\n",
      "Starting Epoch 99\n",
      "0.8136282096738401\n",
      "Starting Epoch 100\n",
      "0.8126938213472781\n",
      "New best model found at epoch 100 with validation loss 0.82381272315979\n",
      "Starting Epoch 101\n",
      "0.8116668074027352\n",
      "Starting Epoch 102\n",
      "0.811528275842252\n",
      "Starting Epoch 103\n",
      "0.8124474001967389\n",
      "Starting Epoch 104\n",
      "0.8127678218095199\n",
      "Starting Epoch 105\n",
      "0.812940151795097\n",
      "New best model found at epoch 105 with validation loss 0.8237957954406738\n",
      "Starting Epoch 106\n",
      "0.8117840886116028\n",
      "New best model found at epoch 106 with validation loss 0.8230549693107605\n",
      "Starting Epoch 107\n",
      "0.8134944879490397\n",
      "Starting Epoch 108\n",
      "0.8118470751720926\n",
      "New best model found at epoch 108 with validation loss 0.8221440315246582\n",
      "Starting Epoch 109\n",
      "0.8104278911714968\n",
      "Starting Epoch 110\n",
      "0.8120279908180237\n",
      "Starting Epoch 111\n",
      "0.8133133131524791\n",
      "Starting Epoch 112\n",
      "0.812574231106302\n",
      "Starting Epoch 113\n",
      "0.8116745637810748\n",
      "New best model found at epoch 113 with validation loss 0.8195236921310425\n",
      "Starting Epoch 114\n",
      "0.8094407682833464\n",
      "Starting Epoch 115\n",
      "0.8101388267848803\n",
      "Starting Epoch 116\n",
      "0.8116859897323276\n",
      "Starting Epoch 117\n",
      "0.8098392927128336\n",
      "Starting Epoch 118\n",
      "0.809820092242697\n",
      "Starting Epoch 119\n",
      "0.8105224345041357\n",
      "Starting Epoch 120\n",
      "0.8104206012642902\n",
      "Starting Epoch 121\n",
      "0.8122776591259501\n",
      "Starting Epoch 122\n",
      "0.8119083824365035\n",
      "New best model found at epoch 122 with validation loss 0.8194761872291565\n",
      "Starting Epoch 123\n",
      "0.8059176984040634\n",
      "Starting Epoch 124\n",
      "0.8094806463822074\n",
      "Starting Epoch 125\n",
      "0.8128269833067189\n",
      "New best model found at epoch 125 with validation loss 0.818709135055542\n",
      "Starting Epoch 126\n",
      "0.8084588517313418\n",
      "Starting Epoch 127\n",
      "0.8104601865229399\n",
      "Starting Epoch 128\n",
      "0.8099783296170442\n",
      "Starting Epoch 129\n",
      "0.8093202295510665\n",
      "Starting Epoch 130\n",
      "0.8090448871902798\n",
      "Starting Epoch 131\n",
      "0.8083728240883868\n",
      "Starting Epoch 132\n",
      "0.8066547305687614\n",
      "Starting Epoch 133\n",
      "0.8049011463704316\n",
      "Starting Epoch 134\n",
      "0.8077433394349139\n",
      "Starting Epoch 135\n",
      "0.8074648872665737\n",
      "New best model found at epoch 135 with validation loss 0.817808985710144\n",
      "Starting Epoch 136\n",
      "0.8077596270519755\n",
      "Starting Epoch 137\n",
      "0.8067442411961763\n",
      "Starting Epoch 138\n",
      "0.8082374904466711\n",
      "Starting Epoch 139\n",
      "0.8070358996805937\n",
      "Starting Epoch 140\n",
      "0.8094621844913649\n",
      "Starting Epoch 141\n",
      "0.8048497308855471\n",
      "Starting Epoch 142\n",
      "0.8086149407469708\n",
      "New best model found at epoch 142 with validation loss 0.8156676888465881\n",
      "Starting Epoch 143\n",
      "0.8069856115009474\n",
      "Starting Epoch 144\n",
      "0.809772429258927\n",
      "Starting Epoch 145\n",
      "0.8059349993000859\n",
      "Starting Epoch 146\n",
      "0.8069244467693827\n",
      "Starting Epoch 147\n",
      "0.8066395676654318\n",
      "Starting Epoch 148\n",
      "0.8067232007565706\n",
      "Starting Epoch 149\n",
      "0.8059720241505167\n",
      "Starting Epoch 150\n",
      "0.8079385290975156\n",
      "Starting Epoch 151\n",
      "0.8065251682115637\n",
      "Starting Epoch 152\n",
      "0.8080729531205219\n",
      "New best model found at epoch 152 with validation loss 0.8148171305656433\n",
      "Starting Epoch 153\n",
      "0.8076453519904095\n",
      "Starting Epoch 154\n",
      "0.8088102392528368\n",
      "Starting Epoch 155\n",
      "0.8046755246494127\n",
      "Starting Epoch 156\n",
      "0.8054121266240659\n",
      "Starting Epoch 157\n",
      "0.8054786739142045\n",
      "Starting Epoch 158\n",
      "0.8039950624756191\n",
      "New best model found at epoch 158 with validation loss 0.8125008344650269\n",
      "Starting Epoch 159\n",
      "0.8085699340571528\n",
      "Starting Epoch 160\n",
      "0.8066942018011342\n",
      "Starting Epoch 161\n",
      "0.8043576764023822\n",
      "Starting Epoch 162\n",
      "0.8052185825679613\n",
      "Starting Epoch 163\n",
      "0.8037100563878599\n",
      "Starting Epoch 164\n",
      "0.8040023342422817\n",
      "Starting Epoch 165\n",
      "0.8069494703541631\n",
      "Starting Epoch 166\n",
      "0.8066975033801534\n",
      "Starting Epoch 167\n",
      "0.8055063874825187\n",
      "Starting Epoch 168\n",
      "0.8050367754438649\n",
      "Starting Epoch 169\n",
      "0.8038590135781661\n",
      "Starting Epoch 170\n",
      "0.8049468009368234\n",
      "New best model found at epoch 170 with validation loss 0.8111419677734375\n",
      "Starting Epoch 171\n",
      "0.8054798582325811\n",
      "Starting Epoch 172\n",
      "0.8032824423002161\n",
      "Starting Epoch 173\n",
      "0.8037385033524554\n",
      "Starting Epoch 174\n",
      "0.8037904604621555\n",
      "Starting Epoch 175\n",
      "0.8042427327321924\n",
      "Starting Epoch 176\n",
      "0.8069327966026638\n",
      "New best model found at epoch 176 with validation loss 0.8107892274856567\n",
      "Starting Epoch 177\n",
      "0.8047935522120931\n",
      "Starting Epoch 178\n",
      "0.8063829256140668\n",
      "Starting Epoch 179\n",
      "0.8020118138064509\n",
      "New best model found at epoch 179 with validation loss 0.8107255101203918\n",
      "Starting Epoch 180\n",
      "0.8046918822371442\n",
      "Starting Epoch 181\n",
      "0.8023923765058103\n",
      "Starting Epoch 182\n",
      "0.803382404472517\n",
      "Starting Epoch 183\n",
      "0.803894711577374\n",
      "Starting Epoch 184\n",
      "0.8040356661962427\n",
      "Starting Epoch 185\n",
      "0.8022813589676566\n",
      "Starting Epoch 186\n",
      "0.8032263724700265\n",
      "Starting Epoch 187\n",
      "0.8033752337745999\n",
      "Starting Epoch 188\n",
      "0.8032553791999817\n",
      "Starting Epoch 189\n",
      "0.8028918815695721\n",
      "Starting Epoch 190\n",
      "0.803119174812151\n",
      "Starting Epoch 191\n",
      "0.803061956944673\n",
      "Starting Epoch 192\n",
      "0.8038402355235555\n",
      "Starting Epoch 193\n",
      "0.8030776303747426\n",
      "Starting Epoch 194\n",
      "0.8042537077613499\n",
      "Starting Epoch 195\n",
      "0.8032358029614324\n",
      "Starting Epoch 196\n",
      "0.8012857825859733\n",
      "Starting Epoch 197\n",
      "0.8018787270006926\n",
      "Starting Epoch 198\n",
      "0.8019949871560802\n",
      "Starting Epoch 199\n",
      "0.8041402464327605\n",
      "Starting Epoch 200\n",
      "0.8028821323228919\n",
      "Starting Epoch 201\n",
      "0.8027344579282014\n",
      "Starting Epoch 202\n",
      "0.8035169010576995\n",
      "Starting Epoch 203\n",
      "0.8014068603515625\n",
      "Starting Epoch 204\n",
      "0.8034862461297408\n",
      "Starting Epoch 205\n",
      "0.8046345192453136\n",
      "New best model found at epoch 205 with validation loss 0.8085680603981018\n",
      "Starting Epoch 206\n",
      "0.8049146895823271\n",
      "Starting Epoch 207\n",
      "0.8043293564215951\n",
      "Starting Epoch 208\n",
      "0.8014899025792661\n",
      "Starting Epoch 209\n",
      "0.8025618143703627\n",
      "Starting Epoch 210\n",
      "0.8003411474435226\n",
      "Starting Epoch 211\n",
      "0.8023222633030104\n",
      "Starting Epoch 212\n",
      "0.803912015064903\n",
      "Starting Epoch 213\n",
      "0.8017136921053347\n",
      "Starting Epoch 214\n",
      "0.8024186621541562\n",
      "Starting Epoch 215\n",
      "0.8032433001891427\n",
      "Starting Epoch 216\n",
      "0.8035644603812176\n",
      "Starting Epoch 217\n",
      "0.8016593844994254\n",
      "Starting Epoch 218\n",
      "0.8013969167419102\n",
      "Starting Epoch 219\n",
      "0.8024264910946721\n",
      "Starting Epoch 220\n",
      "0.8009059869724772\n",
      "Starting Epoch 221\n",
      "0.8004721351291822\n",
      "Starting Epoch 222\n",
      "0.8035885277001754\n",
      "Starting Epoch 223\n",
      "0.7989819205325582\n",
      "Starting Epoch 224\n",
      "0.8015283708987029\n",
      "Starting Epoch 225\n",
      "0.8033952713012695\n",
      "Starting Epoch 226\n",
      "0.8027718766875889\n",
      "Starting Epoch 227\n",
      "0.8004828976548236\n",
      "Starting Epoch 228\n",
      "0.7988944286885469\n",
      "New best model found at epoch 228 with validation loss 0.8074777126312256\n",
      "Starting Epoch 229\n",
      "0.8010577896366948\n",
      "Starting Epoch 230\n",
      "0.8006679545278135\n",
      "Starting Epoch 231\n",
      "0.7999380308648815\n",
      "Starting Epoch 232\n",
      "0.8003834719243257\n",
      "Starting Epoch 233\n",
      "0.8025656523911849\n",
      "Starting Epoch 234\n",
      "0.8022323691326639\n",
      "Starting Epoch 235\n",
      "0.8012641046358191\n",
      "Starting Epoch 236\n",
      "0.8022851218347964\n",
      "Starting Epoch 237\n",
      "0.7995431293611941\n",
      "Starting Epoch 238\n",
      "0.8005270698796147\n",
      "New best model found at epoch 238 with validation loss 0.8066549897193909\n",
      "Starting Epoch 239\n",
      "0.7994382873825405\n",
      "Starting Epoch 240\n",
      "0.8036728786385577\n",
      "New best model found at epoch 240 with validation loss 0.806210994720459\n",
      "Starting Epoch 241\n",
      "0.8024863263835078\n",
      "Starting Epoch 242\n",
      "0.8004974385966426\n",
      "Starting Epoch 243\n",
      "0.8006965492082678\n",
      "Starting Epoch 244\n",
      "0.8009914678076039\n",
      "Starting Epoch 245\n",
      "0.8014737963676453\n",
      "Starting Epoch 246\n",
      "0.8002031808314116\n",
      "Starting Epoch 247\n",
      "0.7986469424289205\n",
      "Starting Epoch 248\n",
      "0.8002584472946499\n",
      "Starting Epoch 249\n",
      "0.7979682865350143\n",
      "Starting Epoch 250\n",
      "0.7993178963661194\n",
      "Starting Epoch 251\n",
      "0.7982000112533569\n",
      "Starting Epoch 252\n",
      "0.8005056899526845\n",
      "Starting Epoch 253\n",
      "0.8001159818276115\n",
      "Starting Epoch 254\n",
      "0.8006519027378248\n",
      "Starting Epoch 255\n",
      "0.7990977038507876\n",
      "Starting Epoch 256\n",
      "0.8005818983782893\n",
      "Starting Epoch 257\n",
      "0.8014838384545367\n",
      "Starting Epoch 258\n",
      "0.7997600539870884\n",
      "Starting Epoch 259\n",
      "0.7990117954171222\n",
      "Starting Epoch 260\n",
      "0.7995729886967203\n",
      "New best model found at epoch 260 with validation loss 0.8056159615516663\n",
      "Starting Epoch 261\n",
      "0.7991221469381581\n",
      "Starting Epoch 262\n",
      "0.7993605007296023\n",
      "Starting Epoch 263\n",
      "0.8010805456534676\n",
      "Starting Epoch 264\n",
      "0.79900440444117\n",
      "Starting Epoch 265\n",
      "0.7993850967158442\n",
      "Starting Epoch 266\n",
      "0.7980142106180605\n",
      "Starting Epoch 267\n",
      "0.8012707311174144\n",
      "Starting Epoch 268\n",
      "0.7999869066735973\n",
      "New best model found at epoch 268 with validation loss 0.8051438927650452\n",
      "Starting Epoch 269\n",
      "0.7996928354968196\n",
      "New best model found at epoch 269 with validation loss 0.8044639825820923\n",
      "Starting Epoch 270\n",
      "0.8018142606901086\n",
      "Starting Epoch 271\n",
      "0.7989690018736798\n",
      "Starting Epoch 272\n",
      "0.8003704314646514\n",
      "Starting Epoch 273\n",
      "0.798139548819998\n",
      "Starting Epoch 274\n",
      "0.7989072074060855\n",
      "Starting Epoch 275\n",
      "0.7991705355436906\n",
      "Starting Epoch 276\n",
      "0.7996608381686003\n",
      "Starting Epoch 277\n",
      "0.7984197943106942\n",
      "Starting Epoch 278\n",
      "0.7999065285143645\n",
      "Starting Epoch 279\n",
      "0.7982747399288675\n",
      "Starting Epoch 280\n",
      "0.7994266826173534\n",
      "Starting Epoch 281\n",
      "0.7995631979859393\n",
      "Starting Epoch 282\n",
      "0.7979276828143907\n",
      "Starting Epoch 283\n",
      "0.7974264829055123\n",
      "New best model found at epoch 283 with validation loss 0.8039429187774658\n",
      "Starting Epoch 284\n",
      "0.7981056104535642\n",
      "Starting Epoch 285\n",
      "0.7983903625737065\n",
      "Starting Epoch 286\n",
      "0.797544399033422\n",
      "Starting Epoch 287\n",
      "0.8000236645988796\n",
      "Starting Epoch 288\n",
      "0.798290174940358\n",
      "Starting Epoch 289\n",
      "0.800425288469895\n",
      "Starting Epoch 290\n",
      "0.7998392219128816\n",
      "Starting Epoch 291\n",
      "0.7982652316922727\n",
      "Starting Epoch 292\n",
      "0.7996704759805099\n",
      "Starting Epoch 293\n",
      "0.8000796307688174\n",
      "Starting Epoch 294\n",
      "0.7978981862897458\n",
      "Starting Epoch 295\n",
      "0.7983330332714579\n",
      "Starting Epoch 296\n",
      "0.798286673815354\n",
      "Starting Epoch 297\n",
      "0.7995957602625308\n",
      "Starting Epoch 298\n",
      "0.7968191063922384\n",
      "Starting Epoch 299\n",
      "0.797694400600765\n",
      "Starting Epoch 300\n",
      "0.7986491763073466\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "099dd9d7-516a-4e35-8aa1-0c0f35cd1d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.140265555485435\n",
      "New best model found at epoch 1 with validation loss 0.7656881213188171\n",
      "Starting Epoch 2\n",
      "0.7745201639507128\n",
      "New best model found at epoch 2 with validation loss 0.7450772523880005\n",
      "Starting Epoch 3\n",
      "0.7633364252422167\n",
      "New best model found at epoch 3 with validation loss 0.7400042414665222\n",
      "Starting Epoch 4\n",
      "0.7566977272862974\n",
      "New best model found at epoch 4 with validation loss 0.731938362121582\n",
      "Starting Epoch 5\n",
      "0.7458533696506334\n",
      "New best model found at epoch 5 with validation loss 0.7173871994018555\n",
      "Starting Epoch 6\n",
      "0.734768517639326\n",
      "New best model found at epoch 6 with validation loss 0.7020120620727539\n",
      "Starting Epoch 7\n",
      "0.7287614293720411\n",
      "New best model found at epoch 7 with validation loss 0.6958364248275757\n",
      "Starting Epoch 8\n",
      "0.7296454776888308\n",
      "Starting Epoch 9\n",
      "0.7225598718809045\n",
      "New best model found at epoch 9 with validation loss 0.6935048699378967\n",
      "Starting Epoch 10\n",
      "0.7103077847024669\n",
      "New best model found at epoch 10 with validation loss 0.6828289031982422\n",
      "Starting Epoch 11\n",
      "0.7079129478205806\n",
      "New best model found at epoch 11 with validation loss 0.6738077998161316\n",
      "Starting Epoch 12\n",
      "0.7066126154816669\n",
      "Starting Epoch 13\n",
      "0.6976410409678584\n",
      "Starting Epoch 14\n",
      "0.7007973790168762\n",
      "New best model found at epoch 14 with validation loss 0.6706627011299133\n",
      "Starting Epoch 15\n",
      "0.6975779170575349\n",
      "New best model found at epoch 15 with validation loss 0.6666656136512756\n",
      "Starting Epoch 16\n",
      "0.6904027747071307\n",
      "Starting Epoch 17\n",
      "0.6975533651269\n",
      "New best model found at epoch 17 with validation loss 0.6612417101860046\n",
      "Starting Epoch 18\n",
      "0.6929816940556401\n",
      "New best model found at epoch 18 with validation loss 0.6596358418464661\n",
      "Starting Epoch 19\n",
      "0.6829719154731088\n",
      "New best model found at epoch 19 with validation loss 0.6528959274291992\n",
      "Starting Epoch 20\n",
      "0.681237122286921\n",
      "Starting Epoch 21\n",
      "0.6823939706968225\n",
      "Starting Epoch 22\n",
      "0.6891371478205142\n",
      "New best model found at epoch 22 with validation loss 0.6527796983718872\n",
      "Starting Epoch 23\n",
      "0.6816226192142653\n",
      "New best model found at epoch 23 with validation loss 0.6496065855026245\n",
      "Starting Epoch 24\n",
      "0.6834492787070896\n",
      "New best model found at epoch 24 with validation loss 0.6468526124954224\n",
      "Starting Epoch 25\n",
      "0.681289906087129\n",
      "Starting Epoch 26\n",
      "0.6812954933747001\n",
      "Starting Epoch 27\n",
      "0.6784544613050378\n",
      "Starting Epoch 28\n",
      "0.6798352650974108\n",
      "New best model found at epoch 28 with validation loss 0.6465694308280945\n",
      "Starting Epoch 29\n",
      "0.6755071256471716\n",
      "Starting Epoch 30\n",
      "0.6776948312054509\n",
      "Starting Epoch 31\n",
      "0.6746714659359144\n",
      "Starting Epoch 32\n",
      "0.6784963167232015\n",
      "New best model found at epoch 32 with validation loss 0.6395983695983887\n",
      "Starting Epoch 33\n",
      "0.6767446709715802\n",
      "Starting Epoch 34\n",
      "0.6754751179529273\n",
      "Starting Epoch 35\n",
      "0.6721675681031268\n",
      "Starting Epoch 36\n",
      "0.6727562339409537\n",
      "Starting Epoch 37\n",
      "0.6730673779612002\n",
      "Starting Epoch 38\n",
      "0.6688040235768193\n",
      "New best model found at epoch 38 with validation loss 0.6390743255615234\n",
      "Starting Epoch 39\n",
      "0.6710930803547734\n",
      "New best model found at epoch 39 with validation loss 0.636804461479187\n",
      "Starting Epoch 40\n",
      "0.6698058584462041\n",
      "Starting Epoch 41\n",
      "0.6710267222445944\n",
      "Starting Epoch 42\n",
      "0.670851891455443\n",
      "New best model found at epoch 42 with validation loss 0.6350878477096558\n",
      "Starting Epoch 43\n",
      "0.6705060886300128\n",
      "Starting Epoch 44\n",
      "0.671587744484777\n",
      "Starting Epoch 45\n",
      "0.6680424524390179\n",
      "Starting Epoch 46\n",
      "0.6682279084039771\n",
      "New best model found at epoch 46 with validation loss 0.6331659555435181\n",
      "Starting Epoch 47\n",
      "0.6656340904857801\n",
      "Starting Epoch 48\n",
      "0.6683783583019091\n",
      "Starting Epoch 49\n",
      "0.6673974446628405\n",
      "Starting Epoch 50\n",
      "0.6669540146122808\n",
      "Starting Epoch 51\n",
      "0.6691830935685531\n",
      "Starting Epoch 52\n",
      "0.668496424737184\n",
      "Starting Epoch 53\n",
      "0.667208088480908\n",
      "New best model found at epoch 53 with validation loss 0.6324043273925781\n",
      "Starting Epoch 54\n",
      "0.6666054544241532\n",
      "Starting Epoch 55\n",
      "0.6644977020180743\n",
      "Starting Epoch 56\n",
      "0.6665765617204749\n",
      "Starting Epoch 57\n",
      "0.6635343976642775\n",
      "Starting Epoch 58\n",
      "0.6647947793421538\n",
      "Starting Epoch 59\n",
      "0.6644202989080678\n",
      "New best model found at epoch 59 with validation loss 0.6288283467292786\n",
      "Starting Epoch 60\n",
      "0.6637743037679921\n",
      "Starting Epoch 61\n",
      "0.6681571758311727\n",
      "Starting Epoch 62\n",
      "0.6669320464134216\n",
      "Starting Epoch 63\n",
      "0.6656732481458912\n",
      "Starting Epoch 64\n",
      "0.6673834608948749\n",
      "Starting Epoch 65\n",
      "0.6634147322696188\n",
      "Starting Epoch 66\n",
      "0.6649456905282062\n",
      "Starting Epoch 67\n",
      "0.664332415746606\n",
      "Starting Epoch 68\n",
      "0.6642478989518207\n",
      "Starting Epoch 69\n",
      "0.6638409573098888\n",
      "Starting Epoch 70\n",
      "0.6624119618664617\n",
      "Starting Epoch 71\n",
      "0.6642388856929281\n",
      "Starting Epoch 72\n",
      "0.6640981124795001\n",
      "Starting Epoch 73\n",
      "0.6635856835738473\n",
      "Starting Epoch 74\n",
      "0.6647662805474323\n",
      "Starting Epoch 75\n",
      "0.6626149312309597\n",
      "Starting Epoch 76\n",
      "0.6598010425982268\n",
      "New best model found at epoch 76 with validation loss 0.6272193789482117\n",
      "Starting Epoch 77\n",
      "0.6583862226942311\n",
      "Starting Epoch 78\n",
      "0.6599355314088904\n",
      "New best model found at epoch 78 with validation loss 0.6252707839012146\n",
      "Starting Epoch 79\n",
      "0.6627036048018414\n",
      "Starting Epoch 80\n",
      "0.6637875696887141\n",
      "Starting Epoch 81\n",
      "0.6601493773253068\n",
      "Starting Epoch 82\n",
      "0.6590811662051989\n",
      "Starting Epoch 83\n",
      "0.6593886406525321\n",
      "Starting Epoch 84\n",
      "0.6592644349388455\n",
      "New best model found at epoch 84 with validation loss 0.6244776844978333\n",
      "Starting Epoch 85\n",
      "0.6597866752873296\n",
      "New best model found at epoch 85 with validation loss 0.624354898929596\n",
      "Starting Epoch 86\n",
      "0.6610505010770715\n",
      "Starting Epoch 87\n",
      "0.6604488388351772\n",
      "Starting Epoch 88\n",
      "0.6586728199668552\n",
      "Starting Epoch 89\n",
      "0.65931745197462\n",
      "Starting Epoch 90\n",
      "0.6584364901418271\n",
      "Starting Epoch 91\n",
      "0.6610123800194782\n",
      "Starting Epoch 92\n",
      "0.6572178913199384\n",
      "Starting Epoch 93\n",
      "0.6587553127952244\n",
      "Starting Epoch 94\n",
      "0.6559422223464303\n",
      "Starting Epoch 95\n",
      "0.6613813794177511\n",
      "New best model found at epoch 95 with validation loss 0.6219676733016968\n",
      "Starting Epoch 96\n",
      "0.6579821265262106\n",
      "Starting Epoch 97\n",
      "0.6571909033733866\n",
      "Starting Epoch 98\n",
      "0.6561933626299319\n",
      "Starting Epoch 99\n",
      "0.6591113391129867\n",
      "Starting Epoch 100\n",
      "0.6561591806619064\n",
      "Starting Epoch 101\n",
      "0.6567586660385132\n",
      "Starting Epoch 102\n",
      "0.6556394385254901\n",
      "Starting Epoch 103\n",
      "0.6573073190191517\n",
      "Starting Epoch 104\n",
      "0.6569463066432787\n",
      "Starting Epoch 105\n",
      "0.6556755641232366\n",
      "New best model found at epoch 105 with validation loss 0.620570719242096\n",
      "Starting Epoch 106\n",
      "0.6561431392379429\n",
      "Starting Epoch 107\n",
      "0.657634657362233\n",
      "Starting Epoch 108\n",
      "0.6549188028211179\n",
      "New best model found at epoch 108 with validation loss 0.6205403804779053\n",
      "Starting Epoch 109\n",
      "0.6555359311725782\n",
      "Starting Epoch 110\n",
      "0.6576427635939225\n",
      "Starting Epoch 111\n",
      "0.6568520872489266\n",
      "Starting Epoch 112\n",
      "0.6586633402368297\n",
      "Starting Epoch 113\n",
      "0.6559300396753394\n",
      "New best model found at epoch 113 with validation loss 0.6201796531677246\n",
      "Starting Epoch 114\n",
      "0.6529982115911401\n",
      "Starting Epoch 115\n",
      "0.6552930189215619\n",
      "New best model found at epoch 115 with validation loss 0.6194829344749451\n",
      "Starting Epoch 116\n",
      "0.6554060630176378\n",
      "Starting Epoch 117\n",
      "0.6539533630661343\n",
      "Starting Epoch 118\n",
      "0.6548995997594751\n",
      "Starting Epoch 119\n",
      "0.6539416287256323\n",
      "Starting Epoch 120\n",
      "0.6549284665480904\n",
      "Starting Epoch 121\n",
      "0.6574702988500181\n",
      "New best model found at epoch 121 with validation loss 0.6187193393707275\n",
      "Starting Epoch 122\n",
      "0.6574443449144778\n",
      "Starting Epoch 123\n",
      "0.6507306850474813\n",
      "Starting Epoch 124\n",
      "0.6529927409213522\n",
      "Starting Epoch 125\n",
      "0.6566244882086049\n",
      "Starting Epoch 126\n",
      "0.6528574824333191\n",
      "Starting Epoch 127\n",
      "0.654695855534595\n",
      "Starting Epoch 128\n",
      "0.6536219327346139\n",
      "New best model found at epoch 128 with validation loss 0.618175745010376\n",
      "Starting Epoch 129\n",
      "0.6523664982422538\n",
      "Starting Epoch 130\n",
      "0.6523431176724641\n",
      "Starting Epoch 131\n",
      "0.6526556222335153\n",
      "Starting Epoch 132\n",
      "0.6495536773101144\n",
      "Starting Epoch 133\n",
      "0.6507276322530664\n",
      "Starting Epoch 134\n",
      "0.6511772534121638\n",
      "Starting Epoch 135\n",
      "0.6537568439608035\n",
      "New best model found at epoch 135 with validation loss 0.6172521710395813\n",
      "Starting Epoch 136\n",
      "0.6524466042933257\n",
      "Starting Epoch 137\n",
      "0.6498045558514802\n",
      "Starting Epoch 138\n",
      "0.6536891926889834\n",
      "Starting Epoch 139\n",
      "0.6514698992604795\n",
      "Starting Epoch 140\n",
      "0.6522465814714846\n",
      "Starting Epoch 141\n",
      "0.6503488252992216\n",
      "New best model found at epoch 141 with validation loss 0.6166231632232666\n",
      "Starting Epoch 142\n",
      "0.6534399571626083\n",
      "Starting Epoch 143\n",
      "0.652704005656035\n",
      "Starting Epoch 144\n",
      "0.6534683548885843\n",
      "Starting Epoch 145\n",
      "0.649268803389176\n",
      "Starting Epoch 146\n",
      "0.6506851548733918\n",
      "Starting Epoch 147\n",
      "0.6520358272220778\n",
      "Starting Epoch 148\n",
      "0.6506335113359534\n",
      "Starting Epoch 149\n",
      "0.6506086458330569\n",
      "New best model found at epoch 149 with validation loss 0.6165997385978699\n",
      "Starting Epoch 150\n",
      "0.6519994891208151\n",
      "Starting Epoch 151\n",
      "0.6517714469329171\n",
      "Starting Epoch 152\n",
      "0.652383223823879\n",
      "Starting Epoch 153\n",
      "0.652427217234736\n",
      "New best model found at epoch 153 with validation loss 0.6159395575523376\n",
      "Starting Epoch 154\n",
      "0.6524628193482108\n",
      "Starting Epoch 155\n",
      "0.650888310826343\n",
      "Starting Epoch 156\n",
      "0.6503470125405685\n",
      "Starting Epoch 157\n",
      "0.6508624605510546\n",
      "Starting Epoch 158\n",
      "0.6494559827058212\n",
      "New best model found at epoch 158 with validation loss 0.6141050457954407\n",
      "Starting Epoch 159\n",
      "0.6506112528883893\n",
      "Starting Epoch 160\n",
      "0.6519406619279281\n",
      "Starting Epoch 161\n",
      "0.6494757170262544\n",
      "Starting Epoch 162\n",
      "0.6500278270762899\n",
      "Starting Epoch 163\n",
      "0.6484655349150948\n",
      "Starting Epoch 164\n",
      "0.6498040194096772\n",
      "Starting Epoch 165\n",
      "0.6491635804590972\n",
      "Starting Epoch 166\n",
      "0.6508206543715104\n",
      "Starting Epoch 167\n",
      "0.6503679622774539\n",
      "Starting Epoch 168\n",
      "0.6502951072609943\n",
      "Starting Epoch 169\n",
      "0.6490312063175699\n",
      "Starting Epoch 170\n",
      "0.6501912578292515\n",
      "New best model found at epoch 170 with validation loss 0.6138342022895813\n",
      "Starting Epoch 171\n",
      "0.6493799971497577\n",
      "Starting Epoch 172\n",
      "0.6497331857681274\n",
      "Starting Epoch 173\n",
      "0.6485018548758134\n",
      "Starting Epoch 174\n",
      "0.649029457050821\n",
      "Starting Epoch 175\n",
      "0.6487684094387552\n",
      "New best model found at epoch 175 with validation loss 0.6137429475784302\n",
      "Starting Epoch 176\n",
      "0.6500279618346173\n",
      "New best model found at epoch 176 with validation loss 0.6131024956703186\n",
      "Starting Epoch 177\n",
      "0.6500782551972762\n",
      "New best model found at epoch 177 with validation loss 0.612722635269165\n",
      "Starting Epoch 178\n",
      "0.6512559004451918\n",
      "Starting Epoch 179\n",
      "0.6465264688367429\n",
      "Starting Epoch 180\n",
      "0.6484588280968044\n",
      "Starting Epoch 181\n",
      "0.6479290050009022\n",
      "Starting Epoch 182\n",
      "0.6494592816933341\n",
      "New best model found at epoch 182 with validation loss 0.6124651432037354\n",
      "Starting Epoch 183\n",
      "0.6500287962996442\n",
      "Starting Epoch 184\n",
      "0.6484141064726788\n",
      "Starting Epoch 185\n",
      "0.6460368840590768\n",
      "Starting Epoch 186\n",
      "0.648058655469314\n",
      "Starting Epoch 187\n",
      "0.647241296975509\n",
      "Starting Epoch 188\n",
      "0.6483938823575559\n",
      "Starting Epoch 189\n",
      "0.6467134356498718\n",
      "Starting Epoch 190\n",
      "0.6474401691685552\n",
      "Starting Epoch 191\n",
      "0.647420206795568\n",
      "Starting Epoch 192\n",
      "0.6489592712858449\n",
      "Starting Epoch 193\n",
      "0.647872691569121\n",
      "Starting Epoch 194\n",
      "0.6477034817571226\n",
      "Starting Epoch 195\n",
      "0.6481406662775122\n",
      "Starting Epoch 196\n",
      "0.6467268829760344\n",
      "Starting Epoch 197\n",
      "0.6469913099123084\n",
      "Starting Epoch 198\n",
      "0.6467635631561279\n",
      "Starting Epoch 199\n",
      "0.6494100612142811\n",
      "Starting Epoch 200\n",
      "0.6488106302593065\n",
      "New best model found at epoch 200 with validation loss 0.6119784712791443\n",
      "Starting Epoch 201\n",
      "0.6462723768275717\n",
      "New best model found at epoch 201 with validation loss 0.6114010214805603\n",
      "Starting Epoch 202\n",
      "0.6487241698348004\n",
      "Starting Epoch 203\n",
      "0.6459200200827225\n",
      "New best model found at epoch 203 with validation loss 0.6105045676231384\n",
      "Starting Epoch 204\n",
      "0.6491904155067776\n",
      "Starting Epoch 205\n",
      "0.6492890871089437\n",
      "Starting Epoch 206\n",
      "0.6486311943634696\n",
      "Starting Epoch 207\n",
      "0.6481759807337886\n",
      "Starting Epoch 208\n",
      "0.6466192473535952\n",
      "Starting Epoch 209\n",
      "0.6474452770274618\n",
      "Starting Epoch 210\n",
      "0.6452332242675449\n",
      "Starting Epoch 211\n",
      "0.6473193246385326\n",
      "New best model found at epoch 211 with validation loss 0.6101904511451721\n",
      "Starting Epoch 212\n",
      "0.6478133823560632\n",
      "Starting Epoch 213\n",
      "0.6453926381857499\n",
      "Starting Epoch 214\n",
      "0.64626261462336\n",
      "Starting Epoch 215\n",
      "0.6468687238900558\n",
      "Starting Epoch 216\n",
      "0.6467274220093436\n",
      "Starting Epoch 217\n",
      "0.6456205559813458\n",
      "Starting Epoch 218\n",
      "0.6454245707263118\n",
      "Starting Epoch 219\n",
      "0.6468119595361792\n",
      "Starting Epoch 220\n",
      "0.6442006748655568\n",
      "Starting Epoch 221\n",
      "0.6443790404692941\n",
      "Starting Epoch 222\n",
      "0.6463759515596472\n",
      "Starting Epoch 223\n",
      "0.643141447202019\n",
      "Starting Epoch 224\n",
      "0.6458492045817168\n",
      "Starting Epoch 225\n",
      "0.6470769643783569\n",
      "Starting Epoch 226\n",
      "0.6482145138408827\n",
      "Starting Epoch 227\n",
      "0.6445054930189381\n",
      "Starting Epoch 228\n",
      "0.6436949398206628\n",
      "New best model found at epoch 228 with validation loss 0.6092809438705444\n",
      "Starting Epoch 229\n",
      "0.6450146721756976\n",
      "Starting Epoch 230\n",
      "0.6452303088229635\n",
      "Starting Epoch 231\n",
      "0.6451386057812235\n",
      "Starting Epoch 232\n",
      "0.6459222980167555\n",
      "Starting Epoch 233\n",
      "0.6470114536907362\n",
      "Starting Epoch 234\n",
      "0.6453205398891283\n",
      "New best model found at epoch 234 with validation loss 0.6083766222000122\n",
      "Starting Epoch 235\n",
      "0.6454768491827924\n",
      "Starting Epoch 236\n",
      "0.6470431426297063\n",
      "Starting Epoch 237\n",
      "0.6446828388649485\n",
      "Starting Epoch 238\n",
      "0.6443226363347925\n",
      "Starting Epoch 239\n",
      "0.6440070401067319\n",
      "Starting Epoch 240\n",
      "0.6477303064387777\n",
      "Starting Epoch 241\n",
      "0.6471528125845868\n",
      "Starting Epoch 242\n",
      "0.6431917677754941\n",
      "Starting Epoch 243\n",
      "0.6446217700191166\n",
      "Starting Epoch 244\n",
      "0.6448480512784875\n",
      "Starting Epoch 245\n",
      "0.6451621936715167\n",
      "Starting Epoch 246\n",
      "0.6455943765847579\n",
      "Starting Epoch 247\n",
      "0.6431977152824402\n",
      "Starting Epoch 248\n",
      "0.6455255202625109\n",
      "Starting Epoch 249\n",
      "0.6423114227211993\n",
      "Starting Epoch 250\n",
      "0.644093728583792\n",
      "Starting Epoch 251\n",
      "0.6440357695455137\n",
      "Starting Epoch 252\n",
      "0.6436885258425837\n",
      "New best model found at epoch 252 with validation loss 0.6066030263900757\n",
      "Starting Epoch 253\n",
      "0.6427031755447388\n",
      "Starting Epoch 254\n",
      "0.6451361075691555\n",
      "Starting Epoch 255\n",
      "0.6430868221365887\n",
      "Starting Epoch 256\n",
      "0.645247423130533\n",
      "Starting Epoch 257\n",
      "0.6442925385806871\n",
      "Starting Epoch 258\n",
      "0.643479787785074\n",
      "Starting Epoch 259\n",
      "0.6427637753279313\n",
      "Starting Epoch 260\n",
      "0.6445857286453247\n",
      "Starting Epoch 261\n",
      "0.6433556792528733\n",
      "Starting Epoch 262\n",
      "0.6425452854322351\n",
      "Starting Epoch 263\n",
      "0.6437864433164182\n",
      "Starting Epoch 264\n",
      "0.6442658616148907\n",
      "Starting Epoch 265\n",
      "0.6429887491723766\n",
      "Starting Epoch 266\n",
      "0.6435418919376705\n",
      "Starting Epoch 267\n",
      "0.6452240192371866\n",
      "Starting Epoch 268\n",
      "0.6431574769642042\n",
      "Starting Epoch 269\n",
      "0.6421676433604696\n",
      "Starting Epoch 270\n",
      "0.644908695117287\n",
      "Starting Epoch 271\n",
      "0.6415049355963002\n",
      "Starting Epoch 272\n",
      "0.6438228254732878\n",
      "Starting Epoch 273\n",
      "0.6416860663372538\n",
      "Starting Epoch 274\n",
      "0.6434813997019893\n",
      "Starting Epoch 275\n",
      "0.6431766230127086\n",
      "Starting Epoch 276\n",
      "0.6440508663654327\n",
      "Starting Epoch 277\n",
      "0.6417768869711005\n",
      "Starting Epoch 278\n",
      "0.6441548233446868\n",
      "Starting Epoch 279\n",
      "0.6418584222378938\n",
      "Starting Epoch 280\n",
      "0.6426901817321777\n",
      "Starting Epoch 281\n",
      "0.6423140790151514\n",
      "Starting Epoch 282\n",
      "0.6416160982588063\n",
      "Starting Epoch 283\n",
      "0.6425316826156948\n",
      "New best model found at epoch 283 with validation loss 0.6058988571166992\n",
      "Starting Epoch 284\n",
      "0.6417280824288077\n",
      "New best model found at epoch 284 with validation loss 0.604931652545929\n",
      "Starting Epoch 285\n",
      "0.6426739329877107\n",
      "Starting Epoch 286\n",
      "0.6412114267763884\n",
      "Starting Epoch 287\n",
      "0.6428293222966401\n",
      "Starting Epoch 288\n",
      "0.6414118927458058\n",
      "Starting Epoch 289\n",
      "0.6431813965673032\n",
      "Starting Epoch 290\n",
      "0.643314444500467\n",
      "Starting Epoch 291\n",
      "0.6424466993497766\n",
      "Starting Epoch 292\n",
      "0.6436548207117163\n",
      "Starting Epoch 293\n",
      "0.6423249866651453\n",
      "Starting Epoch 294\n",
      "0.6408530318218729\n",
      "Starting Epoch 295\n",
      "0.6409678174101788\n",
      "Starting Epoch 296\n",
      "0.6425286764683931\n",
      "Starting Epoch 297\n",
      "0.6436623412629833\n",
      "Starting Epoch 298\n",
      "0.6411150149677111\n",
      "Starting Epoch 299\n",
      "0.641148901504019\n",
      "Starting Epoch 300\n",
      "0.6412809672562972\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-20-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d82414b",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 4, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 25 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c56cda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9df8f3b1-d7f1-4c77-8027-4d724838446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.1974157431851262\n",
      "New best model found at epoch 1 with validation loss 0.8564024567604065\n",
      "Starting Epoch 2\n",
      "0.9074807659439419\n",
      "New best model found at epoch 2 with validation loss 0.8440020084381104\n",
      "Starting Epoch 3\n",
      "0.8928738832473755\n",
      "New best model found at epoch 3 with validation loss 0.8302165865898132\n",
      "Starting Epoch 4\n",
      "0.8615088100018709\n",
      "New best model found at epoch 4 with validation loss 0.795293927192688\n",
      "Starting Epoch 5\n",
      "0.8358647019966788\n",
      "New best model found at epoch 5 with validation loss 0.7829149961471558\n",
      "Starting Epoch 6\n",
      "0.8223850442015607\n",
      "New best model found at epoch 6 with validation loss 0.7654423117637634\n",
      "Starting Epoch 7\n",
      "0.8111654753270356\n",
      "New best model found at epoch 7 with validation loss 0.762102484703064\n",
      "Starting Epoch 8\n",
      "0.7936301931090977\n",
      "Starting Epoch 9\n",
      "0.7920371864152991\n",
      "New best model found at epoch 9 with validation loss 0.7578873038291931\n",
      "Starting Epoch 10\n",
      "0.7808260192041812\n",
      "New best model found at epoch 10 with validation loss 0.7512304782867432\n",
      "Starting Epoch 11\n",
      "0.7782937443774679\n",
      "Starting Epoch 12\n",
      "0.7798484123271444\n",
      "New best model found at epoch 12 with validation loss 0.7320328950881958\n",
      "Starting Epoch 13\n",
      "0.7708398647930311\n",
      "Starting Epoch 14\n",
      "0.7652031571968742\n",
      "New best model found at epoch 14 with validation loss 0.722796618938446\n",
      "Starting Epoch 15\n",
      "0.7570028590119403\n",
      "Starting Epoch 16\n",
      "0.7559510987737904\n",
      "New best model found at epoch 16 with validation loss 0.7191935777664185\n",
      "Starting Epoch 17\n",
      "0.7524648982545604\n",
      "New best model found at epoch 17 with validation loss 0.7035493850708008\n",
      "Starting Epoch 18\n",
      "0.7446004359618478\n",
      "Starting Epoch 19\n",
      "0.7406575135562731\n",
      "Starting Epoch 20\n",
      "0.7394664805868397\n",
      "New best model found at epoch 20 with validation loss 0.696021318435669\n",
      "Starting Epoch 21\n",
      "0.7326059367345727\n",
      "New best model found at epoch 21 with validation loss 0.6890751719474792\n",
      "Starting Epoch 22\n",
      "0.733604996100716\n",
      "Starting Epoch 23\n",
      "0.728642419628475\n",
      "New best model found at epoch 23 with validation loss 0.6871374249458313\n",
      "Starting Epoch 24\n",
      "0.7295425326927848\n",
      "Starting Epoch 25\n",
      "0.721152126789093\n",
      "Starting Epoch 26\n",
      "0.7218465830968774\n",
      "New best model found at epoch 26 with validation loss 0.6841151118278503\n",
      "Starting Epoch 27\n",
      "0.7158248476360155\n",
      "New best model found at epoch 27 with validation loss 0.6826581358909607\n",
      "Starting Epoch 28\n",
      "0.7140478958254275\n",
      "New best model found at epoch 28 with validation loss 0.6803425550460815\n",
      "Starting Epoch 29\n",
      "0.7161856604659039\n",
      "Starting Epoch 30\n",
      "0.7130778976108717\n",
      "Starting Epoch 31\n",
      "0.7098963934442272\n",
      "New best model found at epoch 31 with validation loss 0.6740710139274597\n",
      "Starting Epoch 32\n",
      "0.7094637129617773\n",
      "Starting Epoch 33\n",
      "0.7023022822711779\n",
      "Starting Epoch 34\n",
      "0.7020207384358281\n",
      "Starting Epoch 35\n",
      "0.7011590651843859\n",
      "Starting Epoch 36\n",
      "0.7058384496232738\n",
      "Starting Epoch 37\n",
      "0.7120160901028177\n",
      "New best model found at epoch 37 with validation loss 0.6706783175468445\n",
      "Starting Epoch 38\n",
      "0.6981550532838573\n",
      "Starting Epoch 39\n",
      "0.701070090998774\n",
      "Starting Epoch 40\n",
      "0.6964353944944299\n",
      "Starting Epoch 41\n",
      "0.7038908497146938\n",
      "New best model found at epoch 41 with validation loss 0.6705336570739746\n",
      "Starting Epoch 42\n",
      "0.6970151222270468\n",
      "Starting Epoch 43\n",
      "0.696129682271377\n",
      "Starting Epoch 44\n",
      "0.696995426779208\n",
      "Starting Epoch 45\n",
      "0.6971074290897535\n",
      "Starting Epoch 46\n",
      "0.6977494151695914\n",
      "Starting Epoch 47\n",
      "0.6965084957039874\n",
      "New best model found at epoch 47 with validation loss 0.6648362874984741\n",
      "Starting Epoch 48\n",
      "0.6950143472008083\n",
      "Starting Epoch 49\n",
      "0.6940476712973221\n",
      "Starting Epoch 50\n",
      "0.6922414354656053\n",
      "Starting Epoch 51\n",
      "0.6930791295093038\n",
      "Starting Epoch 52\n",
      "0.688767847807511\n",
      "Starting Epoch 53\n",
      "0.6929206381673398\n",
      "Starting Epoch 54\n",
      "0.6910181097362352\n",
      "Starting Epoch 55\n",
      "0.6953559180964595\n",
      "Starting Epoch 56\n",
      "0.6932978552320729\n",
      "Starting Epoch 57\n",
      "0.6893256047497625\n",
      "Starting Epoch 58\n",
      "0.6867426141448643\n",
      "Starting Epoch 59\n",
      "0.6860998765282009\n",
      "Starting Epoch 60\n",
      "0.6882822694985763\n",
      "Starting Epoch 61\n",
      "0.6846666491549948\n",
      "Starting Epoch 62\n",
      "0.6858889745629352\n",
      "Starting Epoch 63\n",
      "0.6871670043986776\n",
      "Starting Epoch 64\n",
      "0.6842143224633258\n",
      "Starting Epoch 65\n",
      "0.6846918230471404\n",
      "Starting Epoch 66\n",
      "0.6880741845006528\n",
      "Starting Epoch 67\n",
      "0.684508212234663\n",
      "Starting Epoch 68\n",
      "0.6835534002469934\n",
      "New best model found at epoch 68 with validation loss 0.6643618941307068\n",
      "Starting Epoch 69\n",
      "0.6827114354009214\n",
      "Starting Epoch 70\n",
      "0.6836375931034917\n",
      "Starting Epoch 71\n",
      "0.6841531758723052\n",
      "Starting Epoch 72\n",
      "0.6860106794730477\n",
      "Starting Epoch 73\n",
      "0.681109791216643\n",
      "Starting Epoch 74\n",
      "0.6824177088944808\n",
      "New best model found at epoch 74 with validation loss 0.6636747121810913\n",
      "Starting Epoch 75\n",
      "0.6820756274720897\n",
      "Starting Epoch 76\n",
      "0.6828991045122561\n",
      "Starting Epoch 77\n",
      "0.6834614017735356\n",
      "Starting Epoch 78\n",
      "0.6838410678117172\n",
      "Starting Epoch 79\n",
      "0.6821446496507396\n",
      "Starting Epoch 80\n",
      "0.6796914339065552\n",
      "New best model found at epoch 80 with validation loss 0.6608127355575562\n",
      "Starting Epoch 81\n",
      "0.6823303129362024\n",
      "Starting Epoch 82\n",
      "0.6798485932142838\n",
      "Starting Epoch 83\n",
      "0.6805745557598446\n",
      "Starting Epoch 84\n",
      "0.6794926912888236\n",
      "Starting Epoch 85\n",
      "0.6792380602463431\n",
      "Starting Epoch 86\n",
      "0.6823671019595602\n",
      "Starting Epoch 87\n",
      "0.6764545647994332\n",
      "Starting Epoch 88\n",
      "0.6780104092929674\n",
      "Starting Epoch 89\n",
      "0.679926379867222\n",
      "Starting Epoch 90\n",
      "0.6776101122731748\n",
      "New best model found at epoch 90 with validation loss 0.6590448021888733\n",
      "Starting Epoch 91\n",
      "0.6778333575829215\n",
      "Starting Epoch 92\n",
      "0.677828488142594\n",
      "Starting Epoch 93\n",
      "0.6776484017786772\n",
      "New best model found at epoch 93 with validation loss 0.6570256352424622\n",
      "Starting Epoch 94\n",
      "0.6756411324376645\n",
      "Starting Epoch 95\n",
      "0.6790774620097616\n",
      "Starting Epoch 96\n",
      "0.6812257974044137\n",
      "Starting Epoch 97\n",
      "0.6791716451230256\n",
      "Starting Epoch 98\n",
      "0.6752813328867373\n",
      "Starting Epoch 99\n",
      "0.6762632105661475\n",
      "Starting Epoch 100\n",
      "0.675439697244893\n",
      "Starting Epoch 101\n",
      "0.6779122689495916\n",
      "Starting Epoch 102\n",
      "0.6776883602142334\n",
      "Starting Epoch 103\n",
      "0.6747223423874896\n",
      "Starting Epoch 104\n",
      "0.6733112516610519\n",
      "Starting Epoch 105\n",
      "0.6758155745008717\n",
      "Starting Epoch 106\n",
      "0.675714796004088\n",
      "Starting Epoch 107\n",
      "0.6776240442110144\n",
      "Starting Epoch 108\n",
      "0.673888175383858\n",
      "Starting Epoch 109\n",
      "0.6742783266565074\n",
      "Starting Epoch 110\n",
      "0.6770999820336051\n",
      "New best model found at epoch 110 with validation loss 0.6565366387367249\n",
      "Starting Epoch 111\n",
      "0.6756276358728823\n",
      "Starting Epoch 112\n",
      "0.674881979175236\n",
      "New best model found at epoch 112 with validation loss 0.6553642153739929\n",
      "Starting Epoch 113\n",
      "0.6772510150204534\n",
      "Starting Epoch 114\n",
      "0.6747485114180524\n",
      "Starting Epoch 115\n",
      "0.6774988770484924\n",
      "Starting Epoch 116\n",
      "0.6746948024500972\n",
      "Starting Epoch 117\n",
      "0.6723627305549124\n",
      "New best model found at epoch 117 with validation loss 0.6539391875267029\n",
      "Starting Epoch 118\n",
      "0.6712134817372197\n",
      "Starting Epoch 119\n",
      "0.6720663697823234\n",
      "Starting Epoch 120\n",
      "0.6747762418311575\n",
      "New best model found at epoch 120 with validation loss 0.6536465883255005\n",
      "Starting Epoch 121\n",
      "0.6771395621092423\n",
      "Starting Epoch 122\n",
      "0.6739625542060189\n",
      "Starting Epoch 123\n",
      "0.6752738745316215\n",
      "Starting Epoch 124\n",
      "0.6704904566640439\n",
      "Starting Epoch 125\n",
      "0.6719170575556548\n",
      "Starting Epoch 126\n",
      "0.6709445818610813\n",
      "Starting Epoch 127\n",
      "0.6733422305272974\n",
      "Starting Epoch 128\n",
      "0.6703640714935635\n",
      "Starting Epoch 129\n",
      "0.6716837805250416\n",
      "Starting Epoch 130\n",
      "0.6722023370473281\n",
      "Starting Epoch 131\n",
      "0.6709285404371179\n",
      "New best model found at epoch 131 with validation loss 0.6513313055038452\n",
      "Starting Epoch 132\n",
      "0.6701329791027567\n",
      "Starting Epoch 133\n",
      "0.6695326333460601\n",
      "Starting Epoch 134\n",
      "0.6712648142939028\n",
      "Starting Epoch 135\n",
      "0.6750417610873347\n",
      "Starting Epoch 136\n",
      "0.6723880767822266\n",
      "Starting Epoch 137\n",
      "0.6714575109274491\n",
      "Starting Epoch 138\n",
      "0.670169560805611\n",
      "New best model found at epoch 138 with validation loss 0.6490201354026794\n",
      "Starting Epoch 139\n",
      "0.6734510504681132\n",
      "Starting Epoch 140\n",
      "0.6686239242553711\n",
      "Starting Epoch 141\n",
      "0.6703478590301846\n",
      "Starting Epoch 142\n",
      "0.6693644601365795\n",
      "Starting Epoch 143\n",
      "0.6729445599991343\n",
      "Starting Epoch 144\n",
      "0.6703193395034127\n",
      "Starting Epoch 145\n",
      "0.6711337838483893\n",
      "Starting Epoch 146\n",
      "0.6741923793502476\n",
      "Starting Epoch 147\n",
      "0.6673728072124979\n",
      "Starting Epoch 148\n",
      "0.669078977211662\n",
      "Starting Epoch 149\n",
      "0.6693822119546973\n",
      "Starting Epoch 150\n",
      "0.6695710342863331\n",
      "Starting Epoch 151\n",
      "0.6671522259712219\n",
      "Starting Epoch 152\n",
      "0.6691023033598195\n",
      "Starting Epoch 153\n",
      "0.6682505244794099\n",
      "Starting Epoch 154\n",
      "0.6690477417862933\n",
      "Starting Epoch 155\n",
      "0.6675894415896871\n",
      "New best model found at epoch 155 with validation loss 0.6484808921813965\n",
      "Starting Epoch 156\n",
      "0.6702894646188488\n",
      "New best model found at epoch 156 with validation loss 0.6482422947883606\n",
      "Starting Epoch 157\n",
      "0.6686844411103622\n",
      "Starting Epoch 158\n",
      "0.6697962724644205\n",
      "Starting Epoch 159\n",
      "0.670999615088753\n",
      "Starting Epoch 160\n",
      "0.6683965299440466\n",
      "Starting Epoch 161\n",
      "0.6677132715349612\n",
      "Starting Epoch 162\n",
      "0.6661859025125918\n",
      "New best model found at epoch 162 with validation loss 0.6468172669410706\n",
      "Starting Epoch 163\n",
      "0.6690194762271383\n",
      "Starting Epoch 164\n",
      "0.6690761524698009\n",
      "Starting Epoch 165\n",
      "0.6678769407065018\n",
      "Starting Epoch 166\n",
      "0.668669221193894\n",
      "Starting Epoch 167\n",
      "0.6686777835306914\n",
      "Starting Epoch 168\n",
      "0.6686236184576283\n",
      "New best model found at epoch 168 with validation loss 0.6455583572387695\n",
      "Starting Epoch 169\n",
      "0.6675586985505145\n",
      "Starting Epoch 170\n",
      "0.6676035212433856\n",
      "Starting Epoch 171\n",
      "0.6686383226643438\n",
      "Starting Epoch 172\n",
      "0.6708407972169959\n",
      "Starting Epoch 173\n",
      "0.6667943855990535\n",
      "Starting Epoch 174\n",
      "0.6670784872511158\n",
      "Starting Epoch 175\n",
      "0.6673440259435902\n",
      "Starting Epoch 176\n",
      "0.6653165169384169\n",
      "Starting Epoch 177\n",
      "0.6666743444359821\n",
      "Starting Epoch 178\n",
      "0.6668992249862008\n",
      "Starting Epoch 179\n",
      "0.6659930892612623\n",
      "Starting Epoch 180\n",
      "0.6667665243148804\n",
      "Starting Epoch 181\n",
      "0.6662413011426511\n",
      "Starting Epoch 182\n",
      "0.6662117165067921\n",
      "Starting Epoch 183\n",
      "0.6678345099739407\n",
      "Starting Epoch 184\n",
      "0.6687697301740232\n",
      "Starting Epoch 185\n",
      "0.6653673959814984\n",
      "Starting Epoch 186\n",
      "0.6676723075949628\n",
      "Starting Epoch 187\n",
      "0.6660685046859409\n",
      "Starting Epoch 188\n",
      "0.664208357748778\n",
      "Starting Epoch 189\n",
      "0.6654639166334401\n",
      "Starting Epoch 190\n",
      "0.6658238133658534\n",
      "Starting Epoch 191\n",
      "0.6668824035188426\n",
      "Starting Epoch 192\n",
      "0.6655639280443606\n",
      "New best model found at epoch 192 with validation loss 0.6433636546134949\n",
      "Starting Epoch 193\n",
      "0.6653371194134587\n",
      "Starting Epoch 194\n",
      "0.6654357728750809\n",
      "New best model found at epoch 194 with validation loss 0.6427189111709595\n",
      "Starting Epoch 195\n",
      "0.6661404889562855\n",
      "Starting Epoch 196\n",
      "0.6619196119515792\n",
      "Starting Epoch 197\n",
      "0.6635916466298311\n",
      "Starting Epoch 198\n",
      "0.6641719393108202\n",
      "Starting Epoch 199\n",
      "0.6651196272476859\n",
      "Starting Epoch 200\n",
      "0.6660099832907967\n",
      "Starting Epoch 201\n",
      "0.6654116018958713\n",
      "Starting Epoch 202\n",
      "0.6647271164085554\n",
      "Starting Epoch 203\n",
      "0.665522178877955\n",
      "Starting Epoch 204\n",
      "0.6653759090796761\n",
      "Starting Epoch 205\n",
      "0.6632220278615537\n",
      "Starting Epoch 206\n",
      "0.6657264906427135\n",
      "Starting Epoch 207\n",
      "0.6648690583913223\n",
      "Starting Epoch 208\n",
      "0.6638992480609728\n",
      "New best model found at epoch 208 with validation loss 0.6425992846488953\n",
      "Starting Epoch 209\n",
      "0.6660329880921737\n",
      "Starting Epoch 210\n",
      "0.6646754327027694\n",
      "Starting Epoch 211\n",
      "0.6625578636708467\n",
      "Starting Epoch 212\n",
      "0.6645057823347009\n",
      "New best model found at epoch 212 with validation loss 0.6414771676063538\n",
      "Starting Epoch 213\n",
      "0.6649135584416597\n",
      "Starting Epoch 214\n",
      "0.663728434106578\n",
      "New best model found at epoch 214 with validation loss 0.6412566900253296\n",
      "Starting Epoch 215\n",
      "0.6633518053137738\n",
      "Starting Epoch 216\n",
      "0.6639582138994465\n",
      "Starting Epoch 217\n",
      "0.6628259860950968\n",
      "Starting Epoch 218\n",
      "0.6663743464843087\n",
      "Starting Epoch 219\n",
      "0.6630232334136963\n",
      "Starting Epoch 220\n",
      "0.663513297620027\n",
      "Starting Epoch 221\n",
      "0.664328484431557\n",
      "Starting Epoch 222\n",
      "0.6630170785862467\n",
      "Starting Epoch 223\n",
      "0.6628332215806713\n",
      "New best model found at epoch 223 with validation loss 0.6412503719329834\n",
      "Starting Epoch 224\n",
      "0.6621442152106244\n",
      "New best model found at epoch 224 with validation loss 0.6404014229774475\n",
      "Starting Epoch 225\n",
      "0.6617286386697189\n",
      "Starting Epoch 226\n",
      "0.6612722199896107\n",
      "Starting Epoch 227\n",
      "0.6611686530320541\n",
      "Starting Epoch 228\n",
      "0.6618899728940881\n",
      "Starting Epoch 229\n",
      "0.6656937949035479\n",
      "Starting Epoch 230\n",
      "0.661305837009264\n",
      "New best model found at epoch 230 with validation loss 0.6402468681335449\n",
      "Starting Epoch 231\n",
      "0.6608587062877157\n",
      "Starting Epoch 232\n",
      "0.6636670231819153\n",
      "Starting Epoch 233\n",
      "0.6612733291543048\n",
      "Starting Epoch 234\n",
      "0.6619176683218583\n",
      "Starting Epoch 235\n",
      "0.6628222906071207\n",
      "New best model found at epoch 235 with validation loss 0.6398468613624573\n",
      "Starting Epoch 236\n",
      "0.6614118296167125\n",
      "Starting Epoch 237\n",
      "0.6612350215082583\n",
      "Starting Epoch 238\n",
      "0.6617524468380472\n",
      "Starting Epoch 239\n",
      "0.6617009976635808\n",
      "Starting Epoch 240\n",
      "0.6602451697639797\n",
      "Starting Epoch 241\n",
      "0.661020885343137\n",
      "New best model found at epoch 241 with validation loss 0.6395891904830933\n",
      "Starting Epoch 242\n",
      "0.6613124583078467\n",
      "Starting Epoch 243\n",
      "0.6615430116653442\n",
      "Starting Epoch 244\n",
      "0.6606209925983263\n",
      "Starting Epoch 245\n",
      "0.6624389498130135\n",
      "New best model found at epoch 245 with validation loss 0.6378887891769409\n",
      "Starting Epoch 246\n",
      "0.6661143976709117\n",
      "Starting Epoch 247\n",
      "0.6606743931770325\n",
      "Starting Epoch 248\n",
      "0.6601443860841834\n",
      "Starting Epoch 249\n",
      "0.660174996956535\n",
      "Starting Epoch 250\n",
      "0.6589661888454271\n",
      "Starting Epoch 251\n",
      "0.6603869951289633\n",
      "Starting Epoch 252\n",
      "0.6593802934107573\n",
      "Starting Epoch 253\n",
      "0.6591463335182356\n",
      "Starting Epoch 254\n",
      "0.6604783664578977\n",
      "Starting Epoch 255\n",
      "0.6628783552542977\n",
      "New best model found at epoch 255 with validation loss 0.637748122215271\n",
      "Starting Epoch 256\n",
      "0.658001827157062\n",
      "Starting Epoch 257\n",
      "0.6596614200135936\n",
      "Starting Epoch 258\n",
      "0.6604851225148076\n",
      "Starting Epoch 259\n",
      "0.6589485873346743\n",
      "Starting Epoch 260\n",
      "0.657452510750812\n",
      "Starting Epoch 261\n",
      "0.6576044844544452\n",
      "New best model found at epoch 261 with validation loss 0.6371945738792419\n",
      "Starting Epoch 262\n",
      "0.6599341371785039\n",
      "Starting Epoch 263\n",
      "0.6606921035310497\n",
      "Starting Epoch 264\n",
      "0.6585899824681489\n",
      "Starting Epoch 265\n",
      "0.6593474875325742\n",
      "Starting Epoch 266\n",
      "0.657305341699849\n",
      "Starting Epoch 267\n",
      "0.6604540581288545\n",
      "Starting Epoch 268\n",
      "0.6592323469079059\n",
      "New best model found at epoch 268 with validation loss 0.6371739506721497\n",
      "Starting Epoch 269\n",
      "0.6599135036053865\n",
      "Starting Epoch 270\n",
      "0.6588006382403166\n",
      "Starting Epoch 271\n",
      "0.6581736932630124\n",
      "Starting Epoch 272\n",
      "0.6605055565419404\n",
      "Starting Epoch 273\n",
      "0.6582634630410568\n",
      "Starting Epoch 274\n",
      "0.6601150035858154\n",
      "Starting Epoch 275\n",
      "0.6588893817818683\n",
      "Starting Epoch 276\n",
      "0.6591162033703016\n",
      "Starting Epoch 277\n",
      "0.6587636393049489\n",
      "Starting Epoch 278\n",
      "0.6598533884338711\n",
      "Starting Epoch 279\n",
      "0.6574414709339971\n",
      "Starting Epoch 280\n",
      "0.6580865823704264\n",
      "New best model found at epoch 280 with validation loss 0.6349973678588867\n",
      "Starting Epoch 281\n",
      "0.6567308514014535\n",
      "Starting Epoch 282\n",
      "0.6579167480054109\n",
      "Starting Epoch 283\n",
      "0.6577155175416366\n",
      "Starting Epoch 284\n",
      "0.6584240275880565\n",
      "New best model found at epoch 284 with validation loss 0.6347973942756653\n",
      "Starting Epoch 285\n",
      "0.6609776434691056\n",
      "Starting Epoch 286\n",
      "0.6581422712491907\n",
      "Starting Epoch 287\n",
      "0.6593222086844237\n",
      "New best model found at epoch 287 with validation loss 0.633621096611023\n",
      "Starting Epoch 288\n",
      "0.6557197933611663\n",
      "Starting Epoch 289\n",
      "0.6569317864335101\n",
      "New best model found at epoch 289 with validation loss 0.632972776889801\n",
      "Starting Epoch 290\n",
      "0.6562873669292616\n",
      "New best model found at epoch 290 with validation loss 0.6311931610107422\n",
      "Starting Epoch 291\n",
      "0.656014832465545\n",
      "Starting Epoch 292\n",
      "0.6569291275480519\n",
      "Starting Epoch 293\n",
      "0.6590048929919368\n",
      "Starting Epoch 294\n",
      "0.6583771757457567\n",
      "New best model found at epoch 294 with validation loss 0.6303353309631348\n",
      "Starting Epoch 295\n",
      "0.6557351298954176\n",
      "Starting Epoch 296\n",
      "0.6556518777557041\n",
      "Starting Epoch 297\n",
      "0.6586195100908694\n",
      "New best model found at epoch 297 with validation loss 0.6302843689918518\n",
      "Starting Epoch 298\n",
      "0.6579152475232664\n",
      "Starting Epoch 299\n",
      "0.6560945381288943\n",
      "Starting Epoch 300\n",
      "0.6559781717217487\n",
      "New best model found at epoch 300 with validation loss 0.6291304230690002\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-25-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7ff8151a-aa3a-4ab6-b584-325ab115f950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.2857670654421267\n",
      "New best model found at epoch 1 with validation loss 1.0584626197814941\n",
      "Starting Epoch 2\n",
      "1.0330183169116145\n",
      "New best model found at epoch 2 with validation loss 1.0459928512573242\n",
      "Starting Epoch 3\n",
      "1.0231009047964346\n",
      "New best model found at epoch 3 with validation loss 1.035426378250122\n",
      "Starting Epoch 4\n",
      "1.0144782791966978\n",
      "New best model found at epoch 4 with validation loss 1.0306583642959595\n",
      "Starting Epoch 5\n",
      "1.0109040089275525\n",
      "Starting Epoch 6\n",
      "1.001822248749111\n",
      "New best model found at epoch 6 with validation loss 1.0269851684570312\n",
      "Starting Epoch 7\n",
      "0.998064258824224\n",
      "New best model found at epoch 7 with validation loss 1.0142207145690918\n",
      "Starting Epoch 8\n",
      "0.9860329524330471\n",
      "New best model found at epoch 8 with validation loss 1.0080522298812866\n",
      "Starting Epoch 9\n",
      "0.9825691295706708\n",
      "Starting Epoch 10\n",
      "0.9737702193467513\n",
      "New best model found at epoch 10 with validation loss 1.007343053817749\n",
      "Starting Epoch 11\n",
      "0.9663181097611137\n",
      "New best model found at epoch 11 with validation loss 0.9899492859840393\n",
      "Starting Epoch 12\n",
      "0.9665275371592977\n",
      "Starting Epoch 13\n",
      "0.9599065858384838\n",
      "Starting Epoch 14\n",
      "0.9513697753781858\n",
      "New best model found at epoch 14 with validation loss 0.980323076248169\n",
      "Starting Epoch 15\n",
      "0.9478817167489425\n",
      "New best model found at epoch 15 with validation loss 0.9739932417869568\n",
      "Starting Epoch 16\n",
      "0.9449018732361172\n",
      "New best model found at epoch 16 with validation loss 0.9635143280029297\n",
      "Starting Epoch 17\n",
      "0.9353687529978545\n",
      "Starting Epoch 18\n",
      "0.93097193085629\n",
      "New best model found at epoch 18 with validation loss 0.9607851505279541\n",
      "Starting Epoch 19\n",
      "0.9264317180799402\n",
      "Starting Epoch 20\n",
      "0.9247680487840072\n",
      "New best model found at epoch 20 with validation loss 0.9504706263542175\n",
      "Starting Epoch 21\n",
      "0.9164736478225045\n",
      "New best model found at epoch 21 with validation loss 0.9351058602333069\n",
      "Starting Epoch 22\n",
      "0.9097078623978988\n",
      "Starting Epoch 23\n",
      "0.9101750539696735\n",
      "New best model found at epoch 23 with validation loss 0.9289259314537048\n",
      "Starting Epoch 24\n",
      "0.9187906591788583\n",
      "Starting Epoch 25\n",
      "0.905424511950949\n",
      "Starting Epoch 26\n",
      "0.9010735231897106\n",
      "New best model found at epoch 26 with validation loss 0.9176075458526611\n",
      "Starting Epoch 27\n",
      "0.9002163462016893\n",
      "Starting Epoch 28\n",
      "0.8976692427759585\n",
      "New best model found at epoch 28 with validation loss 0.9110323786735535\n",
      "Starting Epoch 29\n",
      "0.8997990618581357\n",
      "Starting Epoch 30\n",
      "0.8935732660086259\n",
      "Starting Epoch 31\n",
      "0.8935705164204473\n",
      "New best model found at epoch 31 with validation loss 0.9076038599014282\n",
      "Starting Epoch 32\n",
      "0.8914681102918542\n",
      "Starting Epoch 33\n",
      "0.882925720318504\n",
      "New best model found at epoch 33 with validation loss 0.9067907929420471\n",
      "Starting Epoch 34\n",
      "0.8802650389464005\n",
      "Starting Epoch 35\n",
      "0.8780873910240505\n",
      "New best model found at epoch 35 with validation loss 0.9000602960586548\n",
      "Starting Epoch 36\n",
      "0.8832100707551708\n",
      "Starting Epoch 37\n",
      "0.8859827959019205\n",
      "Starting Epoch 38\n",
      "0.8752029849135358\n",
      "Starting Epoch 39\n",
      "0.8741107168404952\n",
      "New best model found at epoch 39 with validation loss 0.8960700631141663\n",
      "Starting Epoch 40\n",
      "0.877737291481184\n",
      "Starting Epoch 41\n",
      "0.8768289115117944\n",
      "Starting Epoch 42\n",
      "0.8730995680974878\n",
      "New best model found at epoch 42 with validation loss 0.895279586315155\n",
      "Starting Epoch 43\n",
      "0.8755446387373883\n",
      "Starting Epoch 44\n",
      "0.8725547505461652\n",
      "Starting Epoch 45\n",
      "0.8764813049979832\n",
      "Starting Epoch 46\n",
      "0.8728490808735723\n",
      "New best model found at epoch 46 with validation loss 0.8939597606658936\n",
      "Starting Epoch 47\n",
      "0.8701657419619353\n",
      "Starting Epoch 48\n",
      "0.8758320290109386\n",
      "Starting Epoch 49\n",
      "0.8732877632846003\n",
      "Starting Epoch 50\n",
      "0.870643499104873\n",
      "Starting Epoch 51\n",
      "0.8674803324367689\n",
      "New best model found at epoch 51 with validation loss 0.8928247690200806\n",
      "Starting Epoch 52\n",
      "0.8645651392314745\n",
      "Starting Epoch 53\n",
      "0.8674014262531115\n",
      "Starting Epoch 54\n",
      "0.866955482441446\n",
      "New best model found at epoch 54 with validation loss 0.8911359906196594\n",
      "Starting Epoch 55\n",
      "0.8701544067134028\n",
      "New best model found at epoch 55 with validation loss 0.8854014277458191\n",
      "Starting Epoch 56\n",
      "0.8668420081553252\n",
      "Starting Epoch 57\n",
      "0.8699208316595658\n",
      "Starting Epoch 58\n",
      "0.8657289613848147\n",
      "Starting Epoch 59\n",
      "0.8667579370996227\n",
      "Starting Epoch 60\n",
      "0.8670749197835508\n",
      "Starting Epoch 61\n",
      "0.8638621542764746\n",
      "Starting Epoch 62\n",
      "0.865374383719071\n",
      "Starting Epoch 63\n",
      "0.8645012974739075\n",
      "New best model found at epoch 63 with validation loss 0.8838201761245728\n",
      "Starting Epoch 64\n",
      "0.8586885151655778\n",
      "Starting Epoch 65\n",
      "0.8624625594719596\n",
      "Starting Epoch 66\n",
      "0.8624568192855172\n",
      "Starting Epoch 67\n",
      "0.8594655575959579\n",
      "Starting Epoch 68\n",
      "0.8598403308702551\n",
      "Starting Epoch 69\n",
      "0.8616227844487065\n",
      "Starting Epoch 70\n",
      "0.8608198399129121\n",
      "Starting Epoch 71\n",
      "0.8624548471492269\n",
      "Starting Epoch 72\n",
      "0.8588971884354301\n",
      "Starting Epoch 73\n",
      "0.857107514920442\n",
      "Starting Epoch 74\n",
      "0.8627177813778752\n",
      "Starting Epoch 75\n",
      "0.8578815149224323\n",
      "Starting Epoch 76\n",
      "0.8627486436263375\n",
      "Starting Epoch 77\n",
      "0.863640995129295\n",
      "Starting Epoch 78\n",
      "0.8558262094207432\n",
      "New best model found at epoch 78 with validation loss 0.8799126744270325\n",
      "Starting Epoch 79\n",
      "0.8536745465320089\n",
      "Starting Epoch 80\n",
      "0.8547594676847043\n",
      "Starting Epoch 81\n",
      "0.8572520328604657\n",
      "Starting Epoch 82\n",
      "0.8577342240706735\n",
      "Starting Epoch 83\n",
      "0.8557427447775136\n",
      "Starting Epoch 84\n",
      "0.8547663921895234\n",
      "Starting Epoch 85\n",
      "0.854417930478635\n",
      "Starting Epoch 86\n",
      "0.8576240850531537\n",
      "Starting Epoch 87\n",
      "0.8517305254936218\n",
      "New best model found at epoch 87 with validation loss 0.879626989364624\n",
      "Starting Epoch 88\n",
      "0.8522862636524698\n",
      "Starting Epoch 89\n",
      "0.8590453707653544\n",
      "Starting Epoch 90\n",
      "0.8553983491400013\n",
      "Starting Epoch 91\n",
      "0.8548915930416273\n",
      "Starting Epoch 92\n",
      "0.8549759180649467\n",
      "Starting Epoch 93\n",
      "0.853172602860824\n",
      "Starting Epoch 94\n",
      "0.8516150039175282\n",
      "Starting Epoch 95\n",
      "0.8541416188944941\n",
      "Starting Epoch 96\n",
      "0.8533381534659344\n",
      "Starting Epoch 97\n",
      "0.8590873764908832\n",
      "Starting Epoch 98\n",
      "0.8520633241404658\n",
      "Starting Epoch 99\n",
      "0.8507910681807477\n",
      "Starting Epoch 100\n",
      "0.8496917356615481\n",
      "New best model found at epoch 100 with validation loss 0.8792585730552673\n",
      "Starting Epoch 101\n",
      "0.8523260147675223\n",
      "Starting Epoch 102\n",
      "0.852114094340283\n",
      "Starting Epoch 103\n",
      "0.850854754447937\n",
      "Starting Epoch 104\n",
      "0.8533936816713085\n",
      "New best model found at epoch 104 with validation loss 0.8779482841491699\n",
      "Starting Epoch 105\n",
      "0.8536269535189089\n",
      "Starting Epoch 106\n",
      "0.8524040761201278\n",
      "Starting Epoch 107\n",
      "0.8519972796025483\n",
      "Starting Epoch 108\n",
      "0.8483797130377396\n",
      "Starting Epoch 109\n",
      "0.8516029819198276\n",
      "Starting Epoch 110\n",
      "0.8493787050247192\n",
      "New best model found at epoch 110 with validation loss 0.8778795003890991\n",
      "Starting Epoch 111\n",
      "0.8482528769451639\n",
      "Starting Epoch 112\n",
      "0.8489912048630093\n",
      "Starting Epoch 113\n",
      "0.8550657889117366\n",
      "Starting Epoch 114\n",
      "0.8511541045230367\n",
      "Starting Epoch 115\n",
      "0.8519220300342726\n",
      "Starting Epoch 116\n",
      "0.8484659505927045\n",
      "Starting Epoch 117\n",
      "0.8451806073603423\n",
      "Starting Epoch 118\n",
      "0.8471623218577841\n",
      "Starting Epoch 119\n",
      "0.8476630708445674\n",
      "Starting Epoch 120\n",
      "0.8481667404589446\n",
      "Starting Epoch 121\n",
      "0.8511464595794678\n",
      "Starting Epoch 122\n",
      "0.847328826137211\n",
      "Starting Epoch 123\n",
      "0.8470486195191093\n",
      "Starting Epoch 124\n",
      "0.8463889930559241\n",
      "Starting Epoch 125\n",
      "0.8476151072460673\n",
      "Starting Epoch 126\n",
      "0.8474394108938135\n",
      "Starting Epoch 127\n",
      "0.8489178159962529\n",
      "Starting Epoch 128\n",
      "0.8448719796927079\n",
      "Starting Epoch 129\n",
      "0.847478625567063\n",
      "Starting Epoch 130\n",
      "0.8437081134837606\n",
      "Starting Epoch 131\n",
      "0.8485913147097048\n",
      "Starting Epoch 132\n",
      "0.843523911807848\n",
      "Starting Epoch 133\n",
      "0.8447286201559979\n",
      "Starting Epoch 134\n",
      "0.8451094886531001\n",
      "Starting Epoch 135\n",
      "0.8480355091716932\n",
      "Starting Epoch 136\n",
      "0.8474988082180852\n",
      "Starting Epoch 137\n",
      "0.8461116941078849\n",
      "Starting Epoch 138\n",
      "0.847384292146434\n",
      "Starting Epoch 139\n",
      "0.8476121840269669\n",
      "New best model found at epoch 139 with validation loss 0.8768428564071655\n",
      "Starting Epoch 140\n",
      "0.8442939934523209\n",
      "Starting Epoch 141\n",
      "0.8432858068010082\n",
      "New best model found at epoch 141 with validation loss 0.8763813376426697\n",
      "Starting Epoch 142\n",
      "0.8464775266854659\n",
      "Starting Epoch 143\n",
      "0.8470026487889497\n",
      "New best model found at epoch 143 with validation loss 0.8741613030433655\n",
      "Starting Epoch 144\n",
      "0.8452424536580625\n",
      "Starting Epoch 145\n",
      "0.844698289166326\n",
      "Starting Epoch 146\n",
      "0.8432826607123666\n",
      "Starting Epoch 147\n",
      "0.8448983249456986\n",
      "Starting Epoch 148\n",
      "0.8455442967622177\n",
      "Starting Epoch 149\n",
      "0.8436677170836407\n",
      "Starting Epoch 150\n",
      "0.8423520222954128\n",
      "Starting Epoch 151\n",
      "0.8434638977050781\n",
      "Starting Epoch 152\n",
      "0.8424460032711858\n",
      "Starting Epoch 153\n",
      "0.8431816515715226\n",
      "Starting Epoch 154\n",
      "0.8419300265934156\n",
      "Starting Epoch 155\n",
      "0.8406138212784476\n",
      "New best model found at epoch 155 with validation loss 0.8736423850059509\n",
      "Starting Epoch 156\n",
      "0.8426741905834364\n",
      "Starting Epoch 157\n",
      "0.8426959566448046\n",
      "Starting Epoch 158\n",
      "0.8436276135237321\n",
      "Starting Epoch 159\n",
      "0.8471149879953136\n",
      "Starting Epoch 160\n",
      "0.8421572628228561\n",
      "Starting Epoch 161\n",
      "0.8464232242625692\n",
      "Starting Epoch 162\n",
      "0.840597372987996\n",
      "Starting Epoch 163\n",
      "0.8398919105529785\n",
      "Starting Epoch 164\n",
      "0.8409418230471404\n",
      "Starting Epoch 165\n",
      "0.8397575124450352\n",
      "Starting Epoch 166\n",
      "0.8446467052335325\n",
      "Starting Epoch 167\n",
      "0.8425814664882162\n",
      "Starting Epoch 168\n",
      "0.8384602432665618\n",
      "Starting Epoch 169\n",
      "0.8412763631862142\n",
      "Starting Epoch 170\n",
      "0.8397100412327311\n",
      "Starting Epoch 171\n",
      "0.8394157886505127\n",
      "Starting Epoch 172\n",
      "0.8415711807168048\n",
      "Starting Epoch 173\n",
      "0.8441850776257722\n",
      "Starting Epoch 174\n",
      "0.8398169797399769\n",
      "Starting Epoch 175\n",
      "0.8411380493122599\n",
      "Starting Epoch 176\n",
      "0.8380976863529371\n",
      "Starting Epoch 177\n",
      "0.8412060322968856\n",
      "Starting Epoch 178\n",
      "0.8415752545647\n",
      "New best model found at epoch 178 with validation loss 0.8723679780960083\n",
      "Starting Epoch 179\n",
      "0.8419947442801102\n",
      "Starting Epoch 180\n",
      "0.8377880013507345\n",
      "Starting Epoch 181\n",
      "0.8394308997237164\n",
      "Starting Epoch 182\n",
      "0.8399277925491333\n",
      "Starting Epoch 183\n",
      "0.8389698629793914\n",
      "Starting Epoch 184\n",
      "0.8386175062345422\n",
      "Starting Epoch 185\n",
      "0.8377032487288766\n",
      "Starting Epoch 186\n",
      "0.8425282524979633\n",
      "New best model found at epoch 186 with validation loss 0.8704067468643188\n",
      "Starting Epoch 187\n",
      "0.8405098241308461\n",
      "Starting Epoch 188\n",
      "0.8371285148288893\n",
      "Starting Epoch 189\n",
      "0.8373537270919137\n",
      "Starting Epoch 190\n",
      "0.8398849342180335\n",
      "Starting Epoch 191\n",
      "0.8392371924027152\n",
      "Starting Epoch 192\n",
      "0.8388680867526842\n",
      "Starting Epoch 193\n",
      "0.8383883056433304\n",
      "Starting Epoch 194\n",
      "0.835044238878333\n",
      "New best model found at epoch 194 with validation loss 0.8699015378952026\n",
      "Starting Epoch 195\n",
      "0.837365140085635\n",
      "Starting Epoch 196\n",
      "0.8345096992409747\n",
      "Starting Epoch 197\n",
      "0.8359504834465359\n",
      "Starting Epoch 198\n",
      "0.8384789668995402\n",
      "Starting Epoch 199\n",
      "0.8367104271183843\n",
      "Starting Epoch 200\n",
      "0.8374127382817476\n",
      "Starting Epoch 201\n",
      "0.8368849909823873\n",
      "Starting Epoch 202\n",
      "0.8343602263409159\n",
      "Starting Epoch 203\n",
      "0.836093052573826\n",
      "Starting Epoch 204\n",
      "0.8344753954721533\n",
      "Starting Epoch 205\n",
      "0.8398589725079744\n",
      "Starting Epoch 206\n",
      "0.8349018122838892\n",
      "Starting Epoch 207\n",
      "0.8361069896946782\n",
      "Starting Epoch 208\n",
      "0.8373646062353383\n",
      "New best model found at epoch 208 with validation loss 0.8695439696311951\n",
      "Starting Epoch 209\n",
      "0.8401946062627046\n",
      "Starting Epoch 210\n",
      "0.837542334328527\n",
      "Starting Epoch 211\n",
      "0.835145248019177\n",
      "Starting Epoch 212\n",
      "0.8338260935700458\n",
      "Starting Epoch 213\n",
      "0.8366450200910154\n",
      "Starting Epoch 214\n",
      "0.8379164389942003\n",
      "Starting Epoch 215\n",
      "0.8382678653882898\n",
      "Starting Epoch 216\n",
      "0.8348280087761257\n",
      "Starting Epoch 217\n",
      "0.8364347349042478\n",
      "Starting Epoch 218\n",
      "0.836397445720175\n",
      "Starting Epoch 219\n",
      "0.834419336007989\n",
      "New best model found at epoch 219 with validation loss 0.8664313554763794\n",
      "Starting Epoch 220\n",
      "0.8349002418310746\n",
      "Starting Epoch 221\n",
      "0.8339162468910217\n",
      "Starting Epoch 222\n",
      "0.8345611017683278\n",
      "Starting Epoch 223\n",
      "0.8332641409791034\n",
      "Starting Epoch 224\n",
      "0.8340394004531528\n",
      "Starting Epoch 225\n",
      "0.8383581560590992\n",
      "Starting Epoch 226\n",
      "0.8380547062210415\n",
      "Starting Epoch 227\n",
      "0.8360291797181835\n",
      "Starting Epoch 228\n",
      "0.8316749697146208\n",
      "Starting Epoch 229\n",
      "0.8355113682539567\n",
      "Starting Epoch 230\n",
      "0.834673531677412\n",
      "Starting Epoch 231\n",
      "0.8335325355115144\n",
      "Starting Epoch 232\n",
      "0.8343166423880536\n",
      "Starting Epoch 233\n",
      "0.8318967871043993\n",
      "Starting Epoch 234\n",
      "0.8366905062094979\n",
      "Starting Epoch 235\n",
      "0.8326538671617922\n",
      "Starting Epoch 236\n",
      "0.8314182291860166\n",
      "Starting Epoch 237\n",
      "0.831921372724616\n",
      "Starting Epoch 238\n",
      "0.8351239613864733\n",
      "Starting Epoch 239\n",
      "0.8317536245221677\n",
      "Starting Epoch 240\n",
      "0.8326925117036571\n",
      "Starting Epoch 241\n",
      "0.8325633458469225\n",
      "Starting Epoch 242\n",
      "0.8340546981148098\n",
      "Starting Epoch 243\n",
      "0.8344014908956445\n",
      "Starting Epoch 244\n",
      "0.8328972044198409\n",
      "Starting Epoch 245\n",
      "0.8326201698054438\n",
      "Starting Epoch 246\n",
      "0.8320823234060536\n",
      "Starting Epoch 247\n",
      "0.8342008331547612\n",
      "Starting Epoch 248\n",
      "0.8330996503000674\n",
      "Starting Epoch 249\n",
      "0.8328163753385129\n",
      "Starting Epoch 250\n",
      "0.8315578776857128\n",
      "Starting Epoch 251\n",
      "0.8342698423758798\n",
      "Starting Epoch 252\n",
      "0.8318353839542555\n",
      "Starting Epoch 253\n",
      "0.8310745565787606\n",
      "Starting Epoch 254\n",
      "0.8318677622339\n",
      "Starting Epoch 255\n",
      "0.8336380849713865\n",
      "Starting Epoch 256\n",
      "0.8314803760984669\n",
      "Starting Epoch 257\n",
      "0.830266509367072\n",
      "Starting Epoch 258\n",
      "0.8313594978788624\n",
      "Starting Epoch 259\n",
      "0.8287664159484531\n",
      "Starting Epoch 260\n",
      "0.8312215908713962\n",
      "Starting Epoch 261\n",
      "0.8312010428179866\n",
      "Starting Epoch 262\n",
      "0.8303108033926591\n",
      "Starting Epoch 263\n",
      "0.8291592934857244\n",
      "Starting Epoch 264\n",
      "0.8299295798591946\n",
      "Starting Epoch 265\n",
      "0.8316099643707275\n",
      "New best model found at epoch 265 with validation loss 0.8659833073616028\n",
      "Starting Epoch 266\n",
      "0.8310345618621163\n",
      "Starting Epoch 267\n",
      "0.8303599642670673\n",
      "Starting Epoch 268\n",
      "0.832170087358226\n",
      "Starting Epoch 269\n",
      "0.8303291123846303\n",
      "Starting Epoch 270\n",
      "0.8325360546941343\n",
      "Starting Epoch 271\n",
      "0.8284481193708337\n",
      "Starting Epoch 272\n",
      "0.8336927476136581\n",
      "Starting Epoch 273\n",
      "0.830164795336516\n",
      "Starting Epoch 274\n",
      "0.8325353860855103\n",
      "Starting Epoch 275\n",
      "0.8304720961529276\n",
      "Starting Epoch 276\n",
      "0.8313281536102295\n",
      "Starting Epoch 277\n",
      "0.8304012884264407\n",
      "Starting Epoch 278\n",
      "0.8312015196551448\n",
      "Starting Epoch 279\n",
      "0.8338246760161027\n",
      "Starting Epoch 280\n",
      "0.8307812628538712\n",
      "New best model found at epoch 280 with validation loss 0.8657495379447937\n",
      "Starting Epoch 281\n",
      "0.8302490918532662\n",
      "New best model found at epoch 281 with validation loss 0.8655245304107666\n",
      "Starting Epoch 282\n",
      "0.8280989890513213\n",
      "Starting Epoch 283\n",
      "0.8285605726034745\n",
      "Starting Epoch 284\n",
      "0.8275441605111827\n",
      "Starting Epoch 285\n",
      "0.8342893175456835\n",
      "New best model found at epoch 285 with validation loss 0.8654769659042358\n",
      "Starting Epoch 286\n",
      "0.8282698392868042\n",
      "Starting Epoch 287\n",
      "0.8293061230493628\n",
      "New best model found at epoch 287 with validation loss 0.8646955490112305\n",
      "Starting Epoch 288\n",
      "0.8268228561981864\n",
      "Starting Epoch 289\n",
      "0.8303918061049088\n",
      "Starting Epoch 290\n",
      "0.8287316975386246\n",
      "Starting Epoch 291\n",
      "0.8300677693408468\n",
      "New best model found at epoch 291 with validation loss 0.8637751340866089\n",
      "Starting Epoch 292\n",
      "0.8283887090890304\n",
      "Starting Epoch 293\n",
      "0.831112291501916\n",
      "Starting Epoch 294\n",
      "0.8263518784357153\n",
      "New best model found at epoch 294 with validation loss 0.8622351288795471\n",
      "Starting Epoch 295\n",
      "0.8277645007423733\n",
      "Starting Epoch 296\n",
      "0.8290910746740259\n",
      "Starting Epoch 297\n",
      "0.8281380845152814\n",
      "Starting Epoch 298\n",
      "0.8309887388478154\n",
      "Starting Epoch 299\n",
      "0.8275082629659901\n",
      "Starting Epoch 300\n",
      "0.827779145344444\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-25-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a530c87f-297f-4ba2-9c2a-bbc927a40528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "1.1851190328598022\n",
      "New best model found at epoch 1 with validation loss 1.006568431854248\n",
      "Starting Epoch 2\n",
      "0.9743214249610901\n",
      "New best model found at epoch 2 with validation loss 0.9910430908203125\n",
      "Starting Epoch 3\n",
      "0.9669103829757028\n",
      "New best model found at epoch 3 with validation loss 0.9842290282249451\n",
      "Starting Epoch 4\n",
      "0.9578322068504665\n",
      "New best model found at epoch 4 with validation loss 0.9758389592170715\n",
      "Starting Epoch 5\n",
      "0.9510037536206453\n",
      "Starting Epoch 6\n",
      "0.9425387589827828\n",
      "New best model found at epoch 6 with validation loss 0.9673057794570923\n",
      "Starting Epoch 7\n",
      "0.9380835605704266\n",
      "New best model found at epoch 7 with validation loss 0.9577319622039795\n",
      "Starting Epoch 8\n",
      "0.9255924820899963\n",
      "Starting Epoch 9\n",
      "0.9232097734575686\n",
      "New best model found at epoch 9 with validation loss 0.9418401122093201\n",
      "Starting Epoch 10\n",
      "0.9132617038229237\n",
      "Starting Epoch 11\n",
      "0.9075772632723269\n",
      "New best model found at epoch 11 with validation loss 0.9290322065353394\n",
      "Starting Epoch 12\n",
      "0.9044073068577311\n",
      "New best model found at epoch 12 with validation loss 0.9226983189582825\n",
      "Starting Epoch 13\n",
      "0.8996206677478292\n",
      "Starting Epoch 14\n",
      "0.8942921161651611\n",
      "New best model found at epoch 14 with validation loss 0.9170892834663391\n",
      "Starting Epoch 15\n",
      "0.8918598449748495\n",
      "New best model found at epoch 15 with validation loss 0.912331759929657\n",
      "Starting Epoch 16\n",
      "0.8860438284666642\n",
      "Starting Epoch 17\n",
      "0.8821553950724395\n",
      "New best model found at epoch 17 with validation loss 0.9052485823631287\n",
      "Starting Epoch 18\n",
      "0.879095821276955\n",
      "Starting Epoch 19\n",
      "0.8776339059290679\n",
      "Starting Epoch 20\n",
      "0.874459779780844\n",
      "New best model found at epoch 20 with validation loss 0.9029321074485779\n",
      "Starting Epoch 21\n",
      "0.8703346122866091\n",
      "New best model found at epoch 21 with validation loss 0.8989533185958862\n",
      "Starting Epoch 22\n",
      "0.8675829016644022\n",
      "New best model found at epoch 22 with validation loss 0.889362633228302\n",
      "Starting Epoch 23\n",
      "0.8679162004719609\n",
      "New best model found at epoch 23 with validation loss 0.8887780904769897\n",
      "Starting Epoch 24\n",
      "0.8675156909486522\n",
      "Starting Epoch 25\n",
      "0.8632899445036183\n",
      "Starting Epoch 26\n",
      "0.8612675900044648\n",
      "New best model found at epoch 26 with validation loss 0.8858113288879395\n",
      "Starting Epoch 27\n",
      "0.8613781669865483\n",
      "Starting Epoch 28\n",
      "0.8578925599222598\n",
      "New best model found at epoch 28 with validation loss 0.8796872496604919\n",
      "Starting Epoch 29\n",
      "0.8565803144289099\n",
      "Starting Epoch 30\n",
      "0.8527096484018408\n",
      "New best model found at epoch 30 with validation loss 0.8787925839424133\n",
      "Starting Epoch 31\n",
      "0.8580355229585067\n",
      "New best model found at epoch 31 with validation loss 0.8768483996391296\n",
      "Starting Epoch 32\n",
      "0.8523339525513027\n",
      "Starting Epoch 33\n",
      "0.8481818567151609\n",
      "Starting Epoch 34\n",
      "0.8479708666386812\n",
      "New best model found at epoch 34 with validation loss 0.8747081756591797\n",
      "Starting Epoch 35\n",
      "0.844797784867494\n",
      "New best model found at epoch 35 with validation loss 0.8733385801315308\n",
      "Starting Epoch 36\n",
      "0.8492940638376318\n",
      "New best model found at epoch 36 with validation loss 0.8716331720352173\n",
      "Starting Epoch 37\n",
      "0.84578923297965\n",
      "New best model found at epoch 37 with validation loss 0.8713569641113281\n",
      "Starting Epoch 38\n",
      "0.8425627117571624\n",
      "New best model found at epoch 38 with validation loss 0.8655610084533691\n",
      "Starting Epoch 39\n",
      "0.8444071567576864\n",
      "Starting Epoch 40\n",
      "0.8415246579958044\n",
      "Starting Epoch 41\n",
      "0.8433670064677363\n",
      "Starting Epoch 42\n",
      "0.8412520211675892\n",
      "New best model found at epoch 42 with validation loss 0.8610613346099854\n",
      "Starting Epoch 43\n",
      "0.8430202318274457\n",
      "Starting Epoch 44\n",
      "0.841022499229597\n",
      "Starting Epoch 45\n",
      "0.8423785904179448\n",
      "New best model found at epoch 45 with validation loss 0.8580176830291748\n",
      "Starting Epoch 46\n",
      "0.8407770732174749\n",
      "Starting Epoch 47\n",
      "0.8354238815929579\n",
      "Starting Epoch 48\n",
      "0.8375590262205704\n",
      "Starting Epoch 49\n",
      "0.8368678663087927\n",
      "Starting Epoch 50\n",
      "0.8358910109685815\n",
      "Starting Epoch 51\n",
      "0.8364004311354264\n",
      "New best model found at epoch 51 with validation loss 0.8578976988792419\n",
      "Starting Epoch 52\n",
      "0.834536295870076\n",
      "Starting Epoch 53\n",
      "0.8334347035573877\n",
      "Starting Epoch 54\n",
      "0.8349765616914501\n",
      "New best model found at epoch 54 with validation loss 0.8547153472900391\n",
      "Starting Epoch 55\n",
      "0.8358883183935414\n",
      "New best model found at epoch 55 with validation loss 0.8519004583358765\n",
      "Starting Epoch 56\n",
      "0.8328083131624304\n",
      "Starting Epoch 57\n",
      "0.8353749772776728\n",
      "Starting Epoch 58\n",
      "0.8341268326925195\n",
      "Starting Epoch 59\n",
      "0.831811759782874\n",
      "Starting Epoch 60\n",
      "0.835173399552055\n",
      "Starting Epoch 61\n",
      "0.8307751754055852\n",
      "Starting Epoch 62\n",
      "0.8299822910972263\n",
      "Starting Epoch 63\n",
      "0.8323233982791072\n",
      "New best model found at epoch 63 with validation loss 0.8492423892021179\n",
      "Starting Epoch 64\n",
      "0.8283157970594324\n",
      "Starting Epoch 65\n",
      "0.8304881790409917\n",
      "Starting Epoch 66\n",
      "0.8311881008355514\n",
      "Starting Epoch 67\n",
      "0.8293722893880762\n",
      "Starting Epoch 68\n",
      "0.8292552180912184\n",
      "New best model found at epoch 68 with validation loss 0.8477314710617065\n",
      "Starting Epoch 69\n",
      "0.8299473653668943\n",
      "Starting Epoch 70\n",
      "0.8288435728653617\n",
      "Starting Epoch 71\n",
      "0.8315498802972876\n",
      "New best model found at epoch 71 with validation loss 0.8456283807754517\n",
      "Starting Epoch 72\n",
      "0.8271325774814772\n",
      "Starting Epoch 73\n",
      "0.8269132297971974\n",
      "Starting Epoch 74\n",
      "0.82749626170034\n",
      "Starting Epoch 75\n",
      "0.8258575719335804\n",
      "Starting Epoch 76\n",
      "0.8283146956692571\n",
      "Starting Epoch 77\n",
      "0.8289814228596895\n",
      "Starting Epoch 78\n",
      "0.8267180660496587\n",
      "Starting Epoch 79\n",
      "0.8260810245638308\n",
      "Starting Epoch 80\n",
      "0.8249434103136477\n",
      "New best model found at epoch 80 with validation loss 0.8431621789932251\n",
      "Starting Epoch 81\n",
      "0.8256043092064236\n",
      "Starting Epoch 82\n",
      "0.8259255756502566\n",
      "Starting Epoch 83\n",
      "0.8242018170978712\n",
      "Starting Epoch 84\n",
      "0.825156613536503\n",
      "Starting Epoch 85\n",
      "0.8239329224047454\n",
      "Starting Epoch 86\n",
      "0.8254079533659894\n",
      "Starting Epoch 87\n",
      "0.8219569766003153\n",
      "New best model found at epoch 87 with validation loss 0.8420007824897766\n",
      "Starting Epoch 88\n",
      "0.8241122261337612\n",
      "Starting Epoch 89\n",
      "0.8258651728215425\n",
      "Starting Epoch 90\n",
      "0.8236710740172345\n",
      "New best model found at epoch 90 with validation loss 0.8407816290855408\n",
      "Starting Epoch 91\n",
      "0.8253455680349598\n",
      "Starting Epoch 92\n",
      "0.824479657670726\n",
      "Starting Epoch 93\n",
      "0.822565356026525\n",
      "Starting Epoch 94\n",
      "0.8201273679733276\n",
      "Starting Epoch 95\n",
      "0.8266374935274539\n",
      "Starting Epoch 96\n",
      "0.8240260896475419\n",
      "Starting Epoch 97\n",
      "0.8244761047155961\n",
      "Starting Epoch 98\n",
      "0.8226313305937726\n",
      "Starting Epoch 99\n",
      "0.8228962343672047\n",
      "Starting Epoch 100\n",
      "0.8222660940626393\n",
      "Starting Epoch 101\n",
      "0.8244214913119441\n",
      "Starting Epoch 102\n",
      "0.8227218778237052\n",
      "Starting Epoch 103\n",
      "0.8233720971190411\n",
      "Starting Epoch 104\n",
      "0.8227918484936589\n",
      "Starting Epoch 105\n",
      "0.8221808879271798\n",
      "Starting Epoch 106\n",
      "0.8218900846398395\n",
      "Starting Epoch 107\n",
      "0.8230073218760283\n",
      "Starting Epoch 108\n",
      "0.8214684983958369\n",
      "Starting Epoch 109\n",
      "0.8234936802283578\n",
      "Starting Epoch 110\n",
      "0.8243229700171429\n",
      "Starting Epoch 111\n",
      "0.8206795039384261\n",
      "Starting Epoch 112\n",
      "0.8218358988347261\n",
      "New best model found at epoch 112 with validation loss 0.840104877948761\n",
      "Starting Epoch 113\n",
      "0.8218724105669104\n",
      "Starting Epoch 114\n",
      "0.8221908911414768\n",
      "Starting Epoch 115\n",
      "0.8222316995910977\n",
      "Starting Epoch 116\n",
      "0.8212464451789856\n",
      "Starting Epoch 117\n",
      "0.8198889779007953\n",
      "Starting Epoch 118\n",
      "0.8205859479696854\n",
      "Starting Epoch 119\n",
      "0.8197934394297393\n",
      "Starting Epoch 120\n",
      "0.8186043164004451\n",
      "Starting Epoch 121\n",
      "0.82151242442753\n",
      "Starting Epoch 122\n",
      "0.8218405972356382\n",
      "Starting Epoch 123\n",
      "0.820829160835432\n",
      "Starting Epoch 124\n",
      "0.8202201853627744\n",
      "Starting Epoch 125\n",
      "0.8204194436902585\n",
      "Starting Epoch 126\n",
      "0.8209051204764325\n",
      "Starting Epoch 127\n",
      "0.8208950757980347\n",
      "Starting Epoch 128\n",
      "0.8179179533668186\n",
      "Starting Epoch 129\n",
      "0.8201379957406417\n",
      "Starting Epoch 130\n",
      "0.8192419928053151\n",
      "New best model found at epoch 130 with validation loss 0.8387752771377563\n",
      "Starting Epoch 131\n",
      "0.8184682389964228\n",
      "Starting Epoch 132\n",
      "0.8200943988302479\n",
      "Starting Epoch 133\n",
      "0.8183416387309199\n",
      "Starting Epoch 134\n",
      "0.8196782081023507\n",
      "Starting Epoch 135\n",
      "0.8208219098008197\n",
      "Starting Epoch 136\n",
      "0.8192138620044874\n",
      "Starting Epoch 137\n",
      "0.819031184134276\n",
      "New best model found at epoch 137 with validation loss 0.8382968306541443\n",
      "Starting Epoch 138\n",
      "0.8173779689747355\n",
      "Starting Epoch 139\n",
      "0.8209298797275709\n",
      "New best model found at epoch 139 with validation loss 0.837041974067688\n",
      "Starting Epoch 140\n",
      "0.8184168053709943\n",
      "Starting Epoch 141\n",
      "0.8185273175654204\n",
      "Starting Epoch 142\n",
      "0.8182517627011174\n",
      "Starting Epoch 143\n",
      "0.8185568736947101\n",
      "Starting Epoch 144\n",
      "0.8183941167333851\n",
      "Starting Epoch 145\n",
      "0.8192456157311149\n",
      "Starting Epoch 146\n",
      "0.8206213971842891\n",
      "Starting Epoch 147\n",
      "0.8174796493157096\n",
      "Starting Epoch 148\n",
      "0.8181066590806713\n",
      "Starting Epoch 149\n",
      "0.8168655789416769\n",
      "Starting Epoch 150\n",
      "0.8190089852913566\n",
      "Starting Epoch 151\n",
      "0.8175761725591577\n",
      "New best model found at epoch 151 with validation loss 0.8360832929611206\n",
      "Starting Epoch 152\n",
      "0.8175890160643536\n",
      "Starting Epoch 153\n",
      "0.8176461535951366\n",
      "Starting Epoch 154\n",
      "0.8169770033463187\n",
      "Starting Epoch 155\n",
      "0.8185925535533739\n",
      "Starting Epoch 156\n",
      "0.8171165689178135\n",
      "Starting Epoch 157\n",
      "0.8183974312699359\n",
      "Starting Epoch 158\n",
      "0.8172942088997882\n",
      "Starting Epoch 159\n",
      "0.8180117296135944\n",
      "Starting Epoch 160\n",
      "0.8168894182080808\n",
      "Starting Epoch 161\n",
      "0.8177112522332565\n",
      "Starting Epoch 162\n",
      "0.8175198591273763\n",
      "New best model found at epoch 162 with validation loss 0.8357645273208618\n",
      "Starting Epoch 163\n",
      "0.8165682528329932\n",
      "Starting Epoch 164\n",
      "0.8159253623174585\n",
      "Starting Epoch 165\n",
      "0.8158220493275187\n",
      "Starting Epoch 166\n",
      "0.8170512603676837\n",
      "Starting Epoch 167\n",
      "0.8150520065556401\n",
      "Starting Epoch 168\n",
      "0.8161988854408264\n",
      "New best model found at epoch 168 with validation loss 0.8356105089187622\n",
      "Starting Epoch 169\n",
      "0.8167620482652084\n",
      "Starting Epoch 170\n",
      "0.818326024905495\n",
      "Starting Epoch 171\n",
      "0.8161023881124414\n",
      "Starting Epoch 172\n",
      "0.8169357439746028\n",
      "Starting Epoch 173\n",
      "0.8180877799573152\n",
      "Starting Epoch 174\n",
      "0.8158901826195095\n",
      "Starting Epoch 175\n",
      "0.8178207019101018\n",
      "Starting Epoch 176\n",
      "0.8164953667184581\n",
      "Starting Epoch 177\n",
      "0.8157702995383221\n",
      "Starting Epoch 178\n",
      "0.8176815121070199\n",
      "Starting Epoch 179\n",
      "0.8166139384974604\n",
      "Starting Epoch 180\n",
      "0.8156921837640845\n",
      "Starting Epoch 181\n",
      "0.8169998837553937\n",
      "Starting Epoch 182\n",
      "0.8160988118337549\n",
      "Starting Epoch 183\n",
      "0.8151165635689445\n",
      "Starting Epoch 184\n",
      "0.816800990830297\n",
      "New best model found at epoch 184 with validation loss 0.8347633481025696\n",
      "Starting Epoch 185\n",
      "0.8163304017937701\n",
      "Starting Epoch 186\n",
      "0.815655749777089\n",
      "Starting Epoch 187\n",
      "0.8162440165229465\n",
      "Starting Epoch 188\n",
      "0.8145817207253497\n",
      "Starting Epoch 189\n",
      "0.8166039119596067\n",
      "New best model found at epoch 189 with validation loss 0.8345903754234314\n",
      "Starting Epoch 190\n",
      "0.8154440729514413\n",
      "Starting Epoch 191\n",
      "0.815408714439558\n",
      "Starting Epoch 192\n",
      "0.8151847979296809\n",
      "Starting Epoch 193\n",
      "0.8152744770050049\n",
      "Starting Epoch 194\n",
      "0.8134357048117596\n",
      "Starting Epoch 195\n",
      "0.8165605819743612\n",
      "New best model found at epoch 195 with validation loss 0.8336606621742249\n",
      "Starting Epoch 196\n",
      "0.8141663074493408\n",
      "Starting Epoch 197\n",
      "0.8136226949484452\n",
      "Starting Epoch 198\n",
      "0.8140957044518512\n",
      "New best model found at epoch 198 with validation loss 0.8332438468933105\n",
      "Starting Epoch 199\n",
      "0.81536073529202\n",
      "Starting Epoch 200\n",
      "0.8159481131512186\n",
      "Starting Epoch 201\n",
      "0.8139163126116213\n",
      "Starting Epoch 202\n",
      "0.8134757487670236\n",
      "Starting Epoch 203\n",
      "0.8152662411980007\n",
      "Starting Epoch 204\n",
      "0.814474458279817\n",
      "Starting Epoch 205\n",
      "0.813800555208455\n",
      "Starting Epoch 206\n",
      "0.8135169563086136\n",
      "Starting Epoch 207\n",
      "0.8143087133117344\n",
      "Starting Epoch 208\n",
      "0.8136632338814114\n",
      "Starting Epoch 209\n",
      "0.8170454994491909\n",
      "Starting Epoch 210\n",
      "0.8157502283220706\n",
      "Starting Epoch 211\n",
      "0.8135347547738448\n",
      "Starting Epoch 212\n",
      "0.8131957909335261\n",
      "Starting Epoch 213\n",
      "0.8139828599017599\n",
      "Starting Epoch 214\n",
      "0.8145468286845995\n",
      "New best model found at epoch 214 with validation loss 0.8328585028648376\n",
      "Starting Epoch 215\n",
      "0.8153268591217373\n",
      "Starting Epoch 216\n",
      "0.8144826733547709\n",
      "Starting Epoch 217\n",
      "0.8148922661076421\n",
      "Starting Epoch 218\n",
      "0.8146244753961978\n",
      "Starting Epoch 219\n",
      "0.8143401145935059\n",
      "Starting Epoch 220\n",
      "0.8135748350101969\n",
      "Starting Epoch 221\n",
      "0.8138705310614213\n",
      "Starting Epoch 222\n",
      "0.8135004484135172\n",
      "New best model found at epoch 222 with validation loss 0.8323467373847961\n",
      "Starting Epoch 223\n",
      "0.8145434078962906\n",
      "Starting Epoch 224\n",
      "0.8135278458180635\n",
      "Starting Epoch 225\n",
      "0.8123244409975798\n",
      "Starting Epoch 226\n",
      "0.8143284294916235\n",
      "Starting Epoch 227\n",
      "0.8141431031019791\n",
      "Starting Epoch 228\n",
      "0.812131915403449\n",
      "Starting Epoch 229\n",
      "0.8162891968436863\n",
      "Starting Epoch 230\n",
      "0.8126627906509067\n",
      "Starting Epoch 231\n",
      "0.8142733496168385\n",
      "Starting Epoch 232\n",
      "0.8132922105167223\n",
      "Starting Epoch 233\n",
      "0.8132728830627773\n",
      "Starting Epoch 234\n",
      "0.8155321452928626\n",
      "Starting Epoch 235\n",
      "0.8139475273049396\n",
      "Starting Epoch 236\n",
      "0.8128097964369733\n",
      "Starting Epoch 237\n",
      "0.8137403311936752\n",
      "Starting Epoch 238\n",
      "0.8140724975129833\n",
      "Starting Epoch 239\n",
      "0.8131620521130769\n",
      "Starting Epoch 240\n",
      "0.812018342640089\n",
      "Starting Epoch 241\n",
      "0.8122006006862806\n",
      "Starting Epoch 242\n",
      "0.8133216526197351\n",
      "Starting Epoch 243\n",
      "0.8128545672997184\n",
      "Starting Epoch 244\n",
      "0.8132953410563262\n",
      "New best model found at epoch 244 with validation loss 0.831748366355896\n",
      "Starting Epoch 245\n",
      "0.8128422239552373\n",
      "Starting Epoch 246\n",
      "0.8121504446734553\n",
      "Starting Epoch 247\n",
      "0.813350252483202\n",
      "Starting Epoch 248\n",
      "0.8140073807343192\n",
      "Starting Epoch 249\n",
      "0.815162358076676\n",
      "Starting Epoch 250\n",
      "0.8122569089350493\n",
      "Starting Epoch 251\n",
      "0.8124275699905728\n",
      "Starting Epoch 252\n",
      "0.8128844940144083\n",
      "New best model found at epoch 252 with validation loss 0.8299075365066528\n",
      "Starting Epoch 253\n",
      "0.8126406436381133\n",
      "Starting Epoch 254\n",
      "0.8114935159683228\n",
      "Starting Epoch 255\n",
      "0.8138160575991091\n",
      "Starting Epoch 256\n",
      "0.8124122282733088\n",
      "Starting Epoch 257\n",
      "0.8119981262994849\n",
      "Starting Epoch 258\n",
      "0.8126377359680508\n",
      "Starting Epoch 259\n",
      "0.8133747759072677\n",
      "Starting Epoch 260\n",
      "0.8122368506763292\n",
      "Starting Epoch 261\n",
      "0.8126892447471619\n",
      "Starting Epoch 262\n",
      "0.8119898386623549\n",
      "Starting Epoch 263\n",
      "0.8112909949344137\n",
      "Starting Epoch 264\n",
      "0.811256248018016\n",
      "Starting Epoch 265\n",
      "0.8117741450019504\n",
      "Starting Epoch 266\n",
      "0.8126443469006083\n",
      "Starting Epoch 267\n",
      "0.8116695518079011\n",
      "Starting Epoch 268\n",
      "0.81471012727074\n",
      "Starting Epoch 269\n",
      "0.8115357030992922\n",
      "Starting Epoch 270\n",
      "0.8115193740181301\n",
      "Starting Epoch 271\n",
      "0.8109886464865311\n",
      "New best model found at epoch 271 with validation loss 0.8285250067710876\n",
      "Starting Epoch 272\n",
      "0.8112831685854041\n",
      "Starting Epoch 273\n",
      "0.8109310087950333\n",
      "Starting Epoch 274\n",
      "0.8113430686618971\n",
      "New best model found at epoch 274 with validation loss 0.8279414772987366\n",
      "Starting Epoch 275\n",
      "0.8122712866119717\n",
      "New best model found at epoch 275 with validation loss 0.827530026435852\n",
      "Starting Epoch 276\n",
      "0.8113639536111251\n",
      "Starting Epoch 277\n",
      "0.8121209429657977\n",
      "Starting Epoch 278\n",
      "0.8116649000541024\n",
      "Starting Epoch 279\n",
      "0.8120390591414078\n",
      "Starting Epoch 280\n",
      "0.8122854673344156\n",
      "Starting Epoch 281\n",
      "0.8103634948315828\n",
      "Starting Epoch 282\n",
      "0.8100073026574176\n",
      "Starting Epoch 283\n",
      "0.8101024498110232\n",
      "Starting Epoch 284\n",
      "0.810767412185669\n",
      "Starting Epoch 285\n",
      "0.8123963967613552\n",
      "Starting Epoch 286\n",
      "0.8101017682448678\n",
      "Starting Epoch 287\n",
      "0.8116778912751571\n",
      "New best model found at epoch 287 with validation loss 0.827403724193573\n",
      "Starting Epoch 288\n",
      "0.8097422822662022\n",
      "Starting Epoch 289\n",
      "0.811321541019108\n",
      "Starting Epoch 290\n",
      "0.8107784053553706\n",
      "Starting Epoch 291\n",
      "0.8113866085591523\n",
      "New best model found at epoch 291 with validation loss 0.8271462321281433\n",
      "Starting Epoch 292\n",
      "0.8116196653117305\n",
      "Starting Epoch 293\n",
      "0.8125198949938235\n",
      "Starting Epoch 294\n",
      "0.81036158748295\n",
      "Starting Epoch 295\n",
      "0.8095862476722054\n",
      "Starting Epoch 296\n",
      "0.8111860803935839\n",
      "Starting Epoch 297\n",
      "0.8098736509032871\n",
      "Starting Epoch 298\n",
      "0.8106119347655255\n",
      "Starting Epoch 299\n",
      "0.8098073834958284\n",
      "Starting Epoch 300\n",
      "0.8093497208926989\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-25-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "52799feb-48d3-4ff5-9e9c-ca3b3972ddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "0.9833692856456923\n",
      "New best model found at epoch 1 with validation loss 0.7996848821640015\n",
      "Starting Epoch 2\n",
      "0.80243363328602\n",
      "New best model found at epoch 2 with validation loss 0.7949261665344238\n",
      "Starting Epoch 3\n",
      "0.7952267916306205\n",
      "New best model found at epoch 3 with validation loss 0.7891013622283936\n",
      "Starting Epoch 4\n",
      "0.7926316520442134\n",
      "New best model found at epoch 4 with validation loss 0.7835365533828735\n",
      "Starting Epoch 5\n",
      "0.7895577575849451\n",
      "New best model found at epoch 5 with validation loss 0.7795851230621338\n",
      "Starting Epoch 6\n",
      "0.7866314053535461\n",
      "New best model found at epoch 6 with validation loss 0.7765664458274841\n",
      "Starting Epoch 7\n",
      "0.7857390408930571\n",
      "New best model found at epoch 7 with validation loss 0.7742095589637756\n",
      "Starting Epoch 8\n",
      "0.7791652212972227\n",
      "Starting Epoch 9\n",
      "0.7794456948404727\n",
      "New best model found at epoch 9 with validation loss 0.7632995843887329\n",
      "Starting Epoch 10\n",
      "0.7699461631152941\n",
      "New best model found at epoch 10 with validation loss 0.7584646344184875\n",
      "Starting Epoch 11\n",
      "0.76608632699303\n",
      "New best model found at epoch 11 with validation loss 0.7489027976989746\n",
      "Starting Epoch 12\n",
      "0.762409904728765\n",
      "New best model found at epoch 12 with validation loss 0.7415759563446045\n",
      "Starting Epoch 13\n",
      "0.7577742726906486\n",
      "New best model found at epoch 13 with validation loss 0.7377067804336548\n",
      "Starting Epoch 14\n",
      "0.7536275671875995\n",
      "New best model found at epoch 14 with validation loss 0.7299229502677917\n",
      "Starting Epoch 15\n",
      "0.7487103083859319\n",
      "New best model found at epoch 15 with validation loss 0.7268001437187195\n",
      "Starting Epoch 16\n",
      "0.7468580422194108\n",
      "New best model found at epoch 16 with validation loss 0.7183430790901184\n",
      "Starting Epoch 17\n",
      "0.7373188630394314\n",
      "New best model found at epoch 17 with validation loss 0.7127360701560974\n",
      "Starting Epoch 18\n",
      "0.7346298616865407\n",
      "New best model found at epoch 18 with validation loss 0.709388256072998\n",
      "Starting Epoch 19\n",
      "0.7298183855803116\n",
      "Starting Epoch 20\n",
      "0.7270952955536221\n",
      "New best model found at epoch 20 with validation loss 0.699560821056366\n",
      "Starting Epoch 21\n",
      "0.7218299248944158\n",
      "New best model found at epoch 21 with validation loss 0.6992403864860535\n",
      "Starting Epoch 22\n",
      "0.7190600892771846\n",
      "New best model found at epoch 22 with validation loss 0.6919078826904297\n",
      "Starting Epoch 23\n",
      "0.7181819936503535\n",
      "New best model found at epoch 23 with validation loss 0.6900216341018677\n",
      "Starting Epoch 24\n",
      "0.7194293815156688\n",
      "New best model found at epoch 24 with validation loss 0.689154326915741\n",
      "Starting Epoch 25\n",
      "0.7089410735213239\n",
      "New best model found at epoch 25 with validation loss 0.6857990622520447\n",
      "Starting Epoch 26\n",
      "0.7066092076508895\n",
      "New best model found at epoch 26 with validation loss 0.6802526712417603\n",
      "Starting Epoch 27\n",
      "0.7069824363874353\n",
      "Starting Epoch 28\n",
      "0.7051242019819177\n",
      "New best model found at epoch 28 with validation loss 0.6767676472663879\n",
      "Starting Epoch 29\n",
      "0.7060686868170033\n",
      "Starting Epoch 30\n",
      "0.700448743675066\n",
      "New best model found at epoch 30 with validation loss 0.6732659935951233\n",
      "Starting Epoch 31\n",
      "0.7031157483225283\n",
      "New best model found at epoch 31 with validation loss 0.6717235445976257\n",
      "Starting Epoch 32\n",
      "0.6982228470885236\n",
      "Starting Epoch 33\n",
      "0.6914248466491699\n",
      "New best model found at epoch 33 with validation loss 0.6701433658599854\n",
      "Starting Epoch 34\n",
      "0.6926218297170557\n",
      "Starting Epoch 35\n",
      "0.6902773691260297\n",
      "New best model found at epoch 35 with validation loss 0.667637050151825\n",
      "Starting Epoch 36\n",
      "0.6939087276873381\n",
      "Starting Epoch 37\n",
      "0.6884155403012815\n",
      "New best model found at epoch 37 with validation loss 0.6650931239128113\n",
      "Starting Epoch 38\n",
      "0.6864798172660496\n",
      "Starting Epoch 39\n",
      "0.686791541783706\n",
      "New best model found at epoch 39 with validation loss 0.6637225151062012\n",
      "Starting Epoch 40\n",
      "0.6855167694713759\n",
      "Starting Epoch 41\n",
      "0.6857339169668115\n",
      "Starting Epoch 42\n",
      "0.6833365637323131\n",
      "New best model found at epoch 42 with validation loss 0.6613212823867798\n",
      "Starting Epoch 43\n",
      "0.685339313486348\n",
      "New best model found at epoch 43 with validation loss 0.6601799130439758\n",
      "Starting Epoch 44\n",
      "0.6849734601767167\n",
      "Starting Epoch 45\n",
      "0.6879702650982401\n",
      "Starting Epoch 46\n",
      "0.6856341802555582\n",
      "Starting Epoch 47\n",
      "0.6802840906640758\n",
      "New best model found at epoch 47 with validation loss 0.6600761413574219\n",
      "Starting Epoch 48\n",
      "0.6819236382194187\n",
      "New best model found at epoch 48 with validation loss 0.659612238407135\n",
      "Starting Epoch 49\n",
      "0.6834637133971505\n",
      "Starting Epoch 50\n",
      "0.6802590230236882\n",
      "New best model found at epoch 50 with validation loss 0.657017707824707\n",
      "Starting Epoch 51\n",
      "0.6797371351200602\n",
      "Starting Epoch 52\n",
      "0.6779108591701674\n",
      "Starting Epoch 53\n",
      "0.6799530050028926\n",
      "Starting Epoch 54\n",
      "0.6810189615125242\n",
      "Starting Epoch 55\n",
      "0.6790670363799386\n",
      "Starting Epoch 56\n",
      "0.6774791090384774\n",
      "New best model found at epoch 56 with validation loss 0.6568279266357422\n",
      "Starting Epoch 57\n",
      "0.679971008197121\n",
      "Starting Epoch 58\n",
      "0.677913468817006\n",
      "Starting Epoch 59\n",
      "0.6761495471000671\n",
      "Starting Epoch 60\n",
      "0.6787136274835338\n",
      "Starting Epoch 61\n",
      "0.6781648708426434\n",
      "New best model found at epoch 61 with validation loss 0.6561124324798584\n",
      "Starting Epoch 62\n",
      "0.6752560449683148\n",
      "New best model found at epoch 62 with validation loss 0.6550933718681335\n",
      "Starting Epoch 63\n",
      "0.6759908199310303\n",
      "Starting Epoch 64\n",
      "0.6750518446383269\n",
      "Starting Epoch 65\n",
      "0.6744160989056462\n",
      "Starting Epoch 66\n",
      "0.6738715534624846\n",
      "Starting Epoch 67\n",
      "0.675887960454692\n",
      "New best model found at epoch 67 with validation loss 0.6515406966209412\n",
      "Starting Epoch 68\n",
      "0.6739336407702902\n",
      "New best model found at epoch 68 with validation loss 0.6506844162940979\n",
      "Starting Epoch 69\n",
      "0.6749559226243392\n",
      "Starting Epoch 70\n",
      "0.6749397930891617\n",
      "Starting Epoch 71\n",
      "0.6739597476047018\n",
      "New best model found at epoch 71 with validation loss 0.6497495174407959\n",
      "Starting Epoch 72\n",
      "0.6736128770786783\n",
      "Starting Epoch 73\n",
      "0.6703608528427456\n",
      "Starting Epoch 74\n",
      "0.6734777585319851\n",
      "Starting Epoch 75\n",
      "0.6725027898083562\n",
      "New best model found at epoch 75 with validation loss 0.6493357419967651\n",
      "Starting Epoch 76\n",
      "0.6738191221071326\n",
      "Starting Epoch 77\n",
      "0.6751058723615564\n",
      "Starting Epoch 78\n",
      "0.6722549770189368\n",
      "Starting Epoch 79\n",
      "0.6694675113843835\n",
      "Starting Epoch 80\n",
      "0.6706589434457861\n",
      "New best model found at epoch 80 with validation loss 0.6492019295692444\n",
      "Starting Epoch 81\n",
      "0.6701417021129442\n",
      "New best model found at epoch 81 with validation loss 0.6483135223388672\n",
      "Starting Epoch 82\n",
      "0.6691480900930322\n",
      "Starting Epoch 83\n",
      "0.6697670921035435\n",
      "Starting Epoch 84\n",
      "0.6706755109455275\n",
      "Starting Epoch 85\n",
      "0.6690669927908026\n",
      "Starting Epoch 86\n",
      "0.671267252901326\n",
      "Starting Epoch 87\n",
      "0.6669894275457963\n",
      "Starting Epoch 88\n",
      "0.6695258073184801\n",
      "New best model found at epoch 88 with validation loss 0.6472353339195251\n",
      "Starting Epoch 89\n",
      "0.6709266823271046\n",
      "Starting Epoch 90\n",
      "0.6696757078170776\n",
      "New best model found at epoch 90 with validation loss 0.6469806432723999\n",
      "Starting Epoch 91\n",
      "0.6683612491773523\n",
      "Starting Epoch 92\n",
      "0.6708380916844243\n",
      "Starting Epoch 93\n",
      "0.666146475335826\n",
      "Starting Epoch 94\n",
      "0.664908652720244\n",
      "Starting Epoch 95\n",
      "0.6688556541567263\n",
      "Starting Epoch 96\n",
      "0.6682416278383007\n",
      "New best model found at epoch 96 with validation loss 0.6469349265098572\n",
      "Starting Epoch 97\n",
      "0.6705963611602783\n",
      "Starting Epoch 98\n",
      "0.6673081076663473\n",
      "New best model found at epoch 98 with validation loss 0.64633709192276\n",
      "Starting Epoch 99\n",
      "0.6676003466481748\n",
      "Starting Epoch 100\n",
      "0.6652952614037887\n",
      "Starting Epoch 101\n",
      "0.6680316043936688\n",
      "Starting Epoch 102\n",
      "0.6684170520823934\n",
      "Starting Epoch 103\n",
      "0.6654135144275167\n",
      "Starting Epoch 104\n",
      "0.6657742521037227\n",
      "Starting Epoch 105\n",
      "0.6665030277293661\n",
      "Starting Epoch 106\n",
      "0.6659295895825261\n",
      "Starting Epoch 107\n",
      "0.6651146593301193\n",
      "Starting Epoch 108\n",
      "0.6665615698565608\n",
      "Starting Epoch 109\n",
      "0.6667338842931001\n",
      "Starting Epoch 110\n",
      "0.666685428308404\n",
      "New best model found at epoch 110 with validation loss 0.6462008357048035\n",
      "Starting Epoch 111\n",
      "0.6630271206731382\n",
      "Starting Epoch 112\n",
      "0.6640485188235408\n",
      "New best model found at epoch 112 with validation loss 0.6445383429527283\n",
      "Starting Epoch 113\n",
      "0.6663959700128307\n",
      "New best model found at epoch 113 with validation loss 0.6441754698753357\n",
      "Starting Epoch 114\n",
      "0.6638070694778276\n",
      "Starting Epoch 115\n",
      "0.6645640264386716\n",
      "Starting Epoch 116\n",
      "0.6631706227426943\n",
      "Starting Epoch 117\n",
      "0.6610722308573516\n",
      "Starting Epoch 118\n",
      "0.6603600719700689\n",
      "New best model found at epoch 118 with validation loss 0.6437593698501587\n",
      "Starting Epoch 119\n",
      "0.6614930331707001\n",
      "New best model found at epoch 119 with validation loss 0.6423749327659607\n",
      "Starting Epoch 120\n",
      "0.6608517351357833\n",
      "Starting Epoch 121\n",
      "0.6628029709276946\n",
      "Starting Epoch 122\n",
      "0.6622643833575041\n",
      "Starting Epoch 123\n",
      "0.6620244331981825\n",
      "Starting Epoch 124\n",
      "0.6619975333628447\n",
      "New best model found at epoch 124 with validation loss 0.6423676013946533\n",
      "Starting Epoch 125\n",
      "0.6599478488383086\n",
      "Starting Epoch 126\n",
      "0.659619372823964\n",
      "Starting Epoch 127\n",
      "0.6633891566939976\n",
      "Starting Epoch 128\n",
      "0.6607687265976615\n",
      "Starting Epoch 129\n",
      "0.659191281899162\n",
      "Starting Epoch 130\n",
      "0.6630127170811528\n",
      "Starting Epoch 131\n",
      "0.6602591276168823\n",
      "Starting Epoch 132\n",
      "0.6578772638155066\n",
      "Starting Epoch 133\n",
      "0.6586468660313151\n",
      "Starting Epoch 134\n",
      "0.6585251870362655\n",
      "New best model found at epoch 134 with validation loss 0.6412322521209717\n",
      "Starting Epoch 135\n",
      "0.6621848914934241\n",
      "Starting Epoch 136\n",
      "0.6590441957764004\n",
      "Starting Epoch 137\n",
      "0.6591369665187338\n",
      "Starting Epoch 138\n",
      "0.657797616461049\n",
      "New best model found at epoch 138 with validation loss 0.6393935084342957\n",
      "Starting Epoch 139\n",
      "0.6595539087834565\n",
      "Starting Epoch 140\n",
      "0.6585993948190109\n",
      "Starting Epoch 141\n",
      "0.6563154329424319\n",
      "Starting Epoch 142\n",
      "0.6576514451400094\n",
      "Starting Epoch 143\n",
      "0.6572778872821642\n",
      "New best model found at epoch 143 with validation loss 0.6387977600097656\n",
      "Starting Epoch 144\n",
      "0.6571025848388672\n",
      "Starting Epoch 145\n",
      "0.6569557008535966\n",
      "Starting Epoch 146\n",
      "0.6588321017182391\n",
      "Starting Epoch 147\n",
      "0.6554323590320089\n",
      "Starting Epoch 148\n",
      "0.6570151551910068\n",
      "New best model found at epoch 148 with validation loss 0.6381263732910156\n",
      "Starting Epoch 149\n",
      "0.6545282705970432\n",
      "Starting Epoch 150\n",
      "0.6574739373248556\n",
      "Starting Epoch 151\n",
      "0.6569155428720557\n",
      "New best model found at epoch 151 with validation loss 0.6378743648529053\n",
      "Starting Epoch 152\n",
      "0.6551737578018851\n",
      "Starting Epoch 153\n",
      "0.6560021379719609\n",
      "Starting Epoch 154\n",
      "0.6561819833257924\n",
      "Starting Epoch 155\n",
      "0.6553537430970565\n",
      "Starting Epoch 156\n",
      "0.656582192234371\n",
      "New best model found at epoch 156 with validation loss 0.6370962262153625\n",
      "Starting Epoch 157\n",
      "0.6564397993295089\n",
      "Starting Epoch 158\n",
      "0.654936142589735\n",
      "Starting Epoch 159\n",
      "0.6574191839798637\n",
      "New best model found at epoch 159 with validation loss 0.6363555788993835\n",
      "Starting Epoch 160\n",
      "0.6567260415657706\n",
      "Starting Epoch 161\n",
      "0.6560728109401205\n",
      "Starting Epoch 162\n",
      "0.6583364372668059\n",
      "Starting Epoch 163\n",
      "0.6552021322043046\n",
      "Starting Epoch 164\n",
      "0.6541859015174534\n",
      "Starting Epoch 165\n",
      "0.6548458337783813\n",
      "New best model found at epoch 165 with validation loss 0.6362307071685791\n",
      "Starting Epoch 166\n",
      "0.6555097725080408\n",
      "Starting Epoch 167\n",
      "0.6549609225729237\n",
      "Starting Epoch 168\n",
      "0.6549617855445199\n",
      "New best model found at epoch 168 with validation loss 0.6352718472480774\n",
      "Starting Epoch 169\n",
      "0.653636379086453\n",
      "Starting Epoch 170\n",
      "0.6548031827677852\n",
      "Starting Epoch 171\n",
      "0.6553958395253057\n",
      "Starting Epoch 172\n",
      "0.6534719700398652\n",
      "Starting Epoch 173\n",
      "0.6561536063318667\n",
      "Starting Epoch 174\n",
      "0.6530918349390444\n",
      "Starting Epoch 175\n",
      "0.6548664155213729\n",
      "Starting Epoch 176\n",
      "0.6518984022347823\n",
      "New best model found at epoch 176 with validation loss 0.633994460105896\n",
      "Starting Epoch 177\n",
      "0.6551870781442394\n",
      "Starting Epoch 178\n",
      "0.6555922653364099\n",
      "Starting Epoch 179\n",
      "0.6564628689185433\n",
      "Starting Epoch 180\n",
      "0.653496617856233\n",
      "Starting Epoch 181\n",
      "0.6553177963132444\n",
      "Starting Epoch 182\n",
      "0.6534577634023584\n",
      "Starting Epoch 183\n",
      "0.6535942891369695\n",
      "Starting Epoch 184\n",
      "0.654287804727969\n",
      "Starting Epoch 185\n",
      "0.6510128508443418\n",
      "Starting Epoch 186\n",
      "0.6534618035606716\n",
      "Starting Epoch 187\n",
      "0.6543643448663794\n",
      "Starting Epoch 188\n",
      "0.6513400984847028\n",
      "Starting Epoch 189\n",
      "0.6524929844814799\n",
      "Starting Epoch 190\n",
      "0.6516412237416143\n",
      "Starting Epoch 191\n",
      "0.6528845818146415\n",
      "New best model found at epoch 191 with validation loss 0.6336748003959656\n",
      "Starting Epoch 192\n",
      "0.6526680485061978\n",
      "New best model found at epoch 192 with validation loss 0.6334275603294373\n",
      "Starting Epoch 193\n",
      "0.6529862427193186\n",
      "New best model found at epoch 193 with validation loss 0.6333541870117188\n",
      "Starting Epoch 194\n",
      "0.6500604722810828\n",
      "New best model found at epoch 194 with validation loss 0.6327895522117615\n",
      "Starting Epoch 195\n",
      "0.6529829320700272\n",
      "Starting Epoch 196\n",
      "0.6502794338309247\n",
      "Starting Epoch 197\n",
      "0.6514872234800587\n",
      "New best model found at epoch 197 with validation loss 0.6327313184738159\n",
      "Starting Epoch 198\n",
      "0.6516439681467803\n",
      "Starting Epoch 199\n",
      "0.6513724508492843\n",
      "New best model found at epoch 199 with validation loss 0.6322076320648193\n",
      "Starting Epoch 200\n",
      "0.6540677314219268\n",
      "Starting Epoch 201\n",
      "0.6523597007212432\n",
      "Starting Epoch 202\n",
      "0.6506194912868998\n",
      "Starting Epoch 203\n",
      "0.6524519376132799\n",
      "Starting Epoch 204\n",
      "0.650322095207546\n",
      "Starting Epoch 205\n",
      "0.6520744095677915\n",
      "Starting Epoch 206\n",
      "0.6504197068836378\n",
      "New best model found at epoch 206 with validation loss 0.6319073438644409\n",
      "Starting Epoch 207\n",
      "0.6509177866189376\n",
      "Starting Epoch 208\n",
      "0.6513953183008276\n",
      "New best model found at epoch 208 with validation loss 0.6317442655563354\n",
      "Starting Epoch 209\n",
      "0.652820524962052\n",
      "New best model found at epoch 209 with validation loss 0.6315019130706787\n",
      "Starting Epoch 210\n",
      "0.6508759078772172\n",
      "New best model found at epoch 210 with validation loss 0.6313768625259399\n",
      "Starting Epoch 211\n",
      "0.6506118437518245\n",
      "New best model found at epoch 211 with validation loss 0.6305451989173889\n",
      "Starting Epoch 212\n",
      "0.6486046780710635\n",
      "Starting Epoch 213\n",
      "0.6515667205271514\n",
      "Starting Epoch 214\n",
      "0.650935621365257\n",
      "Starting Epoch 215\n",
      "0.651427554047626\n",
      "Starting Epoch 216\n",
      "0.6497310555499533\n",
      "New best model found at epoch 216 with validation loss 0.6294918656349182\n",
      "Starting Epoch 217\n",
      "0.6508418930613477\n",
      "Starting Epoch 218\n",
      "0.650778819685397\n",
      "Starting Epoch 219\n",
      "0.6505941800449205\n",
      "Starting Epoch 220\n",
      "0.6498774886131287\n",
      "Starting Epoch 221\n",
      "0.6503184489581896\n",
      "Starting Epoch 222\n",
      "0.6485788588938506\n",
      "Starting Epoch 223\n",
      "0.6502308897350145\n",
      "Starting Epoch 224\n",
      "0.6510031378787496\n",
      "Starting Epoch 225\n",
      "0.6512535499489825\n",
      "Starting Epoch 226\n",
      "0.6515682339668274\n",
      "New best model found at epoch 226 with validation loss 0.6280876398086548\n",
      "Starting Epoch 227\n",
      "0.6511242778404899\n",
      "Starting Epoch 228\n",
      "0.6479801017305126\n",
      "Starting Epoch 229\n",
      "0.6507914649403613\n",
      "Starting Epoch 230\n",
      "0.648404616376628\n",
      "Starting Epoch 231\n",
      "0.6506410422532455\n",
      "Starting Epoch 232\n",
      "0.6496541811072308\n",
      "Starting Epoch 233\n",
      "0.6473216362621473\n",
      "Starting Epoch 234\n",
      "0.6510657046152197\n",
      "New best model found at epoch 234 with validation loss 0.6275295615196228\n",
      "Starting Epoch 235\n",
      "0.649377035058063\n",
      "New best model found at epoch 235 with validation loss 0.6269620656967163\n",
      "Starting Epoch 236\n",
      "0.6469644515410714\n",
      "Starting Epoch 237\n",
      "0.647681386574455\n",
      "Starting Epoch 238\n",
      "0.6503414304360099\n",
      "Starting Epoch 239\n",
      "0.6477067729701167\n",
      "Starting Epoch 240\n",
      "0.6483781648718793\n",
      "New best model found at epoch 240 with validation loss 0.6268131732940674\n",
      "Starting Epoch 241\n",
      "0.647276010202325\n",
      "Starting Epoch 242\n",
      "0.6479131527568983\n",
      "Starting Epoch 243\n",
      "0.6494003845297772\n",
      "Starting Epoch 244\n",
      "0.6482743050741113\n",
      "Starting Epoch 245\n",
      "0.6478886578394019\n",
      "Starting Epoch 246\n",
      "0.6480222344398499\n",
      "Starting Epoch 247\n",
      "0.6487359611884408\n",
      "Starting Epoch 248\n",
      "0.6477437822715096\n",
      "Starting Epoch 249\n",
      "0.6486907005310059\n",
      "New best model found at epoch 249 with validation loss 0.6265387535095215\n",
      "Starting Epoch 250\n",
      "0.6476431825886602\n",
      "Starting Epoch 251\n",
      "0.648037094136943\n",
      "Starting Epoch 252\n",
      "0.6483950563099073\n",
      "Starting Epoch 253\n",
      "0.646314219288204\n",
      "Starting Epoch 254\n",
      "0.6459251927292865\n",
      "Starting Epoch 255\n",
      "0.647761881351471\n",
      "Starting Epoch 256\n",
      "0.6465199382408805\n",
      "Starting Epoch 257\n",
      "0.645727637021438\n",
      "Starting Epoch 258\n",
      "0.6477927228678828\n",
      "Starting Epoch 259\n",
      "0.6486080444377401\n",
      "Starting Epoch 260\n",
      "0.6474893093109131\n",
      "Starting Epoch 261\n",
      "0.6470498624055282\n",
      "New best model found at epoch 261 with validation loss 0.6256177425384521\n",
      "Starting Epoch 262\n",
      "0.6463424796643464\n",
      "Starting Epoch 263\n",
      "0.64623463931291\n",
      "Starting Epoch 264\n",
      "0.6455456795899764\n",
      "Starting Epoch 265\n",
      "0.6485177615414495\n",
      "Starting Epoch 266\n",
      "0.6468749435051627\n",
      "Starting Epoch 267\n",
      "0.6480132082234258\n",
      "Starting Epoch 268\n",
      "0.6497778115065201\n",
      "Starting Epoch 269\n",
      "0.6479433878608372\n",
      "Starting Epoch 270\n",
      "0.6465719679127568\n",
      "New best model found at epoch 270 with validation loss 0.6252219676971436\n",
      "Starting Epoch 271\n",
      "0.6451509361681731\n",
      "New best model found at epoch 271 with validation loss 0.6250203251838684\n",
      "Starting Epoch 272\n",
      "0.6473023995109226\n",
      "Starting Epoch 273\n",
      "0.6474519086920697\n",
      "Starting Epoch 274\n",
      "0.6466267212577488\n",
      "Starting Epoch 275\n",
      "0.6461387276649475\n",
      "Starting Epoch 276\n",
      "0.6476925170939901\n",
      "Starting Epoch 277\n",
      "0.6458314605381178\n",
      "Starting Epoch 278\n",
      "0.6441087917141293\n",
      "Starting Epoch 279\n",
      "0.6467853473580402\n",
      "Starting Epoch 280\n",
      "0.6458656088165615\n",
      "Starting Epoch 281\n",
      "0.6455675726351531\n",
      "Starting Epoch 282\n",
      "0.6448519255803979\n",
      "Starting Epoch 283\n",
      "0.6447225679521975\n",
      "Starting Epoch 284\n",
      "0.6444670324740203\n",
      "Starting Epoch 285\n",
      "0.6510019120962723\n",
      "Starting Epoch 286\n",
      "0.6454538521559342\n",
      "Starting Epoch 287\n",
      "0.645524219326351\n",
      "New best model found at epoch 287 with validation loss 0.6243473887443542\n",
      "Starting Epoch 288\n",
      "0.64330597286639\n",
      "Starting Epoch 289\n",
      "0.6467752793560857\n",
      "New best model found at epoch 289 with validation loss 0.623953104019165\n",
      "Starting Epoch 290\n",
      "0.6453998581222866\n",
      "Starting Epoch 291\n",
      "0.6435944800791533\n",
      "Starting Epoch 292\n",
      "0.6456621988959934\n",
      "Starting Epoch 293\n",
      "0.6467120206874349\n",
      "Starting Epoch 294\n",
      "0.6435964185258617\n",
      "Starting Epoch 295\n",
      "0.6424497832422671\n",
      "Starting Epoch 296\n",
      "0.6467935287434122\n",
      "Starting Epoch 297\n",
      "0.6456472821857618\n",
      "Starting Epoch 298\n",
      "0.6466944917388584\n",
      "Starting Epoch 299\n",
      "0.6441815495491028\n",
      "Starting Epoch 300\n",
      "0.6455172870470129\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-25-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b973983",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 5, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 40 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a06a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c95bb68-4936-4eb1-96c8-9ecf66694148",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466353e-80f0-4663-a237-2e160d214590",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3932c5-b9e9-45b5-95f6-833ea8df8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02cd381-8869-49b3-8f76-ea258a167c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-40-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd548efc",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 6, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 60 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe2484-8cd1-4458-9f80-028626758ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-60-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a39e80-531e-42b4-8857-522445450288",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-60-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cdf2e-1f3a-48be-bb1a-bafa856cd5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-60-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4261fb9-95dc-4ca3-b161-5355bf2cdc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-60-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8266617",
   "metadata": {},
   "source": [
    "#### 4-layer MLP\n",
    "*  Loss: Cross-entropy\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91bc9bf",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 1, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 10 - 5 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b134b59-3293-4158-913c-72067cb498f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-10-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7b10b-7ec2-4713-b394-04cf0c22ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-10-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a01ad-9e06-4387-bd2d-53e82703d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-10-5-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22014df1-5a55-48f6-8173-610b5d8e9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-10-5-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05523747",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 2, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 20 - 10 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12219b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b4f16-2797-4d69-a048-8ee88cc67422",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-20-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333ce2d-d3f9-438a-9a5c-7906c5c1dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-20-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eee324-fe9e-4592-a989-ea93aff01046",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-20-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951583da-2c9d-4e84-aec0-9b7be63db9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-20-10-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8bf3d",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 3, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 20 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87001a65-8c3d-4bde-a024-0ea33f4cd8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-40-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34048d50-99cd-4cb8-81ce-26d7f8bb4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-40-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771fc293-4e96-47be-b524-3c1368bf31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-40-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a56ee-8671-4c31-9f1d-5787ebd74bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-40-20-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac158a",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 4, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 10 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f3058-04cf-4f60-846f-9caa294451ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-40-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3cc4d-4b25-4d08-b8f0-c380fba8f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-40-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8a60a-6d33-41d3-b7a1-5e7b3cbc224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-40-10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c05f8-d6f0-4ff9-8bc6-390ac975bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-40-10-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e096df",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 5, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 40 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f5cb9-775b-4c31-bae9-cb7eddf2a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-60-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1868044-5266-4793-bffc-02839f770ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-60-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914242a5-3568-40df-9d67-1f564ee0ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-60-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948cbc5-dc74-4ae4-878d-69739376ed9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-60-40-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c67be7",
   "metadata": {},
   "source": [
    "##### 4-layers MLP: Version 6, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 20 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb635d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3274689-b0f2-4158-abc5-14ba670ac4f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8c8a1-4737-4f23-9355-9f70516eeb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c02e0-366a-4aef-a470-11f788a27283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751884a-5150-4316-9db2-15e9b528581c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-60-20-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6fec98",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 7, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 80 - 50 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76887ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84858f-4bb4-4f71-8aed-0437f66fbad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5: 17-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e4c7f-40aa-4478-9a3d-48f7b4665699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1: 17-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bacc3e1-a68a-4915-84be-d7f119e5dcb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05: 17-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824cb04-c96e-44b8-bb71-77c830d24d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01: 17-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d489cb-9856-4d8e-a93f-d4ccadcb987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "table_3_classes[:76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565bd87-c60d-43cb-b844-ea1f6bf9497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = table_3_classes.iloc[::4][6:19]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93fee26-8fb1-4049-90cb-76f7bbaecf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = table_3_classes.iloc[1::4][6:19]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458a5ae-e8e6-422a-804c-3b625a11a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = table_3_classes.iloc[2::4][6:19]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d388eff-4904-4752-878f-0cc510d7204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = table_3_classes.iloc[3::4][6:19]\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6162045a",
   "metadata": {},
   "source": [
    "best performing model until now: \n",
    "*  cut-off 0.5: 4 layers, 17-60-20-3\n",
    "*  cut-off 0.1: 4 layers, 17-60-40-3/17-60-20-3/17-80-50-3\n",
    "*  cut-off 0.05: 4 layers, 17-80-50-3\n",
    "*  cut-off 0.01: 4 layers, 17-80-50-3\n",
    "\n",
    "For comparibility we decide to use 17-80-50-3 as \"best model\" for all the next models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889c99c",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 1, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb81d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,9,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a364cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a783da-7da2-4414-b1de-6c64d873cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_median: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db798375-d7e0-4105-a57f-e88bb984a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_median: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1359623-79e9-49df-919c-719d1894a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_median: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd57a00-396b-4f40-8675-2bf296502abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_median: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62121ea3",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 2, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896dd70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,7,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9418b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551fdd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c59552-a1a7-4d74-b63c-6ab1fad8013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_mean: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb968d-71f0-4b5a-98a1-d2afbc1ef100",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_mean: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7568a41-30a2-460b-acd7-ba295ee36eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_mean: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3d2b3-f930-4696-bac9-3bc4be287d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_mean: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2573f11",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 3, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,5,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dbeb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af8df9-793d-426a-b94e-ae36d2276b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_min: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0d6e9-d704-45d4-9fee-03ccb037abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_min: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cfa07-512b-4d78-9788-23f2bc889c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_min: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020df786-30cc-4145-9829-acd0333a02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_min: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b495992",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 4, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,6,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51793d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f6b23-0776-443e-bdfd-7f0087c7555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_max: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db6f28-ee20-4380-a070-33c608317ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_max: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dedaac-4ff5-48b3-8353-6abb30bc66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_max: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a027e74-cc46-4370-b7e4-ee2d2a1cc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_max: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e60356",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 5, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.25-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f05e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0f4c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,8,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8eac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc1d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a17189-1774-44b7-8b9d-3566b3f1c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_q25: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b812ee3-c4ac-47bf-bd51-4601dded3d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_q25: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2bd1b-7b18-4bfe-bab0-03e6136bf72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_q25: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2fe1e6-fda9-4bc7-b4cf-d72b96cb3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_q25: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216add0b",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 6, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.75-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deacd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,10,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1612a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220a45c-7014-47b4-9258-d6c0e1eb85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_05_train_mlp, X_val_small, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, small_q75: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886a94ae-8b3f-492c-9a78-af47454dfa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_01_train_mlp, X_val_small, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, small_q75: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a4838-fd1d-489c-9cb1-a0bf630dda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_005_train_mlp, X_val_small, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, small_q75: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe632b03-ddfa-4ec6-9d80-e5cd899a1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train_small, y1_equal_001_train_mlp, X_val_small, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, small_q75: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c852afb",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, custom layer, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 80 - 50 - 3 (best model before)\n",
    "*  Adding a custom layer, where we group all features occuring multiple times together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13529344",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 1)  \n",
    "        self.fc2 = nn.Linear(1, 1)  \n",
    "        self.fc3 = nn.Linear(1, 1)  \n",
    "        self.fc4 = nn.Linear(1, 1)  \n",
    "        self.fc5 = nn.Linear(1, 1)  \n",
    "        self.fc6 = nn.Linear(6, 1)  \n",
    "        self.fc7 = nn.Linear(6, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        grouped_features = torch.cat((self.fc1(x[:, 0:1]), self.fc2(x[:, 1:2]), self.fc3(x[:, 2:3]), self.fc4(x[:, 3:4]), \n",
    "                                      self.fc5(x[:, 4:5]), self.fc6(x[:, 5:11]), self.fc7(x[:, 11:17])), dim=1)\n",
    "        \n",
    "        return grouped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.custom_layer = CustomLayer()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.custom_layer(x)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee277fab-ab7e-4ce0-9050-c2932c946359",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_05_train_mlp, X_val, y1_equal_05_val_mlp, \"3_class\", \"MLP 0.5, custom: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44466c-6757-4845-8358-ea6251e2f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_01_train_mlp, X_val, y1_equal_01_val_mlp, \"3_class\", \"MLP 0.1, custom: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab05a3e-9ef0-4c01-908b-88c6f04b61e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_005_train_mlp, X_val, y1_equal_005_val_mlp, \"3_class\", \"MLP 0.05, custom: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb448d4a-3ab1-47bd-bdf8-7cb82f1b0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_classification(X_train, y1_equal_001_train_mlp, X_val, y1_equal_001_val_mlp, \"3_class\", \"MLP 0.01, custom: 7-80-50-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2088d-dff8-454c-a8ed-87d71b45dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c483731-887c-4a2a-8147-cc7cc94df2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes.to_csv('results/table_3_classes_DDB_rounded.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6aec2f",
   "metadata": {},
   "source": [
    "### Deep MLP with time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "925b6880-d278-436c-81dc-587a2808c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.values).float()  # Convert DataFrame to tensor\n",
    "        self.y = torch.from_numpy(y.values).float()  # Convert DataFrame to tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "d0ad622c-7c29-43d9-bca2-d48eb3437a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_regression(X_training, y_training, X_validation, y_validation, text):\n",
    "    custom_dataset = CustomDataset(X_training, y_training)\n",
    "    trainloader = torch.utils.data.DataLoader(custom_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "    mlp = MLP(random_seed=20)\n",
    "    \n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adagrad(mlp.parameters(), lr=0.01)\n",
    "    \n",
    "    val_data = torch.tensor(X_validation.values, dtype=torch.float32)\n",
    "    val_targets = torch.tensor(y_validation.values, dtype=torch.float32)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(0,300):\n",
    "        print(f'Starting Epoch {epoch+1}')\n",
    "    \n",
    "        current_loss = 0.0\n",
    "    \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.float(), targets.float()\n",
    "            targets = targets.reshape((targets.shape[0], 1))\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = mlp(inputs)\n",
    "    \n",
    "            loss = loss_function(outputs, targets)\n",
    "    \n",
    "            loss.backward()\n",
    "    \n",
    "            optimizer.step()\n",
    "    \n",
    "            current_loss += loss.item()\n",
    "    \n",
    "        print(current_loss/len(trainloader))\n",
    "    \n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = mlp(val_data)\n",
    "            val_loss = loss_function(val_outputs, val_targets.reshape(val_targets.shape[0], 1)).item()\n",
    "            print(f'Validation loss: {val_loss}')\n",
    "            print(\"mse\", mean_squared_error(np.array(val_targets), np.array(val_outputs.squeeze().tolist())))\n",
    "    \n",
    "        # Check if this is the best model so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = deepcopy(mlp.state_dict())\n",
    "            print(f'New best model found at epoch {epoch+1} with validation loss {best_val_loss}')\n",
    "    \n",
    "    \n",
    "    print(\"Training has completed\")\n",
    "\n",
    "    mlp2 = MLP(random_seed=20)\n",
    "    mlp2.load_state_dict(best_model_state)\n",
    "\n",
    "    mlp2.eval() \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = mlp2(val_data)\n",
    "        predicted_labels = outputs.squeeze().tolist()\n",
    "    \n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    val_targets = np.array(val_targets)\n",
    "    \n",
    "    mse = mean_squared_error(val_targets, predicted_labels)\n",
    "    mae = mean_absolute_error(val_targets, predicted_labels)\n",
    "    r2 = r2_score(val_targets, predicted_labels)\n",
    "    \n",
    "    table_time_diff.loc[text] = [mse, mae, r2, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b3dde-40da-4508-b3ab-f21545d5a14d",
   "metadata": {},
   "source": [
    "#### 3-layer MLP\n",
    "*  Loss: MSE\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca9fc6-2fa6-4b8e-a43c-5a082d450165",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 1\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 5 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "7030ab18-5d89-446f-a151-cdc4cb0cfdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "1f527fb9-3fbb-4e56-9ac3-33ecd7ce92e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "2.9354673105737437\n",
      "Validation loss: 2.5213797092437744\n",
      "mse 2.521379580241457\n",
      "New best model found at epoch 1 with validation loss 2.5213797092437744\n",
      "Starting Epoch 2\n",
      "2.8019696214924688\n",
      "Validation loss: 2.447984218597412\n",
      "mse 2.4479844457723665\n",
      "New best model found at epoch 2 with validation loss 2.447984218597412\n",
      "Starting Epoch 3\n",
      "2.7247597238291865\n",
      "Validation loss: 2.388216733932495\n",
      "mse 2.388216758077042\n",
      "New best model found at epoch 3 with validation loss 2.388216733932495\n",
      "Starting Epoch 4\n",
      "2.6599289748979653\n",
      "Validation loss: 2.3374054431915283\n",
      "mse 2.3374052540315033\n",
      "New best model found at epoch 4 with validation loss 2.3374054431915283\n",
      "Starting Epoch 5\n",
      "2.603290749632794\n",
      "Validation loss: 2.292165756225586\n",
      "mse 2.292165825013207\n",
      "New best model found at epoch 5 with validation loss 2.292165756225586\n",
      "Starting Epoch 6\n",
      "2.552706480026245\n",
      "Validation loss: 2.2513372898101807\n",
      "mse 2.251337188937752\n",
      "New best model found at epoch 6 with validation loss 2.2513372898101807\n",
      "Starting Epoch 7\n",
      "2.506913801898127\n",
      "Validation loss: 2.2146217823028564\n",
      "mse 2.2146218481550175\n",
      "New best model found at epoch 7 with validation loss 2.2146217823028564\n",
      "Starting Epoch 8\n",
      "2.4647457858790522\n",
      "Validation loss: 2.181475877761841\n",
      "mse 2.1814759287202827\n",
      "New best model found at epoch 8 with validation loss 2.181475877761841\n",
      "Starting Epoch 9\n",
      "2.4260147343511167\n",
      "Validation loss: 2.1511547565460205\n",
      "mse 2.1511546830951263\n",
      "New best model found at epoch 9 with validation loss 2.1511547565460205\n",
      "Starting Epoch 10\n",
      "2.38977733384008\n",
      "Validation loss: 2.1228737831115723\n",
      "mse 2.12287385983335\n",
      "New best model found at epoch 10 with validation loss 2.1228737831115723\n",
      "Starting Epoch 11\n",
      "2.355667927990789\n",
      "Validation loss: 2.0967109203338623\n",
      "mse 2.0967107968631313\n",
      "New best model found at epoch 11 with validation loss 2.0967109203338623\n",
      "Starting Epoch 12\n",
      "2.32389061347298\n",
      "Validation loss: 2.0725784301757812\n",
      "mse 2.072578243216199\n",
      "New best model found at epoch 12 with validation loss 2.0725784301757812\n",
      "Starting Epoch 13\n",
      "2.294482707977295\n",
      "Validation loss: 2.049936532974243\n",
      "mse 2.0499365176531628\n",
      "New best model found at epoch 13 with validation loss 2.049936532974243\n",
      "Starting Epoch 14\n",
      "2.2671933847924937\n",
      "Validation loss: 2.0285356044769287\n",
      "mse 2.028535701756128\n",
      "New best model found at epoch 14 with validation loss 2.0285356044769287\n",
      "Starting Epoch 15\n",
      "2.241708708846051\n",
      "Validation loss: 2.008805274963379\n",
      "mse 2.008805162058087\n",
      "New best model found at epoch 15 with validation loss 2.008805274963379\n",
      "Starting Epoch 16\n",
      "2.2175096843553628\n",
      "Validation loss: 1.99092435836792\n",
      "mse 1.9909242696734322\n",
      "New best model found at epoch 16 with validation loss 1.99092435836792\n",
      "Starting Epoch 17\n",
      "2.1948622205983037\n",
      "Validation loss: 1.9735993146896362\n",
      "mse 1.9735991400169919\n",
      "New best model found at epoch 17 with validation loss 1.9735993146896362\n",
      "Starting Epoch 18\n",
      "2.1735211351643438\n",
      "Validation loss: 1.9566898345947266\n",
      "mse 1.956689690769883\n",
      "New best model found at epoch 18 with validation loss 1.9566898345947266\n",
      "Starting Epoch 19\n",
      "2.152583308841871\n",
      "Validation loss: 1.9407912492752075\n",
      "mse 1.9407913844261329\n",
      "New best model found at epoch 19 with validation loss 1.9407912492752075\n",
      "Starting Epoch 20\n",
      "2.133182618928992\n",
      "Validation loss: 1.9253132343292236\n",
      "mse 1.925313046239568\n",
      "New best model found at epoch 20 with validation loss 1.9253132343292236\n",
      "Starting Epoch 21\n",
      "2.1138032208318296\n",
      "Validation loss: 1.911272406578064\n",
      "mse 1.9112724671034744\n",
      "New best model found at epoch 21 with validation loss 1.911272406578064\n",
      "Starting Epoch 22\n",
      "2.0964129437570986\n",
      "Validation loss: 1.8971822261810303\n",
      "mse 1.897182241015055\n",
      "New best model found at epoch 22 with validation loss 1.8971822261810303\n",
      "Starting Epoch 23\n",
      "2.0790055005446724\n",
      "Validation loss: 1.8845981359481812\n",
      "mse 1.8845979961074526\n",
      "New best model found at epoch 23 with validation loss 1.8845981359481812\n",
      "Starting Epoch 24\n",
      "2.063441385393557\n",
      "Validation loss: 1.8723393678665161\n",
      "mse 1.872339357063027\n",
      "New best model found at epoch 24 with validation loss 1.8723393678665161\n",
      "Starting Epoch 25\n",
      "2.048633907152259\n",
      "Validation loss: 1.8607091903686523\n",
      "mse 1.8607092405469334\n",
      "New best model found at epoch 25 with validation loss 1.8607091903686523\n",
      "Starting Epoch 26\n",
      "2.034660868022753\n",
      "Validation loss: 1.8496336936950684\n",
      "mse 1.8496336778351574\n",
      "New best model found at epoch 26 with validation loss 1.8496336936950684\n",
      "Starting Epoch 27\n",
      "2.021379398263019\n",
      "Validation loss: 1.838911771774292\n",
      "mse 1.8389118347832438\n",
      "New best model found at epoch 27 with validation loss 1.838911771774292\n",
      "Starting Epoch 28\n",
      "2.008558397707732\n",
      "Validation loss: 1.828517198562622\n",
      "mse 1.8285172039644586\n",
      "New best model found at epoch 28 with validation loss 1.828517198562622\n",
      "Starting Epoch 29\n",
      "1.996439208155093\n",
      "Validation loss: 1.8184669017791748\n",
      "mse 1.818466906337053\n",
      "New best model found at epoch 29 with validation loss 1.8184669017791748\n",
      "Starting Epoch 30\n",
      "1.9849215486775273\n",
      "Validation loss: 1.8085416555404663\n",
      "mse 1.8085415155596223\n",
      "New best model found at epoch 30 with validation loss 1.8085416555404663\n",
      "Starting Epoch 31\n",
      "1.973612816437431\n",
      "Validation loss: 1.7996420860290527\n",
      "mse 1.799642212488819\n",
      "New best model found at epoch 31 with validation loss 1.7996420860290527\n",
      "Starting Epoch 32\n",
      "1.9629919373470803\n",
      "Validation loss: 1.7909456491470337\n",
      "mse 1.7909454907320737\n",
      "New best model found at epoch 32 with validation loss 1.7909456491470337\n",
      "Starting Epoch 33\n",
      "1.952831796977831\n",
      "Validation loss: 1.7827038764953613\n",
      "mse 1.7827039733576768\n",
      "New best model found at epoch 33 with validation loss 1.7827038764953613\n",
      "Starting Epoch 34\n",
      "1.9432981428892717\n",
      "Validation loss: 1.7751646041870117\n",
      "mse 1.7751647157118693\n",
      "New best model found at epoch 34 with validation loss 1.7751646041870117\n",
      "Starting Epoch 35\n",
      "1.934006234873896\n",
      "Validation loss: 1.7677891254425049\n",
      "mse 1.7677892058213438\n",
      "New best model found at epoch 35 with validation loss 1.7677891254425049\n",
      "Starting Epoch 36\n",
      "1.9251313935155454\n",
      "Validation loss: 1.7606984376907349\n",
      "mse 1.7606983111079997\n",
      "New best model found at epoch 36 with validation loss 1.7606984376907349\n",
      "Starting Epoch 37\n",
      "1.9166016008542932\n",
      "Validation loss: 1.7536463737487793\n",
      "mse 1.753646325938569\n",
      "New best model found at epoch 37 with validation loss 1.7536463737487793\n",
      "Starting Epoch 38\n",
      "1.9085242489109868\n",
      "Validation loss: 1.7467412948608398\n",
      "mse 1.7467413382461296\n",
      "New best model found at epoch 38 with validation loss 1.7467412948608398\n",
      "Starting Epoch 39\n",
      "1.9005025832549385\n",
      "Validation loss: 1.7406539916992188\n",
      "mse 1.7406538825477562\n",
      "New best model found at epoch 39 with validation loss 1.7406539916992188\n",
      "Starting Epoch 40\n",
      "1.8928188396536785\n",
      "Validation loss: 1.7348668575286865\n",
      "mse 1.7348667748457036\n",
      "New best model found at epoch 40 with validation loss 1.7348668575286865\n",
      "Starting Epoch 41\n",
      "1.8857604109722634\n",
      "Validation loss: 1.728799819946289\n",
      "mse 1.7287997579922578\n",
      "New best model found at epoch 41 with validation loss 1.728799819946289\n",
      "Starting Epoch 42\n",
      "1.8786341833031697\n",
      "Validation loss: 1.7233445644378662\n",
      "mse 1.7233445417590967\n",
      "New best model found at epoch 42 with validation loss 1.7233445644378662\n",
      "Starting Epoch 43\n",
      "1.8720224525617517\n",
      "Validation loss: 1.7179811000823975\n",
      "mse 1.7179810830181919\n",
      "New best model found at epoch 43 with validation loss 1.7179811000823975\n",
      "Starting Epoch 44\n",
      "1.8655907641286436\n",
      "Validation loss: 1.7127243280410767\n",
      "mse 1.7127242618582599\n",
      "New best model found at epoch 44 with validation loss 1.7127243280410767\n",
      "Starting Epoch 45\n",
      "1.8594968733580217\n",
      "Validation loss: 1.7077603340148926\n",
      "mse 1.7077602898514224\n",
      "New best model found at epoch 45 with validation loss 1.7077603340148926\n",
      "Starting Epoch 46\n",
      "1.8535807029060696\n",
      "Validation loss: 1.7029333114624023\n",
      "mse 1.7029332899825922\n",
      "New best model found at epoch 46 with validation loss 1.7029333114624023\n",
      "Starting Epoch 47\n",
      "1.8478854583657307\n",
      "Validation loss: 1.6980491876602173\n",
      "mse 1.6980492085196346\n",
      "New best model found at epoch 47 with validation loss 1.6980491876602173\n",
      "Starting Epoch 48\n",
      "1.8422616616539333\n",
      "Validation loss: 1.693699836730957\n",
      "mse 1.6936998289796588\n",
      "New best model found at epoch 48 with validation loss 1.693699836730957\n",
      "Starting Epoch 49\n",
      "1.8370988058007283\n",
      "Validation loss: 1.689070224761963\n",
      "mse 1.6890702455780844\n",
      "New best model found at epoch 49 with validation loss 1.689070224761963\n",
      "Starting Epoch 50\n",
      "1.8318054105924524\n",
      "Validation loss: 1.68509042263031\n",
      "mse 1.685090545157617\n",
      "New best model found at epoch 50 with validation loss 1.68509042263031\n",
      "Starting Epoch 51\n",
      "1.8268397735512776\n",
      "Validation loss: 1.680885910987854\n",
      "mse 1.6808859947817496\n",
      "New best model found at epoch 51 with validation loss 1.680885910987854\n",
      "Starting Epoch 52\n",
      "1.822044647258261\n",
      "Validation loss: 1.6770035028457642\n",
      "mse 1.677003587997147\n",
      "New best model found at epoch 52 with validation loss 1.6770035028457642\n",
      "Starting Epoch 53\n",
      "1.8173865028049634\n",
      "Validation loss: 1.6731274127960205\n",
      "mse 1.6731273754452\n",
      "New best model found at epoch 53 with validation loss 1.6731274127960205\n",
      "Starting Epoch 54\n",
      "1.8128905140835305\n",
      "Validation loss: 1.6693675518035889\n",
      "mse 1.6693676412547416\n",
      "New best model found at epoch 54 with validation loss 1.6693675518035889\n",
      "Starting Epoch 55\n",
      "1.8085009066954902\n",
      "Validation loss: 1.6655490398406982\n",
      "mse 1.6655489895187894\n",
      "New best model found at epoch 55 with validation loss 1.6655490398406982\n",
      "Starting Epoch 56\n",
      "1.8042761553888735\n",
      "Validation loss: 1.6619796752929688\n",
      "mse 1.6619798326235482\n",
      "New best model found at epoch 56 with validation loss 1.6619796752929688\n",
      "Starting Epoch 57\n",
      "1.8002746986306233\n",
      "Validation loss: 1.658447027206421\n",
      "mse 1.6584469865220661\n",
      "New best model found at epoch 57 with validation loss 1.658447027206421\n",
      "Starting Epoch 58\n",
      "1.7961169481277466\n",
      "Validation loss: 1.6555535793304443\n",
      "mse 1.655553652892539\n",
      "New best model found at epoch 58 with validation loss 1.6555535793304443\n",
      "Starting Epoch 59\n",
      "1.7922418221183445\n",
      "Validation loss: 1.652288794517517\n",
      "mse 1.6522888617282234\n",
      "New best model found at epoch 59 with validation loss 1.652288794517517\n",
      "Starting Epoch 60\n",
      "1.7885267786357715\n",
      "Validation loss: 1.649184226989746\n",
      "mse 1.6491843566494726\n",
      "New best model found at epoch 60 with validation loss 1.649184226989746\n",
      "Starting Epoch 61\n",
      "1.7848920822143555\n",
      "Validation loss: 1.6461408138275146\n",
      "mse 1.6461408202394432\n",
      "New best model found at epoch 61 with validation loss 1.6461408138275146\n",
      "Starting Epoch 62\n",
      "1.781338790188665\n",
      "Validation loss: 1.6432902812957764\n",
      "mse 1.643290203338542\n",
      "New best model found at epoch 62 with validation loss 1.6432902812957764\n",
      "Starting Epoch 63\n",
      "1.7779394077218098\n",
      "Validation loss: 1.6406627893447876\n",
      "mse 1.6406627651767354\n",
      "New best model found at epoch 63 with validation loss 1.6406627893447876\n",
      "Starting Epoch 64\n",
      "1.7746020970137224\n",
      "Validation loss: 1.637943983078003\n",
      "mse 1.6379440055194863\n",
      "New best model found at epoch 64 with validation loss 1.637943983078003\n",
      "Starting Epoch 65\n",
      "1.7714144302451091\n",
      "Validation loss: 1.6352784633636475\n",
      "mse 1.6352783632668921\n",
      "New best model found at epoch 65 with validation loss 1.6352784633636475\n",
      "Starting Epoch 66\n",
      "1.7682320967964504\n",
      "Validation loss: 1.6329021453857422\n",
      "mse 1.6329020134263013\n",
      "New best model found at epoch 66 with validation loss 1.6329021453857422\n",
      "Starting Epoch 67\n",
      "1.7652636299962583\n",
      "Validation loss: 1.6301705837249756\n",
      "mse 1.6301705706166605\n",
      "New best model found at epoch 67 with validation loss 1.6301705837249756\n",
      "Starting Epoch 68\n",
      "1.7623209901477979\n",
      "Validation loss: 1.6281254291534424\n",
      "mse 1.6281253609189104\n",
      "New best model found at epoch 68 with validation loss 1.6281254291534424\n",
      "Starting Epoch 69\n",
      "1.7593969832295957\n",
      "Validation loss: 1.6256232261657715\n",
      "mse 1.625623083708427\n",
      "New best model found at epoch 69 with validation loss 1.6256232261657715\n",
      "Starting Epoch 70\n",
      "1.756719102030215\n",
      "Validation loss: 1.6236913204193115\n",
      "mse 1.623691239288412\n",
      "New best model found at epoch 70 with validation loss 1.6236913204193115\n",
      "Starting Epoch 71\n",
      "1.753956120947133\n",
      "Validation loss: 1.6215848922729492\n",
      "mse 1.6215848521280316\n",
      "New best model found at epoch 71 with validation loss 1.6215848922729492\n",
      "Starting Epoch 72\n",
      "1.7513723010602205\n",
      "Validation loss: 1.6195220947265625\n",
      "mse 1.6195220933616428\n",
      "New best model found at epoch 72 with validation loss 1.6195220947265625\n",
      "Starting Epoch 73\n",
      "1.7488352474959001\n",
      "Validation loss: 1.6174167394638062\n",
      "mse 1.6174168414947634\n",
      "New best model found at epoch 73 with validation loss 1.6174167394638062\n",
      "Starting Epoch 74\n",
      "1.746383635894112\n",
      "Validation loss: 1.6153563261032104\n",
      "mse 1.6153564448900621\n",
      "New best model found at epoch 74 with validation loss 1.6153563261032104\n",
      "Starting Epoch 75\n",
      "1.7439907270929087\n",
      "Validation loss: 1.6133650541305542\n",
      "mse 1.613364966806576\n",
      "New best model found at epoch 75 with validation loss 1.6133650541305542\n",
      "Starting Epoch 76\n",
      "1.7416577909303748\n",
      "Validation loss: 1.6114243268966675\n",
      "mse 1.6114242092582332\n",
      "New best model found at epoch 76 with validation loss 1.6114243268966675\n",
      "Starting Epoch 77\n",
      "1.7393823862075806\n",
      "Validation loss: 1.6095994710922241\n",
      "mse 1.6095996710710037\n",
      "New best model found at epoch 77 with validation loss 1.6095994710922241\n",
      "Starting Epoch 78\n",
      "1.7371612528096074\n",
      "Validation loss: 1.6078051328659058\n",
      "mse 1.6078052434428856\n",
      "New best model found at epoch 78 with validation loss 1.6078051328659058\n",
      "Starting Epoch 79\n",
      "1.734999620396158\n",
      "Validation loss: 1.6060620546340942\n",
      "mse 1.6060618878673696\n",
      "New best model found at epoch 79 with validation loss 1.6060620546340942\n",
      "Starting Epoch 80\n",
      "1.7329017338545427\n",
      "Validation loss: 1.6044327020645142\n",
      "mse 1.604432715080271\n",
      "New best model found at epoch 80 with validation loss 1.6044327020645142\n",
      "Starting Epoch 81\n",
      "1.7308891026870064\n",
      "Validation loss: 1.6027926206588745\n",
      "mse 1.6027926292633081\n",
      "New best model found at epoch 81 with validation loss 1.6027926206588745\n",
      "Starting Epoch 82\n",
      "1.7289233466853267\n",
      "Validation loss: 1.6012390851974487\n",
      "mse 1.6012390808208448\n",
      "New best model found at epoch 82 with validation loss 1.6012390851974487\n",
      "Starting Epoch 83\n",
      "1.7269822255424832\n",
      "Validation loss: 1.5996811389923096\n",
      "mse 1.5996811029873215\n",
      "New best model found at epoch 83 with validation loss 1.5996811389923096\n",
      "Starting Epoch 84\n",
      "1.7251272305198337\n",
      "Validation loss: 1.5979148149490356\n",
      "mse 1.5979146733517606\n",
      "New best model found at epoch 84 with validation loss 1.5979148149490356\n",
      "Starting Epoch 85\n",
      "1.7233264705409175\n",
      "Validation loss: 1.5963997840881348\n",
      "mse 1.5963997771183764\n",
      "New best model found at epoch 85 with validation loss 1.5963997840881348\n",
      "Starting Epoch 86\n",
      "1.7214812817780867\n",
      "Validation loss: 1.594861626625061\n",
      "mse 1.594861817683478\n",
      "New best model found at epoch 86 with validation loss 1.594861626625061\n",
      "Starting Epoch 87\n",
      "1.7197577331377112\n",
      "Validation loss: 1.5934016704559326\n",
      "mse 1.5934018069302855\n",
      "New best model found at epoch 87 with validation loss 1.5934016704559326\n",
      "Starting Epoch 88\n",
      "1.7179938554763794\n",
      "Validation loss: 1.5919244289398193\n",
      "mse 1.5919243895789323\n",
      "New best model found at epoch 88 with validation loss 1.5919244289398193\n",
      "Starting Epoch 89\n",
      "1.7163343014924421\n",
      "Validation loss: 1.5904954671859741\n",
      "mse 1.5904955876371456\n",
      "New best model found at epoch 89 with validation loss 1.5904954671859741\n",
      "Starting Epoch 90\n",
      "1.714686580326246\n",
      "Validation loss: 1.5891261100769043\n",
      "mse 1.5891260061989183\n",
      "New best model found at epoch 90 with validation loss 1.5891261100769043\n",
      "Starting Epoch 91\n",
      "1.7131028745485388\n",
      "Validation loss: 1.5879124402999878\n",
      "mse 1.587912376869473\n",
      "New best model found at epoch 91 with validation loss 1.5879124402999878\n",
      "Starting Epoch 92\n",
      "1.7115041328513103\n",
      "Validation loss: 1.5864883661270142\n",
      "mse 1.5864883261043559\n",
      "New best model found at epoch 92 with validation loss 1.5864883661270142\n",
      "Starting Epoch 93\n",
      "1.7099885370420373\n",
      "Validation loss: 1.5852890014648438\n",
      "mse 1.585288928601733\n",
      "New best model found at epoch 93 with validation loss 1.5852890014648438\n",
      "Starting Epoch 94\n",
      "1.708480928255164\n",
      "Validation loss: 1.5840591192245483\n",
      "mse 1.5840591341579537\n",
      "New best model found at epoch 94 with validation loss 1.5840591192245483\n",
      "Starting Epoch 95\n",
      "1.7069747240647026\n",
      "Validation loss: 1.5829395055770874\n",
      "mse 1.5829394754254098\n",
      "New best model found at epoch 95 with validation loss 1.5829395055770874\n",
      "Starting Epoch 96\n",
      "1.7055253723393315\n",
      "Validation loss: 1.5818939208984375\n",
      "mse 1.5818938103910516\n",
      "New best model found at epoch 96 with validation loss 1.5818939208984375\n",
      "Starting Epoch 97\n",
      "1.7041136078212573\n",
      "Validation loss: 1.5808123350143433\n",
      "mse 1.5808124345023544\n",
      "New best model found at epoch 97 with validation loss 1.5808123350143433\n",
      "Starting Epoch 98\n",
      "1.7027432296587073\n",
      "Validation loss: 1.5797113180160522\n",
      "mse 1.579711235116632\n",
      "New best model found at epoch 98 with validation loss 1.5797113180160522\n",
      "Starting Epoch 99\n",
      "1.7014003421949304\n",
      "Validation loss: 1.5786207914352417\n",
      "mse 1.5786208824432368\n",
      "New best model found at epoch 99 with validation loss 1.5786207914352417\n",
      "Starting Epoch 100\n",
      "1.7000751754511958\n",
      "Validation loss: 1.5774610042572021\n",
      "mse 1.5774609365565468\n",
      "New best model found at epoch 100 with validation loss 1.5774610042572021\n",
      "Starting Epoch 101\n",
      "1.698780718057052\n",
      "Validation loss: 1.5763087272644043\n",
      "mse 1.5763085949491649\n",
      "New best model found at epoch 101 with validation loss 1.5763087272644043\n",
      "Starting Epoch 102\n",
      "1.697519038034522\n",
      "Validation loss: 1.5752350091934204\n",
      "mse 1.5752349458729653\n",
      "New best model found at epoch 102 with validation loss 1.5752350091934204\n",
      "Starting Epoch 103\n",
      "1.6962590321250584\n",
      "Validation loss: 1.5742301940917969\n",
      "mse 1.574230333177596\n",
      "New best model found at epoch 103 with validation loss 1.5742301940917969\n",
      "Starting Epoch 104\n",
      "1.695035696029663\n",
      "Validation loss: 1.5731861591339111\n",
      "mse 1.5731861182932243\n",
      "New best model found at epoch 104 with validation loss 1.5731861591339111\n",
      "Starting Epoch 105\n",
      "1.6938403378362241\n",
      "Validation loss: 1.5721626281738281\n",
      "mse 1.5721626987326123\n",
      "New best model found at epoch 105 with validation loss 1.5721626281738281\n",
      "Starting Epoch 106\n",
      "1.6926676812379255\n",
      "Validation loss: 1.571162223815918\n",
      "mse 1.5711622556055667\n",
      "New best model found at epoch 106 with validation loss 1.571162223815918\n",
      "Starting Epoch 107\n",
      "1.6915253504462864\n",
      "Validation loss: 1.5700548887252808\n",
      "mse 1.5700549701001298\n",
      "New best model found at epoch 107 with validation loss 1.5700548887252808\n",
      "Starting Epoch 108\n",
      "1.690396267434825\n",
      "Validation loss: 1.5691828727722168\n",
      "mse 1.5691829394396397\n",
      "New best model found at epoch 108 with validation loss 1.5691828727722168\n",
      "Starting Epoch 109\n",
      "1.6892885488012563\n",
      "Validation loss: 1.5681217908859253\n",
      "mse 1.5681218899087892\n",
      "New best model found at epoch 109 with validation loss 1.5681217908859253\n",
      "Starting Epoch 110\n",
      "1.6882076056107231\n",
      "Validation loss: 1.5671628713607788\n",
      "mse 1.5671627486028616\n",
      "New best model found at epoch 110 with validation loss 1.5671628713607788\n",
      "Starting Epoch 111\n",
      "1.687139604402625\n",
      "Validation loss: 1.566226601600647\n",
      "mse 1.5662267510902217\n",
      "New best model found at epoch 111 with validation loss 1.566226601600647\n",
      "Starting Epoch 112\n",
      "1.6860900806344075\n",
      "Validation loss: 1.5653101205825806\n",
      "mse 1.5653101540309\n",
      "New best model found at epoch 112 with validation loss 1.5653101205825806\n",
      "Starting Epoch 113\n",
      "1.6850589513778687\n",
      "Validation loss: 1.5644131898880005\n",
      "mse 1.5644130827704354\n",
      "New best model found at epoch 113 with validation loss 1.5644131898880005\n",
      "Starting Epoch 114\n",
      "1.6840457553448884\n",
      "Validation loss: 1.5635343790054321\n",
      "mse 1.5635343179803196\n",
      "New best model found at epoch 114 with validation loss 1.5635343790054321\n",
      "Starting Epoch 115\n",
      "1.683041354884272\n",
      "Validation loss: 1.5627533197402954\n",
      "mse 1.5627534068828368\n",
      "New best model found at epoch 115 with validation loss 1.5627533197402954\n",
      "Starting Epoch 116\n",
      "1.68207353612651\n",
      "Validation loss: 1.5618616342544556\n",
      "mse 1.5618615966559546\n",
      "New best model found at epoch 116 with validation loss 1.5618616342544556\n",
      "Starting Epoch 117\n",
      "1.6811151297196099\n",
      "Validation loss: 1.561066746711731\n",
      "mse 1.5610667870130006\n",
      "New best model found at epoch 117 with validation loss 1.561066746711731\n",
      "Starting Epoch 118\n",
      "1.6801704427470332\n",
      "Validation loss: 1.560272455215454\n",
      "mse 1.560272365510238\n",
      "New best model found at epoch 118 with validation loss 1.560272455215454\n",
      "Starting Epoch 119\n",
      "1.6792414292045261\n",
      "Validation loss: 1.5594878196716309\n",
      "mse 1.5594878575419642\n",
      "New best model found at epoch 119 with validation loss 1.5594878196716309\n",
      "Starting Epoch 120\n",
      "1.6783358791600103\n",
      "Validation loss: 1.5586378574371338\n",
      "mse 1.5586377715309097\n",
      "New best model found at epoch 120 with validation loss 1.5586378574371338\n",
      "Starting Epoch 121\n",
      "1.6774250320766284\n",
      "Validation loss: 1.557796597480774\n",
      "mse 1.557796606359958\n",
      "New best model found at epoch 121 with validation loss 1.557796597480774\n",
      "Starting Epoch 122\n",
      "1.676550699316937\n",
      "Validation loss: 1.557026982307434\n",
      "mse 1.5570269938185675\n",
      "New best model found at epoch 122 with validation loss 1.557026982307434\n",
      "Starting Epoch 123\n",
      "1.675669639006905\n",
      "Validation loss: 1.5562255382537842\n",
      "mse 1.5562254598636787\n",
      "New best model found at epoch 123 with validation loss 1.5562255382537842\n",
      "Starting Epoch 124\n",
      "1.6748070924178413\n",
      "Validation loss: 1.5554535388946533\n",
      "mse 1.5554535748534186\n",
      "New best model found at epoch 124 with validation loss 1.5554535388946533\n",
      "Starting Epoch 125\n",
      "1.6739584777666174\n",
      "Validation loss: 1.5547021627426147\n",
      "mse 1.5547020585305307\n",
      "New best model found at epoch 125 with validation loss 1.5547021627426147\n",
      "Starting Epoch 126\n",
      "1.6731339330258577\n",
      "Validation loss: 1.5539382696151733\n",
      "mse 1.553938221145415\n",
      "New best model found at epoch 126 with validation loss 1.5539382696151733\n",
      "Starting Epoch 127\n",
      "1.6723119901574177\n",
      "Validation loss: 1.5532091856002808\n",
      "mse 1.5532093709294765\n",
      "New best model found at epoch 127 with validation loss 1.5532091856002808\n",
      "Starting Epoch 128\n",
      "1.6715030618335889\n",
      "Validation loss: 1.5525009632110596\n",
      "mse 1.5525009850252272\n",
      "New best model found at epoch 128 with validation loss 1.5525009632110596\n",
      "Starting Epoch 129\n",
      "1.6707068059755408\n",
      "Validation loss: 1.5518081188201904\n",
      "mse 1.551808072506681\n",
      "New best model found at epoch 129 with validation loss 1.5518081188201904\n",
      "Starting Epoch 130\n",
      "1.6699226835499639\n",
      "Validation loss: 1.55112886428833\n",
      "mse 1.55112886456655\n",
      "New best model found at epoch 130 with validation loss 1.55112886428833\n",
      "Starting Epoch 131\n",
      "1.669150621994682\n",
      "Validation loss: 1.550462007522583\n",
      "mse 1.5504619530888735\n",
      "New best model found at epoch 131 with validation loss 1.550462007522583\n",
      "Starting Epoch 132\n",
      "1.668390092642411\n",
      "Validation loss: 1.549806833267212\n",
      "mse 1.549806796494413\n",
      "New best model found at epoch 132 with validation loss 1.549806833267212\n",
      "Starting Epoch 133\n",
      "1.66764089335566\n",
      "Validation loss: 1.5491632223129272\n",
      "mse 1.5491630820771618\n",
      "New best model found at epoch 133 with validation loss 1.5491632223129272\n",
      "Starting Epoch 134\n",
      "1.6669028582780256\n",
      "Validation loss: 1.548529863357544\n",
      "mse 1.548529870835578\n",
      "New best model found at epoch 134 with validation loss 1.548529863357544\n",
      "Starting Epoch 135\n",
      "1.666175593500552\n",
      "Validation loss: 1.5479073524475098\n",
      "mse 1.5479075036331487\n",
      "New best model found at epoch 135 with validation loss 1.5479073524475098\n",
      "Starting Epoch 136\n",
      "1.6654589694479238\n",
      "Validation loss: 1.5472948551177979\n",
      "mse 1.5472948119360186\n",
      "New best model found at epoch 136 with validation loss 1.5472948551177979\n",
      "Starting Epoch 137\n",
      "1.664752669956373\n",
      "Validation loss: 1.5466923713684082\n",
      "mse 1.5466923072334917\n",
      "New best model found at epoch 137 with validation loss 1.5466923713684082\n",
      "Starting Epoch 138\n",
      "1.6640565447185351\n",
      "Validation loss: 1.546099305152893\n",
      "mse 1.5460991282825278\n",
      "New best model found at epoch 138 with validation loss 1.546099305152893\n",
      "Starting Epoch 139\n",
      "1.6633703915969185\n",
      "Validation loss: 1.5455152988433838\n",
      "mse 1.5455151918504697\n",
      "New best model found at epoch 139 with validation loss 1.5455152988433838\n",
      "Starting Epoch 140\n",
      "1.6627144295236338\n",
      "Validation loss: 1.5448390245437622\n",
      "mse 1.5448390606791358\n",
      "New best model found at epoch 140 with validation loss 1.5448390245437622\n",
      "Starting Epoch 141\n",
      "1.662054331406303\n",
      "Validation loss: 1.5442321300506592\n",
      "mse 1.5442320104379288\n",
      "New best model found at epoch 141 with validation loss 1.5442321300506592\n",
      "Starting Epoch 142\n",
      "1.6613790315130483\n",
      "Validation loss: 1.5437371730804443\n",
      "mse 1.5437370593719981\n",
      "New best model found at epoch 142 with validation loss 1.5437371730804443\n",
      "Starting Epoch 143\n",
      "1.660747388134832\n",
      "Validation loss: 1.5432156324386597\n",
      "mse 1.5432157313965642\n",
      "New best model found at epoch 143 with validation loss 1.5432156324386597\n",
      "Starting Epoch 144\n",
      "1.6601144490034685\n",
      "Validation loss: 1.5426387786865234\n",
      "mse 1.5426387220580648\n",
      "New best model found at epoch 144 with validation loss 1.5426387786865234\n",
      "Starting Epoch 145\n",
      "1.6594978726428489\n",
      "Validation loss: 1.5422066450119019\n",
      "mse 1.5422066826490142\n",
      "New best model found at epoch 145 with validation loss 1.5422066450119019\n",
      "Starting Epoch 146\n",
      "1.658887215282606\n",
      "Validation loss: 1.541580319404602\n",
      "mse 1.5415801704015764\n",
      "New best model found at epoch 146 with validation loss 1.541580319404602\n",
      "Starting Epoch 147\n",
      "1.65828654040461\n",
      "Validation loss: 1.5411378145217896\n",
      "mse 1.5411378858504596\n",
      "New best model found at epoch 147 with validation loss 1.5411378145217896\n",
      "Starting Epoch 148\n",
      "1.6576971593110457\n",
      "Validation loss: 1.5407040119171143\n",
      "mse 1.5407041065335891\n",
      "New best model found at epoch 148 with validation loss 1.5407040119171143\n",
      "Starting Epoch 149\n",
      "1.6571192637733791\n",
      "Validation loss: 1.5402965545654297\n",
      "mse 1.5402965595244564\n",
      "New best model found at epoch 149 with validation loss 1.5402965545654297\n",
      "Starting Epoch 150\n",
      "1.6565568343452786\n",
      "Validation loss: 1.5398375988006592\n",
      "mse 1.5398374147379783\n",
      "New best model found at epoch 150 with validation loss 1.5398375988006592\n",
      "Starting Epoch 151\n",
      "1.6560228233752043\n",
      "Validation loss: 1.5394396781921387\n",
      "mse 1.5394397928509989\n",
      "New best model found at epoch 151 with validation loss 1.5394396781921387\n",
      "Starting Epoch 152\n",
      "1.6554830074310303\n",
      "Validation loss: 1.5390002727508545\n",
      "mse 1.5390002254324473\n",
      "New best model found at epoch 152 with validation loss 1.5390002727508545\n",
      "Starting Epoch 153\n",
      "1.6549499397692473\n",
      "Validation loss: 1.5385488271713257\n",
      "mse 1.5385488449000224\n",
      "New best model found at epoch 153 with validation loss 1.5385488271713257\n",
      "Starting Epoch 154\n",
      "1.654423221297886\n",
      "Validation loss: 1.5380958318710327\n",
      "mse 1.5380958288399496\n",
      "New best model found at epoch 154 with validation loss 1.5380958318710327\n",
      "Starting Epoch 155\n",
      "1.6539034739784573\n",
      "Validation loss: 1.5376464128494263\n",
      "mse 1.537646361328712\n",
      "New best model found at epoch 155 with validation loss 1.5376464128494263\n",
      "Starting Epoch 156\n",
      "1.6533905656441399\n",
      "Validation loss: 1.5372014045715332\n",
      "mse 1.537201480080189\n",
      "New best model found at epoch 156 with validation loss 1.5372014045715332\n",
      "Starting Epoch 157\n",
      "1.6528843719026316\n",
      "Validation loss: 1.536761999130249\n",
      "mse 1.536762097839511\n",
      "New best model found at epoch 157 with validation loss 1.536761999130249\n",
      "Starting Epoch 158\n",
      "1.652378499507904\n",
      "Validation loss: 1.5363961458206177\n",
      "mse 1.5363961150812169\n",
      "New best model found at epoch 158 with validation loss 1.5363961458206177\n",
      "Starting Epoch 159\n",
      "1.6518904877745586\n",
      "Validation loss: 1.5358943939208984\n",
      "mse 1.5358944354809438\n",
      "New best model found at epoch 159 with validation loss 1.5358943939208984\n",
      "Starting Epoch 160\n",
      "1.6514356239982273\n",
      "Validation loss: 1.5355373620986938\n",
      "mse 1.535537339335594\n",
      "New best model found at epoch 160 with validation loss 1.5355373620986938\n",
      "Starting Epoch 161\n",
      "1.6509464823681375\n",
      "Validation loss: 1.5350770950317383\n",
      "mse 1.535076889716488\n",
      "New best model found at epoch 161 with validation loss 1.5350770950317383\n",
      "Starting Epoch 162\n",
      "1.6504671495893728\n",
      "Validation loss: 1.5347262620925903\n",
      "mse 1.5347262781102906\n",
      "New best model found at epoch 162 with validation loss 1.5347262620925903\n",
      "Starting Epoch 163\n",
      "1.6500118504399839\n",
      "Validation loss: 1.534256100654602\n",
      "mse 1.5342561028628023\n",
      "New best model found at epoch 163 with validation loss 1.534256100654602\n",
      "Starting Epoch 164\n",
      "1.6495450216790903\n",
      "Validation loss: 1.533801794052124\n",
      "mse 1.5338018969984177\n",
      "New best model found at epoch 164 with validation loss 1.533801794052124\n",
      "Starting Epoch 165\n",
      "1.649106792781664\n",
      "Validation loss: 1.533407211303711\n",
      "mse 1.5334073646795308\n",
      "New best model found at epoch 165 with validation loss 1.533407211303711\n",
      "Starting Epoch 166\n",
      "1.6486453569453696\n",
      "Validation loss: 1.5330697298049927\n",
      "mse 1.5330697507558555\n",
      "New best model found at epoch 166 with validation loss 1.5330697298049927\n",
      "Starting Epoch 167\n",
      "1.6482118756874748\n",
      "Validation loss: 1.5326181650161743\n",
      "mse 1.532618079838409\n",
      "New best model found at epoch 167 with validation loss 1.5326181650161743\n",
      "Starting Epoch 168\n",
      "1.6477673105571582\n",
      "Validation loss: 1.532186508178711\n",
      "mse 1.5321865440587916\n",
      "New best model found at epoch 168 with validation loss 1.532186508178711\n",
      "Starting Epoch 169\n",
      "1.6473511431528174\n",
      "Validation loss: 1.531811237335205\n",
      "mse 1.5318112450049777\n",
      "New best model found at epoch 169 with validation loss 1.531811237335205\n",
      "Starting Epoch 170\n",
      "1.646912007228188\n",
      "Validation loss: 1.5313960313796997\n",
      "mse 1.5313960992058668\n",
      "New best model found at epoch 170 with validation loss 1.5313960313796997\n",
      "Starting Epoch 171\n",
      "1.6465055994365527\n",
      "Validation loss: 1.5310311317443848\n",
      "mse 1.5310312607095502\n",
      "New best model found at epoch 171 with validation loss 1.5310311317443848\n",
      "Starting Epoch 172\n",
      "1.6460908988247747\n",
      "Validation loss: 1.5306589603424072\n",
      "mse 1.5306590052531923\n",
      "New best model found at epoch 172 with validation loss 1.5306589603424072\n",
      "Starting Epoch 173\n",
      "1.6456669050714243\n",
      "Validation loss: 1.5302515029907227\n",
      "mse 1.5302513617452724\n",
      "New best model found at epoch 173 with validation loss 1.5302515029907227\n",
      "Starting Epoch 174\n",
      "1.6452749604764192\n",
      "Validation loss: 1.5298995971679688\n",
      "mse 1.5298994541317517\n",
      "New best model found at epoch 174 with validation loss 1.5298995971679688\n",
      "Starting Epoch 175\n",
      "1.6448748059894727\n",
      "Validation loss: 1.5295418500900269\n",
      "mse 1.529541757031373\n",
      "New best model found at epoch 175 with validation loss 1.5295418500900269\n",
      "Starting Epoch 176\n",
      "1.6444653635439666\n",
      "Validation loss: 1.5291485786437988\n",
      "mse 1.5291487246120627\n",
      "New best model found at epoch 176 with validation loss 1.5291485786437988\n",
      "Starting Epoch 177\n",
      "1.6440873871678892\n",
      "Validation loss: 1.5288110971450806\n",
      "mse 1.5288110768318695\n",
      "New best model found at epoch 177 with validation loss 1.5288110971450806\n",
      "Starting Epoch 178\n",
      "1.6437010505925054\n",
      "Validation loss: 1.5284663438796997\n",
      "mse 1.5284663319176859\n",
      "New best model found at epoch 178 with validation loss 1.5284663438796997\n",
      "Starting Epoch 179\n",
      "1.6433051824569702\n",
      "Validation loss: 1.5280884504318237\n",
      "mse 1.5280885271934301\n",
      "New best model found at epoch 179 with validation loss 1.5280884504318237\n",
      "Starting Epoch 180\n",
      "1.6429404668186023\n",
      "Validation loss: 1.5277645587921143\n",
      "mse 1.527764598571105\n",
      "New best model found at epoch 180 with validation loss 1.5277645587921143\n",
      "Starting Epoch 181\n",
      "1.6425673495168271\n",
      "Validation loss: 1.527431607246399\n",
      "mse 1.5274315458834289\n",
      "New best model found at epoch 181 with validation loss 1.527431607246399\n",
      "Starting Epoch 182\n",
      "1.6421981427980505\n",
      "Validation loss: 1.5270990133285522\n",
      "mse 1.5270990890588378\n",
      "New best model found at epoch 182 with validation loss 1.5270990133285522\n",
      "Starting Epoch 183\n",
      "1.6418191738750623\n",
      "Validation loss: 1.5267359018325806\n",
      "mse 1.52673596129622\n",
      "New best model found at epoch 183 with validation loss 1.5267359018325806\n",
      "Starting Epoch 184\n",
      "1.641470976497816\n",
      "Validation loss: 1.5264272689819336\n",
      "mse 1.5264272606956808\n",
      "New best model found at epoch 184 with validation loss 1.5264272689819336\n",
      "Starting Epoch 185\n",
      "1.6411142090092534\n",
      "Validation loss: 1.5261101722717285\n",
      "mse 1.5261099519719172\n",
      "New best model found at epoch 185 with validation loss 1.5261101722717285\n",
      "Starting Epoch 186\n",
      "1.6408191401025523\n",
      "Validation loss: 1.5256438255310059\n",
      "mse 1.5256436983539226\n",
      "New best model found at epoch 186 with validation loss 1.5256438255310059\n",
      "Starting Epoch 187\n",
      "1.6404078110404636\n",
      "Validation loss: 1.5253793001174927\n",
      "mse 1.5253792964282553\n",
      "New best model found at epoch 187 with validation loss 1.5253793001174927\n",
      "Starting Epoch 188\n",
      "1.6400679168493852\n",
      "Validation loss: 1.5250911712646484\n",
      "mse 1.5250912048444898\n",
      "New best model found at epoch 188 with validation loss 1.5250911712646484\n",
      "Starting Epoch 189\n",
      "1.639725332674773\n",
      "Validation loss: 1.5247889757156372\n",
      "mse 1.5247889676543367\n",
      "New best model found at epoch 189 with validation loss 1.5247889757156372\n",
      "Starting Epoch 190\n",
      "1.6393870167110278\n",
      "Validation loss: 1.5244859457015991\n",
      "mse 1.5244859608192647\n",
      "New best model found at epoch 190 with validation loss 1.5244859457015991\n",
      "Starting Epoch 191\n",
      "1.6391099898711494\n",
      "Validation loss: 1.5240389108657837\n",
      "mse 1.5240389690281242\n",
      "New best model found at epoch 191 with validation loss 1.5240389108657837\n",
      "Starting Epoch 192\n",
      "1.6387311038763628\n",
      "Validation loss: 1.5238221883773804\n",
      "mse 1.523821996271437\n",
      "New best model found at epoch 192 with validation loss 1.5238221883773804\n",
      "Starting Epoch 193\n",
      "1.6383962708970774\n",
      "Validation loss: 1.5235326290130615\n",
      "mse 1.5235327934103937\n",
      "New best model found at epoch 193 with validation loss 1.5235326290130615\n",
      "Starting Epoch 194\n",
      "1.6380708787752234\n",
      "Validation loss: 1.5232408046722412\n",
      "mse 1.5232408050844666\n",
      "New best model found at epoch 194 with validation loss 1.5232408046722412\n",
      "Starting Epoch 195\n",
      "1.6378069986467776\n",
      "Validation loss: 1.5228073596954346\n",
      "mse 1.5228074011230617\n",
      "New best model found at epoch 195 with validation loss 1.5228073596954346\n",
      "Starting Epoch 196\n",
      "1.6374420186747676\n",
      "Validation loss: 1.5226038694381714\n",
      "mse 1.5226036588624983\n",
      "New best model found at epoch 196 with validation loss 1.5226038694381714\n",
      "Starting Epoch 197\n",
      "1.6371204956718113\n",
      "Validation loss: 1.5223281383514404\n",
      "mse 1.5223280598354243\n",
      "New best model found at epoch 197 with validation loss 1.5223281383514404\n",
      "Starting Epoch 198\n",
      "1.63686473214108\n",
      "Validation loss: 1.5219060182571411\n",
      "mse 1.5219060935813564\n",
      "New best model found at epoch 198 with validation loss 1.5219060182571411\n",
      "Starting Epoch 199\n",
      "1.6364964324495066\n",
      "Validation loss: 1.5216822624206543\n",
      "mse 1.5216820896520211\n",
      "New best model found at epoch 199 with validation loss 1.5216822624206543\n",
      "Starting Epoch 200\n",
      "1.6361968672793845\n",
      "Validation loss: 1.5214365720748901\n",
      "mse 1.5214365494429916\n",
      "New best model found at epoch 200 with validation loss 1.5214365720748901\n",
      "Starting Epoch 201\n",
      "1.6359489197316377\n",
      "Validation loss: 1.5210444927215576\n",
      "mse 1.5210447444860704\n",
      "New best model found at epoch 201 with validation loss 1.5210444927215576\n",
      "Starting Epoch 202\n",
      "1.6355901516002158\n",
      "Validation loss: 1.5209147930145264\n",
      "mse 1.5209148220563269\n",
      "New best model found at epoch 202 with validation loss 1.5209147930145264\n",
      "Starting Epoch 203\n",
      "1.6352913820225259\n",
      "Validation loss: 1.520686388015747\n",
      "mse 1.5206862977115478\n",
      "New best model found at epoch 203 with validation loss 1.520686388015747\n",
      "Starting Epoch 204\n",
      "1.635062336921692\n",
      "Validation loss: 1.5203863382339478\n",
      "mse 1.520386246791786\n",
      "New best model found at epoch 204 with validation loss 1.5203863382339478\n",
      "Starting Epoch 205\n",
      "1.6347259205320608\n",
      "Validation loss: 1.520164966583252\n",
      "mse 1.520165112419402\n",
      "New best model found at epoch 205 with validation loss 1.520164966583252\n",
      "Starting Epoch 206\n",
      "1.6344187726145205\n",
      "Validation loss: 1.5201023817062378\n",
      "mse 1.5201022133651365\n",
      "New best model found at epoch 206 with validation loss 1.5201023817062378\n",
      "Starting Epoch 207\n",
      "1.6341879886129629\n",
      "Validation loss: 1.519763708114624\n",
      "mse 1.5197638809745926\n",
      "New best model found at epoch 207 with validation loss 1.519763708114624\n",
      "Starting Epoch 208\n",
      "1.6338835488195005\n",
      "Validation loss: 1.5196629762649536\n",
      "mse 1.5196628811512933\n",
      "New best model found at epoch 208 with validation loss 1.5196629762649536\n",
      "Starting Epoch 209\n",
      "1.6336635817652163\n",
      "Validation loss: 1.5193201303482056\n",
      "mse 1.5193202135096227\n",
      "New best model found at epoch 209 with validation loss 1.5193201303482056\n",
      "Starting Epoch 210\n",
      "1.6333513233972632\n",
      "Validation loss: 1.5191811323165894\n",
      "mse 1.5191811527811945\n",
      "New best model found at epoch 210 with validation loss 1.5191811323165894\n",
      "Starting Epoch 211\n",
      "1.6330800522928652\n",
      "Validation loss: 1.5189664363861084\n",
      "mse 1.518966487112948\n",
      "New best model found at epoch 211 with validation loss 1.5189664363861084\n",
      "Starting Epoch 212\n",
      "1.6328729494758274\n",
      "Validation loss: 1.518603801727295\n",
      "mse 1.5186038185066144\n",
      "New best model found at epoch 212 with validation loss 1.518603801727295\n",
      "Starting Epoch 213\n",
      "1.632542522057243\n",
      "Validation loss: 1.5186309814453125\n",
      "mse 1.5186308976857807\n",
      "Starting Epoch 214\n",
      "1.6323662296585415\n",
      "Validation loss: 1.5181957483291626\n",
      "mse 1.5181957504185104\n",
      "New best model found at epoch 214 with validation loss 1.5181957483291626\n",
      "Starting Epoch 215\n",
      "1.6320405991181084\n",
      "Validation loss: 1.5181924104690552\n",
      "mse 1.5181923645608295\n",
      "New best model found at epoch 215 with validation loss 1.5181924104690552\n",
      "Starting Epoch 216\n",
      "1.6318404907765596\n",
      "Validation loss: 1.5179147720336914\n",
      "mse 1.5179147377984625\n",
      "New best model found at epoch 216 with validation loss 1.5179147720336914\n",
      "Starting Epoch 217\n",
      "1.6315749391265537\n",
      "Validation loss: 1.5176565647125244\n",
      "mse 1.5176564741606962\n",
      "New best model found at epoch 217 with validation loss 1.5176565647125244\n",
      "Starting Epoch 218\n",
      "1.6313683079636616\n",
      "Validation loss: 1.5174225568771362\n",
      "mse 1.5174224304799773\n",
      "New best model found at epoch 218 with validation loss 1.5174225568771362\n",
      "Starting Epoch 219\n",
      "1.6310643450073574\n",
      "Validation loss: 1.5173578262329102\n",
      "mse 1.517357784468027\n",
      "New best model found at epoch 219 with validation loss 1.5173578262329102\n",
      "Starting Epoch 220\n",
      "1.6308934688568115\n",
      "Validation loss: 1.517054796218872\n",
      "mse 1.517054783094047\n",
      "New best model found at epoch 220 with validation loss 1.517054796218872\n",
      "Starting Epoch 221\n",
      "1.6306110154027524\n",
      "Validation loss: 1.5169601440429688\n",
      "mse 1.516960002642581\n",
      "New best model found at epoch 221 with validation loss 1.5169601440429688\n",
      "Starting Epoch 222\n",
      "1.6304085384244504\n",
      "Validation loss: 1.5168626308441162\n",
      "mse 1.516862595635445\n",
      "New best model found at epoch 222 with validation loss 1.5168626308441162\n",
      "Starting Epoch 223\n",
      "1.6301421600839365\n",
      "Validation loss: 1.5167055130004883\n",
      "mse 1.5167055700180216\n",
      "New best model found at epoch 223 with validation loss 1.5167055130004883\n",
      "Starting Epoch 224\n",
      "1.6299825129301653\n",
      "Validation loss: 1.5163655281066895\n",
      "mse 1.5163654799819268\n",
      "New best model found at epoch 224 with validation loss 1.5163655281066895\n",
      "Starting Epoch 225\n",
      "1.62970871510713\n",
      "Validation loss: 1.5162510871887207\n",
      "mse 1.5162510468889387\n",
      "New best model found at epoch 225 with validation loss 1.5162510871887207\n",
      "Starting Epoch 226\n",
      "1.6295104648755945\n",
      "Validation loss: 1.5161027908325195\n",
      "mse 1.5161027190723046\n",
      "New best model found at epoch 226 with validation loss 1.5161027908325195\n",
      "Starting Epoch 227\n",
      "1.6293220727340034\n",
      "Validation loss: 1.515782117843628\n",
      "mse 1.5157819903163814\n",
      "New best model found at epoch 227 with validation loss 1.515782117843628\n",
      "Starting Epoch 228\n",
      "1.629051545391912\n",
      "Validation loss: 1.5159481763839722\n",
      "mse 1.5159483456565541\n",
      "Starting Epoch 229\n",
      "1.6289032723592676\n",
      "Validation loss: 1.5155221223831177\n",
      "mse 1.5155222869073797\n",
      "New best model found at epoch 229 with validation loss 1.5155221223831177\n",
      "Starting Epoch 230\n",
      "1.6286257868227751\n",
      "Validation loss: 1.5156246423721313\n",
      "mse 1.515624549221331\n",
      "Starting Epoch 231\n",
      "1.6284566988115725\n",
      "Validation loss: 1.5153424739837646\n",
      "mse 1.515342400619097\n",
      "New best model found at epoch 231 with validation loss 1.5153424739837646\n",
      "Starting Epoch 232\n",
      "1.6282779004262842\n",
      "Validation loss: 1.5149636268615723\n",
      "mse 1.5149635924783607\n",
      "New best model found at epoch 232 with validation loss 1.5149636268615723\n",
      "Starting Epoch 233\n",
      "1.6280021719310596\n",
      "Validation loss: 1.5150609016418457\n",
      "mse 1.5150610771139545\n",
      "Starting Epoch 234\n",
      "1.6278688156086465\n",
      "Validation loss: 1.5146944522857666\n",
      "mse 1.5146943987662924\n",
      "New best model found at epoch 234 with validation loss 1.5146944522857666\n",
      "Starting Epoch 235\n",
      "1.6276463943979014\n",
      "Validation loss: 1.5146125555038452\n",
      "mse 1.5146125361391554\n",
      "New best model found at epoch 235 with validation loss 1.5146125555038452\n",
      "Starting Epoch 236\n",
      "1.6273862486300261\n",
      "Validation loss: 1.5145268440246582\n",
      "mse 1.5145268086221138\n",
      "New best model found at epoch 236 with validation loss 1.5145268440246582\n",
      "Starting Epoch 237\n",
      "1.627265064612679\n",
      "Validation loss: 1.5141589641571045\n",
      "mse 1.5141590878853919\n",
      "New best model found at epoch 237 with validation loss 1.5141589641571045\n",
      "Starting Epoch 238\n",
      "1.6270467561224233\n",
      "Validation loss: 1.5140769481658936\n",
      "mse 1.514076985761095\n",
      "New best model found at epoch 238 with validation loss 1.5140769481658936\n",
      "Starting Epoch 239\n",
      "1.6268769087998762\n",
      "Validation loss: 1.513777256011963\n",
      "mse 1.51377731897802\n",
      "New best model found at epoch 239 with validation loss 1.513777256011963\n",
      "Starting Epoch 240\n",
      "1.6266049405802852\n",
      "Validation loss: 1.5138338804244995\n",
      "mse 1.5138339241721428\n",
      "Starting Epoch 241\n",
      "1.626494972602181\n",
      "Validation loss: 1.5135430097579956\n",
      "mse 1.5135430177169547\n",
      "New best model found at epoch 241 with validation loss 1.5135430097579956\n",
      "Starting Epoch 242\n",
      "1.6262753139371458\n",
      "Validation loss: 1.5134072303771973\n",
      "mse 1.5134072757895052\n",
      "New best model found at epoch 242 with validation loss 1.5134072303771973\n",
      "Starting Epoch 243\n",
      "1.6260857063791025\n",
      "Validation loss: 1.5132533311843872\n",
      "mse 1.5132532932501785\n",
      "New best model found at epoch 243 with validation loss 1.5132533311843872\n",
      "Starting Epoch 244\n",
      "1.6258832734564077\n",
      "Validation loss: 1.5131422281265259\n",
      "mse 1.5131422279159297\n",
      "New best model found at epoch 244 with validation loss 1.5131422281265259\n",
      "Starting Epoch 245\n",
      "1.6257064783054849\n",
      "Validation loss: 1.5129246711730957\n",
      "mse 1.5129245333556889\n",
      "New best model found at epoch 245 with validation loss 1.5129246711730957\n",
      "Starting Epoch 246\n",
      "1.6255255574765413\n",
      "Validation loss: 1.512758731842041\n",
      "mse 1.5127587518564787\n",
      "New best model found at epoch 246 with validation loss 1.512758731842041\n",
      "Starting Epoch 247\n",
      "1.625379888907723\n",
      "Validation loss: 1.5125147104263306\n",
      "mse 1.5125146312755808\n",
      "New best model found at epoch 247 with validation loss 1.5125147104263306\n",
      "Starting Epoch 248\n",
      "1.6251625522323276\n",
      "Validation loss: 1.5123751163482666\n",
      "mse 1.5123751814382473\n",
      "New best model found at epoch 248 with validation loss 1.5123751163482666\n",
      "Starting Epoch 249\n",
      "1.6249942520390386\n",
      "Validation loss: 1.512304425239563\n",
      "mse 1.5123044916007662\n",
      "New best model found at epoch 249 with validation loss 1.512304425239563\n",
      "Starting Epoch 250\n",
      "1.6247541049252385\n",
      "Validation loss: 1.5122238397598267\n",
      "mse 1.5122239709566743\n",
      "New best model found at epoch 250 with validation loss 1.5122238397598267\n",
      "Starting Epoch 251\n",
      "1.6246546921522722\n",
      "Validation loss: 1.5118824243545532\n",
      "mse 1.5118824360844225\n",
      "New best model found at epoch 251 with validation loss 1.5118824243545532\n",
      "Starting Epoch 252\n",
      "1.6244484652643618\n",
      "Validation loss: 1.5117276906967163\n",
      "mse 1.51172773455872\n",
      "New best model found at epoch 252 with validation loss 1.5117276906967163\n",
      "Starting Epoch 253\n",
      "1.6242859648621601\n",
      "Validation loss: 1.5116556882858276\n",
      "mse 1.5116555721649418\n",
      "New best model found at epoch 253 with validation loss 1.5116556882858276\n",
      "Starting Epoch 254\n",
      "1.6241021493206853\n",
      "Validation loss: 1.5114459991455078\n",
      "mse 1.5114458357825826\n",
      "New best model found at epoch 254 with validation loss 1.5114459991455078\n",
      "Starting Epoch 255\n",
      "1.6239631746126257\n",
      "Validation loss: 1.5111842155456543\n",
      "mse 1.511184168388138\n",
      "New best model found at epoch 255 with validation loss 1.5111842155456543\n",
      "Starting Epoch 256\n",
      "1.623757489349531\n",
      "Validation loss: 1.5110399723052979\n",
      "mse 1.5110400202109673\n",
      "New best model found at epoch 256 with validation loss 1.5110399723052979\n",
      "Starting Epoch 257\n",
      "1.623599244200665\n",
      "Validation loss: 1.5109716653823853\n",
      "mse 1.5109715298144843\n",
      "New best model found at epoch 257 with validation loss 1.5109716653823853\n",
      "Starting Epoch 258\n",
      "1.6233697922333428\n",
      "Validation loss: 1.510897159576416\n",
      "mse 1.5108969374157806\n",
      "New best model found at epoch 258 with validation loss 1.510897159576416\n",
      "Starting Epoch 259\n",
      "1.6232577951058098\n",
      "Validation loss: 1.5107288360595703\n",
      "mse 1.5107288750806627\n",
      "New best model found at epoch 259 with validation loss 1.5107288360595703\n",
      "Starting Epoch 260\n",
      "1.623097697029943\n",
      "Validation loss: 1.5105901956558228\n",
      "mse 1.51059022238938\n",
      "New best model found at epoch 260 with validation loss 1.5105901956558228\n",
      "Starting Epoch 261\n",
      "1.6229451324628748\n",
      "Validation loss: 1.5101957321166992\n",
      "mse 1.510195790998522\n",
      "New best model found at epoch 261 with validation loss 1.5101957321166992\n",
      "Starting Epoch 262\n",
      "1.6227676894353784\n",
      "Validation loss: 1.5101662874221802\n",
      "mse 1.5101662815199053\n",
      "New best model found at epoch 262 with validation loss 1.5101662874221802\n",
      "Starting Epoch 263\n",
      "1.622594768586366\n",
      "Validation loss: 1.5099797248840332\n",
      "mse 1.5099796927033202\n",
      "New best model found at epoch 263 with validation loss 1.5099797248840332\n",
      "Starting Epoch 264\n",
      "1.6224516319191975\n",
      "Validation loss: 1.509920597076416\n",
      "mse 1.5099204990580768\n",
      "New best model found at epoch 264 with validation loss 1.509920597076416\n",
      "Starting Epoch 265\n",
      "1.6222775423008462\n",
      "Validation loss: 1.5097222328186035\n",
      "mse 1.5097222756569137\n",
      "New best model found at epoch 265 with validation loss 1.5097222328186035\n",
      "Starting Epoch 266\n",
      "1.6221517272617505\n",
      "Validation loss: 1.5094830989837646\n",
      "mse 1.5094830343828305\n",
      "New best model found at epoch 266 with validation loss 1.5094830989837646\n",
      "Starting Epoch 267\n",
      "1.621968976829363\n",
      "Validation loss: 1.5094399452209473\n",
      "mse 1.5094398536642546\n",
      "New best model found at epoch 267 with validation loss 1.5094399452209473\n",
      "Starting Epoch 268\n",
      "1.6218012726825217\n",
      "Validation loss: 1.5092564821243286\n",
      "mse 1.5092564313247967\n",
      "New best model found at epoch 268 with validation loss 1.5092564821243286\n",
      "Starting Epoch 269\n",
      "1.6216552490773408\n",
      "Validation loss: 1.5091842412948608\n",
      "mse 1.509184214591056\n",
      "New best model found at epoch 269 with validation loss 1.5091842412948608\n",
      "Starting Epoch 270\n",
      "1.6214882679607556\n",
      "Validation loss: 1.508989691734314\n",
      "mse 1.5089896469345108\n",
      "New best model found at epoch 270 with validation loss 1.508989691734314\n",
      "Starting Epoch 271\n",
      "1.621366946593575\n",
      "Validation loss: 1.5087682008743286\n",
      "mse 1.5087681920876987\n",
      "New best model found at epoch 271 with validation loss 1.5087682008743286\n",
      "Starting Epoch 272\n",
      "1.6211857562479766\n",
      "Validation loss: 1.508784532546997\n",
      "mse 1.5087845844310348\n",
      "Starting Epoch 273\n",
      "1.6210289131040159\n",
      "Validation loss: 1.508579969406128\n",
      "mse 1.508580054843179\n",
      "New best model found at epoch 273 with validation loss 1.508579969406128\n",
      "Starting Epoch 274\n",
      "1.6208880932434746\n",
      "Validation loss: 1.5084993839263916\n",
      "mse 1.508499484312233\n",
      "New best model found at epoch 274 with validation loss 1.5084993839263916\n",
      "Starting Epoch 275\n",
      "1.6207552785458772\n",
      "Validation loss: 1.5083012580871582\n",
      "mse 1.5083011844890235\n",
      "New best model found at epoch 275 with validation loss 1.5083012580871582\n",
      "Starting Epoch 276\n",
      "1.6205724037211875\n",
      "Validation loss: 1.5081915855407715\n",
      "mse 1.508191579998062\n",
      "New best model found at epoch 276 with validation loss 1.5081915855407715\n",
      "Starting Epoch 277\n",
      "1.6204562524090642\n",
      "Validation loss: 1.508014440536499\n",
      "mse 1.5080143923068974\n",
      "New best model found at epoch 277 with validation loss 1.508014440536499\n",
      "Starting Epoch 278\n",
      "1.6202881750853166\n",
      "Validation loss: 1.5080013275146484\n",
      "mse 1.5080013683636486\n",
      "New best model found at epoch 278 with validation loss 1.5080013275146484\n",
      "Starting Epoch 279\n",
      "1.6201305544894675\n",
      "Validation loss: 1.5078411102294922\n",
      "mse 1.5078411011890986\n",
      "New best model found at epoch 279 with validation loss 1.5078411102294922\n",
      "Starting Epoch 280\n",
      "1.6200022386467976\n",
      "Validation loss: 1.5077317953109741\n",
      "mse 1.507731884701771\n",
      "New best model found at epoch 280 with validation loss 1.5077317953109741\n",
      "Starting Epoch 281\n",
      "1.6198742882065151\n",
      "Validation loss: 1.507522702217102\n",
      "mse 1.5075227010255228\n",
      "New best model found at epoch 281 with validation loss 1.507522702217102\n",
      "Starting Epoch 282\n",
      "1.6197084784507751\n",
      "Validation loss: 1.5074950456619263\n",
      "mse 1.507495285257246\n",
      "New best model found at epoch 282 with validation loss 1.5074950456619263\n",
      "Starting Epoch 283\n",
      "1.6195667697035747\n",
      "Validation loss: 1.5074158906936646\n",
      "mse 1.5074158741606918\n",
      "New best model found at epoch 283 with validation loss 1.5074158906936646\n",
      "Starting Epoch 284\n",
      "1.6194670304008152\n",
      "Validation loss: 1.5069055557250977\n",
      "mse 1.5069055359773644\n",
      "New best model found at epoch 284 with validation loss 1.5069055557250977\n",
      "Starting Epoch 285\n",
      "1.6192934461261914\n",
      "Validation loss: 1.5070158243179321\n",
      "mse 1.5070159359122544\n",
      "Starting Epoch 286\n",
      "1.6191458520681963\n",
      "Validation loss: 1.5069643259048462\n",
      "mse 1.5069642176672464\n",
      "Starting Epoch 287\n",
      "1.6190270055895266\n",
      "Validation loss: 1.5067285299301147\n",
      "mse 1.506728518175571\n",
      "New best model found at epoch 287 with validation loss 1.5067285299301147\n",
      "Starting Epoch 288\n",
      "1.618866301101187\n",
      "Validation loss: 1.5066895484924316\n",
      "mse 1.5066893704012974\n",
      "New best model found at epoch 288 with validation loss 1.5066895484924316\n",
      "Starting Epoch 289\n",
      "1.6187250510506008\n",
      "Validation loss: 1.5066176652908325\n",
      "mse 1.5066176809416363\n",
      "New best model found at epoch 289 with validation loss 1.5066176652908325\n",
      "Starting Epoch 290\n",
      "1.6186198540355847\n",
      "Validation loss: 1.506341576576233\n",
      "mse 1.5063415484096412\n",
      "New best model found at epoch 290 with validation loss 1.506341576576233\n",
      "Starting Epoch 291\n",
      "1.6184839347134465\n",
      "Validation loss: 1.5062028169631958\n",
      "mse 1.50620291668757\n",
      "New best model found at epoch 291 with validation loss 1.5062028169631958\n",
      "Starting Epoch 292\n",
      "1.6183056986850242\n",
      "Validation loss: 1.5060902833938599\n",
      "mse 1.5060901423818307\n",
      "New best model found at epoch 292 with validation loss 1.5060902833938599\n",
      "Starting Epoch 293\n",
      "1.6181796063547549\n",
      "Validation loss: 1.5060545206069946\n",
      "mse 1.5060544159783147\n",
      "New best model found at epoch 293 with validation loss 1.5060545206069946\n",
      "Starting Epoch 294\n",
      "1.6180460608523826\n",
      "Validation loss: 1.5059787034988403\n",
      "mse 1.505978627171683\n",
      "New best model found at epoch 294 with validation loss 1.5059787034988403\n",
      "Starting Epoch 295\n",
      "1.6179677662642107\n",
      "Validation loss: 1.505566954612732\n",
      "mse 1.5055668867664576\n",
      "New best model found at epoch 295 with validation loss 1.505566954612732\n",
      "Starting Epoch 296\n",
      "1.6177913183751313\n",
      "Validation loss: 1.5056403875350952\n",
      "mse 1.5056403573591168\n",
      "Starting Epoch 297\n",
      "1.617651667283929\n",
      "Validation loss: 1.5055795907974243\n",
      "mse 1.5055795098791511\n",
      "Starting Epoch 298\n",
      "1.6175194149431975\n",
      "Validation loss: 1.505488395690918\n",
      "mse 1.505488426590334\n",
      "New best model found at epoch 298 with validation loss 1.505488395690918\n",
      "Starting Epoch 299\n",
      "1.6174423539120217\n",
      "Validation loss: 1.505070686340332\n",
      "mse 1.5050706817567994\n",
      "New best model found at epoch 299 with validation loss 1.505070686340332\n",
      "Starting Epoch 300\n",
      "1.6172693242197451\n",
      "Validation loss: 1.505139946937561\n",
      "mse 1.5051400852467012\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-5-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d8c11e",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 2\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 10 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "84554db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "7a63c91c-6491-4b5a-ba8e-595a47b9548e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.504763416621996\n",
      "Validation loss: 2.693621873855591\n",
      "mse 2.6936219221685813\n",
      "New best model found at epoch 1 with validation loss 2.693621873855591\n",
      "Starting Epoch 2\n",
      "2.911408968593763\n",
      "Validation loss: 2.617635726928711\n",
      "mse 2.617635799763673\n",
      "New best model found at epoch 2 with validation loss 2.617635726928711\n",
      "Starting Epoch 3\n",
      "2.852804018103558\n",
      "Validation loss: 2.578300952911377\n",
      "mse 2.578301096322479\n",
      "New best model found at epoch 3 with validation loss 2.578300952911377\n",
      "Starting Epoch 4\n",
      "2.806778643442237\n",
      "Validation loss: 2.5441510677337646\n",
      "mse 2.544151075254131\n",
      "New best model found at epoch 4 with validation loss 2.5441510677337646\n",
      "Starting Epoch 5\n",
      "2.7659587549126665\n",
      "Validation loss: 2.513857126235962\n",
      "mse 2.5138572036646343\n",
      "New best model found at epoch 5 with validation loss 2.513857126235962\n",
      "Starting Epoch 6\n",
      "2.7293992509012637\n",
      "Validation loss: 2.4840869903564453\n",
      "mse 2.4840867775887183\n",
      "New best model found at epoch 6 with validation loss 2.4840869903564453\n",
      "Starting Epoch 7\n",
      "2.6951125290082847\n",
      "Validation loss: 2.4570505619049072\n",
      "mse 2.45705039168655\n",
      "New best model found at epoch 7 with validation loss 2.4570505619049072\n",
      "Starting Epoch 8\n",
      "2.663335416627967\n",
      "Validation loss: 2.4304513931274414\n",
      "mse 2.43045127448608\n",
      "New best model found at epoch 8 with validation loss 2.4304513931274414\n",
      "Starting Epoch 9\n",
      "2.633350475974705\n",
      "Validation loss: 2.4053311347961426\n",
      "mse 2.405331139267988\n",
      "New best model found at epoch 9 with validation loss 2.4053311347961426\n",
      "Starting Epoch 10\n",
      "2.6048778606497724\n",
      "Validation loss: 2.381131410598755\n",
      "mse 2.3811314669141335\n",
      "New best model found at epoch 10 with validation loss 2.381131410598755\n",
      "Starting Epoch 11\n",
      "2.577848735062972\n",
      "Validation loss: 2.3578431606292725\n",
      "mse 2.3578429579452895\n",
      "New best model found at epoch 11 with validation loss 2.3578431606292725\n",
      "Starting Epoch 12\n",
      "2.552102591680444\n",
      "Validation loss: 2.3355391025543213\n",
      "mse 2.3355390571672388\n",
      "New best model found at epoch 12 with validation loss 2.3355391025543213\n",
      "Starting Epoch 13\n",
      "2.5271668589633443\n",
      "Validation loss: 2.314918279647827\n",
      "mse 2.314918613275976\n",
      "New best model found at epoch 13 with validation loss 2.314918279647827\n",
      "Starting Epoch 14\n",
      "2.5036029867503955\n",
      "Validation loss: 2.2951009273529053\n",
      "mse 2.2951007292649392\n",
      "New best model found at epoch 14 with validation loss 2.2951009273529053\n",
      "Starting Epoch 15\n",
      "2.480938092521999\n",
      "Validation loss: 2.2764697074890137\n",
      "mse 2.2764698416534674\n",
      "New best model found at epoch 15 with validation loss 2.2764697074890137\n",
      "Starting Epoch 16\n",
      "2.4592934224916543\n",
      "Validation loss: 2.2587289810180664\n",
      "mse 2.258728989283978\n",
      "New best model found at epoch 16 with validation loss 2.2587289810180664\n",
      "Starting Epoch 17\n",
      "2.4385615639064624\n",
      "Validation loss: 2.2409236431121826\n",
      "mse 2.240923537647345\n",
      "New best model found at epoch 17 with validation loss 2.2409236431121826\n",
      "Starting Epoch 18\n",
      "2.4184055224708887\n",
      "Validation loss: 2.2244839668273926\n",
      "mse 2.2244838470768253\n",
      "New best model found at epoch 18 with validation loss 2.2244839668273926\n",
      "Starting Epoch 19\n",
      "2.399310853170312\n",
      "Validation loss: 2.208407163619995\n",
      "mse 2.2084070828648645\n",
      "New best model found at epoch 19 with validation loss 2.208407163619995\n",
      "Starting Epoch 20\n",
      "2.3808322471121084\n",
      "Validation loss: 2.194582223892212\n",
      "mse 2.194582207119752\n",
      "New best model found at epoch 20 with validation loss 2.194582223892212\n",
      "Starting Epoch 21\n",
      "2.36285980888035\n",
      "Validation loss: 2.1793837547302246\n",
      "mse 2.179383768393267\n",
      "New best model found at epoch 21 with validation loss 2.1793837547302246\n",
      "Starting Epoch 22\n",
      "2.3456379434336787\n",
      "Validation loss: 2.1632280349731445\n",
      "mse 2.163228158772673\n",
      "New best model found at epoch 22 with validation loss 2.1632280349731445\n",
      "Starting Epoch 23\n",
      "2.3289734436118086\n",
      "Validation loss: 2.1484110355377197\n",
      "mse 2.14841112500903\n",
      "New best model found at epoch 23 with validation loss 2.1484110355377197\n",
      "Starting Epoch 24\n",
      "2.312567519104999\n",
      "Validation loss: 2.133899450302124\n",
      "mse 2.133899302052695\n",
      "New best model found at epoch 24 with validation loss 2.133899450302124\n",
      "Starting Epoch 25\n",
      "2.2966902256011963\n",
      "Validation loss: 2.1199047565460205\n",
      "mse 2.119904912066226\n",
      "New best model found at epoch 25 with validation loss 2.1199047565460205\n",
      "Starting Epoch 26\n",
      "2.2813129580539204\n",
      "Validation loss: 2.107480525970459\n",
      "mse 2.107480557099028\n",
      "New best model found at epoch 26 with validation loss 2.107480525970459\n",
      "Starting Epoch 27\n",
      "2.266450607258341\n",
      "Validation loss: 2.09328293800354\n",
      "mse 2.0932829393292858\n",
      "New best model found at epoch 27 with validation loss 2.09328293800354\n",
      "Starting Epoch 28\n",
      "2.2520183013833086\n",
      "Validation loss: 2.0810999870300293\n",
      "mse 2.0810999417127145\n",
      "New best model found at epoch 28 with validation loss 2.0810999870300293\n",
      "Starting Epoch 29\n",
      "2.2381845816321997\n",
      "Validation loss: 2.069685697555542\n",
      "mse 2.069685738058115\n",
      "New best model found at epoch 29 with validation loss 2.069685697555542\n",
      "Starting Epoch 30\n",
      "2.2246996008831523\n",
      "Validation loss: 2.057832717895508\n",
      "mse 2.057832866885596\n",
      "New best model found at epoch 30 with validation loss 2.057832717895508\n",
      "Starting Epoch 31\n",
      "2.211601221043131\n",
      "Validation loss: 2.0460262298583984\n",
      "mse 2.046026285222997\n",
      "New best model found at epoch 31 with validation loss 2.0460262298583984\n",
      "Starting Epoch 32\n",
      "2.1989999128424604\n",
      "Validation loss: 2.034510374069214\n",
      "mse 2.0345103412923247\n",
      "New best model found at epoch 32 with validation loss 2.034510374069214\n",
      "Starting Epoch 33\n",
      "2.186794146247532\n",
      "Validation loss: 2.0231025218963623\n",
      "mse 2.023102234686422\n",
      "New best model found at epoch 33 with validation loss 2.0231025218963623\n",
      "Starting Epoch 34\n",
      "2.1748311104981797\n",
      "Validation loss: 2.0122947692871094\n",
      "mse 2.0122946546897595\n",
      "New best model found at epoch 34 with validation loss 2.0122947692871094\n",
      "Starting Epoch 35\n",
      "2.163281870924908\n",
      "Validation loss: 2.001842498779297\n",
      "mse 2.0018424251696727\n",
      "New best model found at epoch 35 with validation loss 2.001842498779297\n",
      "Starting Epoch 36\n",
      "2.152059466942497\n",
      "Validation loss: 1.9913994073867798\n",
      "mse 1.9913993909026326\n",
      "New best model found at epoch 36 with validation loss 1.9913994073867798\n",
      "Starting Epoch 37\n",
      "2.14110411250073\n",
      "Validation loss: 1.980715036392212\n",
      "mse 1.9807151286121631\n",
      "New best model found at epoch 37 with validation loss 1.980715036392212\n",
      "Starting Epoch 38\n",
      "2.130512538163558\n",
      "Validation loss: 1.970823049545288\n",
      "mse 1.9708230080872076\n",
      "New best model found at epoch 38 with validation loss 1.970823049545288\n",
      "Starting Epoch 39\n",
      "2.120230177174444\n",
      "Validation loss: 1.9614492654800415\n",
      "mse 1.9614492899572473\n",
      "New best model found at epoch 39 with validation loss 1.9614492654800415\n",
      "Starting Epoch 40\n",
      "2.1101693070453145\n",
      "Validation loss: 1.9519883394241333\n",
      "mse 1.9519884969839822\n",
      "New best model found at epoch 40 with validation loss 1.9519883394241333\n",
      "Starting Epoch 41\n",
      "2.1004997025365415\n",
      "Validation loss: 1.9435395002365112\n",
      "mse 1.9435394162728084\n",
      "New best model found at epoch 41 with validation loss 1.9435395002365112\n",
      "Starting Epoch 42\n",
      "2.0908162179200547\n",
      "Validation loss: 1.9344860315322876\n",
      "mse 1.9344861351233333\n",
      "New best model found at epoch 42 with validation loss 1.9344860315322876\n",
      "Starting Epoch 43\n",
      "2.081569256989852\n",
      "Validation loss: 1.9260631799697876\n",
      "mse 1.9260630861607564\n",
      "New best model found at epoch 43 with validation loss 1.9260631799697876\n",
      "Starting Epoch 44\n",
      "2.0724945431170254\n",
      "Validation loss: 1.917924165725708\n",
      "mse 1.9179240680360647\n",
      "New best model found at epoch 44 with validation loss 1.917924165725708\n",
      "Starting Epoch 45\n",
      "2.06373363474141\n",
      "Validation loss: 1.9102920293807983\n",
      "mse 1.9102919746995068\n",
      "New best model found at epoch 45 with validation loss 1.9102920293807983\n",
      "Starting Epoch 46\n",
      "2.055171354957249\n",
      "Validation loss: 1.9032206535339355\n",
      "mse 1.9032205729979246\n",
      "New best model found at epoch 46 with validation loss 1.9032206535339355\n",
      "Starting Epoch 47\n",
      "2.0469447581664375\n",
      "Validation loss: 1.8957767486572266\n",
      "mse 1.8957766782148064\n",
      "New best model found at epoch 47 with validation loss 1.8957767486572266\n",
      "Starting Epoch 48\n",
      "2.0388691684474116\n",
      "Validation loss: 1.8887286186218262\n",
      "mse 1.8887286793788163\n",
      "New best model found at epoch 48 with validation loss 1.8887286186218262\n",
      "Starting Epoch 49\n",
      "2.0311130492583565\n",
      "Validation loss: 1.882152795791626\n",
      "mse 1.8821526840166065\n",
      "New best model found at epoch 49 with validation loss 1.882152795791626\n",
      "Starting Epoch 50\n",
      "2.0235970123954443\n",
      "Validation loss: 1.8756332397460938\n",
      "mse 1.8756332892560168\n",
      "New best model found at epoch 50 with validation loss 1.8756332397460938\n",
      "Starting Epoch 51\n",
      "2.0162352271701978\n",
      "Validation loss: 1.8695640563964844\n",
      "mse 1.8695640235017794\n",
      "New best model found at epoch 51 with validation loss 1.8695640563964844\n",
      "Starting Epoch 52\n",
      "2.00921544821366\n",
      "Validation loss: 1.863223671913147\n",
      "mse 1.8632236292645916\n",
      "New best model found at epoch 52 with validation loss 1.863223671913147\n",
      "Starting Epoch 53\n",
      "2.0024392034696494\n",
      "Validation loss: 1.8578354120254517\n",
      "mse 1.8578353495578162\n",
      "New best model found at epoch 53 with validation loss 1.8578354120254517\n",
      "Starting Epoch 54\n",
      "1.9956681417382283\n",
      "Validation loss: 1.8518198728561401\n",
      "mse 1.851819945951608\n",
      "New best model found at epoch 54 with validation loss 1.8518198728561401\n",
      "Starting Epoch 55\n",
      "1.9891229816105054\n",
      "Validation loss: 1.8454440832138062\n",
      "mse 1.8454440579643145\n",
      "New best model found at epoch 55 with validation loss 1.8454440832138062\n",
      "Starting Epoch 56\n",
      "1.9828513083250627\n",
      "Validation loss: 1.840273380279541\n",
      "mse 1.8402732727073983\n",
      "New best model found at epoch 56 with validation loss 1.840273380279541\n",
      "Starting Epoch 57\n",
      "1.9765837503516155\n",
      "Validation loss: 1.8341578245162964\n",
      "mse 1.834157697426034\n",
      "New best model found at epoch 57 with validation loss 1.8341578245162964\n",
      "Starting Epoch 58\n",
      "1.970578468364218\n",
      "Validation loss: 1.8293143510818481\n",
      "mse 1.8293142475870565\n",
      "New best model found at epoch 58 with validation loss 1.8293143510818481\n",
      "Starting Epoch 59\n",
      "1.9645974739738132\n",
      "Validation loss: 1.823918104171753\n",
      "mse 1.8239179864307717\n",
      "New best model found at epoch 59 with validation loss 1.823918104171753\n",
      "Starting Epoch 60\n",
      "1.958965767984805\n",
      "Validation loss: 1.8188025951385498\n",
      "mse 1.8188026954949834\n",
      "New best model found at epoch 60 with validation loss 1.8188025951385498\n",
      "Starting Epoch 61\n",
      "1.953521350155706\n",
      "Validation loss: 1.8144844770431519\n",
      "mse 1.8144846117551507\n",
      "New best model found at epoch 61 with validation loss 1.8144844770431519\n",
      "Starting Epoch 62\n",
      "1.947992583979731\n",
      "Validation loss: 1.8086885213851929\n",
      "mse 1.808688388599385\n",
      "New best model found at epoch 62 with validation loss 1.8086885213851929\n",
      "Starting Epoch 63\n",
      "1.9428257423898447\n",
      "Validation loss: 1.8042848110198975\n",
      "mse 1.8042848452663456\n",
      "New best model found at epoch 63 with validation loss 1.8042848110198975\n",
      "Starting Epoch 64\n",
      "1.9375346277071082\n",
      "Validation loss: 1.7994824647903442\n",
      "mse 1.799482450681034\n",
      "New best model found at epoch 64 with validation loss 1.7994824647903442\n",
      "Starting Epoch 65\n",
      "1.9325347620507944\n",
      "Validation loss: 1.7957804203033447\n",
      "mse 1.795780273099436\n",
      "New best model found at epoch 65 with validation loss 1.7957804203033447\n",
      "Starting Epoch 66\n",
      "1.9275485432666282\n",
      "Validation loss: 1.7912518978118896\n",
      "mse 1.7912519381002587\n",
      "New best model found at epoch 66 with validation loss 1.7912518978118896\n",
      "Starting Epoch 67\n",
      "1.92301272827646\n",
      "Validation loss: 1.7874853610992432\n",
      "mse 1.7874854186561173\n",
      "New best model found at epoch 67 with validation loss 1.7874853610992432\n",
      "Starting Epoch 68\n",
      "1.9182773880336597\n",
      "Validation loss: 1.7832273244857788\n",
      "mse 1.7832273223932618\n",
      "New best model found at epoch 68 with validation loss 1.7832273244857788\n",
      "Starting Epoch 69\n",
      "1.913930286531863\n",
      "Validation loss: 1.7795627117156982\n",
      "mse 1.7795626694996345\n",
      "New best model found at epoch 69 with validation loss 1.7795627117156982\n",
      "Starting Epoch 70\n",
      "1.909575394962145\n",
      "Validation loss: 1.7758195400238037\n",
      "mse 1.7758196103920256\n",
      "New best model found at epoch 70 with validation loss 1.7758195400238037\n",
      "Starting Epoch 71\n",
      "1.9052068357882292\n",
      "Validation loss: 1.7716548442840576\n",
      "mse 1.771654885050235\n",
      "New best model found at epoch 71 with validation loss 1.7716548442840576\n",
      "Starting Epoch 72\n",
      "1.9012110492457515\n",
      "Validation loss: 1.7682942152023315\n",
      "mse 1.768294230808063\n",
      "New best model found at epoch 72 with validation loss 1.7682942152023315\n",
      "Starting Epoch 73\n",
      "1.897181661232658\n",
      "Validation loss: 1.7650582790374756\n",
      "mse 1.7650583182965074\n",
      "New best model found at epoch 73 with validation loss 1.7650582790374756\n",
      "Starting Epoch 74\n",
      "1.8930840233097905\n",
      "Validation loss: 1.7612336874008179\n",
      "mse 1.7612335612427974\n",
      "New best model found at epoch 74 with validation loss 1.7612336874008179\n",
      "Starting Epoch 75\n",
      "1.8895689508189326\n",
      "Validation loss: 1.7578859329223633\n",
      "mse 1.757885872899054\n",
      "New best model found at epoch 75 with validation loss 1.7578859329223633\n",
      "Starting Epoch 76\n",
      "1.8857853049817292\n",
      "Validation loss: 1.754585862159729\n",
      "mse 1.7545861393685411\n",
      "New best model found at epoch 76 with validation loss 1.754585862159729\n",
      "Starting Epoch 77\n",
      "1.8821395272793977\n",
      "Validation loss: 1.7512891292572021\n",
      "mse 1.7512890418993465\n",
      "New best model found at epoch 77 with validation loss 1.7512891292572021\n",
      "Starting Epoch 78\n",
      "1.878710404686306\n",
      "Validation loss: 1.7485345602035522\n",
      "mse 1.748534521930083\n",
      "New best model found at epoch 78 with validation loss 1.7485345602035522\n",
      "Starting Epoch 79\n",
      "1.875215488931407\n",
      "Validation loss: 1.745082139968872\n",
      "mse 1.7450822995578354\n",
      "New best model found at epoch 79 with validation loss 1.745082139968872\n",
      "Starting Epoch 80\n",
      "1.8718243992846946\n",
      "Validation loss: 1.7421159744262695\n",
      "mse 1.7421159438989944\n",
      "New best model found at epoch 80 with validation loss 1.7421159744262695\n",
      "Starting Epoch 81\n",
      "1.8685257486675098\n",
      "Validation loss: 1.7411692142486572\n",
      "mse 1.7411691215384353\n",
      "New best model found at epoch 81 with validation loss 1.7411692142486572\n",
      "Starting Epoch 82\n",
      "1.8654459766719653\n",
      "Validation loss: 1.7366942167282104\n",
      "mse 1.7366944499135293\n",
      "New best model found at epoch 82 with validation loss 1.7366942167282104\n",
      "Starting Epoch 83\n",
      "1.8622793322024138\n",
      "Validation loss: 1.7336376905441284\n",
      "mse 1.7336375961599293\n",
      "New best model found at epoch 83 with validation loss 1.7336376905441284\n",
      "Starting Epoch 84\n",
      "1.859262414600538\n",
      "Validation loss: 1.730895757675171\n",
      "mse 1.7308957783674201\n",
      "New best model found at epoch 84 with validation loss 1.730895757675171\n",
      "Starting Epoch 85\n",
      "1.8563731235006582\n",
      "Validation loss: 1.728259801864624\n",
      "mse 1.7282598073628257\n",
      "New best model found at epoch 85 with validation loss 1.728259801864624\n",
      "Starting Epoch 86\n",
      "1.8534678013428398\n",
      "Validation loss: 1.7258598804473877\n",
      "mse 1.7258598215232663\n",
      "New best model found at epoch 86 with validation loss 1.7258598804473877\n",
      "Starting Epoch 87\n",
      "1.850633258404939\n",
      "Validation loss: 1.7233494520187378\n",
      "mse 1.7233494834914251\n",
      "New best model found at epoch 87 with validation loss 1.7233494520187378\n",
      "Starting Epoch 88\n",
      "1.8478870547336081\n",
      "Validation loss: 1.7206517457962036\n",
      "mse 1.7206518770517305\n",
      "New best model found at epoch 88 with validation loss 1.7206517457962036\n",
      "Starting Epoch 89\n",
      "1.8450555905051853\n",
      "Validation loss: 1.7197542190551758\n",
      "mse 1.7197539722552542\n",
      "New best model found at epoch 89 with validation loss 1.7197542190551758\n",
      "Starting Epoch 90\n",
      "1.8425219629121863\n",
      "Validation loss: 1.7161829471588135\n",
      "mse 1.7161828695541599\n",
      "New best model found at epoch 90 with validation loss 1.7161829471588135\n",
      "Starting Epoch 91\n",
      "1.8398589362268862\n",
      "Validation loss: 1.7136439085006714\n",
      "mse 1.7136437541642144\n",
      "New best model found at epoch 91 with validation loss 1.7136439085006714\n",
      "Starting Epoch 92\n",
      "1.837157156156457\n",
      "Validation loss: 1.7108546495437622\n",
      "mse 1.710854555662462\n",
      "New best model found at epoch 92 with validation loss 1.7108546495437622\n",
      "Starting Epoch 93\n",
      "1.834705985110739\n",
      "Validation loss: 1.7085822820663452\n",
      "mse 1.7085822677848441\n",
      "New best model found at epoch 93 with validation loss 1.7085822820663452\n",
      "Starting Epoch 94\n",
      "1.8321974329326465\n",
      "Validation loss: 1.7063591480255127\n",
      "mse 1.706359169416233\n",
      "New best model found at epoch 94 with validation loss 1.7063591480255127\n",
      "Starting Epoch 95\n",
      "1.8297224044799805\n",
      "Validation loss: 1.7042834758758545\n",
      "mse 1.7042834737569317\n",
      "New best model found at epoch 95 with validation loss 1.7042834758758545\n",
      "Starting Epoch 96\n",
      "1.827253906623177\n",
      "Validation loss: 1.7022054195404053\n",
      "mse 1.702205327415979\n",
      "New best model found at epoch 96 with validation loss 1.7022054195404053\n",
      "Starting Epoch 97\n",
      "1.824738481770391\n",
      "Validation loss: 1.7000224590301514\n",
      "mse 1.700022359117661\n",
      "New best model found at epoch 97 with validation loss 1.7000224590301514\n",
      "Starting Epoch 98\n",
      "1.8224062971446826\n",
      "Validation loss: 1.6982511281967163\n",
      "mse 1.6982510308410668\n",
      "New best model found at epoch 98 with validation loss 1.6982511281967163\n",
      "Starting Epoch 99\n",
      "1.8200762012730474\n",
      "Validation loss: 1.6970207691192627\n",
      "mse 1.6970208411693515\n",
      "New best model found at epoch 99 with validation loss 1.6970207691192627\n",
      "Starting Epoch 100\n",
      "1.8179505389669668\n",
      "Validation loss: 1.6942790746688843\n",
      "mse 1.6942789600762427\n",
      "New best model found at epoch 100 with validation loss 1.6942790746688843\n",
      "Starting Epoch 101\n",
      "1.8157609856646995\n",
      "Validation loss: 1.693274736404419\n",
      "mse 1.6932746200533568\n",
      "New best model found at epoch 101 with validation loss 1.693274736404419\n",
      "Starting Epoch 102\n",
      "1.8137224653492803\n",
      "Validation loss: 1.6913247108459473\n",
      "mse 1.6913246808096514\n",
      "New best model found at epoch 102 with validation loss 1.6913247108459473\n",
      "Starting Epoch 103\n",
      "1.8116669706676318\n",
      "Validation loss: 1.6890530586242676\n",
      "mse 1.6890530453892296\n",
      "New best model found at epoch 103 with validation loss 1.6890530586242676\n",
      "Starting Epoch 104\n",
      "1.8096434655396834\n",
      "Validation loss: 1.6871705055236816\n",
      "mse 1.6871704571755852\n",
      "New best model found at epoch 104 with validation loss 1.6871705055236816\n",
      "Starting Epoch 105\n",
      "1.8076143420260886\n",
      "Validation loss: 1.6852933168411255\n",
      "mse 1.6852935313613722\n",
      "New best model found at epoch 105 with validation loss 1.6852933168411255\n",
      "Starting Epoch 106\n",
      "1.805692600167316\n",
      "Validation loss: 1.6835047006607056\n",
      "mse 1.6835045904327999\n",
      "New best model found at epoch 106 with validation loss 1.6835047006607056\n",
      "Starting Epoch 107\n",
      "1.8038453381994497\n",
      "Validation loss: 1.681780457496643\n",
      "mse 1.6817805731044293\n",
      "New best model found at epoch 107 with validation loss 1.681780457496643\n",
      "Starting Epoch 108\n",
      "1.8020384415336277\n",
      "Validation loss: 1.680120587348938\n",
      "mse 1.6801205323335797\n",
      "New best model found at epoch 108 with validation loss 1.680120587348938\n",
      "Starting Epoch 109\n",
      "1.8002552416013635\n",
      "Validation loss: 1.6784117221832275\n",
      "mse 1.6784118014395897\n",
      "New best model found at epoch 109 with validation loss 1.6784117221832275\n",
      "Starting Epoch 110\n",
      "1.7985215601713762\n",
      "Validation loss: 1.676820158958435\n",
      "mse 1.67682014720478\n",
      "New best model found at epoch 110 with validation loss 1.676820158958435\n",
      "Starting Epoch 111\n",
      "1.7968119797499285\n",
      "Validation loss: 1.6752815246582031\n",
      "mse 1.6752815364039229\n",
      "New best model found at epoch 111 with validation loss 1.6752815246582031\n",
      "Starting Epoch 112\n",
      "1.7951009118038674\n",
      "Validation loss: 1.6739157438278198\n",
      "mse 1.673915789628288\n",
      "New best model found at epoch 112 with validation loss 1.6739157438278198\n",
      "Starting Epoch 113\n",
      "1.7934769288353298\n",
      "Validation loss: 1.6726105213165283\n",
      "mse 1.672610510947647\n",
      "New best model found at epoch 113 with validation loss 1.6726105213165283\n",
      "Starting Epoch 114\n",
      "1.7918790786162666\n",
      "Validation loss: 1.6711549758911133\n",
      "mse 1.6711549980881415\n",
      "New best model found at epoch 114 with validation loss 1.6711549758911133\n",
      "Starting Epoch 115\n",
      "1.7903965245122495\n",
      "Validation loss: 1.6695197820663452\n",
      "mse 1.6695196920200401\n",
      "New best model found at epoch 115 with validation loss 1.6695197820663452\n",
      "Starting Epoch 116\n",
      "1.7888604817183122\n",
      "Validation loss: 1.6679589748382568\n",
      "mse 1.667958973604819\n",
      "New best model found at epoch 116 with validation loss 1.6679589748382568\n",
      "Starting Epoch 117\n",
      "1.7872690947159477\n",
      "Validation loss: 1.6664071083068848\n",
      "mse 1.6664072420219533\n",
      "New best model found at epoch 117 with validation loss 1.6664071083068848\n",
      "Starting Epoch 118\n",
      "1.7857634191927703\n",
      "Validation loss: 1.6650631427764893\n",
      "mse 1.665063138170639\n",
      "New best model found at epoch 118 with validation loss 1.6650631427764893\n",
      "Starting Epoch 119\n",
      "1.7842553543007893\n",
      "Validation loss: 1.6636886596679688\n",
      "mse 1.6636886425669268\n",
      "New best model found at epoch 119 with validation loss 1.6636886596679688\n",
      "Starting Epoch 120\n",
      "1.782778983530791\n",
      "Validation loss: 1.6623622179031372\n",
      "mse 1.662362199619956\n",
      "New best model found at epoch 120 with validation loss 1.6623622179031372\n",
      "Starting Epoch 121\n",
      "1.7813107500905576\n",
      "Validation loss: 1.6609723567962646\n",
      "mse 1.660972510435852\n",
      "New best model found at epoch 121 with validation loss 1.6609723567962646\n",
      "Starting Epoch 122\n",
      "1.779861128848532\n",
      "Validation loss: 1.659654140472412\n",
      "mse 1.6596541386175616\n",
      "New best model found at epoch 122 with validation loss 1.659654140472412\n",
      "Starting Epoch 123\n",
      "1.778427885926288\n",
      "Validation loss: 1.6583584547042847\n",
      "mse 1.6583585931258222\n",
      "New best model found at epoch 123 with validation loss 1.6583584547042847\n",
      "Starting Epoch 124\n",
      "1.7770138408826746\n",
      "Validation loss: 1.6570855379104614\n",
      "mse 1.6570854253041813\n",
      "New best model found at epoch 124 with validation loss 1.6570855379104614\n",
      "Starting Epoch 125\n",
      "1.7756126082461814\n",
      "Validation loss: 1.6558303833007812\n",
      "mse 1.6558303887431087\n",
      "New best model found at epoch 125 with validation loss 1.6558303833007812\n",
      "Starting Epoch 126\n",
      "1.7742309155671492\n",
      "Validation loss: 1.6546015739440918\n",
      "mse 1.6546017387926166\n",
      "New best model found at epoch 126 with validation loss 1.6546015739440918\n",
      "Starting Epoch 127\n",
      "1.7728044468423594\n",
      "Validation loss: 1.6534571647644043\n",
      "mse 1.6534573106848895\n",
      "New best model found at epoch 127 with validation loss 1.6534571647644043\n",
      "Starting Epoch 128\n",
      "1.771557154862777\n",
      "Validation loss: 1.6522488594055176\n",
      "mse 1.6522488958758097\n",
      "New best model found at epoch 128 with validation loss 1.6522488594055176\n",
      "Starting Epoch 129\n",
      "1.7701769548913706\n",
      "Validation loss: 1.6511205434799194\n",
      "mse 1.6511205700779124\n",
      "New best model found at epoch 129 with validation loss 1.6511205434799194\n",
      "Starting Epoch 130\n",
      "1.7689325913139011\n",
      "Validation loss: 1.6498888731002808\n",
      "mse 1.6498889482078603\n",
      "New best model found at epoch 130 with validation loss 1.6498888731002808\n",
      "Starting Epoch 131\n",
      "1.7675907197205916\n",
      "Validation loss: 1.6487534046173096\n",
      "mse 1.648753371965405\n",
      "New best model found at epoch 131 with validation loss 1.6487534046173096\n",
      "Starting Epoch 132\n",
      "1.7663043167280115\n",
      "Validation loss: 1.6475660800933838\n",
      "mse 1.6475660453566643\n",
      "New best model found at epoch 132 with validation loss 1.6475660800933838\n",
      "Starting Epoch 133\n",
      "1.7650638455929963\n",
      "Validation loss: 1.6464128494262695\n",
      "mse 1.6464128429083917\n",
      "New best model found at epoch 133 with validation loss 1.6464128494262695\n",
      "Starting Epoch 134\n",
      "1.7638567167779673\n",
      "Validation loss: 1.6453063488006592\n",
      "mse 1.6453063830009251\n",
      "New best model found at epoch 134 with validation loss 1.6453063488006592\n",
      "Starting Epoch 135\n",
      "1.7626761664514956\n",
      "Validation loss: 1.6442455053329468\n",
      "mse 1.6442454025046829\n",
      "New best model found at epoch 135 with validation loss 1.6442455053329468\n",
      "Starting Epoch 136\n",
      "1.7614872559257175\n",
      "Validation loss: 1.643149971961975\n",
      "mse 1.6431499605633964\n",
      "New best model found at epoch 136 with validation loss 1.643149971961975\n",
      "Starting Epoch 137\n",
      "1.7603255303009697\n",
      "Validation loss: 1.6420419216156006\n",
      "mse 1.6420420131240674\n",
      "New best model found at epoch 137 with validation loss 1.6420419216156006\n",
      "Starting Epoch 138\n",
      "1.7591939076133396\n",
      "Validation loss: 1.641033411026001\n",
      "mse 1.6410333734685019\n",
      "New best model found at epoch 138 with validation loss 1.641033411026001\n",
      "Starting Epoch 139\n",
      "1.7580531058104143\n",
      "Validation loss: 1.640002727508545\n",
      "mse 1.6400026526218352\n",
      "New best model found at epoch 139 with validation loss 1.640002727508545\n",
      "Starting Epoch 140\n",
      "1.7569130037141882\n",
      "Validation loss: 1.639005184173584\n",
      "mse 1.6390051454230234\n",
      "New best model found at epoch 140 with validation loss 1.639005184173584\n",
      "Starting Epoch 141\n",
      "1.7558230939118757\n",
      "Validation loss: 1.638021469116211\n",
      "mse 1.638021618325105\n",
      "New best model found at epoch 141 with validation loss 1.638021469116211\n",
      "Starting Epoch 142\n",
      "1.7546942545020061\n",
      "Validation loss: 1.6370627880096436\n",
      "mse 1.637062835119405\n",
      "New best model found at epoch 142 with validation loss 1.6370627880096436\n",
      "Starting Epoch 143\n",
      "1.7535919624826182\n",
      "Validation loss: 1.6360498666763306\n",
      "mse 1.6360498063246163\n",
      "New best model found at epoch 143 with validation loss 1.6360498666763306\n",
      "Starting Epoch 144\n",
      "1.7525254798972087\n",
      "Validation loss: 1.635115146636963\n",
      "mse 1.6351152022290336\n",
      "New best model found at epoch 144 with validation loss 1.635115146636963\n",
      "Starting Epoch 145\n",
      "1.751440395479617\n",
      "Validation loss: 1.6342756748199463\n",
      "mse 1.6342756312455795\n",
      "New best model found at epoch 145 with validation loss 1.6342756748199463\n",
      "Starting Epoch 146\n",
      "1.7503847868546196\n",
      "Validation loss: 1.6334385871887207\n",
      "mse 1.633438600771197\n",
      "New best model found at epoch 146 with validation loss 1.6334385871887207\n",
      "Starting Epoch 147\n",
      "1.7493501901626587\n",
      "Validation loss: 1.6325546503067017\n",
      "mse 1.6325546784248437\n",
      "New best model found at epoch 147 with validation loss 1.6325546503067017\n",
      "Starting Epoch 148\n",
      "1.74831499742425\n",
      "Validation loss: 1.6316953897476196\n",
      "mse 1.6316955213050495\n",
      "New best model found at epoch 148 with validation loss 1.6316953897476196\n",
      "Starting Epoch 149\n",
      "1.747330209483271\n",
      "Validation loss: 1.630799651145935\n",
      "mse 1.63079955859997\n",
      "New best model found at epoch 149 with validation loss 1.630799651145935\n",
      "Starting Epoch 150\n",
      "1.746412728143775\n",
      "Validation loss: 1.6301915645599365\n",
      "mse 1.6301915667184994\n",
      "New best model found at epoch 150 with validation loss 1.6301915645599365\n",
      "Starting Epoch 151\n",
      "1.7454412709111753\n",
      "Validation loss: 1.6291967630386353\n",
      "mse 1.629196739143571\n",
      "New best model found at epoch 151 with validation loss 1.6291967630386353\n",
      "Starting Epoch 152\n",
      "1.7443637692410012\n",
      "Validation loss: 1.6283609867095947\n",
      "mse 1.628360876017794\n",
      "New best model found at epoch 152 with validation loss 1.6283609867095947\n",
      "Starting Epoch 153\n",
      "1.7435137240783027\n",
      "Validation loss: 1.627698302268982\n",
      "mse 1.6276980725476171\n",
      "New best model found at epoch 153 with validation loss 1.627698302268982\n",
      "Starting Epoch 154\n",
      "1.742466169854869\n",
      "Validation loss: 1.626813292503357\n",
      "mse 1.6268134255927\n",
      "New best model found at epoch 154 with validation loss 1.626813292503357\n",
      "Starting Epoch 155\n",
      "1.7416581019111301\n",
      "Validation loss: 1.626155138015747\n",
      "mse 1.626155101559214\n",
      "New best model found at epoch 155 with validation loss 1.626155138015747\n",
      "Starting Epoch 156\n",
      "1.7407436681830364\n",
      "Validation loss: 1.6256346702575684\n",
      "mse 1.6256346889299664\n",
      "New best model found at epoch 156 with validation loss 1.6256346702575684\n",
      "Starting Epoch 157\n",
      "1.7398274566816248\n",
      "Validation loss: 1.6249206066131592\n",
      "mse 1.6249205540497937\n",
      "New best model found at epoch 157 with validation loss 1.6249206066131592\n",
      "Starting Epoch 158\n",
      "1.738937471223914\n",
      "Validation loss: 1.6241779327392578\n",
      "mse 1.6241781682560619\n",
      "New best model found at epoch 158 with validation loss 1.6241779327392578\n",
      "Starting Epoch 159\n",
      "1.7380575045295383\n",
      "Validation loss: 1.6234309673309326\n",
      "mse 1.6234309747936824\n",
      "New best model found at epoch 159 with validation loss 1.6234309673309326\n",
      "Starting Epoch 160\n",
      "1.737191433491914\n",
      "Validation loss: 1.6226942539215088\n",
      "mse 1.6226942072008872\n",
      "New best model found at epoch 160 with validation loss 1.6226942539215088\n",
      "Starting Epoch 161\n",
      "1.736329990884532\n",
      "Validation loss: 1.6219581365585327\n",
      "mse 1.6219580627693317\n",
      "New best model found at epoch 161 with validation loss 1.6219581365585327\n",
      "Starting Epoch 162\n",
      "1.7354769654895947\n",
      "Validation loss: 1.6212279796600342\n",
      "mse 1.6212281023790809\n",
      "New best model found at epoch 162 with validation loss 1.6212279796600342\n",
      "Starting Epoch 163\n",
      "1.73452787813933\n",
      "Validation loss: 1.6203991174697876\n",
      "mse 1.6203991776876079\n",
      "New best model found at epoch 163 with validation loss 1.6203991174697876\n",
      "Starting Epoch 164\n",
      "1.733701379402824\n",
      "Validation loss: 1.619685173034668\n",
      "mse 1.619685315062887\n",
      "New best model found at epoch 164 with validation loss 1.619685173034668\n",
      "Starting Epoch 165\n",
      "1.7328721492186836\n",
      "Validation loss: 1.6189807653427124\n",
      "mse 1.6189807409140686\n",
      "New best model found at epoch 165 with validation loss 1.6189807653427124\n",
      "Starting Epoch 166\n",
      "1.73205842660821\n",
      "Validation loss: 1.6182726621627808\n",
      "mse 1.6182727575948026\n",
      "New best model found at epoch 166 with validation loss 1.6182726621627808\n",
      "Starting Epoch 167\n",
      "1.7313373918118684\n",
      "Validation loss: 1.6176317930221558\n",
      "mse 1.617631758230594\n",
      "New best model found at epoch 167 with validation loss 1.6176317930221558\n",
      "Starting Epoch 168\n",
      "1.730536937713623\n",
      "Validation loss: 1.6170077323913574\n",
      "mse 1.6170078767943399\n",
      "New best model found at epoch 168 with validation loss 1.6170077323913574\n",
      "Starting Epoch 169\n",
      "1.7296401365943577\n",
      "Validation loss: 1.6162792444229126\n",
      "mse 1.6162791510831844\n",
      "New best model found at epoch 169 with validation loss 1.6162792444229126\n",
      "Starting Epoch 170\n",
      "1.72885437115379\n",
      "Validation loss: 1.6155260801315308\n",
      "mse 1.6155260907267894\n",
      "New best model found at epoch 170 with validation loss 1.6155260801315308\n",
      "Starting Epoch 171\n",
      "1.7280791738758916\n",
      "Validation loss: 1.6148911714553833\n",
      "mse 1.614891228823691\n",
      "New best model found at epoch 171 with validation loss 1.6148911714553833\n",
      "Starting Epoch 172\n",
      "1.7272995554882546\n",
      "Validation loss: 1.6141616106033325\n",
      "mse 1.6141615347024443\n",
      "New best model found at epoch 172 with validation loss 1.6141616106033325\n",
      "Starting Epoch 173\n",
      "1.7266268989314204\n",
      "Validation loss: 1.6135097742080688\n",
      "mse 1.613509646569032\n",
      "New best model found at epoch 173 with validation loss 1.6135097742080688\n",
      "Starting Epoch 174\n",
      "1.725860041120778\n",
      "Validation loss: 1.612903356552124\n",
      "mse 1.6129034498386652\n",
      "New best model found at epoch 174 with validation loss 1.612903356552124\n",
      "Starting Epoch 175\n",
      "1.7251127284506094\n",
      "Validation loss: 1.6122770309448242\n",
      "mse 1.6122770269664395\n",
      "New best model found at epoch 175 with validation loss 1.6122770309448242\n",
      "Starting Epoch 176\n",
      "1.7243749317915544\n",
      "Validation loss: 1.6116269826889038\n",
      "mse 1.6116270002601862\n",
      "New best model found at epoch 176 with validation loss 1.6116269826889038\n",
      "Starting Epoch 177\n",
      "1.7236453864885413\n",
      "Validation loss: 1.6109776496887207\n",
      "mse 1.6109776570065508\n",
      "New best model found at epoch 177 with validation loss 1.6109776496887207\n",
      "Starting Epoch 178\n",
      "1.722922833069511\n",
      "Validation loss: 1.6102348566055298\n",
      "mse 1.6102346897239217\n",
      "New best model found at epoch 178 with validation loss 1.6102348566055298\n",
      "Starting Epoch 179\n",
      "1.7221117693444956\n",
      "Validation loss: 1.609612226486206\n",
      "mse 1.6096121194995088\n",
      "New best model found at epoch 179 with validation loss 1.609612226486206\n",
      "Starting Epoch 180\n",
      "1.7214034225629724\n",
      "Validation loss: 1.6089915037155151\n",
      "mse 1.608991652015932\n",
      "New best model found at epoch 180 with validation loss 1.6089915037155151\n",
      "Starting Epoch 181\n",
      "1.7207898471666419\n",
      "Validation loss: 1.6084321737289429\n",
      "mse 1.6084321180050858\n",
      "New best model found at epoch 181 with validation loss 1.6084321737289429\n",
      "Starting Epoch 182\n",
      "1.7200917057369067\n",
      "Validation loss: 1.607840895652771\n",
      "mse 1.6078411066324227\n",
      "New best model found at epoch 182 with validation loss 1.607840895652771\n",
      "Starting Epoch 183\n",
      "1.7194016187087349\n",
      "Validation loss: 1.6072449684143066\n",
      "mse 1.6072451363168838\n",
      "New best model found at epoch 183 with validation loss 1.6072449684143066\n",
      "Starting Epoch 184\n",
      "1.7187234733415686\n",
      "Validation loss: 1.6066654920578003\n",
      "mse 1.6066653877246486\n",
      "New best model found at epoch 184 with validation loss 1.6066654920578003\n",
      "Starting Epoch 185\n",
      "1.7180476706960928\n",
      "Validation loss: 1.6060763597488403\n",
      "mse 1.6060762761712244\n",
      "New best model found at epoch 185 with validation loss 1.6060763597488403\n",
      "Starting Epoch 186\n",
      "1.7173771028933318\n",
      "Validation loss: 1.6054933071136475\n",
      "mse 1.6054931873446117\n",
      "New best model found at epoch 186 with validation loss 1.6054933071136475\n",
      "Starting Epoch 187\n",
      "1.716694448305213\n",
      "Validation loss: 1.6048825979232788\n",
      "mse 1.604882721329979\n",
      "New best model found at epoch 187 with validation loss 1.6048825979232788\n",
      "Starting Epoch 188\n",
      "1.7160362471704897\n",
      "Validation loss: 1.6042832136154175\n",
      "mse 1.6042833239848118\n",
      "New best model found at epoch 188 with validation loss 1.6042832136154175\n",
      "Starting Epoch 189\n",
      "1.715390391971754\n",
      "Validation loss: 1.6036808490753174\n",
      "mse 1.6036808769054995\n",
      "New best model found at epoch 189 with validation loss 1.6036808490753174\n",
      "Starting Epoch 190\n",
      "1.7147397632184236\n",
      "Validation loss: 1.6032791137695312\n",
      "mse 1.6032790888810897\n",
      "New best model found at epoch 190 with validation loss 1.6032791137695312\n",
      "Starting Epoch 191\n",
      "1.714092518972314\n",
      "Validation loss: 1.6027123928070068\n",
      "mse 1.602712308819754\n",
      "New best model found at epoch 191 with validation loss 1.6027123928070068\n",
      "Starting Epoch 192\n",
      "1.7134555163590803\n",
      "Validation loss: 1.6021157503128052\n",
      "mse 1.602115761472046\n",
      "New best model found at epoch 192 with validation loss 1.6021157503128052\n",
      "Starting Epoch 193\n",
      "1.7128159999847412\n",
      "Validation loss: 1.6016249656677246\n",
      "mse 1.601624773818911\n",
      "New best model found at epoch 193 with validation loss 1.6016249656677246\n",
      "Starting Epoch 194\n",
      "1.7121989623360012\n",
      "Validation loss: 1.6010584831237793\n",
      "mse 1.6010586168437484\n",
      "New best model found at epoch 194 with validation loss 1.6010584831237793\n",
      "Starting Epoch 195\n",
      "1.7115731031998345\n",
      "Validation loss: 1.6005498170852661\n",
      "mse 1.600549931862348\n",
      "New best model found at epoch 195 with validation loss 1.6005498170852661\n",
      "Starting Epoch 196\n",
      "1.710968950520391\n",
      "Validation loss: 1.6001625061035156\n",
      "mse 1.6001625191089452\n",
      "New best model found at epoch 196 with validation loss 1.6001625061035156\n",
      "Starting Epoch 197\n",
      "1.7103509488313093\n",
      "Validation loss: 1.5995707511901855\n",
      "mse 1.599570710904874\n",
      "New best model found at epoch 197 with validation loss 1.5995707511901855\n",
      "Starting Epoch 198\n",
      "1.709739959758261\n",
      "Validation loss: 1.5990698337554932\n",
      "mse 1.5990698880245275\n",
      "New best model found at epoch 198 with validation loss 1.5990698337554932\n",
      "Starting Epoch 199\n",
      "1.7091453749200571\n",
      "Validation loss: 1.598508358001709\n",
      "mse 1.5985082642575752\n",
      "New best model found at epoch 199 with validation loss 1.598508358001709\n",
      "Starting Epoch 200\n",
      "1.7085350492726201\n",
      "Validation loss: 1.5979384183883667\n",
      "mse 1.5979383388300816\n",
      "New best model found at epoch 200 with validation loss 1.5979384183883667\n",
      "Starting Epoch 201\n",
      "1.7079740348069563\n",
      "Validation loss: 1.5975234508514404\n",
      "mse 1.5975234983106044\n",
      "New best model found at epoch 201 with validation loss 1.5975234508514404\n",
      "Starting Epoch 202\n",
      "1.7073598737302034\n",
      "Validation loss: 1.5970181226730347\n",
      "mse 1.5970180765660156\n",
      "New best model found at epoch 202 with validation loss 1.5970181226730347\n",
      "Starting Epoch 203\n",
      "1.7068102618922358\n",
      "Validation loss: 1.5965700149536133\n",
      "mse 1.5965698736727678\n",
      "New best model found at epoch 203 with validation loss 1.5965700149536133\n",
      "Starting Epoch 204\n",
      "1.7062339160753333\n",
      "Validation loss: 1.5961105823516846\n",
      "mse 1.5961105308346333\n",
      "New best model found at epoch 204 with validation loss 1.5961105823516846\n",
      "Starting Epoch 205\n",
      "1.7056639298148777\n",
      "Validation loss: 1.5956437587738037\n",
      "mse 1.595643787998404\n",
      "New best model found at epoch 205 with validation loss 1.5956437587738037\n",
      "Starting Epoch 206\n",
      "1.705095913099206\n",
      "Validation loss: 1.5951594114303589\n",
      "mse 1.5951594200148473\n",
      "New best model found at epoch 206 with validation loss 1.5951594114303589\n",
      "Starting Epoch 207\n",
      "1.7045341626457546\n",
      "Validation loss: 1.5947208404541016\n",
      "mse 1.5947206741520015\n",
      "New best model found at epoch 207 with validation loss 1.5947208404541016\n",
      "Starting Epoch 208\n",
      "1.7039811870326167\n",
      "Validation loss: 1.5942704677581787\n",
      "mse 1.5942705147534642\n",
      "New best model found at epoch 208 with validation loss 1.5942704677581787\n",
      "Starting Epoch 209\n",
      "1.7034310361613398\n",
      "Validation loss: 1.5938082933425903\n",
      "mse 1.593808191149613\n",
      "New best model found at epoch 209 with validation loss 1.5938082933425903\n",
      "Starting Epoch 210\n",
      "1.7028850835302602\n",
      "Validation loss: 1.5933425426483154\n",
      "mse 1.5933424224456896\n",
      "New best model found at epoch 210 with validation loss 1.5933425426483154\n",
      "Starting Epoch 211\n",
      "1.7023376278255298\n",
      "Validation loss: 1.5928430557250977\n",
      "mse 1.5928429692944104\n",
      "New best model found at epoch 211 with validation loss 1.5928430557250977\n",
      "Starting Epoch 212\n",
      "1.7017938054126243\n",
      "Validation loss: 1.5923656225204468\n",
      "mse 1.5923656143858058\n",
      "New best model found at epoch 212 with validation loss 1.5923656225204468\n",
      "Starting Epoch 213\n",
      "1.7012579544730808\n",
      "Validation loss: 1.591876745223999\n",
      "mse 1.591876672879231\n",
      "New best model found at epoch 213 with validation loss 1.591876745223999\n",
      "Starting Epoch 214\n",
      "1.7007285149201103\n",
      "Validation loss: 1.5913695096969604\n",
      "mse 1.5913694974056118\n",
      "New best model found at epoch 214 with validation loss 1.5913695096969604\n",
      "Starting Epoch 215\n",
      "1.7002007961273193\n",
      "Validation loss: 1.5908634662628174\n",
      "mse 1.5908632273642795\n",
      "New best model found at epoch 215 with validation loss 1.5908634662628174\n",
      "Starting Epoch 216\n",
      "1.6996683193289714\n",
      "Validation loss: 1.5903351306915283\n",
      "mse 1.5903351637763437\n",
      "New best model found at epoch 216 with validation loss 1.5903351306915283\n",
      "Starting Epoch 217\n",
      "1.6991468564323757\n",
      "Validation loss: 1.589792251586914\n",
      "mse 1.58979239343456\n",
      "New best model found at epoch 217 with validation loss 1.589792251586914\n",
      "Starting Epoch 218\n",
      "1.6984184565751448\n",
      "Validation loss: 1.5889623165130615\n",
      "mse 1.5889622242231858\n",
      "New best model found at epoch 218 with validation loss 1.5889623165130615\n",
      "Starting Epoch 219\n",
      "1.6978744164757107\n",
      "Validation loss: 1.588304042816162\n",
      "mse 1.5883040107524464\n",
      "New best model found at epoch 219 with validation loss 1.588304042816162\n",
      "Starting Epoch 220\n",
      "1.697341519853343\n",
      "Validation loss: 1.5877606868743896\n",
      "mse 1.5877606870461343\n",
      "New best model found at epoch 220 with validation loss 1.5877606868743896\n",
      "Starting Epoch 221\n",
      "1.6968229361202405\n",
      "Validation loss: 1.5872349739074707\n",
      "mse 1.5872351773108397\n",
      "New best model found at epoch 221 with validation loss 1.5872349739074707\n",
      "Starting Epoch 222\n",
      "1.696291060551353\n",
      "Validation loss: 1.5867300033569336\n",
      "mse 1.5867299303956994\n",
      "New best model found at epoch 222 with validation loss 1.5867300033569336\n",
      "Starting Epoch 223\n",
      "1.6957632666048796\n",
      "Validation loss: 1.5862305164337158\n",
      "mse 1.5862303343136515\n",
      "New best model found at epoch 223 with validation loss 1.5862305164337158\n",
      "Starting Epoch 224\n",
      "1.695239727911742\n",
      "Validation loss: 1.585735559463501\n",
      "mse 1.585735519021236\n",
      "New best model found at epoch 224 with validation loss 1.585735559463501\n",
      "Starting Epoch 225\n",
      "1.6947204600209775\n",
      "Validation loss: 1.5852457284927368\n",
      "mse 1.585245767543047\n",
      "New best model found at epoch 225 with validation loss 1.5852457284927368\n",
      "Starting Epoch 226\n",
      "1.6942053748213726\n",
      "Validation loss: 1.5847612619400024\n",
      "mse 1.5847612647128213\n",
      "New best model found at epoch 226 with validation loss 1.5847612619400024\n",
      "Starting Epoch 227\n",
      "1.6936944308488264\n",
      "Validation loss: 1.5842820405960083\n",
      "mse 1.5842820777198625\n",
      "New best model found at epoch 227 with validation loss 1.5842820405960083\n",
      "Starting Epoch 228\n",
      "1.693187617737314\n",
      "Validation loss: 1.5838083028793335\n",
      "mse 1.5838084279517022\n",
      "New best model found at epoch 228 with validation loss 1.5838083028793335\n",
      "Starting Epoch 229\n",
      "1.6926847825879636\n",
      "Validation loss: 1.5833401679992676\n",
      "mse 1.5833401184379232\n",
      "New best model found at epoch 229 with validation loss 1.5833401679992676\n",
      "Starting Epoch 230\n",
      "1.6921857828679292\n",
      "Validation loss: 1.5828771591186523\n",
      "mse 1.5828772548414465\n",
      "New best model found at epoch 230 with validation loss 1.5828771591186523\n",
      "Starting Epoch 231\n",
      "1.6916906419007673\n",
      "Validation loss: 1.5824196338653564\n",
      "mse 1.5824196098997891\n",
      "New best model found at epoch 231 with validation loss 1.5824196338653564\n",
      "Starting Epoch 232\n",
      "1.6911992974903272\n",
      "Validation loss: 1.5819669961929321\n",
      "mse 1.581966930373865\n",
      "New best model found at epoch 232 with validation loss 1.5819669961929321\n",
      "Starting Epoch 233\n",
      "1.6907116848489512\n",
      "Validation loss: 1.5815192461013794\n",
      "mse 1.5815192152465187\n",
      "New best model found at epoch 233 with validation loss 1.5815192461013794\n",
      "Starting Epoch 234\n",
      "1.6902277547380198\n",
      "Validation loss: 1.5810765027999878\n",
      "mse 1.5810765661184627\n",
      "New best model found at epoch 234 with validation loss 1.5810765027999878\n",
      "Starting Epoch 235\n",
      "1.6897473257520925\n",
      "Validation loss: 1.5806387662887573\n",
      "mse 1.5806386172632212\n",
      "New best model found at epoch 235 with validation loss 1.5806387662887573\n",
      "Starting Epoch 236\n",
      "1.6892705948456475\n",
      "Validation loss: 1.5802052021026611\n",
      "mse 1.5802051159956096\n",
      "New best model found at epoch 236 with validation loss 1.5802052021026611\n",
      "Starting Epoch 237\n",
      "1.6888008039930593\n",
      "Validation loss: 1.5797761678695679\n",
      "mse 1.5797761681519826\n",
      "New best model found at epoch 237 with validation loss 1.5797761678695679\n",
      "Starting Epoch 238\n",
      "1.6883311738138613\n",
      "Validation loss: 1.5793462991714478\n",
      "mse 1.5793462518453547\n",
      "New best model found at epoch 238 with validation loss 1.5793462991714478\n",
      "Starting Epoch 239\n",
      "1.6878653505574102\n",
      "Validation loss: 1.5789204835891724\n",
      "mse 1.5789203403373462\n",
      "New best model found at epoch 239 with validation loss 1.5789204835891724\n",
      "Starting Epoch 240\n",
      "1.687416390232418\n",
      "Validation loss: 1.5784764289855957\n",
      "mse 1.5784763809136646\n",
      "New best model found at epoch 240 with validation loss 1.5784764289855957\n",
      "Starting Epoch 241\n",
      "1.6869416055472002\n",
      "Validation loss: 1.5780624151229858\n",
      "mse 1.5780625012557152\n",
      "New best model found at epoch 241 with validation loss 1.5780624151229858\n",
      "Starting Epoch 242\n",
      "1.6864869128102842\n",
      "Validation loss: 1.577645182609558\n",
      "mse 1.5776451422046114\n",
      "New best model found at epoch 242 with validation loss 1.577645182609558\n",
      "Starting Epoch 243\n",
      "1.6860351640245188\n",
      "Validation loss: 1.5772337913513184\n",
      "mse 1.577233576512236\n",
      "New best model found at epoch 243 with validation loss 1.5772337913513184\n",
      "Starting Epoch 244\n",
      "1.6856003844219705\n",
      "Validation loss: 1.576805830001831\n",
      "mse 1.576805826431835\n",
      "New best model found at epoch 244 with validation loss 1.576805830001831\n",
      "Starting Epoch 245\n",
      "1.6851386557454648\n",
      "Validation loss: 1.5764089822769165\n",
      "mse 1.5764088463178683\n",
      "New best model found at epoch 245 with validation loss 1.5764089822769165\n",
      "Starting Epoch 246\n",
      "1.6847104507943857\n",
      "Validation loss: 1.5759862661361694\n",
      "mse 1.5759862841729138\n",
      "New best model found at epoch 246 with validation loss 1.5759862661361694\n",
      "Starting Epoch 247\n",
      "1.684255786564039\n",
      "Validation loss: 1.5755956172943115\n",
      "mse 1.5755956146024745\n",
      "New best model found at epoch 247 with validation loss 1.5755956172943115\n",
      "Starting Epoch 248\n",
      "1.6838327490765115\n",
      "Validation loss: 1.5751981735229492\n",
      "mse 1.5751980192165385\n",
      "New best model found at epoch 248 with validation loss 1.5751981735229492\n",
      "Starting Epoch 249\n",
      "1.6833849030992258\n",
      "Validation loss: 1.5748242139816284\n",
      "mse 1.574824254303697\n",
      "New best model found at epoch 249 with validation loss 1.5748242139816284\n",
      "Starting Epoch 250\n",
      "1.6829706119454426\n",
      "Validation loss: 1.5744210481643677\n",
      "mse 1.57442115653307\n",
      "New best model found at epoch 250 with validation loss 1.5744210481643677\n",
      "Starting Epoch 251\n",
      "1.6825386907743372\n",
      "Validation loss: 1.5740447044372559\n",
      "mse 1.574044761085927\n",
      "New best model found at epoch 251 with validation loss 1.5740447044372559\n",
      "Starting Epoch 252\n",
      "1.6821014570153279\n",
      "Validation loss: 1.573682427406311\n",
      "mse 1.5736824939164393\n",
      "New best model found at epoch 252 with validation loss 1.573682427406311\n",
      "Starting Epoch 253\n",
      "1.681696451228598\n",
      "Validation loss: 1.5732953548431396\n",
      "mse 1.573295328179045\n",
      "New best model found at epoch 253 with validation loss 1.5732953548431396\n",
      "Starting Epoch 254\n",
      "1.6812801542489424\n",
      "Validation loss: 1.5729587078094482\n",
      "mse 1.5729586653726484\n",
      "New best model found at epoch 254 with validation loss 1.5729587078094482\n",
      "Starting Epoch 255\n",
      "1.6808659097422725\n",
      "Validation loss: 1.572638988494873\n",
      "mse 1.5726390023236814\n",
      "New best model found at epoch 255 with validation loss 1.572638988494873\n",
      "Starting Epoch 256\n",
      "1.680457592010498\n",
      "Validation loss: 1.572287917137146\n",
      "mse 1.572288003118238\n",
      "New best model found at epoch 256 with validation loss 1.572287917137146\n",
      "Starting Epoch 257\n",
      "1.68003882791685\n",
      "Validation loss: 1.571948528289795\n",
      "mse 1.5719485646763978\n",
      "New best model found at epoch 257 with validation loss 1.571948528289795\n",
      "Starting Epoch 258\n",
      "1.679651809775311\n",
      "Validation loss: 1.5715817213058472\n",
      "mse 1.5715817720106204\n",
      "New best model found at epoch 258 with validation loss 1.5715817213058472\n",
      "Starting Epoch 259\n",
      "1.6792516708374023\n",
      "Validation loss: 1.5712175369262695\n",
      "mse 1.5712176201879677\n",
      "New best model found at epoch 259 with validation loss 1.5712175369262695\n",
      "Starting Epoch 260\n",
      "1.6788544628931128\n",
      "Validation loss: 1.5708521604537964\n",
      "mse 1.5708520724572896\n",
      "New best model found at epoch 260 with validation loss 1.5708521604537964\n",
      "Starting Epoch 261\n",
      "1.6784606861031575\n",
      "Validation loss: 1.570502758026123\n",
      "mse 1.5705027992286857\n",
      "New best model found at epoch 261 with validation loss 1.570502758026123\n",
      "Starting Epoch 262\n",
      "1.6780734865561775\n",
      "Validation loss: 1.5701565742492676\n",
      "mse 1.5701564648107404\n",
      "New best model found at epoch 262 with validation loss 1.5701565742492676\n",
      "Starting Epoch 263\n",
      "1.6776889251626057\n",
      "Validation loss: 1.569838523864746\n",
      "mse 1.5698384046104261\n",
      "New best model found at epoch 263 with validation loss 1.569838523864746\n",
      "Starting Epoch 264\n",
      "1.6773064965787141\n",
      "Validation loss: 1.56950843334198\n",
      "mse 1.5695083548011002\n",
      "New best model found at epoch 264 with validation loss 1.56950843334198\n",
      "Starting Epoch 265\n",
      "1.6769252289896426\n",
      "Validation loss: 1.5692009925842285\n",
      "mse 1.569200870070273\n",
      "New best model found at epoch 265 with validation loss 1.5692009925842285\n",
      "Starting Epoch 266\n",
      "1.6765477942383809\n",
      "Validation loss: 1.5688790082931519\n",
      "mse 1.568878972807624\n",
      "New best model found at epoch 266 with validation loss 1.5688790082931519\n",
      "Starting Epoch 267\n",
      "1.6761757912843123\n",
      "Validation loss: 1.5685553550720215\n",
      "mse 1.568555528027492\n",
      "New best model found at epoch 267 with validation loss 1.5685553550720215\n",
      "Starting Epoch 268\n",
      "1.6758044232492861\n",
      "Validation loss: 1.5682172775268555\n",
      "mse 1.568217283434654\n",
      "New best model found at epoch 268 with validation loss 1.5682172775268555\n",
      "Starting Epoch 269\n",
      "1.6754316972649617\n",
      "Validation loss: 1.5678722858428955\n",
      "mse 1.5678723805427928\n",
      "New best model found at epoch 269 with validation loss 1.5678722858428955\n",
      "Starting Epoch 270\n",
      "1.6750729032184766\n",
      "Validation loss: 1.5675605535507202\n",
      "mse 1.5675606993777849\n",
      "New best model found at epoch 270 with validation loss 1.5675605535507202\n",
      "Starting Epoch 271\n",
      "1.674708604812622\n",
      "Validation loss: 1.5672434568405151\n",
      "mse 1.5672434559676498\n",
      "New best model found at epoch 271 with validation loss 1.5672434568405151\n",
      "Starting Epoch 272\n",
      "1.6743465972983318\n",
      "Validation loss: 1.5669115781784058\n",
      "mse 1.5669115803210152\n",
      "New best model found at epoch 272 with validation loss 1.5669115781784058\n",
      "Starting Epoch 273\n",
      "1.6739099103471506\n",
      "Validation loss: 1.5663015842437744\n",
      "mse 1.5663014410437701\n",
      "New best model found at epoch 273 with validation loss 1.5663015842437744\n",
      "Starting Epoch 274\n",
      "1.6733046744180762\n",
      "Validation loss: 1.5657395124435425\n",
      "mse 1.5657395531235523\n",
      "New best model found at epoch 274 with validation loss 1.5657395124435425\n",
      "Starting Epoch 275\n",
      "1.672933930936067\n",
      "Validation loss: 1.5652087926864624\n",
      "mse 1.56520885729639\n",
      "New best model found at epoch 275 with validation loss 1.5652087926864624\n",
      "Starting Epoch 276\n",
      "1.6724918381027554\n",
      "Validation loss: 1.5647459030151367\n",
      "mse 1.5647459740107463\n",
      "New best model found at epoch 276 with validation loss 1.5647459030151367\n",
      "Starting Epoch 277\n",
      "1.6720565298329229\n",
      "Validation loss: 1.564281940460205\n",
      "mse 1.5642819682457714\n",
      "New best model found at epoch 277 with validation loss 1.564281940460205\n",
      "Starting Epoch 278\n",
      "1.6716260547223298\n",
      "Validation loss: 1.5638166666030884\n",
      "mse 1.5638165377130946\n",
      "New best model found at epoch 278 with validation loss 1.5638166666030884\n",
      "Starting Epoch 279\n",
      "1.6712048209231833\n",
      "Validation loss: 1.5633947849273682\n",
      "mse 1.563394792737688\n",
      "New best model found at epoch 279 with validation loss 1.5633947849273682\n",
      "Starting Epoch 280\n",
      "1.6707826438157454\n",
      "Validation loss: 1.562957763671875\n",
      "mse 1.5629578838452025\n",
      "New best model found at epoch 280 with validation loss 1.562957763671875\n",
      "Starting Epoch 281\n",
      "1.6703651702922324\n",
      "Validation loss: 1.5625150203704834\n",
      "mse 1.562515262637632\n",
      "New best model found at epoch 281 with validation loss 1.5625150203704834\n",
      "Starting Epoch 282\n",
      "1.6699512626813806\n",
      "Validation loss: 1.5620713233947754\n",
      "mse 1.5620713799094565\n",
      "New best model found at epoch 282 with validation loss 1.5620713233947754\n",
      "Starting Epoch 283\n",
      "1.6695405348487522\n",
      "Validation loss: 1.5616289377212524\n",
      "mse 1.5616289722595575\n",
      "New best model found at epoch 283 with validation loss 1.5616289377212524\n",
      "Starting Epoch 284\n",
      "1.6691330723140552\n",
      "Validation loss: 1.5611891746520996\n",
      "mse 1.5611890582807166\n",
      "New best model found at epoch 284 with validation loss 1.5611891746520996\n",
      "Starting Epoch 285\n",
      "1.66872863665871\n",
      "Validation loss: 1.5607527494430542\n",
      "mse 1.560752782927539\n",
      "New best model found at epoch 285 with validation loss 1.5607527494430542\n",
      "Starting Epoch 286\n",
      "1.6683334267657737\n",
      "Validation loss: 1.5603057146072388\n",
      "mse 1.5603056545244733\n",
      "New best model found at epoch 286 with validation loss 1.5603057146072388\n",
      "Starting Epoch 287\n",
      "1.6679348297741101\n",
      "Validation loss: 1.5598764419555664\n",
      "mse 1.5598765819051552\n",
      "New best model found at epoch 287 with validation loss 1.5598764419555664\n",
      "Starting Epoch 288\n",
      "1.6675392985343933\n",
      "Validation loss: 1.5594522953033447\n",
      "mse 1.5594522290353583\n",
      "New best model found at epoch 288 with validation loss 1.5594522953033447\n",
      "Starting Epoch 289\n",
      "1.6671468822852424\n",
      "Validation loss: 1.5590312480926514\n",
      "mse 1.559031310927056\n",
      "New best model found at epoch 289 with validation loss 1.5590312480926514\n",
      "Starting Epoch 290\n",
      "1.6667574151702549\n",
      "Validation loss: 1.5586146116256714\n",
      "mse 1.5586146099162284\n",
      "New best model found at epoch 290 with validation loss 1.5586146116256714\n",
      "Starting Epoch 291\n",
      "1.6663706250812695\n",
      "Validation loss: 1.558201789855957\n",
      "mse 1.558201716305237\n",
      "New best model found at epoch 291 with validation loss 1.558201789855957\n",
      "Starting Epoch 292\n",
      "1.6659865638484126\n",
      "Validation loss: 1.5577932596206665\n",
      "mse 1.5577931820697424\n",
      "New best model found at epoch 292 with validation loss 1.5577932596206665\n",
      "Starting Epoch 293\n",
      "1.6656050293341926\n",
      "Validation loss: 1.5573887825012207\n",
      "mse 1.5573888492731052\n",
      "New best model found at epoch 293 with validation loss 1.5573887825012207\n",
      "Starting Epoch 294\n",
      "1.6652259697084841\n",
      "Validation loss: 1.5569884777069092\n",
      "mse 1.5569886366915753\n",
      "New best model found at epoch 294 with validation loss 1.5569884777069092\n",
      "Starting Epoch 295\n",
      "1.6648493201836296\n",
      "Validation loss: 1.556592345237732\n",
      "mse 1.5565924571391043\n",
      "New best model found at epoch 295 with validation loss 1.556592345237732\n",
      "Starting Epoch 296\n",
      "1.664475010788959\n",
      "Validation loss: 1.5562002658843994\n",
      "mse 1.5562002762871299\n",
      "New best model found at epoch 296 with validation loss 1.5562002658843994\n",
      "Starting Epoch 297\n",
      "1.6641031296356865\n",
      "Validation loss: 1.5558120012283325\n",
      "mse 1.5558119204366136\n",
      "New best model found at epoch 297 with validation loss 1.5558120012283325\n",
      "Starting Epoch 298\n",
      "1.6637334642202959\n",
      "Validation loss: 1.5554269552230835\n",
      "mse 1.5554270496454194\n",
      "New best model found at epoch 298 with validation loss 1.5554269552230835\n",
      "Starting Epoch 299\n",
      "1.6633659860362178\n",
      "Validation loss: 1.5550459623336792\n",
      "mse 1.5550457765823598\n",
      "New best model found at epoch 299 with validation loss 1.5550459623336792\n",
      "Starting Epoch 300\n",
      "1.6629898366720781\n",
      "Validation loss: 1.554706335067749\n",
      "mse 1.5547063731883257\n",
      "New best model found at epoch 300 with validation loss 1.554706335067749\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-10-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf6e76",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 3\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 20 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "233fd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "d5df51ba-a4b0-4341-96ae-0bb4fc6a6672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.36153623332148\n",
      "Validation loss: 2.6678807735443115\n",
      "mse 2.6678808315395077\n",
      "New best model found at epoch 1 with validation loss 2.6678807735443115\n",
      "Starting Epoch 2\n",
      "2.9476331161416094\n",
      "Validation loss: 2.568406343460083\n",
      "mse 2.5684065424737064\n",
      "New best model found at epoch 2 with validation loss 2.568406343460083\n",
      "Starting Epoch 3\n",
      "2.8564717095831167\n",
      "Validation loss: 2.5032832622528076\n",
      "mse 2.503283185945677\n",
      "New best model found at epoch 3 with validation loss 2.5032832622528076\n",
      "Starting Epoch 4\n",
      "2.782254825467649\n",
      "Validation loss: 2.4449727535247803\n",
      "mse 2.444972885438429\n",
      "New best model found at epoch 4 with validation loss 2.4449727535247803\n",
      "Starting Epoch 5\n",
      "2.7138555723687876\n",
      "Validation loss: 2.3952364921569824\n",
      "mse 2.39523657270494\n",
      "New best model found at epoch 5 with validation loss 2.3952364921569824\n",
      "Starting Epoch 6\n",
      "2.6550577360650767\n",
      "Validation loss: 2.3533174991607666\n",
      "mse 2.3533176121688846\n",
      "New best model found at epoch 6 with validation loss 2.3533174991607666\n",
      "Starting Epoch 7\n",
      "2.6028555009676064\n",
      "Validation loss: 2.3142356872558594\n",
      "mse 2.3142356094431396\n",
      "New best model found at epoch 7 with validation loss 2.3142356872558594\n",
      "Starting Epoch 8\n",
      "2.555151934209077\n",
      "Validation loss: 2.2771873474121094\n",
      "mse 2.277187415989065\n",
      "New best model found at epoch 8 with validation loss 2.2771873474121094\n",
      "Starting Epoch 9\n",
      "2.511898906334587\n",
      "Validation loss: 2.2426881790161133\n",
      "mse 2.242688128671987\n",
      "New best model found at epoch 9 with validation loss 2.2426881790161133\n",
      "Starting Epoch 10\n",
      "2.4716124119965928\n",
      "Validation loss: 2.210157632827759\n",
      "mse 2.210157745708425\n",
      "New best model found at epoch 10 with validation loss 2.210157632827759\n",
      "Starting Epoch 11\n",
      "2.4341252731240313\n",
      "Validation loss: 2.179651975631714\n",
      "mse 2.1796517265072803\n",
      "New best model found at epoch 11 with validation loss 2.179651975631714\n",
      "Starting Epoch 12\n",
      "2.3989862151767896\n",
      "Validation loss: 2.1510136127471924\n",
      "mse 2.1510135354501725\n",
      "New best model found at epoch 12 with validation loss 2.1510136127471924\n",
      "Starting Epoch 13\n",
      "2.36571220729662\n",
      "Validation loss: 2.1233103275299072\n",
      "mse 2.1233101440433093\n",
      "New best model found at epoch 13 with validation loss 2.1233103275299072\n",
      "Starting Epoch 14\n",
      "2.334408200305441\n",
      "Validation loss: 2.0964999198913574\n",
      "mse 2.09650004528249\n",
      "New best model found at epoch 14 with validation loss 2.0964999198913574\n",
      "Starting Epoch 15\n",
      "2.304530029711516\n",
      "Validation loss: 2.070672035217285\n",
      "mse 2.070671894280819\n",
      "New best model found at epoch 15 with validation loss 2.070672035217285\n",
      "Starting Epoch 16\n",
      "2.2764944408250893\n",
      "Validation loss: 2.047379732131958\n",
      "mse 2.0473798161075667\n",
      "New best model found at epoch 16 with validation loss 2.047379732131958\n",
      "Starting Epoch 17\n",
      "2.250296245450559\n",
      "Validation loss: 2.025278329849243\n",
      "mse 2.025278199425224\n",
      "New best model found at epoch 17 with validation loss 2.025278329849243\n",
      "Starting Epoch 18\n",
      "2.22538567625958\n",
      "Validation loss: 2.004023790359497\n",
      "mse 2.0040237210751854\n",
      "New best model found at epoch 18 with validation loss 2.004023790359497\n",
      "Starting Epoch 19\n",
      "2.201692767765211\n",
      "Validation loss: 1.983917474746704\n",
      "mse 1.9839176006830304\n",
      "New best model found at epoch 19 with validation loss 1.983917474746704\n",
      "Starting Epoch 20\n",
      "2.1789903796237446\n",
      "Validation loss: 1.9646986722946167\n",
      "mse 1.9646985288596857\n",
      "New best model found at epoch 20 with validation loss 1.9646986722946167\n",
      "Starting Epoch 21\n",
      "2.1577308333438374\n",
      "Validation loss: 1.9465713500976562\n",
      "mse 1.9465713950560544\n",
      "New best model found at epoch 21 with validation loss 1.9465713500976562\n",
      "Starting Epoch 22\n",
      "2.137395547783893\n",
      "Validation loss: 1.9291146993637085\n",
      "mse 1.929114734518793\n",
      "New best model found at epoch 22 with validation loss 1.9291146993637085\n",
      "Starting Epoch 23\n",
      "2.1180321962937065\n",
      "Validation loss: 1.9126805067062378\n",
      "mse 1.9126806482482397\n",
      "New best model found at epoch 23 with validation loss 1.9126805067062378\n",
      "Starting Epoch 24\n",
      "2.099682294804117\n",
      "Validation loss: 1.8969794511795044\n",
      "mse 1.8969794407480596\n",
      "New best model found at epoch 24 with validation loss 1.8969794511795044\n",
      "Starting Epoch 25\n",
      "2.0821948414263516\n",
      "Validation loss: 1.882001519203186\n",
      "mse 1.8820015312375993\n",
      "New best model found at epoch 25 with validation loss 1.882001519203186\n",
      "Starting Epoch 26\n",
      "2.0653572911801548\n",
      "Validation loss: 1.8679101467132568\n",
      "mse 1.8679100616626039\n",
      "New best model found at epoch 26 with validation loss 1.8679101467132568\n",
      "Starting Epoch 27\n",
      "2.0494263223979785\n",
      "Validation loss: 1.8544379472732544\n",
      "mse 1.8544380193363965\n",
      "New best model found at epoch 27 with validation loss 1.8544379472732544\n",
      "Starting Epoch 28\n",
      "2.034201549447101\n",
      "Validation loss: 1.841082215309143\n",
      "mse 1.841082229544044\n",
      "New best model found at epoch 28 with validation loss 1.841082215309143\n",
      "Starting Epoch 29\n",
      "2.0193592258121655\n",
      "Validation loss: 1.8285330533981323\n",
      "mse 1.828532932798029\n",
      "New best model found at epoch 29 with validation loss 1.8285330533981323\n",
      "Starting Epoch 30\n",
      "2.0048337915669316\n",
      "Validation loss: 1.8160730600357056\n",
      "mse 1.8160731749028869\n",
      "New best model found at epoch 30 with validation loss 1.8160730600357056\n",
      "Starting Epoch 31\n",
      "1.990978075110394\n",
      "Validation loss: 1.8043283224105835\n",
      "mse 1.8043282788152786\n",
      "New best model found at epoch 31 with validation loss 1.8043283224105835\n",
      "Starting Epoch 32\n",
      "1.9778251596119092\n",
      "Validation loss: 1.792724370956421\n",
      "mse 1.7927243023265031\n",
      "New best model found at epoch 32 with validation loss 1.792724370956421\n",
      "Starting Epoch 33\n",
      "1.9654955138330874\n",
      "Validation loss: 1.7821494340896606\n",
      "mse 1.7821494211092737\n",
      "New best model found at epoch 33 with validation loss 1.7821494340896606\n",
      "Starting Epoch 34\n",
      "1.9536921718846196\n",
      "Validation loss: 1.7718663215637207\n",
      "mse 1.7718663793810414\n",
      "New best model found at epoch 34 with validation loss 1.7718663215637207\n",
      "Starting Epoch 35\n",
      "1.9424206795899763\n",
      "Validation loss: 1.762320637702942\n",
      "mse 1.7623207504177327\n",
      "New best model found at epoch 35 with validation loss 1.762320637702942\n",
      "Starting Epoch 36\n",
      "1.9316413298897122\n",
      "Validation loss: 1.7528297901153564\n",
      "mse 1.7528298245851952\n",
      "New best model found at epoch 36 with validation loss 1.7528297901153564\n",
      "Starting Epoch 37\n",
      "1.9212536759998486\n",
      "Validation loss: 1.7438595294952393\n",
      "mse 1.7438596238883604\n",
      "New best model found at epoch 37 with validation loss 1.7438595294952393\n",
      "Starting Epoch 38\n",
      "1.9109641313552856\n",
      "Validation loss: 1.7355356216430664\n",
      "mse 1.7355355762148101\n",
      "New best model found at epoch 38 with validation loss 1.7355356216430664\n",
      "Starting Epoch 39\n",
      "1.901229220887889\n",
      "Validation loss: 1.7273117303848267\n",
      "mse 1.7273118609444813\n",
      "New best model found at epoch 39 with validation loss 1.7273117303848267\n",
      "Starting Epoch 40\n",
      "1.8918811497480974\n",
      "Validation loss: 1.7194145917892456\n",
      "mse 1.7194145411798867\n",
      "New best model found at epoch 40 with validation loss 1.7194145917892456\n",
      "Starting Epoch 41\n",
      "1.882774980171867\n",
      "Validation loss: 1.712206482887268\n",
      "mse 1.7122065164398572\n",
      "New best model found at epoch 41 with validation loss 1.712206482887268\n",
      "Starting Epoch 42\n",
      "1.8738248503726462\n",
      "Validation loss: 1.704620361328125\n",
      "mse 1.7046203565198972\n",
      "New best model found at epoch 42 with validation loss 1.704620361328125\n",
      "Starting Epoch 43\n",
      "1.8651985448339712\n",
      "Validation loss: 1.6974602937698364\n",
      "mse 1.6974603319525283\n",
      "New best model found at epoch 43 with validation loss 1.6974602937698364\n",
      "Starting Epoch 44\n",
      "1.8566988654758618\n",
      "Validation loss: 1.6908849477767944\n",
      "mse 1.690884660424918\n",
      "New best model found at epoch 44 with validation loss 1.6908849477767944\n",
      "Starting Epoch 45\n",
      "1.8487474659214849\n",
      "Validation loss: 1.684876799583435\n",
      "mse 1.6848768104512473\n",
      "New best model found at epoch 45 with validation loss 1.684876799583435\n",
      "Starting Epoch 46\n",
      "1.8412377367848936\n",
      "Validation loss: 1.6787363290786743\n",
      "mse 1.6787363683382717\n",
      "New best model found at epoch 46 with validation loss 1.6787363290786743\n",
      "Starting Epoch 47\n",
      "1.8342812475950823\n",
      "Validation loss: 1.6726244688034058\n",
      "mse 1.6726243440791562\n",
      "New best model found at epoch 47 with validation loss 1.6726244688034058\n",
      "Starting Epoch 48\n",
      "1.827375712602035\n",
      "Validation loss: 1.6674519777297974\n",
      "mse 1.667451983586994\n",
      "New best model found at epoch 48 with validation loss 1.6674519777297974\n",
      "Starting Epoch 49\n",
      "1.8207013140554014\n",
      "Validation loss: 1.661612868309021\n",
      "mse 1.6616129830575244\n",
      "New best model found at epoch 49 with validation loss 1.661612868309021\n",
      "Starting Epoch 50\n",
      "1.8142993191014165\n",
      "Validation loss: 1.6568031311035156\n",
      "mse 1.6568030277472177\n",
      "New best model found at epoch 50 with validation loss 1.6568031311035156\n",
      "Starting Epoch 51\n",
      "1.8080862449563069\n",
      "Validation loss: 1.6515908241271973\n",
      "mse 1.6515907871979516\n",
      "New best model found at epoch 51 with validation loss 1.6515908241271973\n",
      "Starting Epoch 52\n",
      "1.8020483255386353\n",
      "Validation loss: 1.6467169523239136\n",
      "mse 1.6467168352647426\n",
      "New best model found at epoch 52 with validation loss 1.6467169523239136\n",
      "Starting Epoch 53\n",
      "1.7962975294693657\n",
      "Validation loss: 1.642037034034729\n",
      "mse 1.6420370390765124\n",
      "New best model found at epoch 53 with validation loss 1.642037034034729\n",
      "Starting Epoch 54\n",
      "1.7909104668575784\n",
      "Validation loss: 1.6371699571609497\n",
      "mse 1.637169849711247\n",
      "New best model found at epoch 54 with validation loss 1.6371699571609497\n",
      "Starting Epoch 55\n",
      "1.785701694695846\n",
      "Validation loss: 1.6327354907989502\n",
      "mse 1.632735512612019\n",
      "New best model found at epoch 55 with validation loss 1.6327354907989502\n",
      "Starting Epoch 56\n",
      "1.7807508396065754\n",
      "Validation loss: 1.6281770467758179\n",
      "mse 1.6281769529352716\n",
      "New best model found at epoch 56 with validation loss 1.6281770467758179\n",
      "Starting Epoch 57\n",
      "1.775980840558591\n",
      "Validation loss: 1.6238676309585571\n",
      "mse 1.6238674341102002\n",
      "New best model found at epoch 57 with validation loss 1.6238676309585571\n",
      "Starting Epoch 58\n",
      "1.7711865124495134\n",
      "Validation loss: 1.6196863651275635\n",
      "mse 1.6196863278849445\n",
      "New best model found at epoch 58 with validation loss 1.6196863651275635\n",
      "Starting Epoch 59\n",
      "1.7668058716732522\n",
      "Validation loss: 1.6159367561340332\n",
      "mse 1.6159368008194899\n",
      "New best model found at epoch 59 with validation loss 1.6159367561340332\n",
      "Starting Epoch 60\n",
      "1.7625913257184236\n",
      "Validation loss: 1.6122238636016846\n",
      "mse 1.6122237693828056\n",
      "New best model found at epoch 60 with validation loss 1.6122238636016846\n",
      "Starting Epoch 61\n",
      "1.7584551572799683\n",
      "Validation loss: 1.6084998846054077\n",
      "mse 1.6084997791669204\n",
      "New best model found at epoch 61 with validation loss 1.6084998846054077\n",
      "Starting Epoch 62\n",
      "1.7545602010644001\n",
      "Validation loss: 1.6051037311553955\n",
      "mse 1.6051037260070398\n",
      "New best model found at epoch 62 with validation loss 1.6051037311553955\n",
      "Starting Epoch 63\n",
      "1.7504435363023176\n",
      "Validation loss: 1.6015148162841797\n",
      "mse 1.601514803323218\n",
      "New best model found at epoch 63 with validation loss 1.6015148162841797\n",
      "Starting Epoch 64\n",
      "1.7466760925624683\n",
      "Validation loss: 1.598233699798584\n",
      "mse 1.5982338325540417\n",
      "New best model found at epoch 64 with validation loss 1.598233699798584\n",
      "Starting Epoch 65\n",
      "1.7427834635195525\n",
      "Validation loss: 1.5945831537246704\n",
      "mse 1.5945830438295496\n",
      "New best model found at epoch 65 with validation loss 1.5945831537246704\n",
      "Starting Epoch 66\n",
      "1.7388394449068152\n",
      "Validation loss: 1.5917211771011353\n",
      "mse 1.5917211396265107\n",
      "New best model found at epoch 66 with validation loss 1.5917211771011353\n",
      "Starting Epoch 67\n",
      "1.7351394943569018\n",
      "Validation loss: 1.5882928371429443\n",
      "mse 1.5882928303032524\n",
      "New best model found at epoch 67 with validation loss 1.5882928371429443\n",
      "Starting Epoch 68\n",
      "1.731475037077199\n",
      "Validation loss: 1.5849226713180542\n",
      "mse 1.5849226243010799\n",
      "New best model found at epoch 68 with validation loss 1.5849226713180542\n",
      "Starting Epoch 69\n",
      "1.7277432731960132\n",
      "Validation loss: 1.5818568468093872\n",
      "mse 1.581856755647818\n",
      "New best model found at epoch 69 with validation loss 1.5818568468093872\n",
      "Starting Epoch 70\n",
      "1.7238638141880864\n",
      "Validation loss: 1.5784966945648193\n",
      "mse 1.5784967025523207\n",
      "New best model found at epoch 70 with validation loss 1.5784966945648193\n",
      "Starting Epoch 71\n",
      "1.7202737020409626\n",
      "Validation loss: 1.5755928754806519\n",
      "mse 1.5755927387704123\n",
      "New best model found at epoch 71 with validation loss 1.5755928754806519\n",
      "Starting Epoch 72\n",
      "1.7168037062105925\n",
      "Validation loss: 1.5724939107894897\n",
      "mse 1.57249385035691\n",
      "New best model found at epoch 72 with validation loss 1.5724939107894897\n",
      "Starting Epoch 73\n",
      "1.713307878245478\n",
      "Validation loss: 1.5697178840637207\n",
      "mse 1.5697178433885661\n",
      "New best model found at epoch 73 with validation loss 1.5697178840637207\n",
      "Starting Epoch 74\n",
      "1.7099488196165666\n",
      "Validation loss: 1.5666780471801758\n",
      "mse 1.5666779579328713\n",
      "New best model found at epoch 74 with validation loss 1.5666780471801758\n",
      "Starting Epoch 75\n",
      "1.706589242686396\n",
      "Validation loss: 1.564333200454712\n",
      "mse 1.564333103434466\n",
      "New best model found at epoch 75 with validation loss 1.564333200454712\n",
      "Starting Epoch 76\n",
      "1.7036783487900444\n",
      "Validation loss: 1.5614529848098755\n",
      "mse 1.561452980245744\n",
      "New best model found at epoch 76 with validation loss 1.5614529848098755\n",
      "Starting Epoch 77\n",
      "1.7007874146751736\n",
      "Validation loss: 1.5591089725494385\n",
      "mse 1.5591088949374394\n",
      "New best model found at epoch 77 with validation loss 1.5591089725494385\n",
      "Starting Epoch 78\n",
      "1.6979266094124836\n",
      "Validation loss: 1.5567750930786133\n",
      "mse 1.5567750331614925\n",
      "New best model found at epoch 78 with validation loss 1.5567750930786133\n",
      "Starting Epoch 79\n",
      "1.6951514119687288\n",
      "Validation loss: 1.5550328493118286\n",
      "mse 1.5550328352969676\n",
      "New best model found at epoch 79 with validation loss 1.5550328493118286\n",
      "Starting Epoch 80\n",
      "1.6925064325332642\n",
      "Validation loss: 1.5522507429122925\n",
      "mse 1.552250754782808\n",
      "New best model found at epoch 80 with validation loss 1.5522507429122925\n",
      "Starting Epoch 81\n",
      "1.689929433490919\n",
      "Validation loss: 1.550080418586731\n",
      "mse 1.5500804727264053\n",
      "New best model found at epoch 81 with validation loss 1.550080418586731\n",
      "Starting Epoch 82\n",
      "1.6874943038691645\n",
      "Validation loss: 1.5483437776565552\n",
      "mse 1.5483438437663417\n",
      "New best model found at epoch 82 with validation loss 1.5483437776565552\n",
      "Starting Epoch 83\n",
      "1.6852620321771372\n",
      "Validation loss: 1.5465903282165527\n",
      "mse 1.5465902963585882\n",
      "New best model found at epoch 83 with validation loss 1.5465903282165527\n",
      "Starting Epoch 84\n",
      "1.6829381144565085\n",
      "Validation loss: 1.5446408987045288\n",
      "mse 1.5446409495296989\n",
      "New best model found at epoch 84 with validation loss 1.5446408987045288\n",
      "Starting Epoch 85\n",
      "1.6802793793056323\n",
      "Validation loss: 1.5424230098724365\n",
      "mse 1.5424229594505328\n",
      "New best model found at epoch 85 with validation loss 1.5424230098724365\n",
      "Starting Epoch 86\n",
      "1.6778580468633901\n",
      "Validation loss: 1.5407562255859375\n",
      "mse 1.540756292312827\n",
      "New best model found at epoch 86 with validation loss 1.5407562255859375\n",
      "Starting Epoch 87\n",
      "1.6754523723021797\n",
      "Validation loss: 1.539157509803772\n",
      "mse 1.539157564721334\n",
      "New best model found at epoch 87 with validation loss 1.539157509803772\n",
      "Starting Epoch 88\n",
      "1.6733713564665422\n",
      "Validation loss: 1.5375093221664429\n",
      "mse 1.5375093789685708\n",
      "New best model found at epoch 88 with validation loss 1.5375093221664429\n",
      "Starting Epoch 89\n",
      "1.671354205712028\n",
      "Validation loss: 1.5360792875289917\n",
      "mse 1.5360792151864053\n",
      "New best model found at epoch 89 with validation loss 1.5360792875289917\n",
      "Starting Epoch 90\n",
      "1.6692883294561636\n",
      "Validation loss: 1.5346384048461914\n",
      "mse 1.53463825603547\n",
      "New best model found at epoch 90 with validation loss 1.5346384048461914\n",
      "Starting Epoch 91\n",
      "1.6673372828442117\n",
      "Validation loss: 1.5333726406097412\n",
      "mse 1.533372588648509\n",
      "New best model found at epoch 91 with validation loss 1.5333726406097412\n",
      "Starting Epoch 92\n",
      "1.6654682729555212\n",
      "Validation loss: 1.5320926904678345\n",
      "mse 1.5320925804006271\n",
      "New best model found at epoch 92 with validation loss 1.5320926904678345\n",
      "Starting Epoch 93\n",
      "1.6634926795959473\n",
      "Validation loss: 1.5307950973510742\n",
      "mse 1.5307951421247095\n",
      "New best model found at epoch 93 with validation loss 1.5307950973510742\n",
      "Starting Epoch 94\n",
      "1.6616051248882129\n",
      "Validation loss: 1.5293561220169067\n",
      "mse 1.5293562241292449\n",
      "New best model found at epoch 94 with validation loss 1.5293561220169067\n",
      "Starting Epoch 95\n",
      "1.6597482743470564\n",
      "Validation loss: 1.528011679649353\n",
      "mse 1.5280116780558524\n",
      "New best model found at epoch 95 with validation loss 1.528011679649353\n",
      "Starting Epoch 96\n",
      "1.6578794147657312\n",
      "Validation loss: 1.5266646146774292\n",
      "mse 1.5266646854842967\n",
      "New best model found at epoch 96 with validation loss 1.5266646146774292\n",
      "Starting Epoch 97\n",
      "1.6560515994610994\n",
      "Validation loss: 1.5256290435791016\n",
      "mse 1.5256288992577345\n",
      "New best model found at epoch 97 with validation loss 1.5256290435791016\n",
      "Starting Epoch 98\n",
      "1.6542598890221638\n",
      "Validation loss: 1.5241962671279907\n",
      "mse 1.5241963372166962\n",
      "New best model found at epoch 98 with validation loss 1.5241962671279907\n",
      "Starting Epoch 99\n",
      "1.652480441591014\n",
      "Validation loss: 1.5231852531433105\n",
      "mse 1.523185230347369\n",
      "New best model found at epoch 99 with validation loss 1.5231852531433105\n",
      "Starting Epoch 100\n",
      "1.6507157035495923\n",
      "Validation loss: 1.5219212770462036\n",
      "mse 1.5219212569177494\n",
      "New best model found at epoch 100 with validation loss 1.5219212770462036\n",
      "Starting Epoch 101\n",
      "1.6490551388782004\n",
      "Validation loss: 1.5205825567245483\n",
      "mse 1.5205825618209352\n",
      "New best model found at epoch 101 with validation loss 1.5205825567245483\n",
      "Starting Epoch 102\n",
      "1.647427481153737\n",
      "Validation loss: 1.5194023847579956\n",
      "mse 1.5194023104999748\n",
      "New best model found at epoch 102 with validation loss 1.5194023847579956\n",
      "Starting Epoch 103\n",
      "1.6457894314890322\n",
      "Validation loss: 1.5182316303253174\n",
      "mse 1.518231436815182\n",
      "New best model found at epoch 103 with validation loss 1.5182316303253174\n",
      "Starting Epoch 104\n",
      "1.6441882174947988\n",
      "Validation loss: 1.5170756578445435\n",
      "mse 1.5170754847336174\n",
      "New best model found at epoch 104 with validation loss 1.5170756578445435\n",
      "Starting Epoch 105\n",
      "1.6426208900368733\n",
      "Validation loss: 1.5158836841583252\n",
      "mse 1.5158835985491288\n",
      "New best model found at epoch 105 with validation loss 1.5158836841583252\n",
      "Starting Epoch 106\n",
      "1.641070993050285\n",
      "Validation loss: 1.5147923231124878\n",
      "mse 1.5147922811852434\n",
      "New best model found at epoch 106 with validation loss 1.5147923231124878\n",
      "Starting Epoch 107\n",
      "1.6395217698553335\n",
      "Validation loss: 1.5137325525283813\n",
      "mse 1.513732582915485\n",
      "New best model found at epoch 107 with validation loss 1.5137325525283813\n",
      "Starting Epoch 108\n",
      "1.6379896298698757\n",
      "Validation loss: 1.5129213333129883\n",
      "mse 1.5129214042909795\n",
      "New best model found at epoch 108 with validation loss 1.5129213333129883\n",
      "Starting Epoch 109\n",
      "1.6365477364996206\n",
      "Validation loss: 1.5118423700332642\n",
      "mse 1.5118423022791077\n",
      "New best model found at epoch 109 with validation loss 1.5118423700332642\n",
      "Starting Epoch 110\n",
      "1.6351170850836712\n",
      "Validation loss: 1.510811686515808\n",
      "mse 1.5108116257701938\n",
      "New best model found at epoch 110 with validation loss 1.510811686515808\n",
      "Starting Epoch 111\n",
      "1.6337099023487256\n",
      "Validation loss: 1.5097393989562988\n",
      "mse 1.5097394375138433\n",
      "New best model found at epoch 111 with validation loss 1.5097393989562988\n",
      "Starting Epoch 112\n",
      "1.6323018488676653\n",
      "Validation loss: 1.5088893175125122\n",
      "mse 1.50888918268256\n",
      "New best model found at epoch 112 with validation loss 1.5088893175125122\n",
      "Starting Epoch 113\n",
      "1.6309055323186128\n",
      "Validation loss: 1.5079213380813599\n",
      "mse 1.5079213692593139\n",
      "New best model found at epoch 113 with validation loss 1.5079213380813599\n",
      "Starting Epoch 114\n",
      "1.629577118417491\n",
      "Validation loss: 1.5068029165267944\n",
      "mse 1.5068030018462\n",
      "New best model found at epoch 114 with validation loss 1.5068029165267944\n",
      "Starting Epoch 115\n",
      "1.6282356744227202\n",
      "Validation loss: 1.505906105041504\n",
      "mse 1.5059060648417437\n",
      "New best model found at epoch 115 with validation loss 1.505906105041504\n",
      "Starting Epoch 116\n",
      "1.6269455914912017\n",
      "Validation loss: 1.504929780960083\n",
      "mse 1.5049297275492115\n",
      "New best model found at epoch 116 with validation loss 1.504929780960083\n",
      "Starting Epoch 117\n",
      "1.625681371792503\n",
      "Validation loss: 1.504073143005371\n",
      "mse 1.5040731929515323\n",
      "New best model found at epoch 117 with validation loss 1.504073143005371\n",
      "Starting Epoch 118\n",
      "1.6244637162789055\n",
      "Validation loss: 1.5031542778015137\n",
      "mse 1.5031544491839488\n",
      "New best model found at epoch 118 with validation loss 1.5031542778015137\n",
      "Starting Epoch 119\n",
      "1.6232658806054487\n",
      "Validation loss: 1.5024080276489258\n",
      "mse 1.5024080027881705\n",
      "New best model found at epoch 119 with validation loss 1.5024080276489258\n",
      "Starting Epoch 120\n",
      "1.622078335803488\n",
      "Validation loss: 1.5016356706619263\n",
      "mse 1.5016355424003516\n",
      "New best model found at epoch 120 with validation loss 1.5016356706619263\n",
      "Starting Epoch 121\n",
      "1.620908998924753\n",
      "Validation loss: 1.5008028745651245\n",
      "mse 1.5008028767324806\n",
      "New best model found at epoch 121 with validation loss 1.5008028745651245\n",
      "Starting Epoch 122\n",
      "1.6198124937389209\n",
      "Validation loss: 1.5000356435775757\n",
      "mse 1.5000355074694287\n",
      "New best model found at epoch 122 with validation loss 1.5000356435775757\n",
      "Starting Epoch 123\n",
      "1.6187077320140342\n",
      "Validation loss: 1.4993247985839844\n",
      "mse 1.4993248387112408\n",
      "New best model found at epoch 123 with validation loss 1.4993247985839844\n",
      "Starting Epoch 124\n",
      "1.6175815566726353\n",
      "Validation loss: 1.4987361431121826\n",
      "mse 1.4987361188875687\n",
      "New best model found at epoch 124 with validation loss 1.4987361431121826\n",
      "Starting Epoch 125\n",
      "1.616519298242486\n",
      "Validation loss: 1.4979907274246216\n",
      "mse 1.4979908208438928\n",
      "New best model found at epoch 125 with validation loss 1.4979907274246216\n",
      "Starting Epoch 126\n",
      "1.6154791298119917\n",
      "Validation loss: 1.4973409175872803\n",
      "mse 1.4973409674481466\n",
      "New best model found at epoch 126 with validation loss 1.4973409175872803\n",
      "Starting Epoch 127\n",
      "1.6144276546395344\n",
      "Validation loss: 1.496705412864685\n",
      "mse 1.4967053030345647\n",
      "New best model found at epoch 127 with validation loss 1.496705412864685\n",
      "Starting Epoch 128\n",
      "1.613416314125061\n",
      "Validation loss: 1.4960596561431885\n",
      "mse 1.496059649464709\n",
      "New best model found at epoch 128 with validation loss 1.4960596561431885\n",
      "Starting Epoch 129\n",
      "1.6124076039894768\n",
      "Validation loss: 1.495387315750122\n",
      "mse 1.4953872748524524\n",
      "New best model found at epoch 129 with validation loss 1.495387315750122\n",
      "Starting Epoch 130\n",
      "1.6114191568416099\n",
      "Validation loss: 1.494839072227478\n",
      "mse 1.4948392475023358\n",
      "New best model found at epoch 130 with validation loss 1.494839072227478\n",
      "Starting Epoch 131\n",
      "1.6103539000386777\n",
      "Validation loss: 1.4942262172698975\n",
      "mse 1.494226167769504\n",
      "New best model found at epoch 131 with validation loss 1.4942262172698975\n",
      "Starting Epoch 132\n",
      "1.6094713314719822\n",
      "Validation loss: 1.493722915649414\n",
      "mse 1.493722903456398\n",
      "New best model found at epoch 132 with validation loss 1.493722915649414\n",
      "Starting Epoch 133\n",
      "1.6084435970886894\n",
      "Validation loss: 1.493090033531189\n",
      "mse 1.493090001145038\n",
      "New best model found at epoch 133 with validation loss 1.493090033531189\n",
      "Starting Epoch 134\n",
      "1.607562313909116\n",
      "Validation loss: 1.4924923181533813\n",
      "mse 1.4924923051681547\n",
      "New best model found at epoch 134 with validation loss 1.4924923181533813\n",
      "Starting Epoch 135\n",
      "1.6065435798271843\n",
      "Validation loss: 1.4918948411941528\n",
      "mse 1.491894779225514\n",
      "New best model found at epoch 135 with validation loss 1.4918948411941528\n",
      "Starting Epoch 136\n",
      "1.6056852573933809\n",
      "Validation loss: 1.4913476705551147\n",
      "mse 1.4913475950665513\n",
      "New best model found at epoch 136 with validation loss 1.4913476705551147\n",
      "Starting Epoch 137\n",
      "1.6046456565027651\n",
      "Validation loss: 1.4907872676849365\n",
      "mse 1.4907874629111222\n",
      "New best model found at epoch 137 with validation loss 1.4907872676849365\n",
      "Starting Epoch 138\n",
      "1.6038095147713372\n",
      "Validation loss: 1.4902856349945068\n",
      "mse 1.4902855707875005\n",
      "New best model found at epoch 138 with validation loss 1.4902856349945068\n",
      "Starting Epoch 139\n",
      "1.6029174975726916\n",
      "Validation loss: 1.4898005723953247\n",
      "mse 1.4898007577590489\n",
      "New best model found at epoch 139 with validation loss 1.4898005723953247\n",
      "Starting Epoch 140\n",
      "1.6020633448725161\n",
      "Validation loss: 1.4892109632492065\n",
      "mse 1.4892109429445588\n",
      "New best model found at epoch 140 with validation loss 1.4892109632492065\n",
      "Starting Epoch 141\n",
      "1.6012070412221162\n",
      "Validation loss: 1.4887123107910156\n",
      "mse 1.4887123880445146\n",
      "New best model found at epoch 141 with validation loss 1.4887123107910156\n",
      "Starting Epoch 142\n",
      "1.6003239984097688\n",
      "Validation loss: 1.488246202468872\n",
      "mse 1.4882462260318723\n",
      "New best model found at epoch 142 with validation loss 1.488246202468872\n",
      "Starting Epoch 143\n",
      "1.5995067902233289\n",
      "Validation loss: 1.4877861738204956\n",
      "mse 1.4877861402776784\n",
      "New best model found at epoch 143 with validation loss 1.4877861738204956\n",
      "Starting Epoch 144\n",
      "1.5986461328423542\n",
      "Validation loss: 1.4874495267868042\n",
      "mse 1.4874494738502932\n",
      "New best model found at epoch 144 with validation loss 1.4874495267868042\n",
      "Starting Epoch 145\n",
      "1.5978573431139407\n",
      "Validation loss: 1.4870518445968628\n",
      "mse 1.4870517587073646\n",
      "New best model found at epoch 145 with validation loss 1.4870518445968628\n",
      "Starting Epoch 146\n",
      "1.5970242878665095\n",
      "Validation loss: 1.4866613149642944\n",
      "mse 1.4866611700929648\n",
      "New best model found at epoch 146 with validation loss 1.4866613149642944\n",
      "Starting Epoch 147\n",
      "1.596247338730356\n",
      "Validation loss: 1.4862655401229858\n",
      "mse 1.4862655722926097\n",
      "New best model found at epoch 147 with validation loss 1.4862655401229858\n",
      "Starting Epoch 148\n",
      "1.5954778842304065\n",
      "Validation loss: 1.4858002662658691\n",
      "mse 1.4858003422224604\n",
      "New best model found at epoch 148 with validation loss 1.4858002662658691\n",
      "Starting Epoch 149\n",
      "1.5947486188100732\n",
      "Validation loss: 1.4855109453201294\n",
      "mse 1.4855109467138892\n",
      "New best model found at epoch 149 with validation loss 1.4855109453201294\n",
      "Starting Epoch 150\n",
      "1.5939037773920142\n",
      "Validation loss: 1.485032558441162\n",
      "mse 1.4850326649001744\n",
      "New best model found at epoch 150 with validation loss 1.485032558441162\n",
      "Starting Epoch 151\n",
      "1.5932428059370622\n",
      "Validation loss: 1.4846986532211304\n",
      "mse 1.484698656927532\n",
      "New best model found at epoch 151 with validation loss 1.4846986532211304\n",
      "Starting Epoch 152\n",
      "1.592494099036507\n",
      "Validation loss: 1.48430597782135\n",
      "mse 1.4843059273937065\n",
      "New best model found at epoch 152 with validation loss 1.48430597782135\n",
      "Starting Epoch 153\n",
      "1.5916381867035576\n",
      "Validation loss: 1.4838930368423462\n",
      "mse 1.4838931450388708\n",
      "New best model found at epoch 153 with validation loss 1.4838930368423462\n",
      "Starting Epoch 154\n",
      "1.5909739369931428\n",
      "Validation loss: 1.4834372997283936\n",
      "mse 1.4834370324333057\n",
      "New best model found at epoch 154 with validation loss 1.4834372997283936\n",
      "Starting Epoch 155\n",
      "1.5902549987253936\n",
      "Validation loss: 1.4830591678619385\n",
      "mse 1.4830593732666983\n",
      "New best model found at epoch 155 with validation loss 1.4830591678619385\n",
      "Starting Epoch 156\n",
      "1.589526811371679\n",
      "Validation loss: 1.4827308654785156\n",
      "mse 1.4827308571852535\n",
      "New best model found at epoch 156 with validation loss 1.4827308654785156\n",
      "Starting Epoch 157\n",
      "1.5887278447980466\n",
      "Validation loss: 1.4822696447372437\n",
      "mse 1.482269612870117\n",
      "New best model found at epoch 157 with validation loss 1.4822696447372437\n",
      "Starting Epoch 158\n",
      "1.5881180296773496\n",
      "Validation loss: 1.4819982051849365\n",
      "mse 1.4819983002189998\n",
      "New best model found at epoch 158 with validation loss 1.4819982051849365\n",
      "Starting Epoch 159\n",
      "1.5873387248619744\n",
      "Validation loss: 1.4816254377365112\n",
      "mse 1.4816253676984492\n",
      "New best model found at epoch 159 with validation loss 1.4816254377365112\n",
      "Starting Epoch 160\n",
      "1.586769145468007\n",
      "Validation loss: 1.4813716411590576\n",
      "mse 1.4813717488486677\n",
      "New best model found at epoch 160 with validation loss 1.4813716411590576\n",
      "Starting Epoch 161\n",
      "1.5860102565392205\n",
      "Validation loss: 1.481061577796936\n",
      "mse 1.4810616327542758\n",
      "New best model found at epoch 161 with validation loss 1.481061577796936\n",
      "Starting Epoch 162\n",
      "1.5854265067888342\n",
      "Validation loss: 1.4807853698730469\n",
      "mse 1.4807853577717949\n",
      "New best model found at epoch 162 with validation loss 1.4807853698730469\n",
      "Starting Epoch 163\n",
      "1.5847025746884553\n",
      "Validation loss: 1.4803414344787598\n",
      "mse 1.4803414848945864\n",
      "New best model found at epoch 163 with validation loss 1.4803414344787598\n",
      "Starting Epoch 164\n",
      "1.5841630256694297\n",
      "Validation loss: 1.480150818824768\n",
      "mse 1.480150960209074\n",
      "New best model found at epoch 164 with validation loss 1.480150818824768\n",
      "Starting Epoch 165\n",
      "1.5834456345309382\n",
      "Validation loss: 1.47978937625885\n",
      "mse 1.4797892996739683\n",
      "New best model found at epoch 165 with validation loss 1.47978937625885\n",
      "Starting Epoch 166\n",
      "1.5828041149222332\n",
      "Validation loss: 1.4795117378234863\n",
      "mse 1.4795116087900535\n",
      "New best model found at epoch 166 with validation loss 1.4795117378234863\n",
      "Starting Epoch 167\n",
      "1.5822542620741802\n",
      "Validation loss: 1.479272484779358\n",
      "mse 1.4792726179090951\n",
      "New best model found at epoch 167 with validation loss 1.479272484779358\n",
      "Starting Epoch 168\n",
      "1.5815739657567895\n",
      "Validation loss: 1.4789901971817017\n",
      "mse 1.4789901291137206\n",
      "New best model found at epoch 168 with validation loss 1.4789901971817017\n",
      "Starting Epoch 169\n",
      "1.580960900887199\n",
      "Validation loss: 1.4786185026168823\n",
      "mse 1.4786184461527871\n",
      "New best model found at epoch 169 with validation loss 1.4786185026168823\n",
      "Starting Epoch 170\n",
      "1.5803462707478066\n",
      "Validation loss: 1.4783421754837036\n",
      "mse 1.4783423109035891\n",
      "New best model found at epoch 170 with validation loss 1.4783421754837036\n",
      "Starting Epoch 171\n",
      "1.5797447121661643\n",
      "Validation loss: 1.4780688285827637\n",
      "mse 1.478068775837582\n",
      "New best model found at epoch 171 with validation loss 1.4780688285827637\n",
      "Starting Epoch 172\n",
      "1.5791573524475098\n",
      "Validation loss: 1.4778177738189697\n",
      "mse 1.4778178308908072\n",
      "New best model found at epoch 172 with validation loss 1.4778177738189697\n",
      "Starting Epoch 173\n",
      "1.578575629255046\n",
      "Validation loss: 1.4775313138961792\n",
      "mse 1.4775313387822782\n",
      "New best model found at epoch 173 with validation loss 1.4775313138961792\n",
      "Starting Epoch 174\n",
      "1.5780006206553916\n",
      "Validation loss: 1.477268934249878\n",
      "mse 1.4772688689312192\n",
      "New best model found at epoch 174 with validation loss 1.477268934249878\n",
      "Starting Epoch 175\n",
      "1.5774016898611318\n",
      "Validation loss: 1.4769505262374878\n",
      "mse 1.4769507414216596\n",
      "New best model found at epoch 175 with validation loss 1.4769505262374878\n",
      "Starting Epoch 176\n",
      "1.576847545478655\n",
      "Validation loss: 1.476697325706482\n",
      "mse 1.476697261892888\n",
      "New best model found at epoch 176 with validation loss 1.476697325706482\n",
      "Starting Epoch 177\n",
      "1.576269691405089\n",
      "Validation loss: 1.4763678312301636\n",
      "mse 1.4763677205241985\n",
      "New best model found at epoch 177 with validation loss 1.4763678312301636\n",
      "Starting Epoch 178\n",
      "1.575725837894108\n",
      "Validation loss: 1.4761278629302979\n",
      "mse 1.4761277725628545\n",
      "New best model found at epoch 178 with validation loss 1.4761278629302979\n",
      "Starting Epoch 179\n",
      "1.57517293225164\n",
      "Validation loss: 1.4758518934249878\n",
      "mse 1.4758519752072288\n",
      "New best model found at epoch 179 with validation loss 1.4758518934249878\n",
      "Starting Epoch 180\n",
      "1.5746069135873213\n",
      "Validation loss: 1.4755446910858154\n",
      "mse 1.475544543644526\n",
      "New best model found at epoch 180 with validation loss 1.4755446910858154\n",
      "Starting Epoch 181\n",
      "1.574133118857508\n",
      "Validation loss: 1.4752541780471802\n",
      "mse 1.4752540932898146\n",
      "New best model found at epoch 181 with validation loss 1.4752541780471802\n",
      "Starting Epoch 182\n",
      "1.5736518061679343\n",
      "Validation loss: 1.474926233291626\n",
      "mse 1.4749262258406706\n",
      "New best model found at epoch 182 with validation loss 1.474926233291626\n",
      "Starting Epoch 183\n",
      "1.5730442871218142\n",
      "Validation loss: 1.474884271621704\n",
      "mse 1.4748842828548017\n",
      "New best model found at epoch 183 with validation loss 1.474884271621704\n",
      "Starting Epoch 184\n",
      "1.5725345326506572\n",
      "Validation loss: 1.4745060205459595\n",
      "mse 1.4745059802931888\n",
      "New best model found at epoch 184 with validation loss 1.4745060205459595\n",
      "Starting Epoch 185\n",
      "1.5720238296881965\n",
      "Validation loss: 1.4742951393127441\n",
      "mse 1.4742951917110132\n",
      "New best model found at epoch 185 with validation loss 1.4742951393127441\n",
      "Starting Epoch 186\n",
      "1.5715035459269648\n",
      "Validation loss: 1.4740138053894043\n",
      "mse 1.4740138028502325\n",
      "New best model found at epoch 186 with validation loss 1.4740138053894043\n",
      "Starting Epoch 187\n",
      "1.5709880849589473\n",
      "Validation loss: 1.4738028049468994\n",
      "mse 1.4738028369668794\n",
      "New best model found at epoch 187 with validation loss 1.4738028049468994\n",
      "Starting Epoch 188\n",
      "1.5704807250396065\n",
      "Validation loss: 1.4734973907470703\n",
      "mse 1.4734972798363941\n",
      "New best model found at epoch 188 with validation loss 1.4734973907470703\n",
      "Starting Epoch 189\n",
      "1.5699701438779416\n",
      "Validation loss: 1.4732619524002075\n",
      "mse 1.473261957025793\n",
      "New best model found at epoch 189 with validation loss 1.4732619524002075\n",
      "Starting Epoch 190\n",
      "1.5694820880889893\n",
      "Validation loss: 1.4730595350265503\n",
      "mse 1.4730594395205052\n",
      "New best model found at epoch 190 with validation loss 1.4730595350265503\n",
      "Starting Epoch 191\n",
      "1.5690032373303953\n",
      "Validation loss: 1.4727725982666016\n",
      "mse 1.4727725934098703\n",
      "New best model found at epoch 191 with validation loss 1.4727725982666016\n",
      "Starting Epoch 192\n",
      "1.5685823741166487\n",
      "Validation loss: 1.4724715948104858\n",
      "mse 1.4724715491781026\n",
      "New best model found at epoch 192 with validation loss 1.4724715948104858\n",
      "Starting Epoch 193\n",
      "1.5680070700852766\n",
      "Validation loss: 1.4724482297897339\n",
      "mse 1.4724480946496583\n",
      "New best model found at epoch 193 with validation loss 1.4724482297897339\n",
      "Starting Epoch 194\n",
      "1.567571399004563\n",
      "Validation loss: 1.47216796875\n",
      "mse 1.472168047827625\n",
      "New best model found at epoch 194 with validation loss 1.47216796875\n",
      "Starting Epoch 195\n",
      "1.5671661547992541\n",
      "Validation loss: 1.4718337059020996\n",
      "mse 1.4718336924367226\n",
      "New best model found at epoch 195 with validation loss 1.4718337059020996\n",
      "Starting Epoch 196\n",
      "1.5665911876637002\n",
      "Validation loss: 1.4717518091201782\n",
      "mse 1.4717516835315727\n",
      "New best model found at epoch 196 with validation loss 1.4717518091201782\n",
      "Starting Epoch 197\n",
      "1.5662243988202966\n",
      "Validation loss: 1.4714025259017944\n",
      "mse 1.4714024701029447\n",
      "New best model found at epoch 197 with validation loss 1.4714025259017944\n",
      "Starting Epoch 198\n",
      "1.565649574217589\n",
      "Validation loss: 1.4713190793991089\n",
      "mse 1.4713191510945451\n",
      "New best model found at epoch 198 with validation loss 1.4713190793991089\n",
      "Starting Epoch 199\n",
      "1.5652284725852634\n",
      "Validation loss: 1.471000075340271\n",
      "mse 1.4710000347208738\n",
      "New best model found at epoch 199 with validation loss 1.471000075340271\n",
      "Starting Epoch 200\n",
      "1.564833736937979\n",
      "Validation loss: 1.4706358909606934\n",
      "mse 1.4706359817624013\n",
      "New best model found at epoch 200 with validation loss 1.4706358909606934\n",
      "Starting Epoch 201\n",
      "1.5643571459728738\n",
      "Validation loss: 1.4704898595809937\n",
      "mse 1.470489870505979\n",
      "New best model found at epoch 201 with validation loss 1.4704898595809937\n",
      "Starting Epoch 202\n",
      "1.5638280847798223\n",
      "Validation loss: 1.4703949689865112\n",
      "mse 1.4703949665351208\n",
      "New best model found at epoch 202 with validation loss 1.4703949689865112\n",
      "Starting Epoch 203\n",
      "1.5634039044380188\n",
      "Validation loss: 1.4700429439544678\n",
      "mse 1.470042996413603\n",
      "New best model found at epoch 203 with validation loss 1.4700429439544678\n",
      "Starting Epoch 204\n",
      "1.5629462910735088\n",
      "Validation loss: 1.469835638999939\n",
      "mse 1.469835664901538\n",
      "New best model found at epoch 204 with validation loss 1.469835638999939\n",
      "Starting Epoch 205\n",
      "1.562507968881856\n",
      "Validation loss: 1.469604730606079\n",
      "mse 1.4696046911481888\n",
      "New best model found at epoch 205 with validation loss 1.469604730606079\n",
      "Starting Epoch 206\n",
      "1.562066324379133\n",
      "Validation loss: 1.4693207740783691\n",
      "mse 1.4693207788821219\n",
      "New best model found at epoch 206 with validation loss 1.4693207740783691\n",
      "Starting Epoch 207\n",
      "1.561698449694592\n",
      "Validation loss: 1.4690425395965576\n",
      "mse 1.4690426466932025\n",
      "New best model found at epoch 207 with validation loss 1.4690425395965576\n",
      "Starting Epoch 208\n",
      "1.5611650088559026\n",
      "Validation loss: 1.4689185619354248\n",
      "mse 1.468918530405892\n",
      "New best model found at epoch 208 with validation loss 1.4689185619354248\n",
      "Starting Epoch 209\n",
      "1.5607057498848957\n",
      "Validation loss: 1.4686757326126099\n",
      "mse 1.4686757176004177\n",
      "New best model found at epoch 209 with validation loss 1.4686757326126099\n",
      "Starting Epoch 210\n",
      "1.5604041244672693\n",
      "Validation loss: 1.468341588973999\n",
      "mse 1.468341581845642\n",
      "New best model found at epoch 210 with validation loss 1.468341588973999\n",
      "Starting Epoch 211\n",
      "1.5598548521166262\n",
      "Validation loss: 1.4682857990264893\n",
      "mse 1.4682859375729092\n",
      "New best model found at epoch 211 with validation loss 1.4682857990264893\n",
      "Starting Epoch 212\n",
      "1.559432379577471\n",
      "Validation loss: 1.468072772026062\n",
      "mse 1.4680727815287478\n",
      "New best model found at epoch 212 with validation loss 1.468072772026062\n",
      "Starting Epoch 213\n",
      "1.559101218762605\n",
      "Validation loss: 1.4677045345306396\n",
      "mse 1.4677042821380137\n",
      "New best model found at epoch 213 with validation loss 1.4677045345306396\n",
      "Starting Epoch 214\n",
      "1.5586438645487246\n",
      "Validation loss: 1.4676063060760498\n",
      "mse 1.467606342536355\n",
      "New best model found at epoch 214 with validation loss 1.4676063060760498\n",
      "Starting Epoch 215\n",
      "1.5581826075263645\n",
      "Validation loss: 1.467451810836792\n",
      "mse 1.4674517595384742\n",
      "New best model found at epoch 215 with validation loss 1.467451810836792\n",
      "Starting Epoch 216\n",
      "1.5578022055003955\n",
      "Validation loss: 1.467134952545166\n",
      "mse 1.4671349541800738\n",
      "New best model found at epoch 216 with validation loss 1.467134952545166\n",
      "Starting Epoch 217\n",
      "1.5573961086895154\n",
      "Validation loss: 1.4670032262802124\n",
      "mse 1.4670032315699162\n",
      "New best model found at epoch 217 with validation loss 1.4670032262802124\n",
      "Starting Epoch 218\n",
      "1.556980003481326\n",
      "Validation loss: 1.4668127298355103\n",
      "mse 1.4668128621123584\n",
      "New best model found at epoch 218 with validation loss 1.4668127298355103\n",
      "Starting Epoch 219\n",
      "1.5565687728964763\n",
      "Validation loss: 1.4666030406951904\n",
      "mse 1.4666032438946743\n",
      "New best model found at epoch 219 with validation loss 1.4666030406951904\n",
      "Starting Epoch 220\n",
      "1.5560753397319629\n",
      "Validation loss: 1.466494083404541\n",
      "mse 1.4664941394892952\n",
      "New best model found at epoch 220 with validation loss 1.466494083404541\n",
      "Starting Epoch 221\n",
      "1.55572851067004\n",
      "Validation loss: 1.4662055969238281\n",
      "mse 1.4662055729650203\n",
      "New best model found at epoch 221 with validation loss 1.4662055969238281\n",
      "Starting Epoch 222\n",
      "1.555347230123437\n",
      "Validation loss: 1.4659801721572876\n",
      "mse 1.4659800228462858\n",
      "New best model found at epoch 222 with validation loss 1.4659801721572876\n",
      "Starting Epoch 223\n",
      "1.5549488093542017\n",
      "Validation loss: 1.465856671333313\n",
      "mse 1.4658565425154144\n",
      "New best model found at epoch 223 with validation loss 1.465856671333313\n",
      "Starting Epoch 224\n",
      "1.5544858989508257\n",
      "Validation loss: 1.4656901359558105\n",
      "mse 1.465689980343968\n",
      "New best model found at epoch 224 with validation loss 1.4656901359558105\n",
      "Starting Epoch 225\n",
      "1.5541297586067864\n",
      "Validation loss: 1.4653816223144531\n",
      "mse 1.4653817649354597\n",
      "New best model found at epoch 225 with validation loss 1.4653816223144531\n",
      "Starting Epoch 226\n",
      "1.5536784451940786\n",
      "Validation loss: 1.4652546644210815\n",
      "mse 1.4652546202536159\n",
      "New best model found at epoch 226 with validation loss 1.4652546644210815\n",
      "Starting Epoch 227\n",
      "1.5533543669659158\n",
      "Validation loss: 1.4649022817611694\n",
      "mse 1.4649023260252805\n",
      "New best model found at epoch 227 with validation loss 1.4649022817611694\n",
      "Starting Epoch 228\n",
      "1.5529975942943408\n",
      "Validation loss: 1.4647526741027832\n",
      "mse 1.464752556605697\n",
      "New best model found at epoch 228 with validation loss 1.4647526741027832\n",
      "Starting Epoch 229\n",
      "1.552612050719883\n",
      "Validation loss: 1.4645442962646484\n",
      "mse 1.4645443670632179\n",
      "New best model found at epoch 229 with validation loss 1.4645442962646484\n",
      "Starting Epoch 230\n",
      "1.5521277215169824\n",
      "Validation loss: 1.464477300643921\n",
      "mse 1.4644774796989775\n",
      "New best model found at epoch 230 with validation loss 1.464477300643921\n",
      "Starting Epoch 231\n",
      "1.5518196354741636\n",
      "Validation loss: 1.464192271232605\n",
      "mse 1.4641921600497902\n",
      "New best model found at epoch 231 with validation loss 1.464192271232605\n",
      "Starting Epoch 232\n",
      "1.5514394433602043\n",
      "Validation loss: 1.4640017747879028\n",
      "mse 1.4640017549058855\n",
      "New best model found at epoch 232 with validation loss 1.4640017747879028\n",
      "Starting Epoch 233\n",
      "1.5510930963184522\n",
      "Validation loss: 1.4638376235961914\n",
      "mse 1.4638376987095343\n",
      "New best model found at epoch 233 with validation loss 1.4638376235961914\n",
      "Starting Epoch 234\n",
      "1.5507225238758584\n",
      "Validation loss: 1.4636526107788086\n",
      "mse 1.4636526597023765\n",
      "New best model found at epoch 234 with validation loss 1.4636526107788086\n",
      "Starting Epoch 235\n",
      "1.5502644181251526\n",
      "Validation loss: 1.463574767112732\n",
      "mse 1.4635748028637594\n",
      "New best model found at epoch 235 with validation loss 1.463574767112732\n",
      "Starting Epoch 236\n",
      "1.5499718163324439\n",
      "Validation loss: 1.463230848312378\n",
      "mse 1.4632308273118422\n",
      "New best model found at epoch 236 with validation loss 1.463230848312378\n",
      "Starting Epoch 237\n",
      "1.5495970948882725\n",
      "Validation loss: 1.4630986452102661\n",
      "mse 1.4630986530189445\n",
      "New best model found at epoch 237 with validation loss 1.4630986452102661\n",
      "Starting Epoch 238\n",
      "1.5491617192392764\n",
      "Validation loss: 1.4629714488983154\n",
      "mse 1.462971567792528\n",
      "New best model found at epoch 238 with validation loss 1.4629714488983154\n",
      "Starting Epoch 239\n",
      "1.5488366977028225\n",
      "Validation loss: 1.4627361297607422\n",
      "mse 1.4627362473833447\n",
      "New best model found at epoch 239 with validation loss 1.4627361297607422\n",
      "Starting Epoch 240\n",
      "1.5484728165294812\n",
      "Validation loss: 1.4625298976898193\n",
      "mse 1.4625297940863764\n",
      "New best model found at epoch 240 with validation loss 1.4625298976898193\n",
      "Starting Epoch 241\n",
      "1.5481801369915837\n",
      "Validation loss: 1.462264895439148\n",
      "mse 1.4622647780315032\n",
      "New best model found at epoch 241 with validation loss 1.462264895439148\n",
      "Starting Epoch 242\n",
      "1.5478267669677734\n",
      "Validation loss: 1.462200403213501\n",
      "mse 1.4622003311958431\n",
      "New best model found at epoch 242 with validation loss 1.462200403213501\n",
      "Starting Epoch 243\n",
      "1.5474439885305322\n",
      "Validation loss: 1.4620285034179688\n",
      "mse 1.4620284367655192\n",
      "New best model found at epoch 243 with validation loss 1.4620285034179688\n",
      "Starting Epoch 244\n",
      "1.5471221001251885\n",
      "Validation loss: 1.4619419574737549\n",
      "mse 1.461941978564356\n",
      "New best model found at epoch 244 with validation loss 1.4619419574737549\n",
      "Starting Epoch 245\n",
      "1.5467520433923472\n",
      "Validation loss: 1.4617609977722168\n",
      "mse 1.46176099458313\n",
      "New best model found at epoch 245 with validation loss 1.4617609977722168\n",
      "Starting Epoch 246\n",
      "1.5463994067648184\n",
      "Validation loss: 1.461655616760254\n",
      "mse 1.4616556975103376\n",
      "New best model found at epoch 246 with validation loss 1.461655616760254\n",
      "Starting Epoch 247\n",
      "1.5460412450458692\n",
      "Validation loss: 1.4614474773406982\n",
      "mse 1.4614472466276027\n",
      "New best model found at epoch 247 with validation loss 1.4614474773406982\n",
      "Starting Epoch 248\n",
      "1.545709358609241\n",
      "Validation loss: 1.461207389831543\n",
      "mse 1.46120726298037\n",
      "New best model found at epoch 248 with validation loss 1.461207389831543\n",
      "Starting Epoch 249\n",
      "1.5453445470851401\n",
      "Validation loss: 1.4610884189605713\n",
      "mse 1.4610884931740948\n",
      "New best model found at epoch 249 with validation loss 1.4610884189605713\n",
      "Starting Epoch 250\n",
      "1.5450038676676543\n",
      "Validation loss: 1.4609273672103882\n",
      "mse 1.4609273981445998\n",
      "New best model found at epoch 250 with validation loss 1.4609273672103882\n",
      "Starting Epoch 251\n",
      "1.544655390407728\n",
      "Validation loss: 1.4607584476470947\n",
      "mse 1.460758491119531\n",
      "New best model found at epoch 251 with validation loss 1.4607584476470947\n",
      "Starting Epoch 252\n",
      "1.5443111476690874\n",
      "Validation loss: 1.4605648517608643\n",
      "mse 1.460564995566916\n",
      "New best model found at epoch 252 with validation loss 1.4605648517608643\n",
      "Starting Epoch 253\n",
      "1.5439701520878335\n",
      "Validation loss: 1.4603383541107178\n",
      "mse 1.4603383108344923\n",
      "New best model found at epoch 253 with validation loss 1.4603383541107178\n",
      "Starting Epoch 254\n",
      "1.5436169971590457\n",
      "Validation loss: 1.460169792175293\n",
      "mse 1.4601696867687073\n",
      "New best model found at epoch 254 with validation loss 1.460169792175293\n",
      "Starting Epoch 255\n",
      "1.54329767693644\n",
      "Validation loss: 1.459978699684143\n",
      "mse 1.459978772475918\n",
      "New best model found at epoch 255 with validation loss 1.459978699684143\n",
      "Starting Epoch 256\n",
      "1.542935866376628\n",
      "Validation loss: 1.4596900939941406\n",
      "mse 1.4596900360317804\n",
      "New best model found at epoch 256 with validation loss 1.4596900939941406\n",
      "Starting Epoch 257\n",
      "1.542607421460359\n",
      "Validation loss: 1.4595235586166382\n",
      "mse 1.4595235801677862\n",
      "New best model found at epoch 257 with validation loss 1.4595235586166382\n",
      "Starting Epoch 258\n",
      "1.542255927687106\n",
      "Validation loss: 1.4593528509140015\n",
      "mse 1.4593527159863129\n",
      "New best model found at epoch 258 with validation loss 1.4593528509140015\n",
      "Starting Epoch 259\n",
      "1.5419245932413184\n",
      "Validation loss: 1.459169626235962\n",
      "mse 1.4591696510843264\n",
      "New best model found at epoch 259 with validation loss 1.459169626235962\n",
      "Starting Epoch 260\n",
      "1.541597923506861\n",
      "Validation loss: 1.4589635133743286\n",
      "mse 1.4589633541329206\n",
      "New best model found at epoch 260 with validation loss 1.4589635133743286\n",
      "Starting Epoch 261\n",
      "1.5412563655687415\n",
      "Validation loss: 1.4587507247924805\n",
      "mse 1.458750855168249\n",
      "New best model found at epoch 261 with validation loss 1.4587507247924805\n",
      "Starting Epoch 262\n",
      "1.5409431172453838\n",
      "Validation loss: 1.4585293531417847\n",
      "mse 1.458529390447362\n",
      "New best model found at epoch 262 with validation loss 1.4585293531417847\n",
      "Starting Epoch 263\n",
      "1.5406283088352368\n",
      "Validation loss: 1.4583667516708374\n",
      "mse 1.4583668401490113\n",
      "New best model found at epoch 263 with validation loss 1.4583667516708374\n",
      "Starting Epoch 264\n",
      "1.5402769031731978\n",
      "Validation loss: 1.4581799507141113\n",
      "mse 1.4581798788344136\n",
      "New best model found at epoch 264 with validation loss 1.4581799507141113\n",
      "Starting Epoch 265\n",
      "1.5399471650952878\n",
      "Validation loss: 1.4579615592956543\n",
      "mse 1.457961672542465\n",
      "New best model found at epoch 265 with validation loss 1.4579615592956543\n",
      "Starting Epoch 266\n",
      "1.539631136085676\n",
      "Validation loss: 1.457763433456421\n",
      "mse 1.457763390688587\n",
      "New best model found at epoch 266 with validation loss 1.457763433456421\n",
      "Starting Epoch 267\n",
      "1.539301820423292\n",
      "Validation loss: 1.4575762748718262\n",
      "mse 1.457576152869536\n",
      "New best model found at epoch 267 with validation loss 1.4575762748718262\n",
      "Starting Epoch 268\n",
      "1.538956318212592\n",
      "Validation loss: 1.457298994064331\n",
      "mse 1.4572990121616034\n",
      "New best model found at epoch 268 with validation loss 1.457298994064331\n",
      "Starting Epoch 269\n",
      "1.538683805776679\n",
      "Validation loss: 1.4570903778076172\n",
      "mse 1.4570903384127605\n",
      "New best model found at epoch 269 with validation loss 1.4570903778076172\n",
      "Starting Epoch 270\n",
      "1.538370819195457\n",
      "Validation loss: 1.4568804502487183\n",
      "mse 1.4568803779095398\n",
      "New best model found at epoch 270 with validation loss 1.4568804502487183\n",
      "Starting Epoch 271\n",
      "1.5380160419837288\n",
      "Validation loss: 1.4566950798034668\n",
      "mse 1.456695011953702\n",
      "New best model found at epoch 271 with validation loss 1.4566950798034668\n",
      "Starting Epoch 272\n",
      "1.53770853643832\n",
      "Validation loss: 1.4564844369888306\n",
      "mse 1.4564843275672579\n",
      "New best model found at epoch 272 with validation loss 1.4564844369888306\n",
      "Starting Epoch 273\n",
      "1.5374030600423398\n",
      "Validation loss: 1.4563400745391846\n",
      "mse 1.456339947447997\n",
      "New best model found at epoch 273 with validation loss 1.4563400745391846\n",
      "Starting Epoch 274\n",
      "1.5370883190113565\n",
      "Validation loss: 1.4561094045639038\n",
      "mse 1.4561093782742303\n",
      "New best model found at epoch 274 with validation loss 1.4561094045639038\n",
      "Starting Epoch 275\n",
      "1.5367754516394243\n",
      "Validation loss: 1.4559907913208008\n",
      "mse 1.4559908408549964\n",
      "New best model found at epoch 275 with validation loss 1.4559907913208008\n",
      "Starting Epoch 276\n",
      "1.5364767209343289\n",
      "Validation loss: 1.4557368755340576\n",
      "mse 1.4557367576690095\n",
      "New best model found at epoch 276 with validation loss 1.4557368755340576\n",
      "Starting Epoch 277\n",
      "1.5361697751542795\n",
      "Validation loss: 1.4556058645248413\n",
      "mse 1.4556058572362303\n",
      "New best model found at epoch 277 with validation loss 1.4556058645248413\n",
      "Starting Epoch 278\n",
      "1.5358648248340772\n",
      "Validation loss: 1.4553887844085693\n",
      "mse 1.455388840141944\n",
      "New best model found at epoch 278 with validation loss 1.4553887844085693\n",
      "Starting Epoch 279\n",
      "1.535563642564027\n",
      "Validation loss: 1.4552496671676636\n",
      "mse 1.4552497195311502\n",
      "New best model found at epoch 279 with validation loss 1.4552496671676636\n",
      "Starting Epoch 280\n",
      "1.535311670407005\n",
      "Validation loss: 1.4550502300262451\n",
      "mse 1.4550503484526383\n",
      "New best model found at epoch 280 with validation loss 1.4550502300262451\n",
      "Starting Epoch 281\n",
      "1.5349670959555584\n",
      "Validation loss: 1.4548996686935425\n",
      "mse 1.4548997126308658\n",
      "New best model found at epoch 281 with validation loss 1.4548996686935425\n",
      "Starting Epoch 282\n",
      "1.534657050733981\n",
      "Validation loss: 1.4547741413116455\n",
      "mse 1.4547741432135477\n",
      "New best model found at epoch 282 with validation loss 1.4547741413116455\n",
      "Starting Epoch 283\n",
      "1.5342898938966834\n",
      "Validation loss: 1.45466947555542\n",
      "mse 1.4546694778302112\n",
      "New best model found at epoch 283 with validation loss 1.45466947555542\n",
      "Starting Epoch 284\n",
      "1.5341451349465742\n",
      "Validation loss: 1.454351782798767\n",
      "mse 1.454351731831648\n",
      "New best model found at epoch 284 with validation loss 1.454351782798767\n",
      "Starting Epoch 285\n",
      "1.5337860169618025\n",
      "Validation loss: 1.4542045593261719\n",
      "mse 1.4542044301355332\n",
      "New best model found at epoch 285 with validation loss 1.4542045593261719\n",
      "Starting Epoch 286\n",
      "1.533525542072628\n",
      "Validation loss: 1.454038381576538\n",
      "mse 1.4540382474278588\n",
      "New best model found at epoch 286 with validation loss 1.454038381576538\n",
      "Starting Epoch 287\n",
      "1.5332083909407905\n",
      "Validation loss: 1.4538154602050781\n",
      "mse 1.4538154913678862\n",
      "New best model found at epoch 287 with validation loss 1.4538154602050781\n",
      "Starting Epoch 288\n",
      "1.5328593720560488\n",
      "Validation loss: 1.453724980354309\n",
      "mse 1.4537250386482297\n",
      "New best model found at epoch 288 with validation loss 1.453724980354309\n",
      "Starting Epoch 289\n",
      "1.5326861635498379\n",
      "Validation loss: 1.453432559967041\n",
      "mse 1.4534326150783543\n",
      "New best model found at epoch 289 with validation loss 1.453432559967041\n",
      "Starting Epoch 290\n",
      "1.5323648789654607\n",
      "Validation loss: 1.4532567262649536\n",
      "mse 1.4532568323086439\n",
      "New best model found at epoch 290 with validation loss 1.4532567262649536\n",
      "Starting Epoch 291\n",
      "1.5320599467858025\n",
      "Validation loss: 1.453125238418579\n",
      "mse 1.453125184911071\n",
      "New best model found at epoch 291 with validation loss 1.453125238418579\n",
      "Starting Epoch 292\n",
      "1.531834415767504\n",
      "Validation loss: 1.4528428316116333\n",
      "mse 1.4528426313928728\n",
      "New best model found at epoch 292 with validation loss 1.4528428316116333\n",
      "Starting Epoch 293\n",
      "1.531568978143775\n",
      "Validation loss: 1.4526723623275757\n",
      "mse 1.4526723500636298\n",
      "New best model found at epoch 293 with validation loss 1.4526723623275757\n",
      "Starting Epoch 294\n",
      "1.5311988203421882\n",
      "Validation loss: 1.4525113105773926\n",
      "mse 1.4525113982029112\n",
      "New best model found at epoch 294 with validation loss 1.4525113105773926\n",
      "Starting Epoch 295\n",
      "1.5310518586117288\n",
      "Validation loss: 1.4521664381027222\n",
      "mse 1.452166477935692\n",
      "New best model found at epoch 295 with validation loss 1.4521664381027222\n",
      "Starting Epoch 296\n",
      "1.530677575132121\n",
      "Validation loss: 1.4520472288131714\n",
      "mse 1.4520473347986984\n",
      "New best model found at epoch 296 with validation loss 1.4520472288131714\n",
      "Starting Epoch 297\n",
      "1.5304420253504878\n",
      "Validation loss: 1.4517165422439575\n",
      "mse 1.4517166144608504\n",
      "New best model found at epoch 297 with validation loss 1.4517165422439575\n",
      "Starting Epoch 298\n",
      "1.5301874590956646\n",
      "Validation loss: 1.4515033960342407\n",
      "mse 1.4515033539207396\n",
      "New best model found at epoch 298 with validation loss 1.4515033960342407\n",
      "Starting Epoch 299\n",
      "1.5299773630888567\n",
      "Validation loss: 1.4513212442398071\n",
      "mse 1.4513214020495504\n",
      "New best model found at epoch 299 with validation loss 1.4513212442398071\n",
      "Starting Epoch 300\n",
      "1.5295457943626072\n",
      "Validation loss: 1.4512184858322144\n",
      "mse 1.4512186189992535\n",
      "New best model found at epoch 300 with validation loss 1.4512184858322144\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-20-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225023a",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 4\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 25 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "09ddcc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "3c53eee6-4d3e-4614-aef5-55f857f19eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.14285641649495\n",
      "Validation loss: 2.6313953399658203\n",
      "mse 2.631395333581262\n",
      "New best model found at epoch 1 with validation loss 2.6313953399658203\n",
      "Starting Epoch 2\n",
      "2.9473894782688306\n",
      "Validation loss: 2.549868106842041\n",
      "mse 2.5498679334946406\n",
      "New best model found at epoch 2 with validation loss 2.549868106842041\n",
      "Starting Epoch 3\n",
      "2.851782824682153\n",
      "Validation loss: 2.4938950538635254\n",
      "mse 2.493895066361711\n",
      "New best model found at epoch 3 with validation loss 2.4938950538635254\n",
      "Starting Epoch 4\n",
      "2.7808364059614097\n",
      "Validation loss: 2.447866439819336\n",
      "mse 2.4478665448055397\n",
      "New best model found at epoch 4 with validation loss 2.447866439819336\n",
      "Starting Epoch 5\n",
      "2.720224282015925\n",
      "Validation loss: 2.404888868331909\n",
      "mse 2.404888950945691\n",
      "New best model found at epoch 5 with validation loss 2.404888868331909\n",
      "Starting Epoch 6\n",
      "2.6668888796930728\n",
      "Validation loss: 2.3650007247924805\n",
      "mse 2.3650006857567276\n",
      "New best model found at epoch 6 with validation loss 2.3650007247924805\n",
      "Starting Epoch 7\n",
      "2.61799448987712\n",
      "Validation loss: 2.3283135890960693\n",
      "mse 2.3283135157115433\n",
      "New best model found at epoch 7 with validation loss 2.3283135890960693\n",
      "Starting Epoch 8\n",
      "2.5729036123856255\n",
      "Validation loss: 2.2932474613189697\n",
      "mse 2.293247444535565\n",
      "New best model found at epoch 8 with validation loss 2.2932474613189697\n",
      "Starting Epoch 9\n",
      "2.5304784360139267\n",
      "Validation loss: 2.2597906589508057\n",
      "mse 2.2597904553591333\n",
      "New best model found at epoch 9 with validation loss 2.2597906589508057\n",
      "Starting Epoch 10\n",
      "2.4903416374455327\n",
      "Validation loss: 2.2278079986572266\n",
      "mse 2.227807836573052\n",
      "New best model found at epoch 10 with validation loss 2.2278079986572266\n",
      "Starting Epoch 11\n",
      "2.451890769212142\n",
      "Validation loss: 2.196831464767456\n",
      "mse 2.196831405821651\n",
      "New best model found at epoch 11 with validation loss 2.196831464767456\n",
      "Starting Epoch 12\n",
      "2.4158489030340444\n",
      "Validation loss: 2.167733669281006\n",
      "mse 2.1677336856181975\n",
      "New best model found at epoch 12 with validation loss 2.167733669281006\n",
      "Starting Epoch 13\n",
      "2.3816500383874644\n",
      "Validation loss: 2.140232563018799\n",
      "mse 2.140232268210292\n",
      "New best model found at epoch 13 with validation loss 2.140232563018799\n",
      "Starting Epoch 14\n",
      "2.349208785139996\n",
      "Validation loss: 2.113825798034668\n",
      "mse 2.1138258176826055\n",
      "New best model found at epoch 14 with validation loss 2.113825798034668\n",
      "Starting Epoch 15\n",
      "2.3188315681789233\n",
      "Validation loss: 2.088937997817993\n",
      "mse 2.0889380404669313\n",
      "New best model found at epoch 15 with validation loss 2.088937997817993\n",
      "Starting Epoch 16\n",
      "2.2897033587745996\n",
      "Validation loss: 2.065092086791992\n",
      "mse 2.0650921416487598\n",
      "New best model found at epoch 16 with validation loss 2.065092086791992\n",
      "Starting Epoch 17\n",
      "2.2620738019113955\n",
      "Validation loss: 2.0423848628997803\n",
      "mse 2.042384870327363\n",
      "New best model found at epoch 17 with validation loss 2.0423848628997803\n",
      "Starting Epoch 18\n",
      "2.235669866852138\n",
      "Validation loss: 2.0196001529693604\n",
      "mse 2.019600179306102\n",
      "New best model found at epoch 18 with validation loss 2.0196001529693604\n",
      "Starting Epoch 19\n",
      "2.210475398146588\n",
      "Validation loss: 1.999510407447815\n",
      "mse 1.9995103327183237\n",
      "New best model found at epoch 19 with validation loss 1.999510407447815\n",
      "Starting Epoch 20\n",
      "2.1867250981538193\n",
      "Validation loss: 1.9787602424621582\n",
      "mse 1.97876010465008\n",
      "New best model found at epoch 20 with validation loss 1.9787602424621582\n",
      "Starting Epoch 21\n",
      "2.163993400076161\n",
      "Validation loss: 1.9599792957305908\n",
      "mse 1.9599792655479875\n",
      "New best model found at epoch 21 with validation loss 1.9599792957305908\n",
      "Starting Epoch 22\n",
      "2.1419942378997803\n",
      "Validation loss: 1.9422601461410522\n",
      "mse 1.9422600710479923\n",
      "New best model found at epoch 22 with validation loss 1.9422601461410522\n",
      "Starting Epoch 23\n",
      "2.1214271161867226\n",
      "Validation loss: 1.9250298738479614\n",
      "mse 1.9250297214966428\n",
      "New best model found at epoch 23 with validation loss 1.9250298738479614\n",
      "Starting Epoch 24\n",
      "2.101577323416005\n",
      "Validation loss: 1.908475637435913\n",
      "mse 1.9084754457191508\n",
      "New best model found at epoch 24 with validation loss 1.908475637435913\n",
      "Starting Epoch 25\n",
      "2.0825013077777363\n",
      "Validation loss: 1.892137885093689\n",
      "mse 1.8921379918795007\n",
      "New best model found at epoch 25 with validation loss 1.892137885093689\n",
      "Starting Epoch 26\n",
      "2.0643647079882412\n",
      "Validation loss: 1.8772354125976562\n",
      "mse 1.8772355231825169\n",
      "New best model found at epoch 26 with validation loss 1.8772354125976562\n",
      "Starting Epoch 27\n",
      "2.0472323220709097\n",
      "Validation loss: 1.8633652925491333\n",
      "mse 1.863365374535284\n",
      "New best model found at epoch 27 with validation loss 1.8633652925491333\n",
      "Starting Epoch 28\n",
      "2.0308067280313242\n",
      "Validation loss: 1.849899172782898\n",
      "mse 1.8498991966106988\n",
      "New best model found at epoch 28 with validation loss 1.849899172782898\n",
      "Starting Epoch 29\n",
      "2.0154476943223374\n",
      "Validation loss: 1.8378015756607056\n",
      "mse 1.8378016230110314\n",
      "New best model found at epoch 29 with validation loss 1.8378015756607056\n",
      "Starting Epoch 30\n",
      "2.0007845059685083\n",
      "Validation loss: 1.8246705532073975\n",
      "mse 1.8246704488104655\n",
      "New best model found at epoch 30 with validation loss 1.8246705532073975\n",
      "Starting Epoch 31\n",
      "1.9866743606069814\n",
      "Validation loss: 1.8134965896606445\n",
      "mse 1.8134965117334845\n",
      "New best model found at epoch 31 with validation loss 1.8134965896606445\n",
      "Starting Epoch 32\n",
      "1.973189670106639\n",
      "Validation loss: 1.8023203611373901\n",
      "mse 1.802320385353224\n",
      "New best model found at epoch 32 with validation loss 1.8023203611373901\n",
      "Starting Epoch 33\n",
      "1.9602940808171812\n",
      "Validation loss: 1.7918919324874878\n",
      "mse 1.7918919672436255\n",
      "New best model found at epoch 33 with validation loss 1.7918919324874878\n",
      "Starting Epoch 34\n",
      "1.9479935272880222\n",
      "Validation loss: 1.7813518047332764\n",
      "mse 1.7813516873614859\n",
      "New best model found at epoch 34 with validation loss 1.7813518047332764\n",
      "Starting Epoch 35\n",
      "1.9361489907554958\n",
      "Validation loss: 1.7711858749389648\n",
      "mse 1.7711859664474223\n",
      "New best model found at epoch 35 with validation loss 1.7711858749389648\n",
      "Starting Epoch 36\n",
      "1.9247846603393555\n",
      "Validation loss: 1.7615787982940674\n",
      "mse 1.7615787676309886\n",
      "New best model found at epoch 36 with validation loss 1.7615787982940674\n",
      "Starting Epoch 37\n",
      "1.9139970281849736\n",
      "Validation loss: 1.751940369606018\n",
      "mse 1.7519401916182793\n",
      "New best model found at epoch 37 with validation loss 1.751940369606018\n",
      "Starting Epoch 38\n",
      "1.9035994799240776\n",
      "Validation loss: 1.7436307668685913\n",
      "mse 1.7436308114943166\n",
      "New best model found at epoch 38 with validation loss 1.7436307668685913\n",
      "Starting Epoch 39\n",
      "1.8936626859333203\n",
      "Validation loss: 1.7346657514572144\n",
      "mse 1.7346656589365415\n",
      "New best model found at epoch 39 with validation loss 1.7346657514572144\n",
      "Starting Epoch 40\n",
      "1.8835515250330386\n",
      "Validation loss: 1.725679874420166\n",
      "mse 1.725679775038839\n",
      "New best model found at epoch 40 with validation loss 1.725679874420166\n",
      "Starting Epoch 41\n",
      "1.8736573457717896\n",
      "Validation loss: 1.7177454233169556\n",
      "mse 1.7177452559499282\n",
      "New best model found at epoch 41 with validation loss 1.7177454233169556\n",
      "Starting Epoch 42\n",
      "1.8644070055173791\n",
      "Validation loss: 1.7098448276519775\n",
      "mse 1.709844878040402\n",
      "New best model found at epoch 42 with validation loss 1.7098448276519775\n",
      "Starting Epoch 43\n",
      "1.855442762374878\n",
      "Validation loss: 1.7026927471160889\n",
      "mse 1.7026927021165148\n",
      "New best model found at epoch 43 with validation loss 1.7026927471160889\n",
      "Starting Epoch 44\n",
      "1.8468088792717976\n",
      "Validation loss: 1.6957474946975708\n",
      "mse 1.6957474882763666\n",
      "New best model found at epoch 44 with validation loss 1.6957474946975708\n",
      "Starting Epoch 45\n",
      "1.8384979704151982\n",
      "Validation loss: 1.6893010139465332\n",
      "mse 1.6893008769540376\n",
      "New best model found at epoch 45 with validation loss 1.6893010139465332\n",
      "Starting Epoch 46\n",
      "1.830471862917361\n",
      "Validation loss: 1.6831752061843872\n",
      "mse 1.6831753216635044\n",
      "New best model found at epoch 46 with validation loss 1.6831752061843872\n",
      "Starting Epoch 47\n",
      "1.8225717389065286\n",
      "Validation loss: 1.6763629913330078\n",
      "mse 1.676362898898399\n",
      "New best model found at epoch 47 with validation loss 1.6763629913330078\n",
      "Starting Epoch 48\n",
      "1.8148816927619602\n",
      "Validation loss: 1.6694415807724\n",
      "mse 1.669441582763464\n",
      "New best model found at epoch 48 with validation loss 1.6694415807724\n",
      "Starting Epoch 49\n",
      "1.8073456650194915\n",
      "Validation loss: 1.6642247438430786\n",
      "mse 1.6642244528816288\n",
      "New best model found at epoch 49 with validation loss 1.6642247438430786\n",
      "Starting Epoch 50\n",
      "1.8002104033594546\n",
      "Validation loss: 1.6582636833190918\n",
      "mse 1.6582637343254014\n",
      "New best model found at epoch 50 with validation loss 1.6582636833190918\n",
      "Starting Epoch 51\n",
      "1.7934064450471296\n",
      "Validation loss: 1.6527903079986572\n",
      "mse 1.6527903486569229\n",
      "New best model found at epoch 51 with validation loss 1.6527903079986572\n",
      "Starting Epoch 52\n",
      "1.786855215611665\n",
      "Validation loss: 1.647647500038147\n",
      "mse 1.647647445568643\n",
      "New best model found at epoch 52 with validation loss 1.647647500038147\n",
      "Starting Epoch 53\n",
      "1.7806764530098957\n",
      "Validation loss: 1.6425949335098267\n",
      "mse 1.6425950367363595\n",
      "New best model found at epoch 53 with validation loss 1.6425949335098267\n",
      "Starting Epoch 54\n",
      "1.7745749172957048\n",
      "Validation loss: 1.6375044584274292\n",
      "mse 1.6375043746509288\n",
      "New best model found at epoch 54 with validation loss 1.6375044584274292\n",
      "Starting Epoch 55\n",
      "1.76874768215677\n",
      "Validation loss: 1.6327297687530518\n",
      "mse 1.6327298939411543\n",
      "New best model found at epoch 55 with validation loss 1.6327297687530518\n",
      "Starting Epoch 56\n",
      "1.7631912438765815\n",
      "Validation loss: 1.6282353401184082\n",
      "mse 1.6282353831295484\n",
      "New best model found at epoch 56 with validation loss 1.6282353401184082\n",
      "Starting Epoch 57\n",
      "1.7577596125395403\n",
      "Validation loss: 1.6235682964324951\n",
      "mse 1.6235683220870971\n",
      "New best model found at epoch 57 with validation loss 1.6235682964324951\n",
      "Starting Epoch 58\n",
      "1.7526725219643635\n",
      "Validation loss: 1.6195403337478638\n",
      "mse 1.619540343903501\n",
      "New best model found at epoch 58 with validation loss 1.6195403337478638\n",
      "Starting Epoch 59\n",
      "1.7477352878321772\n",
      "Validation loss: 1.6155531406402588\n",
      "mse 1.6155531646929715\n",
      "New best model found at epoch 59 with validation loss 1.6155531406402588\n",
      "Starting Epoch 60\n",
      "1.7429296918537305\n",
      "Validation loss: 1.6117750406265259\n",
      "mse 1.6117750736473542\n",
      "New best model found at epoch 60 with validation loss 1.6117750406265259\n",
      "Starting Epoch 61\n",
      "1.738246316495149\n",
      "Validation loss: 1.6080936193466187\n",
      "mse 1.608093621092505\n",
      "New best model found at epoch 61 with validation loss 1.6080936193466187\n",
      "Starting Epoch 62\n",
      "1.7337716973346213\n",
      "Validation loss: 1.604334831237793\n",
      "mse 1.6043346255442361\n",
      "New best model found at epoch 62 with validation loss 1.604334831237793\n",
      "Starting Epoch 63\n",
      "1.7294126852698948\n",
      "Validation loss: 1.6009477376937866\n",
      "mse 1.600947712864026\n",
      "New best model found at epoch 63 with validation loss 1.6009477376937866\n",
      "Starting Epoch 64\n",
      "1.7252943826758342\n",
      "Validation loss: 1.5975185632705688\n",
      "mse 1.5975185041344948\n",
      "New best model found at epoch 64 with validation loss 1.5975185632705688\n",
      "Starting Epoch 65\n",
      "1.7214099894399228\n",
      "Validation loss: 1.5946407318115234\n",
      "mse 1.5946407034540788\n",
      "New best model found at epoch 65 with validation loss 1.5946407318115234\n",
      "Starting Epoch 66\n",
      "1.7173305749893188\n",
      "Validation loss: 1.5915886163711548\n",
      "mse 1.5915886214715644\n",
      "New best model found at epoch 66 with validation loss 1.5915886163711548\n",
      "Starting Epoch 67\n",
      "1.7136710312055505\n",
      "Validation loss: 1.5887598991394043\n",
      "mse 1.5887597717399187\n",
      "New best model found at epoch 67 with validation loss 1.5887598991394043\n",
      "Starting Epoch 68\n",
      "1.7099318089692488\n",
      "Validation loss: 1.5857257843017578\n",
      "mse 1.5857257982371489\n",
      "New best model found at epoch 68 with validation loss 1.5857257843017578\n",
      "Starting Epoch 69\n",
      "1.7065780318301658\n",
      "Validation loss: 1.5831326246261597\n",
      "mse 1.5831326514299302\n",
      "New best model found at epoch 69 with validation loss 1.5831326246261597\n",
      "Starting Epoch 70\n",
      "1.7032387619433196\n",
      "Validation loss: 1.5808568000793457\n",
      "mse 1.5808567431471763\n",
      "New best model found at epoch 70 with validation loss 1.5808568000793457\n",
      "Starting Epoch 71\n",
      "1.6999561786651611\n",
      "Validation loss: 1.5782732963562012\n",
      "mse 1.578273344750358\n",
      "New best model found at epoch 71 with validation loss 1.5782732963562012\n",
      "Starting Epoch 72\n",
      "1.6969092721524446\n",
      "Validation loss: 1.5759638547897339\n",
      "mse 1.5759637874374524\n",
      "New best model found at epoch 72 with validation loss 1.5759638547897339\n",
      "Starting Epoch 73\n",
      "1.6938209637351658\n",
      "Validation loss: 1.5743454694747925\n",
      "mse 1.5743455715888712\n",
      "New best model found at epoch 73 with validation loss 1.5743454694747925\n",
      "Starting Epoch 74\n",
      "1.690834289011748\n",
      "Validation loss: 1.5723594427108765\n",
      "mse 1.5723594359501691\n",
      "New best model found at epoch 74 with validation loss 1.5723594427108765\n",
      "Starting Epoch 75\n",
      "1.6879428314126057\n",
      "Validation loss: 1.5696908235549927\n",
      "mse 1.5696907613132731\n",
      "New best model found at epoch 75 with validation loss 1.5696908235549927\n",
      "Starting Epoch 76\n",
      "1.685324129850968\n",
      "Validation loss: 1.567821741104126\n",
      "mse 1.5678218192844233\n",
      "New best model found at epoch 76 with validation loss 1.567821741104126\n",
      "Starting Epoch 77\n",
      "1.6825881004333496\n",
      "Validation loss: 1.565528392791748\n",
      "mse 1.565528438478465\n",
      "New best model found at epoch 77 with validation loss 1.565528392791748\n",
      "Starting Epoch 78\n",
      "1.6799375285273013\n",
      "Validation loss: 1.563571572303772\n",
      "mse 1.5635715145585392\n",
      "New best model found at epoch 78 with validation loss 1.563571572303772\n",
      "Starting Epoch 79\n",
      "1.6774227930151897\n",
      "Validation loss: 1.5618209838867188\n",
      "mse 1.5618210447847758\n",
      "New best model found at epoch 79 with validation loss 1.5618209838867188\n",
      "Starting Epoch 80\n",
      "1.6750719495441602\n",
      "Validation loss: 1.5600357055664062\n",
      "mse 1.560035564112326\n",
      "New best model found at epoch 80 with validation loss 1.5600357055664062\n",
      "Starting Epoch 81\n",
      "1.6728425751561704\n",
      "Validation loss: 1.5584908723831177\n",
      "mse 1.5584908767467098\n",
      "New best model found at epoch 81 with validation loss 1.5584908723831177\n",
      "Starting Epoch 82\n",
      "1.6705930129341457\n",
      "Validation loss: 1.5568296909332275\n",
      "mse 1.5568299348025139\n",
      "New best model found at epoch 82 with validation loss 1.5568296909332275\n",
      "Starting Epoch 83\n",
      "1.6684197031933328\n",
      "Validation loss: 1.5553420782089233\n",
      "mse 1.5553422121874736\n",
      "New best model found at epoch 83 with validation loss 1.5553420782089233\n",
      "Starting Epoch 84\n",
      "1.6663290884183801\n",
      "Validation loss: 1.553615927696228\n",
      "mse 1.5536159364875564\n",
      "New best model found at epoch 84 with validation loss 1.553615927696228\n",
      "Starting Epoch 85\n",
      "1.6643903514613276\n",
      "Validation loss: 1.552129864692688\n",
      "mse 1.552129894786751\n",
      "New best model found at epoch 85 with validation loss 1.552129864692688\n",
      "Starting Epoch 86\n",
      "1.6624216877895852\n",
      "Validation loss: 1.5505660772323608\n",
      "mse 1.5505661408705869\n",
      "New best model found at epoch 86 with validation loss 1.5505660772323608\n",
      "Starting Epoch 87\n",
      "1.6605314586473547\n",
      "Validation loss: 1.5491868257522583\n",
      "mse 1.5491869144696568\n",
      "New best model found at epoch 87 with validation loss 1.5491868257522583\n",
      "Starting Epoch 88\n",
      "1.6586634698121443\n",
      "Validation loss: 1.5477274656295776\n",
      "mse 1.547727297575527\n",
      "New best model found at epoch 88 with validation loss 1.5477274656295776\n",
      "Starting Epoch 89\n",
      "1.6567984041960344\n",
      "Validation loss: 1.5461759567260742\n",
      "mse 1.5461759816411351\n",
      "New best model found at epoch 89 with validation loss 1.5461759567260742\n",
      "Starting Epoch 90\n",
      "1.655042974845223\n",
      "Validation loss: 1.5448511838912964\n",
      "mse 1.5448513130511046\n",
      "New best model found at epoch 90 with validation loss 1.5448511838912964\n",
      "Starting Epoch 91\n",
      "1.653217533360357\n",
      "Validation loss: 1.543262243270874\n",
      "mse 1.543262163861634\n",
      "New best model found at epoch 91 with validation loss 1.543262243270874\n",
      "Starting Epoch 92\n",
      "1.6515798827876216\n",
      "Validation loss: 1.541844129562378\n",
      "mse 1.5418441631527031\n",
      "New best model found at epoch 92 with validation loss 1.541844129562378\n",
      "Starting Epoch 93\n",
      "1.649919665378073\n",
      "Validation loss: 1.5405927896499634\n",
      "mse 1.5405927592998185\n",
      "New best model found at epoch 93 with validation loss 1.5405927896499634\n",
      "Starting Epoch 94\n",
      "1.6482649471448816\n",
      "Validation loss: 1.5391511917114258\n",
      "mse 1.5391512500043583\n",
      "New best model found at epoch 94 with validation loss 1.5391511917114258\n",
      "Starting Epoch 95\n",
      "1.6466569019400554\n",
      "Validation loss: 1.5377954244613647\n",
      "mse 1.5377954497657036\n",
      "New best model found at epoch 95 with validation loss 1.5377954244613647\n",
      "Starting Epoch 96\n",
      "1.6450865942498911\n",
      "Validation loss: 1.5365488529205322\n",
      "mse 1.5365488757467518\n",
      "New best model found at epoch 96 with validation loss 1.5365488529205322\n",
      "Starting Epoch 97\n",
      "1.6435435906700466\n",
      "Validation loss: 1.5352001190185547\n",
      "mse 1.5352001266355608\n",
      "New best model found at epoch 97 with validation loss 1.5352001190185547\n",
      "Starting Epoch 98\n",
      "1.6420274921085523\n",
      "Validation loss: 1.5340479612350464\n",
      "mse 1.5340479176470585\n",
      "New best model found at epoch 98 with validation loss 1.5340479612350464\n",
      "Starting Epoch 99\n",
      "1.6405068584110425\n",
      "Validation loss: 1.532668113708496\n",
      "mse 1.5326681600678727\n",
      "New best model found at epoch 99 with validation loss 1.532668113708496\n",
      "Starting Epoch 100\n",
      "1.6390537541845571\n",
      "Validation loss: 1.5315343141555786\n",
      "mse 1.5315342468648914\n",
      "New best model found at epoch 100 with validation loss 1.5315343141555786\n",
      "Starting Epoch 101\n",
      "1.6375870393670124\n",
      "Validation loss: 1.5301212072372437\n",
      "mse 1.5301211751361683\n",
      "New best model found at epoch 101 with validation loss 1.5301212072372437\n",
      "Starting Epoch 102\n",
      "1.636165764020837\n",
      "Validation loss: 1.528903841972351\n",
      "mse 1.5289039749918314\n",
      "New best model found at epoch 102 with validation loss 1.528903841972351\n",
      "Starting Epoch 103\n",
      "1.6348330300787222\n",
      "Validation loss: 1.527966022491455\n",
      "mse 1.5279661341004445\n",
      "New best model found at epoch 103 with validation loss 1.527966022491455\n",
      "Starting Epoch 104\n",
      "1.633434570353964\n",
      "Validation loss: 1.5269871950149536\n",
      "mse 1.526987145914458\n",
      "New best model found at epoch 104 with validation loss 1.5269871950149536\n",
      "Starting Epoch 105\n",
      "1.6321455603060515\n",
      "Validation loss: 1.5260258913040161\n",
      "mse 1.5260258561335729\n",
      "New best model found at epoch 105 with validation loss 1.5260258913040161\n",
      "Starting Epoch 106\n",
      "1.6308712285497915\n",
      "Validation loss: 1.5249565839767456\n",
      "mse 1.5249566402259214\n",
      "New best model found at epoch 106 with validation loss 1.5249565839767456\n",
      "Starting Epoch 107\n",
      "1.6296238173609194\n",
      "Validation loss: 1.5239040851593018\n",
      "mse 1.5239039904268064\n",
      "New best model found at epoch 107 with validation loss 1.5239040851593018\n",
      "Starting Epoch 108\n",
      "1.628395650697791\n",
      "Validation loss: 1.5229880809783936\n",
      "mse 1.5229880580783355\n",
      "New best model found at epoch 108 with validation loss 1.5229880809783936\n",
      "Starting Epoch 109\n",
      "1.6271788400152456\n",
      "Validation loss: 1.5219013690948486\n",
      "mse 1.5219014336206689\n",
      "New best model found at epoch 109 with validation loss 1.5219013690948486\n",
      "Starting Epoch 110\n",
      "1.6260002022204192\n",
      "Validation loss: 1.5209206342697144\n",
      "mse 1.520920650533958\n",
      "New best model found at epoch 110 with validation loss 1.5209206342697144\n",
      "Starting Epoch 111\n",
      "1.62477018263029\n",
      "Validation loss: 1.5201908349990845\n",
      "mse 1.5201908039203214\n",
      "New best model found at epoch 111 with validation loss 1.5201908349990845\n",
      "Starting Epoch 112\n",
      "1.623682817687159\n",
      "Validation loss: 1.519094467163086\n",
      "mse 1.5190945209830216\n",
      "New best model found at epoch 112 with validation loss 1.519094467163086\n",
      "Starting Epoch 113\n",
      "1.622598824293717\n",
      "Validation loss: 1.5188474655151367\n",
      "mse 1.5188475493167548\n",
      "New best model found at epoch 113 with validation loss 1.5188474655151367\n",
      "Starting Epoch 114\n",
      "1.6214411362357761\n",
      "Validation loss: 1.51772940158844\n",
      "mse 1.5177294871226554\n",
      "New best model found at epoch 114 with validation loss 1.51772940158844\n",
      "Starting Epoch 115\n",
      "1.6204938007437664\n",
      "Validation loss: 1.51699960231781\n",
      "mse 1.516999603171063\n",
      "New best model found at epoch 115 with validation loss 1.51699960231781\n",
      "Starting Epoch 116\n",
      "1.6194363573323125\n",
      "Validation loss: 1.5161300897598267\n",
      "mse 1.5161299906049426\n",
      "New best model found at epoch 116 with validation loss 1.5161300897598267\n",
      "Starting Epoch 117\n",
      "1.6183160310206206\n",
      "Validation loss: 1.5159657001495361\n",
      "mse 1.515965580657967\n",
      "New best model found at epoch 117 with validation loss 1.5159657001495361\n",
      "Starting Epoch 118\n",
      "1.6173821169397105\n",
      "Validation loss: 1.5151569843292236\n",
      "mse 1.515156947270735\n",
      "New best model found at epoch 118 with validation loss 1.5151569843292236\n",
      "Starting Epoch 119\n",
      "1.6164357921351558\n",
      "Validation loss: 1.5142024755477905\n",
      "mse 1.5142025584528083\n",
      "New best model found at epoch 119 with validation loss 1.5142024755477905\n",
      "Starting Epoch 120\n",
      "1.6154718088067097\n",
      "Validation loss: 1.5139472484588623\n",
      "mse 1.5139473766004719\n",
      "New best model found at epoch 120 with validation loss 1.5139472484588623\n",
      "Starting Epoch 121\n",
      "1.6145786668943323\n",
      "Validation loss: 1.512821912765503\n",
      "mse 1.5128218745138389\n",
      "New best model found at epoch 121 with validation loss 1.512821912765503\n",
      "Starting Epoch 122\n",
      "1.6136417233425637\n",
      "Validation loss: 1.5126456022262573\n",
      "mse 1.5126457088684246\n",
      "New best model found at epoch 122 with validation loss 1.5126456022262573\n",
      "Starting Epoch 123\n",
      "1.612762689590454\n",
      "Validation loss: 1.511612892150879\n",
      "mse 1.5116127232973355\n",
      "New best model found at epoch 123 with validation loss 1.511612892150879\n",
      "Starting Epoch 124\n",
      "1.6118506504141765\n",
      "Validation loss: 1.511437177658081\n",
      "mse 1.511437275432393\n",
      "New best model found at epoch 124 with validation loss 1.511437177658081\n",
      "Starting Epoch 125\n",
      "1.6109723992969678\n",
      "Validation loss: 1.510898470878601\n",
      "mse 1.5108985144482794\n",
      "New best model found at epoch 125 with validation loss 1.510898470878601\n",
      "Starting Epoch 126\n",
      "1.6101583993953208\n",
      "Validation loss: 1.5099763870239258\n",
      "mse 1.509976445012761\n",
      "New best model found at epoch 126 with validation loss 1.5099763870239258\n",
      "Starting Epoch 127\n",
      "1.6092933234961138\n",
      "Validation loss: 1.5098307132720947\n",
      "mse 1.5098307818174783\n",
      "New best model found at epoch 127 with validation loss 1.5098307132720947\n",
      "Starting Epoch 128\n",
      "1.6084794117056804\n",
      "Validation loss: 1.5094650983810425\n",
      "mse 1.509464987043588\n",
      "New best model found at epoch 128 with validation loss 1.5094650983810425\n",
      "Starting Epoch 129\n",
      "1.6076957713002744\n",
      "Validation loss: 1.5089678764343262\n",
      "mse 1.508967899837649\n",
      "New best model found at epoch 129 with validation loss 1.5089678764343262\n",
      "Starting Epoch 130\n",
      "1.6069436747094858\n",
      "Validation loss: 1.5081734657287598\n",
      "mse 1.508173428561303\n",
      "New best model found at epoch 130 with validation loss 1.5081734657287598\n",
      "Starting Epoch 131\n",
      "1.606181422005529\n",
      "Validation loss: 1.508002519607544\n",
      "mse 1.5080024721868677\n",
      "New best model found at epoch 131 with validation loss 1.508002519607544\n",
      "Starting Epoch 132\n",
      "1.6054486710092295\n",
      "Validation loss: 1.5075350999832153\n",
      "mse 1.5075351157237344\n",
      "New best model found at epoch 132 with validation loss 1.5075350999832153\n",
      "Starting Epoch 133\n",
      "1.6047293414240298\n",
      "Validation loss: 1.5070903301239014\n",
      "mse 1.5070903230572223\n",
      "New best model found at epoch 133 with validation loss 1.5070903301239014\n",
      "Starting Epoch 134\n",
      "1.6040573171947314\n",
      "Validation loss: 1.5067459344863892\n",
      "mse 1.506745720970535\n",
      "New best model found at epoch 134 with validation loss 1.5067459344863892\n",
      "Starting Epoch 135\n",
      "1.603336012881735\n",
      "Validation loss: 1.506438136100769\n",
      "mse 1.5064382181159768\n",
      "New best model found at epoch 135 with validation loss 1.506438136100769\n",
      "Starting Epoch 136\n",
      "1.602631688117981\n",
      "Validation loss: 1.5059776306152344\n",
      "mse 1.5059776196348176\n",
      "New best model found at epoch 136 with validation loss 1.5059776306152344\n",
      "Starting Epoch 137\n",
      "1.6019714630168418\n",
      "Validation loss: 1.5057005882263184\n",
      "mse 1.5057004896977657\n",
      "New best model found at epoch 137 with validation loss 1.5057005882263184\n",
      "Starting Epoch 138\n",
      "1.6013294743454975\n",
      "Validation loss: 1.5052319765090942\n",
      "mse 1.5052320275396296\n",
      "New best model found at epoch 138 with validation loss 1.5052319765090942\n",
      "Starting Epoch 139\n",
      "1.6006658465965935\n",
      "Validation loss: 1.505002498626709\n",
      "mse 1.5050025216437843\n",
      "New best model found at epoch 139 with validation loss 1.505002498626709\n",
      "Starting Epoch 140\n",
      "1.6000744648601697\n",
      "Validation loss: 1.5044751167297363\n",
      "mse 1.5044751452646872\n",
      "New best model found at epoch 140 with validation loss 1.5044751167297363\n",
      "Starting Epoch 141\n",
      "1.5994758139485898\n",
      "Validation loss: 1.504152774810791\n",
      "mse 1.5041528517694773\n",
      "New best model found at epoch 141 with validation loss 1.504152774810791\n",
      "Starting Epoch 142\n",
      "1.5988701037738635\n",
      "Validation loss: 1.5038236379623413\n",
      "mse 1.5038237306407332\n",
      "New best model found at epoch 142 with validation loss 1.5038236379623413\n",
      "Starting Epoch 143\n",
      "1.5982039259827656\n",
      "Validation loss: 1.5035717487335205\n",
      "mse 1.503571625013323\n",
      "New best model found at epoch 143 with validation loss 1.5035717487335205\n",
      "Starting Epoch 144\n",
      "1.5975834830947544\n",
      "Validation loss: 1.5031377077102661\n",
      "mse 1.5031376784337056\n",
      "New best model found at epoch 144 with validation loss 1.5031377077102661\n",
      "Starting Epoch 145\n",
      "1.597035006336544\n",
      "Validation loss: 1.5027778148651123\n",
      "mse 1.5027779448968315\n",
      "New best model found at epoch 145 with validation loss 1.5027778148651123\n",
      "Starting Epoch 146\n",
      "1.5964446249215498\n",
      "Validation loss: 1.5024006366729736\n",
      "mse 1.502400710325208\n",
      "New best model found at epoch 146 with validation loss 1.5024006366729736\n",
      "Starting Epoch 147\n",
      "1.5958661566609922\n",
      "Validation loss: 1.5020464658737183\n",
      "mse 1.5020465852984244\n",
      "New best model found at epoch 147 with validation loss 1.5020464658737183\n",
      "Starting Epoch 148\n",
      "1.5952258550602456\n",
      "Validation loss: 1.5017706155776978\n",
      "mse 1.501770771735689\n",
      "New best model found at epoch 148 with validation loss 1.5017706155776978\n",
      "Starting Epoch 149\n",
      "1.594637489837149\n",
      "Validation loss: 1.5012308359146118\n",
      "mse 1.5012308963618115\n",
      "New best model found at epoch 149 with validation loss 1.5012308359146118\n",
      "Starting Epoch 150\n",
      "1.5940848200217537\n",
      "Validation loss: 1.500970721244812\n",
      "mse 1.5009706541169134\n",
      "New best model found at epoch 150 with validation loss 1.500970721244812\n",
      "Starting Epoch 151\n",
      "1.5935666198315828\n",
      "Validation loss: 1.5005311965942383\n",
      "mse 1.5005312419960768\n",
      "New best model found at epoch 151 with validation loss 1.5005311965942383\n",
      "Starting Epoch 152\n",
      "1.5930357679076816\n",
      "Validation loss: 1.5001771450042725\n",
      "mse 1.500176991028129\n",
      "New best model found at epoch 152 with validation loss 1.5001771450042725\n",
      "Starting Epoch 153\n",
      "1.5924938761669656\n",
      "Validation loss: 1.4998584985733032\n",
      "mse 1.4998585679493006\n",
      "New best model found at epoch 153 with validation loss 1.4998584985733032\n",
      "Starting Epoch 154\n",
      "1.591902372629746\n",
      "Validation loss: 1.4995951652526855\n",
      "mse 1.499595127134719\n",
      "New best model found at epoch 154 with validation loss 1.4995951652526855\n",
      "Starting Epoch 155\n",
      "1.5914173514946648\n",
      "Validation loss: 1.4993548393249512\n",
      "mse 1.499354790585687\n",
      "New best model found at epoch 155 with validation loss 1.4993548393249512\n",
      "Starting Epoch 156\n",
      "1.5908533334732056\n",
      "Validation loss: 1.4992657899856567\n",
      "mse 1.4992657741249023\n",
      "New best model found at epoch 156 with validation loss 1.4992657899856567\n",
      "Starting Epoch 157\n",
      "1.5903755400491797\n",
      "Validation loss: 1.49893319606781\n",
      "mse 1.4989332000800841\n",
      "New best model found at epoch 157 with validation loss 1.49893319606781\n",
      "Starting Epoch 158\n",
      "1.5898945046507793\n",
      "Validation loss: 1.4985219240188599\n",
      "mse 1.4985220340502496\n",
      "New best model found at epoch 158 with validation loss 1.4985219240188599\n",
      "Starting Epoch 159\n",
      "1.5893857271774956\n",
      "Validation loss: 1.4985300302505493\n",
      "mse 1.4985300396331638\n",
      "Starting Epoch 160\n",
      "1.588883410329404\n",
      "Validation loss: 1.4978727102279663\n",
      "mse 1.4978726286360353\n",
      "New best model found at epoch 160 with validation loss 1.4978727102279663\n",
      "Starting Epoch 161\n",
      "1.5883874063906462\n",
      "Validation loss: 1.4978504180908203\n",
      "mse 1.4978504567047508\n",
      "New best model found at epoch 161 with validation loss 1.4978504180908203\n",
      "Starting Epoch 162\n",
      "1.5879521758660027\n",
      "Validation loss: 1.4973393678665161\n",
      "mse 1.4973393071027254\n",
      "New best model found at epoch 162 with validation loss 1.4973393678665161\n",
      "Starting Epoch 163\n",
      "1.587503176668416\n",
      "Validation loss: 1.4970656633377075\n",
      "mse 1.4970655086590965\n",
      "New best model found at epoch 163 with validation loss 1.4970656633377075\n",
      "Starting Epoch 164\n",
      "1.587026790432308\n",
      "Validation loss: 1.4968714714050293\n",
      "mse 1.4968714709884723\n",
      "New best model found at epoch 164 with validation loss 1.4968714714050293\n",
      "Starting Epoch 165\n",
      "1.5865026841992917\n",
      "Validation loss: 1.4965949058532715\n",
      "mse 1.4965949724635241\n",
      "New best model found at epoch 165 with validation loss 1.4965949058532715\n",
      "Starting Epoch 166\n",
      "1.5860561961713044\n",
      "Validation loss: 1.4962127208709717\n",
      "mse 1.4962126818066717\n",
      "New best model found at epoch 166 with validation loss 1.4962127208709717\n",
      "Starting Epoch 167\n",
      "1.5855657095494478\n",
      "Validation loss: 1.4959354400634766\n",
      "mse 1.4959355212668983\n",
      "New best model found at epoch 167 with validation loss 1.4959354400634766\n",
      "Starting Epoch 168\n",
      "1.5851554067238518\n",
      "Validation loss: 1.4956296682357788\n",
      "mse 1.4956297333817101\n",
      "New best model found at epoch 168 with validation loss 1.4956296682357788\n",
      "Starting Epoch 169\n",
      "1.5847181055856787\n",
      "Validation loss: 1.4953378438949585\n",
      "mse 1.495337745999796\n",
      "New best model found at epoch 169 with validation loss 1.4953378438949585\n",
      "Starting Epoch 170\n",
      "1.5842618164808855\n",
      "Validation loss: 1.4951502084732056\n",
      "mse 1.495150180295848\n",
      "New best model found at epoch 170 with validation loss 1.4951502084732056\n",
      "Starting Epoch 171\n",
      "1.5838625094164973\n",
      "Validation loss: 1.4948046207427979\n",
      "mse 1.4948047570937728\n",
      "New best model found at epoch 171 with validation loss 1.4948046207427979\n",
      "Starting Epoch 172\n",
      "1.583439948766128\n",
      "Validation loss: 1.494678258895874\n",
      "mse 1.4946782088303834\n",
      "New best model found at epoch 172 with validation loss 1.494678258895874\n",
      "Starting Epoch 173\n",
      "1.5829943211182305\n",
      "Validation loss: 1.4945030212402344\n",
      "mse 1.4945029751746277\n",
      "New best model found at epoch 173 with validation loss 1.4945030212402344\n",
      "Starting Epoch 174\n",
      "1.5826366466024648\n",
      "Validation loss: 1.494093656539917\n",
      "mse 1.4940935553145915\n",
      "New best model found at epoch 174 with validation loss 1.494093656539917\n",
      "Starting Epoch 175\n",
      "1.5821598509083623\n",
      "Validation loss: 1.4938929080963135\n",
      "mse 1.493892863020237\n",
      "New best model found at epoch 175 with validation loss 1.4938929080963135\n",
      "Starting Epoch 176\n",
      "1.5818296282187752\n",
      "Validation loss: 1.4936213493347168\n",
      "mse 1.4936213272358396\n",
      "New best model found at epoch 176 with validation loss 1.4936213493347168\n",
      "Starting Epoch 177\n",
      "1.5814540386199951\n",
      "Validation loss: 1.4933511018753052\n",
      "mse 1.493351057843617\n",
      "New best model found at epoch 177 with validation loss 1.4933511018753052\n",
      "Starting Epoch 178\n",
      "1.5810148119926453\n",
      "Validation loss: 1.4931575059890747\n",
      "mse 1.493157501980889\n",
      "New best model found at epoch 178 with validation loss 1.4931575059890747\n",
      "Starting Epoch 179\n",
      "1.580613242543262\n",
      "Validation loss: 1.4930353164672852\n",
      "mse 1.4930352915660274\n",
      "New best model found at epoch 179 with validation loss 1.4930353164672852\n",
      "Starting Epoch 180\n",
      "1.5802131917165674\n",
      "Validation loss: 1.4928189516067505\n",
      "mse 1.4928189543214452\n",
      "New best model found at epoch 180 with validation loss 1.4928189516067505\n",
      "Starting Epoch 181\n",
      "1.5799188173335532\n",
      "Validation loss: 1.492369294166565\n",
      "mse 1.4923694002823207\n",
      "New best model found at epoch 181 with validation loss 1.492369294166565\n",
      "Starting Epoch 182\n",
      "1.5795400194499805\n",
      "Validation loss: 1.4921913146972656\n",
      "mse 1.4921914148409676\n",
      "New best model found at epoch 182 with validation loss 1.4921913146972656\n",
      "Starting Epoch 183\n",
      "1.5791113661683125\n",
      "Validation loss: 1.4921420812606812\n",
      "mse 1.4921421135995903\n",
      "New best model found at epoch 183 with validation loss 1.4921420812606812\n",
      "Starting Epoch 184\n",
      "1.5787162029224893\n",
      "Validation loss: 1.4918510913848877\n",
      "mse 1.491851041326778\n",
      "New best model found at epoch 184 with validation loss 1.4918510913848877\n",
      "Starting Epoch 185\n",
      "1.5783720120139744\n",
      "Validation loss: 1.4913734197616577\n",
      "mse 1.4913734781418153\n",
      "New best model found at epoch 185 with validation loss 1.4913734197616577\n",
      "Starting Epoch 186\n",
      "1.5780298606209133\n",
      "Validation loss: 1.491241455078125\n",
      "mse 1.491241584922619\n",
      "New best model found at epoch 186 with validation loss 1.491241455078125\n",
      "Starting Epoch 187\n",
      "1.5776271094446597\n",
      "Validation loss: 1.4911977052688599\n",
      "mse 1.49119766585263\n",
      "New best model found at epoch 187 with validation loss 1.4911977052688599\n",
      "Starting Epoch 188\n",
      "1.5772732807242351\n",
      "Validation loss: 1.490661859512329\n",
      "mse 1.490661824370165\n",
      "New best model found at epoch 188 with validation loss 1.490661859512329\n",
      "Starting Epoch 189\n",
      "1.5768975278605586\n",
      "Validation loss: 1.490704894065857\n",
      "mse 1.4907050198522378\n",
      "Starting Epoch 190\n",
      "1.576549955036329\n",
      "Validation loss: 1.490338683128357\n",
      "mse 1.4903386221738675\n",
      "New best model found at epoch 190 with validation loss 1.490338683128357\n",
      "Starting Epoch 191\n",
      "1.5761632997056712\n",
      "Validation loss: 1.4903243780136108\n",
      "mse 1.490324558629145\n",
      "New best model found at epoch 191 with validation loss 1.4903243780136108\n",
      "Starting Epoch 192\n",
      "1.5758192616960276\n",
      "Validation loss: 1.4898144006729126\n",
      "mse 1.4898145231345412\n",
      "New best model found at epoch 192 with validation loss 1.4898144006729126\n",
      "Starting Epoch 193\n",
      "1.5754279934841653\n",
      "Validation loss: 1.4897631406784058\n",
      "mse 1.489763200395415\n",
      "New best model found at epoch 193 with validation loss 1.4897631406784058\n",
      "Starting Epoch 194\n",
      "1.5751162741495215\n",
      "Validation loss: 1.4893999099731445\n",
      "mse 1.4894000121330817\n",
      "New best model found at epoch 194 with validation loss 1.4893999099731445\n",
      "Starting Epoch 195\n",
      "1.5747393732485564\n",
      "Validation loss: 1.4893194437026978\n",
      "mse 1.48931945263316\n",
      "New best model found at epoch 195 with validation loss 1.4893194437026978\n",
      "Starting Epoch 196\n",
      "1.5743978567745374\n",
      "Validation loss: 1.4889591932296753\n",
      "mse 1.4889591664556368\n",
      "New best model found at epoch 196 with validation loss 1.4889591932296753\n",
      "Starting Epoch 197\n",
      "1.5739885620448901\n",
      "Validation loss: 1.4888856410980225\n",
      "mse 1.4888856124294538\n",
      "New best model found at epoch 197 with validation loss 1.4888856410980225\n",
      "Starting Epoch 198\n",
      "1.573672908803691\n",
      "Validation loss: 1.4883763790130615\n",
      "mse 1.4883765492333205\n",
      "New best model found at epoch 198 with validation loss 1.4883763790130615\n",
      "Starting Epoch 199\n",
      "1.5733336728552114\n",
      "Validation loss: 1.488203763961792\n",
      "mse 1.4882037318341947\n",
      "New best model found at epoch 199 with validation loss 1.488203763961792\n",
      "Starting Epoch 200\n",
      "1.5729509306990581\n",
      "Validation loss: 1.488173484802246\n",
      "mse 1.4881735900226736\n",
      "New best model found at epoch 200 with validation loss 1.488173484802246\n",
      "Starting Epoch 201\n",
      "1.5726192800895027\n",
      "Validation loss: 1.4877166748046875\n",
      "mse 1.4877165648835402\n",
      "New best model found at epoch 201 with validation loss 1.4877166748046875\n",
      "Starting Epoch 202\n",
      "1.5722441699193872\n",
      "Validation loss: 1.4876869916915894\n",
      "mse 1.487686875522419\n",
      "New best model found at epoch 202 with validation loss 1.4876869916915894\n",
      "Starting Epoch 203\n",
      "1.5719286980836287\n",
      "Validation loss: 1.4872411489486694\n",
      "mse 1.4872412853997832\n",
      "New best model found at epoch 203 with validation loss 1.4872411489486694\n",
      "Starting Epoch 204\n",
      "1.5715683880059614\n",
      "Validation loss: 1.4871845245361328\n",
      "mse 1.4871844981676217\n",
      "New best model found at epoch 204 with validation loss 1.4871845245361328\n",
      "Starting Epoch 205\n",
      "1.5712492932444033\n",
      "Validation loss: 1.4867242574691772\n",
      "mse 1.486724258296017\n",
      "New best model found at epoch 205 with validation loss 1.4867242574691772\n",
      "Starting Epoch 206\n",
      "1.5708955033965732\n",
      "Validation loss: 1.4867814779281616\n",
      "mse 1.486781442928334\n",
      "Starting Epoch 207\n",
      "1.570575053277223\n",
      "Validation loss: 1.4863404035568237\n",
      "mse 1.486340277446251\n",
      "New best model found at epoch 207 with validation loss 1.4863404035568237\n",
      "Starting Epoch 208\n",
      "1.5702102987662605\n",
      "Validation loss: 1.4863011837005615\n",
      "mse 1.4863011988485035\n",
      "New best model found at epoch 208 with validation loss 1.4863011837005615\n",
      "Starting Epoch 209\n",
      "1.5699105314586475\n",
      "Validation loss: 1.4859064817428589\n",
      "mse 1.4859064548107155\n",
      "New best model found at epoch 209 with validation loss 1.4859064817428589\n",
      "Starting Epoch 210\n",
      "1.5695645575938018\n",
      "Validation loss: 1.48593008518219\n",
      "mse 1.4859301300413332\n",
      "Starting Epoch 211\n",
      "1.5692519441894863\n",
      "Validation loss: 1.4855616092681885\n",
      "mse 1.4855616371711298\n",
      "New best model found at epoch 211 with validation loss 1.4855616092681885\n",
      "Starting Epoch 212\n",
      "1.568919275117957\n",
      "Validation loss: 1.485628366470337\n",
      "mse 1.485628353792954\n",
      "Starting Epoch 213\n",
      "1.568595139876656\n",
      "Validation loss: 1.4853923320770264\n",
      "mse 1.4853923414412553\n",
      "New best model found at epoch 213 with validation loss 1.4853923320770264\n",
      "Starting Epoch 214\n",
      "1.5681904502536939\n",
      "Validation loss: 1.485507607460022\n",
      "mse 1.4855075548923673\n",
      "Starting Epoch 215\n",
      "1.5678266753321108\n",
      "Validation loss: 1.4850903749465942\n",
      "mse 1.4850905417700961\n",
      "New best model found at epoch 215 with validation loss 1.4850903749465942\n",
      "Starting Epoch 216\n",
      "1.5674676610075908\n",
      "Validation loss: 1.4850225448608398\n",
      "mse 1.485022432178258\n",
      "New best model found at epoch 216 with validation loss 1.4850225448608398\n",
      "Starting Epoch 217\n",
      "1.5671727683233179\n",
      "Validation loss: 1.4845846891403198\n",
      "mse 1.4845845683664423\n",
      "New best model found at epoch 217 with validation loss 1.4845846891403198\n",
      "Starting Epoch 218\n",
      "1.5668429343596748\n",
      "Validation loss: 1.484639286994934\n",
      "mse 1.4846392802593094\n",
      "Starting Epoch 219\n",
      "1.566487781379534\n",
      "Validation loss: 1.4843579530715942\n",
      "mse 1.4843578974003049\n",
      "New best model found at epoch 219 with validation loss 1.4843579530715942\n",
      "Starting Epoch 220\n",
      "1.566141066343888\n",
      "Validation loss: 1.484387993812561\n",
      "mse 1.4843882252700276\n",
      "Starting Epoch 221\n",
      "1.5658831622289575\n",
      "Validation loss: 1.4839149713516235\n",
      "mse 1.4839149057685856\n",
      "New best model found at epoch 221 with validation loss 1.4839149713516235\n",
      "Starting Epoch 222\n",
      "1.565533469552579\n",
      "Validation loss: 1.4838401079177856\n",
      "mse 1.4838401547574709\n",
      "New best model found at epoch 222 with validation loss 1.4838401079177856\n",
      "Starting Epoch 223\n",
      "1.5652216983878093\n",
      "Validation loss: 1.4835597276687622\n",
      "mse 1.4835596750273488\n",
      "New best model found at epoch 223 with validation loss 1.4835597276687622\n",
      "Starting Epoch 224\n",
      "1.5648935333542202\n",
      "Validation loss: 1.4834238290786743\n",
      "mse 1.4834237506472159\n",
      "New best model found at epoch 224 with validation loss 1.4834238290786743\n",
      "Starting Epoch 225\n",
      "1.5645656482033108\n",
      "Validation loss: 1.4833216667175293\n",
      "mse 1.483321677702314\n",
      "New best model found at epoch 225 with validation loss 1.4833216667175293\n",
      "Starting Epoch 226\n",
      "1.5642727250638215\n",
      "Validation loss: 1.4829249382019043\n",
      "mse 1.4829249325735325\n",
      "New best model found at epoch 226 with validation loss 1.4829249382019043\n",
      "Starting Epoch 227\n",
      "1.563967940600022\n",
      "Validation loss: 1.4829707145690918\n",
      "mse 1.4829706137200722\n",
      "Starting Epoch 228\n",
      "1.5636390084805696\n",
      "Validation loss: 1.4824936389923096\n",
      "mse 1.4824938077653902\n",
      "New best model found at epoch 228 with validation loss 1.4824936389923096\n",
      "Starting Epoch 229\n",
      "1.563322233117145\n",
      "Validation loss: 1.4824738502502441\n",
      "mse 1.48247373989903\n",
      "New best model found at epoch 229 with validation loss 1.4824738502502441\n",
      "Starting Epoch 230\n",
      "1.5630430060884226\n",
      "Validation loss: 1.4822032451629639\n",
      "mse 1.482203357026745\n",
      "New best model found at epoch 230 with validation loss 1.4822032451629639\n",
      "Starting Epoch 231\n",
      "1.5627259327017742\n",
      "Validation loss: 1.4822020530700684\n",
      "mse 1.4822021641984986\n",
      "New best model found at epoch 231 with validation loss 1.4822020530700684\n",
      "Starting Epoch 232\n",
      "1.562440081782963\n",
      "Validation loss: 1.4817005395889282\n",
      "mse 1.4817007501715425\n",
      "New best model found at epoch 232 with validation loss 1.4817005395889282\n",
      "Starting Epoch 233\n",
      "1.5621222361274387\n",
      "Validation loss: 1.4817103147506714\n",
      "mse 1.481710393569996\n",
      "Starting Epoch 234\n",
      "1.5618767556936846\n",
      "Validation loss: 1.481488823890686\n",
      "mse 1.4814888256309535\n",
      "New best model found at epoch 234 with validation loss 1.481488823890686\n",
      "Starting Epoch 235\n",
      "1.5615266328272612\n",
      "Validation loss: 1.4813827276229858\n",
      "mse 1.481382522120914\n",
      "New best model found at epoch 235 with validation loss 1.4813827276229858\n",
      "Starting Epoch 236\n",
      "1.5612766975941865\n",
      "Validation loss: 1.4810235500335693\n",
      "mse 1.4810233867203688\n",
      "New best model found at epoch 236 with validation loss 1.4810235500335693\n",
      "Starting Epoch 237\n",
      "1.5609794362731602\n",
      "Validation loss: 1.481174111366272\n",
      "mse 1.481174117182628\n",
      "Starting Epoch 238\n",
      "1.5607385298480159\n",
      "Validation loss: 1.4808332920074463\n",
      "mse 1.4808333372804423\n",
      "New best model found at epoch 238 with validation loss 1.4808332920074463\n",
      "Starting Epoch 239\n",
      "1.5604251960049504\n",
      "Validation loss: 1.4809447526931763\n",
      "mse 1.4809447293114737\n",
      "Starting Epoch 240\n",
      "1.5601489543914795\n",
      "Validation loss: 1.4805482625961304\n",
      "mse 1.4805483597399371\n",
      "New best model found at epoch 240 with validation loss 1.4805482625961304\n",
      "Starting Epoch 241\n",
      "1.5598758459091187\n",
      "Validation loss: 1.4806294441223145\n",
      "mse 1.4806296278475686\n",
      "Starting Epoch 242\n",
      "1.5596132174782131\n",
      "Validation loss: 1.4803848266601562\n",
      "mse 1.4803847079136365\n",
      "New best model found at epoch 242 with validation loss 1.4803848266601562\n",
      "Starting Epoch 243\n",
      "1.5593136523080908\n",
      "Validation loss: 1.480407476425171\n",
      "mse 1.4804074514146008\n",
      "Starting Epoch 244\n",
      "1.5590758220009182\n",
      "Validation loss: 1.4801043272018433\n",
      "mse 1.4801043836978867\n",
      "New best model found at epoch 244 with validation loss 1.4801043272018433\n",
      "Starting Epoch 245\n",
      "1.5588022781454998\n",
      "Validation loss: 1.48009192943573\n",
      "mse 1.4800920955763857\n",
      "New best model found at epoch 245 with validation loss 1.48009192943573\n",
      "Starting Epoch 246\n",
      "1.5585283662961877\n",
      "Validation loss: 1.4798153638839722\n",
      "mse 1.4798154057667612\n",
      "New best model found at epoch 246 with validation loss 1.4798153638839722\n",
      "Starting Epoch 247\n",
      "1.5582246080688809\n",
      "Validation loss: 1.4798166751861572\n",
      "mse 1.4798167880344544\n",
      "Starting Epoch 248\n",
      "1.5580021168874658\n",
      "Validation loss: 1.479478359222412\n",
      "mse 1.4794784057455228\n",
      "New best model found at epoch 248 with validation loss 1.479478359222412\n",
      "Starting Epoch 249\n",
      "1.557703850061997\n",
      "Validation loss: 1.4794384241104126\n",
      "mse 1.4794384413638102\n",
      "New best model found at epoch 249 with validation loss 1.4794384241104126\n",
      "Starting Epoch 250\n",
      "1.5574732189593108\n",
      "Validation loss: 1.4791808128356934\n",
      "mse 1.4791806941479135\n",
      "New best model found at epoch 250 with validation loss 1.4791808128356934\n",
      "Starting Epoch 251\n",
      "1.557131914988808\n",
      "Validation loss: 1.479131817817688\n",
      "mse 1.4791318497029455\n",
      "New best model found at epoch 251 with validation loss 1.479131817817688\n",
      "Starting Epoch 252\n",
      "1.5568909360014873\n",
      "Validation loss: 1.478764533996582\n",
      "mse 1.4787645059348322\n",
      "New best model found at epoch 252 with validation loss 1.478764533996582\n",
      "Starting Epoch 253\n",
      "1.5566126963366633\n",
      "Validation loss: 1.4788025617599487\n",
      "mse 1.478802412460786\n",
      "Starting Epoch 254\n",
      "1.556372300438259\n",
      "Validation loss: 1.4785311222076416\n",
      "mse 1.4785310934073455\n",
      "New best model found at epoch 254 with validation loss 1.4785311222076416\n",
      "Starting Epoch 255\n",
      "1.556075500405353\n",
      "Validation loss: 1.4784725904464722\n",
      "mse 1.4784725773417078\n",
      "New best model found at epoch 255 with validation loss 1.4784725904464722\n",
      "Starting Epoch 256\n",
      "1.555845294309699\n",
      "Validation loss: 1.4781829118728638\n",
      "mse 1.4781828881649532\n",
      "New best model found at epoch 256 with validation loss 1.4781829118728638\n",
      "Starting Epoch 257\n",
      "1.5555526769679526\n",
      "Validation loss: 1.4781763553619385\n",
      "mse 1.4781763539521648\n",
      "New best model found at epoch 257 with validation loss 1.4781763553619385\n",
      "Starting Epoch 258\n",
      "1.55532278444456\n",
      "Validation loss: 1.477872610092163\n",
      "mse 1.4778723977400257\n",
      "New best model found at epoch 258 with validation loss 1.477872610092163\n",
      "Starting Epoch 259\n",
      "1.5550280887147654\n",
      "Validation loss: 1.4778834581375122\n",
      "mse 1.4778835288246162\n",
      "Starting Epoch 260\n",
      "1.5548006607138591\n",
      "Validation loss: 1.4775716066360474\n",
      "mse 1.4775716098120457\n",
      "New best model found at epoch 260 with validation loss 1.4775716066360474\n",
      "Starting Epoch 261\n",
      "1.5544893741607666\n",
      "Validation loss: 1.4775590896606445\n",
      "mse 1.4775591195486688\n",
      "New best model found at epoch 261 with validation loss 1.4775590896606445\n",
      "Starting Epoch 262\n",
      "1.5542771997659102\n",
      "Validation loss: 1.4772896766662598\n",
      "mse 1.477289576923743\n",
      "New best model found at epoch 262 with validation loss 1.4772896766662598\n",
      "Starting Epoch 263\n",
      "1.5539864457171897\n",
      "Validation loss: 1.4772579669952393\n",
      "mse 1.4772579398545402\n",
      "New best model found at epoch 263 with validation loss 1.4772579669952393\n",
      "Starting Epoch 264\n",
      "1.5537547339563784\n",
      "Validation loss: 1.476974368095398\n",
      "mse 1.476974422086478\n",
      "New best model found at epoch 264 with validation loss 1.476974368095398\n",
      "Starting Epoch 265\n",
      "1.553476888200511\n",
      "Validation loss: 1.4769138097763062\n",
      "mse 1.4769136641975777\n",
      "New best model found at epoch 265 with validation loss 1.4769138097763062\n",
      "Starting Epoch 266\n",
      "1.5532740458198215\n",
      "Validation loss: 1.4766695499420166\n",
      "mse 1.4766694195237722\n",
      "New best model found at epoch 266 with validation loss 1.4766695499420166\n",
      "Starting Epoch 267\n",
      "1.5529792775278506\n",
      "Validation loss: 1.4766663312911987\n",
      "mse 1.4766661806989174\n",
      "New best model found at epoch 267 with validation loss 1.4766663312911987\n",
      "Starting Epoch 268\n",
      "1.5527376688045005\n",
      "Validation loss: 1.4763706922531128\n",
      "mse 1.4763707743608518\n",
      "New best model found at epoch 268 with validation loss 1.4763706922531128\n",
      "Starting Epoch 269\n",
      "1.5524642882139787\n",
      "Validation loss: 1.476305603981018\n",
      "mse 1.4763054845463204\n",
      "New best model found at epoch 269 with validation loss 1.476305603981018\n",
      "Starting Epoch 270\n",
      "1.5522753907286602\n",
      "Validation loss: 1.476056456565857\n",
      "mse 1.4760564282970787\n",
      "New best model found at epoch 270 with validation loss 1.476056456565857\n",
      "Starting Epoch 271\n",
      "1.5520031607669333\n",
      "Validation loss: 1.4760353565216064\n",
      "mse 1.4760354106318312\n",
      "New best model found at epoch 271 with validation loss 1.4760353565216064\n",
      "Starting Epoch 272\n",
      "1.5517940806305928\n",
      "Validation loss: 1.4758532047271729\n",
      "mse 1.4758531148751055\n",
      "New best model found at epoch 272 with validation loss 1.4758532047271729\n",
      "Starting Epoch 273\n",
      "1.5514848284099414\n",
      "Validation loss: 1.4757771492004395\n",
      "mse 1.4757772065903296\n",
      "New best model found at epoch 273 with validation loss 1.4757771492004395\n",
      "Starting Epoch 274\n",
      "1.5512830951939458\n",
      "Validation loss: 1.4754893779754639\n",
      "mse 1.4754893752715983\n",
      "New best model found at epoch 274 with validation loss 1.4754893779754639\n",
      "Starting Epoch 275\n",
      "1.5510225010954815\n",
      "Validation loss: 1.4754658937454224\n",
      "mse 1.4754657675853355\n",
      "New best model found at epoch 275 with validation loss 1.4754658937454224\n",
      "Starting Epoch 276\n",
      "1.5508151339448017\n",
      "Validation loss: 1.4752291440963745\n",
      "mse 1.4752291627784548\n",
      "New best model found at epoch 276 with validation loss 1.4752291440963745\n",
      "Starting Epoch 277\n",
      "1.5505588598873303\n",
      "Validation loss: 1.4752222299575806\n",
      "mse 1.4752222957028385\n",
      "New best model found at epoch 277 with validation loss 1.4752222299575806\n",
      "Starting Epoch 278\n",
      "1.5503321626911992\n",
      "Validation loss: 1.474953293800354\n",
      "mse 1.4749532861189731\n",
      "New best model found at epoch 278 with validation loss 1.474953293800354\n",
      "Starting Epoch 279\n",
      "1.5500750023385752\n",
      "Validation loss: 1.4750072956085205\n",
      "mse 1.4750072764011233\n",
      "Starting Epoch 280\n",
      "1.549881611181342\n",
      "Validation loss: 1.4747035503387451\n",
      "mse 1.4747036098806077\n",
      "New best model found at epoch 280 with validation loss 1.4747035503387451\n",
      "Starting Epoch 281\n",
      "1.5496099902235942\n",
      "Validation loss: 1.4747177362442017\n",
      "mse 1.4747177224295593\n",
      "Starting Epoch 282\n",
      "1.5493908291277678\n",
      "Validation loss: 1.4744057655334473\n",
      "mse 1.4744057721103179\n",
      "New best model found at epoch 282 with validation loss 1.4744057655334473\n",
      "Starting Epoch 283\n",
      "1.549147649951603\n",
      "Validation loss: 1.474427580833435\n",
      "mse 1.4744275422378423\n",
      "Starting Epoch 284\n",
      "1.5489384557889856\n",
      "Validation loss: 1.4741833209991455\n",
      "mse 1.4741834333640287\n",
      "New best model found at epoch 284 with validation loss 1.4741833209991455\n",
      "Starting Epoch 285\n",
      "1.5486770790556204\n",
      "Validation loss: 1.4741307497024536\n",
      "mse 1.4741307839076525\n",
      "New best model found at epoch 285 with validation loss 1.4741307497024536\n",
      "Starting Epoch 286\n",
      "1.5484933879064477\n",
      "Validation loss: 1.4738918542861938\n",
      "mse 1.4738918038990345\n",
      "New best model found at epoch 286 with validation loss 1.4738918542861938\n",
      "Starting Epoch 287\n",
      "1.5482422553974649\n",
      "Validation loss: 1.4739586114883423\n",
      "mse 1.4739586355630905\n",
      "Starting Epoch 288\n",
      "1.5480245118555815\n",
      "Validation loss: 1.4736740589141846\n",
      "mse 1.4736740620954272\n",
      "New best model found at epoch 288 with validation loss 1.4736740589141846\n",
      "Starting Epoch 289\n",
      "1.5477977731953496\n",
      "Validation loss: 1.473497986793518\n",
      "mse 1.473498181138684\n",
      "New best model found at epoch 289 with validation loss 1.473497986793518\n",
      "Starting Epoch 290\n",
      "1.547559486783069\n",
      "Validation loss: 1.4735971689224243\n",
      "mse 1.4735971023439538\n",
      "Starting Epoch 291\n",
      "1.5473563075065613\n",
      "Validation loss: 1.4732915163040161\n",
      "mse 1.4732915949293617\n",
      "New best model found at epoch 291 with validation loss 1.4732915163040161\n",
      "Starting Epoch 292\n",
      "1.5471005647078804\n",
      "Validation loss: 1.4732826948165894\n",
      "mse 1.4732826159835364\n",
      "New best model found at epoch 292 with validation loss 1.4732826948165894\n",
      "Starting Epoch 293\n",
      "1.5469229558239812\n",
      "Validation loss: 1.473028302192688\n",
      "mse 1.473028177858568\n",
      "New best model found at epoch 293 with validation loss 1.473028302192688\n",
      "Starting Epoch 294\n",
      "1.5466587802638179\n",
      "Validation loss: 1.4730113744735718\n",
      "mse 1.4730112716365165\n",
      "New best model found at epoch 294 with validation loss 1.4730113744735718\n",
      "Starting Epoch 295\n",
      "1.5464821483777917\n",
      "Validation loss: 1.4727668762207031\n",
      "mse 1.472766878996067\n",
      "New best model found at epoch 295 with validation loss 1.4727668762207031\n",
      "Starting Epoch 296\n",
      "1.5462266595467278\n",
      "Validation loss: 1.472829818725586\n",
      "mse 1.4728299171840722\n",
      "Starting Epoch 297\n",
      "1.5460402369499207\n",
      "Validation loss: 1.4725478887557983\n",
      "mse 1.4725479317202599\n",
      "New best model found at epoch 297 with validation loss 1.4725478887557983\n",
      "Starting Epoch 298\n",
      "1.5457842971967615\n",
      "Validation loss: 1.4725149869918823\n",
      "mse 1.4725149272438998\n",
      "New best model found at epoch 298 with validation loss 1.4725149869918823\n",
      "Starting Epoch 299\n",
      "1.5456122704174207\n",
      "Validation loss: 1.4722826480865479\n",
      "mse 1.4722826914659672\n",
      "New best model found at epoch 299 with validation loss 1.4722826480865479\n",
      "Starting Epoch 300\n",
      "1.5453980746476546\n",
      "Validation loss: 1.4721629619598389\n",
      "mse 1.4721629674657482\n",
      "New best model found at epoch 300 with validation loss 1.4721629619598389\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-25-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65049334",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 5\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 40 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "1ef1b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "ebefd968-738d-4bba-a2b9-fcda275aa43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.1247104043545932\n",
      "Validation loss: 2.639878749847412\n",
      "mse 2.639878827438641\n",
      "New best model found at epoch 1 with validation loss 2.639878749847412\n",
      "Starting Epoch 2\n",
      "2.8840987215871396\n",
      "Validation loss: 2.5483808517456055\n",
      "mse 2.5483808273634128\n",
      "New best model found at epoch 2 with validation loss 2.5483808517456055\n",
      "Starting Epoch 3\n",
      "2.790303815966067\n",
      "Validation loss: 2.484009265899658\n",
      "mse 2.4840092792735695\n",
      "New best model found at epoch 3 with validation loss 2.484009265899658\n",
      "Starting Epoch 4\n",
      "2.719596826511881\n",
      "Validation loss: 2.4287729263305664\n",
      "mse 2.428773248411862\n",
      "New best model found at epoch 4 with validation loss 2.4287729263305664\n",
      "Starting Epoch 5\n",
      "2.6582773509232895\n",
      "Validation loss: 2.378891706466675\n",
      "mse 2.378891703648685\n",
      "New best model found at epoch 5 with validation loss 2.378891706466675\n",
      "Starting Epoch 6\n",
      "2.6034304007239966\n",
      "Validation loss: 2.3334243297576904\n",
      "mse 2.3334242899122977\n",
      "New best model found at epoch 6 with validation loss 2.3334243297576904\n",
      "Starting Epoch 7\n",
      "2.5527863709822944\n",
      "Validation loss: 2.290822744369507\n",
      "mse 2.2908225419415102\n",
      "New best model found at epoch 7 with validation loss 2.290822744369507\n",
      "Starting Epoch 8\n",
      "2.506601281788038\n",
      "Validation loss: 2.2513396739959717\n",
      "mse 2.2513399758775208\n",
      "New best model found at epoch 8 with validation loss 2.2513396739959717\n",
      "Starting Epoch 9\n",
      "2.4638253813204556\n",
      "Validation loss: 2.2147045135498047\n",
      "mse 2.2147045190836585\n",
      "New best model found at epoch 9 with validation loss 2.2147045135498047\n",
      "Starting Epoch 10\n",
      "2.4238418703493863\n",
      "Validation loss: 2.180536985397339\n",
      "mse 2.1805370235927946\n",
      "New best model found at epoch 10 with validation loss 2.180536985397339\n",
      "Starting Epoch 11\n",
      "2.386538863182068\n",
      "Validation loss: 2.148615598678589\n",
      "mse 2.148615769473612\n",
      "New best model found at epoch 11 with validation loss 2.148615598678589\n",
      "Starting Epoch 12\n",
      "2.3517474661702695\n",
      "Validation loss: 2.1182861328125\n",
      "mse 2.118286123595683\n",
      "New best model found at epoch 12 with validation loss 2.1182861328125\n",
      "Starting Epoch 13\n",
      "2.318987276243127\n",
      "Validation loss: 2.0901758670806885\n",
      "mse 2.090175865544823\n",
      "New best model found at epoch 13 with validation loss 2.0901758670806885\n",
      "Starting Epoch 14\n",
      "2.288526633511419\n",
      "Validation loss: 2.0635573863983154\n",
      "mse 2.063557336434478\n",
      "New best model found at epoch 14 with validation loss 2.0635573863983154\n",
      "Starting Epoch 15\n",
      "2.2599244687868203\n",
      "Validation loss: 2.039482831954956\n",
      "mse 2.0394828827785267\n",
      "New best model found at epoch 15 with validation loss 2.039482831954956\n",
      "Starting Epoch 16\n",
      "2.2333078747210293\n",
      "Validation loss: 2.016024351119995\n",
      "mse 2.016024237058788\n",
      "New best model found at epoch 16 with validation loss 2.016024351119995\n",
      "Starting Epoch 17\n",
      "2.2080180023027505\n",
      "Validation loss: 1.9944778680801392\n",
      "mse 1.9944778153340563\n",
      "New best model found at epoch 17 with validation loss 1.9944778680801392\n",
      "Starting Epoch 18\n",
      "2.1842279278713725\n",
      "Validation loss: 1.9739463329315186\n",
      "mse 1.9739463738597118\n",
      "New best model found at epoch 18 with validation loss 1.9739463329315186\n",
      "Starting Epoch 19\n",
      "2.161748414454253\n",
      "Validation loss: 1.954376459121704\n",
      "mse 1.954376497525372\n",
      "New best model found at epoch 19 with validation loss 1.954376459121704\n",
      "Starting Epoch 20\n",
      "2.1396226468293564\n",
      "Validation loss: 1.9354313611984253\n",
      "mse 1.9354313131298455\n",
      "New best model found at epoch 20 with validation loss 1.9354313611984253\n",
      "Starting Epoch 21\n",
      "2.1173849209495215\n",
      "Validation loss: 1.9177958965301514\n",
      "mse 1.9177958711441905\n",
      "New best model found at epoch 21 with validation loss 1.9177958965301514\n",
      "Starting Epoch 22\n",
      "2.096750155739162\n",
      "Validation loss: 1.9013142585754395\n",
      "mse 1.9013142149361497\n",
      "New best model found at epoch 22 with validation loss 1.9013142585754395\n",
      "Starting Epoch 23\n",
      "2.0776092384172524\n",
      "Validation loss: 1.885953664779663\n",
      "mse 1.885953625432707\n",
      "New best model found at epoch 23 with validation loss 1.885953664779663\n",
      "Starting Epoch 24\n",
      "2.0594338956086533\n",
      "Validation loss: 1.8710252046585083\n",
      "mse 1.8710251606129173\n",
      "New best model found at epoch 24 with validation loss 1.8710252046585083\n",
      "Starting Epoch 25\n",
      "2.0423073405804844\n",
      "Validation loss: 1.8567248582839966\n",
      "mse 1.856725057929902\n",
      "New best model found at epoch 25 with validation loss 1.8567248582839966\n",
      "Starting Epoch 26\n",
      "2.026065670925638\n",
      "Validation loss: 1.8432608842849731\n",
      "mse 1.8432608327163187\n",
      "New best model found at epoch 26 with validation loss 1.8432608842849731\n",
      "Starting Epoch 27\n",
      "2.010600209236145\n",
      "Validation loss: 1.8302479982376099\n",
      "mse 1.8302481290022765\n",
      "New best model found at epoch 27 with validation loss 1.8302479982376099\n",
      "Starting Epoch 28\n",
      "1.9958351435868635\n",
      "Validation loss: 1.8180627822875977\n",
      "mse 1.8180628783849493\n",
      "New best model found at epoch 28 with validation loss 1.8180627822875977\n",
      "Starting Epoch 29\n",
      "1.9817591387292612\n",
      "Validation loss: 1.8065074682235718\n",
      "mse 1.80650767741143\n",
      "New best model found at epoch 29 with validation loss 1.8065074682235718\n",
      "Starting Epoch 30\n",
      "1.9682746451833975\n",
      "Validation loss: 1.7952524423599243\n",
      "mse 1.7952526347110378\n",
      "New best model found at epoch 30 with validation loss 1.7952524423599243\n",
      "Starting Epoch 31\n",
      "1.9552756029626597\n",
      "Validation loss: 1.7847332954406738\n",
      "mse 1.7847332950571564\n",
      "New best model found at epoch 31 with validation loss 1.7847332954406738\n",
      "Starting Epoch 32\n",
      "1.9426716669746067\n",
      "Validation loss: 1.7748305797576904\n",
      "mse 1.7748305297145341\n",
      "New best model found at epoch 32 with validation loss 1.7748305797576904\n",
      "Starting Epoch 33\n",
      "1.9306995868682861\n",
      "Validation loss: 1.7653568983078003\n",
      "mse 1.76535689015104\n",
      "New best model found at epoch 33 with validation loss 1.7653568983078003\n",
      "Starting Epoch 34\n",
      "1.9192795390668123\n",
      "Validation loss: 1.7565059661865234\n",
      "mse 1.7565061363000725\n",
      "New best model found at epoch 34 with validation loss 1.7565059661865234\n",
      "Starting Epoch 35\n",
      "1.9083078633184019\n",
      "Validation loss: 1.747806429862976\n",
      "mse 1.7478063918880329\n",
      "New best model found at epoch 35 with validation loss 1.747806429862976\n",
      "Starting Epoch 36\n",
      "1.8979679397914722\n",
      "Validation loss: 1.7394933700561523\n",
      "mse 1.7394933667319563\n",
      "New best model found at epoch 36 with validation loss 1.7394933700561523\n",
      "Starting Epoch 37\n",
      "1.8879781235819277\n",
      "Validation loss: 1.7317464351654053\n",
      "mse 1.7317464827546338\n",
      "New best model found at epoch 37 with validation loss 1.7317464351654053\n",
      "Starting Epoch 38\n",
      "1.878761623216712\n",
      "Validation loss: 1.724163293838501\n",
      "mse 1.7241633041372102\n",
      "New best model found at epoch 38 with validation loss 1.724163293838501\n",
      "Starting Epoch 39\n",
      "1.8700494040613589\n",
      "Validation loss: 1.7171605825424194\n",
      "mse 1.7171605526229157\n",
      "New best model found at epoch 39 with validation loss 1.7171605825424194\n",
      "Starting Epoch 40\n",
      "1.8618905285130376\n",
      "Validation loss: 1.7102069854736328\n",
      "mse 1.7102071998920167\n",
      "New best model found at epoch 40 with validation loss 1.7102069854736328\n",
      "Starting Epoch 41\n",
      "1.854053512863491\n",
      "Validation loss: 1.7038285732269287\n",
      "mse 1.7038285944729483\n",
      "New best model found at epoch 41 with validation loss 1.7038285732269287\n",
      "Starting Epoch 42\n",
      "1.8466588103252908\n",
      "Validation loss: 1.6973888874053955\n",
      "mse 1.6973887901744307\n",
      "New best model found at epoch 42 with validation loss 1.6973888874053955\n",
      "Starting Epoch 43\n",
      "1.8394964518754378\n",
      "Validation loss: 1.6913307905197144\n",
      "mse 1.6913308086186973\n",
      "New best model found at epoch 43 with validation loss 1.6913307905197144\n",
      "Starting Epoch 44\n",
      "1.8326268247936084\n",
      "Validation loss: 1.6854641437530518\n",
      "mse 1.6854642186595472\n",
      "New best model found at epoch 44 with validation loss 1.6854641437530518\n",
      "Starting Epoch 45\n",
      "1.8259265370990918\n",
      "Validation loss: 1.680153489112854\n",
      "mse 1.6801534186476819\n",
      "New best model found at epoch 45 with validation loss 1.680153489112854\n",
      "Starting Epoch 46\n",
      "1.8195036597873853\n",
      "Validation loss: 1.6745702028274536\n",
      "mse 1.6745701189932396\n",
      "New best model found at epoch 46 with validation loss 1.6745702028274536\n",
      "Starting Epoch 47\n",
      "1.8131588127302087\n",
      "Validation loss: 1.6691899299621582\n",
      "mse 1.6691900081048656\n",
      "New best model found at epoch 47 with validation loss 1.6691899299621582\n",
      "Starting Epoch 48\n",
      "1.8070648234823476\n",
      "Validation loss: 1.6641987562179565\n",
      "mse 1.6641989125872967\n",
      "New best model found at epoch 48 with validation loss 1.6641987562179565\n",
      "Starting Epoch 49\n",
      "1.801270640414694\n",
      "Validation loss: 1.6596876382827759\n",
      "mse 1.659687612541766\n",
      "New best model found at epoch 49 with validation loss 1.6596876382827759\n",
      "Starting Epoch 50\n",
      "1.795814177264338\n",
      "Validation loss: 1.655143141746521\n",
      "mse 1.6551432124297785\n",
      "New best model found at epoch 50 with validation loss 1.655143141746521\n",
      "Starting Epoch 51\n",
      "1.7905129453410273\n",
      "Validation loss: 1.6505488157272339\n",
      "mse 1.6505488823079162\n",
      "New best model found at epoch 51 with validation loss 1.6505488157272339\n",
      "Starting Epoch 52\n",
      "1.785471859185592\n",
      "Validation loss: 1.6466162204742432\n",
      "mse 1.6466162864583567\n",
      "New best model found at epoch 52 with validation loss 1.6466162204742432\n",
      "Starting Epoch 53\n",
      "1.7808070130970166\n",
      "Validation loss: 1.6428375244140625\n",
      "mse 1.6428374620673536\n",
      "New best model found at epoch 53 with validation loss 1.6428375244140625\n",
      "Starting Epoch 54\n",
      "1.7763236709263013\n",
      "Validation loss: 1.6394823789596558\n",
      "mse 1.6394825050792017\n",
      "New best model found at epoch 54 with validation loss 1.6394823789596558\n",
      "Starting Epoch 55\n",
      "1.7720361222391543\n",
      "Validation loss: 1.636121153831482\n",
      "mse 1.6361211086567902\n",
      "New best model found at epoch 55 with validation loss 1.636121153831482\n",
      "Starting Epoch 56\n",
      "1.767885068188543\n",
      "Validation loss: 1.6327913999557495\n",
      "mse 1.6327914296149146\n",
      "New best model found at epoch 56 with validation loss 1.6327913999557495\n",
      "Starting Epoch 57\n",
      "1.7639391111290974\n",
      "Validation loss: 1.629514217376709\n",
      "mse 1.629514240282569\n",
      "New best model found at epoch 57 with validation loss 1.629514217376709\n",
      "Starting Epoch 58\n",
      "1.7601546308268672\n",
      "Validation loss: 1.6265476942062378\n",
      "mse 1.6265475785304973\n",
      "New best model found at epoch 58 with validation loss 1.6265476942062378\n",
      "Starting Epoch 59\n",
      "1.7565812701764314\n",
      "Validation loss: 1.6239640712738037\n",
      "mse 1.6239642261434624\n",
      "New best model found at epoch 59 with validation loss 1.6239640712738037\n",
      "Starting Epoch 60\n",
      "1.7531590306240579\n",
      "Validation loss: 1.6213017702102661\n",
      "mse 1.6213018740894922\n",
      "New best model found at epoch 60 with validation loss 1.6213017702102661\n",
      "Starting Epoch 61\n",
      "1.7498706993849382\n",
      "Validation loss: 1.6187037229537964\n",
      "mse 1.6187037445604242\n",
      "New best model found at epoch 61 with validation loss 1.6187037229537964\n",
      "Starting Epoch 62\n",
      "1.7466066920238992\n",
      "Validation loss: 1.6161432266235352\n",
      "mse 1.6161432038038326\n",
      "New best model found at epoch 62 with validation loss 1.6161432266235352\n",
      "Starting Epoch 63\n",
      "1.7434902761293494\n",
      "Validation loss: 1.613708257675171\n",
      "mse 1.6137082344662086\n",
      "New best model found at epoch 63 with validation loss 1.613708257675171\n",
      "Starting Epoch 64\n",
      "1.7404625363971875\n",
      "Validation loss: 1.6112481355667114\n",
      "mse 1.611248151268866\n",
      "New best model found at epoch 64 with validation loss 1.6112481355667114\n",
      "Starting Epoch 65\n",
      "1.7375322113866392\n",
      "Validation loss: 1.6087965965270996\n",
      "mse 1.6087965346900719\n",
      "New best model found at epoch 65 with validation loss 1.6087965965270996\n",
      "Starting Epoch 66\n",
      "1.7346955485965894\n",
      "Validation loss: 1.606367588043213\n",
      "mse 1.6063676303092083\n",
      "New best model found at epoch 66 with validation loss 1.606367588043213\n",
      "Starting Epoch 67\n",
      "1.731926829918571\n",
      "Validation loss: 1.6039173603057861\n",
      "mse 1.6039173866053782\n",
      "New best model found at epoch 67 with validation loss 1.6039173603057861\n",
      "Starting Epoch 68\n",
      "1.7292305697565493\n",
      "Validation loss: 1.6015387773513794\n",
      "mse 1.6015387241859782\n",
      "New best model found at epoch 68 with validation loss 1.6015387773513794\n",
      "Starting Epoch 69\n",
      "1.7266167143116826\n",
      "Validation loss: 1.5992053747177124\n",
      "mse 1.599205413082448\n",
      "New best model found at epoch 69 with validation loss 1.5992053747177124\n",
      "Starting Epoch 70\n",
      "1.7240691703298818\n",
      "Validation loss: 1.596777319908142\n",
      "mse 1.5967773276258888\n",
      "New best model found at epoch 70 with validation loss 1.596777319908142\n",
      "Starting Epoch 71\n",
      "1.7213810371315998\n",
      "Validation loss: 1.593611717224121\n",
      "mse 1.593611617553118\n",
      "New best model found at epoch 71 with validation loss 1.593611717224121\n",
      "Starting Epoch 72\n",
      "1.718275583308676\n",
      "Validation loss: 1.590474009513855\n",
      "mse 1.5904740689510828\n",
      "New best model found at epoch 72 with validation loss 1.590474009513855\n",
      "Starting Epoch 73\n",
      "1.7149539823117463\n",
      "Validation loss: 1.5877233743667603\n",
      "mse 1.5877234576107901\n",
      "New best model found at epoch 73 with validation loss 1.5877233743667603\n",
      "Starting Epoch 74\n",
      "1.7119108231171318\n",
      "Validation loss: 1.5851598978042603\n",
      "mse 1.5851598755714653\n",
      "New best model found at epoch 74 with validation loss 1.5851598978042603\n",
      "Starting Epoch 75\n",
      "1.7089780983717546\n",
      "Validation loss: 1.5830258131027222\n",
      "mse 1.5830260064030615\n",
      "New best model found at epoch 75 with validation loss 1.5830258131027222\n",
      "Starting Epoch 76\n",
      "1.7063094170197197\n",
      "Validation loss: 1.5808488130569458\n",
      "mse 1.58084886357251\n",
      "New best model found at epoch 76 with validation loss 1.5808488130569458\n",
      "Starting Epoch 77\n",
      "1.7037477700606636\n",
      "Validation loss: 1.5788283348083496\n",
      "mse 1.578828256639364\n",
      "New best model found at epoch 77 with validation loss 1.5788283348083496\n",
      "Starting Epoch 78\n",
      "1.7012702641279802\n",
      "Validation loss: 1.576682686805725\n",
      "mse 1.5766826732501056\n",
      "New best model found at epoch 78 with validation loss 1.576682686805725\n",
      "Starting Epoch 79\n",
      "1.698869808860447\n",
      "Validation loss: 1.574769377708435\n",
      "mse 1.574769408386293\n",
      "New best model found at epoch 79 with validation loss 1.574769377708435\n",
      "Starting Epoch 80\n",
      "1.6965427813322649\n",
      "Validation loss: 1.5728973150253296\n",
      "mse 1.5728972599873914\n",
      "New best model found at epoch 80 with validation loss 1.5728973150253296\n",
      "Starting Epoch 81\n",
      "1.6943109294642573\n",
      "Validation loss: 1.5709550380706787\n",
      "mse 1.5709551786709093\n",
      "New best model found at epoch 81 with validation loss 1.5709550380706787\n",
      "Starting Epoch 82\n",
      "1.692161140234574\n",
      "Validation loss: 1.5693751573562622\n",
      "mse 1.5693750696431208\n",
      "New best model found at epoch 82 with validation loss 1.5693751573562622\n",
      "Starting Epoch 83\n",
      "1.6901057543961897\n",
      "Validation loss: 1.5677424669265747\n",
      "mse 1.5677424211827506\n",
      "New best model found at epoch 83 with validation loss 1.5677424669265747\n",
      "Starting Epoch 84\n",
      "1.6880746198737102\n",
      "Validation loss: 1.5662628412246704\n",
      "mse 1.5662628443502424\n",
      "New best model found at epoch 84 with validation loss 1.5662628412246704\n",
      "Starting Epoch 85\n",
      "1.6861164207043855\n",
      "Validation loss: 1.5646507740020752\n",
      "mse 1.5646507933341935\n",
      "New best model found at epoch 85 with validation loss 1.5646507740020752\n",
      "Starting Epoch 86\n",
      "1.6841628862463909\n",
      "Validation loss: 1.5630159378051758\n",
      "mse 1.5630157981186463\n",
      "New best model found at epoch 86 with validation loss 1.5630159378051758\n",
      "Starting Epoch 87\n",
      "1.6822817377422168\n",
      "Validation loss: 1.5613133907318115\n",
      "mse 1.5613133622043742\n",
      "New best model found at epoch 87 with validation loss 1.5613133907318115\n",
      "Starting Epoch 88\n",
      "1.6803882899491682\n",
      "Validation loss: 1.5595543384552002\n",
      "mse 1.559554369810481\n",
      "New best model found at epoch 88 with validation loss 1.5595543384552002\n",
      "Starting Epoch 89\n",
      "1.6784611370252527\n",
      "Validation loss: 1.5579259395599365\n",
      "mse 1.5579258924471104\n",
      "New best model found at epoch 89 with validation loss 1.5579259395599365\n",
      "Starting Epoch 90\n",
      "1.6766531000966611\n",
      "Validation loss: 1.5558736324310303\n",
      "mse 1.5558735868637656\n",
      "New best model found at epoch 90 with validation loss 1.5558736324310303\n",
      "Starting Epoch 91\n",
      "1.6747131243995999\n",
      "Validation loss: 1.5541155338287354\n",
      "mse 1.5541155720040412\n",
      "New best model found at epoch 91 with validation loss 1.5541155338287354\n",
      "Starting Epoch 92\n",
      "1.6727860751359358\n",
      "Validation loss: 1.5523178577423096\n",
      "mse 1.5523177835899304\n",
      "New best model found at epoch 92 with validation loss 1.5523178577423096\n",
      "Starting Epoch 93\n",
      "1.6708183495894722\n",
      "Validation loss: 1.5502084493637085\n",
      "mse 1.5502086487594728\n",
      "New best model found at epoch 93 with validation loss 1.5502084493637085\n",
      "Starting Epoch 94\n",
      "1.668505124423815\n",
      "Validation loss: 1.5488570928573608\n",
      "mse 1.548857134770236\n",
      "New best model found at epoch 94 with validation loss 1.5488570928573608\n",
      "Starting Epoch 95\n",
      "1.6665597480276357\n",
      "Validation loss: 1.5467145442962646\n",
      "mse 1.5467144058519202\n",
      "New best model found at epoch 95 with validation loss 1.5467145442962646\n",
      "Starting Epoch 96\n",
      "1.6642933306486711\n",
      "Validation loss: 1.5459504127502441\n",
      "mse 1.5459503079729915\n",
      "New best model found at epoch 96 with validation loss 1.5459504127502441\n",
      "Starting Epoch 97\n",
      "1.6627121127170066\n",
      "Validation loss: 1.5442599058151245\n",
      "mse 1.5442599925464218\n",
      "New best model found at epoch 97 with validation loss 1.5442599058151245\n",
      "Starting Epoch 98\n",
      "1.660846285198046\n",
      "Validation loss: 1.543055772781372\n",
      "mse 1.5430558603214248\n",
      "New best model found at epoch 98 with validation loss 1.543055772781372\n",
      "Starting Epoch 99\n",
      "1.659126323202382\n",
      "Validation loss: 1.5418885946273804\n",
      "mse 1.5418885368693664\n",
      "New best model found at epoch 99 with validation loss 1.5418885946273804\n",
      "Starting Epoch 100\n",
      "1.657459310863329\n",
      "Validation loss: 1.5406584739685059\n",
      "mse 1.540658437351873\n",
      "New best model found at epoch 100 with validation loss 1.5406584739685059\n",
      "Starting Epoch 101\n",
      "1.6559783272121265\n",
      "Validation loss: 1.5391006469726562\n",
      "mse 1.5391007870963822\n",
      "New best model found at epoch 101 with validation loss 1.5391006469726562\n",
      "Starting Epoch 102\n",
      "1.6541802572167439\n",
      "Validation loss: 1.5380772352218628\n",
      "mse 1.5380772535334535\n",
      "New best model found at epoch 102 with validation loss 1.5380772352218628\n",
      "Starting Epoch 103\n",
      "1.6526636921841165\n",
      "Validation loss: 1.536888599395752\n",
      "mse 1.5368885334991595\n",
      "New best model found at epoch 103 with validation loss 1.536888599395752\n",
      "Starting Epoch 104\n",
      "1.651169953138932\n",
      "Validation loss: 1.5356107950210571\n",
      "mse 1.535610835680786\n",
      "New best model found at epoch 104 with validation loss 1.5356107950210571\n",
      "Starting Epoch 105\n",
      "1.6496799873269123\n",
      "Validation loss: 1.534618616104126\n",
      "mse 1.5346187499596269\n",
      "New best model found at epoch 105 with validation loss 1.534618616104126\n",
      "Starting Epoch 106\n",
      "1.6483164662900178\n",
      "Validation loss: 1.5333354473114014\n",
      "mse 1.5333353577968216\n",
      "New best model found at epoch 106 with validation loss 1.5333354473114014\n",
      "Starting Epoch 107\n",
      "1.6468647200128306\n",
      "Validation loss: 1.5320650339126587\n",
      "mse 1.5320651074589728\n",
      "New best model found at epoch 107 with validation loss 1.5320650339126587\n",
      "Starting Epoch 108\n",
      "1.6454301295073137\n",
      "Validation loss: 1.5309127569198608\n",
      "mse 1.5309128607740825\n",
      "New best model found at epoch 108 with validation loss 1.5309127569198608\n",
      "Starting Epoch 109\n",
      "1.644046373989271\n",
      "Validation loss: 1.5295908451080322\n",
      "mse 1.529590939735081\n",
      "New best model found at epoch 109 with validation loss 1.5295908451080322\n",
      "Starting Epoch 110\n",
      "1.6425677330597588\n",
      "Validation loss: 1.5284699201583862\n",
      "mse 1.5284700184426763\n",
      "New best model found at epoch 110 with validation loss 1.5284699201583862\n",
      "Starting Epoch 111\n",
      "1.641281045001486\n",
      "Validation loss: 1.5274714231491089\n",
      "mse 1.5274715065346216\n",
      "New best model found at epoch 111 with validation loss 1.5274714231491089\n",
      "Starting Epoch 112\n",
      "1.6399294604425845\n",
      "Validation loss: 1.5261898040771484\n",
      "mse 1.5261898236606632\n",
      "New best model found at epoch 112 with validation loss 1.5261898040771484\n",
      "Starting Epoch 113\n",
      "1.6386008521784907\n",
      "Validation loss: 1.5251327753067017\n",
      "mse 1.525132745921617\n",
      "New best model found at epoch 113 with validation loss 1.5251327753067017\n",
      "Starting Epoch 114\n",
      "1.6372510583504387\n",
      "Validation loss: 1.523858666419983\n",
      "mse 1.523858793549612\n",
      "New best model found at epoch 114 with validation loss 1.523858666419983\n",
      "Starting Epoch 115\n",
      "1.635944786279098\n",
      "Validation loss: 1.5221123695373535\n",
      "mse 1.5221123134545558\n",
      "New best model found at epoch 115 with validation loss 1.5221123695373535\n",
      "Starting Epoch 116\n",
      "1.6343004884927168\n",
      "Validation loss: 1.5205409526824951\n",
      "mse 1.5205410310861034\n",
      "New best model found at epoch 116 with validation loss 1.5205409526824951\n",
      "Starting Epoch 117\n",
      "1.632764088070911\n",
      "Validation loss: 1.519408941268921\n",
      "mse 1.5194089872088181\n",
      "New best model found at epoch 117 with validation loss 1.519408941268921\n",
      "Starting Epoch 118\n",
      "1.6313731903615205\n",
      "Validation loss: 1.518047571182251\n",
      "mse 1.5180476459374659\n",
      "New best model found at epoch 118 with validation loss 1.518047571182251\n",
      "Starting Epoch 119\n",
      "1.6299108811046765\n",
      "Validation loss: 1.516631007194519\n",
      "mse 1.5166311159466752\n",
      "New best model found at epoch 119 with validation loss 1.516631007194519\n",
      "Starting Epoch 120\n",
      "1.6282172099403713\n",
      "Validation loss: 1.5153999328613281\n",
      "mse 1.5153999392425845\n",
      "New best model found at epoch 120 with validation loss 1.5153999328613281\n",
      "Starting Epoch 121\n",
      "1.626382765562638\n",
      "Validation loss: 1.5135554075241089\n",
      "mse 1.5135554643407334\n",
      "New best model found at epoch 121 with validation loss 1.5135554075241089\n",
      "Starting Epoch 122\n",
      "1.6245807979417883\n",
      "Validation loss: 1.5132561922073364\n",
      "mse 1.5132562270181416\n",
      "New best model found at epoch 122 with validation loss 1.5132561922073364\n",
      "Starting Epoch 123\n",
      "1.6232245590375818\n",
      "Validation loss: 1.5121357440948486\n",
      "mse 1.512135712603401\n",
      "New best model found at epoch 123 with validation loss 1.5121357440948486\n",
      "Starting Epoch 124\n",
      "1.6218773152517236\n",
      "Validation loss: 1.5113474130630493\n",
      "mse 1.511347262465224\n",
      "New best model found at epoch 124 with validation loss 1.5113474130630493\n",
      "Starting Epoch 125\n",
      "1.620667841123498\n",
      "Validation loss: 1.5105164051055908\n",
      "mse 1.5105162983809883\n",
      "New best model found at epoch 125 with validation loss 1.5105164051055908\n",
      "Starting Epoch 126\n",
      "1.6193157123482746\n",
      "Validation loss: 1.5093797445297241\n",
      "mse 1.5093798539458332\n",
      "New best model found at epoch 126 with validation loss 1.5093797445297241\n",
      "Starting Epoch 127\n",
      "1.6180140376091003\n",
      "Validation loss: 1.506972312927246\n",
      "mse 1.5069722911746593\n",
      "New best model found at epoch 127 with validation loss 1.506972312927246\n",
      "Starting Epoch 128\n",
      "1.6166063961775408\n",
      "Validation loss: 1.5074299573898315\n",
      "mse 1.5074298163954405\n",
      "Starting Epoch 129\n",
      "1.6155926844348079\n",
      "Validation loss: 1.5063587427139282\n",
      "mse 1.5063587581923088\n",
      "New best model found at epoch 129 with validation loss 1.5063587427139282\n",
      "Starting Epoch 130\n",
      "1.6142992169960686\n",
      "Validation loss: 1.5056686401367188\n",
      "mse 1.5056686509954305\n",
      "New best model found at epoch 130 with validation loss 1.5056686401367188\n",
      "Starting Epoch 131\n",
      "1.6130959702574688\n",
      "Validation loss: 1.5047059059143066\n",
      "mse 1.5047058770398454\n",
      "New best model found at epoch 131 with validation loss 1.5047059059143066\n",
      "Starting Epoch 132\n",
      "1.61186901382778\n",
      "Validation loss: 1.5024516582489014\n",
      "mse 1.5024517139678062\n",
      "New best model found at epoch 132 with validation loss 1.5024516582489014\n",
      "Starting Epoch 133\n",
      "1.6105233068051545\n",
      "Validation loss: 1.5027947425842285\n",
      "mse 1.5027946780849673\n",
      "Starting Epoch 134\n",
      "1.6095556746358457\n",
      "Validation loss: 1.5020674467086792\n",
      "mse 1.5020676014327852\n",
      "New best model found at epoch 134 with validation loss 1.5020674467086792\n",
      "Starting Epoch 135\n",
      "1.608380359152089\n",
      "Validation loss: 1.5010145902633667\n",
      "mse 1.5010144728072237\n",
      "New best model found at epoch 135 with validation loss 1.5010145902633667\n",
      "Starting Epoch 136\n",
      "1.6072381657102834\n",
      "Validation loss: 1.5003806352615356\n",
      "mse 1.5003806712190302\n",
      "New best model found at epoch 136 with validation loss 1.5003806352615356\n",
      "Starting Epoch 137\n",
      "1.6060650970624841\n",
      "Validation loss: 1.499481201171875\n",
      "mse 1.4994812294504758\n",
      "New best model found at epoch 137 with validation loss 1.499481201171875\n",
      "Starting Epoch 138\n",
      "1.604916233083476\n",
      "Validation loss: 1.4986717700958252\n",
      "mse 1.4986717304409924\n",
      "New best model found at epoch 138 with validation loss 1.4986717700958252\n",
      "Starting Epoch 139\n",
      "1.603689245555712\n",
      "Validation loss: 1.4978786706924438\n",
      "mse 1.497878669308862\n",
      "New best model found at epoch 139 with validation loss 1.4978786706924438\n",
      "Starting Epoch 140\n",
      "1.60243660989015\n",
      "Validation loss: 1.4969650506973267\n",
      "mse 1.4969649959657516\n",
      "New best model found at epoch 140 with validation loss 1.4969650506973267\n",
      "Starting Epoch 141\n",
      "1.601367123748945\n",
      "Validation loss: 1.496231198310852\n",
      "mse 1.4962311386865015\n",
      "New best model found at epoch 141 with validation loss 1.496231198310852\n",
      "Starting Epoch 142\n",
      "1.600423999454664\n",
      "Validation loss: 1.4954829216003418\n",
      "mse 1.4954828620884242\n",
      "New best model found at epoch 142 with validation loss 1.4954829216003418\n",
      "Starting Epoch 143\n",
      "1.5993877545647\n",
      "Validation loss: 1.494794487953186\n",
      "mse 1.4947944537303859\n",
      "New best model found at epoch 143 with validation loss 1.494794487953186\n",
      "Starting Epoch 144\n",
      "1.5983675485071929\n",
      "Validation loss: 1.4941084384918213\n",
      "mse 1.4941083299737843\n",
      "New best model found at epoch 144 with validation loss 1.4941084384918213\n",
      "Starting Epoch 145\n",
      "1.597425261269445\n",
      "Validation loss: 1.4936031103134155\n",
      "mse 1.4936030641176885\n",
      "New best model found at epoch 145 with validation loss 1.4936031103134155\n",
      "Starting Epoch 146\n",
      "1.596564795659936\n",
      "Validation loss: 1.4930163621902466\n",
      "mse 1.4930162777785563\n",
      "New best model found at epoch 146 with validation loss 1.4930163621902466\n",
      "Starting Epoch 147\n",
      "1.595650341199792\n",
      "Validation loss: 1.4907550811767578\n",
      "mse 1.4907550740255966\n",
      "New best model found at epoch 147 with validation loss 1.4907550811767578\n",
      "Starting Epoch 148\n",
      "1.5946041760237322\n",
      "Validation loss: 1.4914402961730957\n",
      "mse 1.4914402700765772\n",
      "Starting Epoch 149\n",
      "1.593838650247325\n",
      "Validation loss: 1.4909815788269043\n",
      "mse 1.4909815935697415\n",
      "Starting Epoch 150\n",
      "1.5930136856825456\n",
      "Validation loss: 1.4904710054397583\n",
      "mse 1.4904710600354445\n",
      "New best model found at epoch 150 with validation loss 1.4904710054397583\n",
      "Starting Epoch 151\n",
      "1.5922010670537534\n",
      "Validation loss: 1.4887727499008179\n",
      "mse 1.4887727350196565\n",
      "New best model found at epoch 151 with validation loss 1.4887727499008179\n",
      "Starting Epoch 152\n",
      "1.591201313163923\n",
      "Validation loss: 1.489422082901001\n",
      "mse 1.4894221413834967\n",
      "Starting Epoch 153\n",
      "1.5905362108479375\n",
      "Validation loss: 1.4889260530471802\n",
      "mse 1.4889260667518531\n",
      "Starting Epoch 154\n",
      "1.5897583831911501\n",
      "Validation loss: 1.4884041547775269\n",
      "mse 1.488404108816794\n",
      "New best model found at epoch 154 with validation loss 1.4884041547775269\n",
      "Starting Epoch 155\n",
      "1.5889774897824163\n",
      "Validation loss: 1.4879781007766724\n",
      "mse 1.4879780681573047\n",
      "New best model found at epoch 155 with validation loss 1.4879781007766724\n",
      "Starting Epoch 156\n",
      "1.5883508557858674\n",
      "Validation loss: 1.4856414794921875\n",
      "mse 1.4856415559440073\n",
      "New best model found at epoch 156 with validation loss 1.4856414794921875\n",
      "Starting Epoch 157\n",
      "1.5872641361278037\n",
      "Validation loss: 1.486964464187622\n",
      "mse 1.4869643380713562\n",
      "Starting Epoch 158\n",
      "1.5867633093958315\n",
      "Validation loss: 1.486284852027893\n",
      "mse 1.4862848625838034\n",
      "Starting Epoch 159\n",
      "1.5859959332839302\n",
      "Validation loss: 1.485650658607483\n",
      "mse 1.4856505372074718\n",
      "Starting Epoch 160\n",
      "1.5853181896002397\n",
      "Validation loss: 1.4853285551071167\n",
      "mse 1.4853282876224914\n",
      "New best model found at epoch 160 with validation loss 1.4853285551071167\n",
      "Starting Epoch 161\n",
      "1.58462328237036\n",
      "Validation loss: 1.4849936962127686\n",
      "mse 1.4849936481818804\n",
      "New best model found at epoch 161 with validation loss 1.4849936962127686\n",
      "Starting Epoch 162\n",
      "1.5838794967402583\n",
      "Validation loss: 1.4846988916397095\n",
      "mse 1.484698805749819\n",
      "New best model found at epoch 162 with validation loss 1.4846988916397095\n",
      "Starting Epoch 163\n",
      "1.583297301893649\n",
      "Validation loss: 1.482587456703186\n",
      "mse 1.4825876176229509\n",
      "New best model found at epoch 163 with validation loss 1.482587456703186\n",
      "Starting Epoch 164\n",
      "1.5823181945344675\n",
      "Validation loss: 1.4838424921035767\n",
      "mse 1.483842501442218\n",
      "Starting Epoch 165\n",
      "1.5819950699806213\n",
      "Validation loss: 1.4818406105041504\n",
      "mse 1.4818405757532778\n",
      "New best model found at epoch 165 with validation loss 1.4818406105041504\n",
      "Starting Epoch 166\n",
      "1.5810309233872786\n",
      "Validation loss: 1.4816008806228638\n",
      "mse 1.4816008095843802\n",
      "New best model found at epoch 166 with validation loss 1.4816008806228638\n",
      "Starting Epoch 167\n",
      "1.580445794955544\n",
      "Validation loss: 1.4825068712234497\n",
      "mse 1.4825068937045238\n",
      "Starting Epoch 168\n",
      "1.579984882603521\n",
      "Validation loss: 1.4824296236038208\n",
      "mse 1.4824295536170515\n",
      "Starting Epoch 169\n",
      "1.5794098325397656\n",
      "Validation loss: 1.48203444480896\n",
      "mse 1.4820342897261043\n",
      "Starting Epoch 170\n",
      "1.5788343574689783\n",
      "Validation loss: 1.481545090675354\n",
      "mse 1.481545042242886\n",
      "New best model found at epoch 170 with validation loss 1.481545090675354\n",
      "Starting Epoch 171\n",
      "1.5781794605047808\n",
      "Validation loss: 1.4799848794937134\n",
      "mse 1.4799847382104607\n",
      "New best model found at epoch 171 with validation loss 1.4799848794937134\n",
      "Starting Epoch 172\n",
      "1.577281936355259\n",
      "Validation loss: 1.4791138172149658\n",
      "mse 1.4791137486641213\n",
      "New best model found at epoch 172 with validation loss 1.4791138172149658\n",
      "Starting Epoch 173\n",
      "1.5768235481303672\n",
      "Validation loss: 1.4803392887115479\n",
      "mse 1.4803394008845356\n",
      "Starting Epoch 174\n",
      "1.5763897144276162\n",
      "Validation loss: 1.4797465801239014\n",
      "mse 1.4797464803628289\n",
      "Starting Epoch 175\n",
      "1.575878811919171\n",
      "Validation loss: 1.4791359901428223\n",
      "mse 1.4791360369805864\n",
      "Starting Epoch 176\n",
      "1.5751623614974644\n",
      "Validation loss: 1.47742760181427\n",
      "mse 1.4774274943475334\n",
      "New best model found at epoch 176 with validation loss 1.47742760181427\n",
      "Starting Epoch 177\n",
      "1.5744424928789553\n",
      "Validation loss: 1.4784245491027832\n",
      "mse 1.4784245263580869\n",
      "Starting Epoch 178\n",
      "1.5740206578503484\n",
      "Validation loss: 1.4778956174850464\n",
      "mse 1.4778957355661069\n",
      "Starting Epoch 179\n",
      "1.5734033118123594\n",
      "Validation loss: 1.476702332496643\n",
      "mse 1.4767023625699103\n",
      "New best model found at epoch 179 with validation loss 1.476702332496643\n",
      "Starting Epoch 180\n",
      "1.5727595660997473\n",
      "Validation loss: 1.4761260747909546\n",
      "mse 1.476126125884637\n",
      "New best model found at epoch 180 with validation loss 1.4761260747909546\n",
      "Starting Epoch 181\n",
      "1.5722099568532861\n",
      "Validation loss: 1.4766759872436523\n",
      "mse 1.4766760230804286\n",
      "Starting Epoch 182\n",
      "1.5717602035273677\n",
      "Validation loss: 1.475416898727417\n",
      "mse 1.475416813689294\n",
      "New best model found at epoch 182 with validation loss 1.475416898727417\n",
      "Starting Epoch 183\n",
      "1.5711441169614377\n",
      "Validation loss: 1.47562575340271\n",
      "mse 1.4756255267885707\n",
      "Starting Epoch 184\n",
      "1.570709694986758\n",
      "Validation loss: 1.4743934869766235\n",
      "mse 1.4743935250629028\n",
      "New best model found at epoch 184 with validation loss 1.4743934869766235\n",
      "Starting Epoch 185\n",
      "1.5700393707855889\n",
      "Validation loss: 1.4747350215911865\n",
      "mse 1.47473489028686\n",
      "Starting Epoch 186\n",
      "1.5696830205295398\n",
      "Validation loss: 1.4732905626296997\n",
      "mse 1.4732905501973343\n",
      "New best model found at epoch 186 with validation loss 1.4732905626296997\n",
      "Starting Epoch 187\n",
      "1.568970317425935\n",
      "Validation loss: 1.4738919734954834\n",
      "mse 1.4738920231717836\n",
      "Starting Epoch 188\n",
      "1.568664980971295\n",
      "Validation loss: 1.4732941389083862\n",
      "mse 1.4732941105242714\n",
      "Starting Epoch 189\n",
      "1.5680744647979736\n",
      "Validation loss: 1.47199285030365\n",
      "mse 1.4719929147797777\n",
      "New best model found at epoch 189 with validation loss 1.47199285030365\n",
      "Starting Epoch 190\n",
      "1.5673789744791777\n",
      "Validation loss: 1.47165048122406\n",
      "mse 1.4716503884015621\n",
      "New best model found at epoch 190 with validation loss 1.47165048122406\n",
      "Starting Epoch 191\n",
      "1.5669183212777842\n",
      "Validation loss: 1.4720454216003418\n",
      "mse 1.4720453775572298\n",
      "Starting Epoch 192\n",
      "1.566570028014805\n",
      "Validation loss: 1.471726417541504\n",
      "mse 1.4717264329726254\n",
      "Starting Epoch 193\n",
      "1.5660391268522844\n",
      "Validation loss: 1.471330165863037\n",
      "mse 1.4713300580404403\n",
      "New best model found at epoch 193 with validation loss 1.471330165863037\n",
      "Starting Epoch 194\n",
      "1.5655254410660786\n",
      "Validation loss: 1.4708930253982544\n",
      "mse 1.4708931695424408\n",
      "New best model found at epoch 194 with validation loss 1.4708930253982544\n",
      "Starting Epoch 195\n",
      "1.5649888541387476\n",
      "Validation loss: 1.4707828760147095\n",
      "mse 1.4707828893852033\n",
      "New best model found at epoch 195 with validation loss 1.4707828760147095\n",
      "Starting Epoch 196\n",
      "1.564554592837458\n",
      "Validation loss: 1.4693968296051025\n",
      "mse 1.4693967402742734\n",
      "New best model found at epoch 196 with validation loss 1.4693968296051025\n",
      "Starting Epoch 197\n",
      "1.563871171163476\n",
      "Validation loss: 1.4688913822174072\n",
      "mse 1.4688915086247643\n",
      "New best model found at epoch 197 with validation loss 1.4688913822174072\n",
      "Starting Epoch 198\n",
      "1.5633345531380696\n",
      "Validation loss: 1.4695849418640137\n",
      "mse 1.4695850678983928\n",
      "Starting Epoch 199\n",
      "1.5630003473033076\n",
      "Validation loss: 1.469207525253296\n",
      "mse 1.469207564805616\n",
      "Starting Epoch 200\n",
      "1.5625559117483057\n",
      "Validation loss: 1.4679701328277588\n",
      "mse 1.4679700317546296\n",
      "New best model found at epoch 200 with validation loss 1.4679701328277588\n",
      "Starting Epoch 201\n",
      "1.561957395595053\n",
      "Validation loss: 1.4685471057891846\n",
      "mse 1.468546963826166\n",
      "Starting Epoch 202\n",
      "1.5615459654642188\n",
      "Validation loss: 1.4682585000991821\n",
      "mse 1.468258615359119\n",
      "Starting Epoch 203\n",
      "1.5611092888790628\n",
      "Validation loss: 1.467236876487732\n",
      "mse 1.467236989956274\n",
      "New best model found at epoch 203 with validation loss 1.467236876487732\n",
      "Starting Epoch 204\n",
      "1.5605714683947356\n",
      "Validation loss: 1.4678983688354492\n",
      "mse 1.467898348982379\n",
      "Starting Epoch 205\n",
      "1.560253003369207\n",
      "Validation loss: 1.466615915298462\n",
      "mse 1.466615868305087\n",
      "New best model found at epoch 205 with validation loss 1.466615915298462\n",
      "Starting Epoch 206\n",
      "1.5596670923025713\n",
      "Validation loss: 1.4673324823379517\n",
      "mse 1.467332395621735\n",
      "Starting Epoch 207\n",
      "1.5593809174454731\n",
      "Validation loss: 1.4661556482315063\n",
      "mse 1.4661557450897036\n",
      "New best model found at epoch 207 with validation loss 1.4661556482315063\n",
      "Starting Epoch 208\n",
      "1.5588138518126116\n",
      "Validation loss: 1.4657052755355835\n",
      "mse 1.465705185611757\n",
      "New best model found at epoch 208 with validation loss 1.4657052755355835\n",
      "Starting Epoch 209\n",
      "1.5582900565603506\n",
      "Validation loss: 1.4663864374160767\n",
      "mse 1.4663864712476578\n",
      "Starting Epoch 210\n",
      "1.5579937877862349\n",
      "Validation loss: 1.4653053283691406\n",
      "mse 1.4653053242641605\n",
      "New best model found at epoch 210 with validation loss 1.4653053283691406\n",
      "Starting Epoch 211\n",
      "1.5574893873670828\n",
      "Validation loss: 1.465856671333313\n",
      "mse 1.4658566949109562\n",
      "Starting Epoch 212\n",
      "1.557103543177895\n",
      "Validation loss: 1.464864730834961\n",
      "mse 1.4648646357089197\n",
      "New best model found at epoch 212 with validation loss 1.464864730834961\n",
      "Starting Epoch 213\n",
      "1.5566045149512913\n",
      "Validation loss: 1.4643820524215698\n",
      "mse 1.4643821257350695\n",
      "New best model found at epoch 213 with validation loss 1.4643820524215698\n",
      "Starting Epoch 214\n",
      "1.556198213411414\n",
      "Validation loss: 1.4638808965682983\n",
      "mse 1.4638809295527662\n",
      "New best model found at epoch 214 with validation loss 1.4638808965682983\n",
      "Starting Epoch 215\n",
      "1.5557275492212046\n",
      "Validation loss: 1.4643396139144897\n",
      "mse 1.4643395426560155\n",
      "Starting Epoch 216\n",
      "1.5552948946538179\n",
      "Validation loss: 1.4632437229156494\n",
      "mse 1.4632437003626246\n",
      "New best model found at epoch 216 with validation loss 1.4632437229156494\n",
      "Starting Epoch 217\n",
      "1.554820003716842\n",
      "Validation loss: 1.4628677368164062\n",
      "mse 1.462867573763335\n",
      "New best model found at epoch 217 with validation loss 1.4628677368164062\n",
      "Starting Epoch 218\n",
      "1.5543314166690991\n",
      "Validation loss: 1.4625234603881836\n",
      "mse 1.4625234037799506\n",
      "New best model found at epoch 218 with validation loss 1.4625234603881836\n",
      "Starting Epoch 219\n",
      "1.5539477882177934\n",
      "Validation loss: 1.462070345878601\n",
      "mse 1.462070436525215\n",
      "New best model found at epoch 219 with validation loss 1.462070345878601\n",
      "Starting Epoch 220\n",
      "1.553462318752123\n",
      "Validation loss: 1.4616647958755493\n",
      "mse 1.4616646333861494\n",
      "New best model found at epoch 220 with validation loss 1.4616647958755493\n",
      "Starting Epoch 221\n",
      "1.553102477737095\n",
      "Validation loss: 1.4610075950622559\n",
      "mse 1.4610075208727524\n",
      "New best model found at epoch 221 with validation loss 1.4610075950622559\n",
      "Starting Epoch 222\n",
      "1.5526499851890232\n",
      "Validation loss: 1.4603707790374756\n",
      "mse 1.4603707873672567\n",
      "New best model found at epoch 222 with validation loss 1.4603707790374756\n",
      "Starting Epoch 223\n",
      "1.5522633557734282\n",
      "Validation loss: 1.4599478244781494\n",
      "mse 1.4599479184505844\n",
      "New best model found at epoch 223 with validation loss 1.4599478244781494\n",
      "Starting Epoch 224\n",
      "1.5518471183984175\n",
      "Validation loss: 1.4597986936569214\n",
      "mse 1.4597988453494768\n",
      "New best model found at epoch 224 with validation loss 1.4597986936569214\n",
      "Starting Epoch 225\n",
      "1.551440697649251\n",
      "Validation loss: 1.4594781398773193\n",
      "mse 1.459478106331925\n",
      "New best model found at epoch 225 with validation loss 1.4594781398773193\n",
      "Starting Epoch 226\n",
      "1.5510308405627375\n",
      "Validation loss: 1.4592328071594238\n",
      "mse 1.459232854201828\n",
      "New best model found at epoch 226 with validation loss 1.4592328071594238\n",
      "Starting Epoch 227\n",
      "1.5506592548411826\n",
      "Validation loss: 1.4591283798217773\n",
      "mse 1.4591282530268261\n",
      "New best model found at epoch 227 with validation loss 1.4591283798217773\n",
      "Starting Epoch 228\n",
      "1.5502566384232563\n",
      "Validation loss: 1.4587717056274414\n",
      "mse 1.4587715851798266\n",
      "New best model found at epoch 228 with validation loss 1.4587717056274414\n",
      "Starting Epoch 229\n",
      "1.5498741295026697\n",
      "Validation loss: 1.4585882425308228\n",
      "mse 1.458588186956988\n",
      "New best model found at epoch 229 with validation loss 1.4585882425308228\n",
      "Starting Epoch 230\n",
      "1.549486289853635\n",
      "Validation loss: 1.458499550819397\n",
      "mse 1.4584995234516631\n",
      "New best model found at epoch 230 with validation loss 1.458499550819397\n",
      "Starting Epoch 231\n",
      "1.5491000984026038\n",
      "Validation loss: 1.4582926034927368\n",
      "mse 1.4582925905262234\n",
      "New best model found at epoch 231 with validation loss 1.4582926034927368\n",
      "Starting Epoch 232\n",
      "1.5487406331559885\n",
      "Validation loss: 1.4579836130142212\n",
      "mse 1.4579836248239113\n",
      "New best model found at epoch 232 with validation loss 1.4579836130142212\n",
      "Starting Epoch 233\n",
      "1.5483458586361096\n",
      "Validation loss: 1.45785653591156\n",
      "mse 1.4578567091170536\n",
      "New best model found at epoch 233 with validation loss 1.45785653591156\n",
      "Starting Epoch 234\n",
      "1.548037132491236\n",
      "Validation loss: 1.4575133323669434\n",
      "mse 1.4575134012831772\n",
      "New best model found at epoch 234 with validation loss 1.4575133323669434\n",
      "Starting Epoch 235\n",
      "1.5476398338442263\n",
      "Validation loss: 1.4572705030441284\n",
      "mse 1.4572704310353553\n",
      "New best model found at epoch 235 with validation loss 1.4572705030441284\n",
      "Starting Epoch 236\n",
      "1.547273029451785\n",
      "Validation loss: 1.4569612741470337\n",
      "mse 1.456961233295443\n",
      "New best model found at epoch 236 with validation loss 1.4569612741470337\n",
      "Starting Epoch 237\n",
      "1.5469048023223877\n",
      "Validation loss: 1.4567515850067139\n",
      "mse 1.456751656142417\n",
      "New best model found at epoch 237 with validation loss 1.4567515850067139\n",
      "Starting Epoch 238\n",
      "1.5465502065161\n",
      "Validation loss: 1.4564809799194336\n",
      "mse 1.4564810087059947\n",
      "New best model found at epoch 238 with validation loss 1.4564809799194336\n",
      "Starting Epoch 239\n",
      "1.546167254447937\n",
      "Validation loss: 1.4563361406326294\n",
      "mse 1.4563361079316592\n",
      "New best model found at epoch 239 with validation loss 1.4563361406326294\n",
      "Starting Epoch 240\n",
      "1.5458244862763777\n",
      "Validation loss: 1.4560179710388184\n",
      "mse 1.4560180680885169\n",
      "New best model found at epoch 240 with validation loss 1.4560179710388184\n",
      "Starting Epoch 241\n",
      "1.5454665862995645\n",
      "Validation loss: 1.4557818174362183\n",
      "mse 1.4557818833692653\n",
      "New best model found at epoch 241 with validation loss 1.4557818174362183\n",
      "Starting Epoch 242\n",
      "1.5450955111047495\n",
      "Validation loss: 1.4555786848068237\n",
      "mse 1.45557866929061\n",
      "New best model found at epoch 242 with validation loss 1.4555786848068237\n",
      "Starting Epoch 243\n",
      "1.5447574931642283\n",
      "Validation loss: 1.4553323984146118\n",
      "mse 1.455332422357091\n",
      "New best model found at epoch 243 with validation loss 1.4553323984146118\n",
      "Starting Epoch 244\n",
      "1.5443940732790076\n",
      "Validation loss: 1.455044150352478\n",
      "mse 1.4550441462686357\n",
      "New best model found at epoch 244 with validation loss 1.455044150352478\n",
      "Starting Epoch 245\n",
      "1.544069080249123\n",
      "Validation loss: 1.4547497034072876\n",
      "mse 1.454749730225589\n",
      "New best model found at epoch 245 with validation loss 1.4547497034072876\n",
      "Starting Epoch 246\n",
      "1.543713989465133\n",
      "Validation loss: 1.4545451402664185\n",
      "mse 1.454545036922903\n",
      "New best model found at epoch 246 with validation loss 1.4545451402664185\n",
      "Starting Epoch 247\n",
      "1.5433146513026694\n",
      "Validation loss: 1.4543678760528564\n",
      "mse 1.454367903643599\n",
      "New best model found at epoch 247 with validation loss 1.4543678760528564\n",
      "Starting Epoch 248\n",
      "1.5430200048114942\n",
      "Validation loss: 1.454146146774292\n",
      "mse 1.4541461344485274\n",
      "New best model found at epoch 248 with validation loss 1.454146146774292\n",
      "Starting Epoch 249\n",
      "1.5425786764725395\n",
      "Validation loss: 1.4542378187179565\n",
      "mse 1.4542378223442014\n",
      "Starting Epoch 250\n",
      "1.5422627796297488\n",
      "Validation loss: 1.4539555311203003\n",
      "mse 1.4539554490597126\n",
      "New best model found at epoch 250 with validation loss 1.4539555311203003\n",
      "Starting Epoch 251\n",
      "1.5420174158137778\n",
      "Validation loss: 1.4534968137741089\n",
      "mse 1.453496791615281\n",
      "New best model found at epoch 251 with validation loss 1.4534968137741089\n",
      "Starting Epoch 252\n",
      "1.5415902526482292\n",
      "Validation loss: 1.4536014795303345\n",
      "mse 1.4536014236880408\n",
      "Starting Epoch 253\n",
      "1.5412800752598306\n",
      "Validation loss: 1.4533113241195679\n",
      "mse 1.4533113248727256\n",
      "New best model found at epoch 253 with validation loss 1.4533113241195679\n",
      "Starting Epoch 254\n",
      "1.5409272675928862\n",
      "Validation loss: 1.4531446695327759\n",
      "mse 1.4531445393720281\n",
      "New best model found at epoch 254 with validation loss 1.4531446695327759\n",
      "Starting Epoch 255\n",
      "1.5406162505564482\n",
      "Validation loss: 1.4530013799667358\n",
      "mse 1.453001419964585\n",
      "New best model found at epoch 255 with validation loss 1.4530013799667358\n",
      "Starting Epoch 256\n",
      "1.5402520506278328\n",
      "Validation loss: 1.4527740478515625\n",
      "mse 1.4527739470813439\n",
      "New best model found at epoch 256 with validation loss 1.4527740478515625\n",
      "Starting Epoch 257\n",
      "1.5399867114813433\n",
      "Validation loss: 1.452582597732544\n",
      "mse 1.452582737288458\n",
      "New best model found at epoch 257 with validation loss 1.452582597732544\n",
      "Starting Epoch 258\n",
      "1.5396483540534973\n",
      "Validation loss: 1.452405333518982\n",
      "mse 1.4524053446105039\n",
      "New best model found at epoch 258 with validation loss 1.452405333518982\n",
      "Starting Epoch 259\n",
      "1.5393314802128335\n",
      "Validation loss: 1.4521476030349731\n",
      "mse 1.4521474619868278\n",
      "New best model found at epoch 259 with validation loss 1.4521476030349731\n",
      "Starting Epoch 260\n",
      "1.5390187294586846\n",
      "Validation loss: 1.451971173286438\n",
      "mse 1.4519711478195145\n",
      "New best model found at epoch 260 with validation loss 1.451971173286438\n",
      "Starting Epoch 261\n",
      "1.5386925391528918\n",
      "Validation loss: 1.4517533779144287\n",
      "mse 1.451753312228745\n",
      "New best model found at epoch 261 with validation loss 1.4517533779144287\n",
      "Starting Epoch 262\n",
      "1.5384044802707175\n",
      "Validation loss: 1.451520562171936\n",
      "mse 1.4515206561209262\n",
      "New best model found at epoch 262 with validation loss 1.451520562171936\n",
      "Starting Epoch 263\n",
      "1.5381200546803682\n",
      "Validation loss: 1.4511796236038208\n",
      "mse 1.4511796726298505\n",
      "New best model found at epoch 263 with validation loss 1.4511796236038208\n",
      "Starting Epoch 264\n",
      "1.5378366734670557\n",
      "Validation loss: 1.4509742259979248\n",
      "mse 1.4509743036236904\n",
      "New best model found at epoch 264 with validation loss 1.4509742259979248\n",
      "Starting Epoch 265\n",
      "1.5375255994174792\n",
      "Validation loss: 1.4507027864456177\n",
      "mse 1.4507026871868178\n",
      "New best model found at epoch 265 with validation loss 1.4507027864456177\n",
      "Starting Epoch 266\n",
      "1.5371247840964275\n",
      "Validation loss: 1.450695514678955\n",
      "mse 1.4506955994067199\n",
      "New best model found at epoch 266 with validation loss 1.450695514678955\n",
      "Starting Epoch 267\n",
      "1.5368318065353062\n",
      "Validation loss: 1.4506431818008423\n",
      "mse 1.4506431173062158\n",
      "New best model found at epoch 267 with validation loss 1.4506431818008423\n",
      "Starting Epoch 268\n",
      "1.5365511775016785\n",
      "Validation loss: 1.4503719806671143\n",
      "mse 1.4503721806721945\n",
      "New best model found at epoch 268 with validation loss 1.4503719806671143\n",
      "Starting Epoch 269\n",
      "1.536248883475428\n",
      "Validation loss: 1.4501782655715942\n",
      "mse 1.4501782793732276\n",
      "New best model found at epoch 269 with validation loss 1.4501782655715942\n",
      "Starting Epoch 270\n",
      "1.5359460063602612\n",
      "Validation loss: 1.4500101804733276\n",
      "mse 1.4500100888680396\n",
      "New best model found at epoch 270 with validation loss 1.4500101804733276\n",
      "Starting Epoch 271\n",
      "1.535673950029456\n",
      "Validation loss: 1.4497976303100586\n",
      "mse 1.4497975334397546\n",
      "New best model found at epoch 271 with validation loss 1.4497976303100586\n",
      "Starting Epoch 272\n",
      "1.5353678257569023\n",
      "Validation loss: 1.4496091604232788\n",
      "mse 1.4496091994426408\n",
      "New best model found at epoch 272 with validation loss 1.4496091604232788\n",
      "Starting Epoch 273\n",
      "1.5350601180740024\n",
      "Validation loss: 1.4494057893753052\n",
      "mse 1.4494057948777406\n",
      "New best model found at epoch 273 with validation loss 1.4494057893753052\n",
      "Starting Epoch 274\n",
      "1.534770157026208\n",
      "Validation loss: 1.4492305517196655\n",
      "mse 1.4492305919551656\n",
      "New best model found at epoch 274 with validation loss 1.4492305517196655\n",
      "Starting Epoch 275\n",
      "1.5344846585522527\n",
      "Validation loss: 1.4490327835083008\n",
      "mse 1.4490327929568172\n",
      "New best model found at epoch 275 with validation loss 1.4490327835083008\n",
      "Starting Epoch 276\n",
      "1.5342005569001902\n",
      "Validation loss: 1.4488743543624878\n",
      "mse 1.4488744877953519\n",
      "New best model found at epoch 276 with validation loss 1.4488743543624878\n",
      "Starting Epoch 277\n",
      "1.5338950805042102\n",
      "Validation loss: 1.4487199783325195\n",
      "mse 1.4487198993898491\n",
      "New best model found at epoch 277 with validation loss 1.4487199783325195\n",
      "Starting Epoch 278\n",
      "1.5336626016575357\n",
      "Validation loss: 1.4482802152633667\n",
      "mse 1.4482802424120582\n",
      "New best model found at epoch 278 with validation loss 1.4482802152633667\n",
      "Starting Epoch 279\n",
      "1.5333466659421506\n",
      "Validation loss: 1.4481898546218872\n",
      "mse 1.448189837644845\n",
      "New best model found at epoch 279 with validation loss 1.4481898546218872\n",
      "Starting Epoch 280\n",
      "1.533079955888831\n",
      "Validation loss: 1.4479645490646362\n",
      "mse 1.4479644965102858\n",
      "New best model found at epoch 280 with validation loss 1.4479645490646362\n",
      "Starting Epoch 281\n",
      "1.5327794785084932\n",
      "Validation loss: 1.4477757215499878\n",
      "mse 1.4477757651899315\n",
      "New best model found at epoch 281 with validation loss 1.4477757215499878\n",
      "Starting Epoch 282\n",
      "1.532492756843567\n",
      "Validation loss: 1.4476760625839233\n",
      "mse 1.4476760555112236\n",
      "New best model found at epoch 282 with validation loss 1.4476760625839233\n",
      "Starting Epoch 283\n",
      "1.5322163597397183\n",
      "Validation loss: 1.4474155902862549\n",
      "mse 1.4474155423216457\n",
      "New best model found at epoch 283 with validation loss 1.4474155902862549\n",
      "Starting Epoch 284\n",
      "1.531936816547228\n",
      "Validation loss: 1.4471161365509033\n",
      "mse 1.4471160773031815\n",
      "New best model found at epoch 284 with validation loss 1.4471161365509033\n",
      "Starting Epoch 285\n",
      "1.5316591133242068\n",
      "Validation loss: 1.4470306634902954\n",
      "mse 1.4470305795671954\n",
      "New best model found at epoch 285 with validation loss 1.4470306634902954\n",
      "Starting Epoch 286\n",
      "1.5313929474872092\n",
      "Validation loss: 1.4467867612838745\n",
      "mse 1.4467866938060496\n",
      "New best model found at epoch 286 with validation loss 1.4467867612838745\n",
      "Starting Epoch 287\n",
      "1.53107314006142\n",
      "Validation loss: 1.4466010332107544\n",
      "mse 1.446601118637876\n",
      "New best model found at epoch 287 with validation loss 1.4466010332107544\n",
      "Starting Epoch 288\n",
      "1.5308148472205452\n",
      "Validation loss: 1.4463768005371094\n",
      "mse 1.4463767270791332\n",
      "New best model found at epoch 288 with validation loss 1.4463768005371094\n",
      "Starting Epoch 289\n",
      "1.5305437523385752\n",
      "Validation loss: 1.4461898803710938\n",
      "mse 1.4461898041987185\n",
      "New best model found at epoch 289 with validation loss 1.4461898803710938\n",
      "Starting Epoch 290\n",
      "1.5302960406179014\n",
      "Validation loss: 1.4459340572357178\n",
      "mse 1.4459340811367014\n",
      "New best model found at epoch 290 with validation loss 1.4459340572357178\n",
      "Starting Epoch 291\n",
      "1.5299989503362905\n",
      "Validation loss: 1.4457383155822754\n",
      "mse 1.4457385282210948\n",
      "New best model found at epoch 291 with validation loss 1.4457383155822754\n",
      "Starting Epoch 292\n",
      "1.5297290423642034\n",
      "Validation loss: 1.4455982446670532\n",
      "mse 1.4455983657321834\n",
      "New best model found at epoch 292 with validation loss 1.4455982446670532\n",
      "Starting Epoch 293\n",
      "1.529461990232053\n",
      "Validation loss: 1.4454528093338013\n",
      "mse 1.445452924929117\n",
      "New best model found at epoch 293 with validation loss 1.4454528093338013\n",
      "Starting Epoch 294\n",
      "1.5292161547619363\n",
      "Validation loss: 1.4451532363891602\n",
      "mse 1.4451530907893648\n",
      "New best model found at epoch 294 with validation loss 1.4451532363891602\n",
      "Starting Epoch 295\n",
      "1.528946692528932\n",
      "Validation loss: 1.445119857788086\n",
      "mse 1.445119870122235\n",
      "New best model found at epoch 295 with validation loss 1.445119857788086\n",
      "Starting Epoch 296\n",
      "1.5286837116531704\n",
      "Validation loss: 1.4448093175888062\n",
      "mse 1.4448093440093501\n",
      "New best model found at epoch 296 with validation loss 1.4448093175888062\n",
      "Starting Epoch 297\n",
      "1.5284096028493799\n",
      "Validation loss: 1.444726586341858\n",
      "mse 1.444726717072663\n",
      "New best model found at epoch 297 with validation loss 1.444726586341858\n",
      "Starting Epoch 298\n",
      "1.52816016777702\n",
      "Validation loss: 1.444410800933838\n",
      "mse 1.4444108245529264\n",
      "New best model found at epoch 298 with validation loss 1.444410800933838\n",
      "Starting Epoch 299\n",
      "1.527894693872203\n",
      "Validation loss: 1.4443076848983765\n",
      "mse 1.4443075658677458\n",
      "New best model found at epoch 299 with validation loss 1.4443076848983765\n",
      "Starting Epoch 300\n",
      "1.5276447379070779\n",
      "Validation loss: 1.4442092180252075\n",
      "mse 1.4442091137677313\n",
      "New best model found at epoch 300 with validation loss 1.4442092180252075\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-40-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54231bf",
   "metadata": {},
   "source": [
    "##### 3-layer MLP: Version 6\n",
    "*  Layers: 3 (including input and output layer), sizes: 17 - 60 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "e14fe9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "c1d5c604-c3e2-4744-b751-fd26d700707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.196211716403132\n",
      "Validation loss: 2.658879518508911\n",
      "mse 2.6588796003417348\n",
      "New best model found at epoch 1 with validation loss 2.658879518508911\n",
      "Starting Epoch 2\n",
      "2.8635497456011563\n",
      "Validation loss: 2.5429651737213135\n",
      "mse 2.542965024822312\n",
      "New best model found at epoch 2 with validation loss 2.5429651737213135\n",
      "Starting Epoch 3\n",
      "2.750861276750979\n",
      "Validation loss: 2.463736057281494\n",
      "mse 2.463736020642786\n",
      "New best model found at epoch 3 with validation loss 2.463736057281494\n",
      "Starting Epoch 4\n",
      "2.6633853445882383\n",
      "Validation loss: 2.3936281204223633\n",
      "mse 2.39362797565571\n",
      "New best model found at epoch 4 with validation loss 2.3936281204223633\n",
      "Starting Epoch 5\n",
      "2.5875208118687505\n",
      "Validation loss: 2.331655740737915\n",
      "mse 2.3316558574113633\n",
      "New best model found at epoch 5 with validation loss 2.331655740737915\n",
      "Starting Epoch 6\n",
      "2.52078944703807\n",
      "Validation loss: 2.2749171257019043\n",
      "mse 2.2749169106514473\n",
      "New best model found at epoch 6 with validation loss 2.2749171257019043\n",
      "Starting Epoch 7\n",
      "2.4608983838039897\n",
      "Validation loss: 2.223872423171997\n",
      "mse 2.2238724644906593\n",
      "New best model found at epoch 7 with validation loss 2.223872423171997\n",
      "Starting Epoch 8\n",
      "2.406751124755196\n",
      "Validation loss: 2.1770694255828857\n",
      "mse 2.1770694744828325\n",
      "New best model found at epoch 8 with validation loss 2.1770694255828857\n",
      "Starting Epoch 9\n",
      "2.357273905173592\n",
      "Validation loss: 2.1343159675598145\n",
      "mse 2.13431589753581\n",
      "New best model found at epoch 9 with validation loss 2.1343159675598145\n",
      "Starting Epoch 10\n",
      "2.312202163364576\n",
      "Validation loss: 2.0941429138183594\n",
      "mse 2.094142985431174\n",
      "New best model found at epoch 10 with validation loss 2.0941429138183594\n",
      "Starting Epoch 11\n",
      "2.270680873290352\n",
      "Validation loss: 2.057237386703491\n",
      "mse 2.057237382925006\n",
      "New best model found at epoch 11 with validation loss 2.057237386703491\n",
      "Starting Epoch 12\n",
      "2.232432826705601\n",
      "Validation loss: 2.0246150493621826\n",
      "mse 2.024615189351465\n",
      "New best model found at epoch 12 with validation loss 2.0246150493621826\n",
      "Starting Epoch 13\n",
      "2.197672154592431\n",
      "Validation loss: 1.993237853050232\n",
      "mse 1.9932379509965394\n",
      "New best model found at epoch 13 with validation loss 1.993237853050232\n",
      "Starting Epoch 14\n",
      "2.164591856624769\n",
      "Validation loss: 1.9640789031982422\n",
      "mse 1.9640791338463919\n",
      "New best model found at epoch 14 with validation loss 1.9640789031982422\n",
      "Starting Epoch 15\n",
      "2.1333949514057324\n",
      "Validation loss: 1.9366111755371094\n",
      "mse 1.9366113006246402\n",
      "New best model found at epoch 15 with validation loss 1.9366111755371094\n",
      "Starting Epoch 16\n",
      "2.1042974461679873\n",
      "Validation loss: 1.9109715223312378\n",
      "mse 1.9109715878748623\n",
      "New best model found at epoch 16 with validation loss 1.9109715223312378\n",
      "Starting Epoch 17\n",
      "2.0779204524081685\n",
      "Validation loss: 1.888200044631958\n",
      "mse 1.888200099778297\n",
      "New best model found at epoch 17 with validation loss 1.888200044631958\n",
      "Starting Epoch 18\n",
      "2.054333510606185\n",
      "Validation loss: 1.867599606513977\n",
      "mse 1.8675993663008623\n",
      "New best model found at epoch 18 with validation loss 1.867599606513977\n",
      "Starting Epoch 19\n",
      "2.032461482545604\n",
      "Validation loss: 1.8482584953308105\n",
      "mse 1.8482583618033956\n",
      "New best model found at epoch 19 with validation loss 1.8482584953308105\n",
      "Starting Epoch 20\n",
      "2.0118341860563858\n",
      "Validation loss: 1.8298194408416748\n",
      "mse 1.8298193110282184\n",
      "New best model found at epoch 20 with validation loss 1.8298194408416748\n",
      "Starting Epoch 21\n",
      "1.9923078651013582\n",
      "Validation loss: 1.8128148317337036\n",
      "mse 1.8128147706679214\n",
      "New best model found at epoch 21 with validation loss 1.8128148317337036\n",
      "Starting Epoch 22\n",
      "1.9739601145619932\n",
      "Validation loss: 1.7965714931488037\n",
      "mse 1.7965714024581372\n",
      "New best model found at epoch 22 with validation loss 1.7965714931488037\n",
      "Starting Epoch 23\n",
      "1.9566023971723474\n",
      "Validation loss: 1.7809017896652222\n",
      "mse 1.780901662068816\n",
      "New best model found at epoch 23 with validation loss 1.7809017896652222\n",
      "Starting Epoch 24\n",
      "1.9401156332181848\n",
      "Validation loss: 1.766309142112732\n",
      "mse 1.766309193044695\n",
      "New best model found at epoch 24 with validation loss 1.766309142112732\n",
      "Starting Epoch 25\n",
      "1.9249211860739666\n",
      "Validation loss: 1.752489686012268\n",
      "mse 1.7524895587241731\n",
      "New best model found at epoch 25 with validation loss 1.752489686012268\n",
      "Starting Epoch 26\n",
      "1.9101223686467046\n",
      "Validation loss: 1.7392895221710205\n",
      "mse 1.7392894151772167\n",
      "New best model found at epoch 26 with validation loss 1.7392895221710205\n",
      "Starting Epoch 27\n",
      "1.896068987639054\n",
      "Validation loss: 1.7270498275756836\n",
      "mse 1.7270498026243568\n",
      "New best model found at epoch 27 with validation loss 1.7270498275756836\n",
      "Starting Epoch 28\n",
      "1.8827122864515886\n",
      "Validation loss: 1.7160356044769287\n",
      "mse 1.7160356610010312\n",
      "New best model found at epoch 28 with validation loss 1.7160356044769287\n",
      "Starting Epoch 29\n",
      "1.86987871190776\n",
      "Validation loss: 1.7052932977676392\n",
      "mse 1.705293300634293\n",
      "New best model found at epoch 29 with validation loss 1.7052932977676392\n",
      "Starting Epoch 30\n",
      "1.8577602220618206\n",
      "Validation loss: 1.694888710975647\n",
      "mse 1.6948887192117459\n",
      "New best model found at epoch 30 with validation loss 1.694888710975647\n",
      "Starting Epoch 31\n",
      "1.8463359293730364\n",
      "Validation loss: 1.6860634088516235\n",
      "mse 1.686063399863907\n",
      "New best model found at epoch 31 with validation loss 1.6860634088516235\n",
      "Starting Epoch 32\n",
      "1.8354723453521729\n",
      "Validation loss: 1.677087664604187\n",
      "mse 1.6770877250395946\n",
      "New best model found at epoch 32 with validation loss 1.677087664604187\n",
      "Starting Epoch 33\n",
      "1.8250981621120288\n",
      "Validation loss: 1.6688838005065918\n",
      "mse 1.6688838474229066\n",
      "New best model found at epoch 33 with validation loss 1.6688838005065918\n",
      "Starting Epoch 34\n",
      "1.8154296304868616\n",
      "Validation loss: 1.6610701084136963\n",
      "mse 1.6610702057189461\n",
      "New best model found at epoch 34 with validation loss 1.6610701084136963\n",
      "Starting Epoch 35\n",
      "1.8062171106753142\n",
      "Validation loss: 1.6541210412979126\n",
      "mse 1.6541209847634462\n",
      "New best model found at epoch 35 with validation loss 1.6541210412979126\n",
      "Starting Epoch 36\n",
      "1.7973655928736147\n",
      "Validation loss: 1.647408127784729\n",
      "mse 1.6474081620848198\n",
      "New best model found at epoch 36 with validation loss 1.647408127784729\n",
      "Starting Epoch 37\n",
      "1.7888920825460684\n",
      "Validation loss: 1.640942096710205\n",
      "mse 1.6409421280808048\n",
      "New best model found at epoch 37 with validation loss 1.640942096710205\n",
      "Starting Epoch 38\n",
      "1.78107620322186\n",
      "Validation loss: 1.6346055269241333\n",
      "mse 1.6346056843586643\n",
      "New best model found at epoch 38 with validation loss 1.6346055269241333\n",
      "Starting Epoch 39\n",
      "1.7735970694085825\n",
      "Validation loss: 1.6280326843261719\n",
      "mse 1.6280327341162992\n",
      "New best model found at epoch 39 with validation loss 1.6280326843261719\n",
      "Starting Epoch 40\n",
      "1.7666020859842715\n",
      "Validation loss: 1.6226699352264404\n",
      "mse 1.6226698394117822\n",
      "New best model found at epoch 40 with validation loss 1.6226699352264404\n",
      "Starting Epoch 41\n",
      "1.7598712236984917\n",
      "Validation loss: 1.6173309087753296\n",
      "mse 1.6173310688036127\n",
      "New best model found at epoch 41 with validation loss 1.6173309087753296\n",
      "Starting Epoch 42\n",
      "1.7534273137216982\n",
      "Validation loss: 1.6116958856582642\n",
      "mse 1.611695809351314\n",
      "New best model found at epoch 42 with validation loss 1.6116958856582642\n",
      "Starting Epoch 43\n",
      "1.7472914509151294\n",
      "Validation loss: 1.606371283531189\n",
      "mse 1.606371406499995\n",
      "New best model found at epoch 43 with validation loss 1.606371283531189\n",
      "Starting Epoch 44\n",
      "1.7414905454801477\n",
      "Validation loss: 1.601652979850769\n",
      "mse 1.6016530040859671\n",
      "New best model found at epoch 44 with validation loss 1.601652979850769\n",
      "Starting Epoch 45\n",
      "1.7358891549317732\n",
      "Validation loss: 1.5968571901321411\n",
      "mse 1.596857208198823\n",
      "New best model found at epoch 45 with validation loss 1.5968571901321411\n",
      "Starting Epoch 46\n",
      "1.7303852413011633\n",
      "Validation loss: 1.5925648212432861\n",
      "mse 1.5925647407201127\n",
      "New best model found at epoch 46 with validation loss 1.5925648212432861\n",
      "Starting Epoch 47\n",
      "1.7251958587895269\n",
      "Validation loss: 1.5881986618041992\n",
      "mse 1.5881986661180922\n",
      "New best model found at epoch 47 with validation loss 1.5881986618041992\n",
      "Starting Epoch 48\n",
      "1.7201749812001768\n",
      "Validation loss: 1.5844577550888062\n",
      "mse 1.5844578636826798\n",
      "New best model found at epoch 48 with validation loss 1.5844577550888062\n",
      "Starting Epoch 49\n",
      "1.7153806582741116\n",
      "Validation loss: 1.5810141563415527\n",
      "mse 1.5810140468387854\n",
      "New best model found at epoch 49 with validation loss 1.5810141563415527\n",
      "Starting Epoch 50\n",
      "1.7107126039007436\n",
      "Validation loss: 1.5768681764602661\n",
      "mse 1.5768681383519862\n",
      "New best model found at epoch 50 with validation loss 1.5768681764602661\n",
      "Starting Epoch 51\n",
      "1.706410781196926\n",
      "Validation loss: 1.5738321542739868\n",
      "mse 1.5738321263186184\n",
      "New best model found at epoch 51 with validation loss 1.5738321542739868\n",
      "Starting Epoch 52\n",
      "1.702211416285971\n",
      "Validation loss: 1.5701159238815308\n",
      "mse 1.5701159556859854\n",
      "New best model found at epoch 52 with validation loss 1.5701159238815308\n",
      "Starting Epoch 53\n",
      "1.6981782446736875\n",
      "Validation loss: 1.566437840461731\n",
      "mse 1.5664378537345132\n",
      "New best model found at epoch 53 with validation loss 1.566437840461731\n",
      "Starting Epoch 54\n",
      "1.694313189257746\n",
      "Validation loss: 1.5635879039764404\n",
      "mse 1.5635880050116475\n",
      "New best model found at epoch 54 with validation loss 1.5635879039764404\n",
      "Starting Epoch 55\n",
      "1.690566415372102\n",
      "Validation loss: 1.560716986656189\n",
      "mse 1.560717050491458\n",
      "New best model found at epoch 55 with validation loss 1.560716986656189\n",
      "Starting Epoch 56\n",
      "1.6869080014850781\n",
      "Validation loss: 1.5578147172927856\n",
      "mse 1.557814733592761\n",
      "New best model found at epoch 56 with validation loss 1.5578147172927856\n",
      "Starting Epoch 57\n",
      "1.6833817233210024\n",
      "Validation loss: 1.5551152229309082\n",
      "mse 1.5551153294665607\n",
      "New best model found at epoch 57 with validation loss 1.5551152229309082\n",
      "Starting Epoch 58\n",
      "1.6799084466436636\n",
      "Validation loss: 1.5522634983062744\n",
      "mse 1.552263409287543\n",
      "New best model found at epoch 58 with validation loss 1.5522634983062744\n",
      "Starting Epoch 59\n",
      "1.67657688907955\n",
      "Validation loss: 1.549609899520874\n",
      "mse 1.549609925437591\n",
      "New best model found at epoch 59 with validation loss 1.549609899520874\n",
      "Starting Epoch 60\n",
      "1.6733902485474297\n",
      "Validation loss: 1.5469738245010376\n",
      "mse 1.5469736064170099\n",
      "New best model found at epoch 60 with validation loss 1.5469738245010376\n",
      "Starting Epoch 61\n",
      "1.6703284045924311\n",
      "Validation loss: 1.5444709062576294\n",
      "mse 1.5444710617175612\n",
      "New best model found at epoch 61 with validation loss 1.5444709062576294\n",
      "Starting Epoch 62\n",
      "1.66732773055201\n",
      "Validation loss: 1.5420582294464111\n",
      "mse 1.5420582499088566\n",
      "New best model found at epoch 62 with validation loss 1.5420582294464111\n",
      "Starting Epoch 63\n",
      "1.6644871960515562\n",
      "Validation loss: 1.5397709608078003\n",
      "mse 1.5397711276474653\n",
      "New best model found at epoch 63 with validation loss 1.5397709608078003\n",
      "Starting Epoch 64\n",
      "1.661683352097221\n",
      "Validation loss: 1.5375568866729736\n",
      "mse 1.5375568403209712\n",
      "New best model found at epoch 64 with validation loss 1.5375568866729736\n",
      "Starting Epoch 65\n",
      "1.6589252741440483\n",
      "Validation loss: 1.5358704328536987\n",
      "mse 1.5358705320585841\n",
      "New best model found at epoch 65 with validation loss 1.5358704328536987\n",
      "Starting Epoch 66\n",
      "1.6563702251600183\n",
      "Validation loss: 1.5342320203781128\n",
      "mse 1.534232115789789\n",
      "New best model found at epoch 66 with validation loss 1.5342320203781128\n",
      "Starting Epoch 67\n",
      "1.6538500163866126\n",
      "Validation loss: 1.5321426391601562\n",
      "mse 1.532142600028884\n",
      "New best model found at epoch 67 with validation loss 1.5321426391601562\n",
      "Starting Epoch 68\n",
      "1.6514066613238791\n",
      "Validation loss: 1.5303083658218384\n",
      "mse 1.5303082736350402\n",
      "New best model found at epoch 68 with validation loss 1.5303083658218384\n",
      "Starting Epoch 69\n",
      "1.6490222111992214\n",
      "Validation loss: 1.5289368629455566\n",
      "mse 1.5289368068358211\n",
      "New best model found at epoch 69 with validation loss 1.5289368629455566\n",
      "Starting Epoch 70\n",
      "1.6467398716055828\n",
      "Validation loss: 1.527132272720337\n",
      "mse 1.5271324843367777\n",
      "New best model found at epoch 70 with validation loss 1.527132272720337\n",
      "Starting Epoch 71\n",
      "1.6444717127343882\n",
      "Validation loss: 1.5258522033691406\n",
      "mse 1.5258521018710545\n",
      "New best model found at epoch 71 with validation loss 1.5258522033691406\n",
      "Starting Epoch 72\n",
      "1.6423625946044922\n",
      "Validation loss: 1.5240800380706787\n",
      "mse 1.524080051574263\n",
      "New best model found at epoch 72 with validation loss 1.5240800380706787\n",
      "Starting Epoch 73\n",
      "1.6402702590693599\n",
      "Validation loss: 1.5222172737121582\n",
      "mse 1.5222172943949768\n",
      "New best model found at epoch 73 with validation loss 1.5222172737121582\n",
      "Starting Epoch 74\n",
      "1.6381862630014834\n",
      "Validation loss: 1.5210133790969849\n",
      "mse 1.5210131789375787\n",
      "New best model found at epoch 74 with validation loss 1.5210133790969849\n",
      "Starting Epoch 75\n",
      "1.6362371703852778\n",
      "Validation loss: 1.5190517902374268\n",
      "mse 1.5190517794274232\n",
      "New best model found at epoch 75 with validation loss 1.5190517902374268\n",
      "Starting Epoch 76\n",
      "1.6343090741530708\n",
      "Validation loss: 1.5178552865982056\n",
      "mse 1.5178552635316886\n",
      "New best model found at epoch 76 with validation loss 1.5178552865982056\n",
      "Starting Epoch 77\n",
      "1.6324289985325025\n",
      "Validation loss: 1.517039179801941\n",
      "mse 1.5170390811425267\n",
      "New best model found at epoch 77 with validation loss 1.517039179801941\n",
      "Starting Epoch 78\n",
      "1.6305990063625833\n",
      "Validation loss: 1.515528678894043\n",
      "mse 1.5155286434880182\n",
      "New best model found at epoch 78 with validation loss 1.515528678894043\n",
      "Starting Epoch 79\n",
      "1.6287800617839978\n",
      "Validation loss: 1.5142143964767456\n",
      "mse 1.5142144310108139\n",
      "New best model found at epoch 79 with validation loss 1.5142143964767456\n",
      "Starting Epoch 80\n",
      "1.6270130820896314\n",
      "Validation loss: 1.5134745836257935\n",
      "mse 1.5134747339234318\n",
      "New best model found at epoch 80 with validation loss 1.5134745836257935\n",
      "Starting Epoch 81\n",
      "1.625279239986254\n",
      "Validation loss: 1.5116773843765259\n",
      "mse 1.5116774465071212\n",
      "New best model found at epoch 81 with validation loss 1.5116773843765259\n",
      "Starting Epoch 82\n",
      "1.6235837677250737\n",
      "Validation loss: 1.5108301639556885\n",
      "mse 1.510830179835396\n",
      "New best model found at epoch 82 with validation loss 1.5108301639556885\n",
      "Starting Epoch 83\n",
      "1.6218450484068498\n",
      "Validation loss: 1.5094932317733765\n",
      "mse 1.5094932165360082\n",
      "New best model found at epoch 83 with validation loss 1.5094932317733765\n",
      "Starting Epoch 84\n",
      "1.6201554795970088\n",
      "Validation loss: 1.507318139076233\n",
      "mse 1.507318244484364\n",
      "New best model found at epoch 84 with validation loss 1.507318139076233\n",
      "Starting Epoch 85\n",
      "1.6181538156841113\n",
      "Validation loss: 1.5060228109359741\n",
      "mse 1.5060227303199503\n",
      "New best model found at epoch 85 with validation loss 1.5060228109359741\n",
      "Starting Epoch 86\n",
      "1.61632290871247\n",
      "Validation loss: 1.504537582397461\n",
      "mse 1.5045376528295038\n",
      "New best model found at epoch 86 with validation loss 1.504537582397461\n",
      "Starting Epoch 87\n",
      "1.6144714588704316\n",
      "Validation loss: 1.502902865409851\n",
      "mse 1.5029028503751731\n",
      "New best model found at epoch 87 with validation loss 1.502902865409851\n",
      "Starting Epoch 88\n",
      "1.6126771128695945\n",
      "Validation loss: 1.5015891790390015\n",
      "mse 1.5015891157403767\n",
      "New best model found at epoch 88 with validation loss 1.5015891790390015\n",
      "Starting Epoch 89\n",
      "1.6108306387196416\n",
      "Validation loss: 1.5004572868347168\n",
      "mse 1.5004574097467493\n",
      "New best model found at epoch 89 with validation loss 1.5004572868347168\n",
      "Starting Epoch 90\n",
      "1.6091081992439602\n",
      "Validation loss: 1.4991602897644043\n",
      "mse 1.4991603576646577\n",
      "New best model found at epoch 90 with validation loss 1.4991602897644043\n",
      "Starting Epoch 91\n",
      "1.607433109179787\n",
      "Validation loss: 1.4978249073028564\n",
      "mse 1.4978249215232253\n",
      "New best model found at epoch 91 with validation loss 1.4978249073028564\n",
      "Starting Epoch 92\n",
      "1.6056990597559058\n",
      "Validation loss: 1.4965670108795166\n",
      "mse 1.4965671193817989\n",
      "New best model found at epoch 92 with validation loss 1.4965670108795166\n",
      "Starting Epoch 93\n",
      "1.6040827165479246\n",
      "Validation loss: 1.495404601097107\n",
      "mse 1.4954044640328528\n",
      "New best model found at epoch 93 with validation loss 1.495404601097107\n",
      "Starting Epoch 94\n",
      "1.6026092664055203\n",
      "Validation loss: 1.4944671392440796\n",
      "mse 1.4944671769482862\n",
      "New best model found at epoch 94 with validation loss 1.4944671392440796\n",
      "Starting Epoch 95\n",
      "1.6012126725652944\n",
      "Validation loss: 1.4932608604431152\n",
      "mse 1.4932608589459397\n",
      "New best model found at epoch 95 with validation loss 1.4932608604431152\n",
      "Starting Epoch 96\n",
      "1.5998425380043362\n",
      "Validation loss: 1.4927725791931152\n",
      "mse 1.492772579568869\n",
      "New best model found at epoch 96 with validation loss 1.4927725791931152\n",
      "Starting Epoch 97\n",
      "1.598449758861376\n",
      "Validation loss: 1.4917967319488525\n",
      "mse 1.4917967170103172\n",
      "New best model found at epoch 97 with validation loss 1.4917967319488525\n",
      "Starting Epoch 98\n",
      "1.5971553377483203\n",
      "Validation loss: 1.490707278251648\n",
      "mse 1.490707402853097\n",
      "New best model found at epoch 98 with validation loss 1.490707278251648\n",
      "Starting Epoch 99\n",
      "1.5958287664081738\n",
      "Validation loss: 1.489696741104126\n",
      "mse 1.4896966976428039\n",
      "New best model found at epoch 99 with validation loss 1.489696741104126\n",
      "Starting Epoch 100\n",
      "1.5944718174312427\n",
      "Validation loss: 1.4889602661132812\n",
      "mse 1.488960387211022\n",
      "New best model found at epoch 100 with validation loss 1.4889602661132812\n",
      "Starting Epoch 101\n",
      "1.5931588307670925\n",
      "Validation loss: 1.4879508018493652\n",
      "mse 1.4879507618694057\n",
      "New best model found at epoch 101 with validation loss 1.4879508018493652\n",
      "Starting Epoch 102\n",
      "1.591920414696569\n",
      "Validation loss: 1.487687587738037\n",
      "mse 1.4876874421590007\n",
      "New best model found at epoch 102 with validation loss 1.487687587738037\n",
      "Starting Epoch 103\n",
      "1.5906959072403286\n",
      "Validation loss: 1.4866394996643066\n",
      "mse 1.4866394844210553\n",
      "New best model found at epoch 103 with validation loss 1.4866394996643066\n",
      "Starting Epoch 104\n",
      "1.5894694820694302\n",
      "Validation loss: 1.4857449531555176\n",
      "mse 1.4857447255335658\n",
      "New best model found at epoch 104 with validation loss 1.4857449531555176\n",
      "Starting Epoch 105\n",
      "1.5883184645486914\n",
      "Validation loss: 1.4851316213607788\n",
      "mse 1.48513165229871\n",
      "New best model found at epoch 105 with validation loss 1.4851316213607788\n",
      "Starting Epoch 106\n",
      "1.5871470181838325\n",
      "Validation loss: 1.4844383001327515\n",
      "mse 1.4844382474136573\n",
      "New best model found at epoch 106 with validation loss 1.4844383001327515\n",
      "Starting Epoch 107\n",
      "1.585991970870806\n",
      "Validation loss: 1.4838427305221558\n",
      "mse 1.4838427258332807\n",
      "New best model found at epoch 107 with validation loss 1.4838427305221558\n",
      "Starting Epoch 108\n",
      "1.5848492047061091\n",
      "Validation loss: 1.483154296875\n",
      "mse 1.4831542408437457\n",
      "New best model found at epoch 108 with validation loss 1.483154296875\n",
      "Starting Epoch 109\n",
      "1.5837416234223738\n",
      "Validation loss: 1.4825291633605957\n",
      "mse 1.4825292250986455\n",
      "New best model found at epoch 109 with validation loss 1.4825291633605957\n",
      "Starting Epoch 110\n",
      "1.5826801476271257\n",
      "Validation loss: 1.482189416885376\n",
      "mse 1.4821894099122916\n",
      "New best model found at epoch 110 with validation loss 1.482189416885376\n",
      "Starting Epoch 111\n",
      "1.5815368398376133\n",
      "Validation loss: 1.4812184572219849\n",
      "mse 1.4812184006729177\n",
      "New best model found at epoch 111 with validation loss 1.4812184572219849\n",
      "Starting Epoch 112\n",
      "1.5805911551351133\n",
      "Validation loss: 1.480513572692871\n",
      "mse 1.4805135999926213\n",
      "New best model found at epoch 112 with validation loss 1.480513572692871\n",
      "Starting Epoch 113\n",
      "1.579516537811445\n",
      "Validation loss: 1.4796630144119263\n",
      "mse 1.4796629730022264\n",
      "New best model found at epoch 113 with validation loss 1.4796630144119263\n",
      "Starting Epoch 114\n",
      "1.57850051962811\n",
      "Validation loss: 1.4792183637619019\n",
      "mse 1.4792183833218182\n",
      "New best model found at epoch 114 with validation loss 1.4792183637619019\n",
      "Starting Epoch 115\n",
      "1.5775114867998206\n",
      "Validation loss: 1.4784388542175293\n",
      "mse 1.4784387780673731\n",
      "New best model found at epoch 115 with validation loss 1.4784388542175293\n",
      "Starting Epoch 116\n",
      "1.576568725316421\n",
      "Validation loss: 1.478022813796997\n",
      "mse 1.4780227687020215\n",
      "New best model found at epoch 116 with validation loss 1.478022813796997\n",
      "Starting Epoch 117\n",
      "1.575507604557535\n",
      "Validation loss: 1.4772567749023438\n",
      "mse 1.477256779860438\n",
      "New best model found at epoch 117 with validation loss 1.4772567749023438\n",
      "Starting Epoch 118\n",
      "1.5746270755062932\n",
      "Validation loss: 1.4766888618469238\n",
      "mse 1.4766888481769493\n",
      "New best model found at epoch 118 with validation loss 1.4766888618469238\n",
      "Starting Epoch 119\n",
      "1.5735968714175017\n",
      "Validation loss: 1.4759654998779297\n",
      "mse 1.4759654516627199\n",
      "New best model found at epoch 119 with validation loss 1.4759654998779297\n",
      "Starting Epoch 120\n",
      "1.5727359263793281\n",
      "Validation loss: 1.475342869758606\n",
      "mse 1.4753427682830869\n",
      "New best model found at epoch 120 with validation loss 1.475342869758606\n",
      "Starting Epoch 121\n",
      "1.5717703725980676\n",
      "Validation loss: 1.4748221635818481\n",
      "mse 1.4748221572772622\n",
      "New best model found at epoch 121 with validation loss 1.4748221635818481\n",
      "Starting Epoch 122\n",
      "1.5708434555841528\n",
      "Validation loss: 1.4741774797439575\n",
      "mse 1.4741775348311055\n",
      "New best model found at epoch 122 with validation loss 1.4741774797439575\n",
      "Starting Epoch 123\n",
      "1.569941733194434\n",
      "Validation loss: 1.4735286235809326\n",
      "mse 1.473528602382383\n",
      "New best model found at epoch 123 with validation loss 1.4735286235809326\n",
      "Starting Epoch 124\n",
      "1.5690618261047031\n",
      "Validation loss: 1.4730606079101562\n",
      "mse 1.473060712393432\n",
      "New best model found at epoch 124 with validation loss 1.4730606079101562\n",
      "Starting Epoch 125\n",
      "1.5682127527568652\n",
      "Validation loss: 1.4725366830825806\n",
      "mse 1.4725365781934225\n",
      "New best model found at epoch 125 with validation loss 1.4725366830825806\n",
      "Starting Epoch 126\n",
      "1.567376927189205\n",
      "Validation loss: 1.4719310998916626\n",
      "mse 1.4719311004701208\n",
      "New best model found at epoch 126 with validation loss 1.4719310998916626\n",
      "Starting Epoch 127\n",
      "1.566485863664876\n",
      "Validation loss: 1.4714751243591309\n",
      "mse 1.4714751451866221\n",
      "New best model found at epoch 127 with validation loss 1.4714751243591309\n",
      "Starting Epoch 128\n",
      "1.5656474647314653\n",
      "Validation loss: 1.4709218740463257\n",
      "mse 1.4709218439239573\n",
      "New best model found at epoch 128 with validation loss 1.4709218740463257\n",
      "Starting Epoch 129\n",
      "1.5648323193840359\n",
      "Validation loss: 1.470310926437378\n",
      "mse 1.4703108543055137\n",
      "New best model found at epoch 129 with validation loss 1.470310926437378\n",
      "Starting Epoch 130\n",
      "1.5640286466349727\n",
      "Validation loss: 1.4698420763015747\n",
      "mse 1.4698419111862644\n",
      "New best model found at epoch 130 with validation loss 1.4698420763015747\n",
      "Starting Epoch 131\n",
      "1.5632059081741\n",
      "Validation loss: 1.4693485498428345\n",
      "mse 1.4693485719918329\n",
      "New best model found at epoch 131 with validation loss 1.4693485498428345\n",
      "Starting Epoch 132\n",
      "1.5623825840328052\n",
      "Validation loss: 1.4689877033233643\n",
      "mse 1.4689876847432741\n",
      "New best model found at epoch 132 with validation loss 1.4689877033233643\n",
      "Starting Epoch 133\n",
      "1.5615855144417805\n",
      "Validation loss: 1.468418836593628\n",
      "mse 1.468418732030885\n",
      "New best model found at epoch 133 with validation loss 1.468418836593628\n",
      "Starting Epoch 134\n",
      "1.560789406299591\n",
      "Validation loss: 1.4680516719818115\n",
      "mse 1.4680517420713504\n",
      "New best model found at epoch 134 with validation loss 1.4680516719818115\n",
      "Starting Epoch 135\n",
      "1.5599727397379668\n",
      "Validation loss: 1.4675601720809937\n",
      "mse 1.4675602559081262\n",
      "New best model found at epoch 135 with validation loss 1.4675601720809937\n",
      "Starting Epoch 136\n",
      "1.559203583261241\n",
      "Validation loss: 1.4671097993850708\n",
      "mse 1.4671099994309045\n",
      "New best model found at epoch 136 with validation loss 1.4671097993850708\n",
      "Starting Epoch 137\n",
      "1.558410592701124\n",
      "Validation loss: 1.466606616973877\n",
      "mse 1.4666066766280625\n",
      "New best model found at epoch 137 with validation loss 1.466606616973877\n",
      "Starting Epoch 138\n",
      "1.5576304663782534\n",
      "Validation loss: 1.466178297996521\n",
      "mse 1.4661784303938303\n",
      "New best model found at epoch 138 with validation loss 1.466178297996521\n",
      "Starting Epoch 139\n",
      "1.5568573734034663\n",
      "Validation loss: 1.4657231569290161\n",
      "mse 1.4657231331142628\n",
      "New best model found at epoch 139 with validation loss 1.4657231569290161\n",
      "Starting Epoch 140\n",
      "1.5560356404470361\n",
      "Validation loss: 1.465303659439087\n",
      "mse 1.4653037270383094\n",
      "New best model found at epoch 140 with validation loss 1.465303659439087\n",
      "Starting Epoch 141\n",
      "1.555268450923588\n",
      "Validation loss: 1.4647667407989502\n",
      "mse 1.4647667305013332\n",
      "New best model found at epoch 141 with validation loss 1.4647667407989502\n",
      "Starting Epoch 142\n",
      "1.5545308771340742\n",
      "Validation loss: 1.464186429977417\n",
      "mse 1.4641864238389728\n",
      "New best model found at epoch 142 with validation loss 1.464186429977417\n",
      "Starting Epoch 143\n",
      "1.5537364431049512\n",
      "Validation loss: 1.4638210535049438\n",
      "mse 1.4638210625331576\n",
      "New best model found at epoch 143 with validation loss 1.4638210535049438\n",
      "Starting Epoch 144\n",
      "1.5530499634535417\n",
      "Validation loss: 1.463292121887207\n",
      "mse 1.4632921807767034\n",
      "New best model found at epoch 144 with validation loss 1.463292121887207\n",
      "Starting Epoch 145\n",
      "1.552270850409632\n",
      "Validation loss: 1.4629733562469482\n",
      "mse 1.4629733617011775\n",
      "New best model found at epoch 145 with validation loss 1.4629733562469482\n",
      "Starting Epoch 146\n",
      "1.5515564239543418\n",
      "Validation loss: 1.4626319408416748\n",
      "mse 1.4626320529448293\n",
      "New best model found at epoch 146 with validation loss 1.4626319408416748\n",
      "Starting Epoch 147\n",
      "1.5508495258248371\n",
      "Validation loss: 1.4622983932495117\n",
      "mse 1.4622983810183456\n",
      "New best model found at epoch 147 with validation loss 1.4622983932495117\n",
      "Starting Epoch 148\n",
      "1.5500784360844155\n",
      "Validation loss: 1.4620040655136108\n",
      "mse 1.4620040853261846\n",
      "New best model found at epoch 148 with validation loss 1.4620040655136108\n",
      "Starting Epoch 149\n",
      "1.5494269910066023\n",
      "Validation loss: 1.461922526359558\n",
      "mse 1.461922440583091\n",
      "New best model found at epoch 149 with validation loss 1.461922526359558\n",
      "Starting Epoch 150\n",
      "1.5486492436865102\n",
      "Validation loss: 1.4615751504898071\n",
      "mse 1.461575230234649\n",
      "New best model found at epoch 150 with validation loss 1.4615751504898071\n",
      "Starting Epoch 151\n",
      "1.547972145287887\n",
      "Validation loss: 1.4612843990325928\n",
      "mse 1.4612844164235506\n",
      "New best model found at epoch 151 with validation loss 1.4612843990325928\n",
      "Starting Epoch 152\n",
      "1.5472350846166196\n",
      "Validation loss: 1.4609216451644897\n",
      "mse 1.4609215852970474\n",
      "New best model found at epoch 152 with validation loss 1.4609216451644897\n",
      "Starting Epoch 153\n",
      "1.5465186108713564\n",
      "Validation loss: 1.460592269897461\n",
      "mse 1.4605921903253116\n",
      "New best model found at epoch 153 with validation loss 1.460592269897461\n",
      "Starting Epoch 154\n",
      "1.5458871307580366\n",
      "Validation loss: 1.460174322128296\n",
      "mse 1.4601742863159974\n",
      "New best model found at epoch 154 with validation loss 1.460174322128296\n",
      "Starting Epoch 155\n",
      "1.5450339110001274\n",
      "Validation loss: 1.459596872329712\n",
      "mse 1.4595968944857272\n",
      "New best model found at epoch 155 with validation loss 1.459596872329712\n",
      "Starting Epoch 156\n",
      "1.5442920379016711\n",
      "Validation loss: 1.458940863609314\n",
      "mse 1.4589410158852911\n",
      "New best model found at epoch 156 with validation loss 1.458940863609314\n",
      "Starting Epoch 157\n",
      "1.5435039141903752\n",
      "Validation loss: 1.4585092067718506\n",
      "mse 1.4585091858726165\n",
      "New best model found at epoch 157 with validation loss 1.4585092067718506\n",
      "Starting Epoch 158\n",
      "1.5427100114200427\n",
      "Validation loss: 1.4579836130142212\n",
      "mse 1.4579836053029531\n",
      "New best model found at epoch 158 with validation loss 1.4579836130142212\n",
      "Starting Epoch 159\n",
      "1.5419275320094565\n",
      "Validation loss: 1.4572972059249878\n",
      "mse 1.4572970107194685\n",
      "New best model found at epoch 159 with validation loss 1.4572972059249878\n",
      "Starting Epoch 160\n",
      "1.5412201803663503\n",
      "Validation loss: 1.4567646980285645\n",
      "mse 1.456764666436435\n",
      "New best model found at epoch 160 with validation loss 1.4567646980285645\n",
      "Starting Epoch 161\n",
      "1.5404574249101721\n",
      "Validation loss: 1.4562439918518066\n",
      "mse 1.456243940877019\n",
      "New best model found at epoch 161 with validation loss 1.4562439918518066\n",
      "Starting Epoch 162\n",
      "1.5397096716839334\n",
      "Validation loss: 1.4556668996810913\n",
      "mse 1.4556669052723734\n",
      "New best model found at epoch 162 with validation loss 1.4556668996810913\n",
      "Starting Epoch 163\n",
      "1.5390034162479898\n",
      "Validation loss: 1.4550739526748657\n",
      "mse 1.455073999226676\n",
      "New best model found at epoch 163 with validation loss 1.4550739526748657\n",
      "Starting Epoch 164\n",
      "1.5382828790208567\n",
      "Validation loss: 1.4545341730117798\n",
      "mse 1.454534032839711\n",
      "New best model found at epoch 164 with validation loss 1.4545341730117798\n",
      "Starting Epoch 165\n",
      "1.5375843307246333\n",
      "Validation loss: 1.4538812637329102\n",
      "mse 1.4538812168639694\n",
      "New best model found at epoch 165 with validation loss 1.4538812637329102\n",
      "Starting Epoch 166\n",
      "1.5369237661361694\n",
      "Validation loss: 1.4534863233566284\n",
      "mse 1.4534862932115904\n",
      "New best model found at epoch 166 with validation loss 1.4534863233566284\n",
      "Starting Epoch 167\n",
      "1.5362559245980305\n",
      "Validation loss: 1.4529796838760376\n",
      "mse 1.4529797152177488\n",
      "New best model found at epoch 167 with validation loss 1.4529796838760376\n",
      "Starting Epoch 168\n",
      "1.5356129770693572\n",
      "Validation loss: 1.4524128437042236\n",
      "mse 1.4524128527325768\n",
      "New best model found at epoch 168 with validation loss 1.4524128437042236\n",
      "Starting Epoch 169\n",
      "1.534976575685584\n",
      "Validation loss: 1.4520469903945923\n",
      "mse 1.452046907680706\n",
      "New best model found at epoch 169 with validation loss 1.4520469903945923\n",
      "Starting Epoch 170\n",
      "1.5343308811602385\n",
      "Validation loss: 1.4514857530593872\n",
      "mse 1.4514858663015906\n",
      "New best model found at epoch 170 with validation loss 1.4514857530593872\n",
      "Starting Epoch 171\n",
      "1.5336862724760305\n",
      "Validation loss: 1.4510235786437988\n",
      "mse 1.451023569164849\n",
      "New best model found at epoch 171 with validation loss 1.4510235786437988\n",
      "Starting Epoch 172\n",
      "1.5331037899722224\n",
      "Validation loss: 1.4505665302276611\n",
      "mse 1.4505665906671696\n",
      "New best model found at epoch 172 with validation loss 1.4505665302276611\n",
      "Starting Epoch 173\n",
      "1.5324374307756838\n",
      "Validation loss: 1.450282335281372\n",
      "mse 1.4502823133252296\n",
      "New best model found at epoch 173 with validation loss 1.450282335281372\n",
      "Starting Epoch 174\n",
      "1.5318339959434841\n",
      "Validation loss: 1.4497736692428589\n",
      "mse 1.449773648144377\n",
      "New best model found at epoch 174 with validation loss 1.4497736692428589\n",
      "Starting Epoch 175\n",
      "1.531311156957046\n",
      "Validation loss: 1.4493236541748047\n",
      "mse 1.4493235459695317\n",
      "New best model found at epoch 175 with validation loss 1.4493236541748047\n",
      "Starting Epoch 176\n",
      "1.5307095543197964\n",
      "Validation loss: 1.4489076137542725\n",
      "mse 1.448907584035728\n",
      "New best model found at epoch 176 with validation loss 1.4489076137542725\n",
      "Starting Epoch 177\n",
      "1.530152800290481\n",
      "Validation loss: 1.4486181735992432\n",
      "mse 1.4486181856256128\n",
      "New best model found at epoch 177 with validation loss 1.4486181735992432\n",
      "Starting Epoch 178\n",
      "1.5295942503473032\n",
      "Validation loss: 1.448236107826233\n",
      "mse 1.4482361200795582\n",
      "New best model found at epoch 178 with validation loss 1.448236107826233\n",
      "Starting Epoch 179\n",
      "1.529001155625219\n",
      "Validation loss: 1.447946548461914\n",
      "mse 1.4479465347284526\n",
      "New best model found at epoch 179 with validation loss 1.447946548461914\n",
      "Starting Epoch 180\n",
      "1.5284291998199795\n",
      "Validation loss: 1.4475717544555664\n",
      "mse 1.447571686795822\n",
      "New best model found at epoch 180 with validation loss 1.4475717544555664\n",
      "Starting Epoch 181\n",
      "1.5279248719630034\n",
      "Validation loss: 1.447153925895691\n",
      "mse 1.4471538776672057\n",
      "New best model found at epoch 181 with validation loss 1.447153925895691\n",
      "Starting Epoch 182\n",
      "1.527381217998007\n",
      "Validation loss: 1.4467824697494507\n",
      "mse 1.4467825050025462\n",
      "New best model found at epoch 182 with validation loss 1.4467824697494507\n",
      "Starting Epoch 183\n",
      "1.5268392511036084\n",
      "Validation loss: 1.4463937282562256\n",
      "mse 1.44639366226634\n",
      "New best model found at epoch 183 with validation loss 1.4463937282562256\n",
      "Starting Epoch 184\n",
      "1.5262995310451672\n",
      "Validation loss: 1.4460577964782715\n",
      "mse 1.4460578564956375\n",
      "New best model found at epoch 184 with validation loss 1.4460577964782715\n",
      "Starting Epoch 185\n",
      "1.5258015186890312\n",
      "Validation loss: 1.445697546005249\n",
      "mse 1.4456974960185223\n",
      "New best model found at epoch 185 with validation loss 1.445697546005249\n",
      "Starting Epoch 186\n",
      "1.5251982004746147\n",
      "Validation loss: 1.4452717304229736\n",
      "mse 1.445271727750716\n",
      "New best model found at epoch 186 with validation loss 1.4452717304229736\n",
      "Starting Epoch 187\n",
      "1.5246569306954094\n",
      "Validation loss: 1.4447463750839233\n",
      "mse 1.4447463499544233\n",
      "New best model found at epoch 187 with validation loss 1.4447463750839233\n",
      "Starting Epoch 188\n",
      "1.5239543526068977\n",
      "Validation loss: 1.4440785646438599\n",
      "mse 1.44407856484948\n",
      "New best model found at epoch 188 with validation loss 1.4440785646438599\n",
      "Starting Epoch 189\n",
      "1.523228057052778\n",
      "Validation loss: 1.4434378147125244\n",
      "mse 1.44343773060551\n",
      "New best model found at epoch 189 with validation loss 1.4434378147125244\n",
      "Starting Epoch 190\n",
      "1.5224103564801423\n",
      "Validation loss: 1.4429258108139038\n",
      "mse 1.4429258443994943\n",
      "New best model found at epoch 190 with validation loss 1.4429258108139038\n",
      "Starting Epoch 191\n",
      "1.5216532971547998\n",
      "Validation loss: 1.442366361618042\n",
      "mse 1.4423664194694672\n",
      "New best model found at epoch 191 with validation loss 1.442366361618042\n",
      "Starting Epoch 192\n",
      "1.5208808961121931\n",
      "Validation loss: 1.4417237043380737\n",
      "mse 1.441723637954125\n",
      "New best model found at epoch 192 with validation loss 1.4417237043380737\n",
      "Starting Epoch 193\n",
      "1.5201221808143284\n",
      "Validation loss: 1.441238522529602\n",
      "mse 1.4412386886861455\n",
      "New best model found at epoch 193 with validation loss 1.441238522529602\n",
      "Starting Epoch 194\n",
      "1.5194090786187544\n",
      "Validation loss: 1.4406815767288208\n",
      "mse 1.4406814355415245\n",
      "New best model found at epoch 194 with validation loss 1.4406815767288208\n",
      "Starting Epoch 195\n",
      "1.518644763075787\n",
      "Validation loss: 1.4402462244033813\n",
      "mse 1.440246183407203\n",
      "New best model found at epoch 195 with validation loss 1.4402462244033813\n",
      "Starting Epoch 196\n",
      "1.5179035456284233\n",
      "Validation loss: 1.4397926330566406\n",
      "mse 1.439792687202476\n",
      "New best model found at epoch 196 with validation loss 1.4397926330566406\n",
      "Starting Epoch 197\n",
      "1.5172182606614155\n",
      "Validation loss: 1.4392751455307007\n",
      "mse 1.439275101687949\n",
      "New best model found at epoch 197 with validation loss 1.4392751455307007\n",
      "Starting Epoch 198\n",
      "1.5164811922156292\n",
      "Validation loss: 1.4388443231582642\n",
      "mse 1.4388442548950091\n",
      "New best model found at epoch 198 with validation loss 1.4388443231582642\n",
      "Starting Epoch 199\n",
      "1.51577351404273\n",
      "Validation loss: 1.4383000135421753\n",
      "mse 1.438300051251119\n",
      "New best model found at epoch 199 with validation loss 1.4383000135421753\n",
      "Starting Epoch 200\n",
      "1.5151204829630645\n",
      "Validation loss: 1.438094973564148\n",
      "mse 1.4380949916135837\n",
      "New best model found at epoch 200 with validation loss 1.438094973564148\n",
      "Starting Epoch 201\n",
      "1.5145766527756401\n",
      "Validation loss: 1.4377459287643433\n",
      "mse 1.4377459126222998\n",
      "New best model found at epoch 201 with validation loss 1.4377459287643433\n",
      "Starting Epoch 202\n",
      "1.5140070656071538\n",
      "Validation loss: 1.4374735355377197\n",
      "mse 1.4374736424884629\n",
      "New best model found at epoch 202 with validation loss 1.4374735355377197\n",
      "Starting Epoch 203\n",
      "1.5134909749031067\n",
      "Validation loss: 1.4370629787445068\n",
      "mse 1.4370629230813203\n",
      "New best model found at epoch 203 with validation loss 1.4370629787445068\n",
      "Starting Epoch 204\n",
      "1.51291372983352\n",
      "Validation loss: 1.4368464946746826\n",
      "mse 1.4368464592745345\n",
      "New best model found at epoch 204 with validation loss 1.4368464946746826\n",
      "Starting Epoch 205\n",
      "1.5123874493267224\n",
      "Validation loss: 1.4365005493164062\n",
      "mse 1.4365006055069482\n",
      "New best model found at epoch 205 with validation loss 1.4365005493164062\n",
      "Starting Epoch 206\n",
      "1.5118280519609866\n",
      "Validation loss: 1.436271071434021\n",
      "mse 1.4362711090612328\n",
      "New best model found at epoch 206 with validation loss 1.436271071434021\n",
      "Starting Epoch 207\n",
      "1.5113431552182073\n",
      "Validation loss: 1.4359948635101318\n",
      "mse 1.4359948111156222\n",
      "New best model found at epoch 207 with validation loss 1.4359948635101318\n",
      "Starting Epoch 208\n",
      "1.5107571897299394\n",
      "Validation loss: 1.4356846809387207\n",
      "mse 1.4356846693822418\n",
      "New best model found at epoch 208 with validation loss 1.4356846809387207\n",
      "Starting Epoch 209\n",
      "1.5102566998937856\n",
      "Validation loss: 1.4353606700897217\n",
      "mse 1.4353607780858326\n",
      "New best model found at epoch 209 with validation loss 1.4353606700897217\n",
      "Starting Epoch 210\n",
      "1.5097138104231462\n",
      "Validation loss: 1.4351483583450317\n",
      "mse 1.435148392214991\n",
      "New best model found at epoch 210 with validation loss 1.4351483583450317\n",
      "Starting Epoch 211\n",
      "1.5092117656832156\n",
      "Validation loss: 1.4347788095474243\n",
      "mse 1.4347788609996124\n",
      "New best model found at epoch 211 with validation loss 1.4347788095474243\n",
      "Starting Epoch 212\n",
      "1.508680030055668\n",
      "Validation loss: 1.434557557106018\n",
      "mse 1.434557518695122\n",
      "New best model found at epoch 212 with validation loss 1.434557557106018\n",
      "Starting Epoch 213\n",
      "1.5082053360731706\n",
      "Validation loss: 1.434190034866333\n",
      "mse 1.4341899701226561\n",
      "New best model found at epoch 213 with validation loss 1.434190034866333\n",
      "Starting Epoch 214\n",
      "1.5077419047770293\n",
      "Validation loss: 1.4341614246368408\n",
      "mse 1.4341614904836246\n",
      "New best model found at epoch 214 with validation loss 1.4341614246368408\n",
      "Starting Epoch 215\n",
      "1.5072412724080293\n",
      "Validation loss: 1.4337049722671509\n",
      "mse 1.4337049436828657\n",
      "New best model found at epoch 215 with validation loss 1.4337049722671509\n",
      "Starting Epoch 216\n",
      "1.5067850247673367\n",
      "Validation loss: 1.433717966079712\n",
      "mse 1.4337177689329113\n",
      "Starting Epoch 217\n",
      "1.5063023256218953\n",
      "Validation loss: 1.4332265853881836\n",
      "mse 1.433226515521937\n",
      "New best model found at epoch 217 with validation loss 1.4332265853881836\n",
      "Starting Epoch 218\n",
      "1.5058443649955418\n",
      "Validation loss: 1.4331492185592651\n",
      "mse 1.433149204364685\n",
      "New best model found at epoch 218 with validation loss 1.4331492185592651\n",
      "Starting Epoch 219\n",
      "1.5053658563157786\n",
      "Validation loss: 1.432706594467163\n",
      "mse 1.4327066626402134\n",
      "New best model found at epoch 219 with validation loss 1.432706594467163\n",
      "Starting Epoch 220\n",
      "1.5048959747604702\n",
      "Validation loss: 1.432404637336731\n",
      "mse 1.4324046454064212\n",
      "New best model found at epoch 220 with validation loss 1.432404637336731\n",
      "Starting Epoch 221\n",
      "1.5044410513794941\n",
      "Validation loss: 1.4322209358215332\n",
      "mse 1.4322210570424483\n",
      "New best model found at epoch 221 with validation loss 1.4322209358215332\n",
      "Starting Epoch 222\n",
      "1.5040514080420784\n",
      "Validation loss: 1.43220055103302\n",
      "mse 1.4322004554272016\n",
      "New best model found at epoch 222 with validation loss 1.43220055103302\n",
      "Starting Epoch 223\n",
      "1.5035774578218875\n",
      "Validation loss: 1.4317947626113892\n",
      "mse 1.4317948029484415\n",
      "New best model found at epoch 223 with validation loss 1.4317947626113892\n",
      "Starting Epoch 224\n",
      "1.5031017609264539\n",
      "Validation loss: 1.4316074848175049\n",
      "mse 1.4316074685070572\n",
      "New best model found at epoch 224 with validation loss 1.4316074848175049\n",
      "Starting Epoch 225\n",
      "1.5026609301567078\n",
      "Validation loss: 1.4312167167663574\n",
      "mse 1.4312167859138762\n",
      "New best model found at epoch 225 with validation loss 1.4312167167663574\n",
      "Starting Epoch 226\n",
      "1.5022748449574346\n",
      "Validation loss: 1.4311531782150269\n",
      "mse 1.431153223710194\n",
      "New best model found at epoch 226 with validation loss 1.4311531782150269\n",
      "Starting Epoch 227\n",
      "1.5017916223277217\n",
      "Validation loss: 1.4306857585906982\n",
      "mse 1.4306858025454645\n",
      "New best model found at epoch 227 with validation loss 1.4306857585906982\n",
      "Starting Epoch 228\n",
      "1.5013956997705542\n",
      "Validation loss: 1.4305808544158936\n",
      "mse 1.4305808223339695\n",
      "New best model found at epoch 228 with validation loss 1.4305808544158936\n",
      "Starting Epoch 229\n",
      "1.500944303429645\n",
      "Validation loss: 1.4300025701522827\n",
      "mse 1.4300024930677906\n",
      "New best model found at epoch 229 with validation loss 1.4300025701522827\n",
      "Starting Epoch 230\n",
      "1.5004488126091335\n",
      "Validation loss: 1.4296351671218872\n",
      "mse 1.4296350972804743\n",
      "New best model found at epoch 230 with validation loss 1.4296351671218872\n",
      "Starting Epoch 231\n",
      "1.499932638976885\n",
      "Validation loss: 1.4293798208236694\n",
      "mse 1.4293797556357115\n",
      "New best model found at epoch 231 with validation loss 1.4293798208236694\n",
      "Starting Epoch 232\n",
      "1.4994951408842336\n",
      "Validation loss: 1.4291000366210938\n",
      "mse 1.4291000164674437\n",
      "New best model found at epoch 232 with validation loss 1.4291000366210938\n",
      "Starting Epoch 233\n",
      "1.4990206956863403\n",
      "Validation loss: 1.4288125038146973\n",
      "mse 1.4288125155505436\n",
      "New best model found at epoch 233 with validation loss 1.4288125038146973\n",
      "Starting Epoch 234\n",
      "1.4986092966535818\n",
      "Validation loss: 1.4285588264465332\n",
      "mse 1.4285588288304802\n",
      "New best model found at epoch 234 with validation loss 1.4285588264465332\n",
      "Starting Epoch 235\n",
      "1.4981270717537922\n",
      "Validation loss: 1.4282960891723633\n",
      "mse 1.4282961596013486\n",
      "New best model found at epoch 235 with validation loss 1.4282960891723633\n",
      "Starting Epoch 236\n",
      "1.4976998956307122\n",
      "Validation loss: 1.4280906915664673\n",
      "mse 1.4280906944494494\n",
      "New best model found at epoch 236 with validation loss 1.4280906915664673\n",
      "Starting Epoch 237\n",
      "1.49727099356444\n",
      "Validation loss: 1.427882194519043\n",
      "mse 1.4278820824336396\n",
      "New best model found at epoch 237 with validation loss 1.427882194519043\n",
      "Starting Epoch 238\n",
      "1.4968253996061243\n",
      "Validation loss: 1.4276270866394043\n",
      "mse 1.4276269732923772\n",
      "New best model found at epoch 238 with validation loss 1.4276270866394043\n",
      "Starting Epoch 239\n",
      "1.4964035516199858\n",
      "Validation loss: 1.4273558855056763\n",
      "mse 1.427355802644408\n",
      "New best model found at epoch 239 with validation loss 1.4273558855056763\n",
      "Starting Epoch 240\n",
      "1.4960009455680847\n",
      "Validation loss: 1.4270899295806885\n",
      "mse 1.4270899170242834\n",
      "New best model found at epoch 240 with validation loss 1.4270899295806885\n",
      "Starting Epoch 241\n",
      "1.4955572796904522\n",
      "Validation loss: 1.4268349409103394\n",
      "mse 1.4268349946316712\n",
      "New best model found at epoch 241 with validation loss 1.4268349409103394\n",
      "Starting Epoch 242\n",
      "1.4951428434123164\n",
      "Validation loss: 1.4266191720962524\n",
      "mse 1.4266193447402185\n",
      "New best model found at epoch 242 with validation loss 1.4266191720962524\n",
      "Starting Epoch 243\n",
      "1.4947518136190332\n",
      "Validation loss: 1.42630136013031\n",
      "mse 1.426301291956812\n",
      "New best model found at epoch 243 with validation loss 1.42630136013031\n",
      "Starting Epoch 244\n",
      "1.4943113923072815\n",
      "Validation loss: 1.4260936975479126\n",
      "mse 1.426093723322554\n",
      "New best model found at epoch 244 with validation loss 1.4260936975479126\n",
      "Starting Epoch 245\n",
      "1.4939230680465698\n",
      "Validation loss: 1.4258463382720947\n",
      "mse 1.4258462827395486\n",
      "New best model found at epoch 245 with validation loss 1.4258463382720947\n",
      "Starting Epoch 246\n",
      "1.4934952103573342\n",
      "Validation loss: 1.4255120754241943\n",
      "mse 1.4255121416868894\n",
      "New best model found at epoch 246 with validation loss 1.4255120754241943\n",
      "Starting Epoch 247\n",
      "1.4930629807969797\n",
      "Validation loss: 1.4252601861953735\n",
      "mse 1.425260323328622\n",
      "New best model found at epoch 247 with validation loss 1.4252601861953735\n",
      "Starting Epoch 248\n",
      "1.4927054073499597\n",
      "Validation loss: 1.4250015020370483\n",
      "mse 1.4250015985863653\n",
      "New best model found at epoch 248 with validation loss 1.4250015020370483\n",
      "Starting Epoch 249\n",
      "1.4922729445540386\n",
      "Validation loss: 1.4248241186141968\n",
      "mse 1.4248240837051136\n",
      "New best model found at epoch 249 with validation loss 1.4248241186141968\n",
      "Starting Epoch 250\n",
      "1.4918708360713462\n",
      "Validation loss: 1.424562692642212\n",
      "mse 1.4245627872407183\n",
      "New best model found at epoch 250 with validation loss 1.424562692642212\n",
      "Starting Epoch 251\n",
      "1.4914603103762087\n",
      "Validation loss: 1.4243496656417847\n",
      "mse 1.4243495979598089\n",
      "New best model found at epoch 251 with validation loss 1.4243496656417847\n",
      "Starting Epoch 252\n",
      "1.491059124469757\n",
      "Validation loss: 1.4240670204162598\n",
      "mse 1.4240669997740067\n",
      "New best model found at epoch 252 with validation loss 1.4240670204162598\n",
      "Starting Epoch 253\n",
      "1.4906830476677937\n",
      "Validation loss: 1.42379629611969\n",
      "mse 1.423796389760351\n",
      "New best model found at epoch 253 with validation loss 1.42379629611969\n",
      "Starting Epoch 254\n",
      "1.4902866404989492\n",
      "Validation loss: 1.4237544536590576\n",
      "mse 1.423754366542412\n",
      "New best model found at epoch 254 with validation loss 1.4237544536590576\n",
      "Starting Epoch 255\n",
      "1.4898936385693757\n",
      "Validation loss: 1.4232690334320068\n",
      "mse 1.4232690004463457\n",
      "New best model found at epoch 255 with validation loss 1.4232690334320068\n",
      "Starting Epoch 256\n",
      "1.489477408968884\n",
      "Validation loss: 1.4230220317840576\n",
      "mse 1.423021986515258\n",
      "New best model found at epoch 256 with validation loss 1.4230220317840576\n",
      "Starting Epoch 257\n",
      "1.489116090795268\n",
      "Validation loss: 1.4229764938354492\n",
      "mse 1.4229765538478767\n",
      "New best model found at epoch 257 with validation loss 1.4229764938354492\n",
      "Starting Epoch 258\n",
      "1.48869127035141\n",
      "Validation loss: 1.42253839969635\n",
      "mse 1.4225383551464494\n",
      "New best model found at epoch 258 with validation loss 1.42253839969635\n",
      "Starting Epoch 259\n",
      "1.4883393230645552\n",
      "Validation loss: 1.4223016500473022\n",
      "mse 1.4223016562233632\n",
      "New best model found at epoch 259 with validation loss 1.4223016500473022\n",
      "Starting Epoch 260\n",
      "1.4879371627517368\n",
      "Validation loss: 1.4219937324523926\n",
      "mse 1.4219937265346658\n",
      "New best model found at epoch 260 with validation loss 1.4219937324523926\n",
      "Starting Epoch 261\n",
      "1.4875422094179236\n",
      "Validation loss: 1.422022819519043\n",
      "mse 1.4220228184277628\n",
      "Starting Epoch 262\n",
      "1.4871592573497607\n",
      "Validation loss: 1.421545386314392\n",
      "mse 1.4215453544404386\n",
      "New best model found at epoch 262 with validation loss 1.421545386314392\n",
      "Starting Epoch 263\n",
      "1.486754077932109\n",
      "Validation loss: 1.4213143587112427\n",
      "mse 1.4213143452634254\n",
      "New best model found at epoch 263 with validation loss 1.4213143587112427\n",
      "Starting Epoch 264\n",
      "1.4863965226256328\n",
      "Validation loss: 1.4212809801101685\n",
      "mse 1.4212810853816722\n",
      "New best model found at epoch 264 with validation loss 1.4212809801101685\n",
      "Starting Epoch 265\n",
      "1.485988041628962\n",
      "Validation loss: 1.421050786972046\n",
      "mse 1.4210508116566558\n",
      "New best model found at epoch 265 with validation loss 1.421050786972046\n",
      "Starting Epoch 266\n",
      "1.4856314140817393\n",
      "Validation loss: 1.4205042123794556\n",
      "mse 1.4205042608103255\n",
      "New best model found at epoch 266 with validation loss 1.4205042123794556\n",
      "Starting Epoch 267\n",
      "1.4852454947388691\n",
      "Validation loss: 1.420562982559204\n",
      "mse 1.4205629172332275\n",
      "Starting Epoch 268\n",
      "1.4848615475322888\n",
      "Validation loss: 1.420027494430542\n",
      "mse 1.4200273785233646\n",
      "New best model found at epoch 268 with validation loss 1.420027494430542\n",
      "Starting Epoch 269\n",
      "1.4845273442890332\n",
      "Validation loss: 1.4199284315109253\n",
      "mse 1.4199284182505227\n",
      "New best model found at epoch 269 with validation loss 1.4199284315109253\n",
      "Starting Epoch 270\n",
      "1.4840878455535225\n",
      "Validation loss: 1.4197509288787842\n",
      "mse 1.4197509502504237\n",
      "New best model found at epoch 270 with validation loss 1.4197509288787842\n",
      "Starting Epoch 271\n",
      "1.4837566406830498\n",
      "Validation loss: 1.419197678565979\n",
      "mse 1.4191975666968464\n",
      "New best model found at epoch 271 with validation loss 1.419197678565979\n",
      "Starting Epoch 272\n",
      "1.4834032266036323\n",
      "Validation loss: 1.419148564338684\n",
      "mse 1.419148758646827\n",
      "New best model found at epoch 272 with validation loss 1.419148564338684\n",
      "Starting Epoch 273\n",
      "1.483061951139699\n",
      "Validation loss: 1.4186832904815674\n",
      "mse 1.4186831773538713\n",
      "New best model found at epoch 273 with validation loss 1.4186832904815674\n",
      "Starting Epoch 274\n",
      "1.48262889229733\n",
      "Validation loss: 1.4187521934509277\n",
      "mse 1.4187523496176568\n",
      "Starting Epoch 275\n",
      "1.4822988950687905\n",
      "Validation loss: 1.4181357622146606\n",
      "mse 1.418135749795047\n",
      "New best model found at epoch 275 with validation loss 1.4181357622146606\n",
      "Starting Epoch 276\n",
      "1.481928542904232\n",
      "Validation loss: 1.4180811643600464\n",
      "mse 1.4180811211511473\n",
      "New best model found at epoch 276 with validation loss 1.4180811643600464\n",
      "Starting Epoch 277\n",
      "1.4815625677938047\n",
      "Validation loss: 1.4178520441055298\n",
      "mse 1.4178519937494878\n",
      "New best model found at epoch 277 with validation loss 1.4178520441055298\n",
      "Starting Epoch 278\n",
      "1.4812175916588826\n",
      "Validation loss: 1.4175337553024292\n",
      "mse 1.4175336899219866\n",
      "New best model found at epoch 278 with validation loss 1.4175337553024292\n",
      "Starting Epoch 279\n",
      "1.4808550632518271\n",
      "Validation loss: 1.4172523021697998\n",
      "mse 1.4172523504893342\n",
      "New best model found at epoch 279 with validation loss 1.4172523021697998\n",
      "Starting Epoch 280\n",
      "1.480488499869471\n",
      "Validation loss: 1.416974425315857\n",
      "mse 1.4169743524950904\n",
      "New best model found at epoch 280 with validation loss 1.416974425315857\n",
      "Starting Epoch 281\n",
      "1.4801458949628084\n",
      "Validation loss: 1.4167219400405884\n",
      "mse 1.416722007529606\n",
      "New best model found at epoch 281 with validation loss 1.4167219400405884\n",
      "Starting Epoch 282\n",
      "1.4798013153283491\n",
      "Validation loss: 1.4163925647735596\n",
      "mse 1.4163926100285953\n",
      "New best model found at epoch 282 with validation loss 1.4163925647735596\n",
      "Starting Epoch 283\n",
      "1.479415826175524\n",
      "Validation loss: 1.4161301851272583\n",
      "mse 1.4161301397147465\n",
      "New best model found at epoch 283 with validation loss 1.4161301851272583\n",
      "Starting Epoch 284\n",
      "1.479061378085095\n",
      "Validation loss: 1.4158332347869873\n",
      "mse 1.4158332422205517\n",
      "New best model found at epoch 284 with validation loss 1.4158332347869873\n",
      "Starting Epoch 285\n",
      "1.4786890926568403\n",
      "Validation loss: 1.415562629699707\n",
      "mse 1.4155626286851355\n",
      "New best model found at epoch 285 with validation loss 1.415562629699707\n",
      "Starting Epoch 286\n",
      "1.4783676163009976\n",
      "Validation loss: 1.4152625799179077\n",
      "mse 1.4152627030052907\n",
      "New best model found at epoch 286 with validation loss 1.4152625799179077\n",
      "Starting Epoch 287\n",
      "1.4779678583145142\n",
      "Validation loss: 1.414981722831726\n",
      "mse 1.414981804113474\n",
      "New best model found at epoch 287 with validation loss 1.414981722831726\n",
      "Starting Epoch 288\n",
      "1.4776322919389475\n",
      "Validation loss: 1.4146779775619507\n",
      "mse 1.4146780151406004\n",
      "New best model found at epoch 288 with validation loss 1.4146779775619507\n",
      "Starting Epoch 289\n",
      "1.4772749672765317\n",
      "Validation loss: 1.4144483804702759\n",
      "mse 1.4144484352447981\n",
      "New best model found at epoch 289 with validation loss 1.4144483804702759\n",
      "Starting Epoch 290\n",
      "1.4769293484480486\n",
      "Validation loss: 1.4141724109649658\n",
      "mse 1.4141722862177053\n",
      "New best model found at epoch 290 with validation loss 1.4141724109649658\n",
      "Starting Epoch 291\n",
      "1.4765952825546265\n",
      "Validation loss: 1.4139560461044312\n",
      "mse 1.4139559939598951\n",
      "New best model found at epoch 291 with validation loss 1.4139560461044312\n",
      "Starting Epoch 292\n",
      "1.4762309375016585\n",
      "Validation loss: 1.4136394262313843\n",
      "mse 1.4136393163120906\n",
      "New best model found at epoch 292 with validation loss 1.4136394262313843\n",
      "Starting Epoch 293\n",
      "1.4759222243143164\n",
      "Validation loss: 1.4133362770080566\n",
      "mse 1.4133362227661925\n",
      "New best model found at epoch 293 with validation loss 1.4133362770080566\n",
      "Starting Epoch 294\n",
      "1.4755607402842978\n",
      "Validation loss: 1.4130651950836182\n",
      "mse 1.413065193272314\n",
      "New best model found at epoch 294 with validation loss 1.4130651950836182\n",
      "Starting Epoch 295\n",
      "1.4751941043397654\n",
      "Validation loss: 1.412845253944397\n",
      "mse 1.4128452576165211\n",
      "New best model found at epoch 295 with validation loss 1.412845253944397\n",
      "Starting Epoch 296\n",
      "1.4748536089192266\n",
      "Validation loss: 1.412551999092102\n",
      "mse 1.4125519623713463\n",
      "New best model found at epoch 296 with validation loss 1.412551999092102\n",
      "Starting Epoch 297\n",
      "1.4745359835417375\n",
      "Validation loss: 1.4122732877731323\n",
      "mse 1.4122733212597995\n",
      "New best model found at epoch 297 with validation loss 1.4122732877731323\n",
      "Starting Epoch 298\n",
      "1.4741736261740974\n",
      "Validation loss: 1.4120769500732422\n",
      "mse 1.4120769414624221\n",
      "New best model found at epoch 298 with validation loss 1.4120769500732422\n",
      "Starting Epoch 299\n",
      "1.4738402755364128\n",
      "Validation loss: 1.4118009805679321\n",
      "mse 1.4118009980888389\n",
      "New best model found at epoch 299 with validation loss 1.4118009805679321\n",
      "Starting Epoch 300\n",
      "1.4734903392584429\n",
      "Validation loss: 1.411536455154419\n",
      "mse 1.411536540238914\n",
      "New best model found at epoch 300 with validation loss 1.411536455154419\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-60-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94d16c-f981-498f-bbf2-5d335b8b72ec",
   "metadata": {},
   "source": [
    "#### 4-layer MLP\n",
    "*  Loss: MSE\n",
    "*  Batch size: 100\n",
    "*  Epochs: 300 (saving best model)\n",
    "*  Leaning rate: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb20c43",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 10 - 5 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "f72895bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "0e5f2d2a-72ff-4e8a-8eb5-1b9bb946c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.065895298252935\n",
      "Validation loss: 2.699038028717041\n",
      "mse 2.699037911422376\n",
      "New best model found at epoch 1 with validation loss 2.699038028717041\n",
      "Starting Epoch 2\n",
      "2.939885569655377\n",
      "Validation loss: 2.6291897296905518\n",
      "mse 2.6291897209124726\n",
      "New best model found at epoch 2 with validation loss 2.6291897296905518\n",
      "Starting Epoch 3\n",
      "2.8481201866398687\n",
      "Validation loss: 2.563185214996338\n",
      "mse 2.563185296791851\n",
      "New best model found at epoch 3 with validation loss 2.563185214996338\n",
      "Starting Epoch 4\n",
      "2.7624733085217685\n",
      "Validation loss: 2.4946889877319336\n",
      "mse 2.4946892186757035\n",
      "New best model found at epoch 4 with validation loss 2.4946889877319336\n",
      "Starting Epoch 5\n",
      "2.68242291263912\n",
      "Validation loss: 2.4291136264801025\n",
      "mse 2.42911353085348\n",
      "New best model found at epoch 5 with validation loss 2.4291136264801025\n",
      "Starting Epoch 6\n",
      "2.6059415962385093\n",
      "Validation loss: 2.3650717735290527\n",
      "mse 2.3650717466334936\n",
      "New best model found at epoch 6 with validation loss 2.3650717735290527\n",
      "Starting Epoch 7\n",
      "2.533887293027795\n",
      "Validation loss: 2.3023436069488525\n",
      "mse 2.302343601819433\n",
      "New best model found at epoch 7 with validation loss 2.3023436069488525\n",
      "Starting Epoch 8\n",
      "2.464854017547939\n",
      "Validation loss: 2.240217447280884\n",
      "mse 2.2402175094831005\n",
      "New best model found at epoch 8 with validation loss 2.240217447280884\n",
      "Starting Epoch 9\n",
      "2.398633018783901\n",
      "Validation loss: 2.180833339691162\n",
      "mse 2.1808332840165447\n",
      "New best model found at epoch 9 with validation loss 2.180833339691162\n",
      "Starting Epoch 10\n",
      "2.3347889288612036\n",
      "Validation loss: 2.1222853660583496\n",
      "mse 2.1222853346242125\n",
      "New best model found at epoch 10 with validation loss 2.1222853660583496\n",
      "Starting Epoch 11\n",
      "2.2729535828466\n",
      "Validation loss: 2.0655691623687744\n",
      "mse 2.0655690771882447\n",
      "New best model found at epoch 11 with validation loss 2.0655691623687744\n",
      "Starting Epoch 12\n",
      "2.2143822182779727\n",
      "Validation loss: 2.009498357772827\n",
      "mse 2.0094984292790734\n",
      "New best model found at epoch 12 with validation loss 2.009498357772827\n",
      "Starting Epoch 13\n",
      "2.1594970329948096\n",
      "Validation loss: 1.9584969282150269\n",
      "mse 1.958497006612226\n",
      "New best model found at epoch 13 with validation loss 1.9584969282150269\n",
      "Starting Epoch 14\n",
      "2.107940321383269\n",
      "Validation loss: 1.9114761352539062\n",
      "mse 1.9114762905084821\n",
      "New best model found at epoch 14 with validation loss 1.9114761352539062\n",
      "Starting Epoch 15\n",
      "2.0608453906100728\n",
      "Validation loss: 1.8670016527175903\n",
      "mse 1.8670015238348396\n",
      "New best model found at epoch 15 with validation loss 1.8670016527175903\n",
      "Starting Epoch 16\n",
      "2.0175821936648823\n",
      "Validation loss: 1.8271459341049194\n",
      "mse 1.8271460388785672\n",
      "New best model found at epoch 16 with validation loss 1.8271459341049194\n",
      "Starting Epoch 17\n",
      "1.9777587600376294\n",
      "Validation loss: 1.7939050197601318\n",
      "mse 1.7939049697184748\n",
      "New best model found at epoch 17 with validation loss 1.7939050197601318\n",
      "Starting Epoch 18\n",
      "1.9418719177660735\n",
      "Validation loss: 1.763287901878357\n",
      "mse 1.7632877627392265\n",
      "New best model found at epoch 18 with validation loss 1.763287901878357\n",
      "Starting Epoch 19\n",
      "1.909581132557081\n",
      "Validation loss: 1.736228346824646\n",
      "mse 1.736228311058062\n",
      "New best model found at epoch 19 with validation loss 1.736228346824646\n",
      "Starting Epoch 20\n",
      "1.8807454938473909\n",
      "Validation loss: 1.7113947868347168\n",
      "mse 1.7113949676463287\n",
      "New best model found at epoch 20 with validation loss 1.7113947868347168\n",
      "Starting Epoch 21\n",
      "1.8546602363171785\n",
      "Validation loss: 1.6887403726577759\n",
      "mse 1.6887403725922137\n",
      "New best model found at epoch 21 with validation loss 1.6887403726577759\n",
      "Starting Epoch 22\n",
      "1.831236657888993\n",
      "Validation loss: 1.669468641281128\n",
      "mse 1.6694685449525153\n",
      "New best model found at epoch 22 with validation loss 1.669468641281128\n",
      "Starting Epoch 23\n",
      "1.8097795973653379\n",
      "Validation loss: 1.6488683223724365\n",
      "mse 1.6488684143701837\n",
      "New best model found at epoch 23 with validation loss 1.6488683223724365\n",
      "Starting Epoch 24\n",
      "1.7910591415736987\n",
      "Validation loss: 1.6353121995925903\n",
      "mse 1.6353122333868537\n",
      "New best model found at epoch 24 with validation loss 1.6353121995925903\n",
      "Starting Epoch 25\n",
      "1.7737046428348706\n",
      "Validation loss: 1.6183655261993408\n",
      "mse 1.6183654717953162\n",
      "New best model found at epoch 25 with validation loss 1.6183655261993408\n",
      "Starting Epoch 26\n",
      "1.7584350368250972\n",
      "Validation loss: 1.6078245639801025\n",
      "mse 1.607824549437545\n",
      "New best model found at epoch 26 with validation loss 1.6078245639801025\n",
      "Starting Epoch 27\n",
      "1.7441321248593538\n",
      "Validation loss: 1.5959968566894531\n",
      "mse 1.5959967757555165\n",
      "New best model found at epoch 27 with validation loss 1.5959968566894531\n",
      "Starting Epoch 28\n",
      "1.731713751088018\n",
      "Validation loss: 1.5836325883865356\n",
      "mse 1.5836325370516635\n",
      "New best model found at epoch 28 with validation loss 1.5836325883865356\n",
      "Starting Epoch 29\n",
      "1.7202779261962227\n",
      "Validation loss: 1.574332594871521\n",
      "mse 1.5743326548795378\n",
      "New best model found at epoch 29 with validation loss 1.574332594871521\n",
      "Starting Epoch 30\n",
      "1.7100679770759915\n",
      "Validation loss: 1.5652388334274292\n",
      "mse 1.5652388071505676\n",
      "New best model found at epoch 30 with validation loss 1.5652388334274292\n",
      "Starting Epoch 31\n",
      "1.7006732329078342\n",
      "Validation loss: 1.5571091175079346\n",
      "mse 1.5571091794857734\n",
      "New best model found at epoch 31 with validation loss 1.5571091175079346\n",
      "Starting Epoch 32\n",
      "1.6922123017518416\n",
      "Validation loss: 1.5493727922439575\n",
      "mse 1.5493727758086109\n",
      "New best model found at epoch 32 with validation loss 1.5493727922439575\n",
      "Starting Epoch 33\n",
      "1.684358405030292\n",
      "Validation loss: 1.542405128479004\n",
      "mse 1.5424052220588587\n",
      "New best model found at epoch 33 with validation loss 1.542405128479004\n",
      "Starting Epoch 34\n",
      "1.6770633718241816\n",
      "Validation loss: 1.5366393327713013\n",
      "mse 1.5366392162325009\n",
      "New best model found at epoch 34 with validation loss 1.5366393327713013\n",
      "Starting Epoch 35\n",
      "1.6704334331595379\n",
      "Validation loss: 1.531976342201233\n",
      "mse 1.5319763035285396\n",
      "New best model found at epoch 35 with validation loss 1.531976342201233\n",
      "Starting Epoch 36\n",
      "1.6642602422963018\n",
      "Validation loss: 1.5263296365737915\n",
      "mse 1.526329650638046\n",
      "New best model found at epoch 36 with validation loss 1.5263296365737915\n",
      "Starting Epoch 37\n",
      "1.6588020013726277\n",
      "Validation loss: 1.521282434463501\n",
      "mse 1.5212825493406665\n",
      "New best model found at epoch 37 with validation loss 1.521282434463501\n",
      "Starting Epoch 38\n",
      "1.653791554596113\n",
      "Validation loss: 1.5176692008972168\n",
      "mse 1.5176691410283045\n",
      "New best model found at epoch 38 with validation loss 1.5176692008972168\n",
      "Starting Epoch 39\n",
      "1.6489297436631245\n",
      "Validation loss: 1.513261318206787\n",
      "mse 1.5132613273445115\n",
      "New best model found at epoch 39 with validation loss 1.513261318206787\n",
      "Starting Epoch 40\n",
      "1.6442964025165723\n",
      "Validation loss: 1.5088309049606323\n",
      "mse 1.5088308082165724\n",
      "New best model found at epoch 40 with validation loss 1.5088309049606323\n",
      "Starting Epoch 41\n",
      "1.6399392978004788\n",
      "Validation loss: 1.503334641456604\n",
      "mse 1.5033347747253452\n",
      "New best model found at epoch 41 with validation loss 1.503334641456604\n",
      "Starting Epoch 42\n",
      "1.635186089121777\n",
      "Validation loss: 1.4992636442184448\n",
      "mse 1.4992636121119647\n",
      "New best model found at epoch 42 with validation loss 1.4992636442184448\n",
      "Starting Epoch 43\n",
      "1.6307344592135886\n",
      "Validation loss: 1.4956755638122559\n",
      "mse 1.4956755282753722\n",
      "New best model found at epoch 43 with validation loss 1.4956755638122559\n",
      "Starting Epoch 44\n",
      "1.6268046731534211\n",
      "Validation loss: 1.4932249784469604\n",
      "mse 1.4932250578384785\n",
      "New best model found at epoch 44 with validation loss 1.4932249784469604\n",
      "Starting Epoch 45\n",
      "1.6229861560075178\n",
      "Validation loss: 1.4903286695480347\n",
      "mse 1.4903288609467922\n",
      "New best model found at epoch 45 with validation loss 1.4903286695480347\n",
      "Starting Epoch 46\n",
      "1.6196627565052197\n",
      "Validation loss: 1.488329529762268\n",
      "mse 1.4883294992512903\n",
      "New best model found at epoch 46 with validation loss 1.488329529762268\n",
      "Starting Epoch 47\n",
      "1.6164778937464175\n",
      "Validation loss: 1.4853001832962036\n",
      "mse 1.4852999713011936\n",
      "New best model found at epoch 47 with validation loss 1.4853001832962036\n",
      "Starting Epoch 48\n",
      "1.6135296588358672\n",
      "Validation loss: 1.481713056564331\n",
      "mse 1.4817130702624919\n",
      "New best model found at epoch 48 with validation loss 1.481713056564331\n",
      "Starting Epoch 49\n",
      "1.6106748814168184\n",
      "Validation loss: 1.478985071182251\n",
      "mse 1.4789850255362735\n",
      "New best model found at epoch 49 with validation loss 1.478985071182251\n",
      "Starting Epoch 50\n",
      "1.6077068370321523\n",
      "Validation loss: 1.4766359329223633\n",
      "mse 1.4766357593339907\n",
      "New best model found at epoch 50 with validation loss 1.4766359329223633\n",
      "Starting Epoch 51\n",
      "1.6049997262332751\n",
      "Validation loss: 1.4757084846496582\n",
      "mse 1.4757084593278738\n",
      "New best model found at epoch 51 with validation loss 1.4757084846496582\n",
      "Starting Epoch 52\n",
      "1.602616592593815\n",
      "Validation loss: 1.4729405641555786\n",
      "mse 1.4729405425960758\n",
      "New best model found at epoch 52 with validation loss 1.4729405641555786\n",
      "Starting Epoch 53\n",
      "1.6002894873204438\n",
      "Validation loss: 1.4710464477539062\n",
      "mse 1.4710466756829597\n",
      "New best model found at epoch 53 with validation loss 1.4710464477539062\n",
      "Starting Epoch 54\n",
      "1.5981136301289434\n",
      "Validation loss: 1.4688715934753418\n",
      "mse 1.468871556677023\n",
      "New best model found at epoch 54 with validation loss 1.4688715934753418\n",
      "Starting Epoch 55\n",
      "1.5960154585216357\n",
      "Validation loss: 1.4681493043899536\n",
      "mse 1.4681494290793375\n",
      "New best model found at epoch 55 with validation loss 1.4681493043899536\n",
      "Starting Epoch 56\n",
      "1.5938192554142163\n",
      "Validation loss: 1.466522216796875\n",
      "mse 1.4665220973422382\n",
      "New best model found at epoch 56 with validation loss 1.466522216796875\n",
      "Starting Epoch 57\n",
      "1.5915842445000359\n",
      "Validation loss: 1.464111566543579\n",
      "mse 1.4641115593042107\n",
      "New best model found at epoch 57 with validation loss 1.464111566543579\n",
      "Starting Epoch 58\n",
      "1.58963106766991\n",
      "Validation loss: 1.46354079246521\n",
      "mse 1.463540720636477\n",
      "New best model found at epoch 58 with validation loss 1.46354079246521\n",
      "Starting Epoch 59\n",
      "1.5874794229217197\n",
      "Validation loss: 1.4603281021118164\n",
      "mse 1.4603281009239892\n",
      "New best model found at epoch 59 with validation loss 1.4603281021118164\n",
      "Starting Epoch 60\n",
      "1.585616287977799\n",
      "Validation loss: 1.4601637125015259\n",
      "mse 1.460163690563363\n",
      "New best model found at epoch 60 with validation loss 1.4601637125015259\n",
      "Starting Epoch 61\n",
      "1.5835127338119175\n",
      "Validation loss: 1.4585728645324707\n",
      "mse 1.4585727425808714\n",
      "New best model found at epoch 61 with validation loss 1.4585728645324707\n",
      "Starting Epoch 62\n",
      "1.58169250384621\n",
      "Validation loss: 1.4546421766281128\n",
      "mse 1.454642107302503\n",
      "New best model found at epoch 62 with validation loss 1.4546421766281128\n",
      "Starting Epoch 63\n",
      "1.580010940199313\n",
      "Validation loss: 1.4533746242523193\n",
      "mse 1.4533746937868786\n",
      "New best model found at epoch 63 with validation loss 1.4533746242523193\n",
      "Starting Epoch 64\n",
      "1.5782624172127766\n",
      "Validation loss: 1.4520474672317505\n",
      "mse 1.4520474861965025\n",
      "New best model found at epoch 64 with validation loss 1.4520474672317505\n",
      "Starting Epoch 65\n",
      "1.576542722142261\n",
      "Validation loss: 1.450698733329773\n",
      "mse 1.4506986302004663\n",
      "New best model found at epoch 65 with validation loss 1.450698733329773\n",
      "Starting Epoch 66\n",
      "1.574908505315366\n",
      "Validation loss: 1.4493153095245361\n",
      "mse 1.4493152524351882\n",
      "New best model found at epoch 66 with validation loss 1.4493153095245361\n",
      "Starting Epoch 67\n",
      "1.5733685260233672\n",
      "Validation loss: 1.4481301307678223\n",
      "mse 1.4481300133263313\n",
      "New best model found at epoch 67 with validation loss 1.4481301307678223\n",
      "Starting Epoch 68\n",
      "1.5715221555336663\n",
      "Validation loss: 1.447096824645996\n",
      "mse 1.4470968372069999\n",
      "New best model found at epoch 68 with validation loss 1.447096824645996\n",
      "Starting Epoch 69\n",
      "1.5700146478155386\n",
      "Validation loss: 1.4460697174072266\n",
      "mse 1.446069667510915\n",
      "New best model found at epoch 69 with validation loss 1.4460697174072266\n",
      "Starting Epoch 70\n",
      "1.5684716571932253\n",
      "Validation loss: 1.4466608762741089\n",
      "mse 1.4466609140517461\n",
      "Starting Epoch 71\n",
      "1.5669879058133\n",
      "Validation loss: 1.4457128047943115\n",
      "mse 1.4457129130067576\n",
      "New best model found at epoch 71 with validation loss 1.4457128047943115\n",
      "Starting Epoch 72\n",
      "1.5657265367715254\n",
      "Validation loss: 1.4465134143829346\n",
      "mse 1.4465135076366709\n",
      "Starting Epoch 73\n",
      "1.5636840022128562\n",
      "Validation loss: 1.4452693462371826\n",
      "mse 1.4452694696876693\n",
      "New best model found at epoch 73 with validation loss 1.4452693462371826\n",
      "Starting Epoch 74\n",
      "1.5621732110562532\n",
      "Validation loss: 1.445265769958496\n",
      "mse 1.4452657953266912\n",
      "New best model found at epoch 74 with validation loss 1.445265769958496\n",
      "Starting Epoch 75\n",
      "1.5608990140583203\n",
      "Validation loss: 1.4444773197174072\n",
      "mse 1.444477222412125\n",
      "New best model found at epoch 75 with validation loss 1.4444773197174072\n",
      "Starting Epoch 76\n",
      "1.5596703394599583\n",
      "Validation loss: 1.4437187910079956\n",
      "mse 1.4437187445017496\n",
      "New best model found at epoch 76 with validation loss 1.4437187910079956\n",
      "Starting Epoch 77\n",
      "1.5585104201150977\n",
      "Validation loss: 1.4434657096862793\n",
      "mse 1.4434657232251176\n",
      "New best model found at epoch 77 with validation loss 1.4434657096862793\n",
      "Starting Epoch 78\n",
      "1.5573090159374734\n",
      "Validation loss: 1.4425311088562012\n",
      "mse 1.442531135645542\n",
      "New best model found at epoch 78 with validation loss 1.4425311088562012\n",
      "Starting Epoch 79\n",
      "1.5561552540115688\n",
      "Validation loss: 1.4416784048080444\n",
      "mse 1.4416784427228684\n",
      "New best model found at epoch 79 with validation loss 1.4416784048080444\n",
      "Starting Epoch 80\n",
      "1.5551322543102761\n",
      "Validation loss: 1.4410265684127808\n",
      "mse 1.4410265219733243\n",
      "New best model found at epoch 80 with validation loss 1.4410265684127808\n",
      "Starting Epoch 81\n",
      "1.5540712657182112\n",
      "Validation loss: 1.4404194355010986\n",
      "mse 1.4404193594306283\n",
      "New best model found at epoch 81 with validation loss 1.4404194355010986\n",
      "Starting Epoch 82\n",
      "1.5531383934228316\n",
      "Validation loss: 1.4401313066482544\n",
      "mse 1.4401312963299662\n",
      "New best model found at epoch 82 with validation loss 1.4401313066482544\n",
      "Starting Epoch 83\n",
      "1.552194771559342\n",
      "Validation loss: 1.4396125078201294\n",
      "mse 1.439612601876713\n",
      "New best model found at epoch 83 with validation loss 1.4396125078201294\n",
      "Starting Epoch 84\n",
      "1.5512292618336885\n",
      "Validation loss: 1.4391109943389893\n",
      "mse 1.4391108750099524\n",
      "New best model found at epoch 84 with validation loss 1.4391109943389893\n",
      "Starting Epoch 85\n",
      "1.5502487861591836\n",
      "Validation loss: 1.4384292364120483\n",
      "mse 1.438429172935465\n",
      "New best model found at epoch 85 with validation loss 1.4384292364120483\n",
      "Starting Epoch 86\n",
      "1.5496431304060894\n",
      "Validation loss: 1.43824303150177\n",
      "mse 1.438242945083552\n",
      "New best model found at epoch 86 with validation loss 1.43824303150177\n",
      "Starting Epoch 87\n",
      "1.548532967982085\n",
      "Validation loss: 1.4375193119049072\n",
      "mse 1.437519305204534\n",
      "New best model found at epoch 87 with validation loss 1.4375193119049072\n",
      "Starting Epoch 88\n",
      "1.5479947328567505\n",
      "Validation loss: 1.4371304512023926\n",
      "mse 1.437130651356685\n",
      "New best model found at epoch 88 with validation loss 1.4371304512023926\n",
      "Starting Epoch 89\n",
      "1.5470144334046736\n",
      "Validation loss: 1.4367735385894775\n",
      "mse 1.4367734847133193\n",
      "New best model found at epoch 89 with validation loss 1.4367735385894775\n",
      "Starting Epoch 90\n",
      "1.54620136126228\n",
      "Validation loss: 1.4361149072647095\n",
      "mse 1.4361148104194248\n",
      "New best model found at epoch 90 with validation loss 1.4361149072647095\n",
      "Starting Epoch 91\n",
      "1.5455156668372776\n",
      "Validation loss: 1.43574857711792\n",
      "mse 1.4357484555504656\n",
      "New best model found at epoch 91 with validation loss 1.43574857711792\n",
      "Starting Epoch 92\n",
      "1.5448420825211897\n",
      "Validation loss: 1.4354057312011719\n",
      "mse 1.4354056930460375\n",
      "New best model found at epoch 92 with validation loss 1.4354057312011719\n",
      "Starting Epoch 93\n",
      "1.5439204832781916\n",
      "Validation loss: 1.4347152709960938\n",
      "mse 1.4347152106294916\n",
      "New best model found at epoch 93 with validation loss 1.4347152709960938\n",
      "Starting Epoch 94\n",
      "1.5432724175245867\n",
      "Validation loss: 1.4348846673965454\n",
      "mse 1.4348847520723578\n",
      "Starting Epoch 95\n",
      "1.542507651059524\n",
      "Validation loss: 1.4343057870864868\n",
      "mse 1.434305892211496\n",
      "New best model found at epoch 95 with validation loss 1.4343057870864868\n",
      "Starting Epoch 96\n",
      "1.5418623193450596\n",
      "Validation loss: 1.4339380264282227\n",
      "mse 1.4339379675401889\n",
      "New best model found at epoch 96 with validation loss 1.4339380264282227\n",
      "Starting Epoch 97\n",
      "1.5409413627956225\n",
      "Validation loss: 1.433271884918213\n",
      "mse 1.4332720123562457\n",
      "New best model found at epoch 97 with validation loss 1.433271884918213\n",
      "Starting Epoch 98\n",
      "1.5404430524162624\n",
      "Validation loss: 1.4332518577575684\n",
      "mse 1.4332520147520182\n",
      "New best model found at epoch 98 with validation loss 1.4332518577575684\n",
      "Starting Epoch 99\n",
      "1.5396981628044792\n",
      "Validation loss: 1.4331097602844238\n",
      "mse 1.433109714771318\n",
      "New best model found at epoch 99 with validation loss 1.4331097602844238\n",
      "Starting Epoch 100\n",
      "1.539025340391242\n",
      "Validation loss: 1.4324071407318115\n",
      "mse 1.4324071701609784\n",
      "New best model found at epoch 100 with validation loss 1.4324071407318115\n",
      "Starting Epoch 101\n",
      "1.5382540329642918\n",
      "Validation loss: 1.4323246479034424\n",
      "mse 1.4323246431491319\n",
      "New best model found at epoch 101 with validation loss 1.4323246479034424\n",
      "Starting Epoch 102\n",
      "1.537694697794707\n",
      "Validation loss: 1.431636095046997\n",
      "mse 1.4316361836536855\n",
      "New best model found at epoch 102 with validation loss 1.431636095046997\n",
      "Starting Epoch 103\n",
      "1.5370469663454138\n",
      "Validation loss: 1.4313079118728638\n",
      "mse 1.4313080333241082\n",
      "New best model found at epoch 103 with validation loss 1.4313079118728638\n",
      "Starting Epoch 104\n",
      "1.5365658013716987\n",
      "Validation loss: 1.4307514429092407\n",
      "mse 1.4307514026351447\n",
      "New best model found at epoch 104 with validation loss 1.4307514429092407\n",
      "Starting Epoch 105\n",
      "1.5357492021892383\n",
      "Validation loss: 1.4310619831085205\n",
      "mse 1.4310620394988287\n",
      "Starting Epoch 106\n",
      "1.5351181807725325\n",
      "Validation loss: 1.4306309223175049\n",
      "mse 1.4306309083983941\n",
      "New best model found at epoch 106 with validation loss 1.4306309223175049\n",
      "Starting Epoch 107\n",
      "1.5345121648000635\n",
      "Validation loss: 1.4303004741668701\n",
      "mse 1.4303005268162714\n",
      "New best model found at epoch 107 with validation loss 1.4303004741668701\n",
      "Starting Epoch 108\n",
      "1.5338496747224226\n",
      "Validation loss: 1.4296951293945312\n",
      "mse 1.4296949569761128\n",
      "New best model found at epoch 108 with validation loss 1.4296951293945312\n",
      "Starting Epoch 109\n",
      "1.5335871706838193\n",
      "Validation loss: 1.428950548171997\n",
      "mse 1.4289506057693968\n",
      "New best model found at epoch 109 with validation loss 1.428950548171997\n",
      "Starting Epoch 110\n",
      "1.5331298812575962\n",
      "Validation loss: 1.428690791130066\n",
      "mse 1.428690767678393\n",
      "New best model found at epoch 110 with validation loss 1.428690791130066\n",
      "Starting Epoch 111\n",
      "1.5322763116463372\n",
      "Validation loss: 1.4292035102844238\n",
      "mse 1.4292035841400264\n",
      "Starting Epoch 112\n",
      "1.531882467477218\n",
      "Validation loss: 1.4281898736953735\n",
      "mse 1.4281899826531732\n",
      "New best model found at epoch 112 with validation loss 1.4281898736953735\n",
      "Starting Epoch 113\n",
      "1.5312835651895274\n",
      "Validation loss: 1.4278663396835327\n",
      "mse 1.4278664888077093\n",
      "New best model found at epoch 113 with validation loss 1.4278663396835327\n",
      "Starting Epoch 114\n",
      "1.5308004850926606\n",
      "Validation loss: 1.4278777837753296\n",
      "mse 1.4278778112686883\n",
      "Starting Epoch 115\n",
      "1.5303616782893306\n",
      "Validation loss: 1.4268476963043213\n",
      "mse 1.426847814321865\n",
      "New best model found at epoch 115 with validation loss 1.4268476963043213\n",
      "Starting Epoch 116\n",
      "1.5297850577727607\n",
      "Validation loss: 1.426975965499878\n",
      "mse 1.426975975806974\n",
      "Starting Epoch 117\n",
      "1.529282862725465\n",
      "Validation loss: 1.4263496398925781\n",
      "mse 1.4263497709219104\n",
      "New best model found at epoch 117 with validation loss 1.4263496398925781\n",
      "Starting Epoch 118\n",
      "1.528726233088452\n",
      "Validation loss: 1.4264720678329468\n",
      "mse 1.4264719935928818\n",
      "Starting Epoch 119\n",
      "1.5282793252364448\n",
      "Validation loss: 1.426084280014038\n",
      "mse 1.4260843943946055\n",
      "New best model found at epoch 119 with validation loss 1.426084280014038\n",
      "Starting Epoch 120\n",
      "1.5278463415477588\n",
      "Validation loss: 1.425612211227417\n",
      "mse 1.4256122193073433\n",
      "New best model found at epoch 120 with validation loss 1.425612211227417\n",
      "Starting Epoch 121\n",
      "1.5272705321726592\n",
      "Validation loss: 1.4253374338150024\n",
      "mse 1.4253373081200398\n",
      "New best model found at epoch 121 with validation loss 1.4253374338150024\n",
      "Starting Epoch 122\n",
      "1.5268007205880207\n",
      "Validation loss: 1.424992322921753\n",
      "mse 1.4249922043628103\n",
      "New best model found at epoch 122 with validation loss 1.424992322921753\n",
      "Starting Epoch 123\n",
      "1.5263536494711172\n",
      "Validation loss: 1.4247287511825562\n",
      "mse 1.4247286421935563\n",
      "New best model found at epoch 123 with validation loss 1.4247287511825562\n",
      "Starting Epoch 124\n",
      "1.5258397097172944\n",
      "Validation loss: 1.4243370294570923\n",
      "mse 1.4243370612847448\n",
      "New best model found at epoch 124 with validation loss 1.4243370294570923\n",
      "Starting Epoch 125\n",
      "1.5253682939902595\n",
      "Validation loss: 1.4241843223571777\n",
      "mse 1.4241843201004682\n",
      "New best model found at epoch 125 with validation loss 1.4241843223571777\n",
      "Starting Epoch 126\n",
      "1.52510128332221\n",
      "Validation loss: 1.4238958358764648\n",
      "mse 1.423895974074083\n",
      "New best model found at epoch 126 with validation loss 1.4238958358764648\n",
      "Starting Epoch 127\n",
      "1.524425472902215\n",
      "Validation loss: 1.4239939451217651\n",
      "mse 1.423993830407822\n",
      "Starting Epoch 128\n",
      "1.524061760176783\n",
      "Validation loss: 1.423903465270996\n",
      "mse 1.4239033704328288\n",
      "Starting Epoch 129\n",
      "1.5235727196154387\n",
      "Validation loss: 1.4237782955169678\n",
      "mse 1.4237782042125418\n",
      "New best model found at epoch 129 with validation loss 1.4237782955169678\n",
      "Starting Epoch 130\n",
      "1.5232841787130937\n",
      "Validation loss: 1.4231194257736206\n",
      "mse 1.4231194342430793\n",
      "New best model found at epoch 130 with validation loss 1.4231194257736206\n",
      "Starting Epoch 131\n",
      "1.52277846440025\n",
      "Validation loss: 1.4232784509658813\n",
      "mse 1.423278467387615\n",
      "Starting Epoch 132\n",
      "1.5225625297297603\n",
      "Validation loss: 1.4225473403930664\n",
      "mse 1.4225474362640689\n",
      "New best model found at epoch 132 with validation loss 1.4225473403930664\n",
      "Starting Epoch 133\n",
      "1.5219959435255632\n",
      "Validation loss: 1.4223536252975464\n",
      "mse 1.4223534488435376\n",
      "New best model found at epoch 133 with validation loss 1.4223536252975464\n",
      "Starting Epoch 134\n",
      "1.5215572222419407\n",
      "Validation loss: 1.422302484512329\n",
      "mse 1.4223025203184023\n",
      "New best model found at epoch 134 with validation loss 1.422302484512329\n",
      "Starting Epoch 135\n",
      "1.5209244126858918\n",
      "Validation loss: 1.4224190711975098\n",
      "mse 1.4224190798813485\n",
      "Starting Epoch 136\n",
      "1.5205923785334048\n",
      "Validation loss: 1.422253966331482\n",
      "mse 1.4222539233087885\n",
      "New best model found at epoch 136 with validation loss 1.422253966331482\n",
      "Starting Epoch 137\n",
      "1.5201832030130469\n",
      "Validation loss: 1.4218417406082153\n",
      "mse 1.4218416595090018\n",
      "New best model found at epoch 137 with validation loss 1.4218417406082153\n",
      "Starting Epoch 138\n",
      "1.5197204584660737\n",
      "Validation loss: 1.4217737913131714\n",
      "mse 1.4217737991246102\n",
      "New best model found at epoch 138 with validation loss 1.4217737913131714\n",
      "Starting Epoch 139\n",
      "1.5192412293475608\n",
      "Validation loss: 1.4212690591812134\n",
      "mse 1.4212690521710267\n",
      "New best model found at epoch 139 with validation loss 1.4212690591812134\n",
      "Starting Epoch 140\n",
      "1.5188738133596338\n",
      "Validation loss: 1.4213811159133911\n",
      "mse 1.4213811675783243\n",
      "Starting Epoch 141\n",
      "1.5185242476670637\n",
      "Validation loss: 1.4208025932312012\n",
      "mse 1.42080263956555\n",
      "New best model found at epoch 141 with validation loss 1.4208025932312012\n",
      "Starting Epoch 142\n",
      "1.5181416221286939\n",
      "Validation loss: 1.4206467866897583\n",
      "mse 1.4206469318848791\n",
      "New best model found at epoch 142 with validation loss 1.4206467866897583\n",
      "Starting Epoch 143\n",
      "1.517698251682779\n",
      "Validation loss: 1.420495629310608\n",
      "mse 1.420495486396258\n",
      "New best model found at epoch 143 with validation loss 1.420495629310608\n",
      "Starting Epoch 144\n",
      "1.5174264545026033\n",
      "Validation loss: 1.420204997062683\n",
      "mse 1.4202050989487087\n",
      "New best model found at epoch 144 with validation loss 1.420204997062683\n",
      "Starting Epoch 145\n",
      "1.5170006155967712\n",
      "Validation loss: 1.4204305410385132\n",
      "mse 1.4204305628952962\n",
      "Starting Epoch 146\n",
      "1.5167068113451418\n",
      "Validation loss: 1.4198896884918213\n",
      "mse 1.419889713832506\n",
      "New best model found at epoch 146 with validation loss 1.4198896884918213\n",
      "Starting Epoch 147\n",
      "1.5162481639696204\n",
      "Validation loss: 1.419727087020874\n",
      "mse 1.4197270913417592\n",
      "New best model found at epoch 147 with validation loss 1.419727087020874\n",
      "Starting Epoch 148\n",
      "1.5159472019776055\n",
      "Validation loss: 1.4197094440460205\n",
      "mse 1.4197095426925102\n",
      "New best model found at epoch 148 with validation loss 1.4197094440460205\n",
      "Starting Epoch 149\n",
      "1.5156010596648506\n",
      "Validation loss: 1.4193083047866821\n",
      "mse 1.4193083440777805\n",
      "New best model found at epoch 149 with validation loss 1.4193083047866821\n",
      "Starting Epoch 150\n",
      "1.5152045747508174\n",
      "Validation loss: 1.4188333749771118\n",
      "mse 1.4188334754022944\n",
      "New best model found at epoch 150 with validation loss 1.4188333749771118\n",
      "Starting Epoch 151\n",
      "1.514828542004461\n",
      "Validation loss: 1.4193044900894165\n",
      "mse 1.4193045230914334\n",
      "Starting Epoch 152\n",
      "1.514586319094119\n",
      "Validation loss: 1.419089436531067\n",
      "mse 1.4190895706924977\n",
      "Starting Epoch 153\n",
      "1.5142286186632903\n",
      "Validation loss: 1.4188032150268555\n",
      "mse 1.4188032398660224\n",
      "New best model found at epoch 153 with validation loss 1.4188032150268555\n",
      "Starting Epoch 154\n",
      "1.5138160767762556\n",
      "Validation loss: 1.4182300567626953\n",
      "mse 1.4182300604338671\n",
      "New best model found at epoch 154 with validation loss 1.4182300567626953\n",
      "Starting Epoch 155\n",
      "1.5135640968447146\n",
      "Validation loss: 1.4182069301605225\n",
      "mse 1.4182068872982942\n",
      "New best model found at epoch 155 with validation loss 1.4182069301605225\n",
      "Starting Epoch 156\n",
      "1.513233482837677\n",
      "Validation loss: 1.4182263612747192\n",
      "mse 1.4182262474739813\n",
      "Starting Epoch 157\n",
      "1.512855350971222\n",
      "Validation loss: 1.4182429313659668\n",
      "mse 1.4182430343088086\n",
      "Starting Epoch 158\n",
      "1.5124364573022593\n",
      "Validation loss: 1.4178963899612427\n",
      "mse 1.417896414576481\n",
      "New best model found at epoch 158 with validation loss 1.4178963899612427\n",
      "Starting Epoch 159\n",
      "1.512107841346575\n",
      "Validation loss: 1.417661428451538\n",
      "mse 1.417661538659485\n",
      "New best model found at epoch 159 with validation loss 1.417661428451538\n",
      "Starting Epoch 160\n",
      "1.5118114611376887\n",
      "Validation loss: 1.4172236919403076\n",
      "mse 1.4172236716470648\n",
      "New best model found at epoch 160 with validation loss 1.4172236919403076\n",
      "Starting Epoch 161\n",
      "1.5114774678064429\n",
      "Validation loss: 1.4173029661178589\n",
      "mse 1.417302953915987\n",
      "Starting Epoch 162\n",
      "1.511124761208244\n",
      "Validation loss: 1.4172532558441162\n",
      "mse 1.4172535181557733\n",
      "Starting Epoch 163\n",
      "1.510806399842967\n",
      "Validation loss: 1.4168094396591187\n",
      "mse 1.4168094862090088\n",
      "New best model found at epoch 163 with validation loss 1.4168094396591187\n",
      "Starting Epoch 164\n",
      "1.5105470937231313\n",
      "Validation loss: 1.416937232017517\n",
      "mse 1.416937187587285\n",
      "Starting Epoch 165\n",
      "1.5102492726367454\n",
      "Validation loss: 1.4169323444366455\n",
      "mse 1.4169321756373894\n",
      "Starting Epoch 166\n",
      "1.509926357994909\n",
      "Validation loss: 1.416503667831421\n",
      "mse 1.416503660036255\n",
      "New best model found at epoch 166 with validation loss 1.416503667831421\n",
      "Starting Epoch 167\n",
      "1.5096759770227515\n",
      "Validation loss: 1.4166371822357178\n",
      "mse 1.4166372324428185\n",
      "Starting Epoch 168\n",
      "1.5093966385592585\n",
      "Validation loss: 1.4161219596862793\n",
      "mse 1.4161219064739408\n",
      "New best model found at epoch 168 with validation loss 1.4161219596862793\n",
      "Starting Epoch 169\n",
      "1.5090963633164116\n",
      "Validation loss: 1.416185975074768\n",
      "mse 1.416186024695535\n",
      "Starting Epoch 170\n",
      "1.5088063893110857\n",
      "Validation loss: 1.4159332513809204\n",
      "mse 1.4159331749036124\n",
      "New best model found at epoch 170 with validation loss 1.4159332513809204\n",
      "Starting Epoch 171\n",
      "1.5084445606107297\n",
      "Validation loss: 1.4157150983810425\n",
      "mse 1.4157152093205845\n",
      "New best model found at epoch 171 with validation loss 1.4157150983810425\n",
      "Starting Epoch 172\n",
      "1.5082482229108396\n",
      "Validation loss: 1.4156924486160278\n",
      "mse 1.4156923497900995\n",
      "New best model found at epoch 172 with validation loss 1.4156924486160278\n",
      "Starting Epoch 173\n",
      "1.5081172559572302\n",
      "Validation loss: 1.4151411056518555\n",
      "mse 1.4151410419113586\n",
      "New best model found at epoch 173 with validation loss 1.4151411056518555\n",
      "Starting Epoch 174\n",
      "1.507877010366191\n",
      "Validation loss: 1.4151231050491333\n",
      "mse 1.415123169755673\n",
      "New best model found at epoch 174 with validation loss 1.4151231050491333\n",
      "Starting Epoch 175\n",
      "1.5076215785482656\n",
      "Validation loss: 1.4148609638214111\n",
      "mse 1.4148609862568948\n",
      "New best model found at epoch 175 with validation loss 1.4148609638214111\n",
      "Starting Epoch 176\n",
      "1.5071401285088581\n",
      "Validation loss: 1.4149644374847412\n",
      "mse 1.4149644696416426\n",
      "Starting Epoch 177\n",
      "1.507067646669305\n",
      "Validation loss: 1.4145039319992065\n",
      "mse 1.4145039691869163\n",
      "New best model found at epoch 177 with validation loss 1.4145039319992065\n",
      "Starting Epoch 178\n",
      "1.5067949009978252\n",
      "Validation loss: 1.4146196842193604\n",
      "mse 1.414619757146788\n",
      "Starting Epoch 179\n",
      "1.506499267142752\n",
      "Validation loss: 1.414198875427246\n",
      "mse 1.414198896027954\n",
      "New best model found at epoch 179 with validation loss 1.414198875427246\n",
      "Starting Epoch 180\n",
      "1.5062831070112146\n",
      "Validation loss: 1.4141734838485718\n",
      "mse 1.4141734454779098\n",
      "New best model found at epoch 180 with validation loss 1.4141734838485718\n",
      "Starting Epoch 181\n",
      "1.5060168426969778\n",
      "Validation loss: 1.41385018825531\n",
      "mse 1.4138502075527835\n",
      "New best model found at epoch 181 with validation loss 1.41385018825531\n",
      "Starting Epoch 182\n",
      "1.5058813794799473\n",
      "Validation loss: 1.4139552116394043\n",
      "mse 1.4139550650723787\n",
      "Starting Epoch 183\n",
      "1.5054471933323403\n",
      "Validation loss: 1.413760781288147\n",
      "mse 1.4137607405820025\n",
      "New best model found at epoch 183 with validation loss 1.413760781288147\n",
      "Starting Epoch 184\n",
      "1.5052656013032664\n",
      "Validation loss: 1.413431167602539\n",
      "mse 1.4134311180754002\n",
      "New best model found at epoch 184 with validation loss 1.413431167602539\n",
      "Starting Epoch 185\n",
      "1.505091719005419\n",
      "Validation loss: 1.4136954545974731\n",
      "mse 1.413695565547238\n",
      "Starting Epoch 186\n",
      "1.5047524752824202\n",
      "Validation loss: 1.4133327007293701\n",
      "mse 1.4133328506084604\n",
      "New best model found at epoch 186 with validation loss 1.4133327007293701\n",
      "Starting Epoch 187\n",
      "1.5045158033785613\n",
      "Validation loss: 1.413405179977417\n",
      "mse 1.4134051799979366\n",
      "Starting Epoch 188\n",
      "1.5042786183564558\n",
      "Validation loss: 1.4132027626037598\n",
      "mse 1.4132027662022655\n",
      "New best model found at epoch 188 with validation loss 1.4132027626037598\n",
      "Starting Epoch 189\n",
      "1.5040897208711375\n",
      "Validation loss: 1.4133284091949463\n",
      "mse 1.413328344957344\n",
      "Starting Epoch 190\n",
      "1.5037856464800627\n",
      "Validation loss: 1.4128233194351196\n",
      "mse 1.4128234054353725\n",
      "New best model found at epoch 190 with validation loss 1.4128233194351196\n",
      "Starting Epoch 191\n",
      "1.5035965494487598\n",
      "Validation loss: 1.4130102396011353\n",
      "mse 1.413010349348551\n",
      "Starting Epoch 192\n",
      "1.5033243013464885\n",
      "Validation loss: 1.4130653142929077\n",
      "mse 1.4130654337680217\n",
      "Starting Epoch 193\n",
      "1.5030702637589497\n",
      "Validation loss: 1.4125967025756836\n",
      "mse 1.4125965667338014\n",
      "New best model found at epoch 193 with validation loss 1.4125967025756836\n",
      "Starting Epoch 194\n",
      "1.5028375827747842\n",
      "Validation loss: 1.4128080606460571\n",
      "mse 1.412808084250701\n",
      "Starting Epoch 195\n",
      "1.5025648345117983\n",
      "Validation loss: 1.4126490354537964\n",
      "mse 1.4126491932759062\n",
      "Starting Epoch 196\n",
      "1.502261371716209\n",
      "Validation loss: 1.4126383066177368\n",
      "mse 1.4126384406953998\n",
      "Starting Epoch 197\n",
      "1.5019971158193506\n",
      "Validation loss: 1.4122902154922485\n",
      "mse 1.4122901690657337\n",
      "New best model found at epoch 197 with validation loss 1.4122902154922485\n",
      "Starting Epoch 198\n",
      "1.501754825529845\n",
      "Validation loss: 1.4124258756637573\n",
      "mse 1.412425785180118\n",
      "Starting Epoch 199\n",
      "1.5015437136525693\n",
      "Validation loss: 1.4123306274414062\n",
      "mse 1.412330682765989\n",
      "Starting Epoch 200\n",
      "1.5012643959211267\n",
      "Validation loss: 1.412298321723938\n",
      "mse 1.4122983771444595\n",
      "Starting Epoch 201\n",
      "1.5010366491649463\n",
      "Validation loss: 1.4121898412704468\n",
      "mse 1.4121898209825663\n",
      "New best model found at epoch 201 with validation loss 1.4121898412704468\n",
      "Starting Epoch 202\n",
      "1.5007835315621418\n",
      "Validation loss: 1.412095308303833\n",
      "mse 1.412095224598402\n",
      "New best model found at epoch 202 with validation loss 1.412095308303833\n",
      "Starting Epoch 203\n",
      "1.5005374732224837\n",
      "Validation loss: 1.4119199514389038\n",
      "mse 1.4119198536340438\n",
      "New best model found at epoch 203 with validation loss 1.4119199514389038\n",
      "Starting Epoch 204\n",
      "1.5003032813901487\n",
      "Validation loss: 1.4112735986709595\n",
      "mse 1.411273612134598\n",
      "New best model found at epoch 204 with validation loss 1.4112735986709595\n",
      "Starting Epoch 205\n",
      "1.5000973810320315\n",
      "Validation loss: 1.411664605140686\n",
      "mse 1.4116644496481718\n",
      "Starting Epoch 206\n",
      "1.4998030973517376\n",
      "Validation loss: 1.4110100269317627\n",
      "mse 1.4110099875209319\n",
      "New best model found at epoch 206 with validation loss 1.4110100269317627\n",
      "Starting Epoch 207\n",
      "1.499514584955962\n",
      "Validation loss: 1.411375641822815\n",
      "mse 1.4113756924182466\n",
      "Starting Epoch 208\n",
      "1.499254514341769\n",
      "Validation loss: 1.4112635850906372\n",
      "mse 1.4112636214490553\n",
      "Starting Epoch 209\n",
      "1.499111639416736\n",
      "Validation loss: 1.4113458395004272\n",
      "mse 1.4113457998804881\n",
      "Starting Epoch 210\n",
      "1.498758974282638\n",
      "Validation loss: 1.4109416007995605\n",
      "mse 1.4109415666063423\n",
      "New best model found at epoch 210 with validation loss 1.4109416007995605\n",
      "Starting Epoch 211\n",
      "1.4986340481302012\n",
      "Validation loss: 1.4109575748443604\n",
      "mse 1.4109575664818925\n",
      "Starting Epoch 212\n",
      "1.4984009784200918\n",
      "Validation loss: 1.4108779430389404\n",
      "mse 1.4108780190593615\n",
      "New best model found at epoch 212 with validation loss 1.4108779430389404\n",
      "Starting Epoch 213\n",
      "1.498193911884142\n",
      "Validation loss: 1.4107930660247803\n",
      "mse 1.4107931130287612\n",
      "New best model found at epoch 213 with validation loss 1.4107930660247803\n",
      "Starting Epoch 214\n",
      "1.4978895472443623\n",
      "Validation loss: 1.4105168581008911\n",
      "mse 1.4105168107311692\n",
      "New best model found at epoch 214 with validation loss 1.4105168581008911\n",
      "Starting Epoch 215\n",
      "1.4976661853168323\n",
      "Validation loss: 1.4104686975479126\n",
      "mse 1.4104685621733377\n",
      "New best model found at epoch 215 with validation loss 1.4104686975479126\n",
      "Starting Epoch 216\n",
      "1.4975465458372366\n",
      "Validation loss: 1.409752368927002\n",
      "mse 1.4097524184314592\n",
      "New best model found at epoch 216 with validation loss 1.409752368927002\n",
      "Starting Epoch 217\n",
      "1.4972782471905584\n",
      "Validation loss: 1.4099854230880737\n",
      "mse 1.4099854583656906\n",
      "Starting Epoch 218\n",
      "1.4970802405606145\n",
      "Validation loss: 1.4099395275115967\n",
      "mse 1.4099396381281422\n",
      "Starting Epoch 219\n",
      "1.496903606083082\n",
      "Validation loss: 1.4092366695404053\n",
      "mse 1.409236705359935\n",
      "New best model found at epoch 219 with validation loss 1.4092366695404053\n",
      "Starting Epoch 220\n",
      "1.4966282403987388\n",
      "Validation loss: 1.4096089601516724\n",
      "mse 1.4096089725826957\n",
      "Starting Epoch 221\n",
      "1.4964237446370332\n",
      "Validation loss: 1.4095261096954346\n",
      "mse 1.4095261098018776\n",
      "Starting Epoch 222\n",
      "1.4962736109028691\n",
      "Validation loss: 1.4088014364242554\n",
      "mse 1.4088013277734268\n",
      "New best model found at epoch 222 with validation loss 1.4088014364242554\n",
      "Starting Epoch 223\n",
      "1.4959772721580837\n",
      "Validation loss: 1.4091651439666748\n",
      "mse 1.4091651772408427\n",
      "Starting Epoch 224\n",
      "1.4957670673080112\n",
      "Validation loss: 1.4090044498443604\n",
      "mse 1.409004542030202\n",
      "Starting Epoch 225\n",
      "1.4956571278364763\n",
      "Validation loss: 1.4082995653152466\n",
      "mse 1.4082996663858958\n",
      "New best model found at epoch 225 with validation loss 1.4082995653152466\n",
      "Starting Epoch 226\n",
      "1.495453259219294\n",
      "Validation loss: 1.4080557823181152\n",
      "mse 1.4080558083275916\n",
      "New best model found at epoch 226 with validation loss 1.4080557823181152\n",
      "Starting Epoch 227\n",
      "1.4953061730965325\n",
      "Validation loss: 1.4079574346542358\n",
      "mse 1.4079573188471808\n",
      "New best model found at epoch 227 with validation loss 1.4079574346542358\n",
      "Starting Epoch 228\n",
      "1.4950263318808183\n",
      "Validation loss: 1.4084190130233765\n",
      "mse 1.4084191326242954\n",
      "Starting Epoch 229\n",
      "1.4947809343752654\n",
      "Validation loss: 1.408366084098816\n",
      "mse 1.40836589498397\n",
      "Starting Epoch 230\n",
      "1.49466247662254\n",
      "Validation loss: 1.4077039957046509\n",
      "mse 1.4077041559760994\n",
      "New best model found at epoch 230 with validation loss 1.4077039957046509\n",
      "Starting Epoch 231\n",
      "1.4943377816158792\n",
      "Validation loss: 1.408089518547058\n",
      "mse 1.4080895340815285\n",
      "Starting Epoch 232\n",
      "1.4942041065381921\n",
      "Validation loss: 1.407305359840393\n",
      "mse 1.4073052936022796\n",
      "New best model found at epoch 232 with validation loss 1.407305359840393\n",
      "Starting Epoch 233\n",
      "1.4939482626707659\n",
      "Validation loss: 1.4076327085494995\n",
      "mse 1.40763271770485\n",
      "Starting Epoch 234\n",
      "1.493758551452471\n",
      "Validation loss: 1.4076398611068726\n",
      "mse 1.407639729447935\n",
      "Starting Epoch 235\n",
      "1.4936407804489136\n",
      "Validation loss: 1.4069054126739502\n",
      "mse 1.4069053684657917\n",
      "New best model found at epoch 235 with validation loss 1.4069054126739502\n",
      "Starting Epoch 236\n",
      "1.4933447552763897\n",
      "Validation loss: 1.4072762727737427\n",
      "mse 1.4072762517352522\n",
      "Starting Epoch 237\n",
      "1.4932524535966956\n",
      "Validation loss: 1.406602144241333\n",
      "mse 1.4066021823057417\n",
      "New best model found at epoch 237 with validation loss 1.406602144241333\n",
      "Starting Epoch 238\n",
      "1.4930275782294895\n",
      "Validation loss: 1.4070239067077637\n",
      "mse 1.4070239961434208\n",
      "Starting Epoch 239\n",
      "1.4928509489349697\n",
      "Validation loss: 1.4062490463256836\n",
      "mse 1.4062489282291515\n",
      "New best model found at epoch 239 with validation loss 1.4062490463256836\n",
      "Starting Epoch 240\n",
      "1.492637284423994\n",
      "Validation loss: 1.4067491292953491\n",
      "mse 1.406749183935308\n",
      "Starting Epoch 241\n",
      "1.492356979328653\n",
      "Validation loss: 1.4065618515014648\n",
      "mse 1.406561954318284\n",
      "Starting Epoch 242\n",
      "1.4922950760177944\n",
      "Validation loss: 1.4059299230575562\n",
      "mse 1.4059297835107032\n",
      "New best model found at epoch 242 with validation loss 1.4059299230575562\n",
      "Starting Epoch 243\n",
      "1.49206498913143\n",
      "Validation loss: 1.4063152074813843\n",
      "mse 1.406315199660305\n",
      "Starting Epoch 244\n",
      "1.4918939186179119\n",
      "Validation loss: 1.4055780172348022\n",
      "mse 1.4055780209810613\n",
      "New best model found at epoch 244 with validation loss 1.4055780172348022\n",
      "Starting Epoch 245\n",
      "1.4918898058974224\n",
      "Validation loss: 1.4056758880615234\n",
      "mse 1.4056759357746804\n",
      "Starting Epoch 246\n",
      "1.4914502708808235\n",
      "Validation loss: 1.4064717292785645\n",
      "mse 1.4064717814113663\n",
      "Starting Epoch 247\n",
      "1.49141649318778\n",
      "Validation loss: 1.4054906368255615\n",
      "mse 1.4054906210961977\n",
      "New best model found at epoch 247 with validation loss 1.4054906368255615\n",
      "Starting Epoch 248\n",
      "1.4911967464115308\n",
      "Validation loss: 1.4051995277404785\n",
      "mse 1.4051993973824277\n",
      "New best model found at epoch 248 with validation loss 1.4051995277404785\n",
      "Starting Epoch 249\n",
      "1.4910633512165234\n",
      "Validation loss: 1.4050220251083374\n",
      "mse 1.4050219610135164\n",
      "New best model found at epoch 249 with validation loss 1.4050220251083374\n",
      "Starting Epoch 250\n",
      "1.4909007238305134\n",
      "Validation loss: 1.4050061702728271\n",
      "mse 1.4050060996192746\n",
      "New best model found at epoch 250 with validation loss 1.4050061702728271\n",
      "Starting Epoch 251\n",
      "1.490740338097448\n",
      "Validation loss: 1.4048417806625366\n",
      "mse 1.4048417142326692\n",
      "New best model found at epoch 251 with validation loss 1.4048417806625366\n",
      "Starting Epoch 252\n",
      "1.4905681584192358\n",
      "Validation loss: 1.404814600944519\n",
      "mse 1.404814487221904\n",
      "New best model found at epoch 252 with validation loss 1.404814600944519\n",
      "Starting Epoch 253\n",
      "1.490365637385327\n",
      "Validation loss: 1.404660940170288\n",
      "mse 1.4046609125884688\n",
      "New best model found at epoch 253 with validation loss 1.404660940170288\n",
      "Starting Epoch 254\n",
      "1.4902043342590332\n",
      "Validation loss: 1.4046722650527954\n",
      "mse 1.4046721900949946\n",
      "Starting Epoch 255\n",
      "1.4900402919105862\n",
      "Validation loss: 1.404528260231018\n",
      "mse 1.4045281991523952\n",
      "New best model found at epoch 255 with validation loss 1.404528260231018\n",
      "Starting Epoch 256\n",
      "1.4898357365442358\n",
      "Validation loss: 1.4043502807617188\n",
      "mse 1.4043501980825654\n",
      "New best model found at epoch 256 with validation loss 1.4043502807617188\n",
      "Starting Epoch 257\n",
      "1.4896951862003491\n",
      "Validation loss: 1.4043253660202026\n",
      "mse 1.4043254164292407\n",
      "New best model found at epoch 257 with validation loss 1.4043253660202026\n",
      "Starting Epoch 258\n",
      "1.4895000405933545\n",
      "Validation loss: 1.404194712638855\n",
      "mse 1.4041946984924871\n",
      "New best model found at epoch 258 with validation loss 1.404194712638855\n",
      "Starting Epoch 259\n",
      "1.489318083161893\n",
      "Validation loss: 1.4040921926498413\n",
      "mse 1.404092132724705\n",
      "New best model found at epoch 259 with validation loss 1.4040921926498413\n",
      "Starting Epoch 260\n",
      "1.4891675114631653\n",
      "Validation loss: 1.4040054082870483\n",
      "mse 1.4040053319220527\n",
      "New best model found at epoch 260 with validation loss 1.4040054082870483\n",
      "Starting Epoch 261\n",
      "1.4889828795972078\n",
      "Validation loss: 1.403876543045044\n",
      "mse 1.4038765010481449\n",
      "New best model found at epoch 261 with validation loss 1.403876543045044\n",
      "Starting Epoch 262\n",
      "1.4888232246689175\n",
      "Validation loss: 1.4037644863128662\n",
      "mse 1.4037645142759423\n",
      "New best model found at epoch 262 with validation loss 1.4037644863128662\n",
      "Starting Epoch 263\n",
      "1.4886455484058545\n",
      "Validation loss: 1.403630018234253\n",
      "mse 1.4036300466606801\n",
      "New best model found at epoch 263 with validation loss 1.403630018234253\n",
      "Starting Epoch 264\n",
      "1.488493175610252\n",
      "Validation loss: 1.4035505056381226\n",
      "mse 1.4035505236175494\n",
      "New best model found at epoch 264 with validation loss 1.4035505056381226\n",
      "Starting Epoch 265\n",
      "1.4883171475451926\n",
      "Validation loss: 1.4034388065338135\n",
      "mse 1.4034387413932157\n",
      "New best model found at epoch 265 with validation loss 1.4034388065338135\n",
      "Starting Epoch 266\n",
      "1.4881620251614114\n",
      "Validation loss: 1.4033418893814087\n",
      "mse 1.403341811240468\n",
      "New best model found at epoch 266 with validation loss 1.4033418893814087\n",
      "Starting Epoch 267\n",
      "1.4879723994628242\n",
      "Validation loss: 1.403253197669983\n",
      "mse 1.4032532112848002\n",
      "New best model found at epoch 267 with validation loss 1.403253197669983\n",
      "Starting Epoch 268\n",
      "1.4878237351127293\n",
      "Validation loss: 1.4031803607940674\n",
      "mse 1.403180341723065\n",
      "New best model found at epoch 268 with validation loss 1.4031803607940674\n",
      "Starting Epoch 269\n",
      "1.4876706237378328\n",
      "Validation loss: 1.4030051231384277\n",
      "mse 1.403005131115599\n",
      "New best model found at epoch 269 with validation loss 1.4030051231384277\n",
      "Starting Epoch 270\n",
      "1.4875276814336362\n",
      "Validation loss: 1.402791142463684\n",
      "mse 1.4027911598849094\n",
      "New best model found at epoch 270 with validation loss 1.402791142463684\n",
      "Starting Epoch 271\n",
      "1.4873296566631482\n",
      "Validation loss: 1.4028269052505493\n",
      "mse 1.40282692794182\n",
      "Starting Epoch 272\n",
      "1.4871766126674155\n",
      "Validation loss: 1.4026602506637573\n",
      "mse 1.402660224703663\n",
      "New best model found at epoch 272 with validation loss 1.4026602506637573\n",
      "Starting Epoch 273\n",
      "1.4869884848594666\n",
      "Validation loss: 1.4025609493255615\n",
      "mse 1.4025611035372352\n",
      "New best model found at epoch 273 with validation loss 1.4025609493255615\n",
      "Starting Epoch 274\n",
      "1.4868431091308594\n",
      "Validation loss: 1.402665376663208\n",
      "mse 1.4026653192156207\n",
      "Starting Epoch 275\n",
      "1.4866987414982007\n",
      "Validation loss: 1.4025505781173706\n",
      "mse 1.4025505082871585\n",
      "New best model found at epoch 275 with validation loss 1.4025505781173706\n",
      "Starting Epoch 276\n",
      "1.4864615357440452\n",
      "Validation loss: 1.4024299383163452\n",
      "mse 1.402429929656848\n",
      "New best model found at epoch 276 with validation loss 1.4024299383163452\n",
      "Starting Epoch 277\n",
      "1.486378252506256\n",
      "Validation loss: 1.402335286140442\n",
      "mse 1.4023352935064657\n",
      "New best model found at epoch 277 with validation loss 1.402335286140442\n",
      "Starting Epoch 278\n",
      "1.4861355294351992\n",
      "Validation loss: 1.4030994176864624\n",
      "mse 1.4030994784350261\n",
      "Starting Epoch 279\n",
      "1.4860035699346792\n",
      "Validation loss: 1.4023305177688599\n",
      "mse 1.4023306816408752\n",
      "New best model found at epoch 279 with validation loss 1.4023305177688599\n",
      "Starting Epoch 280\n",
      "1.4858487196590588\n",
      "Validation loss: 1.4021575450897217\n",
      "mse 1.4021577360356694\n",
      "New best model found at epoch 280 with validation loss 1.4021575450897217\n",
      "Starting Epoch 281\n",
      "1.485714246397433\n",
      "Validation loss: 1.4021210670471191\n",
      "mse 1.4021209186884536\n",
      "New best model found at epoch 281 with validation loss 1.4021210670471191\n",
      "Starting Epoch 282\n",
      "1.4855422973632812\n",
      "Validation loss: 1.4020544290542603\n",
      "mse 1.40205455851852\n",
      "New best model found at epoch 282 with validation loss 1.4020544290542603\n",
      "Starting Epoch 283\n",
      "1.4853903443916985\n",
      "Validation loss: 1.401963233947754\n",
      "mse 1.4019631810318987\n",
      "New best model found at epoch 283 with validation loss 1.401963233947754\n",
      "Starting Epoch 284\n",
      "1.4852538186570872\n",
      "Validation loss: 1.4018194675445557\n",
      "mse 1.401819501981086\n",
      "New best model found at epoch 284 with validation loss 1.4018194675445557\n",
      "Starting Epoch 285\n",
      "1.4850774277811465\n",
      "Validation loss: 1.4017515182495117\n",
      "mse 1.401751398506613\n",
      "New best model found at epoch 285 with validation loss 1.4017515182495117\n",
      "Starting Epoch 286\n",
      "1.4849228340646494\n",
      "Validation loss: 1.401625394821167\n",
      "mse 1.4016254532370624\n",
      "New best model found at epoch 286 with validation loss 1.401625394821167\n",
      "Starting Epoch 287\n",
      "1.4847891408464182\n",
      "Validation loss: 1.401589035987854\n",
      "mse 1.4015889477309986\n",
      "New best model found at epoch 287 with validation loss 1.401589035987854\n",
      "Starting Epoch 288\n",
      "1.4846095183621282\n",
      "Validation loss: 1.401435136795044\n",
      "mse 1.401435193869909\n",
      "New best model found at epoch 288 with validation loss 1.401435136795044\n",
      "Starting Epoch 289\n",
      "1.484488106292227\n",
      "Validation loss: 1.4014390707015991\n",
      "mse 1.4014389804995584\n",
      "Starting Epoch 290\n",
      "1.48430481682653\n",
      "Validation loss: 1.4012738466262817\n",
      "mse 1.401273835453482\n",
      "New best model found at epoch 290 with validation loss 1.4012738466262817\n",
      "Starting Epoch 291\n",
      "1.4841780351555867\n",
      "Validation loss: 1.401232361793518\n",
      "mse 1.401232385958239\n",
      "New best model found at epoch 291 with validation loss 1.401232361793518\n",
      "Starting Epoch 292\n",
      "1.4840008305466694\n",
      "Validation loss: 1.401091456413269\n",
      "mse 1.401091557846132\n",
      "New best model found at epoch 292 with validation loss 1.401091456413269\n",
      "Starting Epoch 293\n",
      "1.4838723851286846\n",
      "Validation loss: 1.4013105630874634\n",
      "mse 1.401310514352705\n",
      "Starting Epoch 294\n",
      "1.4837531369665395\n",
      "Validation loss: 1.40134859085083\n",
      "mse 1.4013485646647061\n",
      "Starting Epoch 295\n",
      "1.4835630188817563\n",
      "Validation loss: 1.4011528491973877\n",
      "mse 1.401152736816735\n",
      "Starting Epoch 296\n",
      "1.483488142490387\n",
      "Validation loss: 1.4008532762527466\n",
      "mse 1.4008534202050964\n",
      "New best model found at epoch 296 with validation loss 1.4008532762527466\n",
      "Starting Epoch 297\n",
      "1.4833342718041462\n",
      "Validation loss: 1.4007614850997925\n",
      "mse 1.4007614877779166\n",
      "New best model found at epoch 297 with validation loss 1.4007614850997925\n",
      "Starting Epoch 298\n",
      "1.4831748760264853\n",
      "Validation loss: 1.4005985260009766\n",
      "mse 1.4005984284770963\n",
      "New best model found at epoch 298 with validation loss 1.4005985260009766\n",
      "Starting Epoch 299\n",
      "1.4830390163089917\n",
      "Validation loss: 1.4005322456359863\n",
      "mse 1.4005322529477844\n",
      "New best model found at epoch 299 with validation loss 1.4005322456359863\n",
      "Starting Epoch 300\n",
      "1.4828773192737414\n",
      "Validation loss: 1.4004149436950684\n",
      "mse 1.4004149350694415\n",
      "New best model found at epoch 300 with validation loss 1.4004149436950684\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-10-5-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41228e1",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 20 - 10 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "368b2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "0a27d32a-a2f4-48fb-b65f-3f08994d609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.013695944910464\n",
      "Validation loss: 2.5935707092285156\n",
      "mse 2.593570952331032\n",
      "New best model found at epoch 1 with validation loss 2.5935707092285156\n",
      "Starting Epoch 2\n",
      "2.8182783748792564\n",
      "Validation loss: 2.468169927597046\n",
      "mse 2.4681699509488646\n",
      "New best model found at epoch 2 with validation loss 2.468169927597046\n",
      "Starting Epoch 3\n",
      "2.680663207302923\n",
      "Validation loss: 2.354560375213623\n",
      "mse 2.354560518170615\n",
      "New best model found at epoch 3 with validation loss 2.354560375213623\n",
      "Starting Epoch 4\n",
      "2.5552903672923213\n",
      "Validation loss: 2.248195171356201\n",
      "mse 2.2481952587915677\n",
      "New best model found at epoch 4 with validation loss 2.248195171356201\n",
      "Starting Epoch 5\n",
      "2.4413186259891675\n",
      "Validation loss: 2.154550790786743\n",
      "mse 2.154550830679693\n",
      "New best model found at epoch 5 with validation loss 2.154550790786743\n",
      "Starting Epoch 6\n",
      "2.3398142586583677\n",
      "Validation loss: 2.069892644882202\n",
      "mse 2.069892812443734\n",
      "New best model found at epoch 6 with validation loss 2.069892644882202\n",
      "Starting Epoch 7\n",
      "2.2509943091351055\n",
      "Validation loss: 1.9974390268325806\n",
      "mse 1.9974389455513264\n",
      "New best model found at epoch 7 with validation loss 1.9974390268325806\n",
      "Starting Epoch 8\n",
      "2.1737002859944883\n",
      "Validation loss: 1.9371713399887085\n",
      "mse 1.937171391370668\n",
      "New best model found at epoch 8 with validation loss 1.9371713399887085\n",
      "Starting Epoch 9\n",
      "2.108066579569941\n",
      "Validation loss: 1.8851326704025269\n",
      "mse 1.8851325418012412\n",
      "New best model found at epoch 9 with validation loss 1.8851326704025269\n",
      "Starting Epoch 10\n",
      "2.0514117427494214\n",
      "Validation loss: 1.8403751850128174\n",
      "mse 1.84037516781284\n",
      "New best model found at epoch 10 with validation loss 1.8403751850128174\n",
      "Starting Epoch 11\n",
      "2.002755693767382\n",
      "Validation loss: 1.8022608757019043\n",
      "mse 1.802260826139645\n",
      "New best model found at epoch 11 with validation loss 1.8022608757019043\n",
      "Starting Epoch 12\n",
      "1.9601257780323857\n",
      "Validation loss: 1.7673287391662598\n",
      "mse 1.7673287422735453\n",
      "New best model found at epoch 12 with validation loss 1.7673287391662598\n",
      "Starting Epoch 13\n",
      "1.9219949193622754\n",
      "Validation loss: 1.7367241382598877\n",
      "mse 1.7367241306882355\n",
      "New best model found at epoch 13 with validation loss 1.7367241382598877\n",
      "Starting Epoch 14\n",
      "1.8883388146110203\n",
      "Validation loss: 1.7111502885818481\n",
      "mse 1.7111502989226037\n",
      "New best model found at epoch 14 with validation loss 1.7111502885818481\n",
      "Starting Epoch 15\n",
      "1.859503201816393\n",
      "Validation loss: 1.6883083581924438\n",
      "mse 1.6883082102007934\n",
      "New best model found at epoch 15 with validation loss 1.6883083581924438\n",
      "Starting Epoch 16\n",
      "1.834094710971998\n",
      "Validation loss: 1.6688286066055298\n",
      "mse 1.6688287672378197\n",
      "New best model found at epoch 16 with validation loss 1.6688286066055298\n",
      "Starting Epoch 17\n",
      "1.8116873813712078\n",
      "Validation loss: 1.6492043733596802\n",
      "mse 1.6492042170700183\n",
      "New best model found at epoch 17 with validation loss 1.6492043733596802\n",
      "Starting Epoch 18\n",
      "1.792167482168778\n",
      "Validation loss: 1.6333509683609009\n",
      "mse 1.6333509863848765\n",
      "New best model found at epoch 18 with validation loss 1.6333509683609009\n",
      "Starting Epoch 19\n",
      "1.7751141786575317\n",
      "Validation loss: 1.6187108755111694\n",
      "mse 1.618710800108872\n",
      "New best model found at epoch 19 with validation loss 1.6187108755111694\n",
      "Starting Epoch 20\n",
      "1.7600920355838279\n",
      "Validation loss: 1.6067132949829102\n",
      "mse 1.6067131726830748\n",
      "New best model found at epoch 20 with validation loss 1.6067132949829102\n",
      "Starting Epoch 21\n",
      "1.744369247685308\n",
      "Validation loss: 1.5906500816345215\n",
      "mse 1.5906501578305676\n",
      "New best model found at epoch 21 with validation loss 1.5906500816345215\n",
      "Starting Epoch 22\n",
      "1.7278675929359768\n",
      "Validation loss: 1.5760984420776367\n",
      "mse 1.5760985723701797\n",
      "New best model found at epoch 22 with validation loss 1.5760984420776367\n",
      "Starting Epoch 23\n",
      "1.7131042946939883\n",
      "Validation loss: 1.5624791383743286\n",
      "mse 1.5624791830999716\n",
      "New best model found at epoch 23 with validation loss 1.5624791383743286\n",
      "Starting Epoch 24\n",
      "1.6988268727841584\n",
      "Validation loss: 1.5521721839904785\n",
      "mse 1.5521721177611834\n",
      "New best model found at epoch 24 with validation loss 1.5521721839904785\n",
      "Starting Epoch 25\n",
      "1.6866350795911706\n",
      "Validation loss: 1.5428613424301147\n",
      "mse 1.5428613678619378\n",
      "New best model found at epoch 25 with validation loss 1.5428613424301147\n",
      "Starting Epoch 26\n",
      "1.6761831407961638\n",
      "Validation loss: 1.5348730087280273\n",
      "mse 1.5348729708892628\n",
      "New best model found at epoch 26 with validation loss 1.5348730087280273\n",
      "Starting Epoch 27\n",
      "1.666554622028185\n",
      "Validation loss: 1.5279805660247803\n",
      "mse 1.5279805326001477\n",
      "New best model found at epoch 27 with validation loss 1.5279805660247803\n",
      "Starting Epoch 28\n",
      "1.6577677312104597\n",
      "Validation loss: 1.5218867063522339\n",
      "mse 1.5218864749371175\n",
      "New best model found at epoch 28 with validation loss 1.5218867063522339\n",
      "Starting Epoch 29\n",
      "1.6499163637990537\n",
      "Validation loss: 1.5161466598510742\n",
      "mse 1.516146630701864\n",
      "New best model found at epoch 29 with validation loss 1.5161466598510742\n",
      "Starting Epoch 30\n",
      "1.6436664798985356\n",
      "Validation loss: 1.5114893913269043\n",
      "mse 1.5114893961086882\n",
      "New best model found at epoch 30 with validation loss 1.5114893913269043\n",
      "Starting Epoch 31\n",
      "1.637616040913955\n",
      "Validation loss: 1.5072147846221924\n",
      "mse 1.507214655271655\n",
      "New best model found at epoch 31 with validation loss 1.5072147846221924\n",
      "Starting Epoch 32\n",
      "1.6320463911346768\n",
      "Validation loss: 1.5034478902816772\n",
      "mse 1.503447899068776\n",
      "New best model found at epoch 32 with validation loss 1.5034478902816772\n",
      "Starting Epoch 33\n",
      "1.626960241276285\n",
      "Validation loss: 1.5000194311141968\n",
      "mse 1.5000194878732518\n",
      "New best model found at epoch 33 with validation loss 1.5000194311141968\n",
      "Starting Epoch 34\n",
      "1.6221299326938132\n",
      "Validation loss: 1.4964475631713867\n",
      "mse 1.4964475666033137\n",
      "New best model found at epoch 34 with validation loss 1.4964475631713867\n",
      "Starting Epoch 35\n",
      "1.618020438629648\n",
      "Validation loss: 1.4931930303573608\n",
      "mse 1.4931930620942278\n",
      "New best model found at epoch 35 with validation loss 1.4931930303573608\n",
      "Starting Epoch 36\n",
      "1.6139896278795989\n",
      "Validation loss: 1.4905331134796143\n",
      "mse 1.490533196626375\n",
      "New best model found at epoch 36 with validation loss 1.4905331134796143\n",
      "Starting Epoch 37\n",
      "1.6102023824401523\n",
      "Validation loss: 1.4877440929412842\n",
      "mse 1.4877441450893405\n",
      "New best model found at epoch 37 with validation loss 1.4877440929412842\n",
      "Starting Epoch 38\n",
      "1.6067135619080586\n",
      "Validation loss: 1.485390543937683\n",
      "mse 1.4853905946241508\n",
      "New best model found at epoch 38 with validation loss 1.485390543937683\n",
      "Starting Epoch 39\n",
      "1.603390615919362\n",
      "Validation loss: 1.4830988645553589\n",
      "mse 1.4830988765728406\n",
      "New best model found at epoch 39 with validation loss 1.4830988645553589\n",
      "Starting Epoch 40\n",
      "1.6002381599467734\n",
      "Validation loss: 1.480355978012085\n",
      "mse 1.480355952192767\n",
      "New best model found at epoch 40 with validation loss 1.480355978012085\n",
      "Starting Epoch 41\n",
      "1.597304344177246\n",
      "Validation loss: 1.4779013395309448\n",
      "mse 1.4779013352926464\n",
      "New best model found at epoch 41 with validation loss 1.4779013395309448\n",
      "Starting Epoch 42\n",
      "1.5943810447402622\n",
      "Validation loss: 1.4756454229354858\n",
      "mse 1.4756453817269277\n",
      "New best model found at epoch 42 with validation loss 1.4756454229354858\n",
      "Starting Epoch 43\n",
      "1.5915574431419373\n",
      "Validation loss: 1.4737972021102905\n",
      "mse 1.473797145008214\n",
      "New best model found at epoch 43 with validation loss 1.4737972021102905\n",
      "Starting Epoch 44\n",
      "1.588857624841773\n",
      "Validation loss: 1.4716975688934326\n",
      "mse 1.471697757968357\n",
      "New best model found at epoch 44 with validation loss 1.4716975688934326\n",
      "Starting Epoch 45\n",
      "1.5863320075947305\n",
      "Validation loss: 1.4701004028320312\n",
      "mse 1.4701002581018079\n",
      "New best model found at epoch 45 with validation loss 1.4701004028320312\n",
      "Starting Epoch 46\n",
      "1.583922546842824\n",
      "Validation loss: 1.4689147472381592\n",
      "mse 1.4689146805910371\n",
      "New best model found at epoch 46 with validation loss 1.4689147472381592\n",
      "Starting Epoch 47\n",
      "1.5816625900890515\n",
      "Validation loss: 1.4675463438034058\n",
      "mse 1.4675464957223614\n",
      "New best model found at epoch 47 with validation loss 1.4675463438034058\n",
      "Starting Epoch 48\n",
      "1.5794572648794756\n",
      "Validation loss: 1.4660500288009644\n",
      "mse 1.4660501142911464\n",
      "New best model found at epoch 48 with validation loss 1.4660500288009644\n",
      "Starting Epoch 49\n",
      "1.5773242271464805\n",
      "Validation loss: 1.4645248651504517\n",
      "mse 1.4645251070030427\n",
      "New best model found at epoch 49 with validation loss 1.4645248651504517\n",
      "Starting Epoch 50\n",
      "1.5754697581996089\n",
      "Validation loss: 1.4631386995315552\n",
      "mse 1.4631387292581308\n",
      "New best model found at epoch 50 with validation loss 1.4631386995315552\n",
      "Starting Epoch 51\n",
      "1.5734068077543508\n",
      "Validation loss: 1.4619247913360596\n",
      "mse 1.4619248288009519\n",
      "New best model found at epoch 51 with validation loss 1.4619247913360596\n",
      "Starting Epoch 52\n",
      "1.5715381243954534\n",
      "Validation loss: 1.460781455039978\n",
      "mse 1.4607815523386654\n",
      "New best model found at epoch 52 with validation loss 1.460781455039978\n",
      "Starting Epoch 53\n",
      "1.5696725871251977\n",
      "Validation loss: 1.4595413208007812\n",
      "mse 1.459541118240145\n",
      "New best model found at epoch 53 with validation loss 1.4595413208007812\n",
      "Starting Epoch 54\n",
      "1.5678562547849573\n",
      "Validation loss: 1.458290696144104\n",
      "mse 1.4582906044210169\n",
      "New best model found at epoch 54 with validation loss 1.458290696144104\n",
      "Starting Epoch 55\n",
      "1.5661490067191746\n",
      "Validation loss: 1.4570866823196411\n",
      "mse 1.4570866936979097\n",
      "New best model found at epoch 55 with validation loss 1.4570866823196411\n",
      "Starting Epoch 56\n",
      "1.5644330978393555\n",
      "Validation loss: 1.456002116203308\n",
      "mse 1.4560022103244452\n",
      "New best model found at epoch 56 with validation loss 1.456002116203308\n",
      "Starting Epoch 57\n",
      "1.5627413107001262\n",
      "Validation loss: 1.4548723697662354\n",
      "mse 1.4548723193257356\n",
      "New best model found at epoch 57 with validation loss 1.4548723697662354\n",
      "Starting Epoch 58\n",
      "1.5611484698627307\n",
      "Validation loss: 1.4538034200668335\n",
      "mse 1.4538033562190464\n",
      "New best model found at epoch 58 with validation loss 1.4538034200668335\n",
      "Starting Epoch 59\n",
      "1.559665068336155\n",
      "Validation loss: 1.452741265296936\n",
      "mse 1.4527412801027677\n",
      "New best model found at epoch 59 with validation loss 1.452741265296936\n",
      "Starting Epoch 60\n",
      "1.5581391505573108\n",
      "Validation loss: 1.4517507553100586\n",
      "mse 1.4517507547989894\n",
      "New best model found at epoch 60 with validation loss 1.4517507553100586\n",
      "Starting Epoch 61\n",
      "1.556743430054706\n",
      "Validation loss: 1.4507935047149658\n",
      "mse 1.4507934456893543\n",
      "New best model found at epoch 61 with validation loss 1.4507935047149658\n",
      "Starting Epoch 62\n",
      "1.5552957602169202\n",
      "Validation loss: 1.449756383895874\n",
      "mse 1.4497563615590403\n",
      "New best model found at epoch 62 with validation loss 1.449756383895874\n",
      "Starting Epoch 63\n",
      "1.5538775324821472\n",
      "Validation loss: 1.4489243030548096\n",
      "mse 1.4489242572307361\n",
      "New best model found at epoch 63 with validation loss 1.4489243030548096\n",
      "Starting Epoch 64\n",
      "1.5526152926942576\n",
      "Validation loss: 1.4480665922164917\n",
      "mse 1.4480665320626982\n",
      "New best model found at epoch 64 with validation loss 1.4480665922164917\n",
      "Starting Epoch 65\n",
      "1.55125093460083\n",
      "Validation loss: 1.4471683502197266\n",
      "mse 1.4471684015977737\n",
      "New best model found at epoch 65 with validation loss 1.4471683502197266\n",
      "Starting Epoch 66\n",
      "1.5499270014140918\n",
      "Validation loss: 1.4462461471557617\n",
      "mse 1.4462462062864496\n",
      "New best model found at epoch 66 with validation loss 1.4462461471557617\n",
      "Starting Epoch 67\n",
      "1.5487053627553193\n",
      "Validation loss: 1.4455419778823853\n",
      "mse 1.445542063756699\n",
      "New best model found at epoch 67 with validation loss 1.4455419778823853\n",
      "Starting Epoch 68\n",
      "1.5474081169004026\n",
      "Validation loss: 1.4446829557418823\n",
      "mse 1.4446829711104197\n",
      "New best model found at epoch 68 with validation loss 1.4446829557418823\n",
      "Starting Epoch 69\n",
      "1.5461998193160347\n",
      "Validation loss: 1.4440299272537231\n",
      "mse 1.4440298737647292\n",
      "New best model found at epoch 69 with validation loss 1.4440299272537231\n",
      "Starting Epoch 70\n",
      "1.5449845972268477\n",
      "Validation loss: 1.4430854320526123\n",
      "mse 1.4430854238698785\n",
      "New best model found at epoch 70 with validation loss 1.4430854320526123\n",
      "Starting Epoch 71\n",
      "1.5438188858654187\n",
      "Validation loss: 1.4424062967300415\n",
      "mse 1.4424062945139595\n",
      "New best model found at epoch 71 with validation loss 1.4424062967300415\n",
      "Starting Epoch 72\n",
      "1.542558200981306\n",
      "Validation loss: 1.4417229890823364\n",
      "mse 1.441722939314072\n",
      "New best model found at epoch 72 with validation loss 1.4417229890823364\n",
      "Starting Epoch 73\n",
      "1.541489751442619\n",
      "Validation loss: 1.441023826599121\n",
      "mse 1.4410237852360808\n",
      "New best model found at epoch 73 with validation loss 1.441023826599121\n",
      "Starting Epoch 74\n",
      "1.540392588014188\n",
      "Validation loss: 1.4400312900543213\n",
      "mse 1.4400311970989266\n",
      "New best model found at epoch 74 with validation loss 1.4400312900543213\n",
      "Starting Epoch 75\n",
      "1.5392134733822034\n",
      "Validation loss: 1.4395371675491333\n",
      "mse 1.4395370902962463\n",
      "New best model found at epoch 75 with validation loss 1.4395371675491333\n",
      "Starting Epoch 76\n",
      "1.538183691708938\n",
      "Validation loss: 1.4385021924972534\n",
      "mse 1.4385022302785277\n",
      "New best model found at epoch 76 with validation loss 1.4385021924972534\n",
      "Starting Epoch 77\n",
      "1.537220527296481\n",
      "Validation loss: 1.4378756284713745\n",
      "mse 1.4378756509911066\n",
      "New best model found at epoch 77 with validation loss 1.4378756284713745\n",
      "Starting Epoch 78\n",
      "1.5360552331675654\n",
      "Validation loss: 1.437398910522461\n",
      "mse 1.4373989941538077\n",
      "New best model found at epoch 78 with validation loss 1.437398910522461\n",
      "Starting Epoch 79\n",
      "1.5351918728455254\n",
      "Validation loss: 1.4367306232452393\n",
      "mse 1.4367306664359418\n",
      "New best model found at epoch 79 with validation loss 1.4367306232452393\n",
      "Starting Epoch 80\n",
      "1.534076830615168\n",
      "Validation loss: 1.4360835552215576\n",
      "mse 1.4360835487600543\n",
      "New best model found at epoch 80 with validation loss 1.4360835552215576\n",
      "Starting Epoch 81\n",
      "1.533172221287437\n",
      "Validation loss: 1.4354139566421509\n",
      "mse 1.435414061726041\n",
      "New best model found at epoch 81 with validation loss 1.4354139566421509\n",
      "Starting Epoch 82\n",
      "1.5321818382843682\n",
      "Validation loss: 1.4347172975540161\n",
      "mse 1.4347174152949462\n",
      "New best model found at epoch 82 with validation loss 1.4347172975540161\n",
      "Starting Epoch 83\n",
      "1.5312335335690042\n",
      "Validation loss: 1.4340968132019043\n",
      "mse 1.4340967315487672\n",
      "New best model found at epoch 83 with validation loss 1.4340968132019043\n",
      "Starting Epoch 84\n",
      "1.5302951335906982\n",
      "Validation loss: 1.4334827661514282\n",
      "mse 1.433482759706545\n",
      "New best model found at epoch 84 with validation loss 1.4334827661514282\n",
      "Starting Epoch 85\n",
      "1.5293712175410727\n",
      "Validation loss: 1.432819128036499\n",
      "mse 1.4328191909116983\n",
      "New best model found at epoch 85 with validation loss 1.432819128036499\n",
      "Starting Epoch 86\n",
      "1.5284819058749988\n",
      "Validation loss: 1.4322539567947388\n",
      "mse 1.4322541583762491\n",
      "New best model found at epoch 86 with validation loss 1.4322539567947388\n",
      "Starting Epoch 87\n",
      "1.5275758323462114\n",
      "Validation loss: 1.4316736459732056\n",
      "mse 1.4316735374478113\n",
      "New best model found at epoch 87 with validation loss 1.4316736459732056\n",
      "Starting Epoch 88\n",
      "1.5266989184462505\n",
      "Validation loss: 1.431045651435852\n",
      "mse 1.4310456455315848\n",
      "New best model found at epoch 88 with validation loss 1.431045651435852\n",
      "Starting Epoch 89\n",
      "1.5258169251939524\n",
      "Validation loss: 1.4305139780044556\n",
      "mse 1.430513957593133\n",
      "New best model found at epoch 89 with validation loss 1.4305139780044556\n",
      "Starting Epoch 90\n",
      "1.52495160828466\n",
      "Validation loss: 1.4299683570861816\n",
      "mse 1.4299682985289057\n",
      "New best model found at epoch 90 with validation loss 1.4299683570861816\n",
      "Starting Epoch 91\n",
      "1.5240898443304973\n",
      "Validation loss: 1.4294143915176392\n",
      "mse 1.42941424241765\n",
      "New best model found at epoch 91 with validation loss 1.4294143915176392\n",
      "Starting Epoch 92\n",
      "1.523207198018613\n",
      "Validation loss: 1.4288231134414673\n",
      "mse 1.4288231596404117\n",
      "New best model found at epoch 92 with validation loss 1.4288231134414673\n",
      "Starting Epoch 93\n",
      "1.522399005682572\n",
      "Validation loss: 1.4282599687576294\n",
      "mse 1.428259939126565\n",
      "New best model found at epoch 93 with validation loss 1.4282599687576294\n",
      "Starting Epoch 94\n",
      "1.521574626798215\n",
      "Validation loss: 1.4277399778366089\n",
      "mse 1.4277398428686239\n",
      "New best model found at epoch 94 with validation loss 1.4277399778366089\n",
      "Starting Epoch 95\n",
      "1.5207527357599009\n",
      "Validation loss: 1.4271451234817505\n",
      "mse 1.427145209007666\n",
      "New best model found at epoch 95 with validation loss 1.4271451234817505\n",
      "Starting Epoch 96\n",
      "1.5199710130691528\n",
      "Validation loss: 1.4265013933181763\n",
      "mse 1.426501362473563\n",
      "New best model found at epoch 96 with validation loss 1.4265013933181763\n",
      "Starting Epoch 97\n",
      "1.519122214420982\n",
      "Validation loss: 1.4260094165802002\n",
      "mse 1.4260092887705673\n",
      "New best model found at epoch 97 with validation loss 1.4260094165802002\n",
      "Starting Epoch 98\n",
      "1.518415611723195\n",
      "Validation loss: 1.4254567623138428\n",
      "mse 1.4254566078617217\n",
      "New best model found at epoch 98 with validation loss 1.4254567623138428\n",
      "Starting Epoch 99\n",
      "1.5176245440607485\n",
      "Validation loss: 1.4248123168945312\n",
      "mse 1.424812275635971\n",
      "New best model found at epoch 99 with validation loss 1.4248123168945312\n",
      "Starting Epoch 100\n",
      "1.516842862834101\n",
      "Validation loss: 1.4243708848953247\n",
      "mse 1.4243710187746421\n",
      "New best model found at epoch 100 with validation loss 1.4243708848953247\n",
      "Starting Epoch 101\n",
      "1.5160813746245012\n",
      "Validation loss: 1.4237465858459473\n",
      "mse 1.4237465566248217\n",
      "New best model found at epoch 101 with validation loss 1.4237465858459473\n",
      "Starting Epoch 102\n",
      "1.515327248884284\n",
      "Validation loss: 1.4233003854751587\n",
      "mse 1.4233001925185285\n",
      "New best model found at epoch 102 with validation loss 1.4233003854751587\n",
      "Starting Epoch 103\n",
      "1.5145901700724727\n",
      "Validation loss: 1.4226692914962769\n",
      "mse 1.4226693440118237\n",
      "New best model found at epoch 103 with validation loss 1.4226692914962769\n",
      "Starting Epoch 104\n",
      "1.513856265855872\n",
      "Validation loss: 1.422242522239685\n",
      "mse 1.4222424048941869\n",
      "New best model found at epoch 104 with validation loss 1.422242522239685\n",
      "Starting Epoch 105\n",
      "1.5131685215493906\n",
      "Validation loss: 1.4215543270111084\n",
      "mse 1.421554341655118\n",
      "New best model found at epoch 105 with validation loss 1.4215543270111084\n",
      "Starting Epoch 106\n",
      "1.5124092127965845\n",
      "Validation loss: 1.42122483253479\n",
      "mse 1.4212248816176118\n",
      "New best model found at epoch 106 with validation loss 1.42122483253479\n",
      "Starting Epoch 107\n",
      "1.5117145932239036\n",
      "Validation loss: 1.420632004737854\n",
      "mse 1.4206320032446147\n",
      "New best model found at epoch 107 with validation loss 1.420632004737854\n",
      "Starting Epoch 108\n",
      "1.5109832986541416\n",
      "Validation loss: 1.4202275276184082\n",
      "mse 1.4202275035144998\n",
      "New best model found at epoch 108 with validation loss 1.4202275276184082\n",
      "Starting Epoch 109\n",
      "1.510320202164028\n",
      "Validation loss: 1.4195563793182373\n",
      "mse 1.4195564346223666\n",
      "New best model found at epoch 109 with validation loss 1.4195563793182373\n",
      "Starting Epoch 110\n",
      "1.509541083937106\n",
      "Validation loss: 1.4190760850906372\n",
      "mse 1.4190760608719575\n",
      "New best model found at epoch 110 with validation loss 1.4190760850906372\n",
      "Starting Epoch 111\n",
      "1.5089152403499768\n",
      "Validation loss: 1.4190363883972168\n",
      "mse 1.4190365616543146\n",
      "New best model found at epoch 111 with validation loss 1.4190363883972168\n",
      "Starting Epoch 112\n",
      "1.5081156388573025\n",
      "Validation loss: 1.418455719947815\n",
      "mse 1.418455701220312\n",
      "New best model found at epoch 112 with validation loss 1.418455719947815\n",
      "Starting Epoch 113\n",
      "1.5075418819551882\n",
      "Validation loss: 1.417663335800171\n",
      "mse 1.417663219748087\n",
      "New best model found at epoch 113 with validation loss 1.417663335800171\n",
      "Starting Epoch 114\n",
      "1.5067734873813132\n",
      "Validation loss: 1.4175745248794556\n",
      "mse 1.4175745357900809\n",
      "New best model found at epoch 114 with validation loss 1.4175745248794556\n",
      "Starting Epoch 115\n",
      "1.5061789828798045\n",
      "Validation loss: 1.416648030281067\n",
      "mse 1.4166480224238598\n",
      "New best model found at epoch 115 with validation loss 1.416648030281067\n",
      "Starting Epoch 116\n",
      "1.5054377732069597\n",
      "Validation loss: 1.416216492652893\n",
      "mse 1.4162165747097069\n",
      "New best model found at epoch 116 with validation loss 1.416216492652893\n",
      "Starting Epoch 117\n",
      "1.5047969273898913\n",
      "Validation loss: 1.4160889387130737\n",
      "mse 1.4160890506429242\n",
      "New best model found at epoch 117 with validation loss 1.4160889387130737\n",
      "Starting Epoch 118\n",
      "1.5041407554045967\n",
      "Validation loss: 1.4152497053146362\n",
      "mse 1.41524983685045\n",
      "New best model found at epoch 118 with validation loss 1.4152497053146362\n",
      "Starting Epoch 119\n",
      "1.5034930654194043\n",
      "Validation loss: 1.414911150932312\n",
      "mse 1.4149111708895497\n",
      "New best model found at epoch 119 with validation loss 1.414911150932312\n",
      "Starting Epoch 120\n",
      "1.5028634252755537\n",
      "Validation loss: 1.414621353149414\n",
      "mse 1.4146213482141345\n",
      "New best model found at epoch 120 with validation loss 1.414621353149414\n",
      "Starting Epoch 121\n",
      "1.5022136102552\n",
      "Validation loss: 1.41396164894104\n",
      "mse 1.4139617527066668\n",
      "New best model found at epoch 121 with validation loss 1.41396164894104\n",
      "Starting Epoch 122\n",
      "1.5015699474707893\n",
      "Validation loss: 1.413369059562683\n",
      "mse 1.4133689810741772\n",
      "New best model found at epoch 122 with validation loss 1.413369059562683\n",
      "Starting Epoch 123\n",
      "1.5009631177653437\n",
      "Validation loss: 1.4130103588104248\n",
      "mse 1.4130103437796209\n",
      "New best model found at epoch 123 with validation loss 1.4130103588104248\n",
      "Starting Epoch 124\n",
      "1.5003394018048826\n",
      "Validation loss: 1.4125709533691406\n",
      "mse 1.4125710025053375\n",
      "New best model found at epoch 124 with validation loss 1.4125709533691406\n",
      "Starting Epoch 125\n",
      "1.4997161730476047\n",
      "Validation loss: 1.4120543003082275\n",
      "mse 1.4120544845303158\n",
      "New best model found at epoch 125 with validation loss 1.4120543003082275\n",
      "Starting Epoch 126\n",
      "1.4991239179735598\n",
      "Validation loss: 1.4115549325942993\n",
      "mse 1.4115549000453216\n",
      "New best model found at epoch 126 with validation loss 1.4115549325942993\n",
      "Starting Epoch 127\n",
      "1.4984595049982485\n",
      "Validation loss: 1.4112257957458496\n",
      "mse 1.4112255769126794\n",
      "New best model found at epoch 127 with validation loss 1.4112257957458496\n",
      "Starting Epoch 128\n",
      "1.497875514237777\n",
      "Validation loss: 1.4106125831604004\n",
      "mse 1.4106126729069108\n",
      "New best model found at epoch 128 with validation loss 1.4106125831604004\n",
      "Starting Epoch 129\n",
      "1.4972843372303506\n",
      "Validation loss: 1.410273551940918\n",
      "mse 1.4102734384145668\n",
      "New best model found at epoch 129 with validation loss 1.410273551940918\n",
      "Starting Epoch 130\n",
      "1.49662474963976\n",
      "Validation loss: 1.4098432064056396\n",
      "mse 1.4098430515655114\n",
      "New best model found at epoch 130 with validation loss 1.4098432064056396\n",
      "Starting Epoch 131\n",
      "1.4960631961407869\n",
      "Validation loss: 1.4094643592834473\n",
      "mse 1.409464370583797\n",
      "New best model found at epoch 131 with validation loss 1.4094643592834473\n",
      "Starting Epoch 132\n",
      "1.4954808406207873\n",
      "Validation loss: 1.4093172550201416\n",
      "mse 1.4093172500800029\n",
      "New best model found at epoch 132 with validation loss 1.4093172550201416\n",
      "Starting Epoch 133\n",
      "1.4948373022286787\n",
      "Validation loss: 1.4083807468414307\n",
      "mse 1.4083808633325712\n",
      "New best model found at epoch 133 with validation loss 1.4083807468414307\n",
      "Starting Epoch 134\n",
      "1.4942566467368084\n",
      "Validation loss: 1.4080522060394287\n",
      "mse 1.408052126645708\n",
      "New best model found at epoch 134 with validation loss 1.4080522060394287\n",
      "Starting Epoch 135\n",
      "1.49365561682245\n",
      "Validation loss: 1.407436728477478\n",
      "mse 1.4074367177669416\n",
      "New best model found at epoch 135 with validation loss 1.407436728477478\n",
      "Starting Epoch 136\n",
      "1.4930580698925515\n",
      "Validation loss: 1.4066277742385864\n",
      "mse 1.4066277480901834\n",
      "New best model found at epoch 136 with validation loss 1.4066277742385864\n",
      "Starting Epoch 137\n",
      "1.492409304432247\n",
      "Validation loss: 1.4060839414596558\n",
      "mse 1.4060839077676246\n",
      "New best model found at epoch 137 with validation loss 1.4060839414596558\n",
      "Starting Epoch 138\n",
      "1.4919375129367993\n",
      "Validation loss: 1.4056683778762817\n",
      "mse 1.405668455861552\n",
      "New best model found at epoch 138 with validation loss 1.4056683778762817\n",
      "Starting Epoch 139\n",
      "1.4913558493489805\n",
      "Validation loss: 1.4051506519317627\n",
      "mse 1.4051505466899712\n",
      "New best model found at epoch 139 with validation loss 1.4051506519317627\n",
      "Starting Epoch 140\n",
      "1.490715555522753\n",
      "Validation loss: 1.4050226211547852\n",
      "mse 1.4050225938421619\n",
      "New best model found at epoch 140 with validation loss 1.4050226211547852\n",
      "Starting Epoch 141\n",
      "1.4901075596394746\n",
      "Validation loss: 1.4040650129318237\n",
      "mse 1.4040650181189736\n",
      "New best model found at epoch 141 with validation loss 1.4040650129318237\n",
      "Starting Epoch 142\n",
      "1.4896349570025569\n",
      "Validation loss: 1.4039260149002075\n",
      "mse 1.4039259897939598\n",
      "New best model found at epoch 142 with validation loss 1.4039260149002075\n",
      "Starting Epoch 143\n",
      "1.4890174166015957\n",
      "Validation loss: 1.4032598733901978\n",
      "mse 1.4032598890447892\n",
      "New best model found at epoch 143 with validation loss 1.4032598733901978\n",
      "Starting Epoch 144\n",
      "1.488433881946232\n",
      "Validation loss: 1.402686357498169\n",
      "mse 1.4026864374149262\n",
      "New best model found at epoch 144 with validation loss 1.402686357498169\n",
      "Starting Epoch 145\n",
      "1.4878812821015068\n",
      "Validation loss: 1.4024547338485718\n",
      "mse 1.4024548846490092\n",
      "New best model found at epoch 145 with validation loss 1.4024547338485718\n",
      "Starting Epoch 146\n",
      "1.4873163751933887\n",
      "Validation loss: 1.4018781185150146\n",
      "mse 1.4018779798774503\n",
      "New best model found at epoch 146 with validation loss 1.4018781185150146\n",
      "Starting Epoch 147\n",
      "1.4868015413698943\n",
      "Validation loss: 1.401466727256775\n",
      "mse 1.401466698636633\n",
      "New best model found at epoch 147 with validation loss 1.401466727256775\n",
      "Starting Epoch 148\n",
      "1.486226164776346\n",
      "Validation loss: 1.4007539749145508\n",
      "mse 1.4007538873830598\n",
      "New best model found at epoch 148 with validation loss 1.4007539749145508\n",
      "Starting Epoch 149\n",
      "1.4856291387392127\n",
      "Validation loss: 1.4002670049667358\n",
      "mse 1.4002670627985812\n",
      "New best model found at epoch 149 with validation loss 1.4002670049667358\n",
      "Starting Epoch 150\n",
      "1.4850698528082475\n",
      "Validation loss: 1.3998743295669556\n",
      "mse 1.3998745258759\n",
      "New best model found at epoch 150 with validation loss 1.3998743295669556\n",
      "Starting Epoch 151\n",
      "1.484504909619041\n",
      "Validation loss: 1.398975133895874\n",
      "mse 1.3989751079764268\n",
      "New best model found at epoch 151 with validation loss 1.398975133895874\n",
      "Starting Epoch 152\n",
      "1.4838983779368193\n",
      "Validation loss: 1.3987157344818115\n",
      "mse 1.3987157114001474\n",
      "New best model found at epoch 152 with validation loss 1.3987157344818115\n",
      "Starting Epoch 153\n",
      "1.4834227924761565\n",
      "Validation loss: 1.398042917251587\n",
      "mse 1.39804287662103\n",
      "New best model found at epoch 153 with validation loss 1.398042917251587\n",
      "Starting Epoch 154\n",
      "1.4828590724779211\n",
      "Validation loss: 1.3977582454681396\n",
      "mse 1.397758241639489\n",
      "New best model found at epoch 154 with validation loss 1.3977582454681396\n",
      "Starting Epoch 155\n",
      "1.4823251314785169\n",
      "Validation loss: 1.3968231678009033\n",
      "mse 1.3968232235259903\n",
      "New best model found at epoch 155 with validation loss 1.3968231678009033\n",
      "Starting Epoch 156\n",
      "1.4817745296851448\n",
      "Validation loss: 1.3966302871704102\n",
      "mse 1.3966302823482777\n",
      "New best model found at epoch 156 with validation loss 1.3966302871704102\n",
      "Starting Epoch 157\n",
      "1.481224617232447\n",
      "Validation loss: 1.3962091207504272\n",
      "mse 1.3962091474094247\n",
      "New best model found at epoch 157 with validation loss 1.3962091207504272\n",
      "Starting Epoch 158\n",
      "1.4806181555208953\n",
      "Validation loss: 1.3957103490829468\n",
      "mse 1.395710510252187\n",
      "New best model found at epoch 158 with validation loss 1.3957103490829468\n",
      "Starting Epoch 159\n",
      "1.4801657640415689\n",
      "Validation loss: 1.3952306509017944\n",
      "mse 1.3952306449335765\n",
      "New best model found at epoch 159 with validation loss 1.3952306509017944\n",
      "Starting Epoch 160\n",
      "1.47959375899771\n",
      "Validation loss: 1.3948084115982056\n",
      "mse 1.3948084630330257\n",
      "New best model found at epoch 160 with validation loss 1.3948084115982056\n",
      "Starting Epoch 161\n",
      "1.4790247860162153\n",
      "Validation loss: 1.3942838907241821\n",
      "mse 1.3942839153778264\n",
      "New best model found at epoch 161 with validation loss 1.3942838907241821\n",
      "Starting Epoch 162\n",
      "1.4785796896271084\n",
      "Validation loss: 1.3936703205108643\n",
      "mse 1.3936702888419288\n",
      "New best model found at epoch 162 with validation loss 1.3936703205108643\n",
      "Starting Epoch 163\n",
      "1.478063368279001\n",
      "Validation loss: 1.3932560682296753\n",
      "mse 1.3932560276912234\n",
      "New best model found at epoch 163 with validation loss 1.3932560682296753\n",
      "Starting Epoch 164\n",
      "1.4775043259496274\n",
      "Validation loss: 1.3929201364517212\n",
      "mse 1.3929200738305627\n",
      "New best model found at epoch 164 with validation loss 1.3929201364517212\n",
      "Starting Epoch 165\n",
      "1.4769711624021116\n",
      "Validation loss: 1.392273187637329\n",
      "mse 1.3922732313823047\n",
      "New best model found at epoch 165 with validation loss 1.392273187637329\n",
      "Starting Epoch 166\n",
      "1.476527706436489\n",
      "Validation loss: 1.3917793035507202\n",
      "mse 1.3917794683530211\n",
      "New best model found at epoch 166 with validation loss 1.3917793035507202\n",
      "Starting Epoch 167\n",
      "1.4760043569233106\n",
      "Validation loss: 1.3913589715957642\n",
      "mse 1.39135893908648\n",
      "New best model found at epoch 167 with validation loss 1.3913589715957642\n",
      "Starting Epoch 168\n",
      "1.4754555043966875\n",
      "Validation loss: 1.390801191329956\n",
      "mse 1.3908011706842722\n",
      "New best model found at epoch 168 with validation loss 1.390801191329956\n",
      "Starting Epoch 169\n",
      "1.4749257357224175\n",
      "Validation loss: 1.3904516696929932\n",
      "mse 1.39045173114673\n",
      "New best model found at epoch 169 with validation loss 1.3904516696929932\n",
      "Starting Epoch 170\n",
      "1.4745058987451636\n",
      "Validation loss: 1.3898677825927734\n",
      "mse 1.3898679149473054\n",
      "New best model found at epoch 170 with validation loss 1.3898677825927734\n",
      "Starting Epoch 171\n",
      "1.4740032968313799\n",
      "Validation loss: 1.3894191980361938\n",
      "mse 1.389419126861171\n",
      "New best model found at epoch 171 with validation loss 1.3894191980361938\n",
      "Starting Epoch 172\n",
      "1.473515121833138\n",
      "Validation loss: 1.389054775238037\n",
      "mse 1.389054763330782\n",
      "New best model found at epoch 172 with validation loss 1.389054775238037\n",
      "Starting Epoch 173\n",
      "1.4730111671530681\n",
      "Validation loss: 1.3884626626968384\n",
      "mse 1.3884626258294164\n",
      "New best model found at epoch 173 with validation loss 1.3884626626968384\n",
      "Starting Epoch 174\n",
      "1.4724596816560496\n",
      "Validation loss: 1.388061285018921\n",
      "mse 1.388061310873398\n",
      "New best model found at epoch 174 with validation loss 1.388061285018921\n",
      "Starting Epoch 175\n",
      "1.471929853377135\n",
      "Validation loss: 1.3875800371170044\n",
      "mse 1.3875800352898167\n",
      "New best model found at epoch 175 with validation loss 1.3875800371170044\n",
      "Starting Epoch 176\n",
      "1.471443640149158\n",
      "Validation loss: 1.387115478515625\n",
      "mse 1.387115497197841\n",
      "New best model found at epoch 176 with validation loss 1.387115478515625\n",
      "Starting Epoch 177\n",
      "1.4710167154021885\n",
      "Validation loss: 1.386674165725708\n",
      "mse 1.3866741752403482\n",
      "New best model found at epoch 177 with validation loss 1.386674165725708\n",
      "Starting Epoch 178\n",
      "1.4705414175987244\n",
      "Validation loss: 1.3861912488937378\n",
      "mse 1.3861911602952406\n",
      "New best model found at epoch 178 with validation loss 1.3861912488937378\n",
      "Starting Epoch 179\n",
      "1.470068361448205\n",
      "Validation loss: 1.3857448101043701\n",
      "mse 1.3857447506475717\n",
      "New best model found at epoch 179 with validation loss 1.3857448101043701\n",
      "Starting Epoch 180\n",
      "1.4695827053940815\n",
      "Validation loss: 1.3852537870407104\n",
      "mse 1.3852537307592152\n",
      "New best model found at epoch 180 with validation loss 1.3852537870407104\n",
      "Starting Epoch 181\n",
      "1.4690884014834529\n",
      "Validation loss: 1.384936809539795\n",
      "mse 1.3849368363793122\n",
      "New best model found at epoch 181 with validation loss 1.384936809539795\n",
      "Starting Epoch 182\n",
      "1.4685725984366045\n",
      "Validation loss: 1.3845657110214233\n",
      "mse 1.3845654898113182\n",
      "New best model found at epoch 182 with validation loss 1.3845657110214233\n",
      "Starting Epoch 183\n",
      "1.4681662010109944\n",
      "Validation loss: 1.3840389251708984\n",
      "mse 1.3840390423824913\n",
      "New best model found at epoch 183 with validation loss 1.3840389251708984\n",
      "Starting Epoch 184\n",
      "1.467734466428342\n",
      "Validation loss: 1.3836734294891357\n",
      "mse 1.3836734338662922\n",
      "New best model found at epoch 184 with validation loss 1.3836734294891357\n",
      "Starting Epoch 185\n",
      "1.467264499353326\n",
      "Validation loss: 1.383283019065857\n",
      "mse 1.3832829485078117\n",
      "New best model found at epoch 185 with validation loss 1.383283019065857\n",
      "Starting Epoch 186\n",
      "1.4668091639228489\n",
      "Validation loss: 1.3827085494995117\n",
      "mse 1.3827085778923207\n",
      "New best model found at epoch 186 with validation loss 1.3827085494995117\n",
      "Starting Epoch 187\n",
      "1.4664017972738848\n",
      "Validation loss: 1.382432222366333\n",
      "mse 1.38243219568938\n",
      "New best model found at epoch 187 with validation loss 1.382432222366333\n",
      "Starting Epoch 188\n",
      "1.4659303452657617\n",
      "Validation loss: 1.3819912672042847\n",
      "mse 1.381991424110193\n",
      "New best model found at epoch 188 with validation loss 1.3819912672042847\n",
      "Starting Epoch 189\n",
      "1.465496856233348\n",
      "Validation loss: 1.3814805746078491\n",
      "mse 1.3814806471128076\n",
      "New best model found at epoch 189 with validation loss 1.3814805746078491\n",
      "Starting Epoch 190\n",
      "1.4650709318078083\n",
      "Validation loss: 1.3810546398162842\n",
      "mse 1.381054639890652\n",
      "New best model found at epoch 190 with validation loss 1.3810546398162842\n",
      "Starting Epoch 191\n",
      "1.4646315937456877\n",
      "Validation loss: 1.3808033466339111\n",
      "mse 1.3808033479674868\n",
      "New best model found at epoch 191 with validation loss 1.3808033466339111\n",
      "Starting Epoch 192\n",
      "1.4641318632208782\n",
      "Validation loss: 1.38031804561615\n",
      "mse 1.3803180687322516\n",
      "New best model found at epoch 192 with validation loss 1.38031804561615\n",
      "Starting Epoch 193\n",
      "1.463729430799899\n",
      "Validation loss: 1.3799903392791748\n",
      "mse 1.3799904371216098\n",
      "New best model found at epoch 193 with validation loss 1.3799903392791748\n",
      "Starting Epoch 194\n",
      "1.4632895381554314\n",
      "Validation loss: 1.3795496225357056\n",
      "mse 1.3795496152446864\n",
      "New best model found at epoch 194 with validation loss 1.3795496225357056\n",
      "Starting Epoch 195\n",
      "1.4628365195315818\n",
      "Validation loss: 1.3792210817337036\n",
      "mse 1.3792210714617337\n",
      "New best model found at epoch 195 with validation loss 1.3792210817337036\n",
      "Starting Epoch 196\n",
      "1.4624059718588125\n",
      "Validation loss: 1.378892421722412\n",
      "mse 1.378892286867345\n",
      "New best model found at epoch 196 with validation loss 1.378892421722412\n",
      "Starting Epoch 197\n",
      "1.4619965916094573\n",
      "Validation loss: 1.3785557746887207\n",
      "mse 1.3785557801986952\n",
      "New best model found at epoch 197 with validation loss 1.3785557746887207\n",
      "Starting Epoch 198\n",
      "1.4616579024688057\n",
      "Validation loss: 1.3781230449676514\n",
      "mse 1.37812301643333\n",
      "New best model found at epoch 198 with validation loss 1.3781230449676514\n",
      "Starting Epoch 199\n",
      "1.4612519404162532\n",
      "Validation loss: 1.3777939081192017\n",
      "mse 1.3777938463284667\n",
      "New best model found at epoch 199 with validation loss 1.3777939081192017\n",
      "Starting Epoch 200\n",
      "1.4608265446579975\n",
      "Validation loss: 1.377433180809021\n",
      "mse 1.3774332234370825\n",
      "New best model found at epoch 200 with validation loss 1.377433180809021\n",
      "Starting Epoch 201\n",
      "1.4603931048642034\n",
      "Validation loss: 1.377077579498291\n",
      "mse 1.3770775694376407\n",
      "New best model found at epoch 201 with validation loss 1.377077579498291\n",
      "Starting Epoch 202\n",
      "1.4600342952686807\n",
      "Validation loss: 1.3766549825668335\n",
      "mse 1.3766550277177476\n",
      "New best model found at epoch 202 with validation loss 1.3766549825668335\n",
      "Starting Epoch 203\n",
      "1.4596029831015545\n",
      "Validation loss: 1.3763986825942993\n",
      "mse 1.376398712990797\n",
      "New best model found at epoch 203 with validation loss 1.3763986825942993\n",
      "Starting Epoch 204\n",
      "1.459151073642399\n",
      "Validation loss: 1.3758409023284912\n",
      "mse 1.3758409754664886\n",
      "New best model found at epoch 204 with validation loss 1.3758409023284912\n",
      "Starting Epoch 205\n",
      "1.4588205762531445\n",
      "Validation loss: 1.3755149841308594\n",
      "mse 1.375515050990159\n",
      "New best model found at epoch 205 with validation loss 1.3755149841308594\n",
      "Starting Epoch 206\n",
      "1.4584474330363066\n",
      "Validation loss: 1.3751951456069946\n",
      "mse 1.3751951590300173\n",
      "New best model found at epoch 206 with validation loss 1.3751951456069946\n",
      "Starting Epoch 207\n",
      "1.458038146081178\n",
      "Validation loss: 1.3748664855957031\n",
      "mse 1.3748665313527304\n",
      "New best model found at epoch 207 with validation loss 1.3748664855957031\n",
      "Starting Epoch 208\n",
      "1.457592451054117\n",
      "Validation loss: 1.3745144605636597\n",
      "mse 1.3745144538745928\n",
      "New best model found at epoch 208 with validation loss 1.3745144605636597\n",
      "Starting Epoch 209\n",
      "1.4572691787844119\n",
      "Validation loss: 1.3741599321365356\n",
      "mse 1.3741599277329906\n",
      "New best model found at epoch 209 with validation loss 1.3741599321365356\n",
      "Starting Epoch 210\n",
      "1.4568377940551094\n",
      "Validation loss: 1.3737837076187134\n",
      "mse 1.3737836800257561\n",
      "New best model found at epoch 210 with validation loss 1.3737837076187134\n",
      "Starting Epoch 211\n",
      "1.4565210523812666\n",
      "Validation loss: 1.3735146522521973\n",
      "mse 1.373514610967613\n",
      "New best model found at epoch 211 with validation loss 1.3735146522521973\n",
      "Starting Epoch 212\n",
      "1.4560625060744907\n",
      "Validation loss: 1.3732534646987915\n",
      "mse 1.3732535067561897\n",
      "New best model found at epoch 212 with validation loss 1.3732534646987915\n",
      "Starting Epoch 213\n",
      "1.4556724947431814\n",
      "Validation loss: 1.3729596138000488\n",
      "mse 1.3729596322949675\n",
      "New best model found at epoch 213 with validation loss 1.3729596138000488\n",
      "Starting Epoch 214\n",
      "1.4553311933641848\n",
      "Validation loss: 1.3724628686904907\n",
      "mse 1.372462897118862\n",
      "New best model found at epoch 214 with validation loss 1.3724628686904907\n",
      "Starting Epoch 215\n",
      "1.4549587939096533\n",
      "Validation loss: 1.3722319602966309\n",
      "mse 1.3722319095882538\n",
      "New best model found at epoch 215 with validation loss 1.3722319602966309\n",
      "Starting Epoch 216\n",
      "1.4546110681865527\n",
      "Validation loss: 1.3719172477722168\n",
      "mse 1.3719172529312964\n",
      "New best model found at epoch 216 with validation loss 1.3719172477722168\n",
      "Starting Epoch 217\n",
      "1.4542391792587612\n",
      "Validation loss: 1.3714848756790161\n",
      "mse 1.37148512236445\n",
      "New best model found at epoch 217 with validation loss 1.3714848756790161\n",
      "Starting Epoch 218\n",
      "1.453842668429665\n",
      "Validation loss: 1.3712763786315918\n",
      "mse 1.3712763752775332\n",
      "New best model found at epoch 218 with validation loss 1.3712763786315918\n",
      "Starting Epoch 219\n",
      "1.4534893709680308\n",
      "Validation loss: 1.3708516359329224\n",
      "mse 1.370851671323803\n",
      "New best model found at epoch 219 with validation loss 1.3708516359329224\n",
      "Starting Epoch 220\n",
      "1.4531739535539046\n",
      "Validation loss: 1.370488166809082\n",
      "mse 1.3704881157542614\n",
      "New best model found at epoch 220 with validation loss 1.370488166809082\n",
      "Starting Epoch 221\n",
      "1.4527495036954465\n",
      "Validation loss: 1.3701635599136353\n",
      "mse 1.3701636126408963\n",
      "New best model found at epoch 221 with validation loss 1.3701635599136353\n",
      "Starting Epoch 222\n",
      "1.4524068702822146\n",
      "Validation loss: 1.3699253797531128\n",
      "mse 1.369925553216182\n",
      "New best model found at epoch 222 with validation loss 1.3699253797531128\n",
      "Starting Epoch 223\n",
      "1.4520200879677483\n",
      "Validation loss: 1.3697514533996582\n",
      "mse 1.3697513594198645\n",
      "New best model found at epoch 223 with validation loss 1.3697514533996582\n",
      "Starting Epoch 224\n",
      "1.4516932808834573\n",
      "Validation loss: 1.369179606437683\n",
      "mse 1.3691796826364384\n",
      "New best model found at epoch 224 with validation loss 1.369179606437683\n",
      "Starting Epoch 225\n",
      "1.4513121273206628\n",
      "Validation loss: 1.3689780235290527\n",
      "mse 1.3689780154183884\n",
      "New best model found at epoch 225 with validation loss 1.3689780235290527\n",
      "Starting Epoch 226\n",
      "1.451005466606306\n",
      "Validation loss: 1.3687117099761963\n",
      "mse 1.368711615344718\n",
      "New best model found at epoch 226 with validation loss 1.3687117099761963\n",
      "Starting Epoch 227\n",
      "1.4505638998487722\n",
      "Validation loss: 1.36837637424469\n",
      "mse 1.3683765303209436\n",
      "New best model found at epoch 227 with validation loss 1.36837637424469\n",
      "Starting Epoch 228\n",
      "1.4502128077589946\n",
      "Validation loss: 1.3679426908493042\n",
      "mse 1.3679425331729638\n",
      "New best model found at epoch 228 with validation loss 1.3679426908493042\n",
      "Starting Epoch 229\n",
      "1.449924526007279\n",
      "Validation loss: 1.3676329851150513\n",
      "mse 1.3676330161946952\n",
      "New best model found at epoch 229 with validation loss 1.3676329851150513\n",
      "Starting Epoch 230\n",
      "1.4494681280592214\n",
      "Validation loss: 1.3671807050704956\n",
      "mse 1.3671806383739116\n",
      "New best model found at epoch 230 with validation loss 1.3671807050704956\n",
      "Starting Epoch 231\n",
      "1.4491360731746838\n",
      "Validation loss: 1.3669122457504272\n",
      "mse 1.3669122116580426\n",
      "New best model found at epoch 231 with validation loss 1.3669122457504272\n",
      "Starting Epoch 232\n",
      "1.4488913131796795\n",
      "Validation loss: 1.3666669130325317\n",
      "mse 1.366666921065208\n",
      "New best model found at epoch 232 with validation loss 1.3666669130325317\n",
      "Starting Epoch 233\n",
      "1.4484313052633535\n",
      "Validation loss: 1.3662824630737305\n",
      "mse 1.3662824653505306\n",
      "New best model found at epoch 233 with validation loss 1.3662824630737305\n",
      "Starting Epoch 234\n",
      "1.4481130112772402\n",
      "Validation loss: 1.3659883737564087\n",
      "mse 1.365988384400352\n",
      "New best model found at epoch 234 with validation loss 1.3659883737564087\n",
      "Starting Epoch 235\n",
      "1.4477468651273977\n",
      "Validation loss: 1.3656871318817139\n",
      "mse 1.365687086501311\n",
      "New best model found at epoch 235 with validation loss 1.3656871318817139\n",
      "Starting Epoch 236\n",
      "1.4474084688269573\n",
      "Validation loss: 1.365376353263855\n",
      "mse 1.365376390812115\n",
      "New best model found at epoch 236 with validation loss 1.365376353263855\n",
      "Starting Epoch 237\n",
      "1.4470382462377134\n",
      "Validation loss: 1.3650749921798706\n",
      "mse 1.3650749485513305\n",
      "New best model found at epoch 237 with validation loss 1.3650749921798706\n",
      "Starting Epoch 238\n",
      "1.4467238421025483\n",
      "Validation loss: 1.3645482063293457\n",
      "mse 1.3645482736620484\n",
      "New best model found at epoch 238 with validation loss 1.3645482063293457\n",
      "Starting Epoch 239\n",
      "1.4463614354962888\n",
      "Validation loss: 1.3642922639846802\n",
      "mse 1.3642922353307534\n",
      "New best model found at epoch 239 with validation loss 1.3642922639846802\n",
      "Starting Epoch 240\n",
      "1.4460061658983645\n",
      "Validation loss: 1.3639991283416748\n",
      "mse 1.3639990493861294\n",
      "New best model found at epoch 240 with validation loss 1.3639991283416748\n",
      "Starting Epoch 241\n",
      "1.4457002515378206\n",
      "Validation loss: 1.3636265993118286\n",
      "mse 1.3636265654497086\n",
      "New best model found at epoch 241 with validation loss 1.3636265993118286\n",
      "Starting Epoch 242\n",
      "1.4453526191089465\n",
      "Validation loss: 1.3633242845535278\n",
      "mse 1.3633242243270232\n",
      "New best model found at epoch 242 with validation loss 1.3633242845535278\n",
      "Starting Epoch 243\n",
      "1.445022650386976\n",
      "Validation loss: 1.3630284070968628\n",
      "mse 1.3630285053793723\n",
      "New best model found at epoch 243 with validation loss 1.3630284070968628\n",
      "Starting Epoch 244\n",
      "1.4446575045585632\n",
      "Validation loss: 1.3627073764801025\n",
      "mse 1.362707515800032\n",
      "New best model found at epoch 244 with validation loss 1.3627073764801025\n",
      "Starting Epoch 245\n",
      "1.4443636536598206\n",
      "Validation loss: 1.3623814582824707\n",
      "mse 1.3623815874941216\n",
      "New best model found at epoch 245 with validation loss 1.3623814582824707\n",
      "Starting Epoch 246\n",
      "1.4439900154652803\n",
      "Validation loss: 1.3619502782821655\n",
      "mse 1.3619503156452155\n",
      "New best model found at epoch 246 with validation loss 1.3619502782821655\n",
      "Starting Epoch 247\n",
      "1.4436952601308408\n",
      "Validation loss: 1.3616880178451538\n",
      "mse 1.3616882071021472\n",
      "New best model found at epoch 247 with validation loss 1.3616880178451538\n",
      "Starting Epoch 248\n",
      "1.4433311146238577\n",
      "Validation loss: 1.3613988161087036\n",
      "mse 1.3613988930052154\n",
      "New best model found at epoch 248 with validation loss 1.3613988161087036\n",
      "Starting Epoch 249\n",
      "1.443058086478192\n",
      "Validation loss: 1.3609609603881836\n",
      "mse 1.3609609606675508\n",
      "New best model found at epoch 249 with validation loss 1.3609609603881836\n",
      "Starting Epoch 250\n",
      "1.442754089832306\n",
      "Validation loss: 1.3608657121658325\n",
      "mse 1.3608656767986178\n",
      "New best model found at epoch 250 with validation loss 1.3608657121658325\n",
      "Starting Epoch 251\n",
      "1.442455716755079\n",
      "Validation loss: 1.3604885339736938\n",
      "mse 1.3604885331986032\n",
      "New best model found at epoch 251 with validation loss 1.3604885339736938\n",
      "Starting Epoch 252\n",
      "1.4420489565185879\n",
      "Validation loss: 1.3603159189224243\n",
      "mse 1.3603158171003473\n",
      "New best model found at epoch 252 with validation loss 1.3603159189224243\n",
      "Starting Epoch 253\n",
      "1.4417427234027698\n",
      "Validation loss: 1.359874963760376\n",
      "mse 1.3598749259191396\n",
      "New best model found at epoch 253 with validation loss 1.359874963760376\n",
      "Starting Epoch 254\n",
      "1.4414455372354258\n",
      "Validation loss: 1.3595495223999023\n",
      "mse 1.3595495783378306\n",
      "New best model found at epoch 254 with validation loss 1.3595495223999023\n",
      "Starting Epoch 255\n",
      "1.4411940678306248\n",
      "Validation loss: 1.3593469858169556\n",
      "mse 1.3593470465132729\n",
      "New best model found at epoch 255 with validation loss 1.3593469858169556\n",
      "Starting Epoch 256\n",
      "1.440761993760648\n",
      "Validation loss: 1.3591032028198242\n",
      "mse 1.3591031765851422\n",
      "New best model found at epoch 256 with validation loss 1.3591032028198242\n",
      "Starting Epoch 257\n",
      "1.440432193486587\n",
      "Validation loss: 1.3588842153549194\n",
      "mse 1.3588843858790773\n",
      "New best model found at epoch 257 with validation loss 1.3588842153549194\n",
      "Starting Epoch 258\n",
      "1.4400691079056782\n",
      "Validation loss: 1.3584535121917725\n",
      "mse 1.3584534363088856\n",
      "New best model found at epoch 258 with validation loss 1.3584535121917725\n",
      "Starting Epoch 259\n",
      "1.4398392568463865\n",
      "Validation loss: 1.3582223653793335\n",
      "mse 1.358222296397476\n",
      "New best model found at epoch 259 with validation loss 1.3582223653793335\n",
      "Starting Epoch 260\n",
      "1.439533972221872\n",
      "Validation loss: 1.357822060585022\n",
      "mse 1.357822050019766\n",
      "New best model found at epoch 260 with validation loss 1.357822060585022\n",
      "Starting Epoch 261\n",
      "1.4391359738681628\n",
      "Validation loss: 1.3577519655227661\n",
      "mse 1.3577521516324267\n",
      "New best model found at epoch 261 with validation loss 1.3577519655227661\n",
      "Starting Epoch 262\n",
      "1.4387958360754924\n",
      "Validation loss: 1.357282042503357\n",
      "mse 1.3572821869472862\n",
      "New best model found at epoch 262 with validation loss 1.357282042503357\n",
      "Starting Epoch 263\n",
      "1.4384623921435813\n",
      "Validation loss: 1.3567496538162231\n",
      "mse 1.3567497051826072\n",
      "New best model found at epoch 263 with validation loss 1.3567496538162231\n",
      "Starting Epoch 264\n",
      "1.438147933586784\n",
      "Validation loss: 1.3568644523620605\n",
      "mse 1.3568644376621186\n",
      "Starting Epoch 265\n",
      "1.4377105210138403\n",
      "Validation loss: 1.3566263914108276\n",
      "mse 1.3566263594455026\n",
      "New best model found at epoch 265 with validation loss 1.3566263914108276\n",
      "Starting Epoch 266\n",
      "1.4373819879863574\n",
      "Validation loss: 1.3562945127487183\n",
      "mse 1.3562945348147317\n",
      "New best model found at epoch 266 with validation loss 1.3562945127487183\n",
      "Starting Epoch 267\n",
      "1.4370257621226104\n",
      "Validation loss: 1.3558145761489868\n",
      "mse 1.355814613320333\n",
      "New best model found at epoch 267 with validation loss 1.3558145761489868\n",
      "Starting Epoch 268\n",
      "1.4367338185725005\n",
      "Validation loss: 1.3554922342300415\n",
      "mse 1.3554921661581278\n",
      "New best model found at epoch 268 with validation loss 1.3554922342300415\n",
      "Starting Epoch 269\n",
      "1.4363892026569531\n",
      "Validation loss: 1.354993224143982\n",
      "mse 1.3549931776262467\n",
      "New best model found at epoch 269 with validation loss 1.354993224143982\n",
      "Starting Epoch 270\n",
      "1.4360550279202668\n",
      "Validation loss: 1.3549580574035645\n",
      "mse 1.3549581125131869\n",
      "New best model found at epoch 270 with validation loss 1.3549580574035645\n",
      "Starting Epoch 271\n",
      "1.4356555679570073\n",
      "Validation loss: 1.3544894456863403\n",
      "mse 1.3544892826088963\n",
      "New best model found at epoch 271 with validation loss 1.3544894456863403\n",
      "Starting Epoch 272\n",
      "1.4353310413982556\n",
      "Validation loss: 1.3546029329299927\n",
      "mse 1.3546029942985782\n",
      "Starting Epoch 273\n",
      "1.434907799181731\n",
      "Validation loss: 1.353864073753357\n",
      "mse 1.3538640543681435\n",
      "New best model found at epoch 273 with validation loss 1.353864073753357\n",
      "Starting Epoch 274\n",
      "1.4346521367197451\n",
      "Validation loss: 1.353991150856018\n",
      "mse 1.3539912374705534\n",
      "Starting Epoch 275\n",
      "1.4342177588006724\n",
      "Validation loss: 1.3534756898880005\n",
      "mse 1.353475592446043\n",
      "New best model found at epoch 275 with validation loss 1.3534756898880005\n",
      "Starting Epoch 276\n",
      "1.4339262298915698\n",
      "Validation loss: 1.3529996871948242\n",
      "mse 1.3529997187933815\n",
      "New best model found at epoch 276 with validation loss 1.3529996871948242\n",
      "Starting Epoch 277\n",
      "1.4336120615834775\n",
      "Validation loss: 1.3528671264648438\n",
      "mse 1.3528670381670735\n",
      "New best model found at epoch 277 with validation loss 1.3528671264648438\n",
      "Starting Epoch 278\n",
      "1.4332527414612148\n",
      "Validation loss: 1.352581262588501\n",
      "mse 1.3525812927914467\n",
      "New best model found at epoch 278 with validation loss 1.352581262588501\n",
      "Starting Epoch 279\n",
      "1.4329027429870937\n",
      "Validation loss: 1.3520870208740234\n",
      "mse 1.3520871181130654\n",
      "New best model found at epoch 279 with validation loss 1.3520870208740234\n",
      "Starting Epoch 280\n",
      "1.4325893910034844\n",
      "Validation loss: 1.3519229888916016\n",
      "mse 1.351922896291741\n",
      "New best model found at epoch 280 with validation loss 1.3519229888916016\n",
      "Starting Epoch 281\n",
      "1.4322163980940115\n",
      "Validation loss: 1.3514100313186646\n",
      "mse 1.3514100796210524\n",
      "New best model found at epoch 281 with validation loss 1.3514100313186646\n",
      "Starting Epoch 282\n",
      "1.4318912728973057\n",
      "Validation loss: 1.3512829542160034\n",
      "mse 1.351282986828692\n",
      "New best model found at epoch 282 with validation loss 1.3512829542160034\n",
      "Starting Epoch 283\n",
      "1.4315152945725813\n",
      "Validation loss: 1.3507431745529175\n",
      "mse 1.3507433122491008\n",
      "New best model found at epoch 283 with validation loss 1.3507431745529175\n",
      "Starting Epoch 284\n",
      "1.431193216987278\n",
      "Validation loss: 1.3505637645721436\n",
      "mse 1.3505637232610521\n",
      "New best model found at epoch 284 with validation loss 1.3505637645721436\n",
      "Starting Epoch 285\n",
      "1.4308331064555957\n",
      "Validation loss: 1.3500643968582153\n",
      "mse 1.3500643205119267\n",
      "New best model found at epoch 285 with validation loss 1.3500643968582153\n",
      "Starting Epoch 286\n",
      "1.4305129310359126\n",
      "Validation loss: 1.349896788597107\n",
      "mse 1.3498967587067878\n",
      "New best model found at epoch 286 with validation loss 1.349896788597107\n",
      "Starting Epoch 287\n",
      "1.4301757682924685\n",
      "Validation loss: 1.3496655225753784\n",
      "mse 1.3496654410988524\n",
      "New best model found at epoch 287 with validation loss 1.3496655225753784\n",
      "Starting Epoch 288\n",
      "1.4298548517019853\n",
      "Validation loss: 1.3493074178695679\n",
      "mse 1.3493074502115865\n",
      "New best model found at epoch 288 with validation loss 1.3493074178695679\n",
      "Starting Epoch 289\n",
      "1.4295245486757029\n",
      "Validation loss: 1.348996877670288\n",
      "mse 1.348996894335532\n",
      "New best model found at epoch 289 with validation loss 1.348996877670288\n",
      "Starting Epoch 290\n",
      "1.4291842994482622\n",
      "Validation loss: 1.348671555519104\n",
      "mse 1.348671481923746\n",
      "New best model found at epoch 290 with validation loss 1.348671555519104\n",
      "Starting Epoch 291\n",
      "1.42885480756345\n",
      "Validation loss: 1.3483271598815918\n",
      "mse 1.3483273093011328\n",
      "New best model found at epoch 291 with validation loss 1.3483271598815918\n",
      "Starting Epoch 292\n",
      "1.4285476155903027\n",
      "Validation loss: 1.3477764129638672\n",
      "mse 1.347776368587055\n",
      "New best model found at epoch 292 with validation loss 1.3477764129638672\n",
      "Starting Epoch 293\n",
      "1.4282104217487832\n",
      "Validation loss: 1.347564697265625\n",
      "mse 1.3475646252778986\n",
      "New best model found at epoch 293 with validation loss 1.347564697265625\n",
      "Starting Epoch 294\n",
      "1.427835358225781\n",
      "Validation loss: 1.3472065925598145\n",
      "mse 1.3472066756662335\n",
      "New best model found at epoch 294 with validation loss 1.3472065925598145\n",
      "Starting Epoch 295\n",
      "1.4275384648986484\n",
      "Validation loss: 1.3466211557388306\n",
      "mse 1.3466210558354657\n",
      "New best model found at epoch 295 with validation loss 1.3466211557388306\n",
      "Starting Epoch 296\n",
      "1.4272065266318943\n",
      "Validation loss: 1.346421718597412\n",
      "mse 1.3464217228062723\n",
      "New best model found at epoch 296 with validation loss 1.346421718597412\n",
      "Starting Epoch 297\n",
      "1.4268393749776094\n",
      "Validation loss: 1.3460742235183716\n",
      "mse 1.3460742570613993\n",
      "New best model found at epoch 297 with validation loss 1.3460742235183716\n",
      "Starting Epoch 298\n",
      "1.426519671212072\n",
      "Validation loss: 1.3457324504852295\n",
      "mse 1.345732524399772\n",
      "New best model found at epoch 298 with validation loss 1.3457324504852295\n",
      "Starting Epoch 299\n",
      "1.4262279323909595\n",
      "Validation loss: 1.3453794717788696\n",
      "mse 1.3453795509757183\n",
      "New best model found at epoch 299 with validation loss 1.3453794717788696\n",
      "Starting Epoch 300\n",
      "1.4259455229925073\n",
      "Validation loss: 1.345054268836975\n",
      "mse 1.3450542725019061\n",
      "New best model found at epoch 300 with validation loss 1.345054268836975\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-20-10-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ece4c4",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 3\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 20 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "80d3e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "218b5f3b-d9b6-4add-a26c-8a439e7e3d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.1636130861614062\n",
      "Validation loss: 2.6909067630767822\n",
      "mse 2.6909069978987827\n",
      "New best model found at epoch 1 with validation loss 2.6909067630767822\n",
      "Starting Epoch 2\n",
      "2.924771682075832\n",
      "Validation loss: 2.5614593029022217\n",
      "mse 2.5614594557308865\n",
      "New best model found at epoch 2 with validation loss 2.5614593029022217\n",
      "Starting Epoch 3\n",
      "2.7572209109430728\n",
      "Validation loss: 2.430907726287842\n",
      "mse 2.430907714436105\n",
      "New best model found at epoch 3 with validation loss 2.430907726287842\n",
      "Starting Epoch 4\n",
      "2.6015085707540098\n",
      "Validation loss: 2.289452075958252\n",
      "mse 2.2894523723586473\n",
      "New best model found at epoch 4 with validation loss 2.289452075958252\n",
      "Starting Epoch 5\n",
      "2.4485703136609946\n",
      "Validation loss: 2.1556553840637207\n",
      "mse 2.1556555200706438\n",
      "New best model found at epoch 5 with validation loss 2.1556553840637207\n",
      "Starting Epoch 6\n",
      "2.308837273846502\n",
      "Validation loss: 2.0198328495025635\n",
      "mse 2.019832879432644\n",
      "New best model found at epoch 6 with validation loss 2.0198328495025635\n",
      "Starting Epoch 7\n",
      "2.1841801042142124\n",
      "Validation loss: 1.9049298763275146\n",
      "mse 1.9049297717394083\n",
      "New best model found at epoch 7 with validation loss 1.9049298763275146\n",
      "Starting Epoch 8\n",
      "2.079372395639834\n",
      "Validation loss: 1.8151618242263794\n",
      "mse 1.8151617636947444\n",
      "New best model found at epoch 8 with validation loss 1.8151618242263794\n",
      "Starting Epoch 9\n",
      "1.9937116788781208\n",
      "Validation loss: 1.7452614307403564\n",
      "mse 1.745261486236103\n",
      "New best model found at epoch 9 with validation loss 1.7452614307403564\n",
      "Starting Epoch 10\n",
      "1.923738552176434\n",
      "Validation loss: 1.6864029169082642\n",
      "mse 1.6864029234621043\n",
      "New best model found at epoch 10 with validation loss 1.6864029169082642\n",
      "Starting Epoch 11\n",
      "1.8664056788320127\n",
      "Validation loss: 1.639280080795288\n",
      "mse 1.6392800758300246\n",
      "New best model found at epoch 11 with validation loss 1.639280080795288\n",
      "Starting Epoch 12\n",
      "1.8174952268600464\n",
      "Validation loss: 1.6016160249710083\n",
      "mse 1.601615951709401\n",
      "New best model found at epoch 12 with validation loss 1.6016160249710083\n",
      "Starting Epoch 13\n",
      "1.7785906999007515\n",
      "Validation loss: 1.5735059976577759\n",
      "mse 1.5735058952160483\n",
      "New best model found at epoch 13 with validation loss 1.5735059976577759\n",
      "Starting Epoch 14\n",
      "1.7466621709906536\n",
      "Validation loss: 1.5521438121795654\n",
      "mse 1.5521436846722994\n",
      "New best model found at epoch 14 with validation loss 1.5521438121795654\n",
      "Starting Epoch 15\n",
      "1.7213780413503232\n",
      "Validation loss: 1.5316299200057983\n",
      "mse 1.531629865151053\n",
      "New best model found at epoch 15 with validation loss 1.5316299200057983\n",
      "Starting Epoch 16\n",
      "1.7012186983357305\n",
      "Validation loss: 1.518541693687439\n",
      "mse 1.5185416823971905\n",
      "New best model found at epoch 16 with validation loss 1.518541693687439\n",
      "Starting Epoch 17\n",
      "1.6824437483497288\n",
      "Validation loss: 1.5064619779586792\n",
      "mse 1.506461931310386\n",
      "New best model found at epoch 17 with validation loss 1.5064619779586792\n",
      "Starting Epoch 18\n",
      "1.6664146184921265\n",
      "Validation loss: 1.4956567287445068\n",
      "mse 1.4956566304412704\n",
      "New best model found at epoch 18 with validation loss 1.4956567287445068\n",
      "Starting Epoch 19\n",
      "1.6531773650127908\n",
      "Validation loss: 1.4866724014282227\n",
      "mse 1.4866723337801853\n",
      "New best model found at epoch 19 with validation loss 1.4866724014282227\n",
      "Starting Epoch 20\n",
      "1.6415756059729534\n",
      "Validation loss: 1.4794127941131592\n",
      "mse 1.479412832882142\n",
      "New best model found at epoch 20 with validation loss 1.4794127941131592\n",
      "Starting Epoch 21\n",
      "1.6322442137676736\n",
      "Validation loss: 1.4725265502929688\n",
      "mse 1.4725266118886575\n",
      "New best model found at epoch 21 with validation loss 1.4725265502929688\n",
      "Starting Epoch 22\n",
      "1.623920834582785\n",
      "Validation loss: 1.4669804573059082\n",
      "mse 1.4669804476820492\n",
      "New best model found at epoch 22 with validation loss 1.4669804573059082\n",
      "Starting Epoch 23\n",
      "1.6163203301637068\n",
      "Validation loss: 1.4625470638275146\n",
      "mse 1.4625469861418958\n",
      "New best model found at epoch 23 with validation loss 1.4625470638275146\n",
      "Starting Epoch 24\n",
      "1.6101597858511882\n",
      "Validation loss: 1.4590957164764404\n",
      "mse 1.4590956751206323\n",
      "New best model found at epoch 24 with validation loss 1.4590957164764404\n",
      "Starting Epoch 25\n",
      "1.6035222981287085\n",
      "Validation loss: 1.4553724527359009\n",
      "mse 1.4553724852453669\n",
      "New best model found at epoch 25 with validation loss 1.4553724527359009\n",
      "Starting Epoch 26\n",
      "1.597663094168124\n",
      "Validation loss: 1.4511620998382568\n",
      "mse 1.4511620661515787\n",
      "New best model found at epoch 26 with validation loss 1.4511620998382568\n",
      "Starting Epoch 27\n",
      "1.5924394104791724\n",
      "Validation loss: 1.4486055374145508\n",
      "mse 1.4486055624869048\n",
      "New best model found at epoch 27 with validation loss 1.4486055374145508\n",
      "Starting Epoch 28\n",
      "1.5873597938081492\n",
      "Validation loss: 1.4456102848052979\n",
      "mse 1.4456102455884425\n",
      "New best model found at epoch 28 with validation loss 1.4456102848052979\n",
      "Starting Epoch 29\n",
      "1.5827965710474097\n",
      "Validation loss: 1.4427622556686401\n",
      "mse 1.442762138301062\n",
      "New best model found at epoch 29 with validation loss 1.4427622556686401\n",
      "Starting Epoch 30\n",
      "1.5785795657531074\n",
      "Validation loss: 1.4404035806655884\n",
      "mse 1.4404036853736575\n",
      "New best model found at epoch 30 with validation loss 1.4404035806655884\n",
      "Starting Epoch 31\n",
      "1.5745103048241658\n",
      "Validation loss: 1.4384100437164307\n",
      "mse 1.43841019391681\n",
      "New best model found at epoch 31 with validation loss 1.4384100437164307\n",
      "Starting Epoch 32\n",
      "1.5706312993298406\n",
      "Validation loss: 1.4361602067947388\n",
      "mse 1.4361602204786053\n",
      "New best model found at epoch 32 with validation loss 1.4361602067947388\n",
      "Starting Epoch 33\n",
      "1.5669508394987688\n",
      "Validation loss: 1.433607578277588\n",
      "mse 1.433607631869223\n",
      "New best model found at epoch 33 with validation loss 1.433607578277588\n",
      "Starting Epoch 34\n",
      "1.563309996024422\n",
      "Validation loss: 1.4315440654754639\n",
      "mse 1.4315440838266569\n",
      "New best model found at epoch 34 with validation loss 1.4315440654754639\n",
      "Starting Epoch 35\n",
      "1.5598489486652871\n",
      "Validation loss: 1.429535150527954\n",
      "mse 1.429535218987384\n",
      "New best model found at epoch 35 with validation loss 1.429535150527954\n",
      "Starting Epoch 36\n",
      "1.5562848163687664\n",
      "Validation loss: 1.4276565313339233\n",
      "mse 1.4276564967285725\n",
      "New best model found at epoch 36 with validation loss 1.4276565313339233\n",
      "Starting Epoch 37\n",
      "1.552954761878304\n",
      "Validation loss: 1.4258061647415161\n",
      "mse 1.4258061657536847\n",
      "New best model found at epoch 37 with validation loss 1.4258061647415161\n",
      "Starting Epoch 38\n",
      "1.5500119950460352\n",
      "Validation loss: 1.4242075681686401\n",
      "mse 1.4242076276729052\n",
      "New best model found at epoch 38 with validation loss 1.4242075681686401\n",
      "Starting Epoch 39\n",
      "1.5469575420669888\n",
      "Validation loss: 1.4225801229476929\n",
      "mse 1.422580026970446\n",
      "New best model found at epoch 39 with validation loss 1.4225801229476929\n",
      "Starting Epoch 40\n",
      "1.543994076873945\n",
      "Validation loss: 1.421209454536438\n",
      "mse 1.4212095109642566\n",
      "New best model found at epoch 40 with validation loss 1.421209454536438\n",
      "Starting Epoch 41\n",
      "1.5409168730611387\n",
      "Validation loss: 1.419301152229309\n",
      "mse 1.4193012285936344\n",
      "New best model found at epoch 41 with validation loss 1.419301152229309\n",
      "Starting Epoch 42\n",
      "1.5378386456033457\n",
      "Validation loss: 1.4178073406219482\n",
      "mse 1.4178073442255736\n",
      "New best model found at epoch 42 with validation loss 1.4178073406219482\n",
      "Starting Epoch 43\n",
      "1.534727368665778\n",
      "Validation loss: 1.4161009788513184\n",
      "mse 1.4161009873568433\n",
      "New best model found at epoch 43 with validation loss 1.4161009788513184\n",
      "Starting Epoch 44\n",
      "1.5319613840269006\n",
      "Validation loss: 1.4143974781036377\n",
      "mse 1.4143973476381762\n",
      "New best model found at epoch 44 with validation loss 1.4143974781036377\n",
      "Starting Epoch 45\n",
      "1.5289989683939063\n",
      "Validation loss: 1.4125258922576904\n",
      "mse 1.4125259896337294\n",
      "New best model found at epoch 45 with validation loss 1.4125258922576904\n",
      "Starting Epoch 46\n",
      "1.5262405276298523\n",
      "Validation loss: 1.4121367931365967\n",
      "mse 1.4121367304860362\n",
      "New best model found at epoch 46 with validation loss 1.4121367931365967\n",
      "Starting Epoch 47\n",
      "1.5237516268439915\n",
      "Validation loss: 1.4108227491378784\n",
      "mse 1.4108227430130889\n",
      "New best model found at epoch 47 with validation loss 1.4108227491378784\n",
      "Starting Epoch 48\n",
      "1.5212282408838687\n",
      "Validation loss: 1.4090750217437744\n",
      "mse 1.4090750336722522\n",
      "New best model found at epoch 48 with validation loss 1.4090750217437744\n",
      "Starting Epoch 49\n",
      "1.5189110973606939\n",
      "Validation loss: 1.4075781106948853\n",
      "mse 1.4075782725299983\n",
      "New best model found at epoch 49 with validation loss 1.4075781106948853\n",
      "Starting Epoch 50\n",
      "1.5164351385572683\n",
      "Validation loss: 1.4062939882278442\n",
      "mse 1.4062939663430822\n",
      "New best model found at epoch 50 with validation loss 1.4062939882278442\n",
      "Starting Epoch 51\n",
      "1.5141877842986065\n",
      "Validation loss: 1.4049092531204224\n",
      "mse 1.4049092594567054\n",
      "New best model found at epoch 51 with validation loss 1.4049092531204224\n",
      "Starting Epoch 52\n",
      "1.5120767562285713\n",
      "Validation loss: 1.4035074710845947\n",
      "mse 1.4035075841469191\n",
      "New best model found at epoch 52 with validation loss 1.4035074710845947\n",
      "Starting Epoch 53\n",
      "1.510083247785983\n",
      "Validation loss: 1.4022361040115356\n",
      "mse 1.4022360011095165\n",
      "New best model found at epoch 53 with validation loss 1.4022361040115356\n",
      "Starting Epoch 54\n",
      "1.5078671289526897\n",
      "Validation loss: 1.4014382362365723\n",
      "mse 1.4014382364535651\n",
      "New best model found at epoch 54 with validation loss 1.4014382362365723\n",
      "Starting Epoch 55\n",
      "1.5062082746754522\n",
      "Validation loss: 1.3996384143829346\n",
      "mse 1.3996382976447121\n",
      "New best model found at epoch 55 with validation loss 1.3996384143829346\n",
      "Starting Epoch 56\n",
      "1.5042367162911787\n",
      "Validation loss: 1.3987704515457153\n",
      "mse 1.3987703938854859\n",
      "New best model found at epoch 56 with validation loss 1.3987704515457153\n",
      "Starting Epoch 57\n",
      "1.5022919048433718\n",
      "Validation loss: 1.397907018661499\n",
      "mse 1.3979070356169638\n",
      "New best model found at epoch 57 with validation loss 1.397907018661499\n",
      "Starting Epoch 58\n",
      "1.5005363303682078\n",
      "Validation loss: 1.3966929912567139\n",
      "mse 1.3966929894123399\n",
      "New best model found at epoch 58 with validation loss 1.3966929912567139\n",
      "Starting Epoch 59\n",
      "1.498898296252541\n",
      "Validation loss: 1.39558744430542\n",
      "mse 1.3955874123942018\n",
      "New best model found at epoch 59 with validation loss 1.39558744430542\n",
      "Starting Epoch 60\n",
      "1.4969993259595789\n",
      "Validation loss: 1.3944751024246216\n",
      "mse 1.3944750964920474\n",
      "New best model found at epoch 60 with validation loss 1.3944751024246216\n",
      "Starting Epoch 61\n",
      "1.4954852228579314\n",
      "Validation loss: 1.3940144777297974\n",
      "mse 1.3940144392452907\n",
      "New best model found at epoch 61 with validation loss 1.3940144777297974\n",
      "Starting Epoch 62\n",
      "1.4938218904578167\n",
      "Validation loss: 1.3932684659957886\n",
      "mse 1.3932685811873224\n",
      "New best model found at epoch 62 with validation loss 1.3932684659957886\n",
      "Starting Epoch 63\n",
      "1.4921780358190122\n",
      "Validation loss: 1.3921583890914917\n",
      "mse 1.3921582400790076\n",
      "New best model found at epoch 63 with validation loss 1.3921583890914917\n",
      "Starting Epoch 64\n",
      "1.4905662795771724\n",
      "Validation loss: 1.3912484645843506\n",
      "mse 1.391248411494441\n",
      "New best model found at epoch 64 with validation loss 1.3912484645843506\n",
      "Starting Epoch 65\n",
      "1.4891363563744917\n",
      "Validation loss: 1.3896774053573608\n",
      "mse 1.3896773839602863\n",
      "New best model found at epoch 65 with validation loss 1.3896774053573608\n",
      "Starting Epoch 66\n",
      "1.487571065840514\n",
      "Validation loss: 1.389224648475647\n",
      "mse 1.3892245497464104\n",
      "New best model found at epoch 66 with validation loss 1.389224648475647\n",
      "Starting Epoch 67\n",
      "1.4860248798909395\n",
      "Validation loss: 1.3880149126052856\n",
      "mse 1.388014789485576\n",
      "New best model found at epoch 67 with validation loss 1.3880149126052856\n",
      "Starting Epoch 68\n",
      "1.4845378217489824\n",
      "Validation loss: 1.3866314888000488\n",
      "mse 1.3866315102754014\n",
      "New best model found at epoch 68 with validation loss 1.3866314888000488\n",
      "Starting Epoch 69\n",
      "1.483112044956373\n",
      "Validation loss: 1.3857316970825195\n",
      "mse 1.3857317852537088\n",
      "New best model found at epoch 69 with validation loss 1.3857316970825195\n",
      "Starting Epoch 70\n",
      "1.4817466139793396\n",
      "Validation loss: 1.3845821619033813\n",
      "mse 1.384582308474069\n",
      "New best model found at epoch 70 with validation loss 1.3845821619033813\n",
      "Starting Epoch 71\n",
      "1.480198393697324\n",
      "Validation loss: 1.3838508129119873\n",
      "mse 1.3838508531932883\n",
      "New best model found at epoch 71 with validation loss 1.3838508129119873\n",
      "Starting Epoch 72\n",
      "1.478901787944462\n",
      "Validation loss: 1.3828554153442383\n",
      "mse 1.3828554100917227\n",
      "New best model found at epoch 72 with validation loss 1.3828554153442383\n",
      "Starting Epoch 73\n",
      "1.4774423785831616\n",
      "Validation loss: 1.3819531202316284\n",
      "mse 1.3819531309998452\n",
      "New best model found at epoch 73 with validation loss 1.3819531202316284\n",
      "Starting Epoch 74\n",
      "1.476180356481801\n",
      "Validation loss: 1.381309986114502\n",
      "mse 1.3813100198127688\n",
      "New best model found at epoch 74 with validation loss 1.381309986114502\n",
      "Starting Epoch 75\n",
      "1.4749123091283052\n",
      "Validation loss: 1.380540132522583\n",
      "mse 1.3805400859619932\n",
      "New best model found at epoch 75 with validation loss 1.380540132522583\n",
      "Starting Epoch 76\n",
      "1.4735460359117258\n",
      "Validation loss: 1.3798425197601318\n",
      "mse 1.3798424914698093\n",
      "New best model found at epoch 76 with validation loss 1.3798425197601318\n",
      "Starting Epoch 77\n",
      "1.4722934028376704\n",
      "Validation loss: 1.3787870407104492\n",
      "mse 1.378787035690063\n",
      "New best model found at epoch 77 with validation loss 1.3787870407104492\n",
      "Starting Epoch 78\n",
      "1.4710063416024912\n",
      "Validation loss: 1.3779335021972656\n",
      "mse 1.377933501668802\n",
      "New best model found at epoch 78 with validation loss 1.3779335021972656\n",
      "Starting Epoch 79\n",
      "1.469774111457493\n",
      "Validation loss: 1.3772436380386353\n",
      "mse 1.377243747196808\n",
      "New best model found at epoch 79 with validation loss 1.3772436380386353\n",
      "Starting Epoch 80\n",
      "1.46856856605281\n",
      "Validation loss: 1.3762660026550293\n",
      "mse 1.3762660412796124\n",
      "New best model found at epoch 80 with validation loss 1.3762660026550293\n",
      "Starting Epoch 81\n",
      "1.4673200249671936\n",
      "Validation loss: 1.3754914999008179\n",
      "mse 1.3754915178834703\n",
      "New best model found at epoch 81 with validation loss 1.3754914999008179\n",
      "Starting Epoch 82\n",
      "1.4662123763042947\n",
      "Validation loss: 1.3752329349517822\n",
      "mse 1.3752330826445798\n",
      "New best model found at epoch 82 with validation loss 1.3752329349517822\n",
      "Starting Epoch 83\n",
      "1.4649967447571133\n",
      "Validation loss: 1.3743915557861328\n",
      "mse 1.3743915930035682\n",
      "New best model found at epoch 83 with validation loss 1.3743915557861328\n",
      "Starting Epoch 84\n",
      "1.4638915424761565\n",
      "Validation loss: 1.3737075328826904\n",
      "mse 1.373707522697128\n",
      "New best model found at epoch 84 with validation loss 1.3737075328826904\n",
      "Starting Epoch 85\n",
      "1.4627896365912065\n",
      "Validation loss: 1.3734897375106812\n",
      "mse 1.3734896909903922\n",
      "New best model found at epoch 85 with validation loss 1.3734897375106812\n",
      "Starting Epoch 86\n",
      "1.4616595377092776\n",
      "Validation loss: 1.3727751970291138\n",
      "mse 1.372775202616557\n",
      "New best model found at epoch 86 with validation loss 1.3727751970291138\n",
      "Starting Epoch 87\n",
      "1.460435380106387\n",
      "Validation loss: 1.372318983078003\n",
      "mse 1.3723189113510341\n",
      "New best model found at epoch 87 with validation loss 1.372318983078003\n",
      "Starting Epoch 88\n",
      "1.4593696101852085\n",
      "Validation loss: 1.3718807697296143\n",
      "mse 1.3718808307999948\n",
      "New best model found at epoch 88 with validation loss 1.3718807697296143\n",
      "Starting Epoch 89\n",
      "1.4583517701729485\n",
      "Validation loss: 1.3714041709899902\n",
      "mse 1.3714040609154\n",
      "New best model found at epoch 89 with validation loss 1.3714041709899902\n",
      "Starting Epoch 90\n",
      "1.4572891100593235\n",
      "Validation loss: 1.370788812637329\n",
      "mse 1.3707888491199456\n",
      "New best model found at epoch 90 with validation loss 1.370788812637329\n",
      "Starting Epoch 91\n",
      "1.4562332215516463\n",
      "Validation loss: 1.3703114986419678\n",
      "mse 1.3703114417573108\n",
      "New best model found at epoch 91 with validation loss 1.3703114986419678\n",
      "Starting Epoch 92\n",
      "1.4550762617069741\n",
      "Validation loss: 1.3696870803833008\n",
      "mse 1.369687085928725\n",
      "New best model found at epoch 92 with validation loss 1.3696870803833008\n",
      "Starting Epoch 93\n",
      "1.4541544318199158\n",
      "Validation loss: 1.3692662715911865\n",
      "mse 1.3692663463432069\n",
      "New best model found at epoch 93 with validation loss 1.3692662715911865\n",
      "Starting Epoch 94\n",
      "1.4531211930772532\n",
      "Validation loss: 1.3687121868133545\n",
      "mse 1.368712370882566\n",
      "New best model found at epoch 94 with validation loss 1.3687121868133545\n",
      "Starting Epoch 95\n",
      "1.4521433192750681\n",
      "Validation loss: 1.3681941032409668\n",
      "mse 1.368194047148115\n",
      "New best model found at epoch 95 with validation loss 1.3681941032409668\n",
      "Starting Epoch 96\n",
      "1.4510416258936343\n",
      "Validation loss: 1.3675575256347656\n",
      "mse 1.3675575545856182\n",
      "New best model found at epoch 96 with validation loss 1.3675575256347656\n",
      "Starting Epoch 97\n",
      "1.4500445075657056\n",
      "Validation loss: 1.367021083831787\n",
      "mse 1.367020902763463\n",
      "New best model found at epoch 97 with validation loss 1.367021083831787\n",
      "Starting Epoch 98\n",
      "1.4490250115809233\n",
      "Validation loss: 1.3664509057998657\n",
      "mse 1.3664509068059851\n",
      "New best model found at epoch 98 with validation loss 1.3664509057998657\n",
      "Starting Epoch 99\n",
      "1.4480854868888855\n",
      "Validation loss: 1.365845799446106\n",
      "mse 1.3658458774991826\n",
      "New best model found at epoch 99 with validation loss 1.365845799446106\n",
      "Starting Epoch 100\n",
      "1.4472309998843982\n",
      "Validation loss: 1.3651037216186523\n",
      "mse 1.3651037134255655\n",
      "New best model found at epoch 100 with validation loss 1.3651037216186523\n",
      "Starting Epoch 101\n",
      "1.4462279366410298\n",
      "Validation loss: 1.3646272420883179\n",
      "mse 1.3646272694733983\n",
      "New best model found at epoch 101 with validation loss 1.3646272420883179\n",
      "Starting Epoch 102\n",
      "1.4452207529026528\n",
      "Validation loss: 1.3641822338104248\n",
      "mse 1.3641823500459676\n",
      "New best model found at epoch 102 with validation loss 1.3641822338104248\n",
      "Starting Epoch 103\n",
      "1.4444004219511282\n",
      "Validation loss: 1.363295078277588\n",
      "mse 1.3632950534311579\n",
      "New best model found at epoch 103 with validation loss 1.363295078277588\n",
      "Starting Epoch 104\n",
      "1.4433571929517\n",
      "Validation loss: 1.3629111051559448\n",
      "mse 1.362911085593548\n",
      "New best model found at epoch 104 with validation loss 1.3629111051559448\n",
      "Starting Epoch 105\n",
      "1.442510135795759\n",
      "Validation loss: 1.3622660636901855\n",
      "mse 1.3622658991448\n",
      "New best model found at epoch 105 with validation loss 1.3622660636901855\n",
      "Starting Epoch 106\n",
      "1.4415604005689207\n",
      "Validation loss: 1.3613861799240112\n",
      "mse 1.3613862036623037\n",
      "New best model found at epoch 106 with validation loss 1.3613861799240112\n",
      "Starting Epoch 107\n",
      "1.4405481789423071\n",
      "Validation loss: 1.3606864213943481\n",
      "mse 1.360686454479083\n",
      "New best model found at epoch 107 with validation loss 1.3606864213943481\n",
      "Starting Epoch 108\n",
      "1.4397258862205173\n",
      "Validation loss: 1.3602442741394043\n",
      "mse 1.3602443265431565\n",
      "New best model found at epoch 108 with validation loss 1.3602442741394043\n",
      "Starting Epoch 109\n",
      "1.4388962854509768\n",
      "Validation loss: 1.3595526218414307\n",
      "mse 1.3595527733895645\n",
      "New best model found at epoch 109 with validation loss 1.3595526218414307\n",
      "Starting Epoch 110\n",
      "1.4378652106160703\n",
      "Validation loss: 1.3592066764831543\n",
      "mse 1.3592067187932428\n",
      "New best model found at epoch 110 with validation loss 1.3592066764831543\n",
      "Starting Epoch 111\n",
      "1.4370031019915706\n",
      "Validation loss: 1.3584240674972534\n",
      "mse 1.3584241305754532\n",
      "New best model found at epoch 111 with validation loss 1.3584240674972534\n",
      "Starting Epoch 112\n",
      "1.436029208743054\n",
      "Validation loss: 1.3577606678009033\n",
      "mse 1.3577605357125762\n",
      "New best model found at epoch 112 with validation loss 1.3577606678009033\n",
      "Starting Epoch 113\n",
      "1.43499008209809\n",
      "Validation loss: 1.3572797775268555\n",
      "mse 1.357279741699364\n",
      "New best model found at epoch 113 with validation loss 1.3572797775268555\n",
      "Starting Epoch 114\n",
      "1.4341849451479705\n",
      "Validation loss: 1.3565647602081299\n",
      "mse 1.3565648023840617\n",
      "New best model found at epoch 114 with validation loss 1.3565647602081299\n",
      "Starting Epoch 115\n",
      "1.4331465752228447\n",
      "Validation loss: 1.3560863733291626\n",
      "mse 1.3560863723936363\n",
      "New best model found at epoch 115 with validation loss 1.3560863733291626\n",
      "Starting Epoch 116\n",
      "1.4321993563486182\n",
      "Validation loss: 1.3554850816726685\n",
      "mse 1.3554852426730524\n",
      "New best model found at epoch 116 with validation loss 1.3554850816726685\n",
      "Starting Epoch 117\n",
      "1.4314395629841348\n",
      "Validation loss: 1.35456120967865\n",
      "mse 1.3545612457792318\n",
      "New best model found at epoch 117 with validation loss 1.35456120967865\n",
      "Starting Epoch 118\n",
      "1.4304531346196714\n",
      "Validation loss: 1.3542274236679077\n",
      "mse 1.3542275332539762\n",
      "New best model found at epoch 118 with validation loss 1.3542274236679077\n",
      "Starting Epoch 119\n",
      "1.429562975531039\n",
      "Validation loss: 1.353384017944336\n",
      "mse 1.3533841150627246\n",
      "New best model found at epoch 119 with validation loss 1.353384017944336\n",
      "Starting Epoch 120\n",
      "1.4287275827449302\n",
      "Validation loss: 1.352783441543579\n",
      "mse 1.352783415688693\n",
      "New best model found at epoch 120 with validation loss 1.352783441543579\n",
      "Starting Epoch 121\n",
      "1.4277847720229107\n",
      "Validation loss: 1.3520634174346924\n",
      "mse 1.3520632582219956\n",
      "New best model found at epoch 121 with validation loss 1.3520634174346924\n",
      "Starting Epoch 122\n",
      "1.4268566162689873\n",
      "Validation loss: 1.3515089750289917\n",
      "mse 1.3515089362232917\n",
      "New best model found at epoch 122 with validation loss 1.3515089750289917\n",
      "Starting Epoch 123\n",
      "1.4259889022163723\n",
      "Validation loss: 1.3508837223052979\n",
      "mse 1.3508836886025253\n",
      "New best model found at epoch 123 with validation loss 1.3508837223052979\n",
      "Starting Epoch 124\n",
      "1.4250488903211511\n",
      "Validation loss: 1.3503003120422363\n",
      "mse 1.3503003010766972\n",
      "New best model found at epoch 124 with validation loss 1.3503003120422363\n",
      "Starting Epoch 125\n",
      "1.4242183566093445\n",
      "Validation loss: 1.3497928380966187\n",
      "mse 1.3497927384269215\n",
      "New best model found at epoch 125 with validation loss 1.3497928380966187\n",
      "Starting Epoch 126\n",
      "1.4233693765557331\n",
      "Validation loss: 1.3493260145187378\n",
      "mse 1.3493259971650338\n",
      "New best model found at epoch 126 with validation loss 1.3493260145187378\n",
      "Starting Epoch 127\n",
      "1.4225405325060305\n",
      "Validation loss: 1.3486100435256958\n",
      "mse 1.348610028053731\n",
      "New best model found at epoch 127 with validation loss 1.3486100435256958\n",
      "Starting Epoch 128\n",
      "1.4217185481734897\n",
      "Validation loss: 1.348117470741272\n",
      "mse 1.3481174316508502\n",
      "New best model found at epoch 128 with validation loss 1.348117470741272\n",
      "Starting Epoch 129\n",
      "1.4208424972451252\n",
      "Validation loss: 1.347641110420227\n",
      "mse 1.3476411343190369\n",
      "New best model found at epoch 129 with validation loss 1.347641110420227\n",
      "Starting Epoch 130\n",
      "1.4200060678564983\n",
      "Validation loss: 1.3470147848129272\n",
      "mse 1.3470147390562046\n",
      "New best model found at epoch 130 with validation loss 1.3470147848129272\n",
      "Starting Epoch 131\n",
      "1.419098983640256\n",
      "Validation loss: 1.3465858697891235\n",
      "mse 1.3465859599514758\n",
      "New best model found at epoch 131 with validation loss 1.3465858697891235\n",
      "Starting Epoch 132\n",
      "1.4184324482212896\n",
      "Validation loss: 1.3460239171981812\n",
      "mse 1.346023867152393\n",
      "New best model found at epoch 132 with validation loss 1.3460239171981812\n",
      "Starting Epoch 133\n",
      "1.4175309305605681\n",
      "Validation loss: 1.3454279899597168\n",
      "mse 1.3454280618676675\n",
      "New best model found at epoch 133 with validation loss 1.3454279899597168\n",
      "Starting Epoch 134\n",
      "1.41661478643832\n",
      "Validation loss: 1.3447810411453247\n",
      "mse 1.3447810119515162\n",
      "New best model found at epoch 134 with validation loss 1.3447810411453247\n",
      "Starting Epoch 135\n",
      "1.4158518236616384\n",
      "Validation loss: 1.3445075750350952\n",
      "mse 1.3445075642964217\n",
      "New best model found at epoch 135 with validation loss 1.3445075750350952\n",
      "Starting Epoch 136\n",
      "1.415010983529298\n",
      "Validation loss: 1.3436449766159058\n",
      "mse 1.3436449634166583\n",
      "New best model found at epoch 136 with validation loss 1.3436449766159058\n",
      "Starting Epoch 137\n",
      "1.414180724517159\n",
      "Validation loss: 1.3433603048324585\n",
      "mse 1.343360176356386\n",
      "New best model found at epoch 137 with validation loss 1.3433603048324585\n",
      "Starting Epoch 138\n",
      "1.4133792960125466\n",
      "Validation loss: 1.3425393104553223\n",
      "mse 1.3425393375076655\n",
      "New best model found at epoch 138 with validation loss 1.3425393104553223\n",
      "Starting Epoch 139\n",
      "1.4125608076219973\n",
      "Validation loss: 1.3422489166259766\n",
      "mse 1.342248777795455\n",
      "New best model found at epoch 139 with validation loss 1.3422489166259766\n",
      "Starting Epoch 140\n",
      "1.4117992934973345\n",
      "Validation loss: 1.341569423675537\n",
      "mse 1.3415694002645113\n",
      "New best model found at epoch 140 with validation loss 1.341569423675537\n",
      "Starting Epoch 141\n",
      "1.4110068678855896\n",
      "Validation loss: 1.3413405418395996\n",
      "mse 1.3413404421798578\n",
      "New best model found at epoch 141 with validation loss 1.3413405418395996\n",
      "Starting Epoch 142\n",
      "1.4102412203083867\n",
      "Validation loss: 1.3405801057815552\n",
      "mse 1.3405800271981656\n",
      "New best model found at epoch 142 with validation loss 1.3405801057815552\n",
      "Starting Epoch 143\n",
      "1.4094160795211792\n",
      "Validation loss: 1.3402035236358643\n",
      "mse 1.3402036156515862\n",
      "New best model found at epoch 143 with validation loss 1.3402035236358643\n",
      "Starting Epoch 144\n",
      "1.408675017564193\n",
      "Validation loss: 1.3396223783493042\n",
      "mse 1.3396223729608934\n",
      "New best model found at epoch 144 with validation loss 1.3396223783493042\n",
      "Starting Epoch 145\n",
      "1.4078003556832024\n",
      "Validation loss: 1.3391222953796387\n",
      "mse 1.3391222285532236\n",
      "New best model found at epoch 145 with validation loss 1.3391222953796387\n",
      "Starting Epoch 146\n",
      "1.4070550281068552\n",
      "Validation loss: 1.3384102582931519\n",
      "mse 1.3384101895024303\n",
      "New best model found at epoch 146 with validation loss 1.3384102582931519\n",
      "Starting Epoch 147\n",
      "1.4062138847682788\n",
      "Validation loss: 1.3382370471954346\n",
      "mse 1.3382370422103924\n",
      "New best model found at epoch 147 with validation loss 1.3382370471954346\n",
      "Starting Epoch 148\n",
      "1.4054281737493433\n",
      "Validation loss: 1.3375200033187866\n",
      "mse 1.3375200593896146\n",
      "New best model found at epoch 148 with validation loss 1.3375200033187866\n",
      "Starting Epoch 149\n",
      "1.4045694496320642\n",
      "Validation loss: 1.3372211456298828\n",
      "mse 1.337221131382294\n",
      "New best model found at epoch 149 with validation loss 1.3372211456298828\n",
      "Starting Epoch 150\n",
      "1.403826635816823\n",
      "Validation loss: 1.3366366624832153\n",
      "mse 1.3366366307672128\n",
      "New best model found at epoch 150 with validation loss 1.3366366624832153\n",
      "Starting Epoch 151\n",
      "1.4031653792961785\n",
      "Validation loss: 1.3364684581756592\n",
      "mse 1.3364685295538519\n",
      "New best model found at epoch 151 with validation loss 1.3364684581756592\n",
      "Starting Epoch 152\n",
      "1.4023646945538728\n",
      "Validation loss: 1.3361245393753052\n",
      "mse 1.3361245308480898\n",
      "New best model found at epoch 152 with validation loss 1.3361245393753052\n",
      "Starting Epoch 153\n",
      "1.4016777095587358\n",
      "Validation loss: 1.3357813358306885\n",
      "mse 1.3357812337003159\n",
      "New best model found at epoch 153 with validation loss 1.3357813358306885\n",
      "Starting Epoch 154\n",
      "1.400919100512629\n",
      "Validation loss: 1.3346576690673828\n",
      "mse 1.3346577047868826\n",
      "New best model found at epoch 154 with validation loss 1.3346576690673828\n",
      "Starting Epoch 155\n",
      "1.4001939478127852\n",
      "Validation loss: 1.3340848684310913\n",
      "mse 1.3340848338513196\n",
      "New best model found at epoch 155 with validation loss 1.3340848684310913\n",
      "Starting Epoch 156\n",
      "1.3994418227154275\n",
      "Validation loss: 1.3336818218231201\n",
      "mse 1.3336818269741884\n",
      "New best model found at epoch 156 with validation loss 1.3336818218231201\n",
      "Starting Epoch 157\n",
      "1.3987375705138496\n",
      "Validation loss: 1.333051323890686\n",
      "mse 1.3330513596594837\n",
      "New best model found at epoch 157 with validation loss 1.333051323890686\n",
      "Starting Epoch 158\n",
      "1.3978438740191252\n",
      "Validation loss: 1.3323094844818115\n",
      "mse 1.3323095958705478\n",
      "New best model found at epoch 158 with validation loss 1.3323094844818115\n",
      "Starting Epoch 159\n",
      "1.3972103958544524\n",
      "Validation loss: 1.3319377899169922\n",
      "mse 1.3319378281057999\n",
      "New best model found at epoch 159 with validation loss 1.3319377899169922\n",
      "Starting Epoch 160\n",
      "1.39654534018558\n",
      "Validation loss: 1.3313679695129395\n",
      "mse 1.3313680174555216\n",
      "New best model found at epoch 160 with validation loss 1.3313679695129395\n",
      "Starting Epoch 161\n",
      "1.395666645920795\n",
      "Validation loss: 1.3310908079147339\n",
      "mse 1.331090912351144\n",
      "New best model found at epoch 161 with validation loss 1.3310908079147339\n",
      "Starting Epoch 162\n",
      "1.3949156325796377\n",
      "Validation loss: 1.330469012260437\n",
      "mse 1.330468963641688\n",
      "New best model found at epoch 162 with validation loss 1.330469012260437\n",
      "Starting Epoch 163\n",
      "1.3943925681321516\n",
      "Validation loss: 1.3298112154006958\n",
      "mse 1.329811297859061\n",
      "New best model found at epoch 163 with validation loss 1.3298112154006958\n",
      "Starting Epoch 164\n",
      "1.3936205817305523\n",
      "Validation loss: 1.3292549848556519\n",
      "mse 1.329255017165041\n",
      "New best model found at epoch 164 with validation loss 1.3292549848556519\n",
      "Starting Epoch 165\n",
      "1.3928835702979045\n",
      "Validation loss: 1.328847050666809\n",
      "mse 1.3288469614157001\n",
      "New best model found at epoch 165 with validation loss 1.328847050666809\n",
      "Starting Epoch 166\n",
      "1.3920851220255313\n",
      "Validation loss: 1.3283671140670776\n",
      "mse 1.3283670861296988\n",
      "New best model found at epoch 166 with validation loss 1.3283671140670776\n",
      "Starting Epoch 167\n",
      "1.3915135160736416\n",
      "Validation loss: 1.32779860496521\n",
      "mse 1.327798557159866\n",
      "New best model found at epoch 167 with validation loss 1.32779860496521\n",
      "Starting Epoch 168\n",
      "1.3907052822734998\n",
      "Validation loss: 1.3273650407791138\n",
      "mse 1.3273651328076965\n",
      "New best model found at epoch 168 with validation loss 1.3273650407791138\n",
      "Starting Epoch 169\n",
      "1.3901103061178457\n",
      "Validation loss: 1.3266894817352295\n",
      "mse 1.3266894730244068\n",
      "New best model found at epoch 169 with validation loss 1.3266894817352295\n",
      "Starting Epoch 170\n",
      "1.3894617013309314\n",
      "Validation loss: 1.3259680271148682\n",
      "mse 1.3259680775746183\n",
      "New best model found at epoch 170 with validation loss 1.3259680271148682\n",
      "Starting Epoch 171\n",
      "1.3887055464412854\n",
      "Validation loss: 1.3253501653671265\n",
      "mse 1.325350133226858\n",
      "New best model found at epoch 171 with validation loss 1.3253501653671265\n",
      "Starting Epoch 172\n",
      "1.3879827027735503\n",
      "Validation loss: 1.3247451782226562\n",
      "mse 1.3247452361280343\n",
      "New best model found at epoch 172 with validation loss 1.3247451782226562\n",
      "Starting Epoch 173\n",
      "1.38738512215407\n",
      "Validation loss: 1.324123501777649\n",
      "mse 1.3241234539888325\n",
      "New best model found at epoch 173 with validation loss 1.324123501777649\n",
      "Starting Epoch 174\n",
      "1.3866412510042605\n",
      "Validation loss: 1.3239320516586304\n",
      "mse 1.323932123561472\n",
      "New best model found at epoch 174 with validation loss 1.3239320516586304\n",
      "Starting Epoch 175\n",
      "1.385889885218247\n",
      "Validation loss: 1.3234665393829346\n",
      "mse 1.3234666837968487\n",
      "New best model found at epoch 175 with validation loss 1.3234665393829346\n",
      "Starting Epoch 176\n",
      "1.3852977804515674\n",
      "Validation loss: 1.3231401443481445\n",
      "mse 1.3231401242427676\n",
      "New best model found at epoch 176 with validation loss 1.3231401443481445\n",
      "Starting Epoch 177\n",
      "1.3845950831537661\n",
      "Validation loss: 1.3225584030151367\n",
      "mse 1.3225583757929547\n",
      "New best model found at epoch 177 with validation loss 1.3225584030151367\n",
      "Starting Epoch 178\n",
      "1.3839324920073799\n",
      "Validation loss: 1.3221391439437866\n",
      "mse 1.3221391843937875\n",
      "New best model found at epoch 178 with validation loss 1.3221391439437866\n",
      "Starting Epoch 179\n",
      "1.3832976273868396\n",
      "Validation loss: 1.3216692209243774\n",
      "mse 1.3216692355131925\n",
      "New best model found at epoch 179 with validation loss 1.3216692209243774\n",
      "Starting Epoch 180\n",
      "1.3825864169908606\n",
      "Validation loss: 1.3211601972579956\n",
      "mse 1.3211601288148822\n",
      "New best model found at epoch 180 with validation loss 1.3211601972579956\n",
      "Starting Epoch 181\n",
      "1.3819499223128608\n",
      "Validation loss: 1.3205868005752563\n",
      "mse 1.3205869215104267\n",
      "New best model found at epoch 181 with validation loss 1.3205868005752563\n",
      "Starting Epoch 182\n",
      "1.3813903850057851\n",
      "Validation loss: 1.3202366828918457\n",
      "mse 1.3202367211094708\n",
      "New best model found at epoch 182 with validation loss 1.3202366828918457\n",
      "Starting Epoch 183\n",
      "1.3807222324868906\n",
      "Validation loss: 1.3195452690124512\n",
      "mse 1.319545285187495\n",
      "New best model found at epoch 183 with validation loss 1.3195452690124512\n",
      "Starting Epoch 184\n",
      "1.3800684032232866\n",
      "Validation loss: 1.3188796043395996\n",
      "mse 1.3188796193599508\n",
      "New best model found at epoch 184 with validation loss 1.3188796043395996\n",
      "Starting Epoch 185\n",
      "1.3795070311297541\n",
      "Validation loss: 1.3185206651687622\n",
      "mse 1.3185205556927533\n",
      "New best model found at epoch 185 with validation loss 1.3185206651687622\n",
      "Starting Epoch 186\n",
      "1.3788070004919302\n",
      "Validation loss: 1.3180341720581055\n",
      "mse 1.3180340540641688\n",
      "New best model found at epoch 186 with validation loss 1.3180341720581055\n",
      "Starting Epoch 187\n",
      "1.378093649511752\n",
      "Validation loss: 1.3174413442611694\n",
      "mse 1.3174412156822626\n",
      "New best model found at epoch 187 with validation loss 1.3174413442611694\n",
      "Starting Epoch 188\n",
      "1.3775883498399153\n",
      "Validation loss: 1.317020297050476\n",
      "mse 1.3170204174588787\n",
      "New best model found at epoch 188 with validation loss 1.317020297050476\n",
      "Starting Epoch 189\n",
      "1.376890322436457\n",
      "Validation loss: 1.3165950775146484\n",
      "mse 1.3165950914827158\n",
      "New best model found at epoch 189 with validation loss 1.3165950775146484\n",
      "Starting Epoch 190\n",
      "1.3762954214344854\n",
      "Validation loss: 1.316266655921936\n",
      "mse 1.316266621783899\n",
      "New best model found at epoch 190 with validation loss 1.316266655921936\n",
      "Starting Epoch 191\n",
      "1.3757197675497637\n",
      "Validation loss: 1.3158105611801147\n",
      "mse 1.3158105487017935\n",
      "New best model found at epoch 191 with validation loss 1.3158105611801147\n",
      "Starting Epoch 192\n",
      "1.3750335392744646\n",
      "Validation loss: 1.315167784690857\n",
      "mse 1.3151678962772124\n",
      "New best model found at epoch 192 with validation loss 1.315167784690857\n",
      "Starting Epoch 193\n",
      "1.3744959675747415\n",
      "Validation loss: 1.3147568702697754\n",
      "mse 1.3147569762101146\n",
      "New best model found at epoch 193 with validation loss 1.3147568702697754\n",
      "Starting Epoch 194\n",
      "1.3738571094430012\n",
      "Validation loss: 1.3143352270126343\n",
      "mse 1.3143352058458413\n",
      "New best model found at epoch 194 with validation loss 1.3143352270126343\n",
      "Starting Epoch 195\n",
      "1.3732668265052463\n",
      "Validation loss: 1.3138949871063232\n",
      "mse 1.3138949701264333\n",
      "New best model found at epoch 195 with validation loss 1.3138949871063232\n",
      "Starting Epoch 196\n",
      "1.3727069160212642\n",
      "Validation loss: 1.313567042350769\n",
      "mse 1.3135671117361385\n",
      "New best model found at epoch 196 with validation loss 1.313567042350769\n",
      "Starting Epoch 197\n",
      "1.3722064391426418\n",
      "Validation loss: 1.313355565071106\n",
      "mse 1.3133554716052567\n",
      "New best model found at epoch 197 with validation loss 1.313355565071106\n",
      "Starting Epoch 198\n",
      "1.3715182620546091\n",
      "Validation loss: 1.3130460977554321\n",
      "mse 1.3130461820813748\n",
      "New best model found at epoch 198 with validation loss 1.3130460977554321\n",
      "Starting Epoch 199\n",
      "1.3709137258322344\n",
      "Validation loss: 1.3126896619796753\n",
      "mse 1.3126898559279379\n",
      "New best model found at epoch 199 with validation loss 1.3126896619796753\n",
      "Starting Epoch 200\n",
      "1.3703315698582192\n",
      "Validation loss: 1.312347650527954\n",
      "mse 1.3123476245562224\n",
      "New best model found at epoch 200 with validation loss 1.312347650527954\n",
      "Starting Epoch 201\n",
      "1.3697681271511575\n",
      "Validation loss: 1.3117806911468506\n",
      "mse 1.3117807479797012\n",
      "New best model found at epoch 201 with validation loss 1.3117806911468506\n",
      "Starting Epoch 202\n",
      "1.3690621490063875\n",
      "Validation loss: 1.3113222122192383\n",
      "mse 1.311322175563814\n",
      "New best model found at epoch 202 with validation loss 1.3113222122192383\n",
      "Starting Epoch 203\n",
      "1.3683521669843923\n",
      "Validation loss: 1.3108423948287964\n",
      "mse 1.3108424300668677\n",
      "New best model found at epoch 203 with validation loss 1.3108423948287964\n",
      "Starting Epoch 204\n",
      "1.367731864037721\n",
      "Validation loss: 1.3102734088897705\n",
      "mse 1.310273308473857\n",
      "New best model found at epoch 204 with validation loss 1.3102734088897705\n",
      "Starting Epoch 205\n",
      "1.3670788770136626\n",
      "Validation loss: 1.3098583221435547\n",
      "mse 1.309858226635516\n",
      "New best model found at epoch 205 with validation loss 1.3098583221435547\n",
      "Starting Epoch 206\n",
      "1.3663628334584443\n",
      "Validation loss: 1.3092536926269531\n",
      "mse 1.3092536982001168\n",
      "New best model found at epoch 206 with validation loss 1.3092536926269531\n",
      "Starting Epoch 207\n",
      "1.3657020485919455\n",
      "Validation loss: 1.3087506294250488\n",
      "mse 1.3087506515303076\n",
      "New best model found at epoch 207 with validation loss 1.3087506294250488\n",
      "Starting Epoch 208\n",
      "1.3651076607082202\n",
      "Validation loss: 1.308382272720337\n",
      "mse 1.3083822201690356\n",
      "New best model found at epoch 208 with validation loss 1.308382272720337\n",
      "Starting Epoch 209\n",
      "1.3643778640290964\n",
      "Validation loss: 1.3077449798583984\n",
      "mse 1.3077449344570187\n",
      "New best model found at epoch 209 with validation loss 1.3077449798583984\n",
      "Starting Epoch 210\n",
      "1.3637452825256016\n",
      "Validation loss: 1.3072494268417358\n",
      "mse 1.3072493687689568\n",
      "New best model found at epoch 210 with validation loss 1.3072494268417358\n",
      "Starting Epoch 211\n",
      "1.3631130275519\n",
      "Validation loss: 1.3065804243087769\n",
      "mse 1.306580465664203\n",
      "New best model found at epoch 211 with validation loss 1.3065804243087769\n",
      "Starting Epoch 212\n",
      "1.3625347018241882\n",
      "Validation loss: 1.3061411380767822\n",
      "mse 1.306141011234581\n",
      "New best model found at epoch 212 with validation loss 1.3061411380767822\n",
      "Starting Epoch 213\n",
      "1.3618645460709282\n",
      "Validation loss: 1.3054462671279907\n",
      "mse 1.3054463437718136\n",
      "New best model found at epoch 213 with validation loss 1.3054462671279907\n",
      "Starting Epoch 214\n",
      "1.361337809459023\n",
      "Validation loss: 1.3049358129501343\n",
      "mse 1.3049358895685557\n",
      "New best model found at epoch 214 with validation loss 1.3049358129501343\n",
      "Starting Epoch 215\n",
      "1.3607012629508972\n",
      "Validation loss: 1.3045729398727417\n",
      "mse 1.3045728122341536\n",
      "New best model found at epoch 215 with validation loss 1.3045729398727417\n",
      "Starting Epoch 216\n",
      "1.3600775262583857\n",
      "Validation loss: 1.3038365840911865\n",
      "mse 1.3038365714866615\n",
      "New best model found at epoch 216 with validation loss 1.3038365840911865\n",
      "Starting Epoch 217\n",
      "1.3593965380088142\n",
      "Validation loss: 1.303523302078247\n",
      "mse 1.303523294687111\n",
      "New best model found at epoch 217 with validation loss 1.303523302078247\n",
      "Starting Epoch 218\n",
      "1.358794831711313\n",
      "Validation loss: 1.3028661012649536\n",
      "mse 1.3028660985664364\n",
      "New best model found at epoch 218 with validation loss 1.3028661012649536\n",
      "Starting Epoch 219\n",
      "1.3581065587375476\n",
      "Validation loss: 1.3022805452346802\n",
      "mse 1.302280538992087\n",
      "New best model found at epoch 219 with validation loss 1.3022805452346802\n",
      "Starting Epoch 220\n",
      "1.357486473477405\n",
      "Validation loss: 1.3018873929977417\n",
      "mse 1.3018872627524896\n",
      "New best model found at epoch 220 with validation loss 1.3018873929977417\n",
      "Starting Epoch 221\n",
      "1.3567416356957478\n",
      "Validation loss: 1.3011406660079956\n",
      "mse 1.3011405779557403\n",
      "New best model found at epoch 221 with validation loss 1.3011406660079956\n",
      "Starting Epoch 222\n",
      "1.3560830225115237\n",
      "Validation loss: 1.300339937210083\n",
      "mse 1.3003398392164853\n",
      "New best model found at epoch 222 with validation loss 1.300339937210083\n",
      "Starting Epoch 223\n",
      "1.355486968289251\n",
      "Validation loss: 1.3000575304031372\n",
      "mse 1.3000575862672397\n",
      "New best model found at epoch 223 with validation loss 1.3000575304031372\n",
      "Starting Epoch 224\n",
      "1.3548162294470745\n",
      "Validation loss: 1.299343466758728\n",
      "mse 1.2993435814858332\n",
      "New best model found at epoch 224 with validation loss 1.299343466758728\n",
      "Starting Epoch 225\n",
      "1.354184212891952\n",
      "Validation loss: 1.2988550662994385\n",
      "mse 1.2988551813878115\n",
      "New best model found at epoch 225 with validation loss 1.2988550662994385\n",
      "Starting Epoch 226\n",
      "1.353494133638299\n",
      "Validation loss: 1.298130750656128\n",
      "mse 1.2981307674506501\n",
      "New best model found at epoch 226 with validation loss 1.298130750656128\n",
      "Starting Epoch 227\n",
      "1.3528861636700837\n",
      "Validation loss: 1.297588586807251\n",
      "mse 1.2975885258335569\n",
      "New best model found at epoch 227 with validation loss 1.297588586807251\n",
      "Starting Epoch 228\n",
      "1.3521550660548003\n",
      "Validation loss: 1.2971175909042358\n",
      "mse 1.297117581722678\n",
      "New best model found at epoch 228 with validation loss 1.2971175909042358\n",
      "Starting Epoch 229\n",
      "1.3514412330544514\n",
      "Validation loss: 1.2965766191482544\n",
      "mse 1.2965766988214995\n",
      "New best model found at epoch 229 with validation loss 1.2965766191482544\n",
      "Starting Epoch 230\n",
      "1.3506985747295877\n",
      "Validation loss: 1.2964035272598267\n",
      "mse 1.2964036108412644\n",
      "New best model found at epoch 230 with validation loss 1.2964035272598267\n",
      "Starting Epoch 231\n",
      "1.349954550680907\n",
      "Validation loss: 1.295827865600586\n",
      "mse 1.2958279030143056\n",
      "New best model found at epoch 231 with validation loss 1.295827865600586\n",
      "Starting Epoch 232\n",
      "1.3492496091386545\n",
      "Validation loss: 1.2955268621444702\n",
      "mse 1.2955269376124035\n",
      "New best model found at epoch 232 with validation loss 1.2955268621444702\n",
      "Starting Epoch 233\n",
      "1.3486905694007874\n",
      "Validation loss: 1.2950444221496582\n",
      "mse 1.295044358232036\n",
      "New best model found at epoch 233 with validation loss 1.2950444221496582\n",
      "Starting Epoch 234\n",
      "1.3478959099106167\n",
      "Validation loss: 1.2945587635040283\n",
      "mse 1.2945586939561722\n",
      "New best model found at epoch 234 with validation loss 1.2945587635040283\n",
      "Starting Epoch 235\n",
      "1.3473365047703618\n",
      "Validation loss: 1.2941391468048096\n",
      "mse 1.2941392052914438\n",
      "New best model found at epoch 235 with validation loss 1.2941391468048096\n",
      "Starting Epoch 236\n",
      "1.3467330051505046\n",
      "Validation loss: 1.2937839031219482\n",
      "mse 1.2937838726257713\n",
      "New best model found at epoch 236 with validation loss 1.2937839031219482\n",
      "Starting Epoch 237\n",
      "1.346002511356188\n",
      "Validation loss: 1.293101191520691\n",
      "mse 1.293101120988749\n",
      "New best model found at epoch 237 with validation loss 1.293101191520691\n",
      "Starting Epoch 238\n",
      "1.3453738818997922\n",
      "Validation loss: 1.2926347255706787\n",
      "mse 1.2926347910152098\n",
      "New best model found at epoch 238 with validation loss 1.2926347255706787\n",
      "Starting Epoch 239\n",
      "1.3447215868079143\n",
      "Validation loss: 1.2920993566513062\n",
      "mse 1.2920993276322221\n",
      "New best model found at epoch 239 with validation loss 1.2920993566513062\n",
      "Starting Epoch 240\n",
      "1.3439117747804392\n",
      "Validation loss: 1.2915509939193726\n",
      "mse 1.291550850466238\n",
      "New best model found at epoch 240 with validation loss 1.2915509939193726\n",
      "Starting Epoch 241\n",
      "1.3433720028918723\n",
      "Validation loss: 1.2908259630203247\n",
      "mse 1.2908260987452005\n",
      "New best model found at epoch 241 with validation loss 1.2908259630203247\n",
      "Starting Epoch 242\n",
      "1.3425786598868992\n",
      "Validation loss: 1.290048599243164\n",
      "mse 1.2900485954758574\n",
      "New best model found at epoch 242 with validation loss 1.290048599243164\n",
      "Starting Epoch 243\n",
      "1.342143740343011\n",
      "Validation loss: 1.2896058559417725\n",
      "mse 1.2896057297175307\n",
      "New best model found at epoch 243 with validation loss 1.2896058559417725\n",
      "Starting Epoch 244\n",
      "1.3413385593372842\n",
      "Validation loss: 1.289227843284607\n",
      "mse 1.2892280210321658\n",
      "New best model found at epoch 244 with validation loss 1.289227843284607\n",
      "Starting Epoch 245\n",
      "1.3407057886538298\n",
      "Validation loss: 1.2887557744979858\n",
      "mse 1.2887558309663645\n",
      "New best model found at epoch 245 with validation loss 1.2887557744979858\n",
      "Starting Epoch 246\n",
      "1.3401850487874902\n",
      "Validation loss: 1.2879921197891235\n",
      "mse 1.2879920728024767\n",
      "New best model found at epoch 246 with validation loss 1.2879921197891235\n",
      "Starting Epoch 247\n",
      "1.3392019608746404\n",
      "Validation loss: 1.2878206968307495\n",
      "mse 1.2878206652329163\n",
      "New best model found at epoch 247 with validation loss 1.2878206968307495\n",
      "Starting Epoch 248\n",
      "1.3384986753049104\n",
      "Validation loss: 1.2882156372070312\n",
      "mse 1.2882155554998196\n",
      "Starting Epoch 249\n",
      "1.3378120505291482\n",
      "Validation loss: 1.2879258394241333\n",
      "mse 1.287925922735979\n",
      "Starting Epoch 250\n",
      "1.3370670313420503\n",
      "Validation loss: 1.2881879806518555\n",
      "mse 1.2881879351723562\n",
      "Starting Epoch 251\n",
      "1.33637389411097\n",
      "Validation loss: 1.2877594232559204\n",
      "mse 1.2877594820095057\n",
      "New best model found at epoch 251 with validation loss 1.2877594232559204\n",
      "Starting Epoch 252\n",
      "1.3357375238252722\n",
      "Validation loss: 1.287615418434143\n",
      "mse 1.2876153155215122\n",
      "New best model found at epoch 252 with validation loss 1.287615418434143\n",
      "Starting Epoch 253\n",
      "1.3350327222243599\n",
      "Validation loss: 1.2871534824371338\n",
      "mse 1.287153446988999\n",
      "New best model found at epoch 253 with validation loss 1.2871534824371338\n",
      "Starting Epoch 254\n",
      "1.3345204928646917\n",
      "Validation loss: 1.286496639251709\n",
      "mse 1.2864966287053377\n",
      "New best model found at epoch 254 with validation loss 1.286496639251709\n",
      "Starting Epoch 255\n",
      "1.3338931280633677\n",
      "Validation loss: 1.2855390310287476\n",
      "mse 1.2855390705033396\n",
      "New best model found at epoch 255 with validation loss 1.2855390310287476\n",
      "Starting Epoch 256\n",
      "1.3332990485688914\n",
      "Validation loss: 1.285068392753601\n",
      "mse 1.2850684181569894\n",
      "New best model found at epoch 256 with validation loss 1.285068392753601\n",
      "Starting Epoch 257\n",
      "1.3326112109681834\n",
      "Validation loss: 1.2843501567840576\n",
      "mse 1.2843501584450967\n",
      "New best model found at epoch 257 with validation loss 1.2843501567840576\n",
      "Starting Epoch 258\n",
      "1.3320605573446855\n",
      "Validation loss: 1.2837529182434082\n",
      "mse 1.2837529218340848\n",
      "New best model found at epoch 258 with validation loss 1.2837529182434082\n",
      "Starting Epoch 259\n",
      "1.3315354948458464\n",
      "Validation loss: 1.2831615209579468\n",
      "mse 1.283161523218255\n",
      "New best model found at epoch 259 with validation loss 1.2831615209579468\n",
      "Starting Epoch 260\n",
      "1.3309380152951116\n",
      "Validation loss: 1.2826136350631714\n",
      "mse 1.2826137704078004\n",
      "New best model found at epoch 260 with validation loss 1.2826136350631714\n",
      "Starting Epoch 261\n",
      "1.3303220919940784\n",
      "Validation loss: 1.2820080518722534\n",
      "mse 1.2820081291205918\n",
      "New best model found at epoch 261 with validation loss 1.2820080518722534\n",
      "Starting Epoch 262\n",
      "1.329860684664353\n",
      "Validation loss: 1.2813717126846313\n",
      "mse 1.28137171223652\n",
      "New best model found at epoch 262 with validation loss 1.2813717126846313\n",
      "Starting Epoch 263\n",
      "1.3292134481927622\n",
      "Validation loss: 1.2809374332427979\n",
      "mse 1.2809375055129144\n",
      "New best model found at epoch 263 with validation loss 1.2809374332427979\n",
      "Starting Epoch 264\n",
      "1.3286171555519104\n",
      "Validation loss: 1.2801446914672852\n",
      "mse 1.2801446566881443\n",
      "New best model found at epoch 264 with validation loss 1.2801446914672852\n",
      "Starting Epoch 265\n",
      "1.328241643698319\n",
      "Validation loss: 1.279823660850525\n",
      "mse 1.2798237752884312\n",
      "New best model found at epoch 265 with validation loss 1.279823660850525\n",
      "Starting Epoch 266\n",
      "1.327632038489632\n",
      "Validation loss: 1.27918541431427\n",
      "mse 1.2791853439441607\n",
      "New best model found at epoch 266 with validation loss 1.27918541431427\n",
      "Starting Epoch 267\n",
      "1.3270515307136204\n",
      "Validation loss: 1.2788587808609009\n",
      "mse 1.2788587110292626\n",
      "New best model found at epoch 267 with validation loss 1.2788587808609009\n",
      "Starting Epoch 268\n",
      "1.3265613654385442\n",
      "Validation loss: 1.2782831192016602\n",
      "mse 1.2782831504260106\n",
      "New best model found at epoch 268 with validation loss 1.2782831192016602\n",
      "Starting Epoch 269\n",
      "1.3260688133861707\n",
      "Validation loss: 1.277954339981079\n",
      "mse 1.2779542191039017\n",
      "New best model found at epoch 269 with validation loss 1.277954339981079\n",
      "Starting Epoch 270\n",
      "1.3255072572956914\n",
      "Validation loss: 1.2772732973098755\n",
      "mse 1.277273358413549\n",
      "New best model found at epoch 270 with validation loss 1.2772732973098755\n",
      "Starting Epoch 271\n",
      "1.3250598829725515\n",
      "Validation loss: 1.2769896984100342\n",
      "mse 1.2769897552826828\n",
      "New best model found at epoch 271 with validation loss 1.2769896984100342\n",
      "Starting Epoch 272\n",
      "1.324443228866743\n",
      "Validation loss: 1.2764079570770264\n",
      "mse 1.2764079636831365\n",
      "New best model found at epoch 272 with validation loss 1.2764079570770264\n",
      "Starting Epoch 273\n",
      "1.3239957016447317\n",
      "Validation loss: 1.2758225202560425\n",
      "mse 1.2758225127973257\n",
      "New best model found at epoch 273 with validation loss 1.2758225202560425\n",
      "Starting Epoch 274\n",
      "1.323423297508903\n",
      "Validation loss: 1.275250792503357\n",
      "mse 1.2752507033811187\n",
      "New best model found at epoch 274 with validation loss 1.275250792503357\n",
      "Starting Epoch 275\n",
      "1.3230178304340527\n",
      "Validation loss: 1.2749707698822021\n",
      "mse 1.2749706279956436\n",
      "New best model found at epoch 275 with validation loss 1.2749707698822021\n",
      "Starting Epoch 276\n",
      "1.3223635657973911\n",
      "Validation loss: 1.274079442024231\n",
      "mse 1.2740793765302494\n",
      "New best model found at epoch 276 with validation loss 1.274079442024231\n",
      "Starting Epoch 277\n",
      "1.3219992596170176\n",
      "Validation loss: 1.2736668586730957\n",
      "mse 1.2736668029333043\n",
      "New best model found at epoch 277 with validation loss 1.2736668586730957\n",
      "Starting Epoch 278\n",
      "1.3215133962423906\n",
      "Validation loss: 1.273435354232788\n",
      "mse 1.2734353874502746\n",
      "New best model found at epoch 278 with validation loss 1.273435354232788\n",
      "Starting Epoch 279\n",
      "1.3209824199261873\n",
      "Validation loss: 1.2726260423660278\n",
      "mse 1.2726258900167098\n",
      "New best model found at epoch 279 with validation loss 1.2726260423660278\n",
      "Starting Epoch 280\n",
      "1.320571798345317\n",
      "Validation loss: 1.2721986770629883\n",
      "mse 1.2721986938400554\n",
      "New best model found at epoch 280 with validation loss 1.2721986770629883\n",
      "Starting Epoch 281\n",
      "1.3199646498845972\n",
      "Validation loss: 1.2717909812927246\n",
      "mse 1.2717908934752176\n",
      "New best model found at epoch 281 with validation loss 1.2717909812927246\n",
      "Starting Epoch 282\n",
      "1.3194541050040203\n",
      "Validation loss: 1.2710627317428589\n",
      "mse 1.2710627490562003\n",
      "New best model found at epoch 282 with validation loss 1.2710627317428589\n",
      "Starting Epoch 283\n",
      "1.3190678176672563\n",
      "Validation loss: 1.270661473274231\n",
      "mse 1.270661479706016\n",
      "New best model found at epoch 283 with validation loss 1.270661473274231\n",
      "Starting Epoch 284\n",
      "1.3186206921287205\n",
      "Validation loss: 1.2701302766799927\n",
      "mse 1.2701302793878284\n",
      "New best model found at epoch 284 with validation loss 1.2701302766799927\n",
      "Starting Epoch 285\n",
      "1.318105197471121\n",
      "Validation loss: 1.2696455717086792\n",
      "mse 1.269645432732057\n",
      "New best model found at epoch 285 with validation loss 1.2696455717086792\n",
      "Starting Epoch 286\n",
      "1.3176801075106082\n",
      "Validation loss: 1.2693686485290527\n",
      "mse 1.2693686599868363\n",
      "New best model found at epoch 286 with validation loss 1.2693686485290527\n",
      "Starting Epoch 287\n",
      "1.3170744128849194\n",
      "Validation loss: 1.2688767910003662\n",
      "mse 1.26887676048421\n",
      "New best model found at epoch 287 with validation loss 1.2688767910003662\n",
      "Starting Epoch 288\n",
      "1.316767850647802\n",
      "Validation loss: 1.268541932106018\n",
      "mse 1.2685418991834954\n",
      "New best model found at epoch 288 with validation loss 1.268541932106018\n",
      "Starting Epoch 289\n",
      "1.3162397223970164\n",
      "Validation loss: 1.2681440114974976\n",
      "mse 1.268143940616559\n",
      "New best model found at epoch 289 with validation loss 1.2681440114974976\n",
      "Starting Epoch 290\n",
      "1.3158749808435855\n",
      "Validation loss: 1.2676277160644531\n",
      "mse 1.2676277918468157\n",
      "New best model found at epoch 290 with validation loss 1.2676277160644531\n",
      "Starting Epoch 291\n",
      "1.315350713937179\n",
      "Validation loss: 1.2672315835952759\n",
      "mse 1.2672314588687095\n",
      "New best model found at epoch 291 with validation loss 1.2672315835952759\n",
      "Starting Epoch 292\n",
      "1.315005185811416\n",
      "Validation loss: 1.2667827606201172\n",
      "mse 1.2667827189268563\n",
      "New best model found at epoch 292 with validation loss 1.2667827606201172\n",
      "Starting Epoch 293\n",
      "1.3145198355550352\n",
      "Validation loss: 1.266448736190796\n",
      "mse 1.2664487549455614\n",
      "New best model found at epoch 293 with validation loss 1.266448736190796\n",
      "Starting Epoch 294\n",
      "1.3142743421637493\n",
      "Validation loss: 1.2658292055130005\n",
      "mse 1.2658292066419792\n",
      "New best model found at epoch 294 with validation loss 1.2658292055130005\n",
      "Starting Epoch 295\n",
      "1.3136554515880088\n",
      "Validation loss: 1.2653539180755615\n",
      "mse 1.2653540454908196\n",
      "New best model found at epoch 295 with validation loss 1.2653539180755615\n",
      "Starting Epoch 296\n",
      "1.3132279774417048\n",
      "Validation loss: 1.2651288509368896\n",
      "mse 1.2651288066762774\n",
      "New best model found at epoch 296 with validation loss 1.2651288509368896\n",
      "Starting Epoch 297\n",
      "1.312990084938381\n",
      "Validation loss: 1.2647610902786255\n",
      "mse 1.2647612235037304\n",
      "New best model found at epoch 297 with validation loss 1.2647610902786255\n",
      "Starting Epoch 298\n",
      "1.3124117773512136\n",
      "Validation loss: 1.2643282413482666\n",
      "mse 1.264328260763042\n",
      "New best model found at epoch 298 with validation loss 1.2643282413482666\n",
      "Starting Epoch 299\n",
      "1.3119960919670437\n",
      "Validation loss: 1.263946771621704\n",
      "mse 1.263946835225227\n",
      "New best model found at epoch 299 with validation loss 1.263946771621704\n",
      "Starting Epoch 300\n",
      "1.311649299186209\n",
      "Validation loss: 1.263770580291748\n",
      "mse 1.2637705896471563\n",
      "New best model found at epoch 300 with validation loss 1.263770580291748\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-40-20-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2d0b9",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 40 - 10 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "e52b392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "77e0e072-0b83-4222-894c-632f1789ba0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.0985054244165835\n",
      "Validation loss: 2.642518997192383\n",
      "mse 2.6425187750273817\n",
      "New best model found at epoch 1 with validation loss 2.642518997192383\n",
      "Starting Epoch 2\n",
      "2.8959206705508023\n",
      "Validation loss: 2.5263679027557373\n",
      "mse 2.52636757678944\n",
      "New best model found at epoch 2 with validation loss 2.5263679027557373\n",
      "Starting Epoch 3\n",
      "2.756403415099434\n",
      "Validation loss: 2.4195525646209717\n",
      "mse 2.4195526884100973\n",
      "New best model found at epoch 3 with validation loss 2.4195525646209717\n",
      "Starting Epoch 4\n",
      "2.6313251153282495\n",
      "Validation loss: 2.3193533420562744\n",
      "mse 2.3193534038640773\n",
      "New best model found at epoch 4 with validation loss 2.3193533420562744\n",
      "Starting Epoch 5\n",
      "2.517798154250435\n",
      "Validation loss: 2.2252118587493896\n",
      "mse 2.2252119697938566\n",
      "New best model found at epoch 5 with validation loss 2.2252118587493896\n",
      "Starting Epoch 6\n",
      "2.414812554483828\n",
      "Validation loss: 2.1412484645843506\n",
      "mse 2.141248722666902\n",
      "New best model found at epoch 6 with validation loss 2.1412484645843506\n",
      "Starting Epoch 7\n",
      "2.3230446577072144\n",
      "Validation loss: 2.06820011138916\n",
      "mse 2.0682000207384403\n",
      "New best model found at epoch 7 with validation loss 2.06820011138916\n",
      "Starting Epoch 8\n",
      "2.2426715311796768\n",
      "Validation loss: 2.0041024684906006\n",
      "mse 2.004102481864236\n",
      "New best model found at epoch 8 with validation loss 2.0041024684906006\n",
      "Starting Epoch 9\n",
      "2.171213445456132\n",
      "Validation loss: 1.9483691453933716\n",
      "mse 1.9483692133802295\n",
      "New best model found at epoch 9 with validation loss 1.9483691453933716\n",
      "Starting Epoch 10\n",
      "2.110305765400762\n",
      "Validation loss: 1.900466799736023\n",
      "mse 1.9004668191611562\n",
      "New best model found at epoch 10 with validation loss 1.900466799736023\n",
      "Starting Epoch 11\n",
      "2.0578555283339126\n",
      "Validation loss: 1.8592588901519775\n",
      "mse 1.8592589728398832\n",
      "New best model found at epoch 11 with validation loss 1.8592588901519775\n",
      "Starting Epoch 12\n",
      "2.0127771211707075\n",
      "Validation loss: 1.8230607509613037\n",
      "mse 1.8230609229587318\n",
      "New best model found at epoch 12 with validation loss 1.8230607509613037\n",
      "Starting Epoch 13\n",
      "1.9733117611511894\n",
      "Validation loss: 1.7907353639602661\n",
      "mse 1.790735403249711\n",
      "New best model found at epoch 13 with validation loss 1.7907353639602661\n",
      "Starting Epoch 14\n",
      "1.9377206149308577\n",
      "Validation loss: 1.7613153457641602\n",
      "mse 1.7613151847935553\n",
      "New best model found at epoch 14 with validation loss 1.7613153457641602\n",
      "Starting Epoch 15\n",
      "1.9061518752056619\n",
      "Validation loss: 1.734806776046753\n",
      "mse 1.7348067978676847\n",
      "New best model found at epoch 15 with validation loss 1.734806776046753\n",
      "Starting Epoch 16\n",
      "1.8781639233879421\n",
      "Validation loss: 1.7118635177612305\n",
      "mse 1.7118635404777052\n",
      "New best model found at epoch 16 with validation loss 1.7118635177612305\n",
      "Starting Epoch 17\n",
      "1.8534201072609944\n",
      "Validation loss: 1.6905896663665771\n",
      "mse 1.6905894496505647\n",
      "New best model found at epoch 17 with validation loss 1.6905896663665771\n",
      "Starting Epoch 18\n",
      "1.831417265145675\n",
      "Validation loss: 1.6715941429138184\n",
      "mse 1.6715941650538306\n",
      "New best model found at epoch 18 with validation loss 1.6715941429138184\n",
      "Starting Epoch 19\n",
      "1.8116342451261438\n",
      "Validation loss: 1.654787540435791\n",
      "mse 1.6547874482844\n",
      "New best model found at epoch 19 with validation loss 1.654787540435791\n",
      "Starting Epoch 20\n",
      "1.7936168753582498\n",
      "Validation loss: 1.6404892206192017\n",
      "mse 1.640489161466861\n",
      "New best model found at epoch 20 with validation loss 1.6404892206192017\n",
      "Starting Epoch 21\n",
      "1.7778689550316853\n",
      "Validation loss: 1.6278996467590332\n",
      "mse 1.627899654696636\n",
      "New best model found at epoch 21 with validation loss 1.6278996467590332\n",
      "Starting Epoch 22\n",
      "1.7639289316923723\n",
      "Validation loss: 1.6168841123580933\n",
      "mse 1.6168841201027198\n",
      "New best model found at epoch 22 with validation loss 1.6168841123580933\n",
      "Starting Epoch 23\n",
      "1.7516859769821167\n",
      "Validation loss: 1.6070857048034668\n",
      "mse 1.6070858917020943\n",
      "New best model found at epoch 23 with validation loss 1.6070857048034668\n",
      "Starting Epoch 24\n",
      "1.740686084913171\n",
      "Validation loss: 1.5979090929031372\n",
      "mse 1.5979091334455109\n",
      "New best model found at epoch 24 with validation loss 1.5979090929031372\n",
      "Starting Epoch 25\n",
      "1.7308208113131316\n",
      "Validation loss: 1.5894191265106201\n",
      "mse 1.589419153452452\n",
      "New best model found at epoch 25 with validation loss 1.5894191265106201\n",
      "Starting Epoch 26\n",
      "1.721735233845918\n",
      "Validation loss: 1.5813993215560913\n",
      "mse 1.581399321040849\n",
      "New best model found at epoch 26 with validation loss 1.5813993215560913\n",
      "Starting Epoch 27\n",
      "1.7132809732271277\n",
      "Validation loss: 1.5736668109893799\n",
      "mse 1.5736668311450974\n",
      "New best model found at epoch 27 with validation loss 1.5736668109893799\n",
      "Starting Epoch 28\n",
      "1.7052430018134739\n",
      "Validation loss: 1.565549612045288\n",
      "mse 1.5655495945153537\n",
      "New best model found at epoch 28 with validation loss 1.565549612045288\n",
      "Starting Epoch 29\n",
      "1.6967957071636035\n",
      "Validation loss: 1.5574051141738892\n",
      "mse 1.5574050604245255\n",
      "New best model found at epoch 29 with validation loss 1.5574051141738892\n",
      "Starting Epoch 30\n",
      "1.6885215044021606\n",
      "Validation loss: 1.5506962537765503\n",
      "mse 1.5506963468911057\n",
      "New best model found at epoch 30 with validation loss 1.5506962537765503\n",
      "Starting Epoch 31\n",
      "1.6812457364538442\n",
      "Validation loss: 1.5451217889785767\n",
      "mse 1.5451219424610343\n",
      "New best model found at epoch 31 with validation loss 1.5451217889785767\n",
      "Starting Epoch 32\n",
      "1.6746521721715513\n",
      "Validation loss: 1.5398625135421753\n",
      "mse 1.5398626901278851\n",
      "New best model found at epoch 32 with validation loss 1.5398625135421753\n",
      "Starting Epoch 33\n",
      "1.6685183514719424\n",
      "Validation loss: 1.5335417985916138\n",
      "mse 1.5335418590223733\n",
      "New best model found at epoch 33 with validation loss 1.5335417985916138\n",
      "Starting Epoch 34\n",
      "1.6620426126148389\n",
      "Validation loss: 1.5282937288284302\n",
      "mse 1.5282936880380984\n",
      "New best model found at epoch 34 with validation loss 1.5282937288284302\n",
      "Starting Epoch 35\n",
      "1.6563098897104678\n",
      "Validation loss: 1.5234342813491821\n",
      "mse 1.523434458411838\n",
      "New best model found at epoch 35 with validation loss 1.5234342813491821\n",
      "Starting Epoch 36\n",
      "1.651044462038123\n",
      "Validation loss: 1.518607258796692\n",
      "mse 1.5186072993452173\n",
      "New best model found at epoch 36 with validation loss 1.518607258796692\n",
      "Starting Epoch 37\n",
      "1.6460530239602793\n",
      "Validation loss: 1.5146591663360596\n",
      "mse 1.5146592088981485\n",
      "New best model found at epoch 37 with validation loss 1.5146591663360596\n",
      "Starting Epoch 38\n",
      "1.6412567081658735\n",
      "Validation loss: 1.5109107494354248\n",
      "mse 1.5109109954201754\n",
      "New best model found at epoch 38 with validation loss 1.5109107494354248\n",
      "Starting Epoch 39\n",
      "1.6368517849756323\n",
      "Validation loss: 1.5073381662368774\n",
      "mse 1.5073381384232099\n",
      "New best model found at epoch 39 with validation loss 1.5073381662368774\n",
      "Starting Epoch 40\n",
      "1.6324744587359221\n",
      "Validation loss: 1.50399649143219\n",
      "mse 1.503996451364599\n",
      "New best model found at epoch 40 with validation loss 1.50399649143219\n",
      "Starting Epoch 41\n",
      "1.628269436566726\n",
      "Validation loss: 1.5009349584579468\n",
      "mse 1.5009350017555825\n",
      "New best model found at epoch 41 with validation loss 1.5009349584579468\n",
      "Starting Epoch 42\n",
      "1.6241916599481\n",
      "Validation loss: 1.497758150100708\n",
      "mse 1.4977581938042852\n",
      "New best model found at epoch 42 with validation loss 1.497758150100708\n",
      "Starting Epoch 43\n",
      "1.6206040460130442\n",
      "Validation loss: 1.4951846599578857\n",
      "mse 1.4951846172813144\n",
      "New best model found at epoch 43 with validation loss 1.4951846599578857\n",
      "Starting Epoch 44\n",
      "1.6172075427096824\n",
      "Validation loss: 1.4926748275756836\n",
      "mse 1.4926748590954368\n",
      "New best model found at epoch 44 with validation loss 1.4926748275756836\n",
      "Starting Epoch 45\n",
      "1.614041831182397\n",
      "Validation loss: 1.4905520677566528\n",
      "mse 1.4905520666099967\n",
      "New best model found at epoch 45 with validation loss 1.4905520677566528\n",
      "Starting Epoch 46\n",
      "1.6109639950420545\n",
      "Validation loss: 1.488619089126587\n",
      "mse 1.4886191047284596\n",
      "New best model found at epoch 46 with validation loss 1.488619089126587\n",
      "Starting Epoch 47\n",
      "1.6079880050990893\n",
      "Validation loss: 1.4865291118621826\n",
      "mse 1.486529209918038\n",
      "New best model found at epoch 47 with validation loss 1.4865291118621826\n",
      "Starting Epoch 48\n",
      "1.6051375321719958\n",
      "Validation loss: 1.4846917390823364\n",
      "mse 1.4846915542193921\n",
      "New best model found at epoch 48 with validation loss 1.4846917390823364\n",
      "Starting Epoch 49\n",
      "1.6024769337280937\n",
      "Validation loss: 1.4828311204910278\n",
      "mse 1.4828311495935842\n",
      "New best model found at epoch 49 with validation loss 1.4828311204910278\n",
      "Starting Epoch 50\n",
      "1.5999263447263967\n",
      "Validation loss: 1.4814682006835938\n",
      "mse 1.4814681582336793\n",
      "New best model found at epoch 50 with validation loss 1.4814682006835938\n",
      "Starting Epoch 51\n",
      "1.597496465496395\n",
      "Validation loss: 1.4798074960708618\n",
      "mse 1.4798075460334164\n",
      "New best model found at epoch 51 with validation loss 1.4798074960708618\n",
      "Starting Epoch 52\n",
      "1.5950472173483476\n",
      "Validation loss: 1.478416085243225\n",
      "mse 1.4784160474731787\n",
      "New best model found at epoch 52 with validation loss 1.478416085243225\n",
      "Starting Epoch 53\n",
      "1.5928224143774614\n",
      "Validation loss: 1.4770219326019287\n",
      "mse 1.4770219021132718\n",
      "New best model found at epoch 53 with validation loss 1.4770219326019287\n",
      "Starting Epoch 54\n",
      "1.5907188213389853\n",
      "Validation loss: 1.475851058959961\n",
      "mse 1.475851149627886\n",
      "New best model found at epoch 54 with validation loss 1.475851058959961\n",
      "Starting Epoch 55\n",
      "1.5884711846061375\n",
      "Validation loss: 1.4746441841125488\n",
      "mse 1.4746440003160246\n",
      "New best model found at epoch 55 with validation loss 1.4746441841125488\n",
      "Starting Epoch 56\n",
      "1.5865209828252378\n",
      "Validation loss: 1.4733216762542725\n",
      "mse 1.4733216253799348\n",
      "New best model found at epoch 56 with validation loss 1.4733216762542725\n",
      "Starting Epoch 57\n",
      "1.584528974864794\n",
      "Validation loss: 1.4720642566680908\n",
      "mse 1.4720642117614655\n",
      "New best model found at epoch 57 with validation loss 1.4720642566680908\n",
      "Starting Epoch 58\n",
      "1.5827425485071929\n",
      "Validation loss: 1.4708982706069946\n",
      "mse 1.4708983116009093\n",
      "New best model found at epoch 58 with validation loss 1.4708982706069946\n",
      "Starting Epoch 59\n",
      "1.5807717442512512\n",
      "Validation loss: 1.4701417684555054\n",
      "mse 1.4701417682018998\n",
      "New best model found at epoch 59 with validation loss 1.4701417684555054\n",
      "Starting Epoch 60\n",
      "1.5791108400925347\n",
      "Validation loss: 1.4692517518997192\n",
      "mse 1.4692517424838571\n",
      "New best model found at epoch 60 with validation loss 1.4692517518997192\n",
      "Starting Epoch 61\n",
      "1.5776418499324634\n",
      "Validation loss: 1.4682015180587769\n",
      "mse 1.4682014649956228\n",
      "New best model found at epoch 61 with validation loss 1.4682015180587769\n",
      "Starting Epoch 62\n",
      "1.5759506899377573\n",
      "Validation loss: 1.4673495292663574\n",
      "mse 1.467349601236575\n",
      "New best model found at epoch 62 with validation loss 1.4673495292663574\n",
      "Starting Epoch 63\n",
      "1.5744949501493704\n",
      "Validation loss: 1.4664642810821533\n",
      "mse 1.4664641702256924\n",
      "New best model found at epoch 63 with validation loss 1.4664642810821533\n",
      "Starting Epoch 64\n",
      "1.5729082926459934\n",
      "Validation loss: 1.465699553489685\n",
      "mse 1.4656995532432056\n",
      "New best model found at epoch 64 with validation loss 1.465699553489685\n",
      "Starting Epoch 65\n",
      "1.5714505366657092\n",
      "Validation loss: 1.465278148651123\n",
      "mse 1.4652781853551795\n",
      "New best model found at epoch 65 with validation loss 1.465278148651123\n",
      "Starting Epoch 66\n",
      "1.5699082872141963\n",
      "Validation loss: 1.4645863771438599\n",
      "mse 1.4645864564974351\n",
      "New best model found at epoch 66 with validation loss 1.4645863771438599\n",
      "Starting Epoch 67\n",
      "1.5685042583424111\n",
      "Validation loss: 1.4641140699386597\n",
      "mse 1.4641140616301065\n",
      "New best model found at epoch 67 with validation loss 1.4641140699386597\n",
      "Starting Epoch 68\n",
      "1.5670053647912068\n",
      "Validation loss: 1.4633837938308716\n",
      "mse 1.463383782148587\n",
      "New best model found at epoch 68 with validation loss 1.4633837938308716\n",
      "Starting Epoch 69\n",
      "1.5655557461406873\n",
      "Validation loss: 1.4628468751907349\n",
      "mse 1.4628469307888818\n",
      "New best model found at epoch 69 with validation loss 1.4628468751907349\n",
      "Starting Epoch 70\n",
      "1.5642455375712851\n",
      "Validation loss: 1.4623281955718994\n",
      "mse 1.462328196145136\n",
      "New best model found at epoch 70 with validation loss 1.4623281955718994\n",
      "Starting Epoch 71\n",
      "1.5629322347433672\n",
      "Validation loss: 1.461667776107788\n",
      "mse 1.4616677218195258\n",
      "New best model found at epoch 71 with validation loss 1.461667776107788\n",
      "Starting Epoch 72\n",
      "1.5615885750107144\n",
      "Validation loss: 1.4611362218856812\n",
      "mse 1.4611362776435783\n",
      "New best model found at epoch 72 with validation loss 1.4611362218856812\n",
      "Starting Epoch 73\n",
      "1.5603355635767397\n",
      "Validation loss: 1.4604507684707642\n",
      "mse 1.460450763551781\n",
      "New best model found at epoch 73 with validation loss 1.4604507684707642\n",
      "Starting Epoch 74\n",
      "1.559005478154058\n",
      "Validation loss: 1.4599329233169556\n",
      "mse 1.459933008615702\n",
      "New best model found at epoch 74 with validation loss 1.4599329233169556\n",
      "Starting Epoch 75\n",
      "1.5578099929768106\n",
      "Validation loss: 1.4593331813812256\n",
      "mse 1.4593331784050052\n",
      "New best model found at epoch 75 with validation loss 1.4593331813812256\n",
      "Starting Epoch 76\n",
      "1.556554755438929\n",
      "Validation loss: 1.4586169719696045\n",
      "mse 1.4586170154025064\n",
      "New best model found at epoch 76 with validation loss 1.4586169719696045\n",
      "Starting Epoch 77\n",
      "1.5553079999011497\n",
      "Validation loss: 1.4581516981124878\n",
      "mse 1.4581516192769675\n",
      "New best model found at epoch 77 with validation loss 1.4581516981124878\n",
      "Starting Epoch 78\n",
      "1.554179258968519\n",
      "Validation loss: 1.4575715065002441\n",
      "mse 1.4575714888836648\n",
      "New best model found at epoch 78 with validation loss 1.4575715065002441\n",
      "Starting Epoch 79\n",
      "1.5531099153601604\n",
      "Validation loss: 1.456973910331726\n",
      "mse 1.4569739692066377\n",
      "New best model found at epoch 79 with validation loss 1.456973910331726\n",
      "Starting Epoch 80\n",
      "1.5519549457923225\n",
      "Validation loss: 1.456464409828186\n",
      "mse 1.4564643069352072\n",
      "New best model found at epoch 80 with validation loss 1.456464409828186\n",
      "Starting Epoch 81\n",
      "1.550900910211646\n",
      "Validation loss: 1.4561642408370972\n",
      "mse 1.4561643933274357\n",
      "New best model found at epoch 81 with validation loss 1.4561642408370972\n",
      "Starting Epoch 82\n",
      "1.5498231571653616\n",
      "Validation loss: 1.4556413888931274\n",
      "mse 1.4556415524508073\n",
      "New best model found at epoch 82 with validation loss 1.4556413888931274\n",
      "Starting Epoch 83\n",
      "1.5486225174820942\n",
      "Validation loss: 1.4551184177398682\n",
      "mse 1.4551185059446656\n",
      "New best model found at epoch 83 with validation loss 1.4551184177398682\n",
      "Starting Epoch 84\n",
      "1.54761708041896\n",
      "Validation loss: 1.454576849937439\n",
      "mse 1.4545768532434455\n",
      "New best model found at epoch 84 with validation loss 1.454576849937439\n",
      "Starting Epoch 85\n",
      "1.5465243821558745\n",
      "Validation loss: 1.4540586471557617\n",
      "mse 1.454058738158883\n",
      "New best model found at epoch 85 with validation loss 1.4540586471557617\n",
      "Starting Epoch 86\n",
      "1.5454887540444084\n",
      "Validation loss: 1.4536211490631104\n",
      "mse 1.453621296672071\n",
      "New best model found at epoch 86 with validation loss 1.4536211490631104\n",
      "Starting Epoch 87\n",
      "1.54447610222775\n",
      "Validation loss: 1.4532201290130615\n",
      "mse 1.4532202127270184\n",
      "New best model found at epoch 87 with validation loss 1.4532201290130615\n",
      "Starting Epoch 88\n",
      "1.5434661896332451\n",
      "Validation loss: 1.4527761936187744\n",
      "mse 1.4527762620090745\n",
      "New best model found at epoch 88 with validation loss 1.4527761936187744\n",
      "Starting Epoch 89\n",
      "1.5424395514571148\n",
      "Validation loss: 1.4528100490570068\n",
      "mse 1.4528100914488642\n",
      "Starting Epoch 90\n",
      "1.5414282783218052\n",
      "Validation loss: 1.4525492191314697\n",
      "mse 1.452549209735995\n",
      "New best model found at epoch 90 with validation loss 1.4525492191314697\n",
      "Starting Epoch 91\n",
      "1.540457344573477\n",
      "Validation loss: 1.4524765014648438\n",
      "mse 1.4524765415503198\n",
      "New best model found at epoch 91 with validation loss 1.4524765014648438\n",
      "Starting Epoch 92\n",
      "1.539359696533369\n",
      "Validation loss: 1.4521273374557495\n",
      "mse 1.4521273092724898\n",
      "New best model found at epoch 92 with validation loss 1.4521273374557495\n",
      "Starting Epoch 93\n",
      "1.538320647633594\n",
      "Validation loss: 1.4516255855560303\n",
      "mse 1.4516257188700568\n",
      "New best model found at epoch 93 with validation loss 1.4516255855560303\n",
      "Starting Epoch 94\n",
      "1.5373677248540132\n",
      "Validation loss: 1.450702428817749\n",
      "mse 1.4507024436156852\n",
      "New best model found at epoch 94 with validation loss 1.450702428817749\n",
      "Starting Epoch 95\n",
      "1.536456559015357\n",
      "Validation loss: 1.4501444101333618\n",
      "mse 1.4501443898996451\n",
      "New best model found at epoch 95 with validation loss 1.4501444101333618\n",
      "Starting Epoch 96\n",
      "1.5355272940967395\n",
      "Validation loss: 1.4495068788528442\n",
      "mse 1.4495067339217402\n",
      "New best model found at epoch 96 with validation loss 1.4495068788528442\n",
      "Starting Epoch 97\n",
      "1.5345805235531018\n",
      "Validation loss: 1.448891282081604\n",
      "mse 1.4488911935504023\n",
      "New best model found at epoch 97 with validation loss 1.448891282081604\n",
      "Starting Epoch 98\n",
      "1.5337777889293174\n",
      "Validation loss: 1.4484797716140747\n",
      "mse 1.4484797508717422\n",
      "New best model found at epoch 98 with validation loss 1.4484797716140747\n",
      "Starting Epoch 99\n",
      "1.532860022524129\n",
      "Validation loss: 1.4480048418045044\n",
      "mse 1.4480048749811059\n",
      "New best model found at epoch 99 with validation loss 1.4480048418045044\n",
      "Starting Epoch 100\n",
      "1.5320181457892708\n",
      "Validation loss: 1.4473068714141846\n",
      "mse 1.4473068048870636\n",
      "New best model found at epoch 100 with validation loss 1.4473068714141846\n",
      "Starting Epoch 101\n",
      "1.5310737309248552\n",
      "Validation loss: 1.446781873703003\n",
      "mse 1.4467819309440557\n",
      "New best model found at epoch 101 with validation loss 1.446781873703003\n",
      "Starting Epoch 102\n",
      "1.530212145784627\n",
      "Validation loss: 1.4460468292236328\n",
      "mse 1.4460467789705307\n",
      "New best model found at epoch 102 with validation loss 1.4460468292236328\n",
      "Starting Epoch 103\n",
      "1.5293773101723713\n",
      "Validation loss: 1.4454072713851929\n",
      "mse 1.4454073789689028\n",
      "New best model found at epoch 103 with validation loss 1.4454072713851929\n",
      "Starting Epoch 104\n",
      "1.5285709733548372\n",
      "Validation loss: 1.4447684288024902\n",
      "mse 1.4447685024392858\n",
      "New best model found at epoch 104 with validation loss 1.4447684288024902\n",
      "Starting Epoch 105\n",
      "1.5277580981669219\n",
      "Validation loss: 1.4438420534133911\n",
      "mse 1.4438421275754767\n",
      "New best model found at epoch 105 with validation loss 1.4438420534133911\n",
      "Starting Epoch 106\n",
      "1.5270356717317\n",
      "Validation loss: 1.443727970123291\n",
      "mse 1.4437280130182273\n",
      "New best model found at epoch 106 with validation loss 1.443727970123291\n",
      "Starting Epoch 107\n",
      "1.5261769216993581\n",
      "Validation loss: 1.4431307315826416\n",
      "mse 1.4431306879144241\n",
      "New best model found at epoch 107 with validation loss 1.4431307315826416\n",
      "Starting Epoch 108\n",
      "1.5253681644149448\n",
      "Validation loss: 1.442336916923523\n",
      "mse 1.4423368878704486\n",
      "New best model found at epoch 108 with validation loss 1.442336916923523\n",
      "Starting Epoch 109\n",
      "1.5247262249822202\n",
      "Validation loss: 1.442037582397461\n",
      "mse 1.4420377250942191\n",
      "New best model found at epoch 109 with validation loss 1.442037582397461\n",
      "Starting Epoch 110\n",
      "1.5238991146502288\n",
      "Validation loss: 1.4414870738983154\n",
      "mse 1.441487132947412\n",
      "New best model found at epoch 110 with validation loss 1.4414870738983154\n",
      "Starting Epoch 111\n",
      "1.5231963629307954\n",
      "Validation loss: 1.4407329559326172\n",
      "mse 1.4407328976051172\n",
      "New best model found at epoch 111 with validation loss 1.4407329559326172\n",
      "Starting Epoch 112\n",
      "1.5224866322849109\n",
      "Validation loss: 1.4403351545333862\n",
      "mse 1.4403351467016712\n",
      "New best model found at epoch 112 with validation loss 1.4403351545333862\n",
      "Starting Epoch 113\n",
      "1.521787552729897\n",
      "Validation loss: 1.4398765563964844\n",
      "mse 1.4398766792989\n",
      "New best model found at epoch 113 with validation loss 1.4398765563964844\n",
      "Starting Epoch 114\n",
      "1.52099486278451\n",
      "Validation loss: 1.4395103454589844\n",
      "mse 1.4395103199927415\n",
      "New best model found at epoch 114 with validation loss 1.4395103454589844\n",
      "Starting Epoch 115\n",
      "1.5202780832415042\n",
      "Validation loss: 1.4389162063598633\n",
      "mse 1.4389161351841504\n",
      "New best model found at epoch 115 with validation loss 1.4389162063598633\n",
      "Starting Epoch 116\n",
      "1.5194844629453577\n",
      "Validation loss: 1.438488245010376\n",
      "mse 1.438488349156568\n",
      "New best model found at epoch 116 with validation loss 1.438488245010376\n",
      "Starting Epoch 117\n",
      "1.518891611824865\n",
      "Validation loss: 1.4381349086761475\n",
      "mse 1.4381349192570392\n",
      "New best model found at epoch 117 with validation loss 1.4381349086761475\n",
      "Starting Epoch 118\n",
      "1.5181105577427407\n",
      "Validation loss: 1.4376108646392822\n",
      "mse 1.437610921576647\n",
      "New best model found at epoch 118 with validation loss 1.4376108646392822\n",
      "Starting Epoch 119\n",
      "1.5175034844357034\n",
      "Validation loss: 1.437050223350525\n",
      "mse 1.4370501450064188\n",
      "New best model found at epoch 119 with validation loss 1.437050223350525\n",
      "Starting Epoch 120\n",
      "1.5167502061180447\n",
      "Validation loss: 1.4368451833724976\n",
      "mse 1.4368452382192223\n",
      "New best model found at epoch 120 with validation loss 1.4368451833724976\n",
      "Starting Epoch 121\n",
      "1.5161586792572685\n",
      "Validation loss: 1.4365949630737305\n",
      "mse 1.4365948980733385\n",
      "New best model found at epoch 121 with validation loss 1.4365949630737305\n",
      "Starting Epoch 122\n",
      "1.515468752902487\n",
      "Validation loss: 1.4359278678894043\n",
      "mse 1.4359279169684587\n",
      "New best model found at epoch 122 with validation loss 1.4359278678894043\n",
      "Starting Epoch 123\n",
      "1.51478678247203\n",
      "Validation loss: 1.4357190132141113\n",
      "mse 1.4357189330606934\n",
      "New best model found at epoch 123 with validation loss 1.4357190132141113\n",
      "Starting Epoch 124\n",
      "1.5141455557035364\n",
      "Validation loss: 1.4352302551269531\n",
      "mse 1.435230145488301\n",
      "New best model found at epoch 124 with validation loss 1.4352302551269531\n",
      "Starting Epoch 125\n",
      "1.513462097748466\n",
      "Validation loss: 1.4348317384719849\n",
      "mse 1.434831835365341\n",
      "New best model found at epoch 125 with validation loss 1.4348317384719849\n",
      "Starting Epoch 126\n",
      "1.5127820087515789\n",
      "Validation loss: 1.4341198205947876\n",
      "mse 1.4341198150831194\n",
      "New best model found at epoch 126 with validation loss 1.4341198205947876\n",
      "Starting Epoch 127\n",
      "1.512149875578673\n",
      "Validation loss: 1.433553695678711\n",
      "mse 1.4335538015170304\n",
      "New best model found at epoch 127 with validation loss 1.433553695678711\n",
      "Starting Epoch 128\n",
      "1.5115406720534614\n",
      "Validation loss: 1.4331709146499634\n",
      "mse 1.433170948850888\n",
      "New best model found at epoch 128 with validation loss 1.4331709146499634\n",
      "Starting Epoch 129\n",
      "1.5108563174372134\n",
      "Validation loss: 1.432601809501648\n",
      "mse 1.4326018194530703\n",
      "New best model found at epoch 129 with validation loss 1.432601809501648\n",
      "Starting Epoch 130\n",
      "1.5102790075799692\n",
      "Validation loss: 1.432399868965149\n",
      "mse 1.4323997711543472\n",
      "New best model found at epoch 130 with validation loss 1.432399868965149\n",
      "Starting Epoch 131\n",
      "1.5096173364183176\n",
      "Validation loss: 1.4318212270736694\n",
      "mse 1.4318211642908665\n",
      "New best model found at epoch 131 with validation loss 1.4318212270736694\n",
      "Starting Epoch 132\n",
      "1.5089487277943154\n",
      "Validation loss: 1.4315592050552368\n",
      "mse 1.4315592124632897\n",
      "New best model found at epoch 132 with validation loss 1.4315592050552368\n",
      "Starting Epoch 133\n",
      "1.508360567300216\n",
      "Validation loss: 1.4310264587402344\n",
      "mse 1.4310264184959374\n",
      "New best model found at epoch 133 with validation loss 1.4310264587402344\n",
      "Starting Epoch 134\n",
      "1.5077982130257979\n",
      "Validation loss: 1.4305394887924194\n",
      "mse 1.4305395655622353\n",
      "New best model found at epoch 134 with validation loss 1.4305394887924194\n",
      "Starting Epoch 135\n",
      "1.5071951435959858\n",
      "Validation loss: 1.430342197418213\n",
      "mse 1.4303422022219776\n",
      "New best model found at epoch 135 with validation loss 1.430342197418213\n",
      "Starting Epoch 136\n",
      "1.5066154314124065\n",
      "Validation loss: 1.4298454523086548\n",
      "mse 1.4298453876224617\n",
      "New best model found at epoch 136 with validation loss 1.4298454523086548\n",
      "Starting Epoch 137\n",
      "1.5059174247409985\n",
      "Validation loss: 1.42933988571167\n",
      "mse 1.429339753880186\n",
      "New best model found at epoch 137 with validation loss 1.42933988571167\n",
      "Starting Epoch 138\n",
      "1.505476625069328\n",
      "Validation loss: 1.4292429685592651\n",
      "mse 1.429243007460623\n",
      "New best model found at epoch 138 with validation loss 1.4292429685592651\n",
      "Starting Epoch 139\n",
      "1.504767506018929\n",
      "Validation loss: 1.4285964965820312\n",
      "mse 1.4285967531816595\n",
      "New best model found at epoch 139 with validation loss 1.4285964965820312\n",
      "Starting Epoch 140\n",
      "1.504295527935028\n",
      "Validation loss: 1.428590178489685\n",
      "mse 1.428590047701721\n",
      "New best model found at epoch 140 with validation loss 1.428590178489685\n",
      "Starting Epoch 141\n",
      "1.503659795159879\n",
      "Validation loss: 1.4280645847320557\n",
      "mse 1.4280646009982183\n",
      "New best model found at epoch 141 with validation loss 1.4280645847320557\n",
      "Starting Epoch 142\n",
      "1.5030637331630872\n",
      "Validation loss: 1.4276366233825684\n",
      "mse 1.4276365618685214\n",
      "New best model found at epoch 142 with validation loss 1.4276366233825684\n",
      "Starting Epoch 143\n",
      "1.5025104543437129\n",
      "Validation loss: 1.4270228147506714\n",
      "mse 1.4270226776356572\n",
      "New best model found at epoch 143 with validation loss 1.4270228147506714\n",
      "Starting Epoch 144\n",
      "1.5020281180091526\n",
      "Validation loss: 1.4271849393844604\n",
      "mse 1.42718505287531\n",
      "Starting Epoch 145\n",
      "1.5013340711593628\n",
      "Validation loss: 1.4266443252563477\n",
      "mse 1.426644305634785\n",
      "New best model found at epoch 145 with validation loss 1.4266443252563477\n",
      "Starting Epoch 146\n",
      "1.5007962247599727\n",
      "Validation loss: 1.4262843132019043\n",
      "mse 1.4262844928065577\n",
      "New best model found at epoch 146 with validation loss 1.4262843132019043\n",
      "Starting Epoch 147\n",
      "1.5001674579537434\n",
      "Validation loss: 1.426034927368164\n",
      "mse 1.426034808640521\n",
      "New best model found at epoch 147 with validation loss 1.426034927368164\n",
      "Starting Epoch 148\n",
      "1.4997244632762412\n",
      "Validation loss: 1.4259443283081055\n",
      "mse 1.4259442986045308\n",
      "New best model found at epoch 148 with validation loss 1.4259443283081055\n",
      "Starting Epoch 149\n",
      "1.4990227041037187\n",
      "Validation loss: 1.4256689548492432\n",
      "mse 1.4256689854716735\n",
      "New best model found at epoch 149 with validation loss 1.4256689548492432\n",
      "Starting Epoch 150\n",
      "1.4984336702719978\n",
      "Validation loss: 1.4254664182662964\n",
      "mse 1.4254665707114507\n",
      "New best model found at epoch 150 with validation loss 1.4254664182662964\n",
      "Starting Epoch 151\n",
      "1.4979289148164832\n",
      "Validation loss: 1.4253979921340942\n",
      "mse 1.4253978460900096\n",
      "New best model found at epoch 151 with validation loss 1.4253979921340942\n",
      "Starting Epoch 152\n",
      "1.4973480831021848\n",
      "Validation loss: 1.4252756834030151\n",
      "mse 1.4252758244486297\n",
      "New best model found at epoch 152 with validation loss 1.4252756834030151\n",
      "Starting Epoch 153\n",
      "1.4967505180317422\n",
      "Validation loss: 1.424907922744751\n",
      "mse 1.4249078644070703\n",
      "New best model found at epoch 153 with validation loss 1.424907922744751\n",
      "Starting Epoch 154\n",
      "1.4962752331858096\n",
      "Validation loss: 1.4245740175247192\n",
      "mse 1.4245740343925217\n",
      "New best model found at epoch 154 with validation loss 1.4245740175247192\n",
      "Starting Epoch 155\n",
      "1.4956418949624766\n",
      "Validation loss: 1.4243488311767578\n",
      "mse 1.4243488341328514\n",
      "New best model found at epoch 155 with validation loss 1.4243488311767578\n",
      "Starting Epoch 156\n",
      "1.4951448751532512\n",
      "Validation loss: 1.4243041276931763\n",
      "mse 1.4243041771625207\n",
      "New best model found at epoch 156 with validation loss 1.4243041276931763\n",
      "Starting Epoch 157\n",
      "1.4946861267089844\n",
      "Validation loss: 1.4242268800735474\n",
      "mse 1.4242270039041518\n",
      "New best model found at epoch 157 with validation loss 1.4242268800735474\n",
      "Starting Epoch 158\n",
      "1.4940213353737541\n",
      "Validation loss: 1.4239466190338135\n",
      "mse 1.423946662437863\n",
      "New best model found at epoch 158 with validation loss 1.4239466190338135\n",
      "Starting Epoch 159\n",
      "1.4934859820034192\n",
      "Validation loss: 1.423774003982544\n",
      "mse 1.4237739934293399\n",
      "New best model found at epoch 159 with validation loss 1.423774003982544\n",
      "Starting Epoch 160\n",
      "1.4929639541584512\n",
      "Validation loss: 1.423641324043274\n",
      "mse 1.4236412699609664\n",
      "New best model found at epoch 160 with validation loss 1.423641324043274\n",
      "Starting Epoch 161\n",
      "1.492418162200762\n",
      "Validation loss: 1.4235421419143677\n",
      "mse 1.4235421447235341\n",
      "New best model found at epoch 161 with validation loss 1.4235421419143677\n",
      "Starting Epoch 162\n",
      "1.4918601849804753\n",
      "Validation loss: 1.4230879545211792\n",
      "mse 1.423087846225363\n",
      "New best model found at epoch 162 with validation loss 1.4230879545211792\n",
      "Starting Epoch 163\n",
      "1.4913806759792825\n",
      "Validation loss: 1.4226176738739014\n",
      "mse 1.4226177077355437\n",
      "New best model found at epoch 163 with validation loss 1.4226176738739014\n",
      "Starting Epoch 164\n",
      "1.4908608146335767\n",
      "Validation loss: 1.4223438501358032\n",
      "mse 1.4223438308108534\n",
      "New best model found at epoch 164 with validation loss 1.4223438501358032\n",
      "Starting Epoch 165\n",
      "1.490370265815569\n",
      "Validation loss: 1.4219969511032104\n",
      "mse 1.4219969529311425\n",
      "New best model found at epoch 165 with validation loss 1.4219969511032104\n",
      "Starting Epoch 166\n",
      "1.4898423863493877\n",
      "Validation loss: 1.4214282035827637\n",
      "mse 1.4214283280144366\n",
      "New best model found at epoch 166 with validation loss 1.4214282035827637\n",
      "Starting Epoch 167\n",
      "1.4893909044887708\n",
      "Validation loss: 1.4211528301239014\n",
      "mse 1.4211528292098994\n",
      "New best model found at epoch 167 with validation loss 1.4211528301239014\n",
      "Starting Epoch 168\n",
      "1.4888609673665918\n",
      "Validation loss: 1.4208511114120483\n",
      "mse 1.420851137488094\n",
      "New best model found at epoch 168 with validation loss 1.4208511114120483\n",
      "Starting Epoch 169\n",
      "1.4884064923162046\n",
      "Validation loss: 1.420462727546692\n",
      "mse 1.4204627899961315\n",
      "New best model found at epoch 169 with validation loss 1.420462727546692\n",
      "Starting Epoch 170\n",
      "1.4878693430320076\n",
      "Validation loss: 1.4200129508972168\n",
      "mse 1.420013065882776\n",
      "New best model found at epoch 170 with validation loss 1.4200129508972168\n",
      "Starting Epoch 171\n",
      "1.4874614788138347\n",
      "Validation loss: 1.4197232723236084\n",
      "mse 1.4197232734550806\n",
      "New best model found at epoch 171 with validation loss 1.4197232723236084\n",
      "Starting Epoch 172\n",
      "1.4869305543277576\n",
      "Validation loss: 1.419313669204712\n",
      "mse 1.4193137570222576\n",
      "New best model found at epoch 172 with validation loss 1.419313669204712\n",
      "Starting Epoch 173\n",
      "1.4865136742591858\n",
      "Validation loss: 1.419129729270935\n",
      "mse 1.4191296996661507\n",
      "New best model found at epoch 173 with validation loss 1.419129729270935\n",
      "Starting Epoch 174\n",
      "1.4859459063281184\n",
      "Validation loss: 1.4187289476394653\n",
      "mse 1.4187289340561253\n",
      "New best model found at epoch 174 with validation loss 1.4187289476394653\n",
      "Starting Epoch 175\n",
      "1.4855621431184851\n",
      "Validation loss: 1.4185525178909302\n",
      "mse 1.4185524299578107\n",
      "New best model found at epoch 175 with validation loss 1.4185525178909302\n",
      "Starting Epoch 176\n",
      "1.485027403935142\n",
      "Validation loss: 1.4183907508850098\n",
      "mse 1.4183907731553378\n",
      "New best model found at epoch 176 with validation loss 1.4183907508850098\n",
      "Starting Epoch 177\n",
      "1.484635573366414\n",
      "Validation loss: 1.4180546998977661\n",
      "mse 1.4180546901099997\n",
      "New best model found at epoch 177 with validation loss 1.4180546998977661\n",
      "Starting Epoch 178\n",
      "1.484147776728091\n",
      "Validation loss: 1.4176419973373413\n",
      "mse 1.4176419114870955\n",
      "New best model found at epoch 178 with validation loss 1.4176419973373413\n",
      "Starting Epoch 179\n",
      "1.4836783590524092\n",
      "Validation loss: 1.4172836542129517\n",
      "mse 1.417283564767993\n",
      "New best model found at epoch 179 with validation loss 1.4172836542129517\n",
      "Starting Epoch 180\n",
      "1.483243880064591\n",
      "Validation loss: 1.4171382188796997\n",
      "mse 1.4171382593888426\n",
      "New best model found at epoch 180 with validation loss 1.4171382188796997\n",
      "Starting Epoch 181\n",
      "1.482754930205967\n",
      "Validation loss: 1.4168078899383545\n",
      "mse 1.4168078661398193\n",
      "New best model found at epoch 181 with validation loss 1.4168078899383545\n",
      "Starting Epoch 182\n",
      "1.482285792412965\n",
      "Validation loss: 1.4166935682296753\n",
      "mse 1.4166935808170096\n",
      "New best model found at epoch 182 with validation loss 1.4166935682296753\n",
      "Starting Epoch 183\n",
      "1.4818683499875276\n",
      "Validation loss: 1.4163674116134644\n",
      "mse 1.4163672835984784\n",
      "New best model found at epoch 183 with validation loss 1.4163674116134644\n",
      "Starting Epoch 184\n",
      "1.481476858906124\n",
      "Validation loss: 1.4161447286605835\n",
      "mse 1.4161448747942729\n",
      "New best model found at epoch 184 with validation loss 1.4161447286605835\n",
      "Starting Epoch 185\n",
      "1.4810177398764568\n",
      "Validation loss: 1.4157767295837402\n",
      "mse 1.415776666301884\n",
      "New best model found at epoch 185 with validation loss 1.4157767295837402\n",
      "Starting Epoch 186\n",
      "1.480524972729061\n",
      "Validation loss: 1.4156020879745483\n",
      "mse 1.4156019518562126\n",
      "New best model found at epoch 186 with validation loss 1.4156020879745483\n",
      "Starting Epoch 187\n",
      "1.480148743028226\n",
      "Validation loss: 1.4153265953063965\n",
      "mse 1.4153267809972347\n",
      "New best model found at epoch 187 with validation loss 1.4153265953063965\n",
      "Starting Epoch 188\n",
      "1.4796595599340356\n",
      "Validation loss: 1.4149833917617798\n",
      "mse 1.4149833150348514\n",
      "New best model found at epoch 188 with validation loss 1.4149833917617798\n",
      "Starting Epoch 189\n",
      "1.4792436724123748\n",
      "Validation loss: 1.4147273302078247\n",
      "mse 1.4147272809433542\n",
      "New best model found at epoch 189 with validation loss 1.4147273302078247\n",
      "Starting Epoch 190\n",
      "1.4788160479587058\n",
      "Validation loss: 1.4145725965499878\n",
      "mse 1.4145725992990563\n",
      "New best model found at epoch 190 with validation loss 1.4145725965499878\n",
      "Starting Epoch 191\n",
      "1.4783601527628691\n",
      "Validation loss: 1.4142094850540161\n",
      "mse 1.4142095005273092\n",
      "New best model found at epoch 191 with validation loss 1.4142094850540161\n",
      "Starting Epoch 192\n",
      "1.4779586947482566\n",
      "Validation loss: 1.4140424728393555\n",
      "mse 1.4140424363340622\n",
      "New best model found at epoch 192 with validation loss 1.4140424728393555\n",
      "Starting Epoch 193\n",
      "1.4775014856587285\n",
      "Validation loss: 1.413688063621521\n",
      "mse 1.4136881153366618\n",
      "New best model found at epoch 193 with validation loss 1.413688063621521\n",
      "Starting Epoch 194\n",
      "1.4771245303361311\n",
      "Validation loss: 1.4136412143707275\n",
      "mse 1.413641262054846\n",
      "New best model found at epoch 194 with validation loss 1.4136412143707275\n",
      "Starting Epoch 195\n",
      "1.4766455577767414\n",
      "Validation loss: 1.413311243057251\n",
      "mse 1.4133111386722321\n",
      "New best model found at epoch 195 with validation loss 1.413311243057251\n",
      "Starting Epoch 196\n",
      "1.4762587469557058\n",
      "Validation loss: 1.4129204750061035\n",
      "mse 1.412920406727043\n",
      "New best model found at epoch 196 with validation loss 1.4129204750061035\n",
      "Starting Epoch 197\n",
      "1.4758723974227905\n",
      "Validation loss: 1.412670373916626\n",
      "mse 1.4126704701152801\n",
      "New best model found at epoch 197 with validation loss 1.412670373916626\n",
      "Starting Epoch 198\n",
      "1.4754851512286975\n",
      "Validation loss: 1.4125310182571411\n",
      "mse 1.4125310404992115\n",
      "New best model found at epoch 198 with validation loss 1.4125310182571411\n",
      "Starting Epoch 199\n",
      "1.475084232247394\n",
      "Validation loss: 1.4124155044555664\n",
      "mse 1.4124155451207556\n",
      "New best model found at epoch 199 with validation loss 1.4124155044555664\n",
      "Starting Epoch 200\n",
      "1.4747002124786377\n",
      "Validation loss: 1.4121394157409668\n",
      "mse 1.4121393840561258\n",
      "New best model found at epoch 200 with validation loss 1.4121394157409668\n",
      "Starting Epoch 201\n",
      "1.4741679896479067\n",
      "Validation loss: 1.4117709398269653\n",
      "mse 1.41177086693507\n",
      "New best model found at epoch 201 with validation loss 1.4117709398269653\n",
      "Starting Epoch 202\n",
      "1.4738277430119722\n",
      "Validation loss: 1.411785364151001\n",
      "mse 1.4117853105291656\n",
      "Starting Epoch 203\n",
      "1.4734592774639959\n",
      "Validation loss: 1.4115859270095825\n",
      "mse 1.411585852355622\n",
      "New best model found at epoch 203 with validation loss 1.4115859270095825\n",
      "Starting Epoch 204\n",
      "1.473053463127302\n",
      "Validation loss: 1.4111552238464355\n",
      "mse 1.4111551731464562\n",
      "New best model found at epoch 204 with validation loss 1.4111552238464355\n",
      "Starting Epoch 205\n",
      "1.4725980680921804\n",
      "Validation loss: 1.4109128713607788\n",
      "mse 1.4109129843157833\n",
      "New best model found at epoch 205 with validation loss 1.4109128713607788\n",
      "Starting Epoch 206\n",
      "1.4722648366637852\n",
      "Validation loss: 1.4106063842773438\n",
      "mse 1.410606419594083\n",
      "New best model found at epoch 206 with validation loss 1.4106063842773438\n",
      "Starting Epoch 207\n",
      "1.4717845476191977\n",
      "Validation loss: 1.4102076292037964\n",
      "mse 1.4102076030055812\n",
      "New best model found at epoch 207 with validation loss 1.4102076292037964\n",
      "Starting Epoch 208\n",
      "1.4714561389840168\n",
      "Validation loss: 1.4101487398147583\n",
      "mse 1.4101486797066425\n",
      "New best model found at epoch 208 with validation loss 1.4101487398147583\n",
      "Starting Epoch 209\n",
      "1.4711338048395903\n",
      "Validation loss: 1.409752607345581\n",
      "mse 1.409752585009292\n",
      "New best model found at epoch 209 with validation loss 1.409752607345581\n",
      "Starting Epoch 210\n",
      "1.4707435447236765\n",
      "Validation loss: 1.4096033573150635\n",
      "mse 1.409603427389938\n",
      "New best model found at epoch 210 with validation loss 1.4096033573150635\n",
      "Starting Epoch 211\n",
      "1.4703528570092244\n",
      "Validation loss: 1.4091852903366089\n",
      "mse 1.4091852239272937\n",
      "New best model found at epoch 211 with validation loss 1.4091852903366089\n",
      "Starting Epoch 212\n",
      "1.4699731106343477\n",
      "Validation loss: 1.4091858863830566\n",
      "mse 1.4091857961900154\n",
      "Starting Epoch 213\n",
      "1.4694881957510244\n",
      "Validation loss: 1.4086291790008545\n",
      "mse 1.4086291630063976\n",
      "New best model found at epoch 213 with validation loss 1.4086291790008545\n",
      "Starting Epoch 214\n",
      "1.469228446483612\n",
      "Validation loss: 1.4085657596588135\n",
      "mse 1.4085657800092037\n",
      "New best model found at epoch 214 with validation loss 1.4085657596588135\n",
      "Starting Epoch 215\n",
      "1.4688567208207173\n",
      "Validation loss: 1.4081060886383057\n",
      "mse 1.4081061165769255\n",
      "New best model found at epoch 215 with validation loss 1.4081060886383057\n",
      "Starting Epoch 216\n",
      "1.468506784542747\n",
      "Validation loss: 1.408087968826294\n",
      "mse 1.408088181717648\n",
      "New best model found at epoch 216 with validation loss 1.408087968826294\n",
      "Starting Epoch 217\n",
      "1.468112069627513\n",
      "Validation loss: 1.407696008682251\n",
      "mse 1.4076959087211647\n",
      "New best model found at epoch 217 with validation loss 1.407696008682251\n",
      "Starting Epoch 218\n",
      "1.4676495660906252\n",
      "Validation loss: 1.4073550701141357\n",
      "mse 1.4073549391875315\n",
      "New best model found at epoch 218 with validation loss 1.4073550701141357\n",
      "Starting Epoch 219\n",
      "1.4673755972281746\n",
      "Validation loss: 1.4070988893508911\n",
      "mse 1.4070988482000215\n",
      "New best model found at epoch 219 with validation loss 1.4070988893508911\n",
      "Starting Epoch 220\n",
      "1.4670321371244348\n",
      "Validation loss: 1.4068307876586914\n",
      "mse 1.4068308768598126\n",
      "New best model found at epoch 220 with validation loss 1.4068307876586914\n",
      "Starting Epoch 221\n",
      "1.4666500143382861\n",
      "Validation loss: 1.4066522121429443\n",
      "mse 1.406652152408699\n",
      "New best model found at epoch 221 with validation loss 1.4066522121429443\n",
      "Starting Epoch 222\n",
      "1.4663139063379038\n",
      "Validation loss: 1.4064215421676636\n",
      "mse 1.4064217005782618\n",
      "New best model found at epoch 222 with validation loss 1.4064215421676636\n",
      "Starting Epoch 223\n",
      "1.4658369784769805\n",
      "Validation loss: 1.405859112739563\n",
      "mse 1.4058591673055751\n",
      "New best model found at epoch 223 with validation loss 1.405859112739563\n",
      "Starting Epoch 224\n",
      "1.4655476316161777\n",
      "Validation loss: 1.405957818031311\n",
      "mse 1.4059578559384456\n",
      "Starting Epoch 225\n",
      "1.4651950286782307\n",
      "Validation loss: 1.4056942462921143\n",
      "mse 1.405694262878899\n",
      "New best model found at epoch 225 with validation loss 1.4056942462921143\n",
      "Starting Epoch 226\n",
      "1.4648820654205654\n",
      "Validation loss: 1.4053943157196045\n",
      "mse 1.405394394213828\n",
      "New best model found at epoch 226 with validation loss 1.4053943157196045\n",
      "Starting Epoch 227\n",
      "1.464407003444174\n",
      "Validation loss: 1.404845118522644\n",
      "mse 1.4048451281391676\n",
      "New best model found at epoch 227 with validation loss 1.404845118522644\n",
      "Starting Epoch 228\n",
      "1.4641113384910251\n",
      "Validation loss: 1.4047082662582397\n",
      "mse 1.4047082977777687\n",
      "New best model found at epoch 228 with validation loss 1.4047082662582397\n",
      "Starting Epoch 229\n",
      "1.4638107263523599\n",
      "Validation loss: 1.4045156240463257\n",
      "mse 1.4045155010000085\n",
      "New best model found at epoch 229 with validation loss 1.4045156240463257\n",
      "Starting Epoch 230\n",
      "1.4634735402853594\n",
      "Validation loss: 1.4043126106262207\n",
      "mse 1.4043127800033797\n",
      "New best model found at epoch 230 with validation loss 1.4043126106262207\n",
      "Starting Epoch 231\n",
      "1.4631117919216985\n",
      "Validation loss: 1.403996467590332\n",
      "mse 1.4039963184677475\n",
      "New best model found at epoch 231 with validation loss 1.403996467590332\n",
      "Starting Epoch 232\n",
      "1.4627735562946484\n",
      "Validation loss: 1.403873085975647\n",
      "mse 1.4038730247979658\n",
      "New best model found at epoch 232 with validation loss 1.403873085975647\n",
      "Starting Epoch 233\n",
      "1.4624214379683784\n",
      "Validation loss: 1.4035862684249878\n",
      "mse 1.4035861055553776\n",
      "New best model found at epoch 233 with validation loss 1.4035862684249878\n",
      "Starting Epoch 234\n",
      "1.4619440332702969\n",
      "Validation loss: 1.4032679796218872\n",
      "mse 1.4032678902142068\n",
      "New best model found at epoch 234 with validation loss 1.4032679796218872\n",
      "Starting Epoch 235\n",
      "1.461750960868338\n",
      "Validation loss: 1.402832269668579\n",
      "mse 1.4028321925688179\n",
      "New best model found at epoch 235 with validation loss 1.402832269668579\n",
      "Starting Epoch 236\n",
      "1.4613028764724731\n",
      "Validation loss: 1.402699589729309\n",
      "mse 1.4026996615338254\n",
      "New best model found at epoch 236 with validation loss 1.402699589729309\n",
      "Starting Epoch 237\n",
      "1.4610464106435361\n",
      "Validation loss: 1.4025622606277466\n",
      "mse 1.4025624085579877\n",
      "New best model found at epoch 237 with validation loss 1.4025622606277466\n",
      "Starting Epoch 238\n",
      "1.46065797753956\n",
      "Validation loss: 1.4022879600524902\n",
      "mse 1.402287998008745\n",
      "New best model found at epoch 238 with validation loss 1.4022879600524902\n",
      "Starting Epoch 239\n",
      "1.4603519776593084\n",
      "Validation loss: 1.4020401239395142\n",
      "mse 1.4020400921295286\n",
      "New best model found at epoch 239 with validation loss 1.4020401239395142\n",
      "Starting Epoch 240\n",
      "1.4599990481915681\n",
      "Validation loss: 1.4016941785812378\n",
      "mse 1.4016941927160178\n",
      "New best model found at epoch 240 with validation loss 1.4016941785812378\n",
      "Starting Epoch 241\n",
      "1.4596655135569365\n",
      "Validation loss: 1.4015027284622192\n",
      "mse 1.4015027716071848\n",
      "New best model found at epoch 241 with validation loss 1.4015027284622192\n",
      "Starting Epoch 242\n",
      "1.4593372992847278\n",
      "Validation loss: 1.4012624025344849\n",
      "mse 1.4012625192143515\n",
      "New best model found at epoch 242 with validation loss 1.4012624025344849\n",
      "Starting Epoch 243\n",
      "1.459010766900104\n",
      "Validation loss: 1.4010624885559082\n",
      "mse 1.4010625353935389\n",
      "New best model found at epoch 243 with validation loss 1.4010624885559082\n",
      "Starting Epoch 244\n",
      "1.4587356759154277\n",
      "Validation loss: 1.400680422782898\n",
      "mse 1.4006805354939489\n",
      "New best model found at epoch 244 with validation loss 1.400680422782898\n",
      "Starting Epoch 245\n",
      "1.4582387234853662\n",
      "Validation loss: 1.400501012802124\n",
      "mse 1.400500943085177\n",
      "New best model found at epoch 245 with validation loss 1.400501012802124\n",
      "Starting Epoch 246\n",
      "1.4579710778982744\n",
      "Validation loss: 1.4003385305404663\n",
      "mse 1.4003386120314947\n",
      "New best model found at epoch 246 with validation loss 1.4003385305404663\n",
      "Starting Epoch 247\n",
      "1.4576091092565786\n",
      "Validation loss: 1.4000564813613892\n",
      "mse 1.4000563254474132\n",
      "New best model found at epoch 247 with validation loss 1.4000564813613892\n",
      "Starting Epoch 248\n",
      "1.4572593232859736\n",
      "Validation loss: 1.3997886180877686\n",
      "mse 1.399788651999675\n",
      "New best model found at epoch 248 with validation loss 1.3997886180877686\n",
      "Starting Epoch 249\n",
      "1.4569407675577246\n",
      "Validation loss: 1.3995411396026611\n",
      "mse 1.3995411239705289\n",
      "New best model found at epoch 249 with validation loss 1.3995411396026611\n",
      "Starting Epoch 250\n",
      "1.4566496299660725\n",
      "Validation loss: 1.3992522954940796\n",
      "mse 1.399252365661871\n",
      "New best model found at epoch 250 with validation loss 1.3992522954940796\n",
      "Starting Epoch 251\n",
      "1.4563003389731697\n",
      "Validation loss: 1.3990321159362793\n",
      "mse 1.3990322431003874\n",
      "New best model found at epoch 251 with validation loss 1.3990321159362793\n",
      "Starting Epoch 252\n",
      "1.4560032461000525\n",
      "Validation loss: 1.3988622426986694\n",
      "mse 1.3988621425163588\n",
      "New best model found at epoch 252 with validation loss 1.3988622426986694\n",
      "Starting Epoch 253\n",
      "1.4556740159573762\n",
      "Validation loss: 1.3986396789550781\n",
      "mse 1.3986398019632686\n",
      "New best model found at epoch 253 with validation loss 1.3986396789550781\n",
      "Starting Epoch 254\n",
      "1.455431958903437\n",
      "Validation loss: 1.3983248472213745\n",
      "mse 1.398324815978369\n",
      "New best model found at epoch 254 with validation loss 1.3983248472213745\n",
      "Starting Epoch 255\n",
      "1.4550597330798274\n",
      "Validation loss: 1.3980916738510132\n",
      "mse 1.3980916793208054\n",
      "New best model found at epoch 255 with validation loss 1.3980916738510132\n",
      "Starting Epoch 256\n",
      "1.4547364167545154\n",
      "Validation loss: 1.3979359865188599\n",
      "mse 1.39793596879628\n",
      "New best model found at epoch 256 with validation loss 1.3979359865188599\n",
      "Starting Epoch 257\n",
      "1.454441065373628\n",
      "Validation loss: 1.3977299928665161\n",
      "mse 1.3977301878154815\n",
      "New best model found at epoch 257 with validation loss 1.3977299928665161\n",
      "Starting Epoch 258\n",
      "1.4541260392769524\n",
      "Validation loss: 1.3977333307266235\n",
      "mse 1.3977334867635274\n",
      "Starting Epoch 259\n",
      "1.453780508559683\n",
      "Validation loss: 1.3974040746688843\n",
      "mse 1.3974040155849108\n",
      "New best model found at epoch 259 with validation loss 1.3974040746688843\n",
      "Starting Epoch 260\n",
      "1.4534987807273865\n",
      "Validation loss: 1.3971307277679443\n",
      "mse 1.397130793350561\n",
      "New best model found at epoch 260 with validation loss 1.3971307277679443\n",
      "Starting Epoch 261\n",
      "1.4531780818234319\n",
      "Validation loss: 1.3967735767364502\n",
      "mse 1.396773602575517\n",
      "New best model found at epoch 261 with validation loss 1.3967735767364502\n",
      "Starting Epoch 262\n",
      "1.4528803281162097\n",
      "Validation loss: 1.396718144416809\n",
      "mse 1.3967182470373676\n",
      "New best model found at epoch 262 with validation loss 1.396718144416809\n",
      "Starting Epoch 263\n",
      "1.4525671368059905\n",
      "Validation loss: 1.3963956832885742\n",
      "mse 1.396395558220534\n",
      "New best model found at epoch 263 with validation loss 1.3963956832885742\n",
      "Starting Epoch 264\n",
      "1.4522575165914453\n",
      "Validation loss: 1.396329402923584\n",
      "mse 1.3963294540979112\n",
      "New best model found at epoch 264 with validation loss 1.396329402923584\n",
      "Starting Epoch 265\n",
      "1.451944200888924\n",
      "Validation loss: 1.3960416316986084\n",
      "mse 1.396041534033097\n",
      "New best model found at epoch 265 with validation loss 1.3960416316986084\n",
      "Starting Epoch 266\n",
      "1.4516464523647143\n",
      "Validation loss: 1.3957829475402832\n",
      "mse 1.3957828012201792\n",
      "New best model found at epoch 266 with validation loss 1.3957829475402832\n",
      "Starting Epoch 267\n",
      "1.451327427573826\n",
      "Validation loss: 1.3956598043441772\n",
      "mse 1.3956598081853149\n",
      "New best model found at epoch 267 with validation loss 1.3956598043441772\n",
      "Starting Epoch 268\n",
      "1.4510032379108926\n",
      "Validation loss: 1.395412564277649\n",
      "mse 1.3954124719007361\n",
      "New best model found at epoch 268 with validation loss 1.395412564277649\n",
      "Starting Epoch 269\n",
      "1.4507163503895635\n",
      "Validation loss: 1.3950777053833008\n",
      "mse 1.395077706474794\n",
      "New best model found at epoch 269 with validation loss 1.3950777053833008\n",
      "Starting Epoch 270\n",
      "1.4504408421723738\n",
      "Validation loss: 1.3950881958007812\n",
      "mse 1.395088185142172\n",
      "Starting Epoch 271\n",
      "1.4500871482102766\n",
      "Validation loss: 1.3948723077774048\n",
      "mse 1.3948722644454459\n",
      "New best model found at epoch 271 with validation loss 1.3948723077774048\n",
      "Starting Epoch 272\n",
      "1.4497955260069475\n",
      "Validation loss: 1.3946781158447266\n",
      "mse 1.3946781029547413\n",
      "New best model found at epoch 272 with validation loss 1.3946781158447266\n",
      "Starting Epoch 273\n",
      "1.4495265613431516\n",
      "Validation loss: 1.3943368196487427\n",
      "mse 1.3943367546722225\n",
      "New best model found at epoch 273 with validation loss 1.3943368196487427\n",
      "Starting Epoch 274\n",
      "1.4492574308229529\n",
      "Validation loss: 1.3940919637680054\n",
      "mse 1.3940920207892165\n",
      "New best model found at epoch 274 with validation loss 1.3940919637680054\n",
      "Starting Epoch 275\n",
      "1.4489245829374895\n",
      "Validation loss: 1.3938124179840088\n",
      "mse 1.393812451642541\n",
      "New best model found at epoch 275 with validation loss 1.3938124179840088\n",
      "Starting Epoch 276\n",
      "1.4486746788024902\n",
      "Validation loss: 1.393695592880249\n",
      "mse 1.393695725023342\n",
      "New best model found at epoch 276 with validation loss 1.393695592880249\n",
      "Starting Epoch 277\n",
      "1.4483893824660259\n",
      "Validation loss: 1.3933627605438232\n",
      "mse 1.393362683835781\n",
      "New best model found at epoch 277 with validation loss 1.3933627605438232\n",
      "Starting Epoch 278\n",
      "1.448150036127671\n",
      "Validation loss: 1.3931190967559814\n",
      "mse 1.3931191170735855\n",
      "New best model found at epoch 278 with validation loss 1.3931190967559814\n",
      "Starting Epoch 279\n",
      "1.4478032718534055\n",
      "Validation loss: 1.3930284976959229\n",
      "mse 1.3930284955972638\n",
      "New best model found at epoch 279 with validation loss 1.3930284976959229\n",
      "Starting Epoch 280\n",
      "1.4475268980731135\n",
      "Validation loss: 1.3927192687988281\n",
      "mse 1.3927191942707042\n",
      "New best model found at epoch 280 with validation loss 1.3927192687988281\n",
      "Starting Epoch 281\n",
      "1.447224013183428\n",
      "Validation loss: 1.3923730850219727\n",
      "mse 1.3923728705468355\n",
      "New best model found at epoch 281 with validation loss 1.3923730850219727\n",
      "Starting Epoch 282\n",
      "1.4469580183858457\n",
      "Validation loss: 1.3921161890029907\n",
      "mse 1.3921163052691903\n",
      "New best model found at epoch 282 with validation loss 1.3921161890029907\n",
      "Starting Epoch 283\n",
      "1.4466368400532266\n",
      "Validation loss: 1.3918488025665283\n",
      "mse 1.3918488108464881\n",
      "New best model found at epoch 283 with validation loss 1.3918488025665283\n",
      "Starting Epoch 284\n",
      "1.4463831108549368\n",
      "Validation loss: 1.3915339708328247\n",
      "mse 1.39153379046992\n",
      "New best model found at epoch 284 with validation loss 1.3915339708328247\n",
      "Starting Epoch 285\n",
      "1.4460676338361658\n",
      "Validation loss: 1.3914501667022705\n",
      "mse 1.3914500797964393\n",
      "New best model found at epoch 285 with validation loss 1.3914501667022705\n",
      "Starting Epoch 286\n",
      "1.445826926957006\n",
      "Validation loss: 1.391148328781128\n",
      "mse 1.391148430058181\n",
      "New best model found at epoch 286 with validation loss 1.391148328781128\n",
      "Starting Epoch 287\n",
      "1.4454728131708892\n",
      "Validation loss: 1.390904188156128\n",
      "mse 1.3909042670844691\n",
      "New best model found at epoch 287 with validation loss 1.390904188156128\n",
      "Starting Epoch 288\n",
      "1.4452017467954885\n",
      "Validation loss: 1.3906995058059692\n",
      "mse 1.3906995254789851\n",
      "New best model found at epoch 288 with validation loss 1.3906995058059692\n",
      "Starting Epoch 289\n",
      "1.444920925990395\n",
      "Validation loss: 1.3903923034667969\n",
      "mse 1.3903922832782425\n",
      "New best model found at epoch 289 with validation loss 1.3903923034667969\n",
      "Starting Epoch 290\n",
      "1.4446340747501538\n",
      "Validation loss: 1.3902291059494019\n",
      "mse 1.3902291992987694\n",
      "New best model found at epoch 290 with validation loss 1.3902291059494019\n",
      "Starting Epoch 291\n",
      "1.4443373550539431\n",
      "Validation loss: 1.3899898529052734\n",
      "mse 1.389989931108777\n",
      "New best model found at epoch 291 with validation loss 1.3899898529052734\n",
      "Starting Epoch 292\n",
      "1.4440773544104204\n",
      "Validation loss: 1.3896311521530151\n",
      "mse 1.3896311268141959\n",
      "New best model found at epoch 292 with validation loss 1.3896311521530151\n",
      "Starting Epoch 293\n",
      "1.443801276061846\n",
      "Validation loss: 1.3895978927612305\n",
      "mse 1.3895977725403834\n",
      "New best model found at epoch 293 with validation loss 1.3895978927612305\n",
      "Starting Epoch 294\n",
      "1.443518623061802\n",
      "Validation loss: 1.3892184495925903\n",
      "mse 1.3892184551478814\n",
      "New best model found at epoch 294 with validation loss 1.3892184495925903\n",
      "Starting Epoch 295\n",
      "1.4432039934655894\n",
      "Validation loss: 1.389168381690979\n",
      "mse 1.3891684006876095\n",
      "New best model found at epoch 295 with validation loss 1.389168381690979\n",
      "Starting Epoch 296\n",
      "1.4429719163023906\n",
      "Validation loss: 1.388872742652893\n",
      "mse 1.3888727774987213\n",
      "New best model found at epoch 296 with validation loss 1.388872742652893\n",
      "Starting Epoch 297\n",
      "1.4426820070847222\n",
      "Validation loss: 1.3886237144470215\n",
      "mse 1.3886237874803677\n",
      "New best model found at epoch 297 with validation loss 1.3886237144470215\n",
      "Starting Epoch 298\n",
      "1.442399219326351\n",
      "Validation loss: 1.3884469270706177\n",
      "mse 1.3884468772287082\n",
      "New best model found at epoch 298 with validation loss 1.3884469270706177\n",
      "Starting Epoch 299\n",
      "1.4421169058136318\n",
      "Validation loss: 1.3882454633712769\n",
      "mse 1.3882454875087047\n",
      "New best model found at epoch 299 with validation loss 1.3882454633712769\n",
      "Starting Epoch 300\n",
      "1.441862712735715\n",
      "Validation loss: 1.3880752325057983\n",
      "mse 1.3880751821984287\n",
      "New best model found at epoch 300 with validation loss 1.3880752325057983\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-40-10-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a754cc",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 40 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "085b77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "dcac8c7e-3107-4876-8178-dd7727dea88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.1405489807543545\n",
      "Validation loss: 2.5766713619232178\n",
      "mse 2.57667132281482\n",
      "New best model found at epoch 1 with validation loss 2.5766713619232178\n",
      "Starting Epoch 2\n",
      "2.668926767680956\n",
      "Validation loss: 2.295450210571289\n",
      "mse 2.295450248504985\n",
      "New best model found at epoch 2 with validation loss 2.295450210571289\n",
      "Starting Epoch 3\n",
      "2.370586820270704\n",
      "Validation loss: 2.0537803173065186\n",
      "mse 2.0537804526176973\n",
      "New best model found at epoch 3 with validation loss 2.0537803173065186\n",
      "Starting Epoch 4\n",
      "2.1479577137076338\n",
      "Validation loss: 1.8809272050857544\n",
      "mse 1.8809270778731826\n",
      "New best model found at epoch 4 with validation loss 1.8809272050857544\n",
      "Starting Epoch 5\n",
      "1.9926032294397769\n",
      "Validation loss: 1.752559781074524\n",
      "mse 1.752559735035591\n",
      "New best model found at epoch 5 with validation loss 1.752559781074524\n",
      "Starting Epoch 6\n",
      "1.8816604458767434\n",
      "Validation loss: 1.6670594215393066\n",
      "mse 1.6670594075610063\n",
      "New best model found at epoch 6 with validation loss 1.6670594215393066\n",
      "Starting Epoch 7\n",
      "1.8063614990400232\n",
      "Validation loss: 1.6118124723434448\n",
      "mse 1.61181235938089\n",
      "New best model found at epoch 7 with validation loss 1.6118124723434448\n",
      "Starting Epoch 8\n",
      "1.7515195608139038\n",
      "Validation loss: 1.5713967084884644\n",
      "mse 1.5713967963701956\n",
      "New best model found at epoch 8 with validation loss 1.5713967084884644\n",
      "Starting Epoch 9\n",
      "1.7105633227721504\n",
      "Validation loss: 1.543372392654419\n",
      "mse 1.5433724315883248\n",
      "New best model found at epoch 9 with validation loss 1.543372392654419\n",
      "Starting Epoch 10\n",
      "1.6792307262835295\n",
      "Validation loss: 1.5205891132354736\n",
      "mse 1.520589135955751\n",
      "New best model found at epoch 10 with validation loss 1.5205891132354736\n",
      "Starting Epoch 11\n",
      "1.6547784753467725\n",
      "Validation loss: 1.5046337842941284\n",
      "mse 1.504633875449189\n",
      "New best model found at epoch 11 with validation loss 1.5046337842941284\n",
      "Starting Epoch 12\n",
      "1.6355885941049326\n",
      "Validation loss: 1.4909114837646484\n",
      "mse 1.4909115998568565\n",
      "New best model found at epoch 12 with validation loss 1.4909114837646484\n",
      "Starting Epoch 13\n",
      "1.6191384895988132\n",
      "Validation loss: 1.4768211841583252\n",
      "mse 1.4768212683479693\n",
      "New best model found at epoch 13 with validation loss 1.4768211841583252\n",
      "Starting Epoch 14\n",
      "1.6049204339151797\n",
      "Validation loss: 1.4673216342926025\n",
      "mse 1.4673215554036532\n",
      "New best model found at epoch 14 with validation loss 1.4673216342926025\n",
      "Starting Epoch 15\n",
      "1.5929078537484873\n",
      "Validation loss: 1.458378553390503\n",
      "mse 1.4583786931406573\n",
      "New best model found at epoch 15 with validation loss 1.458378553390503\n",
      "Starting Epoch 16\n",
      "1.5814667370008386\n",
      "Validation loss: 1.4503086805343628\n",
      "mse 1.450308655347036\n",
      "New best model found at epoch 16 with validation loss 1.4503086805343628\n",
      "Starting Epoch 17\n",
      "1.5713019992994226\n",
      "Validation loss: 1.4410669803619385\n",
      "mse 1.4410668686377648\n",
      "New best model found at epoch 17 with validation loss 1.4410669803619385\n",
      "Starting Epoch 18\n",
      "1.5621777280517246\n",
      "Validation loss: 1.4324077367782593\n",
      "mse 1.4324077581145018\n",
      "New best model found at epoch 18 with validation loss 1.4324077367782593\n",
      "Starting Epoch 19\n",
      "1.5535683528236721\n",
      "Validation loss: 1.4249634742736816\n",
      "mse 1.42496342951548\n",
      "New best model found at epoch 19 with validation loss 1.4249634742736816\n",
      "Starting Epoch 20\n",
      "1.5451575232588726\n",
      "Validation loss: 1.418183445930481\n",
      "mse 1.4181834597852525\n",
      "New best model found at epoch 20 with validation loss 1.418183445930481\n",
      "Starting Epoch 21\n",
      "1.5373921342518018\n",
      "Validation loss: 1.4120835065841675\n",
      "mse 1.4120834741976307\n",
      "New best model found at epoch 21 with validation loss 1.4120835065841675\n",
      "Starting Epoch 22\n",
      "1.5296886174575142\n",
      "Validation loss: 1.4047857522964478\n",
      "mse 1.4047857440638145\n",
      "New best model found at epoch 22 with validation loss 1.4047857522964478\n",
      "Starting Epoch 23\n",
      "1.5228779652844304\n",
      "Validation loss: 1.3986612558364868\n",
      "mse 1.398661293124502\n",
      "New best model found at epoch 23 with validation loss 1.3986612558364868\n",
      "Starting Epoch 24\n",
      "1.5163228693215742\n",
      "Validation loss: 1.3937000036239624\n",
      "mse 1.3937000529038102\n",
      "New best model found at epoch 24 with validation loss 1.3937000036239624\n",
      "Starting Epoch 25\n",
      "1.5099165439605713\n",
      "Validation loss: 1.3883848190307617\n",
      "mse 1.3883847524553583\n",
      "New best model found at epoch 25 with validation loss 1.3883848190307617\n",
      "Starting Epoch 26\n",
      "1.5037465380585713\n",
      "Validation loss: 1.3832948207855225\n",
      "mse 1.3832947929941013\n",
      "New best model found at epoch 26 with validation loss 1.3832948207855225\n",
      "Starting Epoch 27\n",
      "1.4978793859481812\n",
      "Validation loss: 1.3791016340255737\n",
      "mse 1.379101640765026\n",
      "New best model found at epoch 27 with validation loss 1.3791016340255737\n",
      "Starting Epoch 28\n",
      "1.492336348347042\n",
      "Validation loss: 1.3744778633117676\n",
      "mse 1.3744779957562774\n",
      "New best model found at epoch 28 with validation loss 1.3744778633117676\n",
      "Starting Epoch 29\n",
      "1.4867230653762817\n",
      "Validation loss: 1.3696805238723755\n",
      "mse 1.3696804213657998\n",
      "New best model found at epoch 29 with validation loss 1.3696805238723755\n",
      "Starting Epoch 30\n",
      "1.4814909048702405\n",
      "Validation loss: 1.3656431436538696\n",
      "mse 1.3656432529488873\n",
      "New best model found at epoch 30 with validation loss 1.3656431436538696\n",
      "Starting Epoch 31\n",
      "1.4762829801310664\n",
      "Validation loss: 1.361804485321045\n",
      "mse 1.3618044720703486\n",
      "New best model found at epoch 31 with validation loss 1.361804485321045\n",
      "Starting Epoch 32\n",
      "1.4713566458743552\n",
      "Validation loss: 1.35809326171875\n",
      "mse 1.3580933390579544\n",
      "New best model found at epoch 32 with validation loss 1.35809326171875\n",
      "Starting Epoch 33\n",
      "1.4664209277733513\n",
      "Validation loss: 1.3536888360977173\n",
      "mse 1.3536889017319533\n",
      "New best model found at epoch 33 with validation loss 1.3536888360977173\n",
      "Starting Epoch 34\n",
      "1.4620809891949529\n",
      "Validation loss: 1.3502027988433838\n",
      "mse 1.35020292891044\n",
      "New best model found at epoch 34 with validation loss 1.3502027988433838\n",
      "Starting Epoch 35\n",
      "1.4575283009073008\n",
      "Validation loss: 1.3462440967559814\n",
      "mse 1.3462439899234127\n",
      "New best model found at epoch 35 with validation loss 1.3462440967559814\n",
      "Starting Epoch 36\n",
      "1.4530752301216125\n",
      "Validation loss: 1.3430044651031494\n",
      "mse 1.343004465642779\n",
      "New best model found at epoch 36 with validation loss 1.3430044651031494\n",
      "Starting Epoch 37\n",
      "1.4487307175346043\n",
      "Validation loss: 1.339740514755249\n",
      "mse 1.3397405399161626\n",
      "New best model found at epoch 37 with validation loss 1.339740514755249\n",
      "Starting Epoch 38\n",
      "1.444539645443792\n",
      "Validation loss: 1.3365106582641602\n",
      "mse 1.3365105085177174\n",
      "New best model found at epoch 38 with validation loss 1.3365106582641602\n",
      "Starting Epoch 39\n",
      "1.4407945923183276\n",
      "Validation loss: 1.3327580690383911\n",
      "mse 1.3327582383561862\n",
      "New best model found at epoch 39 with validation loss 1.3327580690383911\n",
      "Starting Epoch 40\n",
      "1.436805116093677\n",
      "Validation loss: 1.3287674188613892\n",
      "mse 1.32876724041741\n",
      "New best model found at epoch 40 with validation loss 1.3287674188613892\n",
      "Starting Epoch 41\n",
      "1.432920137177343\n",
      "Validation loss: 1.3258384466171265\n",
      "mse 1.325838488204384\n",
      "New best model found at epoch 41 with validation loss 1.3258384466171265\n",
      "Starting Epoch 42\n",
      "1.4289459171502485\n",
      "Validation loss: 1.3225312232971191\n",
      "mse 1.3225311788214207\n",
      "New best model found at epoch 42 with validation loss 1.3225312232971191\n",
      "Starting Epoch 43\n",
      "1.425228292527406\n",
      "Validation loss: 1.3192591667175293\n",
      "mse 1.3192591759014125\n",
      "New best model found at epoch 43 with validation loss 1.3192591667175293\n",
      "Starting Epoch 44\n",
      "1.4215380549430847\n",
      "Validation loss: 1.316499948501587\n",
      "mse 1.3164998641902732\n",
      "New best model found at epoch 44 with validation loss 1.316499948501587\n",
      "Starting Epoch 45\n",
      "1.4178146123886108\n",
      "Validation loss: 1.3137142658233643\n",
      "mse 1.31371428298549\n",
      "New best model found at epoch 45 with validation loss 1.3137142658233643\n",
      "Starting Epoch 46\n",
      "1.414119689360909\n",
      "Validation loss: 1.310233235359192\n",
      "mse 1.3102333140152964\n",
      "New best model found at epoch 46 with validation loss 1.310233235359192\n",
      "Starting Epoch 47\n",
      "1.4103693132815154\n",
      "Validation loss: 1.3070313930511475\n",
      "mse 1.307031517357166\n",
      "New best model found at epoch 47 with validation loss 1.3070313930511475\n",
      "Starting Epoch 48\n",
      "1.4071637469789255\n",
      "Validation loss: 1.304150104522705\n",
      "mse 1.304150111286677\n",
      "New best model found at epoch 48 with validation loss 1.304150104522705\n",
      "Starting Epoch 49\n",
      "1.4037221799726072\n",
      "Validation loss: 1.3017934560775757\n",
      "mse 1.3017934079587417\n",
      "New best model found at epoch 49 with validation loss 1.3017934560775757\n",
      "Starting Epoch 50\n",
      "1.4005462164464204\n",
      "Validation loss: 1.2988923788070679\n",
      "mse 1.2988923017993368\n",
      "New best model found at epoch 50 with validation loss 1.2988923788070679\n",
      "Starting Epoch 51\n",
      "1.3972399131111477\n",
      "Validation loss: 1.2969958782196045\n",
      "mse 1.296995810611179\n",
      "New best model found at epoch 51 with validation loss 1.2969958782196045\n",
      "Starting Epoch 52\n",
      "1.3943418005238408\n",
      "Validation loss: 1.294347882270813\n",
      "mse 1.2943478712163776\n",
      "New best model found at epoch 52 with validation loss 1.294347882270813\n",
      "Starting Epoch 53\n",
      "1.3911609260932258\n",
      "Validation loss: 1.2923287153244019\n",
      "mse 1.2923288162560613\n",
      "New best model found at epoch 53 with validation loss 1.2923287153244019\n",
      "Starting Epoch 54\n",
      "1.388263772363248\n",
      "Validation loss: 1.2894177436828613\n",
      "mse 1.2894176353720437\n",
      "New best model found at epoch 54 with validation loss 1.2894177436828613\n",
      "Starting Epoch 55\n",
      "1.3851570176041645\n",
      "Validation loss: 1.2869831323623657\n",
      "mse 1.2869830801669482\n",
      "New best model found at epoch 55 with validation loss 1.2869831323623657\n",
      "Starting Epoch 56\n",
      "1.382312844628873\n",
      "Validation loss: 1.2845518589019775\n",
      "mse 1.2845518846391843\n",
      "New best model found at epoch 56 with validation loss 1.2845518589019775\n",
      "Starting Epoch 57\n",
      "1.379556479661361\n",
      "Validation loss: 1.2813818454742432\n",
      "mse 1.2813818637296375\n",
      "New best model found at epoch 57 with validation loss 1.2813818454742432\n",
      "Starting Epoch 58\n",
      "1.3767315771268762\n",
      "Validation loss: 1.2787930965423584\n",
      "mse 1.2787931358356555\n",
      "New best model found at epoch 58 with validation loss 1.2787930965423584\n",
      "Starting Epoch 59\n",
      "1.373963379341623\n",
      "Validation loss: 1.2768553495407104\n",
      "mse 1.2768554013826732\n",
      "New best model found at epoch 59 with validation loss 1.2768553495407104\n",
      "Starting Epoch 60\n",
      "1.3711488868879236\n",
      "Validation loss: 1.27437162399292\n",
      "mse 1.274371620796121\n",
      "New best model found at epoch 60 with validation loss 1.27437162399292\n",
      "Starting Epoch 61\n",
      "1.368376910686493\n",
      "Validation loss: 1.2718302011489868\n",
      "mse 1.2718302916243702\n",
      "New best model found at epoch 61 with validation loss 1.2718302011489868\n",
      "Starting Epoch 62\n",
      "1.3655470065448596\n",
      "Validation loss: 1.2686352729797363\n",
      "mse 1.2686352002780046\n",
      "New best model found at epoch 62 with validation loss 1.2686352729797363\n",
      "Starting Epoch 63\n",
      "1.3626282474269038\n",
      "Validation loss: 1.266222596168518\n",
      "mse 1.266222599434919\n",
      "New best model found at epoch 63 with validation loss 1.266222596168518\n",
      "Starting Epoch 64\n",
      "1.3598712915959565\n",
      "Validation loss: 1.2635724544525146\n",
      "mse 1.2635724110164834\n",
      "New best model found at epoch 64 with validation loss 1.2635724544525146\n",
      "Starting Epoch 65\n",
      "1.3571485566056294\n",
      "Validation loss: 1.2606908082962036\n",
      "mse 1.2606908340242824\n",
      "New best model found at epoch 65 with validation loss 1.2606908082962036\n",
      "Starting Epoch 66\n",
      "1.354277774043705\n",
      "Validation loss: 1.258176565170288\n",
      "mse 1.258176651683496\n",
      "New best model found at epoch 66 with validation loss 1.258176565170288\n",
      "Starting Epoch 67\n",
      "1.3516724291055098\n",
      "Validation loss: 1.255816102027893\n",
      "mse 1.2558159974508716\n",
      "New best model found at epoch 67 with validation loss 1.255816102027893\n",
      "Starting Epoch 68\n",
      "1.348470978114916\n",
      "Validation loss: 1.2537555694580078\n",
      "mse 1.253755447296337\n",
      "New best model found at epoch 68 with validation loss 1.2537555694580078\n",
      "Starting Epoch 69\n",
      "1.3444406442020251\n",
      "Validation loss: 1.2514383792877197\n",
      "mse 1.2514383624795076\n",
      "New best model found at epoch 69 with validation loss 1.2514383792877197\n",
      "Starting Epoch 70\n",
      "1.3416212330693784\n",
      "Validation loss: 1.249469518661499\n",
      "mse 1.2494694957510717\n",
      "New best model found at epoch 70 with validation loss 1.249469518661499\n",
      "Starting Epoch 71\n",
      "1.338415544965993\n",
      "Validation loss: 1.2466486692428589\n",
      "mse 1.2466486614859296\n",
      "New best model found at epoch 71 with validation loss 1.2466486692428589\n",
      "Starting Epoch 72\n",
      "1.3355708536894426\n",
      "Validation loss: 1.242629051208496\n",
      "mse 1.2426290603544146\n",
      "New best model found at epoch 72 with validation loss 1.242629051208496\n",
      "Starting Epoch 73\n",
      "1.3331113872320757\n",
      "Validation loss: 1.2399095296859741\n",
      "mse 1.2399096088430286\n",
      "New best model found at epoch 73 with validation loss 1.2399095296859741\n",
      "Starting Epoch 74\n",
      "1.3302879178005715\n",
      "Validation loss: 1.2365280389785767\n",
      "mse 1.2365280524282747\n",
      "New best model found at epoch 74 with validation loss 1.2365280389785767\n",
      "Starting Epoch 75\n",
      "1.3276548955751502\n",
      "Validation loss: 1.234508991241455\n",
      "mse 1.2345091515525386\n",
      "New best model found at epoch 75 with validation loss 1.234508991241455\n",
      "Starting Epoch 76\n",
      "1.3251857913058738\n",
      "Validation loss: 1.2318209409713745\n",
      "mse 1.2318210225640385\n",
      "New best model found at epoch 76 with validation loss 1.2318209409713745\n",
      "Starting Epoch 77\n",
      "1.3226873330447986\n",
      "Validation loss: 1.2290347814559937\n",
      "mse 1.229034690074296\n",
      "New best model found at epoch 77 with validation loss 1.2290347814559937\n",
      "Starting Epoch 78\n",
      "1.3205518359723298\n",
      "Validation loss: 1.2270663976669312\n",
      "mse 1.2270663781020525\n",
      "New best model found at epoch 78 with validation loss 1.2270663976669312\n",
      "Starting Epoch 79\n",
      "1.317997447822405\n",
      "Validation loss: 1.2241804599761963\n",
      "mse 1.2241802936580164\n",
      "New best model found at epoch 79 with validation loss 1.2241804599761963\n",
      "Starting Epoch 80\n",
      "1.3154110312461853\n",
      "Validation loss: 1.2220418453216553\n",
      "mse 1.222041865287463\n",
      "New best model found at epoch 80 with validation loss 1.2220418453216553\n",
      "Starting Epoch 81\n",
      "1.3130298982495847\n",
      "Validation loss: 1.2195292711257935\n",
      "mse 1.2195293896476505\n",
      "New best model found at epoch 81 with validation loss 1.2195292711257935\n",
      "Starting Epoch 82\n",
      "1.3108398914337158\n",
      "Validation loss: 1.2174633741378784\n",
      "mse 1.2174632494883626\n",
      "New best model found at epoch 82 with validation loss 1.2174633741378784\n",
      "Starting Epoch 83\n",
      "1.3085910444674285\n",
      "Validation loss: 1.215682029724121\n",
      "mse 1.2156819806603296\n",
      "New best model found at epoch 83 with validation loss 1.215682029724121\n",
      "Starting Epoch 84\n",
      "1.306526173716006\n",
      "Validation loss: 1.2137316465377808\n",
      "mse 1.2137315479516388\n",
      "New best model found at epoch 84 with validation loss 1.2137316465377808\n",
      "Starting Epoch 85\n",
      "1.3043055793513423\n",
      "Validation loss: 1.2118260860443115\n",
      "mse 1.2118260953864777\n",
      "New best model found at epoch 85 with validation loss 1.2118260860443115\n",
      "Starting Epoch 86\n",
      "1.3023477663164553\n",
      "Validation loss: 1.2096115350723267\n",
      "mse 1.2096115599446735\n",
      "New best model found at epoch 86 with validation loss 1.2096115350723267\n",
      "Starting Epoch 87\n",
      "1.30034209334332\n",
      "Validation loss: 1.2078977823257446\n",
      "mse 1.2078977627816785\n",
      "New best model found at epoch 87 with validation loss 1.2078977823257446\n",
      "Starting Epoch 88\n",
      "1.298110588737156\n",
      "Validation loss: 1.2062175273895264\n",
      "mse 1.2062174804900543\n",
      "New best model found at epoch 88 with validation loss 1.2062175273895264\n",
      "Starting Epoch 89\n",
      "1.296217988366666\n",
      "Validation loss: 1.204679250717163\n",
      "mse 1.2046793154017588\n",
      "New best model found at epoch 89 with validation loss 1.204679250717163\n",
      "Starting Epoch 90\n",
      "1.2939634193544802\n",
      "Validation loss: 1.203026294708252\n",
      "mse 1.2030263043546872\n",
      "New best model found at epoch 90 with validation loss 1.203026294708252\n",
      "Starting Epoch 91\n",
      "1.2919202757918316\n",
      "Validation loss: 1.2014542818069458\n",
      "mse 1.2014542027142479\n",
      "New best model found at epoch 91 with validation loss 1.2014542818069458\n",
      "Starting Epoch 92\n",
      "1.2900012057760488\n",
      "Validation loss: 1.1995811462402344\n",
      "mse 1.1995810783732024\n",
      "New best model found at epoch 92 with validation loss 1.1995811462402344\n",
      "Starting Epoch 93\n",
      "1.2881229234778362\n",
      "Validation loss: 1.1979048252105713\n",
      "mse 1.1979049121889005\n",
      "New best model found at epoch 93 with validation loss 1.1979048252105713\n",
      "Starting Epoch 94\n",
      "1.2859396182972451\n",
      "Validation loss: 1.197350025177002\n",
      "mse 1.197350003016739\n",
      "New best model found at epoch 94 with validation loss 1.197350025177002\n",
      "Starting Epoch 95\n",
      "1.2840275272079136\n",
      "Validation loss: 1.1961439847946167\n",
      "mse 1.1961439783094727\n",
      "New best model found at epoch 95 with validation loss 1.1961439847946167\n",
      "Starting Epoch 96\n",
      "1.2823291006295576\n",
      "Validation loss: 1.1941962242126465\n",
      "mse 1.1941962216276076\n",
      "New best model found at epoch 96 with validation loss 1.1941962242126465\n",
      "Starting Epoch 97\n",
      "1.2804869076480037\n",
      "Validation loss: 1.1920504570007324\n",
      "mse 1.192050351254234\n",
      "New best model found at epoch 97 with validation loss 1.1920504570007324\n",
      "Starting Epoch 98\n",
      "1.2785510161648626\n",
      "Validation loss: 1.190199851989746\n",
      "mse 1.1901997570933753\n",
      "New best model found at epoch 98 with validation loss 1.190199851989746\n",
      "Starting Epoch 99\n",
      "1.2768230256826982\n",
      "Validation loss: 1.1886943578720093\n",
      "mse 1.188694401350597\n",
      "New best model found at epoch 99 with validation loss 1.1886943578720093\n",
      "Starting Epoch 100\n",
      "1.275151304576708\n",
      "Validation loss: 1.1868901252746582\n",
      "mse 1.1868899343404171\n",
      "New best model found at epoch 100 with validation loss 1.1868901252746582\n",
      "Starting Epoch 101\n",
      "1.2734088664469512\n",
      "Validation loss: 1.1858922243118286\n",
      "mse 1.1858922349212337\n",
      "New best model found at epoch 101 with validation loss 1.1858922243118286\n",
      "Starting Epoch 102\n",
      "1.2715677385744841\n",
      "Validation loss: 1.1847184896469116\n",
      "mse 1.184718592791813\n",
      "New best model found at epoch 102 with validation loss 1.1847184896469116\n",
      "Starting Epoch 103\n",
      "1.2700181577516638\n",
      "Validation loss: 1.1832175254821777\n",
      "mse 1.1832175023020186\n",
      "New best model found at epoch 103 with validation loss 1.1832175254821777\n",
      "Starting Epoch 104\n",
      "1.2682147414787956\n",
      "Validation loss: 1.1812742948532104\n",
      "mse 1.1812743253252032\n",
      "New best model found at epoch 104 with validation loss 1.1812742948532104\n",
      "Starting Epoch 105\n",
      "1.2664828922437585\n",
      "Validation loss: 1.1802172660827637\n",
      "mse 1.1802173629196187\n",
      "New best model found at epoch 105 with validation loss 1.1802172660827637\n",
      "Starting Epoch 106\n",
      "1.2648616122162861\n",
      "Validation loss: 1.1781253814697266\n",
      "mse 1.178125339483147\n",
      "New best model found at epoch 106 with validation loss 1.1781253814697266\n",
      "Starting Epoch 107\n",
      "1.2632272036179253\n",
      "Validation loss: 1.176272988319397\n",
      "mse 1.176272939808637\n",
      "New best model found at epoch 107 with validation loss 1.176272988319397\n",
      "Starting Epoch 108\n",
      "1.2613292232803677\n",
      "Validation loss: 1.1761022806167603\n",
      "mse 1.1761023823050016\n",
      "New best model found at epoch 108 with validation loss 1.1761022806167603\n",
      "Starting Epoch 109\n",
      "1.2597217300663823\n",
      "Validation loss: 1.174594759941101\n",
      "mse 1.174594770632183\n",
      "New best model found at epoch 109 with validation loss 1.174594759941101\n",
      "Starting Epoch 110\n",
      "1.258202594259511\n",
      "Validation loss: 1.1724134683609009\n",
      "mse 1.1724134785401645\n",
      "New best model found at epoch 110 with validation loss 1.1724134683609009\n",
      "Starting Epoch 111\n",
      "1.2565236039783643\n",
      "Validation loss: 1.1716537475585938\n",
      "mse 1.1716537104502662\n",
      "New best model found at epoch 111 with validation loss 1.1716537475585938\n",
      "Starting Epoch 112\n",
      "1.2549317142237788\n",
      "Validation loss: 1.1699637174606323\n",
      "mse 1.169963724363019\n",
      "New best model found at epoch 112 with validation loss 1.1699637174606323\n",
      "Starting Epoch 113\n",
      "1.2531333125155906\n",
      "Validation loss: 1.1689374446868896\n",
      "mse 1.1689373623221806\n",
      "New best model found at epoch 113 with validation loss 1.1689374446868896\n",
      "Starting Epoch 114\n",
      "1.2516164572342583\n",
      "Validation loss: 1.1674246788024902\n",
      "mse 1.1674246429383475\n",
      "New best model found at epoch 114 with validation loss 1.1674246788024902\n",
      "Starting Epoch 115\n",
      "1.2500696933787803\n",
      "Validation loss: 1.1656494140625\n",
      "mse 1.165649406760629\n",
      "New best model found at epoch 115 with validation loss 1.1656494140625\n",
      "Starting Epoch 116\n",
      "1.2485654613246089\n",
      "Validation loss: 1.1643192768096924\n",
      "mse 1.1643191337471948\n",
      "New best model found at epoch 116 with validation loss 1.1643192768096924\n",
      "Starting Epoch 117\n",
      "1.247135965720467\n",
      "Validation loss: 1.162076711654663\n",
      "mse 1.1620767125929439\n",
      "New best model found at epoch 117 with validation loss 1.162076711654663\n",
      "Starting Epoch 118\n",
      "1.2454847512037859\n",
      "Validation loss: 1.1612350940704346\n",
      "mse 1.1612351775656715\n",
      "New best model found at epoch 118 with validation loss 1.1612350940704346\n",
      "Starting Epoch 119\n",
      "1.2440195731494739\n",
      "Validation loss: 1.1590601205825806\n",
      "mse 1.1590599962442427\n",
      "New best model found at epoch 119 with validation loss 1.1590601205825806\n",
      "Starting Epoch 120\n",
      "1.242451144301373\n",
      "Validation loss: 1.1593188047409058\n",
      "mse 1.1593188602128663\n",
      "Starting Epoch 121\n",
      "1.2409226039181585\n",
      "Validation loss: 1.1569111347198486\n",
      "mse 1.1569111690774796\n",
      "New best model found at epoch 121 with validation loss 1.1569111347198486\n",
      "Starting Epoch 122\n",
      "1.239640888960465\n",
      "Validation loss: 1.1560289859771729\n",
      "mse 1.1560291043832713\n",
      "New best model found at epoch 122 with validation loss 1.1560289859771729\n",
      "Starting Epoch 123\n",
      "1.2380273108897002\n",
      "Validation loss: 1.1533628702163696\n",
      "mse 1.153362918802296\n",
      "New best model found at epoch 123 with validation loss 1.1533628702163696\n",
      "Starting Epoch 124\n",
      "1.2368470611779585\n",
      "Validation loss: 1.152451515197754\n",
      "mse 1.1524514532921872\n",
      "New best model found at epoch 124 with validation loss 1.152451515197754\n",
      "Starting Epoch 125\n",
      "1.235455694405929\n",
      "Validation loss: 1.1521941423416138\n",
      "mse 1.1521941972431577\n",
      "New best model found at epoch 125 with validation loss 1.1521941423416138\n",
      "Starting Epoch 126\n",
      "1.2338296667389248\n",
      "Validation loss: 1.1496883630752563\n",
      "mse 1.1496883846248345\n",
      "New best model found at epoch 126 with validation loss 1.1496883630752563\n",
      "Starting Epoch 127\n",
      "1.2325997896816419\n",
      "Validation loss: 1.149100422859192\n",
      "mse 1.149100365501618\n",
      "New best model found at epoch 127 with validation loss 1.149100422859192\n",
      "Starting Epoch 128\n",
      "1.2313229804453643\n",
      "Validation loss: 1.146630883216858\n",
      "mse 1.1466307830431457\n",
      "New best model found at epoch 128 with validation loss 1.146630883216858\n",
      "Starting Epoch 129\n",
      "1.2298326699630073\n",
      "Validation loss: 1.1472933292388916\n",
      "mse 1.1472933142133506\n",
      "Starting Epoch 130\n",
      "1.228372485741325\n",
      "Validation loss: 1.145107626914978\n",
      "mse 1.1451077410742405\n",
      "New best model found at epoch 130 with validation loss 1.145107626914978\n",
      "Starting Epoch 131\n",
      "1.2272036904874055\n",
      "Validation loss: 1.1436488628387451\n",
      "mse 1.143648869465028\n",
      "New best model found at epoch 131 with validation loss 1.1436488628387451\n",
      "Starting Epoch 132\n",
      "1.225740170997122\n",
      "Validation loss: 1.1431405544281006\n",
      "mse 1.143140544179072\n",
      "New best model found at epoch 132 with validation loss 1.1431405544281006\n",
      "Starting Epoch 133\n",
      "1.2244344586911409\n",
      "Validation loss: 1.1411170959472656\n",
      "mse 1.1411171671143507\n",
      "New best model found at epoch 133 with validation loss 1.1411170959472656\n",
      "Starting Epoch 134\n",
      "1.2232789811880693\n",
      "Validation loss: 1.138401746749878\n",
      "mse 1.1384015558350296\n",
      "New best model found at epoch 134 with validation loss 1.138401746749878\n",
      "Starting Epoch 135\n",
      "1.2221282798310984\n",
      "Validation loss: 1.139268159866333\n",
      "mse 1.1392681563267375\n",
      "Starting Epoch 136\n",
      "1.2205411195755005\n",
      "Validation loss: 1.135772943496704\n",
      "mse 1.1357729485790027\n",
      "New best model found at epoch 136 with validation loss 1.135772943496704\n",
      "Starting Epoch 137\n",
      "1.2194327478823455\n",
      "Validation loss: 1.134952425956726\n",
      "mse 1.1349524584729285\n",
      "New best model found at epoch 137 with validation loss 1.134952425956726\n",
      "Starting Epoch 138\n",
      "1.218232432137365\n",
      "Validation loss: 1.1342569589614868\n",
      "mse 1.1342570964343013\n",
      "New best model found at epoch 138 with validation loss 1.1342569589614868\n",
      "Starting Epoch 139\n",
      "1.2168667912483215\n",
      "Validation loss: 1.1330547332763672\n",
      "mse 1.1330546589961012\n",
      "New best model found at epoch 139 with validation loss 1.1330547332763672\n",
      "Starting Epoch 140\n",
      "1.2157347280046213\n",
      "Validation loss: 1.1313570737838745\n",
      "mse 1.1313570508884396\n",
      "New best model found at epoch 140 with validation loss 1.1313570737838745\n",
      "Starting Epoch 141\n",
      "1.2144710654797761\n",
      "Validation loss: 1.1304807662963867\n",
      "mse 1.1304807860283437\n",
      "New best model found at epoch 141 with validation loss 1.1304807662963867\n",
      "Starting Epoch 142\n",
      "1.213246718696926\n",
      "Validation loss: 1.1288944482803345\n",
      "mse 1.1288943735942345\n",
      "New best model found at epoch 142 with validation loss 1.1288944482803345\n",
      "Starting Epoch 143\n",
      "1.2121165602103523\n",
      "Validation loss: 1.1275089979171753\n",
      "mse 1.1275090266691712\n",
      "New best model found at epoch 143 with validation loss 1.1275089979171753\n",
      "Starting Epoch 144\n",
      "1.2109066092449685\n",
      "Validation loss: 1.1266233921051025\n",
      "mse 1.126623412426639\n",
      "New best model found at epoch 144 with validation loss 1.1266233921051025\n",
      "Starting Epoch 145\n",
      "1.2096793936646504\n",
      "Validation loss: 1.1253443956375122\n",
      "mse 1.1253444513102382\n",
      "New best model found at epoch 145 with validation loss 1.1253443956375122\n",
      "Starting Epoch 146\n",
      "1.208331110684768\n",
      "Validation loss: 1.124448299407959\n",
      "mse 1.1244483185685494\n",
      "New best model found at epoch 146 with validation loss 1.124448299407959\n",
      "Starting Epoch 147\n",
      "1.2072534716647605\n",
      "Validation loss: 1.122603416442871\n",
      "mse 1.122603441577922\n",
      "New best model found at epoch 147 with validation loss 1.122603416442871\n",
      "Starting Epoch 148\n",
      "1.2060864671416904\n",
      "Validation loss: 1.1215616464614868\n",
      "mse 1.1215616432952769\n",
      "New best model found at epoch 148 with validation loss 1.1215616464614868\n",
      "Starting Epoch 149\n",
      "1.2048430701960688\n",
      "Validation loss: 1.1205174922943115\n",
      "mse 1.1205174580403163\n",
      "New best model found at epoch 149 with validation loss 1.1205174922943115\n",
      "Starting Epoch 150\n",
      "1.203811052052871\n",
      "Validation loss: 1.119651436805725\n",
      "mse 1.119651399558416\n",
      "New best model found at epoch 150 with validation loss 1.119651436805725\n",
      "Starting Epoch 151\n",
      "1.2027762350828752\n",
      "Validation loss: 1.1180040836334229\n",
      "mse 1.1180042094839076\n",
      "New best model found at epoch 151 with validation loss 1.1180040836334229\n",
      "Starting Epoch 152\n",
      "1.2013192980185798\n",
      "Validation loss: 1.1165090799331665\n",
      "mse 1.1165090528509591\n",
      "New best model found at epoch 152 with validation loss 1.1165090799331665\n",
      "Starting Epoch 153\n",
      "1.200114314970763\n",
      "Validation loss: 1.115068793296814\n",
      "mse 1.1150687397218544\n",
      "New best model found at epoch 153 with validation loss 1.115068793296814\n",
      "Starting Epoch 154\n",
      "1.1985816851906155\n",
      "Validation loss: 1.114304780960083\n",
      "mse 1.1143049247579042\n",
      "New best model found at epoch 154 with validation loss 1.114304780960083\n",
      "Starting Epoch 155\n",
      "1.1972948805145596\n",
      "Validation loss: 1.1135488748550415\n",
      "mse 1.1135488758206458\n",
      "New best model found at epoch 155 with validation loss 1.1135488748550415\n",
      "Starting Epoch 156\n",
      "1.1962101459503174\n",
      "Validation loss: 1.1120370626449585\n",
      "mse 1.1120371721921773\n",
      "New best model found at epoch 156 with validation loss 1.1120370626449585\n",
      "Starting Epoch 157\n",
      "1.1948265277821084\n",
      "Validation loss: 1.1116399765014648\n",
      "mse 1.1116400783635563\n",
      "New best model found at epoch 157 with validation loss 1.1116399765014648\n",
      "Starting Epoch 158\n",
      "1.1938405710717905\n",
      "Validation loss: 1.109895944595337\n",
      "mse 1.109895880525095\n",
      "New best model found at epoch 158 with validation loss 1.109895944595337\n",
      "Starting Epoch 159\n",
      "1.192455397999805\n",
      "Validation loss: 1.1094530820846558\n",
      "mse 1.1094531168518718\n",
      "New best model found at epoch 159 with validation loss 1.1094530820846558\n",
      "Starting Epoch 160\n",
      "1.191552107748778\n",
      "Validation loss: 1.1077044010162354\n",
      "mse 1.10770438251074\n",
      "New best model found at epoch 160 with validation loss 1.1077044010162354\n",
      "Starting Epoch 161\n",
      "1.1901867026868074\n",
      "Validation loss: 1.1066151857376099\n",
      "mse 1.106615154622368\n",
      "New best model found at epoch 161 with validation loss 1.1066151857376099\n",
      "Starting Epoch 162\n",
      "1.189431791720183\n",
      "Validation loss: 1.105594515800476\n",
      "mse 1.1055945074187299\n",
      "New best model found at epoch 162 with validation loss 1.105594515800476\n",
      "Starting Epoch 163\n",
      "1.1882789990176326\n",
      "Validation loss: 1.104526400566101\n",
      "mse 1.104526289027104\n",
      "New best model found at epoch 163 with validation loss 1.104526400566101\n",
      "Starting Epoch 164\n",
      "1.1872237894846045\n",
      "Validation loss: 1.1040440797805786\n",
      "mse 1.1040441480048533\n",
      "New best model found at epoch 164 with validation loss 1.1040440797805786\n",
      "Starting Epoch 165\n",
      "1.1865606800369595\n",
      "Validation loss: 1.1027013063430786\n",
      "mse 1.1027013467770375\n",
      "New best model found at epoch 165 with validation loss 1.1027013063430786\n",
      "Starting Epoch 166\n",
      "1.1855207940806514\n",
      "Validation loss: 1.1017824411392212\n",
      "mse 1.1017824767538997\n",
      "New best model found at epoch 166 with validation loss 1.1017824411392212\n",
      "Starting Epoch 167\n",
      "1.1844891620718914\n",
      "Validation loss: 1.1008421182632446\n",
      "mse 1.1008421126671901\n",
      "New best model found at epoch 167 with validation loss 1.1008421182632446\n",
      "Starting Epoch 168\n",
      "1.183473006538723\n",
      "Validation loss: 1.0996952056884766\n",
      "mse 1.099695134943527\n",
      "New best model found at epoch 168 with validation loss 1.0996952056884766\n",
      "Starting Epoch 169\n",
      "1.1826086847678474\n",
      "Validation loss: 1.0983175039291382\n",
      "mse 1.0983174812587393\n",
      "New best model found at epoch 169 with validation loss 1.0983175039291382\n",
      "Starting Epoch 170\n",
      "1.1817519768424656\n",
      "Validation loss: 1.0976182222366333\n",
      "mse 1.0976181900595465\n",
      "New best model found at epoch 170 with validation loss 1.0976182222366333\n",
      "Starting Epoch 171\n",
      "1.1807468222535176\n",
      "Validation loss: 1.0966615676879883\n",
      "mse 1.0966614677696804\n",
      "New best model found at epoch 171 with validation loss 1.0966615676879883\n",
      "Starting Epoch 172\n",
      "1.1798394426055576\n",
      "Validation loss: 1.0955164432525635\n",
      "mse 1.0955164734814953\n",
      "New best model found at epoch 172 with validation loss 1.0955164432525635\n",
      "Starting Epoch 173\n",
      "1.1789483505746592\n",
      "Validation loss: 1.094524621963501\n",
      "mse 1.0945245670845105\n",
      "New best model found at epoch 173 with validation loss 1.094524621963501\n",
      "Starting Epoch 174\n",
      "1.1782148273094841\n",
      "Validation loss: 1.0937350988388062\n",
      "mse 1.093735143992601\n",
      "New best model found at epoch 174 with validation loss 1.0937350988388062\n",
      "Starting Epoch 175\n",
      "1.1771448228670203\n",
      "Validation loss: 1.0927913188934326\n",
      "mse 1.0927914680469681\n",
      "New best model found at epoch 175 with validation loss 1.0927913188934326\n",
      "Starting Epoch 176\n",
      "1.1762897579566292\n",
      "Validation loss: 1.0918205976486206\n",
      "mse 1.0918205234875071\n",
      "New best model found at epoch 176 with validation loss 1.0918205976486206\n",
      "Starting Epoch 177\n",
      "1.1752710005511409\n",
      "Validation loss: 1.0909548997879028\n",
      "mse 1.0909548692513018\n",
      "New best model found at epoch 177 with validation loss 1.0909548997879028\n",
      "Starting Epoch 178\n",
      "1.1744265763655952\n",
      "Validation loss: 1.0900269746780396\n",
      "mse 1.0900269939576657\n",
      "New best model found at epoch 178 with validation loss 1.0900269746780396\n",
      "Starting Epoch 179\n",
      "1.1735851609188577\n",
      "Validation loss: 1.0888596773147583\n",
      "mse 1.088859756428825\n",
      "New best model found at epoch 179 with validation loss 1.0888596773147583\n",
      "Starting Epoch 180\n",
      "1.1728532936262048\n",
      "Validation loss: 1.0883203744888306\n",
      "mse 1.0883203358718\n",
      "New best model found at epoch 180 with validation loss 1.0883203744888306\n",
      "Starting Epoch 181\n",
      "1.1718839329221975\n",
      "Validation loss: 1.0867818593978882\n",
      "mse 1.0867818960940412\n",
      "New best model found at epoch 181 with validation loss 1.0867818593978882\n",
      "Starting Epoch 182\n",
      "1.171119371186132\n",
      "Validation loss: 1.0863627195358276\n",
      "mse 1.0863626699519575\n",
      "New best model found at epoch 182 with validation loss 1.0863627195358276\n",
      "Starting Epoch 183\n",
      "1.17023991242699\n",
      "Validation loss: 1.0851842164993286\n",
      "mse 1.085184252027671\n",
      "New best model found at epoch 183 with validation loss 1.0851842164993286\n",
      "Starting Epoch 184\n",
      "1.169268408547277\n",
      "Validation loss: 1.0846651792526245\n",
      "mse 1.0846650426158047\n",
      "New best model found at epoch 184 with validation loss 1.0846651792526245\n",
      "Starting Epoch 185\n",
      "1.1684325181919595\n",
      "Validation loss: 1.0834437608718872\n",
      "mse 1.0834437263315835\n",
      "New best model found at epoch 185 with validation loss 1.0834437608718872\n",
      "Starting Epoch 186\n",
      "1.1676899324292722\n",
      "Validation loss: 1.0828607082366943\n",
      "mse 1.082860551159555\n",
      "New best model found at epoch 186 with validation loss 1.0828607082366943\n",
      "Starting Epoch 187\n",
      "1.1668266161628391\n",
      "Validation loss: 1.0820292234420776\n",
      "mse 1.0820291690474337\n",
      "New best model found at epoch 187 with validation loss 1.0820292234420776\n",
      "Starting Epoch 188\n",
      "1.1661050423331882\n",
      "Validation loss: 1.0812374353408813\n",
      "mse 1.0812373818002234\n",
      "New best model found at epoch 188 with validation loss 1.0812374353408813\n",
      "Starting Epoch 189\n",
      "1.1651527181915615\n",
      "Validation loss: 1.08050537109375\n",
      "mse 1.0805052790975214\n",
      "New best model found at epoch 189 with validation loss 1.08050537109375\n",
      "Starting Epoch 190\n",
      "1.1645726095075193\n",
      "Validation loss: 1.0800725221633911\n",
      "mse 1.0800726757167713\n",
      "New best model found at epoch 190 with validation loss 1.0800725221633911\n",
      "Starting Epoch 191\n",
      "1.1635767117790554\n",
      "Validation loss: 1.078556776046753\n",
      "mse 1.0785566971125058\n",
      "New best model found at epoch 191 with validation loss 1.078556776046753\n",
      "Starting Epoch 192\n",
      "1.163001809431159\n",
      "Validation loss: 1.0782816410064697\n",
      "mse 1.078281567776868\n",
      "New best model found at epoch 192 with validation loss 1.0782816410064697\n",
      "Starting Epoch 193\n",
      "1.1621134540309077\n",
      "Validation loss: 1.0774015188217163\n",
      "mse 1.0774015559956058\n",
      "New best model found at epoch 193 with validation loss 1.0774015188217163\n",
      "Starting Epoch 194\n",
      "1.1612230202426082\n",
      "Validation loss: 1.076675534248352\n",
      "mse 1.076675504725657\n",
      "New best model found at epoch 194 with validation loss 1.076675534248352\n",
      "Starting Epoch 195\n",
      "1.1604074498881465\n",
      "Validation loss: 1.0755081176757812\n",
      "mse 1.0755080549057825\n",
      "New best model found at epoch 195 with validation loss 1.0755081176757812\n",
      "Starting Epoch 196\n",
      "1.159554097963416\n",
      "Validation loss: 1.0746371746063232\n",
      "mse 1.0746370759915302\n",
      "New best model found at epoch 196 with validation loss 1.0746371746063232\n",
      "Starting Epoch 197\n",
      "1.1585649925729502\n",
      "Validation loss: 1.073164701461792\n",
      "mse 1.0731646957577254\n",
      "New best model found at epoch 197 with validation loss 1.073164701461792\n",
      "Starting Epoch 198\n",
      "1.1579469468282617\n",
      "Validation loss: 1.0722997188568115\n",
      "mse 1.0722996293107947\n",
      "New best model found at epoch 198 with validation loss 1.0722997188568115\n",
      "Starting Epoch 199\n",
      "1.1569090407827627\n",
      "Validation loss: 1.0710729360580444\n",
      "mse 1.0710728066890698\n",
      "New best model found at epoch 199 with validation loss 1.0710729360580444\n",
      "Starting Epoch 200\n",
      "1.156226933002472\n",
      "Validation loss: 1.0700832605361938\n",
      "mse 1.0700832722892746\n",
      "New best model found at epoch 200 with validation loss 1.0700832605361938\n",
      "Starting Epoch 201\n",
      "1.155336294485175\n",
      "Validation loss: 1.0688871145248413\n",
      "mse 1.068887116169527\n",
      "New best model found at epoch 201 with validation loss 1.0688871145248413\n",
      "Starting Epoch 202\n",
      "1.1545648704404416\n",
      "Validation loss: 1.068179726600647\n",
      "mse 1.0681796249323117\n",
      "New best model found at epoch 202 with validation loss 1.068179726600647\n",
      "Starting Epoch 203\n",
      "1.1537549754847651\n",
      "Validation loss: 1.0671460628509521\n",
      "mse 1.0671460130739636\n",
      "New best model found at epoch 203 with validation loss 1.0671460628509521\n",
      "Starting Epoch 204\n",
      "1.1529484598532966\n",
      "Validation loss: 1.0661364793777466\n",
      "mse 1.0661365125425881\n",
      "New best model found at epoch 204 with validation loss 1.0661364793777466\n",
      "Starting Epoch 205\n",
      "1.1523070205812869\n",
      "Validation loss: 1.0654685497283936\n",
      "mse 1.0654686041828079\n",
      "New best model found at epoch 205 with validation loss 1.0654685497283936\n",
      "Starting Epoch 206\n",
      "1.1513874504877173\n",
      "Validation loss: 1.064816951751709\n",
      "mse 1.0648169131902006\n",
      "New best model found at epoch 206 with validation loss 1.064816951751709\n",
      "Starting Epoch 207\n",
      "1.150531574435856\n",
      "Validation loss: 1.0639503002166748\n",
      "mse 1.0639504250227967\n",
      "New best model found at epoch 207 with validation loss 1.0639503002166748\n",
      "Starting Epoch 208\n",
      "1.1497819242270098\n",
      "Validation loss: 1.0632753372192383\n",
      "mse 1.0632751529781719\n",
      "New best model found at epoch 208 with validation loss 1.0632753372192383\n",
      "Starting Epoch 209\n",
      "1.1490803283193838\n",
      "Validation loss: 1.0625240802764893\n",
      "mse 1.0625241169348858\n",
      "New best model found at epoch 209 with validation loss 1.0625240802764893\n",
      "Starting Epoch 210\n",
      "1.1484009675357654\n",
      "Validation loss: 1.0619875192642212\n",
      "mse 1.0619875276671595\n",
      "New best model found at epoch 210 with validation loss 1.0619875192642212\n",
      "Starting Epoch 211\n",
      "1.1476445431294648\n",
      "Validation loss: 1.0611692667007446\n",
      "mse 1.0611692834173951\n",
      "New best model found at epoch 211 with validation loss 1.0611692667007446\n",
      "Starting Epoch 212\n",
      "1.1469071559284045\n",
      "Validation loss: 1.0604901313781738\n",
      "mse 1.060490110725587\n",
      "New best model found at epoch 212 with validation loss 1.0604901313781738\n",
      "Starting Epoch 213\n",
      "1.1462234828783118\n",
      "Validation loss: 1.0597281455993652\n",
      "mse 1.0597281637372336\n",
      "New best model found at epoch 213 with validation loss 1.0597281455993652\n",
      "Starting Epoch 214\n",
      "1.1453039931214375\n",
      "Validation loss: 1.0588055849075317\n",
      "mse 1.0588055456998662\n",
      "New best model found at epoch 214 with validation loss 1.0588055849075317\n",
      "Starting Epoch 215\n",
      "1.1446973629619763\n",
      "Validation loss: 1.0584341287612915\n",
      "mse 1.0584341494203213\n",
      "New best model found at epoch 215 with validation loss 1.0584341287612915\n",
      "Starting Epoch 216\n",
      "1.1439740294995515\n",
      "Validation loss: 1.057403564453125\n",
      "mse 1.057403513865345\n",
      "New best model found at epoch 216 with validation loss 1.057403564453125\n",
      "Starting Epoch 217\n",
      "1.1433324191881262\n",
      "Validation loss: 1.0567846298217773\n",
      "mse 1.0567847761573\n",
      "New best model found at epoch 217 with validation loss 1.0567846298217773\n",
      "Starting Epoch 218\n",
      "1.1426352651222893\n",
      "Validation loss: 1.0561251640319824\n",
      "mse 1.0561251841527404\n",
      "New best model found at epoch 218 with validation loss 1.0561251640319824\n",
      "Starting Epoch 219\n",
      "1.1419009877287822\n",
      "Validation loss: 1.055405616760254\n",
      "mse 1.0554055406919567\n",
      "New best model found at epoch 219 with validation loss 1.055405616760254\n",
      "Starting Epoch 220\n",
      "1.1412702721098196\n",
      "Validation loss: 1.0550419092178345\n",
      "mse 1.0550418904307892\n",
      "New best model found at epoch 220 with validation loss 1.0550419092178345\n",
      "Starting Epoch 221\n",
      "1.1405375781266585\n",
      "Validation loss: 1.0542341470718384\n",
      "mse 1.0542340672119226\n",
      "New best model found at epoch 221 with validation loss 1.0542341470718384\n",
      "Starting Epoch 222\n",
      "1.1398682153743247\n",
      "Validation loss: 1.0532981157302856\n",
      "mse 1.0532982207448007\n",
      "New best model found at epoch 222 with validation loss 1.0532981157302856\n",
      "Starting Epoch 223\n",
      "1.13925360078397\n",
      "Validation loss: 1.0531114339828491\n",
      "mse 1.0531113870164832\n",
      "New best model found at epoch 223 with validation loss 1.0531114339828491\n",
      "Starting Epoch 224\n",
      "1.1384919596754985\n",
      "Validation loss: 1.0523487329483032\n",
      "mse 1.0523488068372413\n",
      "New best model found at epoch 224 with validation loss 1.0523487329483032\n",
      "Starting Epoch 225\n",
      "1.137915823770606\n",
      "Validation loss: 1.0519047975540161\n",
      "mse 1.0519047774004133\n",
      "New best model found at epoch 225 with validation loss 1.0519047975540161\n",
      "Starting Epoch 226\n",
      "1.137192270030146\n",
      "Validation loss: 1.0508880615234375\n",
      "mse 1.0508881143020847\n",
      "New best model found at epoch 226 with validation loss 1.0508880615234375\n",
      "Starting Epoch 227\n",
      "1.1366798100264177\n",
      "Validation loss: 1.0506582260131836\n",
      "mse 1.0506582668446982\n",
      "New best model found at epoch 227 with validation loss 1.0506582260131836\n",
      "Starting Epoch 228\n",
      "1.1360146921613943\n",
      "Validation loss: 1.04985773563385\n",
      "mse 1.0498576385106115\n",
      "New best model found at epoch 228 with validation loss 1.04985773563385\n",
      "Starting Epoch 229\n",
      "1.1353098672369253\n",
      "Validation loss: 1.0489095449447632\n",
      "mse 1.0489094313509897\n",
      "New best model found at epoch 229 with validation loss 1.0489095449447632\n",
      "Starting Epoch 230\n",
      "1.1346706696178601\n",
      "Validation loss: 1.0483357906341553\n",
      "mse 1.0483357498536057\n",
      "New best model found at epoch 230 with validation loss 1.0483357906341553\n",
      "Starting Epoch 231\n",
      "1.1341556284738623\n",
      "Validation loss: 1.0476579666137695\n",
      "mse 1.0476579553665815\n",
      "New best model found at epoch 231 with validation loss 1.0476579666137695\n",
      "Starting Epoch 232\n",
      "1.1334145613338635\n",
      "Validation loss: 1.0468201637268066\n",
      "mse 1.046820151399176\n",
      "New best model found at epoch 232 with validation loss 1.0468201637268066\n",
      "Starting Epoch 233\n",
      "1.1326837410097537\n",
      "Validation loss: 1.046144723892212\n",
      "mse 1.0461447859144746\n",
      "New best model found at epoch 233 with validation loss 1.046144723892212\n",
      "Starting Epoch 234\n",
      "1.1321184272351472\n",
      "Validation loss: 1.0456815958023071\n",
      "mse 1.0456814858982821\n",
      "New best model found at epoch 234 with validation loss 1.0456815958023071\n",
      "Starting Epoch 235\n",
      "1.131391660026882\n",
      "Validation loss: 1.0448490381240845\n",
      "mse 1.044848939788773\n",
      "New best model found at epoch 235 with validation loss 1.0448490381240845\n",
      "Starting Epoch 236\n",
      "1.13089621844499\n",
      "Validation loss: 1.0446525812149048\n",
      "mse 1.044652543986768\n",
      "New best model found at epoch 236 with validation loss 1.0446525812149048\n",
      "Starting Epoch 237\n",
      "1.1302225019620813\n",
      "Validation loss: 1.044109582901001\n",
      "mse 1.0441096033768742\n",
      "New best model found at epoch 237 with validation loss 1.044109582901001\n",
      "Starting Epoch 238\n",
      "1.1297001501788264\n",
      "Validation loss: 1.0437595844268799\n",
      "mse 1.043759491930458\n",
      "New best model found at epoch 238 with validation loss 1.0437595844268799\n",
      "Starting Epoch 239\n",
      "1.1292010260664898\n",
      "Validation loss: 1.0426841974258423\n",
      "mse 1.0426842106992644\n",
      "New best model found at epoch 239 with validation loss 1.0426841974258423\n",
      "Starting Epoch 240\n",
      "1.1283752944158472\n",
      "Validation loss: 1.041886329650879\n",
      "mse 1.041886236819061\n",
      "New best model found at epoch 240 with validation loss 1.041886329650879\n",
      "Starting Epoch 241\n",
      "1.128036397954692\n",
      "Validation loss: 1.0411629676818848\n",
      "mse 1.041162968309407\n",
      "New best model found at epoch 241 with validation loss 1.0411629676818848\n",
      "Starting Epoch 242\n",
      "1.127197387425796\n",
      "Validation loss: 1.0406581163406372\n",
      "mse 1.040657999004628\n",
      "New best model found at epoch 242 with validation loss 1.0406581163406372\n",
      "Starting Epoch 243\n",
      "1.1264188393302585\n",
      "Validation loss: 1.0401463508605957\n",
      "mse 1.040146481826977\n",
      "New best model found at epoch 243 with validation loss 1.0401463508605957\n",
      "Starting Epoch 244\n",
      "1.125909667948018\n",
      "Validation loss: 1.0394365787506104\n",
      "mse 1.0394365816495044\n",
      "New best model found at epoch 244 with validation loss 1.0394365787506104\n",
      "Starting Epoch 245\n",
      "1.1252751350402832\n",
      "Validation loss: 1.039034128189087\n",
      "mse 1.03903413413142\n",
      "New best model found at epoch 245 with validation loss 1.039034128189087\n",
      "Starting Epoch 246\n",
      "1.1248721298964128\n",
      "Validation loss: 1.0381505489349365\n",
      "mse 1.0381504460456608\n",
      "New best model found at epoch 246 with validation loss 1.0381505489349365\n",
      "Starting Epoch 247\n",
      "1.1241908488066301\n",
      "Validation loss: 1.0376553535461426\n",
      "mse 1.0376553652602758\n",
      "New best model found at epoch 247 with validation loss 1.0376553535461426\n",
      "Starting Epoch 248\n",
      "1.1235782115355781\n",
      "Validation loss: 1.0371906757354736\n",
      "mse 1.0371907445698694\n",
      "New best model found at epoch 248 with validation loss 1.0371906757354736\n",
      "Starting Epoch 249\n",
      "1.1230914489082668\n",
      "Validation loss: 1.036337971687317\n",
      "mse 1.0363380098916282\n",
      "New best model found at epoch 249 with validation loss 1.036337971687317\n",
      "Starting Epoch 250\n",
      "1.1225694236548052\n",
      "Validation loss: 1.0359057188034058\n",
      "mse 1.0359058528614515\n",
      "New best model found at epoch 250 with validation loss 1.0359057188034058\n",
      "Starting Epoch 251\n",
      "1.12204909324646\n",
      "Validation loss: 1.0351524353027344\n",
      "mse 1.035152321234643\n",
      "New best model found at epoch 251 with validation loss 1.0351524353027344\n",
      "Starting Epoch 252\n",
      "1.121367324953494\n",
      "Validation loss: 1.035379409790039\n",
      "mse 1.035379392700861\n",
      "Starting Epoch 253\n",
      "1.1209899731304334\n",
      "Validation loss: 1.0346397161483765\n",
      "mse 1.034639609794308\n",
      "New best model found at epoch 253 with validation loss 1.0346397161483765\n",
      "Starting Epoch 254\n",
      "1.1203559818475142\n",
      "Validation loss: 1.0332975387573242\n",
      "mse 1.0332975503404138\n",
      "New best model found at epoch 254 with validation loss 1.0332975387573242\n",
      "Starting Epoch 255\n",
      "1.1197329655937527\n",
      "Validation loss: 1.0332971811294556\n",
      "mse 1.0332973241704897\n",
      "New best model found at epoch 255 with validation loss 1.0332971811294556\n",
      "Starting Epoch 256\n",
      "1.1190603556840315\n",
      "Validation loss: 1.0328129529953003\n",
      "mse 1.0328130406050702\n",
      "New best model found at epoch 256 with validation loss 1.0328129529953003\n",
      "Starting Epoch 257\n",
      "1.118702857390694\n",
      "Validation loss: 1.0314947366714478\n",
      "mse 1.0314948185596875\n",
      "New best model found at epoch 257 with validation loss 1.0314947366714478\n",
      "Starting Epoch 258\n",
      "1.1180112128672393\n",
      "Validation loss: 1.0314844846725464\n",
      "mse 1.031484388925326\n",
      "New best model found at epoch 258 with validation loss 1.0314844846725464\n",
      "Starting Epoch 259\n",
      "1.1175413935080818\n",
      "Validation loss: 1.0306370258331299\n",
      "mse 1.0306368865119173\n",
      "New best model found at epoch 259 with validation loss 1.0306370258331299\n",
      "Starting Epoch 260\n",
      "1.1169000138407168\n",
      "Validation loss: 1.0303109884262085\n",
      "mse 1.0303110148927896\n",
      "New best model found at epoch 260 with validation loss 1.0303109884262085\n",
      "Starting Epoch 261\n",
      "1.1163644090942715\n",
      "Validation loss: 1.0299111604690552\n",
      "mse 1.0299112030379511\n",
      "New best model found at epoch 261 with validation loss 1.0299111604690552\n",
      "Starting Epoch 262\n",
      "1.1159720083941584\n",
      "Validation loss: 1.0296590328216553\n",
      "mse 1.029659060449553\n",
      "New best model found at epoch 262 with validation loss 1.0296590328216553\n",
      "Starting Epoch 263\n",
      "1.1155111971108809\n",
      "Validation loss: 1.0284600257873535\n",
      "mse 1.0284600646569304\n",
      "New best model found at epoch 263 with validation loss 1.0284600257873535\n",
      "Starting Epoch 264\n",
      "1.11496676310249\n",
      "Validation loss: 1.0280797481536865\n",
      "mse 1.0280798107175513\n",
      "New best model found at epoch 264 with validation loss 1.0280797481536865\n",
      "Starting Epoch 265\n",
      "1.114306900812232\n",
      "Validation loss: 1.0272904634475708\n",
      "mse 1.027290550874278\n",
      "New best model found at epoch 265 with validation loss 1.0272904634475708\n",
      "Starting Epoch 266\n",
      "1.11381450165873\n",
      "Validation loss: 1.0270698070526123\n",
      "mse 1.027069808532041\n",
      "New best model found at epoch 266 with validation loss 1.0270698070526123\n",
      "Starting Epoch 267\n",
      "1.1131487903387651\n",
      "Validation loss: 1.0264414548873901\n",
      "mse 1.026441437995762\n",
      "New best model found at epoch 267 with validation loss 1.0264414548873901\n",
      "Starting Epoch 268\n",
      "1.1127111212066982\n",
      "Validation loss: 1.025990605354309\n",
      "mse 1.025990630842826\n",
      "New best model found at epoch 268 with validation loss 1.025990605354309\n",
      "Starting Epoch 269\n",
      "1.1122061454731484\n",
      "Validation loss: 1.0251195430755615\n",
      "mse 1.02511949016388\n",
      "New best model found at epoch 269 with validation loss 1.0251195430755615\n",
      "Starting Epoch 270\n",
      "1.11143268968748\n",
      "Validation loss: 1.0247392654418945\n",
      "mse 1.0247393542466012\n",
      "New best model found at epoch 270 with validation loss 1.0247392654418945\n",
      "Starting Epoch 271\n",
      "1.110948902109395\n",
      "Validation loss: 1.0239393711090088\n",
      "mse 1.023939294597324\n",
      "New best model found at epoch 271 with validation loss 1.0239393711090088\n",
      "Starting Epoch 272\n",
      "1.1104427057763804\n",
      "Validation loss: 1.0237398147583008\n",
      "mse 1.0237397625563796\n",
      "New best model found at epoch 272 with validation loss 1.0237398147583008\n",
      "Starting Epoch 273\n",
      "1.1097428513609844\n",
      "Validation loss: 1.0230746269226074\n",
      "mse 1.02307470483015\n",
      "New best model found at epoch 273 with validation loss 1.0230746269226074\n",
      "Starting Epoch 274\n",
      "1.1092892600142437\n",
      "Validation loss: 1.0228235721588135\n",
      "mse 1.0228236124685433\n",
      "New best model found at epoch 274 with validation loss 1.0228235721588135\n",
      "Starting Epoch 275\n",
      "1.1087219326392463\n",
      "Validation loss: 1.0223888158798218\n",
      "mse 1.0223887655790416\n",
      "New best model found at epoch 275 with validation loss 1.0223888158798218\n",
      "Starting Epoch 276\n",
      "1.1082180401553279\n",
      "Validation loss: 1.0216361284255981\n",
      "mse 1.021636132676479\n",
      "New best model found at epoch 276 with validation loss 1.0216361284255981\n",
      "Starting Epoch 277\n",
      "1.107665056767671\n",
      "Validation loss: 1.020837426185608\n",
      "mse 1.020837436989179\n",
      "New best model found at epoch 277 with validation loss 1.020837426185608\n",
      "Starting Epoch 278\n",
      "1.1072115561236506\n",
      "Validation loss: 1.020442008972168\n",
      "mse 1.0204420421272435\n",
      "New best model found at epoch 278 with validation loss 1.020442008972168\n",
      "Starting Epoch 279\n",
      "1.106500734453616\n",
      "Validation loss: 1.0203194618225098\n",
      "mse 1.0203195085059276\n",
      "New best model found at epoch 279 with validation loss 1.0203194618225098\n",
      "Starting Epoch 280\n",
      "1.1060722496198572\n",
      "Validation loss: 1.0198390483856201\n",
      "mse 1.0198389922320725\n",
      "New best model found at epoch 280 with validation loss 1.0198390483856201\n",
      "Starting Epoch 281\n",
      "1.1053988389346912\n",
      "Validation loss: 1.0188393592834473\n",
      "mse 1.0188392946509448\n",
      "New best model found at epoch 281 with validation loss 1.0188393592834473\n",
      "Starting Epoch 282\n",
      "1.1049368459245432\n",
      "Validation loss: 1.0184725522994995\n",
      "mse 1.018472582644085\n",
      "New best model found at epoch 282 with validation loss 1.0184725522994995\n",
      "Starting Epoch 283\n",
      "1.1043070787968843\n",
      "Validation loss: 1.0181374549865723\n",
      "mse 1.0181374176455238\n",
      "New best model found at epoch 283 with validation loss 1.0181374549865723\n",
      "Starting Epoch 284\n",
      "1.1037445923556453\n",
      "Validation loss: 1.0176199674606323\n",
      "mse 1.0176199595474154\n",
      "New best model found at epoch 284 with validation loss 1.0176199674606323\n",
      "Starting Epoch 285\n",
      "1.1033807396888733\n",
      "Validation loss: 1.0170649290084839\n",
      "mse 1.0170648653229866\n",
      "New best model found at epoch 285 with validation loss 1.0170649290084839\n",
      "Starting Epoch 286\n",
      "1.1028580354607624\n",
      "Validation loss: 1.0166113376617432\n",
      "mse 1.0166113784424369\n",
      "New best model found at epoch 286 with validation loss 1.0166113376617432\n",
      "Starting Epoch 287\n",
      "1.1023950732272605\n",
      "Validation loss: 1.0161385536193848\n",
      "mse 1.0161385466532449\n",
      "New best model found at epoch 287 with validation loss 1.0161385536193848\n",
      "Starting Epoch 288\n",
      "1.1017819021059119\n",
      "Validation loss: 1.0151844024658203\n",
      "mse 1.015184437145047\n",
      "New best model found at epoch 288 with validation loss 1.0151844024658203\n",
      "Starting Epoch 289\n",
      "1.1013507195141004\n",
      "Validation loss: 1.0151058435440063\n",
      "mse 1.0151058097776222\n",
      "New best model found at epoch 289 with validation loss 1.0151058435440063\n",
      "Starting Epoch 290\n",
      "1.1008196550866831\n",
      "Validation loss: 1.01432204246521\n",
      "mse 1.01432191274917\n",
      "New best model found at epoch 290 with validation loss 1.01432204246521\n",
      "Starting Epoch 291\n",
      "1.1002408214237378\n",
      "Validation loss: 1.0138787031173706\n",
      "mse 1.0138787279620933\n",
      "New best model found at epoch 291 with validation loss 1.0138787031173706\n",
      "Starting Epoch 292\n",
      "1.0997861157292905\n",
      "Validation loss: 1.0134334564208984\n",
      "mse 1.0134334768178093\n",
      "New best model found at epoch 292 with validation loss 1.0134334564208984\n",
      "Starting Epoch 293\n",
      "1.09925231207972\n",
      "Validation loss: 1.013145089149475\n",
      "mse 1.0131451289314999\n",
      "New best model found at epoch 293 with validation loss 1.013145089149475\n",
      "Starting Epoch 294\n",
      "1.0988212538802105\n",
      "Validation loss: 1.012252688407898\n",
      "mse 1.0122527363268954\n",
      "New best model found at epoch 294 with validation loss 1.012252688407898\n",
      "Starting Epoch 295\n",
      "1.0983651928279712\n",
      "Validation loss: 1.0124354362487793\n",
      "mse 1.0124354643902005\n",
      "Starting Epoch 296\n",
      "1.0978870521421018\n",
      "Validation loss: 1.011744737625122\n",
      "mse 1.011744820216241\n",
      "New best model found at epoch 296 with validation loss 1.011744737625122\n",
      "Starting Epoch 297\n",
      "1.0974376590355583\n",
      "Validation loss: 1.011208415031433\n",
      "mse 1.0112083363430726\n",
      "New best model found at epoch 297 with validation loss 1.011208415031433\n",
      "Starting Epoch 298\n",
      "1.0969001598980115\n",
      "Validation loss: 1.0107780694961548\n",
      "mse 1.0107781102664177\n",
      "New best model found at epoch 298 with validation loss 1.0107780694961548\n",
      "Starting Epoch 299\n",
      "1.0964972299078237\n",
      "Validation loss: 1.0105317831039429\n",
      "mse 1.0105317284289068\n",
      "New best model found at epoch 299 with validation loss 1.0105317831039429\n",
      "Starting Epoch 300\n",
      "1.0960912808128025\n",
      "Validation loss: 1.0096018314361572\n",
      "mse 1.0096018095261152\n",
      "New best model found at epoch 300 with validation loss 1.0096018314361572\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-60-40-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdceb04",
   "metadata": {},
   "source": [
    "##### 4-layers MLP: Version 6\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 60 - 20 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "e817cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "b93d3d48-66ed-4ed7-bbaa-32b70f7d8760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.0279541689416636\n",
      "Validation loss: 2.537684202194214\n",
      "mse 2.5376842986922084\n",
      "New best model found at epoch 1 with validation loss 2.537684202194214\n",
      "Starting Epoch 2\n",
      "2.6774327754974365\n",
      "Validation loss: 2.3302500247955322\n",
      "mse 2.330250106119519\n",
      "New best model found at epoch 2 with validation loss 2.3302500247955322\n",
      "Starting Epoch 3\n",
      "2.442050109738889\n",
      "Validation loss: 2.144137144088745\n",
      "mse 2.1441372085649615\n",
      "New best model found at epoch 3 with validation loss 2.144137144088745\n",
      "Starting Epoch 4\n",
      "2.2517011683920156\n",
      "Validation loss: 1.9894649982452393\n",
      "mse 1.9894651827920176\n",
      "New best model found at epoch 4 with validation loss 1.9894649982452393\n",
      "Starting Epoch 5\n",
      "2.1067618649938833\n",
      "Validation loss: 1.8669233322143555\n",
      "mse 1.8669232495244568\n",
      "New best model found at epoch 5 with validation loss 1.8669233322143555\n",
      "Starting Epoch 6\n",
      "1.994538048039312\n",
      "Validation loss: 1.7808995246887207\n",
      "mse 1.7808994012578083\n",
      "New best model found at epoch 6 with validation loss 1.7808995246887207\n",
      "Starting Epoch 7\n",
      "1.9122489638950513\n",
      "Validation loss: 1.7128276824951172\n",
      "mse 1.7128277542864403\n",
      "New best model found at epoch 7 with validation loss 1.7128276824951172\n",
      "Starting Epoch 8\n",
      "1.8491125728773035\n",
      "Validation loss: 1.6628475189208984\n",
      "mse 1.6628475425303593\n",
      "New best model found at epoch 8 with validation loss 1.6628475189208984\n",
      "Starting Epoch 9\n",
      "1.7994080159975134\n",
      "Validation loss: 1.6260254383087158\n",
      "mse 1.626025283365381\n",
      "New best model found at epoch 9 with validation loss 1.6260254383087158\n",
      "Starting Epoch 10\n",
      "1.7620875628098198\n",
      "Validation loss: 1.5969618558883667\n",
      "mse 1.5969619222987939\n",
      "New best model found at epoch 10 with validation loss 1.5969618558883667\n",
      "Starting Epoch 11\n",
      "1.7301719603331194\n",
      "Validation loss: 1.5742900371551514\n",
      "mse 1.5742899572730928\n",
      "New best model found at epoch 11 with validation loss 1.5742900371551514\n",
      "Starting Epoch 12\n",
      "1.7050528267155522\n",
      "Validation loss: 1.5561060905456543\n",
      "mse 1.5561060368955024\n",
      "New best model found at epoch 12 with validation loss 1.5561060905456543\n",
      "Starting Epoch 13\n",
      "1.6848552486170894\n",
      "Validation loss: 1.5414834022521973\n",
      "mse 1.5414834862693068\n",
      "New best model found at epoch 13 with validation loss 1.5414834022521973\n",
      "Starting Epoch 14\n",
      "1.6682583819264951\n",
      "Validation loss: 1.528152585029602\n",
      "mse 1.5281525931516875\n",
      "New best model found at epoch 14 with validation loss 1.528152585029602\n",
      "Starting Epoch 15\n",
      "1.6525562431501306\n",
      "Validation loss: 1.517648696899414\n",
      "mse 1.517648589299566\n",
      "New best model found at epoch 15 with validation loss 1.517648696899414\n",
      "Starting Epoch 16\n",
      "1.639966897342516\n",
      "Validation loss: 1.5073059797286987\n",
      "mse 1.5073060656665693\n",
      "New best model found at epoch 16 with validation loss 1.5073059797286987\n",
      "Starting Epoch 17\n",
      "1.6276195075200952\n",
      "Validation loss: 1.4980955123901367\n",
      "mse 1.4980955059993646\n",
      "New best model found at epoch 17 with validation loss 1.4980955123901367\n",
      "Starting Epoch 18\n",
      "1.6162560089774753\n",
      "Validation loss: 1.4894516468048096\n",
      "mse 1.4894517793913475\n",
      "New best model found at epoch 18 with validation loss 1.4894516468048096\n",
      "Starting Epoch 19\n",
      "1.6071168287940647\n",
      "Validation loss: 1.4813166856765747\n",
      "mse 1.4813166515634795\n",
      "New best model found at epoch 19 with validation loss 1.4813166856765747\n",
      "Starting Epoch 20\n",
      "1.5976303297540415\n",
      "Validation loss: 1.4742788076400757\n",
      "mse 1.4742788872424073\n",
      "New best model found at epoch 20 with validation loss 1.4742788076400757\n",
      "Starting Epoch 21\n",
      "1.5894636019416477\n",
      "Validation loss: 1.4679975509643555\n",
      "mse 1.467997342135184\n",
      "New best model found at epoch 21 with validation loss 1.4679975509643555\n",
      "Starting Epoch 22\n",
      "1.582116020762402\n",
      "Validation loss: 1.4626011848449707\n",
      "mse 1.4626012777699269\n",
      "New best model found at epoch 22 with validation loss 1.4626011848449707\n",
      "Starting Epoch 23\n",
      "1.5751848816871643\n",
      "Validation loss: 1.4570562839508057\n",
      "mse 1.457056293130653\n",
      "New best model found at epoch 23 with validation loss 1.4570562839508057\n",
      "Starting Epoch 24\n",
      "1.5681920051574707\n",
      "Validation loss: 1.451187252998352\n",
      "mse 1.4511872747947947\n",
      "New best model found at epoch 24 with validation loss 1.451187252998352\n",
      "Starting Epoch 25\n",
      "1.5617492224859155\n",
      "Validation loss: 1.4447011947631836\n",
      "mse 1.444701164482686\n",
      "New best model found at epoch 25 with validation loss 1.4447011947631836\n",
      "Starting Epoch 26\n",
      "1.5551164150238037\n",
      "Validation loss: 1.4387199878692627\n",
      "mse 1.4387200214863465\n",
      "New best model found at epoch 26 with validation loss 1.4387199878692627\n",
      "Starting Epoch 27\n",
      "1.5491624008054319\n",
      "Validation loss: 1.433661937713623\n",
      "mse 1.4336619799714798\n",
      "New best model found at epoch 27 with validation loss 1.433661937713623\n",
      "Starting Epoch 28\n",
      "1.5436262617940488\n",
      "Validation loss: 1.4291114807128906\n",
      "mse 1.429111489709975\n",
      "New best model found at epoch 28 with validation loss 1.4291114807128906\n",
      "Starting Epoch 29\n",
      "1.5381571495014688\n",
      "Validation loss: 1.4250717163085938\n",
      "mse 1.4250716287397098\n",
      "New best model found at epoch 29 with validation loss 1.4250717163085938\n",
      "Starting Epoch 30\n",
      "1.5328085837156877\n",
      "Validation loss: 1.420370101928711\n",
      "mse 1.4203700373103032\n",
      "New best model found at epoch 30 with validation loss 1.420370101928711\n",
      "Starting Epoch 31\n",
      "1.5277865917786309\n",
      "Validation loss: 1.416049599647522\n",
      "mse 1.4160495974215745\n",
      "New best model found at epoch 31 with validation loss 1.416049599647522\n",
      "Starting Epoch 32\n",
      "1.522932591645614\n",
      "Validation loss: 1.4125696420669556\n",
      "mse 1.412569675853772\n",
      "New best model found at epoch 32 with validation loss 1.4125696420669556\n",
      "Starting Epoch 33\n",
      "1.5183384548062864\n",
      "Validation loss: 1.408549427986145\n",
      "mse 1.4085492992875568\n",
      "New best model found at epoch 33 with validation loss 1.408549427986145\n",
      "Starting Epoch 34\n",
      "1.5138337663982226\n",
      "Validation loss: 1.4051753282546997\n",
      "mse 1.4051755142363191\n",
      "New best model found at epoch 34 with validation loss 1.4051753282546997\n",
      "Starting Epoch 35\n",
      "1.5096038139384726\n",
      "Validation loss: 1.4015192985534668\n",
      "mse 1.40151917660201\n",
      "New best model found at epoch 35 with validation loss 1.4015192985534668\n",
      "Starting Epoch 36\n",
      "1.5053768624430117\n",
      "Validation loss: 1.3984980583190918\n",
      "mse 1.3984980957913287\n",
      "New best model found at epoch 36 with validation loss 1.3984980583190918\n",
      "Starting Epoch 37\n",
      "1.5014921815499016\n",
      "Validation loss: 1.3958560228347778\n",
      "mse 1.3958560534061881\n",
      "New best model found at epoch 37 with validation loss 1.3958560228347778\n",
      "Starting Epoch 38\n",
      "1.4973888189896294\n",
      "Validation loss: 1.3928834199905396\n",
      "mse 1.392883449720938\n",
      "New best model found at epoch 38 with validation loss 1.3928834199905396\n",
      "Starting Epoch 39\n",
      "1.4935142320135366\n",
      "Validation loss: 1.3898835182189941\n",
      "mse 1.389883605438602\n",
      "New best model found at epoch 39 with validation loss 1.3898835182189941\n",
      "Starting Epoch 40\n",
      "1.4896464399669482\n",
      "Validation loss: 1.3864874839782715\n",
      "mse 1.386487619102013\n",
      "New best model found at epoch 40 with validation loss 1.3864874839782715\n",
      "Starting Epoch 41\n",
      "1.4857944768408071\n",
      "Validation loss: 1.3841341733932495\n",
      "mse 1.3841342137876163\n",
      "New best model found at epoch 41 with validation loss 1.3841341733932495\n",
      "Starting Epoch 42\n",
      "1.4821440344271453\n",
      "Validation loss: 1.3812795877456665\n",
      "mse 1.3812797168927804\n",
      "New best model found at epoch 42 with validation loss 1.3812795877456665\n",
      "Starting Epoch 43\n",
      "1.4786727298860964\n",
      "Validation loss: 1.3788905143737793\n",
      "mse 1.3788905681348749\n",
      "New best model found at epoch 43 with validation loss 1.3788905143737793\n",
      "Starting Epoch 44\n",
      "1.475101297316344\n",
      "Validation loss: 1.3766855001449585\n",
      "mse 1.3766855896940422\n",
      "New best model found at epoch 44 with validation loss 1.3766855001449585\n",
      "Starting Epoch 45\n",
      "1.4717521848885908\n",
      "Validation loss: 1.3736259937286377\n",
      "mse 1.3736259363499979\n",
      "New best model found at epoch 45 with validation loss 1.3736259937286377\n",
      "Starting Epoch 46\n",
      "1.4682698249816895\n",
      "Validation loss: 1.371914267539978\n",
      "mse 1.3719144394954583\n",
      "New best model found at epoch 46 with validation loss 1.371914267539978\n",
      "Starting Epoch 47\n",
      "1.465063802573992\n",
      "Validation loss: 1.369072437286377\n",
      "mse 1.3690723631490496\n",
      "New best model found at epoch 47 with validation loss 1.369072437286377\n",
      "Starting Epoch 48\n",
      "1.4617521451867146\n",
      "Validation loss: 1.3676975965499878\n",
      "mse 1.367697467482422\n",
      "New best model found at epoch 48 with validation loss 1.3676975965499878\n",
      "Starting Epoch 49\n",
      "1.458819876546445\n",
      "Validation loss: 1.3648817539215088\n",
      "mse 1.3648817018318649\n",
      "New best model found at epoch 49 with validation loss 1.3648817539215088\n",
      "Starting Epoch 50\n",
      "1.4556844078976174\n",
      "Validation loss: 1.3637666702270508\n",
      "mse 1.3637666855697288\n",
      "New best model found at epoch 50 with validation loss 1.3637666702270508\n",
      "Starting Epoch 51\n",
      "1.4527353100154712\n",
      "Validation loss: 1.361377239227295\n",
      "mse 1.3613771281079572\n",
      "New best model found at epoch 51 with validation loss 1.361377239227295\n",
      "Starting Epoch 52\n",
      "1.4498083850611811\n",
      "Validation loss: 1.3596923351287842\n",
      "mse 1.3596923076981353\n",
      "New best model found at epoch 52 with validation loss 1.3596923351287842\n",
      "Starting Epoch 53\n",
      "1.4469549474508867\n",
      "Validation loss: 1.3573914766311646\n",
      "mse 1.3573913784767555\n",
      "New best model found at epoch 53 with validation loss 1.3573914766311646\n",
      "Starting Epoch 54\n",
      "1.4440692196721616\n",
      "Validation loss: 1.3550431728363037\n",
      "mse 1.3550431749715313\n",
      "New best model found at epoch 54 with validation loss 1.3550431728363037\n",
      "Starting Epoch 55\n",
      "1.441652906977612\n",
      "Validation loss: 1.3548626899719238\n",
      "mse 1.3548625865175614\n",
      "New best model found at epoch 55 with validation loss 1.3548626899719238\n",
      "Starting Epoch 56\n",
      "1.4388995740724646\n",
      "Validation loss: 1.351514220237732\n",
      "mse 1.35151421415421\n",
      "New best model found at epoch 56 with validation loss 1.351514220237732\n",
      "Starting Epoch 57\n",
      "1.4362280135569365\n",
      "Validation loss: 1.3499051332473755\n",
      "mse 1.3499051148658963\n",
      "New best model found at epoch 57 with validation loss 1.3499051332473755\n",
      "Starting Epoch 58\n",
      "1.4338006195814714\n",
      "Validation loss: 1.3485920429229736\n",
      "mse 1.348592109529664\n",
      "New best model found at epoch 58 with validation loss 1.3485920429229736\n",
      "Starting Epoch 59\n",
      "1.4312112538710884\n",
      "Validation loss: 1.346596360206604\n",
      "mse 1.3465963324583865\n",
      "New best model found at epoch 59 with validation loss 1.346596360206604\n",
      "Starting Epoch 60\n",
      "1.428947267325028\n",
      "Validation loss: 1.3449556827545166\n",
      "mse 1.344955725029817\n",
      "New best model found at epoch 60 with validation loss 1.3449556827545166\n",
      "Starting Epoch 61\n",
      "1.4263498653536257\n",
      "Validation loss: 1.3418258428573608\n",
      "mse 1.3418258668330523\n",
      "New best model found at epoch 61 with validation loss 1.3418258428573608\n",
      "Starting Epoch 62\n",
      "1.423802482045215\n",
      "Validation loss: 1.3407816886901855\n",
      "mse 1.3407817005983964\n",
      "New best model found at epoch 62 with validation loss 1.3407816886901855\n",
      "Starting Epoch 63\n",
      "1.4216028400089429\n",
      "Validation loss: 1.3391364812850952\n",
      "mse 1.3391364687039107\n",
      "New best model found at epoch 63 with validation loss 1.3391364812850952\n",
      "Starting Epoch 64\n",
      "1.4192212949628416\n",
      "Validation loss: 1.337597370147705\n",
      "mse 1.3375973371524164\n",
      "New best model found at epoch 64 with validation loss 1.337597370147705\n",
      "Starting Epoch 65\n",
      "1.417063244011091\n",
      "Validation loss: 1.3360466957092285\n",
      "mse 1.3360466861324023\n",
      "New best model found at epoch 65 with validation loss 1.3360466957092285\n",
      "Starting Epoch 66\n",
      "1.4147734279217927\n",
      "Validation loss: 1.3349742889404297\n",
      "mse 1.3349742390351642\n",
      "New best model found at epoch 66 with validation loss 1.3349742889404297\n",
      "Starting Epoch 67\n",
      "1.412722901157711\n",
      "Validation loss: 1.3326361179351807\n",
      "mse 1.3326360490215907\n",
      "New best model found at epoch 67 with validation loss 1.3326361179351807\n",
      "Starting Epoch 68\n",
      "1.4104367209517437\n",
      "Validation loss: 1.3306806087493896\n",
      "mse 1.330680549187099\n",
      "New best model found at epoch 68 with validation loss 1.3306806087493896\n",
      "Starting Epoch 69\n",
      "1.4082520941029424\n",
      "Validation loss: 1.3284615278244019\n",
      "mse 1.3284614086133633\n",
      "New best model found at epoch 69 with validation loss 1.3284615278244019\n",
      "Starting Epoch 70\n",
      "1.4059950631597768\n",
      "Validation loss: 1.326749563217163\n",
      "mse 1.3267496351642152\n",
      "New best model found at epoch 70 with validation loss 1.326749563217163\n",
      "Starting Epoch 71\n",
      "1.4039466692053753\n",
      "Validation loss: 1.3258485794067383\n",
      "mse 1.325848542489591\n",
      "New best model found at epoch 71 with validation loss 1.3258485794067383\n",
      "Starting Epoch 72\n",
      "1.401584664116735\n",
      "Validation loss: 1.3217473030090332\n",
      "mse 1.3217472350690413\n",
      "New best model found at epoch 72 with validation loss 1.3217473030090332\n",
      "Starting Epoch 73\n",
      "1.3993956109751826\n",
      "Validation loss: 1.3199539184570312\n",
      "mse 1.3199539474181343\n",
      "New best model found at epoch 73 with validation loss 1.3199539184570312\n",
      "Starting Epoch 74\n",
      "1.396772509035857\n",
      "Validation loss: 1.317988634109497\n",
      "mse 1.317988618169174\n",
      "New best model found at epoch 74 with validation loss 1.317988634109497\n",
      "Starting Epoch 75\n",
      "1.3947350434634997\n",
      "Validation loss: 1.316967248916626\n",
      "mse 1.316967388583862\n",
      "New best model found at epoch 75 with validation loss 1.316967248916626\n",
      "Starting Epoch 76\n",
      "1.3923608297887056\n",
      "Validation loss: 1.3147377967834473\n",
      "mse 1.3147378027462364\n",
      "New best model found at epoch 76 with validation loss 1.3147377967834473\n",
      "Starting Epoch 77\n",
      "1.39044291558473\n",
      "Validation loss: 1.313825249671936\n",
      "mse 1.31382519455314\n",
      "New best model found at epoch 77 with validation loss 1.313825249671936\n",
      "Starting Epoch 78\n",
      "1.388201918291009\n",
      "Validation loss: 1.3118748664855957\n",
      "mse 1.3118748026072062\n",
      "New best model found at epoch 78 with validation loss 1.3118748664855957\n",
      "Starting Epoch 79\n",
      "1.3858578049618264\n",
      "Validation loss: 1.309857726097107\n",
      "mse 1.309857872928158\n",
      "New best model found at epoch 79 with validation loss 1.309857726097107\n",
      "Starting Epoch 80\n",
      "1.3838821053504944\n",
      "Validation loss: 1.3080434799194336\n",
      "mse 1.308043410287164\n",
      "New best model found at epoch 80 with validation loss 1.3080434799194336\n",
      "Starting Epoch 81\n",
      "1.381866146688876\n",
      "Validation loss: 1.3070018291473389\n",
      "mse 1.3070018330567807\n",
      "New best model found at epoch 81 with validation loss 1.3070018291473389\n",
      "Starting Epoch 82\n",
      "1.3798808533212412\n",
      "Validation loss: 1.304304599761963\n",
      "mse 1.304304594360478\n",
      "New best model found at epoch 82 with validation loss 1.304304599761963\n",
      "Starting Epoch 83\n",
      "1.3776232470636782\n",
      "Validation loss: 1.3020037412643433\n",
      "mse 1.3020037553410888\n",
      "New best model found at epoch 83 with validation loss 1.3020037412643433\n",
      "Starting Epoch 84\n",
      "1.3755206154740376\n",
      "Validation loss: 1.3003515005111694\n",
      "mse 1.3003514165288144\n",
      "New best model found at epoch 84 with validation loss 1.3003515005111694\n",
      "Starting Epoch 85\n",
      "1.3733526468276978\n",
      "Validation loss: 1.2978706359863281\n",
      "mse 1.297870532981056\n",
      "New best model found at epoch 85 with validation loss 1.2978706359863281\n",
      "Starting Epoch 86\n",
      "1.3713672601658364\n",
      "Validation loss: 1.2966382503509521\n",
      "mse 1.2966382424548248\n",
      "New best model found at epoch 86 with validation loss 1.2966382503509521\n",
      "Starting Epoch 87\n",
      "1.3694695985835532\n",
      "Validation loss: 1.2952831983566284\n",
      "mse 1.2952832327292738\n",
      "New best model found at epoch 87 with validation loss 1.2952831983566284\n",
      "Starting Epoch 88\n",
      "1.367683073748713\n",
      "Validation loss: 1.2941960096359253\n",
      "mse 1.2941960357239444\n",
      "New best model found at epoch 88 with validation loss 1.2941960096359253\n",
      "Starting Epoch 89\n",
      "1.3658983655597852\n",
      "Validation loss: 1.2921146154403687\n",
      "mse 1.292114506825482\n",
      "New best model found at epoch 89 with validation loss 1.2921146154403687\n",
      "Starting Epoch 90\n",
      "1.36407986153727\n",
      "Validation loss: 1.290545105934143\n",
      "mse 1.2905448784153826\n",
      "New best model found at epoch 90 with validation loss 1.290545105934143\n",
      "Starting Epoch 91\n",
      "1.3621747467828833\n",
      "Validation loss: 1.2894667387008667\n",
      "mse 1.2894667328720213\n",
      "New best model found at epoch 91 with validation loss 1.2894667387008667\n",
      "Starting Epoch 92\n",
      "1.3602926782939746\n",
      "Validation loss: 1.2880687713623047\n",
      "mse 1.288068723027243\n",
      "New best model found at epoch 92 with validation loss 1.2880687713623047\n",
      "Starting Epoch 93\n",
      "1.3586738109588623\n",
      "Validation loss: 1.2864761352539062\n",
      "mse 1.2864762499891171\n",
      "New best model found at epoch 93 with validation loss 1.2864761352539062\n",
      "Starting Epoch 94\n",
      "1.356869031553683\n",
      "Validation loss: 1.2850940227508545\n",
      "mse 1.28509399187487\n",
      "New best model found at epoch 94 with validation loss 1.2850940227508545\n",
      "Starting Epoch 95\n",
      "1.3550423720608586\n",
      "Validation loss: 1.283534049987793\n",
      "mse 1.2835338072034517\n",
      "New best model found at epoch 95 with validation loss 1.283534049987793\n",
      "Starting Epoch 96\n",
      "1.3535004620966704\n",
      "Validation loss: 1.2828480005264282\n",
      "mse 1.2828480438188032\n",
      "New best model found at epoch 96 with validation loss 1.2828480005264282\n",
      "Starting Epoch 97\n",
      "1.351954926615176\n",
      "Validation loss: 1.2806110382080078\n",
      "mse 1.2806110372191797\n",
      "New best model found at epoch 97 with validation loss 1.2806110382080078\n",
      "Starting Epoch 98\n",
      "1.350127424882806\n",
      "Validation loss: 1.279767394065857\n",
      "mse 1.2797674723923682\n",
      "New best model found at epoch 98 with validation loss 1.279767394065857\n",
      "Starting Epoch 99\n",
      "1.3486013878946719\n",
      "Validation loss: 1.2787959575653076\n",
      "mse 1.2787959495632528\n",
      "New best model found at epoch 99 with validation loss 1.2787959575653076\n",
      "Starting Epoch 100\n",
      "1.3469972014427185\n",
      "Validation loss: 1.2773720026016235\n",
      "mse 1.2773720422554375\n",
      "New best model found at epoch 100 with validation loss 1.2773720026016235\n",
      "Starting Epoch 101\n",
      "1.3454096809677456\n",
      "Validation loss: 1.276146650314331\n",
      "mse 1.2761467476856512\n",
      "New best model found at epoch 101 with validation loss 1.276146650314331\n",
      "Starting Epoch 102\n",
      "1.3440357550330784\n",
      "Validation loss: 1.2754664421081543\n",
      "mse 1.2754663103565227\n",
      "New best model found at epoch 102 with validation loss 1.2754664421081543\n",
      "Starting Epoch 103\n",
      "1.342340420121732\n",
      "Validation loss: 1.2741684913635254\n",
      "mse 1.2741683963456056\n",
      "New best model found at epoch 103 with validation loss 1.2741684913635254\n",
      "Starting Epoch 104\n",
      "1.3409914400266565\n",
      "Validation loss: 1.2724019289016724\n",
      "mse 1.2724018985328134\n",
      "New best model found at epoch 104 with validation loss 1.2724019289016724\n",
      "Starting Epoch 105\n",
      "1.3395115888637046\n",
      "Validation loss: 1.2717344760894775\n",
      "mse 1.2717344879083818\n",
      "New best model found at epoch 105 with validation loss 1.2717344760894775\n",
      "Starting Epoch 106\n",
      "1.338280667429385\n",
      "Validation loss: 1.2713160514831543\n",
      "mse 1.271315883452634\n",
      "New best model found at epoch 106 with validation loss 1.2713160514831543\n",
      "Starting Epoch 107\n",
      "1.3367919196253237\n",
      "Validation loss: 1.269514560699463\n",
      "mse 1.2695146252573948\n",
      "New best model found at epoch 107 with validation loss 1.269514560699463\n",
      "Starting Epoch 108\n",
      "1.335398308608843\n",
      "Validation loss: 1.2693709135055542\n",
      "mse 1.2693709299229001\n",
      "New best model found at epoch 108 with validation loss 1.2693709135055542\n",
      "Starting Epoch 109\n",
      "1.3340610732202944\n",
      "Validation loss: 1.2676631212234497\n",
      "mse 1.2676631608279685\n",
      "New best model found at epoch 109 with validation loss 1.2676631212234497\n",
      "Starting Epoch 110\n",
      "1.3325956334238467\n",
      "Validation loss: 1.2669323682785034\n",
      "mse 1.2669322990667962\n",
      "New best model found at epoch 110 with validation loss 1.2669323682785034\n",
      "Starting Epoch 111\n",
      "1.3310279405635337\n",
      "Validation loss: 1.2655315399169922\n",
      "mse 1.265531452249753\n",
      "New best model found at epoch 111 with validation loss 1.2655315399169922\n",
      "Starting Epoch 112\n",
      "1.3297722417375315\n",
      "Validation loss: 1.2645652294158936\n",
      "mse 1.2645652921330168\n",
      "New best model found at epoch 112 with validation loss 1.2645652294158936\n",
      "Starting Epoch 113\n",
      "1.3284471916115803\n",
      "Validation loss: 1.2637076377868652\n",
      "mse 1.2637076939516623\n",
      "New best model found at epoch 113 with validation loss 1.2637076377868652\n",
      "Starting Epoch 114\n",
      "1.3272337110146233\n",
      "Validation loss: 1.2626190185546875\n",
      "mse 1.2626190010114522\n",
      "New best model found at epoch 114 with validation loss 1.2626190185546875\n",
      "Starting Epoch 115\n",
      "1.3258241415023804\n",
      "Validation loss: 1.2615771293640137\n",
      "mse 1.2615771831635365\n",
      "New best model found at epoch 115 with validation loss 1.2615771293640137\n",
      "Starting Epoch 116\n",
      "1.324516086474709\n",
      "Validation loss: 1.2604565620422363\n",
      "mse 1.2604565064288975\n",
      "New best model found at epoch 116 with validation loss 1.2604565620422363\n",
      "Starting Epoch 117\n",
      "1.3234934832738794\n",
      "Validation loss: 1.260573387145996\n",
      "mse 1.260573411431926\n",
      "Starting Epoch 118\n",
      "1.3221275288125742\n",
      "Validation loss: 1.2584385871887207\n",
      "mse 1.258438511780783\n",
      "New best model found at epoch 118 with validation loss 1.2584385871887207\n",
      "Starting Epoch 119\n",
      "1.3209660130998362\n",
      "Validation loss: 1.258872628211975\n",
      "mse 1.2588725181378488\n",
      "Starting Epoch 120\n",
      "1.31976346347643\n",
      "Validation loss: 1.2565943002700806\n",
      "mse 1.256594246953431\n",
      "New best model found at epoch 120 with validation loss 1.2565943002700806\n",
      "Starting Epoch 121\n",
      "1.3183420455974082\n",
      "Validation loss: 1.2558234930038452\n",
      "mse 1.255823467163397\n",
      "New best model found at epoch 121 with validation loss 1.2558234930038452\n",
      "Starting Epoch 122\n",
      "1.3170269002085147\n",
      "Validation loss: 1.2550297975540161\n",
      "mse 1.2550297266250907\n",
      "New best model found at epoch 122 with validation loss 1.2550297975540161\n",
      "Starting Epoch 123\n",
      "1.3159336629121199\n",
      "Validation loss: 1.2545050382614136\n",
      "mse 1.2545049651785605\n",
      "New best model found at epoch 123 with validation loss 1.2545050382614136\n",
      "Starting Epoch 124\n",
      "1.3146947285403376\n",
      "Validation loss: 1.254386305809021\n",
      "mse 1.2543863304528082\n",
      "New best model found at epoch 124 with validation loss 1.254386305809021\n",
      "Starting Epoch 125\n",
      "1.313525070314822\n",
      "Validation loss: 1.2523537874221802\n",
      "mse 1.252353878640365\n",
      "New best model found at epoch 125 with validation loss 1.2523537874221802\n",
      "Starting Epoch 126\n",
      "1.3121919243232063\n",
      "Validation loss: 1.2511855363845825\n",
      "mse 1.251185426496379\n",
      "New best model found at epoch 126 with validation loss 1.2511855363845825\n",
      "Starting Epoch 127\n",
      "1.310901351596998\n",
      "Validation loss: 1.2505217790603638\n",
      "mse 1.2505216927213247\n",
      "New best model found at epoch 127 with validation loss 1.2505217790603638\n",
      "Starting Epoch 128\n",
      "1.3096523155336794\n",
      "Validation loss: 1.2494038343429565\n",
      "mse 1.249403828105174\n",
      "New best model found at epoch 128 with validation loss 1.2494038343429565\n",
      "Starting Epoch 129\n",
      "1.3085680992706963\n",
      "Validation loss: 1.2484482526779175\n",
      "mse 1.2484481960894314\n",
      "New best model found at epoch 129 with validation loss 1.2484482526779175\n",
      "Starting Epoch 130\n",
      "1.307218515354654\n",
      "Validation loss: 1.2486218214035034\n",
      "mse 1.2486217859830635\n",
      "Starting Epoch 131\n",
      "1.3061611963355022\n",
      "Validation loss: 1.2469979524612427\n",
      "mse 1.2469979584423\n",
      "New best model found at epoch 131 with validation loss 1.2469979524612427\n",
      "Starting Epoch 132\n",
      "1.3049730736276377\n",
      "Validation loss: 1.2456884384155273\n",
      "mse 1.2456885001959688\n",
      "New best model found at epoch 132 with validation loss 1.2456884384155273\n",
      "Starting Epoch 133\n",
      "1.3038378046906514\n",
      "Validation loss: 1.2449649572372437\n",
      "mse 1.2449648149916053\n",
      "New best model found at epoch 133 with validation loss 1.2449649572372437\n",
      "Starting Epoch 134\n",
      "1.3026310024054155\n",
      "Validation loss: 1.2452492713928223\n",
      "mse 1.2452493133868607\n",
      "Starting Epoch 135\n",
      "1.3014329645944678\n",
      "Validation loss: 1.2429707050323486\n",
      "mse 1.2429707095700064\n",
      "New best model found at epoch 135 with validation loss 1.2429707050323486\n",
      "Starting Epoch 136\n",
      "1.3000110465547312\n",
      "Validation loss: 1.2416545152664185\n",
      "mse 1.2416545870361166\n",
      "New best model found at epoch 136 with validation loss 1.2416545152664185\n",
      "Starting Epoch 137\n",
      "1.29885036530702\n",
      "Validation loss: 1.2413884401321411\n",
      "mse 1.2413883912094517\n",
      "New best model found at epoch 137 with validation loss 1.2413884401321411\n",
      "Starting Epoch 138\n",
      "1.2976072612016096\n",
      "Validation loss: 1.2400680780410767\n",
      "mse 1.2400681602705523\n",
      "New best model found at epoch 138 with validation loss 1.2400680780410767\n",
      "Starting Epoch 139\n",
      "1.2962164775184963\n",
      "Validation loss: 1.2383978366851807\n",
      "mse 1.2383979163567531\n",
      "New best model found at epoch 139 with validation loss 1.2383978366851807\n",
      "Starting Epoch 140\n",
      "1.2950664966002754\n",
      "Validation loss: 1.2372171878814697\n",
      "mse 1.2372172596386455\n",
      "New best model found at epoch 140 with validation loss 1.2372171878814697\n",
      "Starting Epoch 141\n",
      "1.2937885341436968\n",
      "Validation loss: 1.2359734773635864\n",
      "mse 1.2359733951688916\n",
      "New best model found at epoch 141 with validation loss 1.2359734773635864\n",
      "Starting Epoch 142\n",
      "1.2926233825476274\n",
      "Validation loss: 1.235079050064087\n",
      "mse 1.2350790442745125\n",
      "New best model found at epoch 142 with validation loss 1.235079050064087\n",
      "Starting Epoch 143\n",
      "1.291538979696191\n",
      "Validation loss: 1.2346580028533936\n",
      "mse 1.2346580358719723\n",
      "New best model found at epoch 143 with validation loss 1.2346580028533936\n",
      "Starting Epoch 144\n",
      "1.290351647397746\n",
      "Validation loss: 1.23335599899292\n",
      "mse 1.2333558356388667\n",
      "New best model found at epoch 144 with validation loss 1.23335599899292\n",
      "Starting Epoch 145\n",
      "1.2893852410109148\n",
      "Validation loss: 1.2333786487579346\n",
      "mse 1.2333787232460174\n",
      "Starting Epoch 146\n",
      "1.2884386544642241\n",
      "Validation loss: 1.232147216796875\n",
      "mse 1.2321471842308744\n",
      "New best model found at epoch 146 with validation loss 1.232147216796875\n",
      "Starting Epoch 147\n",
      "1.2873472649118174\n",
      "Validation loss: 1.2307302951812744\n",
      "mse 1.2307302989832039\n",
      "New best model found at epoch 147 with validation loss 1.2307302951812744\n",
      "Starting Epoch 148\n",
      "1.2862498449242634\n",
      "Validation loss: 1.2302002906799316\n",
      "mse 1.2302003487739863\n",
      "New best model found at epoch 148 with validation loss 1.2302002906799316\n",
      "Starting Epoch 149\n",
      "1.2852619808653127\n",
      "Validation loss: 1.2291338443756104\n",
      "mse 1.2291338107705982\n",
      "New best model found at epoch 149 with validation loss 1.2291338443756104\n",
      "Starting Epoch 150\n",
      "1.284174452657285\n",
      "Validation loss: 1.228363275527954\n",
      "mse 1.2283630926539018\n",
      "New best model found at epoch 150 with validation loss 1.228363275527954\n",
      "Starting Epoch 151\n",
      "1.2831587480462117\n",
      "Validation loss: 1.2278586626052856\n",
      "mse 1.2278586141859962\n",
      "New best model found at epoch 151 with validation loss 1.2278586626052856\n",
      "Starting Epoch 152\n",
      "1.2821250506069348\n",
      "Validation loss: 1.2267571687698364\n",
      "mse 1.2267571783738438\n",
      "New best model found at epoch 152 with validation loss 1.2267571687698364\n",
      "Starting Epoch 153\n",
      "1.2812079657679019\n",
      "Validation loss: 1.2256227731704712\n",
      "mse 1.2256228745072084\n",
      "New best model found at epoch 153 with validation loss 1.2256227731704712\n",
      "Starting Epoch 154\n",
      "1.2802553021389504\n",
      "Validation loss: 1.2252278327941895\n",
      "mse 1.2252277624816506\n",
      "New best model found at epoch 154 with validation loss 1.2252278327941895\n",
      "Starting Epoch 155\n",
      "1.279193375421607\n",
      "Validation loss: 1.2236909866333008\n",
      "mse 1.2236909095364048\n",
      "New best model found at epoch 155 with validation loss 1.2236909866333008\n",
      "Starting Epoch 156\n",
      "1.2783241971679355\n",
      "Validation loss: 1.2235422134399414\n",
      "mse 1.2235422426706797\n",
      "New best model found at epoch 156 with validation loss 1.2235422134399414\n",
      "Starting Epoch 157\n",
      "1.277338427046071\n",
      "Validation loss: 1.2220243215560913\n",
      "mse 1.2220243023142752\n",
      "New best model found at epoch 157 with validation loss 1.2220243215560913\n",
      "Starting Epoch 158\n",
      "1.2764753025511038\n",
      "Validation loss: 1.2220617532730103\n",
      "mse 1.2220618200126883\n",
      "Starting Epoch 159\n",
      "1.275766028010327\n",
      "Validation loss: 1.2210485935211182\n",
      "mse 1.221048706582535\n",
      "New best model found at epoch 159 with validation loss 1.2210485935211182\n",
      "Starting Epoch 160\n",
      "1.2745907695397087\n",
      "Validation loss: 1.2196643352508545\n",
      "mse 1.219664231753828\n",
      "New best model found at epoch 160 with validation loss 1.2196643352508545\n",
      "Starting Epoch 161\n",
      "1.2736274988754936\n",
      "Validation loss: 1.2187442779541016\n",
      "mse 1.2187442588248143\n",
      "New best model found at epoch 161 with validation loss 1.2187442779541016\n",
      "Starting Epoch 162\n",
      "1.2728390667749487\n",
      "Validation loss: 1.2180376052856445\n",
      "mse 1.218037696396873\n",
      "New best model found at epoch 162 with validation loss 1.2180376052856445\n",
      "Starting Epoch 163\n",
      "1.2718817073365916\n",
      "Validation loss: 1.2174057960510254\n",
      "mse 1.2174057876998376\n",
      "New best model found at epoch 163 with validation loss 1.2174057960510254\n",
      "Starting Epoch 164\n",
      "1.2710062394971433\n",
      "Validation loss: 1.216300368309021\n",
      "mse 1.2163003046220926\n",
      "New best model found at epoch 164 with validation loss 1.216300368309021\n",
      "Starting Epoch 165\n",
      "1.2700970406117646\n",
      "Validation loss: 1.2153451442718506\n",
      "mse 1.2153452483806815\n",
      "New best model found at epoch 165 with validation loss 1.2153451442718506\n",
      "Starting Epoch 166\n",
      "1.2691550902698352\n",
      "Validation loss: 1.2141658067703247\n",
      "mse 1.2141657413980156\n",
      "New best model found at epoch 166 with validation loss 1.2141658067703247\n",
      "Starting Epoch 167\n",
      "1.2682064279266025\n",
      "Validation loss: 1.212951898574829\n",
      "mse 1.2129518356331999\n",
      "New best model found at epoch 167 with validation loss 1.212951898574829\n",
      "Starting Epoch 168\n",
      "1.2672257397485815\n",
      "Validation loss: 1.2125459909439087\n",
      "mse 1.2125460277979907\n",
      "New best model found at epoch 168 with validation loss 1.2125459909439087\n",
      "Starting Epoch 169\n",
      "1.266303168690723\n",
      "Validation loss: 1.2116329669952393\n",
      "mse 1.2116329386635305\n",
      "New best model found at epoch 169 with validation loss 1.2116329669952393\n",
      "Starting Epoch 170\n",
      "1.2654578193374302\n",
      "Validation loss: 1.2104297876358032\n",
      "mse 1.2104297371539023\n",
      "New best model found at epoch 170 with validation loss 1.2104297876358032\n",
      "Starting Epoch 171\n",
      "1.2644964689793794\n",
      "Validation loss: 1.2098989486694336\n",
      "mse 1.209898911825661\n",
      "New best model found at epoch 171 with validation loss 1.2098989486694336\n",
      "Starting Epoch 172\n",
      "1.2635759244794431\n",
      "Validation loss: 1.208875298500061\n",
      "mse 1.208875291187108\n",
      "New best model found at epoch 172 with validation loss 1.208875298500061\n",
      "Starting Epoch 173\n",
      "1.262656385483949\n",
      "Validation loss: 1.2079288959503174\n",
      "mse 1.2079288837930953\n",
      "New best model found at epoch 173 with validation loss 1.2079288959503174\n",
      "Starting Epoch 174\n",
      "1.261813487695611\n",
      "Validation loss: 1.2068065404891968\n",
      "mse 1.2068063861521305\n",
      "New best model found at epoch 174 with validation loss 1.2068065404891968\n",
      "Starting Epoch 175\n",
      "1.2609461312708647\n",
      "Validation loss: 1.2061867713928223\n",
      "mse 1.2061867737706582\n",
      "New best model found at epoch 175 with validation loss 1.2061867713928223\n",
      "Starting Epoch 176\n",
      "1.2599811191144197\n",
      "Validation loss: 1.204758644104004\n",
      "mse 1.2047587640140107\n",
      "New best model found at epoch 176 with validation loss 1.204758644104004\n",
      "Starting Epoch 177\n",
      "1.259122099565423\n",
      "Validation loss: 1.2037856578826904\n",
      "mse 1.2037856243810214\n",
      "New best model found at epoch 177 with validation loss 1.2037856578826904\n",
      "Starting Epoch 178\n",
      "1.2581699516462244\n",
      "Validation loss: 1.203086018562317\n",
      "mse 1.2030859674813366\n",
      "New best model found at epoch 178 with validation loss 1.203086018562317\n",
      "Starting Epoch 179\n",
      "1.2572074454763662\n",
      "Validation loss: 1.2018547058105469\n",
      "mse 1.2018546065377467\n",
      "New best model found at epoch 179 with validation loss 1.2018547058105469\n",
      "Starting Epoch 180\n",
      "1.2563289870386538\n",
      "Validation loss: 1.2010767459869385\n",
      "mse 1.201076881303492\n",
      "New best model found at epoch 180 with validation loss 1.2010767459869385\n",
      "Starting Epoch 181\n",
      "1.255503791829814\n",
      "Validation loss: 1.2003487348556519\n",
      "mse 1.2003487183042076\n",
      "New best model found at epoch 181 with validation loss 1.2003487348556519\n",
      "Starting Epoch 182\n",
      "1.2546015096747356\n",
      "Validation loss: 1.1992799043655396\n",
      "mse 1.199279905275727\n",
      "New best model found at epoch 182 with validation loss 1.1992799043655396\n",
      "Starting Epoch 183\n",
      "1.2538502967875937\n",
      "Validation loss: 1.1987597942352295\n",
      "mse 1.1987596831124872\n",
      "New best model found at epoch 183 with validation loss 1.1987597942352295\n",
      "Starting Epoch 184\n",
      "1.2529867006384807\n",
      "Validation loss: 1.1974354982376099\n",
      "mse 1.197435602045162\n",
      "New best model found at epoch 184 with validation loss 1.1974354982376099\n",
      "Starting Epoch 185\n",
      "1.2521139098250347\n",
      "Validation loss: 1.196773648262024\n",
      "mse 1.196773601943381\n",
      "New best model found at epoch 185 with validation loss 1.196773648262024\n",
      "Starting Epoch 186\n",
      "1.2513122480848562\n",
      "Validation loss: 1.1963497400283813\n",
      "mse 1.1963498855647563\n",
      "New best model found at epoch 186 with validation loss 1.1963497400283813\n",
      "Starting Epoch 187\n",
      "1.2505975572959236\n",
      "Validation loss: 1.195521593093872\n",
      "mse 1.1955216316939048\n",
      "New best model found at epoch 187 with validation loss 1.195521593093872\n",
      "Starting Epoch 188\n",
      "1.249688394691633\n",
      "Validation loss: 1.194366455078125\n",
      "mse 1.1943664100471978\n",
      "New best model found at epoch 188 with validation loss 1.194366455078125\n",
      "Starting Epoch 189\n",
      "1.2489700187807498\n",
      "Validation loss: 1.1934096813201904\n",
      "mse 1.1934098294169861\n",
      "New best model found at epoch 189 with validation loss 1.1934096813201904\n",
      "Starting Epoch 190\n",
      "1.2481752815453901\n",
      "Validation loss: 1.1930614709854126\n",
      "mse 1.193061410884112\n",
      "New best model found at epoch 190 with validation loss 1.1930614709854126\n",
      "Starting Epoch 191\n",
      "1.247369900993679\n",
      "Validation loss: 1.1918963193893433\n",
      "mse 1.1918964638805916\n",
      "New best model found at epoch 191 with validation loss 1.1918963193893433\n",
      "Starting Epoch 192\n",
      "1.2466668668000593\n",
      "Validation loss: 1.1915031671524048\n",
      "mse 1.1915032440567557\n",
      "New best model found at epoch 192 with validation loss 1.1915031671524048\n",
      "Starting Epoch 193\n",
      "1.2459017971287603\n",
      "Validation loss: 1.19063138961792\n",
      "mse 1.190631379829263\n",
      "New best model found at epoch 193 with validation loss 1.19063138961792\n",
      "Starting Epoch 194\n",
      "1.2451070262038189\n",
      "Validation loss: 1.1892439126968384\n",
      "mse 1.1892440136803892\n",
      "New best model found at epoch 194 with validation loss 1.1892439126968384\n",
      "Starting Epoch 195\n",
      "1.2443907157234524\n",
      "Validation loss: 1.1887058019638062\n",
      "mse 1.188705646099783\n",
      "New best model found at epoch 195 with validation loss 1.1887058019638062\n",
      "Starting Epoch 196\n",
      "1.2435286978016729\n",
      "Validation loss: 1.188373327255249\n",
      "mse 1.1883732516475833\n",
      "New best model found at epoch 196 with validation loss 1.188373327255249\n",
      "Starting Epoch 197\n",
      "1.242800665938336\n",
      "Validation loss: 1.18692147731781\n",
      "mse 1.1869213370929619\n",
      "New best model found at epoch 197 with validation loss 1.18692147731781\n",
      "Starting Epoch 198\n",
      "1.2422211714412854\n",
      "Validation loss: 1.186508059501648\n",
      "mse 1.186508061893677\n",
      "New best model found at epoch 198 with validation loss 1.186508059501648\n",
      "Starting Epoch 199\n",
      "1.2413215067075647\n",
      "Validation loss: 1.1854485273361206\n",
      "mse 1.185448450155439\n",
      "New best model found at epoch 199 with validation loss 1.1854485273361206\n",
      "Starting Epoch 200\n",
      "1.2407783658608147\n",
      "Validation loss: 1.1850082874298096\n",
      "mse 1.1850082784595468\n",
      "New best model found at epoch 200 with validation loss 1.1850082874298096\n",
      "Starting Epoch 201\n",
      "1.239944364713586\n",
      "Validation loss: 1.183775782585144\n",
      "mse 1.1837759074725442\n",
      "New best model found at epoch 201 with validation loss 1.183775782585144\n",
      "Starting Epoch 202\n",
      "1.23934115793394\n",
      "Validation loss: 1.1830402612686157\n",
      "mse 1.1830402470437487\n",
      "New best model found at epoch 202 with validation loss 1.1830402612686157\n",
      "Starting Epoch 203\n",
      "1.2384829443434011\n",
      "Validation loss: 1.1828445196151733\n",
      "mse 1.1828444505286428\n",
      "New best model found at epoch 203 with validation loss 1.1828445196151733\n",
      "Starting Epoch 204\n",
      "1.237899679204692\n",
      "Validation loss: 1.1819841861724854\n",
      "mse 1.1819842171019321\n",
      "New best model found at epoch 204 with validation loss 1.1819841861724854\n",
      "Starting Epoch 205\n",
      "1.2372638920079106\n",
      "Validation loss: 1.1806989908218384\n",
      "mse 1.1806989435707484\n",
      "New best model found at epoch 205 with validation loss 1.1806989908218384\n",
      "Starting Epoch 206\n",
      "1.2363184845965842\n",
      "Validation loss: 1.1805862188339233\n",
      "mse 1.1805862293685472\n",
      "New best model found at epoch 206 with validation loss 1.1805862188339233\n",
      "Starting Epoch 207\n",
      "1.2357372071432031\n",
      "Validation loss: 1.1795015335083008\n",
      "mse 1.1795013856293772\n",
      "New best model found at epoch 207 with validation loss 1.1795015335083008\n",
      "Starting Epoch 208\n",
      "1.2350939771403437\n",
      "Validation loss: 1.1788291931152344\n",
      "mse 1.1788292071701458\n",
      "New best model found at epoch 208 with validation loss 1.1788291931152344\n",
      "Starting Epoch 209\n",
      "1.2344387147737585\n",
      "Validation loss: 1.1782807111740112\n",
      "mse 1.178280691312572\n",
      "New best model found at epoch 209 with validation loss 1.1782807111740112\n",
      "Starting Epoch 210\n",
      "1.233746588230133\n",
      "Validation loss: 1.1772146224975586\n",
      "mse 1.177214555138972\n",
      "New best model found at epoch 210 with validation loss 1.1772146224975586\n",
      "Starting Epoch 211\n",
      "1.2329189829204394\n",
      "Validation loss: 1.1770246028900146\n",
      "mse 1.177024416259581\n",
      "New best model found at epoch 211 with validation loss 1.1770246028900146\n",
      "Starting Epoch 212\n",
      "1.2323936405389204\n",
      "Validation loss: 1.1756505966186523\n",
      "mse 1.175650567291959\n",
      "New best model found at epoch 212 with validation loss 1.1756505966186523\n",
      "Starting Epoch 213\n",
      "1.2317348666813062\n",
      "Validation loss: 1.1750757694244385\n",
      "mse 1.1750756993648588\n",
      "New best model found at epoch 213 with validation loss 1.1750757694244385\n",
      "Starting Epoch 214\n",
      "1.2309169561966606\n",
      "Validation loss: 1.1747545003890991\n",
      "mse 1.1747544993529797\n",
      "New best model found at epoch 214 with validation loss 1.1747545003890991\n",
      "Starting Epoch 215\n",
      "1.230171905911487\n",
      "Validation loss: 1.1740777492523193\n",
      "mse 1.174077784523633\n",
      "New best model found at epoch 215 with validation loss 1.1740777492523193\n",
      "Starting Epoch 216\n",
      "1.2296006549959597\n",
      "Validation loss: 1.1735328435897827\n",
      "mse 1.1735327603742827\n",
      "New best model found at epoch 216 with validation loss 1.1735328435897827\n",
      "Starting Epoch 217\n",
      "1.2289808262949404\n",
      "Validation loss: 1.1726003885269165\n",
      "mse 1.1726004273149364\n",
      "New best model found at epoch 217 with validation loss 1.1726003885269165\n",
      "Starting Epoch 218\n",
      "1.228344466375268\n",
      "Validation loss: 1.1717109680175781\n",
      "mse 1.1717109587761085\n",
      "New best model found at epoch 218 with validation loss 1.1717109680175781\n",
      "Starting Epoch 219\n",
      "1.227720382420913\n",
      "Validation loss: 1.17136812210083\n",
      "mse 1.1713681113232217\n",
      "New best model found at epoch 219 with validation loss 1.17136812210083\n",
      "Starting Epoch 220\n",
      "1.22711973345798\n",
      "Validation loss: 1.1704869270324707\n",
      "mse 1.1704867751568653\n",
      "New best model found at epoch 220 with validation loss 1.1704869270324707\n",
      "Starting Epoch 221\n",
      "1.2264309655065122\n",
      "Validation loss: 1.169770359992981\n",
      "mse 1.1697703947158478\n",
      "New best model found at epoch 221 with validation loss 1.169770359992981\n",
      "Starting Epoch 222\n",
      "1.2256737351417542\n",
      "Validation loss: 1.1689969301223755\n",
      "mse 1.1689968416156842\n",
      "New best model found at epoch 222 with validation loss 1.1689969301223755\n",
      "Starting Epoch 223\n",
      "1.2250662316446719\n",
      "Validation loss: 1.1686081886291504\n",
      "mse 1.1686082657182604\n",
      "New best model found at epoch 223 with validation loss 1.1686081886291504\n",
      "Starting Epoch 224\n",
      "1.2244534751643306\n",
      "Validation loss: 1.167357325553894\n",
      "mse 1.167357454740255\n",
      "New best model found at epoch 224 with validation loss 1.167357325553894\n",
      "Starting Epoch 225\n",
      "1.2239795793657717\n",
      "Validation loss: 1.1669925451278687\n",
      "mse 1.1669924194698578\n",
      "New best model found at epoch 225 with validation loss 1.1669925451278687\n",
      "Starting Epoch 226\n",
      "1.2232307947200278\n",
      "Validation loss: 1.1662232875823975\n",
      "mse 1.1662232721361783\n",
      "New best model found at epoch 226 with validation loss 1.1662232875823975\n",
      "Starting Epoch 227\n",
      "1.2225827289664226\n",
      "Validation loss: 1.1659042835235596\n",
      "mse 1.165904329182946\n",
      "New best model found at epoch 227 with validation loss 1.1659042835235596\n",
      "Starting Epoch 228\n",
      "1.2219382213509602\n",
      "Validation loss: 1.1648298501968384\n",
      "mse 1.1648296845347004\n",
      "New best model found at epoch 228 with validation loss 1.1648298501968384\n",
      "Starting Epoch 229\n",
      "1.2213814569556194\n",
      "Validation loss: 1.164191484451294\n",
      "mse 1.1641914267469387\n",
      "New best model found at epoch 229 with validation loss 1.164191484451294\n",
      "Starting Epoch 230\n",
      "1.2207798024882441\n",
      "Validation loss: 1.1632903814315796\n",
      "mse 1.1632903292253056\n",
      "New best model found at epoch 230 with validation loss 1.1632903814315796\n",
      "Starting Epoch 231\n",
      "1.2201930906461633\n",
      "Validation loss: 1.1631122827529907\n",
      "mse 1.1631123431969068\n",
      "New best model found at epoch 231 with validation loss 1.1631122827529907\n",
      "Starting Epoch 232\n",
      "1.2195381107537642\n",
      "Validation loss: 1.1621222496032715\n",
      "mse 1.1621223049036782\n",
      "New best model found at epoch 232 with validation loss 1.1621222496032715\n",
      "Starting Epoch 233\n",
      "1.21902007382849\n",
      "Validation loss: 1.1613961458206177\n",
      "mse 1.1613961135430457\n",
      "New best model found at epoch 233 with validation loss 1.1613961458206177\n",
      "Starting Epoch 234\n",
      "1.2184545060862666\n",
      "Validation loss: 1.1603052616119385\n",
      "mse 1.1603052234917162\n",
      "New best model found at epoch 234 with validation loss 1.1603052616119385\n",
      "Starting Epoch 235\n",
      "1.2177669613257698\n",
      "Validation loss: 1.1603281497955322\n",
      "mse 1.1603280448282878\n",
      "Starting Epoch 236\n",
      "1.2171563817107158\n",
      "Validation loss: 1.1595338582992554\n",
      "mse 1.1595339651284113\n",
      "New best model found at epoch 236 with validation loss 1.1595338582992554\n",
      "Starting Epoch 237\n",
      "1.2166112220805625\n",
      "Validation loss: 1.1586536169052124\n",
      "mse 1.1586535832288536\n",
      "New best model found at epoch 237 with validation loss 1.1586536169052124\n",
      "Starting Epoch 238\n",
      "1.2158714040465977\n",
      "Validation loss: 1.1581121683120728\n",
      "mse 1.158112255670036\n",
      "New best model found at epoch 238 with validation loss 1.1581121683120728\n",
      "Starting Epoch 239\n",
      "1.215422257133152\n",
      "Validation loss: 1.1576693058013916\n",
      "mse 1.1576692345111428\n",
      "New best model found at epoch 239 with validation loss 1.1576693058013916\n",
      "Starting Epoch 240\n",
      "1.2147330253020576\n",
      "Validation loss: 1.1577483415603638\n",
      "mse 1.1577484000382885\n",
      "Starting Epoch 241\n",
      "1.214347445446512\n",
      "Validation loss: 1.1559423208236694\n",
      "mse 1.1559423776566025\n",
      "New best model found at epoch 241 with validation loss 1.1559423208236694\n",
      "Starting Epoch 242\n",
      "1.2134770595509072\n",
      "Validation loss: 1.1556283235549927\n",
      "mse 1.155628285023017\n",
      "New best model found at epoch 242 with validation loss 1.1556283235549927\n",
      "Starting Epoch 243\n",
      "1.2128811556359995\n",
      "Validation loss: 1.1551742553710938\n",
      "mse 1.1551742746856157\n",
      "New best model found at epoch 243 with validation loss 1.1551742553710938\n",
      "Starting Epoch 244\n",
      "1.2124880941017815\n",
      "Validation loss: 1.1544464826583862\n",
      "mse 1.1544465314012986\n",
      "New best model found at epoch 244 with validation loss 1.1544464826583862\n",
      "Starting Epoch 245\n",
      "1.211746485336967\n",
      "Validation loss: 1.153527855873108\n",
      "mse 1.1535278251490477\n",
      "New best model found at epoch 245 with validation loss 1.153527855873108\n",
      "Starting Epoch 246\n",
      "1.211273035277491\n",
      "Validation loss: 1.1533188819885254\n",
      "mse 1.1533190224682675\n",
      "New best model found at epoch 246 with validation loss 1.1533188819885254\n",
      "Starting Epoch 247\n",
      "1.2106151451235232\n",
      "Validation loss: 1.1524118185043335\n",
      "mse 1.1524118641995083\n",
      "New best model found at epoch 247 with validation loss 1.1524118185043335\n",
      "Starting Epoch 248\n",
      "1.2100922776305156\n",
      "Validation loss: 1.1520581245422363\n",
      "mse 1.1520580783237648\n",
      "New best model found at epoch 248 with validation loss 1.1520581245422363\n",
      "Starting Epoch 249\n",
      "1.2096046727636587\n",
      "Validation loss: 1.1513663530349731\n",
      "mse 1.1513663994913503\n",
      "New best model found at epoch 249 with validation loss 1.1513663530349731\n",
      "Starting Epoch 250\n",
      "1.209003228208293\n",
      "Validation loss: 1.1506059169769287\n",
      "mse 1.1506059966906386\n",
      "New best model found at epoch 250 with validation loss 1.1506059169769287\n",
      "Starting Epoch 251\n",
      "1.2084214169046152\n",
      "Validation loss: 1.1501175165176392\n",
      "mse 1.1501175531275378\n",
      "New best model found at epoch 251 with validation loss 1.1501175165176392\n",
      "Starting Epoch 252\n",
      "1.2078768066737964\n",
      "Validation loss: 1.1494628190994263\n",
      "mse 1.1494628334357395\n",
      "New best model found at epoch 252 with validation loss 1.1494628190994263\n",
      "Starting Epoch 253\n",
      "1.2073752439540366\n",
      "Validation loss: 1.149139404296875\n",
      "mse 1.1491393531531338\n",
      "New best model found at epoch 253 with validation loss 1.149139404296875\n",
      "Starting Epoch 254\n",
      "1.206598522870437\n",
      "Validation loss: 1.1484978199005127\n",
      "mse 1.1484978183437404\n",
      "New best model found at epoch 254 with validation loss 1.1484978199005127\n",
      "Starting Epoch 255\n",
      "1.2061897127524666\n",
      "Validation loss: 1.1479499340057373\n",
      "mse 1.1479499558902475\n",
      "New best model found at epoch 255 with validation loss 1.1479499340057373\n",
      "Starting Epoch 256\n",
      "1.2055564522743225\n",
      "Validation loss: 1.1473512649536133\n",
      "mse 1.1473512589228974\n",
      "New best model found at epoch 256 with validation loss 1.1473512649536133\n",
      "Starting Epoch 257\n",
      "1.2050205054490462\n",
      "Validation loss: 1.1468684673309326\n",
      "mse 1.1468685060468962\n",
      "New best model found at epoch 257 with validation loss 1.1468684673309326\n",
      "Starting Epoch 258\n",
      "1.204462748506795\n",
      "Validation loss: 1.1462576389312744\n",
      "mse 1.1462575596657245\n",
      "New best model found at epoch 258 with validation loss 1.1462576389312744\n",
      "Starting Epoch 259\n",
      "1.2040445001228997\n",
      "Validation loss: 1.1457695960998535\n",
      "mse 1.1457693834157956\n",
      "New best model found at epoch 259 with validation loss 1.1457695960998535\n",
      "Starting Epoch 260\n",
      "1.203459109949029\n",
      "Validation loss: 1.1453402042388916\n",
      "mse 1.1453401623841606\n",
      "New best model found at epoch 260 with validation loss 1.1453402042388916\n",
      "Starting Epoch 261\n",
      "1.2028898026632227\n",
      "Validation loss: 1.144668698310852\n",
      "mse 1.1446687339808876\n",
      "New best model found at epoch 261 with validation loss 1.144668698310852\n",
      "Starting Epoch 262\n",
      "1.2023171497427898\n",
      "Validation loss: 1.1441478729248047\n",
      "mse 1.1441477275625043\n",
      "New best model found at epoch 262 with validation loss 1.1441478729248047\n",
      "Starting Epoch 263\n",
      "1.2018441894780034\n",
      "Validation loss: 1.1438329219818115\n",
      "mse 1.143833014079874\n",
      "New best model found at epoch 263 with validation loss 1.1438329219818115\n",
      "Starting Epoch 264\n",
      "1.2012665556824726\n",
      "Validation loss: 1.1432081460952759\n",
      "mse 1.143208083687677\n",
      "New best model found at epoch 264 with validation loss 1.1432081460952759\n",
      "Starting Epoch 265\n",
      "1.2007310597792915\n",
      "Validation loss: 1.1428190469741821\n",
      "mse 1.1428189724613047\n",
      "New best model found at epoch 265 with validation loss 1.1428190469741821\n",
      "Starting Epoch 266\n",
      "1.200052823709405\n",
      "Validation loss: 1.142156720161438\n",
      "mse 1.142156693678639\n",
      "New best model found at epoch 266 with validation loss 1.142156720161438\n",
      "Starting Epoch 267\n",
      "1.1995518103889797\n",
      "Validation loss: 1.1414999961853027\n",
      "mse 1.1415000100101635\n",
      "New best model found at epoch 267 with validation loss 1.1414999961853027\n",
      "Starting Epoch 268\n",
      "1.1991525966188181\n",
      "Validation loss: 1.141108512878418\n",
      "mse 1.1411084558051923\n",
      "New best model found at epoch 268 with validation loss 1.141108512878418\n",
      "Starting Epoch 269\n",
      "1.1986853013867917\n",
      "Validation loss: 1.1414854526519775\n",
      "mse 1.1414854290865004\n",
      "Starting Epoch 270\n",
      "1.1982251768526824\n",
      "Validation loss: 1.140021800994873\n",
      "mse 1.1400219361180381\n",
      "New best model found at epoch 270 with validation loss 1.140021800994873\n",
      "Starting Epoch 271\n",
      "1.197646615297898\n",
      "Validation loss: 1.1392582654953003\n",
      "mse 1.1392582176080597\n",
      "New best model found at epoch 271 with validation loss 1.1392582654953003\n",
      "Starting Epoch 272\n",
      "1.197130490904269\n",
      "Validation loss: 1.1387617588043213\n",
      "mse 1.138761652014276\n",
      "New best model found at epoch 272 with validation loss 1.1387617588043213\n",
      "Starting Epoch 273\n",
      "1.196607996588168\n",
      "Validation loss: 1.1379942893981934\n",
      "mse 1.137994323977543\n",
      "New best model found at epoch 273 with validation loss 1.1379942893981934\n",
      "Starting Epoch 274\n",
      "1.1961263651433198\n",
      "Validation loss: 1.1374300718307495\n",
      "mse 1.1374301728291771\n",
      "New best model found at epoch 274 with validation loss 1.1374300718307495\n",
      "Starting Epoch 275\n",
      "1.1955505143041196\n",
      "Validation loss: 1.1377710103988647\n",
      "mse 1.1377710111183525\n",
      "Starting Epoch 276\n",
      "1.1953202356462893\n",
      "Validation loss: 1.1373146772384644\n",
      "mse 1.1373146919746744\n",
      "New best model found at epoch 276 with validation loss 1.1373146772384644\n",
      "Starting Epoch 277\n",
      "1.1947402954101562\n",
      "Validation loss: 1.135612964630127\n",
      "mse 1.1356130136594702\n",
      "New best model found at epoch 277 with validation loss 1.135612964630127\n",
      "Starting Epoch 278\n",
      "1.1941105230994846\n",
      "Validation loss: 1.1348448991775513\n",
      "mse 1.1348448468917862\n",
      "New best model found at epoch 278 with validation loss 1.1348448991775513\n",
      "Starting Epoch 279\n",
      "1.193722250668899\n",
      "Validation loss: 1.1345075368881226\n",
      "mse 1.1345076146138713\n",
      "New best model found at epoch 279 with validation loss 1.1345075368881226\n",
      "Starting Epoch 280\n",
      "1.1932061599648518\n",
      "Validation loss: 1.1342132091522217\n",
      "mse 1.1342131240921014\n",
      "New best model found at epoch 280 with validation loss 1.1342132091522217\n",
      "Starting Epoch 281\n",
      "1.1927127475323884\n",
      "Validation loss: 1.133492350578308\n",
      "mse 1.1334923909242456\n",
      "New best model found at epoch 281 with validation loss 1.133492350578308\n",
      "Starting Epoch 282\n",
      "1.1922135404918506\n",
      "Validation loss: 1.132940411567688\n",
      "mse 1.1329404381975177\n",
      "New best model found at epoch 282 with validation loss 1.132940411567688\n",
      "Starting Epoch 283\n",
      "1.1918769297392473\n",
      "Validation loss: 1.132296085357666\n",
      "mse 1.132296054405042\n",
      "New best model found at epoch 283 with validation loss 1.132296085357666\n",
      "Starting Epoch 284\n",
      "1.191314539183741\n",
      "Validation loss: 1.132170557975769\n",
      "mse 1.1321705753852587\n",
      "New best model found at epoch 284 with validation loss 1.132170557975769\n",
      "Starting Epoch 285\n",
      "1.1909249424934387\n",
      "Validation loss: 1.1311761140823364\n",
      "mse 1.13117611445964\n",
      "New best model found at epoch 285 with validation loss 1.1311761140823364\n",
      "Starting Epoch 286\n",
      "1.1904094348783079\n",
      "Validation loss: 1.1305733919143677\n",
      "mse 1.1305734411459272\n",
      "New best model found at epoch 286 with validation loss 1.1305733919143677\n",
      "Starting Epoch 287\n",
      "1.1899302912795025\n",
      "Validation loss: 1.1297807693481445\n",
      "mse 1.1297808567165235\n",
      "New best model found at epoch 287 with validation loss 1.1297807693481445\n",
      "Starting Epoch 288\n",
      "1.1896761448486992\n",
      "Validation loss: 1.1297215223312378\n",
      "mse 1.129721458360786\n",
      "New best model found at epoch 288 with validation loss 1.1297215223312378\n",
      "Starting Epoch 289\n",
      "1.1891552158024\n",
      "Validation loss: 1.1291159391403198\n",
      "mse 1.1291157319012437\n",
      "New best model found at epoch 289 with validation loss 1.1291159391403198\n",
      "Starting Epoch 290\n",
      "1.1887004764183708\n",
      "Validation loss: 1.1287542581558228\n",
      "mse 1.1287542573125888\n",
      "New best model found at epoch 290 with validation loss 1.1287542581558228\n",
      "Starting Epoch 291\n",
      "1.188303195911905\n",
      "Validation loss: 1.1282196044921875\n",
      "mse 1.128219719108329\n",
      "New best model found at epoch 291 with validation loss 1.1282196044921875\n",
      "Starting Epoch 292\n",
      "1.1878742471985195\n",
      "Validation loss: 1.127874732017517\n",
      "mse 1.1278748303989032\n",
      "New best model found at epoch 292 with validation loss 1.127874732017517\n",
      "Starting Epoch 293\n",
      "1.1873494982719421\n",
      "Validation loss: 1.1275348663330078\n",
      "mse 1.1275349577194713\n",
      "New best model found at epoch 293 with validation loss 1.1275348663330078\n",
      "Starting Epoch 294\n",
      "1.1868904310724009\n",
      "Validation loss: 1.1270136833190918\n",
      "mse 1.1270137048953173\n",
      "New best model found at epoch 294 with validation loss 1.1270136833190918\n",
      "Starting Epoch 295\n",
      "1.1865506845971812\n",
      "Validation loss: 1.1266624927520752\n",
      "mse 1.1266625627362061\n",
      "New best model found at epoch 295 with validation loss 1.1266624927520752\n",
      "Starting Epoch 296\n",
      "1.1860535455786663\n",
      "Validation loss: 1.1262857913970947\n",
      "mse 1.1262857466931482\n",
      "New best model found at epoch 296 with validation loss 1.1262857913970947\n",
      "Starting Epoch 297\n",
      "1.1856831934141077\n",
      "Validation loss: 1.1263728141784668\n",
      "mse 1.1263729548997252\n",
      "Starting Epoch 298\n",
      "1.1854301509649858\n",
      "Validation loss: 1.1250003576278687\n",
      "mse 1.1250003810296383\n",
      "New best model found at epoch 298 with validation loss 1.1250003576278687\n",
      "Starting Epoch 299\n",
      "1.1847792604695195\n",
      "Validation loss: 1.124672770500183\n",
      "mse 1.1246726425219606\n",
      "New best model found at epoch 299 with validation loss 1.124672770500183\n",
      "Starting Epoch 300\n",
      "1.1843968318856282\n",
      "Validation loss: 1.1249806880950928\n",
      "mse 1.124980784490785\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-60-20-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47165b85",
   "metadata": {},
   "source": [
    "##### 4-layer MLP: Version 7\n",
    "*  Layers: 4 (including input and output layer), sizes: 17 - 80 - 50 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "0ec15841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "0db82fbb-346f-45db-9203-5034ec75d6ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.101454496383667\n",
      "Validation loss: 2.554617166519165\n",
      "mse 2.554617219267403\n",
      "New best model found at epoch 1 with validation loss 2.554617166519165\n",
      "Starting Epoch 2\n",
      "2.6222345984500386\n",
      "Validation loss: 2.252359390258789\n",
      "mse 2.252359281615018\n",
      "New best model found at epoch 2 with validation loss 2.252359390258789\n",
      "Starting Epoch 3\n",
      "2.3302506778551186\n",
      "Validation loss: 1.9932936429977417\n",
      "mse 1.9932936096675649\n",
      "New best model found at epoch 3 with validation loss 1.9932936429977417\n",
      "Starting Epoch 4\n",
      "2.0974831529285596\n",
      "Validation loss: 1.8124035596847534\n",
      "mse 1.8124036942041961\n",
      "New best model found at epoch 4 with validation loss 1.8124035596847534\n",
      "Starting Epoch 5\n",
      "1.9460180375887\n",
      "Validation loss: 1.7102380990982056\n",
      "mse 1.7102382948921755\n",
      "New best model found at epoch 5 with validation loss 1.7102380990982056\n",
      "Starting Epoch 6\n",
      "1.8492829074030337\n",
      "Validation loss: 1.6382834911346436\n",
      "mse 1.638283416574121\n",
      "New best model found at epoch 6 with validation loss 1.6382834911346436\n",
      "Starting Epoch 7\n",
      "1.7785950069842131\n",
      "Validation loss: 1.5882850885391235\n",
      "mse 1.5882851629486745\n",
      "New best model found at epoch 7 with validation loss 1.5882850885391235\n",
      "Starting Epoch 8\n",
      "1.7294764726058296\n",
      "Validation loss: 1.5531437397003174\n",
      "mse 1.5531436405926717\n",
      "New best model found at epoch 8 with validation loss 1.5531437397003174\n",
      "Starting Epoch 9\n",
      "1.6903853001801863\n",
      "Validation loss: 1.5262303352355957\n",
      "mse 1.526230305246779\n",
      "New best model found at epoch 9 with validation loss 1.5262303352355957\n",
      "Starting Epoch 10\n",
      "1.6609015827593596\n",
      "Validation loss: 1.5033930540084839\n",
      "mse 1.5033930437092078\n",
      "New best model found at epoch 10 with validation loss 1.5033930540084839\n",
      "Starting Epoch 11\n",
      "1.6354335650153782\n",
      "Validation loss: 1.4878729581832886\n",
      "mse 1.4878729745668335\n",
      "New best model found at epoch 11 with validation loss 1.4878729581832886\n",
      "Starting Epoch 12\n",
      "1.6158394295236338\n",
      "Validation loss: 1.4741636514663696\n",
      "mse 1.4741636678922847\n",
      "New best model found at epoch 12 with validation loss 1.4741636514663696\n",
      "Starting Epoch 13\n",
      "1.598473020221876\n",
      "Validation loss: 1.4618287086486816\n",
      "mse 1.461828741370524\n",
      "New best model found at epoch 13 with validation loss 1.4618287086486816\n",
      "Starting Epoch 14\n",
      "1.5835959056149358\n",
      "Validation loss: 1.4516358375549316\n",
      "mse 1.4516359203616056\n",
      "New best model found at epoch 14 with validation loss 1.4516358375549316\n",
      "Starting Epoch 15\n",
      "1.5698814029278962\n",
      "Validation loss: 1.4416941404342651\n",
      "mse 1.4416941522610216\n",
      "New best model found at epoch 15 with validation loss 1.4416941404342651\n",
      "Starting Epoch 16\n",
      "1.5570326006930808\n",
      "Validation loss: 1.4321075677871704\n",
      "mse 1.4321075397021301\n",
      "New best model found at epoch 16 with validation loss 1.4321075677871704\n",
      "Starting Epoch 17\n",
      "1.5447962050852568\n",
      "Validation loss: 1.4232028722763062\n",
      "mse 1.4232027684158308\n",
      "New best model found at epoch 17 with validation loss 1.4232028722763062\n",
      "Starting Epoch 18\n",
      "1.533748800339906\n",
      "Validation loss: 1.4149373769760132\n",
      "mse 1.414937305904729\n",
      "New best model found at epoch 18 with validation loss 1.4149373769760132\n",
      "Starting Epoch 19\n",
      "1.5227540990580684\n",
      "Validation loss: 1.406639575958252\n",
      "mse 1.406639554378638\n",
      "New best model found at epoch 19 with validation loss 1.406639575958252\n",
      "Starting Epoch 20\n",
      "1.5133207984592603\n",
      "Validation loss: 1.4003278017044067\n",
      "mse 1.4003277064529422\n",
      "New best model found at epoch 20 with validation loss 1.4003278017044067\n",
      "Starting Epoch 21\n",
      "1.504598627919736\n",
      "Validation loss: 1.3944196701049805\n",
      "mse 1.394419714187575\n",
      "New best model found at epoch 21 with validation loss 1.3944196701049805\n",
      "Starting Epoch 22\n",
      "1.496429697326992\n",
      "Validation loss: 1.3896952867507935\n",
      "mse 1.3896952716539603\n",
      "New best model found at epoch 22 with validation loss 1.3896952867507935\n",
      "Starting Epoch 23\n",
      "1.4892759012139363\n",
      "Validation loss: 1.3853214979171753\n",
      "mse 1.3853214829392722\n",
      "New best model found at epoch 23 with validation loss 1.3853214979171753\n",
      "Starting Epoch 24\n",
      "1.4832634925842285\n",
      "Validation loss: 1.3815399408340454\n",
      "mse 1.3815400628277956\n",
      "New best model found at epoch 24 with validation loss 1.3815399408340454\n",
      "Starting Epoch 25\n",
      "1.4770936214405557\n",
      "Validation loss: 1.3779706954956055\n",
      "mse 1.3779707368112892\n",
      "New best model found at epoch 25 with validation loss 1.3779706954956055\n",
      "Starting Epoch 26\n",
      "1.4712219445601753\n",
      "Validation loss: 1.3737304210662842\n",
      "mse 1.3737302736997803\n",
      "New best model found at epoch 26 with validation loss 1.3737304210662842\n",
      "Starting Epoch 27\n",
      "1.4658572466477104\n",
      "Validation loss: 1.3703701496124268\n",
      "mse 1.3703700944040054\n",
      "New best model found at epoch 27 with validation loss 1.3703701496124268\n",
      "Starting Epoch 28\n",
      "1.4609736644703408\n",
      "Validation loss: 1.3672776222229004\n",
      "mse 1.3672777480389813\n",
      "New best model found at epoch 28 with validation loss 1.3672776222229004\n",
      "Starting Epoch 29\n",
      "1.45604458839997\n",
      "Validation loss: 1.362856149673462\n",
      "mse 1.362856150664795\n",
      "New best model found at epoch 29 with validation loss 1.362856149673462\n",
      "Starting Epoch 30\n",
      "1.4514427081398342\n",
      "Validation loss: 1.3597071170806885\n",
      "mse 1.359707024164696\n",
      "New best model found at epoch 30 with validation loss 1.3597071170806885\n",
      "Starting Epoch 31\n",
      "1.4469541103943535\n",
      "Validation loss: 1.356376051902771\n",
      "mse 1.35637607428468\n",
      "New best model found at epoch 31 with validation loss 1.356376051902771\n",
      "Starting Epoch 32\n",
      "1.4426213088242903\n",
      "Validation loss: 1.3537427186965942\n",
      "mse 1.3537425836969559\n",
      "New best model found at epoch 32 with validation loss 1.3537427186965942\n",
      "Starting Epoch 33\n",
      "1.4382757855498272\n",
      "Validation loss: 1.3506094217300415\n",
      "mse 1.350609414583342\n",
      "New best model found at epoch 33 with validation loss 1.3506094217300415\n",
      "Starting Epoch 34\n",
      "1.4342091342677241\n",
      "Validation loss: 1.3474146127700806\n",
      "mse 1.3474145782673146\n",
      "New best model found at epoch 34 with validation loss 1.3474146127700806\n",
      "Starting Epoch 35\n",
      "1.4300123634545698\n",
      "Validation loss: 1.3439639806747437\n",
      "mse 1.3439638870334991\n",
      "New best model found at epoch 35 with validation loss 1.3439639806747437\n",
      "Starting Epoch 36\n",
      "1.4253429563149163\n",
      "Validation loss: 1.3411973714828491\n",
      "mse 1.341197446012351\n",
      "New best model found at epoch 36 with validation loss 1.3411973714828491\n",
      "Starting Epoch 37\n",
      "1.4217143965804058\n",
      "Validation loss: 1.3388557434082031\n",
      "mse 1.3388558938860966\n",
      "New best model found at epoch 37 with validation loss 1.3388557434082031\n",
      "Starting Epoch 38\n",
      "1.4181044905082039\n",
      "Validation loss: 1.3356136083602905\n",
      "mse 1.3356137319785495\n",
      "New best model found at epoch 38 with validation loss 1.3356136083602905\n",
      "Starting Epoch 39\n",
      "1.4135636454043181\n",
      "Validation loss: 1.332029104232788\n",
      "mse 1.3320290307148774\n",
      "New best model found at epoch 39 with validation loss 1.332029104232788\n",
      "Starting Epoch 40\n",
      "1.4098713657130366\n",
      "Validation loss: 1.3303650617599487\n",
      "mse 1.330365063476211\n",
      "New best model found at epoch 40 with validation loss 1.3303650617599487\n",
      "Starting Epoch 41\n",
      "1.405692898708841\n",
      "Validation loss: 1.3272650241851807\n",
      "mse 1.3272648979666837\n",
      "New best model found at epoch 41 with validation loss 1.3272650241851807\n",
      "Starting Epoch 42\n",
      "1.402042655841164\n",
      "Validation loss: 1.3236740827560425\n",
      "mse 1.3236741996714223\n",
      "New best model found at epoch 42 with validation loss 1.3236740827560425\n",
      "Starting Epoch 43\n",
      "1.397646038428597\n",
      "Validation loss: 1.318981647491455\n",
      "mse 1.3189817631421992\n",
      "New best model found at epoch 43 with validation loss 1.318981647491455\n",
      "Starting Epoch 44\n",
      "1.3939558086187944\n",
      "Validation loss: 1.3166193962097168\n",
      "mse 1.3166193587665973\n",
      "New best model found at epoch 44 with validation loss 1.3166193962097168\n",
      "Starting Epoch 45\n",
      "1.3904434027879133\n",
      "Validation loss: 1.3136833906173706\n",
      "mse 1.3136833303871545\n",
      "New best model found at epoch 45 with validation loss 1.3136833906173706\n",
      "Starting Epoch 46\n",
      "1.3867680378582166\n",
      "Validation loss: 1.3102818727493286\n",
      "mse 1.3102817605634847\n",
      "New best model found at epoch 46 with validation loss 1.3102818727493286\n",
      "Starting Epoch 47\n",
      "1.3833189891732258\n",
      "Validation loss: 1.3077917098999023\n",
      "mse 1.307791630028543\n",
      "New best model found at epoch 47 with validation loss 1.3077917098999023\n",
      "Starting Epoch 48\n",
      "1.3803771008615908\n",
      "Validation loss: 1.3059837818145752\n",
      "mse 1.305983671921724\n",
      "New best model found at epoch 48 with validation loss 1.3059837818145752\n",
      "Starting Epoch 49\n",
      "1.3771683003591455\n",
      "Validation loss: 1.3028655052185059\n",
      "mse 1.302865419315259\n",
      "New best model found at epoch 49 with validation loss 1.3028655052185059\n",
      "Starting Epoch 50\n",
      "1.3738654074461565\n",
      "Validation loss: 1.30022132396698\n",
      "mse 1.3002213860377165\n",
      "New best model found at epoch 50 with validation loss 1.30022132396698\n",
      "Starting Epoch 51\n",
      "1.3710281900737598\n",
      "Validation loss: 1.298034906387329\n",
      "mse 1.2980348045802443\n",
      "New best model found at epoch 51 with validation loss 1.298034906387329\n",
      "Starting Epoch 52\n",
      "1.368035552294358\n",
      "Validation loss: 1.2957158088684082\n",
      "mse 1.2957157674960178\n",
      "New best model found at epoch 52 with validation loss 1.2957158088684082\n",
      "Starting Epoch 53\n",
      "1.364726457906806\n",
      "Validation loss: 1.2930655479431152\n",
      "mse 1.2930655051380364\n",
      "New best model found at epoch 53 with validation loss 1.2930655479431152\n",
      "Starting Epoch 54\n",
      "1.3618693507235984\n",
      "Validation loss: 1.2912412881851196\n",
      "mse 1.2912412418806594\n",
      "New best model found at epoch 54 with validation loss 1.2912412881851196\n",
      "Starting Epoch 55\n",
      "1.3589955594228662\n",
      "Validation loss: 1.28898286819458\n",
      "mse 1.2889830060311975\n",
      "New best model found at epoch 55 with validation loss 1.28898286819458\n",
      "Starting Epoch 56\n",
      "1.3559678637463113\n",
      "Validation loss: 1.2867125272750854\n",
      "mse 1.28671256321458\n",
      "New best model found at epoch 56 with validation loss 1.2867125272750854\n",
      "Starting Epoch 57\n",
      "1.3531104274418042\n",
      "Validation loss: 1.2843323945999146\n",
      "mse 1.2843323991200444\n",
      "New best model found at epoch 57 with validation loss 1.2843323945999146\n",
      "Starting Epoch 58\n",
      "1.3501558822134268\n",
      "Validation loss: 1.2820616960525513\n",
      "mse 1.282061658239729\n",
      "New best model found at epoch 58 with validation loss 1.2820616960525513\n",
      "Starting Epoch 59\n",
      "1.347452277722566\n",
      "Validation loss: 1.279999017715454\n",
      "mse 1.2799989028219507\n",
      "New best model found at epoch 59 with validation loss 1.279999017715454\n",
      "Starting Epoch 60\n",
      "1.3450201309245566\n",
      "Validation loss: 1.2779674530029297\n",
      "mse 1.277967485235313\n",
      "New best model found at epoch 60 with validation loss 1.2779674530029297\n",
      "Starting Epoch 61\n",
      "1.3421505922856538\n",
      "Validation loss: 1.2750447988510132\n",
      "mse 1.2750447105833607\n",
      "New best model found at epoch 61 with validation loss 1.2750447988510132\n",
      "Starting Epoch 62\n",
      "1.3394141223119653\n",
      "Validation loss: 1.2731207609176636\n",
      "mse 1.273120825370141\n",
      "New best model found at epoch 62 with validation loss 1.2731207609176636\n",
      "Starting Epoch 63\n",
      "1.3364691812059153\n",
      "Validation loss: 1.2707270383834839\n",
      "mse 1.2707269124545193\n",
      "New best model found at epoch 63 with validation loss 1.2707270383834839\n",
      "Starting Epoch 64\n",
      "1.3342111188432444\n",
      "Validation loss: 1.2692204713821411\n",
      "mse 1.269220452922202\n",
      "New best model found at epoch 64 with validation loss 1.2692204713821411\n",
      "Starting Epoch 65\n",
      "1.3313670806262805\n",
      "Validation loss: 1.2666001319885254\n",
      "mse 1.2666001875664286\n",
      "New best model found at epoch 65 with validation loss 1.2666001319885254\n",
      "Starting Epoch 66\n",
      "1.329093593618144\n",
      "Validation loss: 1.2650727033615112\n",
      "mse 1.2650726323868229\n",
      "New best model found at epoch 66 with validation loss 1.2650727033615112\n",
      "Starting Epoch 67\n",
      "1.3267422499863997\n",
      "Validation loss: 1.2621084451675415\n",
      "mse 1.2621085581916978\n",
      "New best model found at epoch 67 with validation loss 1.2621084451675415\n",
      "Starting Epoch 68\n",
      "1.3241418289101643\n",
      "Validation loss: 1.2608973979949951\n",
      "mse 1.260897491864547\n",
      "New best model found at epoch 68 with validation loss 1.2608973979949951\n",
      "Starting Epoch 69\n",
      "1.3216856277507285\n",
      "Validation loss: 1.2582508325576782\n",
      "mse 1.2582509105762691\n",
      "New best model found at epoch 69 with validation loss 1.2582508325576782\n",
      "Starting Epoch 70\n",
      "1.319508275260096\n",
      "Validation loss: 1.2568588256835938\n",
      "mse 1.2568588615956253\n",
      "New best model found at epoch 70 with validation loss 1.2568588256835938\n",
      "Starting Epoch 71\n",
      "1.3174865168073904\n",
      "Validation loss: 1.2558969259262085\n",
      "mse 1.2558969466665408\n",
      "New best model found at epoch 71 with validation loss 1.2558969259262085\n",
      "Starting Epoch 72\n",
      "1.3146914476933687\n",
      "Validation loss: 1.2529793977737427\n",
      "mse 1.2529794678248896\n",
      "New best model found at epoch 72 with validation loss 1.2529793977737427\n",
      "Starting Epoch 73\n",
      "1.312631086162899\n",
      "Validation loss: 1.252243995666504\n",
      "mse 1.2522439699777803\n",
      "New best model found at epoch 73 with validation loss 1.252243995666504\n",
      "Starting Epoch 74\n",
      "1.3102794781975124\n",
      "Validation loss: 1.249944806098938\n",
      "mse 1.2499447551300435\n",
      "New best model found at epoch 74 with validation loss 1.249944806098938\n",
      "Starting Epoch 75\n",
      "1.3083250004312266\n",
      "Validation loss: 1.2487953901290894\n",
      "mse 1.2487953695818999\n",
      "New best model found at epoch 75 with validation loss 1.2487953901290894\n",
      "Starting Epoch 76\n",
      "1.3060355134632275\n",
      "Validation loss: 1.2460757493972778\n",
      "mse 1.2460757398982363\n",
      "New best model found at epoch 76 with validation loss 1.2460757493972778\n",
      "Starting Epoch 77\n",
      "1.3041870334874028\n",
      "Validation loss: 1.244341492652893\n",
      "mse 1.2443416829176117\n",
      "New best model found at epoch 77 with validation loss 1.244341492652893\n",
      "Starting Epoch 78\n",
      "1.3019786632579307\n",
      "Validation loss: 1.2432615756988525\n",
      "mse 1.2432616456866665\n",
      "New best model found at epoch 78 with validation loss 1.2432615756988525\n",
      "Starting Epoch 79\n",
      "1.2995996086493782\n",
      "Validation loss: 1.2407816648483276\n",
      "mse 1.2407817369131977\n",
      "New best model found at epoch 79 with validation loss 1.2407816648483276\n",
      "Starting Epoch 80\n",
      "1.297642531602279\n",
      "Validation loss: 1.2397079467773438\n",
      "mse 1.2397079554158048\n",
      "New best model found at epoch 80 with validation loss 1.2397079467773438\n",
      "Starting Epoch 81\n",
      "1.2960225706515105\n",
      "Validation loss: 1.2377938032150269\n",
      "mse 1.2377937930494634\n",
      "New best model found at epoch 81 with validation loss 1.2377938032150269\n",
      "Starting Epoch 82\n",
      "1.29383661435998\n",
      "Validation loss: 1.2360875606536865\n",
      "mse 1.236087627356539\n",
      "New best model found at epoch 82 with validation loss 1.2360875606536865\n",
      "Starting Epoch 83\n",
      "1.2917249721029531\n",
      "Validation loss: 1.2352361679077148\n",
      "mse 1.2352361905687237\n",
      "New best model found at epoch 83 with validation loss 1.2352361679077148\n",
      "Starting Epoch 84\n",
      "1.2897556657376497\n",
      "Validation loss: 1.2329182624816895\n",
      "mse 1.2329183057204764\n",
      "New best model found at epoch 84 with validation loss 1.2329182624816895\n",
      "Starting Epoch 85\n",
      "1.287860349468563\n",
      "Validation loss: 1.2322198152542114\n",
      "mse 1.2322197114456355\n",
      "New best model found at epoch 85 with validation loss 1.2322198152542114\n",
      "Starting Epoch 86\n",
      "1.2856251752894858\n",
      "Validation loss: 1.2297277450561523\n",
      "mse 1.2297277862761842\n",
      "New best model found at epoch 86 with validation loss 1.2297277450561523\n",
      "Starting Epoch 87\n",
      "1.283824472323708\n",
      "Validation loss: 1.2282618284225464\n",
      "mse 1.228261878831367\n",
      "New best model found at epoch 87 with validation loss 1.2282618284225464\n",
      "Starting Epoch 88\n",
      "1.281753615192745\n",
      "Validation loss: 1.2259409427642822\n",
      "mse 1.2259409931912157\n",
      "New best model found at epoch 88 with validation loss 1.2259409427642822\n",
      "Starting Epoch 89\n",
      "1.2796760590180107\n",
      "Validation loss: 1.2245484590530396\n",
      "mse 1.2245484872796406\n",
      "New best model found at epoch 89 with validation loss 1.2245484590530396\n",
      "Starting Epoch 90\n",
      "1.278079735196155\n",
      "Validation loss: 1.22343909740448\n",
      "mse 1.2234392394464435\n",
      "New best model found at epoch 90 with validation loss 1.22343909740448\n",
      "Starting Epoch 91\n",
      "1.2760934674221536\n",
      "Validation loss: 1.2211605310440063\n",
      "mse 1.2211605034911077\n",
      "New best model found at epoch 91 with validation loss 1.2211605310440063\n",
      "Starting Epoch 92\n",
      "1.2738066211990688\n",
      "Validation loss: 1.2196297645568848\n",
      "mse 1.219629652863001\n",
      "New best model found at epoch 92 with validation loss 1.2196297645568848\n",
      "Starting Epoch 93\n",
      "1.272058647611867\n",
      "Validation loss: 1.2176218032836914\n",
      "mse 1.2176217932268028\n",
      "New best model found at epoch 93 with validation loss 1.2176218032836914\n",
      "Starting Epoch 94\n",
      "1.2705466565878496\n",
      "Validation loss: 1.2167011499404907\n",
      "mse 1.2167012128340728\n",
      "New best model found at epoch 94 with validation loss 1.2167011499404907\n",
      "Starting Epoch 95\n",
      "1.2683605370314226\n",
      "Validation loss: 1.2146155834197998\n",
      "mse 1.2146156799205545\n",
      "New best model found at epoch 95 with validation loss 1.2146155834197998\n",
      "Starting Epoch 96\n",
      "1.2668399992196455\n",
      "Validation loss: 1.2131330966949463\n",
      "mse 1.2131331023263185\n",
      "New best model found at epoch 96 with validation loss 1.2131330966949463\n",
      "Starting Epoch 97\n",
      "1.2647644151812014\n",
      "Validation loss: 1.2114717960357666\n",
      "mse 1.2114717998204814\n",
      "New best model found at epoch 97 with validation loss 1.2114717960357666\n",
      "Starting Epoch 98\n",
      "1.2631653106730918\n",
      "Validation loss: 1.210690975189209\n",
      "mse 1.2106910502249375\n",
      "New best model found at epoch 98 with validation loss 1.210690975189209\n",
      "Starting Epoch 99\n",
      "1.2612231995748437\n",
      "Validation loss: 1.2084689140319824\n",
      "mse 1.2084689357277478\n",
      "New best model found at epoch 99 with validation loss 1.2084689140319824\n",
      "Starting Epoch 100\n",
      "1.2594596691753552\n",
      "Validation loss: 1.2065027952194214\n",
      "mse 1.2065028317196684\n",
      "New best model found at epoch 100 with validation loss 1.2065027952194214\n",
      "Starting Epoch 101\n",
      "1.25755433673444\n",
      "Validation loss: 1.205349087715149\n",
      "mse 1.2053490171444001\n",
      "New best model found at epoch 101 with validation loss 1.205349087715149\n",
      "Starting Epoch 102\n",
      "1.255775257297184\n",
      "Validation loss: 1.2035207748413086\n",
      "mse 1.2035207176205442\n",
      "New best model found at epoch 102 with validation loss 1.2035207748413086\n",
      "Starting Epoch 103\n",
      "1.2541397058445474\n",
      "Validation loss: 1.201572060585022\n",
      "mse 1.2015720462705703\n",
      "New best model found at epoch 103 with validation loss 1.201572060585022\n",
      "Starting Epoch 104\n",
      "1.2521804182425789\n",
      "Validation loss: 1.2000659704208374\n",
      "mse 1.2000660406056463\n",
      "New best model found at epoch 104 with validation loss 1.2000659704208374\n",
      "Starting Epoch 105\n",
      "1.250180949335513\n",
      "Validation loss: 1.1990604400634766\n",
      "mse 1.1990603656761218\n",
      "New best model found at epoch 105 with validation loss 1.1990604400634766\n",
      "Starting Epoch 106\n",
      "1.2478756153065225\n",
      "Validation loss: 1.1966187953948975\n",
      "mse 1.1966188051527902\n",
      "New best model found at epoch 106 with validation loss 1.1966187953948975\n",
      "Starting Epoch 107\n",
      "1.245634711307028\n",
      "Validation loss: 1.1945724487304688\n",
      "mse 1.1945723620603648\n",
      "New best model found at epoch 107 with validation loss 1.1945724487304688\n",
      "Starting Epoch 108\n",
      "1.2439703941345215\n",
      "Validation loss: 1.1928379535675049\n",
      "mse 1.19283778508466\n",
      "New best model found at epoch 108 with validation loss 1.1928379535675049\n",
      "Starting Epoch 109\n",
      "1.2417148299839185\n",
      "Validation loss: 1.1919276714324951\n",
      "mse 1.191927568439285\n",
      "New best model found at epoch 109 with validation loss 1.1919276714324951\n",
      "Starting Epoch 110\n",
      "1.240218662697336\n",
      "Validation loss: 1.1904411315917969\n",
      "mse 1.1904411086210176\n",
      "New best model found at epoch 110 with validation loss 1.1904411315917969\n",
      "Starting Epoch 111\n",
      "1.238394706145577\n",
      "Validation loss: 1.1889594793319702\n",
      "mse 1.1889593667460774\n",
      "New best model found at epoch 111 with validation loss 1.1889594793319702\n",
      "Starting Epoch 112\n",
      "1.2367587400519329\n",
      "Validation loss: 1.1873564720153809\n",
      "mse 1.1873564642492085\n",
      "New best model found at epoch 112 with validation loss 1.1873564720153809\n",
      "Starting Epoch 113\n",
      "1.2347853235576465\n",
      "Validation loss: 1.185945749282837\n",
      "mse 1.1859457751545714\n",
      "New best model found at epoch 113 with validation loss 1.185945749282837\n",
      "Starting Epoch 114\n",
      "1.2332287689913874\n",
      "Validation loss: 1.184215784072876\n",
      "mse 1.1842157319407578\n",
      "New best model found at epoch 114 with validation loss 1.184215784072876\n",
      "Starting Epoch 115\n",
      "1.2315826856571694\n",
      "Validation loss: 1.182739496231079\n",
      "mse 1.1827395301756463\n",
      "New best model found at epoch 115 with validation loss 1.182739496231079\n",
      "Starting Epoch 116\n",
      "1.2297388263370679\n",
      "Validation loss: 1.1806941032409668\n",
      "mse 1.1806940663637089\n",
      "New best model found at epoch 116 with validation loss 1.1806941032409668\n",
      "Starting Epoch 117\n",
      "1.22837451748226\n",
      "Validation loss: 1.1795903444290161\n",
      "mse 1.1795903731535693\n",
      "New best model found at epoch 117 with validation loss 1.1795903444290161\n",
      "Starting Epoch 118\n",
      "1.2264081058294878\n",
      "Validation loss: 1.1778080463409424\n",
      "mse 1.1778079317404493\n",
      "New best model found at epoch 118 with validation loss 1.1778080463409424\n",
      "Starting Epoch 119\n",
      "1.2245368672453838\n",
      "Validation loss: 1.1758570671081543\n",
      "mse 1.17585706897964\n",
      "New best model found at epoch 119 with validation loss 1.1758570671081543\n",
      "Starting Epoch 120\n",
      "1.2232280762299248\n",
      "Validation loss: 1.173770546913147\n",
      "mse 1.1737705288483378\n",
      "New best model found at epoch 120 with validation loss 1.173770546913147\n",
      "Starting Epoch 121\n",
      "1.2210906122041785\n",
      "Validation loss: 1.1717534065246582\n",
      "mse 1.1717534619730707\n",
      "New best model found at epoch 121 with validation loss 1.1717534065246582\n",
      "Starting Epoch 122\n",
      "1.219805041085119\n",
      "Validation loss: 1.170278549194336\n",
      "mse 1.1702786336255084\n",
      "New best model found at epoch 122 with validation loss 1.170278549194336\n",
      "Starting Epoch 123\n",
      "1.2181463552557903\n",
      "Validation loss: 1.1683788299560547\n",
      "mse 1.1683787658693596\n",
      "New best model found at epoch 123 with validation loss 1.1683788299560547\n",
      "Starting Epoch 124\n",
      "1.2164154311885005\n",
      "Validation loss: 1.167000651359558\n",
      "mse 1.1670005592400627\n",
      "New best model found at epoch 124 with validation loss 1.167000651359558\n",
      "Starting Epoch 125\n",
      "1.2148995114409404\n",
      "Validation loss: 1.1648123264312744\n",
      "mse 1.1648122693599088\n",
      "New best model found at epoch 125 with validation loss 1.1648123264312744\n",
      "Starting Epoch 126\n",
      "1.2135116846665093\n",
      "Validation loss: 1.1634225845336914\n",
      "mse 1.1634224919019887\n",
      "New best model found at epoch 126 with validation loss 1.1634225845336914\n",
      "Starting Epoch 127\n",
      "1.2118464682413184\n",
      "Validation loss: 1.1615850925445557\n",
      "mse 1.1615851117279832\n",
      "New best model found at epoch 127 with validation loss 1.1615850925445557\n",
      "Starting Epoch 128\n",
      "1.2103575623553733\n",
      "Validation loss: 1.1606194972991943\n",
      "mse 1.1606194714774987\n",
      "New best model found at epoch 128 with validation loss 1.1606194972991943\n",
      "Starting Epoch 129\n",
      "1.2094550728797913\n",
      "Validation loss: 1.1589716672897339\n",
      "mse 1.1589715837249484\n",
      "New best model found at epoch 129 with validation loss 1.1589716672897339\n",
      "Starting Epoch 130\n",
      "1.2075325198795483\n",
      "Validation loss: 1.1574746370315552\n",
      "mse 1.1574745032875895\n",
      "New best model found at epoch 130 with validation loss 1.1574746370315552\n",
      "Starting Epoch 131\n",
      "1.206208358640256\n",
      "Validation loss: 1.1561548709869385\n",
      "mse 1.1561549920449063\n",
      "New best model found at epoch 131 with validation loss 1.1561548709869385\n",
      "Starting Epoch 132\n",
      "1.2049033615900122\n",
      "Validation loss: 1.1553306579589844\n",
      "mse 1.1553307279680947\n",
      "New best model found at epoch 132 with validation loss 1.1553306579589844\n",
      "Starting Epoch 133\n",
      "1.2035417401272317\n",
      "Validation loss: 1.1532022953033447\n",
      "mse 1.1532023204159325\n",
      "New best model found at epoch 133 with validation loss 1.1532022953033447\n",
      "Starting Epoch 134\n",
      "1.202018501965896\n",
      "Validation loss: 1.1514110565185547\n",
      "mse 1.1514111096777724\n",
      "New best model found at epoch 134 with validation loss 1.1514110565185547\n",
      "Starting Epoch 135\n",
      "1.2005798091059146\n",
      "Validation loss: 1.15035879611969\n",
      "mse 1.150358863575642\n",
      "New best model found at epoch 135 with validation loss 1.15035879611969\n",
      "Starting Epoch 136\n",
      "1.1999701235605322\n",
      "Validation loss: 1.1490449905395508\n",
      "mse 1.1490450245164292\n",
      "New best model found at epoch 136 with validation loss 1.1490449905395508\n",
      "Starting Epoch 137\n",
      "1.1980278854784758\n",
      "Validation loss: 1.1472243070602417\n",
      "mse 1.1472240994147438\n",
      "New best model found at epoch 137 with validation loss 1.1472243070602417\n",
      "Starting Epoch 138\n",
      "1.196960394797118\n",
      "Validation loss: 1.145856499671936\n",
      "mse 1.1458566190847999\n",
      "New best model found at epoch 138 with validation loss 1.145856499671936\n",
      "Starting Epoch 139\n",
      "1.1960308059402134\n",
      "Validation loss: 1.144877314567566\n",
      "mse 1.1448773784018715\n",
      "New best model found at epoch 139 with validation loss 1.144877314567566\n",
      "Starting Epoch 140\n",
      "1.1946557449257893\n",
      "Validation loss: 1.1434531211853027\n",
      "mse 1.1434531500738887\n",
      "New best model found at epoch 140 with validation loss 1.1434531211853027\n",
      "Starting Epoch 141\n",
      "1.1935854269110637\n",
      "Validation loss: 1.1428978443145752\n",
      "mse 1.1428978940342416\n",
      "New best model found at epoch 141 with validation loss 1.1428978443145752\n",
      "Starting Epoch 142\n",
      "1.1920873963314553\n",
      "Validation loss: 1.1415586471557617\n",
      "mse 1.141558636559838\n",
      "New best model found at epoch 142 with validation loss 1.1415586471557617\n",
      "Starting Epoch 143\n",
      "1.1909173312394514\n",
      "Validation loss: 1.140866756439209\n",
      "mse 1.140866659441645\n",
      "New best model found at epoch 143 with validation loss 1.140866756439209\n",
      "Starting Epoch 144\n",
      "1.189932934615923\n",
      "Validation loss: 1.139591932296753\n",
      "mse 1.1395918843252661\n",
      "New best model found at epoch 144 with validation loss 1.139591932296753\n",
      "Starting Epoch 145\n",
      "1.1890731479810632\n",
      "Validation loss: 1.1385416984558105\n",
      "mse 1.1385416792649616\n",
      "New best model found at epoch 145 with validation loss 1.1385416984558105\n",
      "Starting Epoch 146\n",
      "1.1876354761745618\n",
      "Validation loss: 1.1375105381011963\n",
      "mse 1.137510585338366\n",
      "New best model found at epoch 146 with validation loss 1.1375105381011963\n",
      "Starting Epoch 147\n",
      "1.186889060165571\n",
      "Validation loss: 1.136528491973877\n",
      "mse 1.1365284813420136\n",
      "New best model found at epoch 147 with validation loss 1.136528491973877\n",
      "Starting Epoch 148\n",
      "1.185658390107362\n",
      "Validation loss: 1.1348994970321655\n",
      "mse 1.134899552653935\n",
      "New best model found at epoch 148 with validation loss 1.1348994970321655\n",
      "Starting Epoch 149\n",
      "1.1843866913214973\n",
      "Validation loss: 1.1341586112976074\n",
      "mse 1.1341585348870449\n",
      "New best model found at epoch 149 with validation loss 1.1341586112976074\n",
      "Starting Epoch 150\n",
      "1.183362224827642\n",
      "Validation loss: 1.1327793598175049\n",
      "mse 1.1327793596302524\n",
      "New best model found at epoch 150 with validation loss 1.1327793598175049\n",
      "Starting Epoch 151\n",
      "1.182319620381231\n",
      "Validation loss: 1.1319148540496826\n",
      "mse 1.131914939820591\n",
      "New best model found at epoch 151 with validation loss 1.1319148540496826\n",
      "Starting Epoch 152\n",
      "1.1812048476675283\n",
      "Validation loss: 1.130760908126831\n",
      "mse 1.130760915269862\n",
      "New best model found at epoch 152 with validation loss 1.130760908126831\n",
      "Starting Epoch 153\n",
      "1.1800745207330454\n",
      "Validation loss: 1.1291720867156982\n",
      "mse 1.1291721411739473\n",
      "New best model found at epoch 153 with validation loss 1.1291720867156982\n",
      "Starting Epoch 154\n",
      "1.1792817867320518\n",
      "Validation loss: 1.1288219690322876\n",
      "mse 1.1288218979944744\n",
      "New best model found at epoch 154 with validation loss 1.1288219690322876\n",
      "Starting Epoch 155\n",
      "1.1782815119494563\n",
      "Validation loss: 1.1274354457855225\n",
      "mse 1.1274353859556485\n",
      "New best model found at epoch 155 with validation loss 1.1274354457855225\n",
      "Starting Epoch 156\n",
      "1.17707687098047\n",
      "Validation loss: 1.1263247728347778\n",
      "mse 1.1263246580320752\n",
      "New best model found at epoch 156 with validation loss 1.1263247728347778\n",
      "Starting Epoch 157\n",
      "1.1758850061375161\n",
      "Validation loss: 1.1250336170196533\n",
      "mse 1.1250335657902386\n",
      "New best model found at epoch 157 with validation loss 1.1250336170196533\n",
      "Starting Epoch 158\n",
      "1.1752755460531816\n",
      "Validation loss: 1.1243606805801392\n",
      "mse 1.1243607764705534\n",
      "New best model found at epoch 158 with validation loss 1.1243606805801392\n",
      "Starting Epoch 159\n",
      "1.1741474270820618\n",
      "Validation loss: 1.1230194568634033\n",
      "mse 1.123019389367218\n",
      "New best model found at epoch 159 with validation loss 1.1230194568634033\n",
      "Starting Epoch 160\n",
      "1.1730997458748196\n",
      "Validation loss: 1.122367024421692\n",
      "mse 1.1223669658162094\n",
      "New best model found at epoch 160 with validation loss 1.122367024421692\n",
      "Starting Epoch 161\n",
      "1.1721224810766138\n",
      "Validation loss: 1.121071696281433\n",
      "mse 1.1210717105087982\n",
      "New best model found at epoch 161 with validation loss 1.121071696281433\n",
      "Starting Epoch 162\n",
      "1.1709450742472773\n",
      "Validation loss: 1.1207982301712036\n",
      "mse 1.120798316988371\n",
      "New best model found at epoch 162 with validation loss 1.1207982301712036\n",
      "Starting Epoch 163\n",
      "1.1700124585110208\n",
      "Validation loss: 1.1187971830368042\n",
      "mse 1.1187972063907283\n",
      "New best model found at epoch 163 with validation loss 1.1187971830368042\n",
      "Starting Epoch 164\n",
      "1.1691022126570991\n",
      "Validation loss: 1.1180284023284912\n",
      "mse 1.1180283731711687\n",
      "New best model found at epoch 164 with validation loss 1.1180284023284912\n",
      "Starting Epoch 165\n",
      "1.1680330063985742\n",
      "Validation loss: 1.1167817115783691\n",
      "mse 1.1167817085552687\n",
      "New best model found at epoch 165 with validation loss 1.1167817115783691\n",
      "Starting Epoch 166\n",
      "1.1669304059899372\n",
      "Validation loss: 1.115714192390442\n",
      "mse 1.1157142600751029\n",
      "New best model found at epoch 166 with validation loss 1.115714192390442\n",
      "Starting Epoch 167\n",
      "1.1661399265994197\n",
      "Validation loss: 1.114971399307251\n",
      "mse 1.1149712791842117\n",
      "New best model found at epoch 167 with validation loss 1.114971399307251\n",
      "Starting Epoch 168\n",
      "1.1651287778564121\n",
      "Validation loss: 1.1135494709014893\n",
      "mse 1.1135495518002425\n",
      "New best model found at epoch 168 with validation loss 1.1135494709014893\n",
      "Starting Epoch 169\n",
      "1.1642542921978494\n",
      "Validation loss: 1.112432599067688\n",
      "mse 1.1124326210260527\n",
      "New best model found at epoch 169 with validation loss 1.112432599067688\n",
      "Starting Epoch 170\n",
      "1.1631276737088743\n",
      "Validation loss: 1.111689567565918\n",
      "mse 1.1116895340753647\n",
      "New best model found at epoch 170 with validation loss 1.111689567565918\n",
      "Starting Epoch 171\n",
      "1.162288593209308\n",
      "Validation loss: 1.1106928586959839\n",
      "mse 1.1106928191333292\n",
      "New best model found at epoch 171 with validation loss 1.1106928586959839\n",
      "Starting Epoch 172\n",
      "1.1615544583486475\n",
      "Validation loss: 1.1093641519546509\n",
      "mse 1.1093641301180195\n",
      "New best model found at epoch 172 with validation loss 1.1093641519546509\n",
      "Starting Epoch 173\n",
      "1.1605444835579914\n",
      "Validation loss: 1.108269214630127\n",
      "mse 1.1082692882964138\n",
      "New best model found at epoch 173 with validation loss 1.108269214630127\n",
      "Starting Epoch 174\n",
      "1.1600188612937927\n",
      "Validation loss: 1.1070517301559448\n",
      "mse 1.1070517598129392\n",
      "New best model found at epoch 174 with validation loss 1.1070517301559448\n",
      "Starting Epoch 175\n",
      "1.1590141964995342\n",
      "Validation loss: 1.1060543060302734\n",
      "mse 1.1060543540673686\n",
      "New best model found at epoch 175 with validation loss 1.1060543060302734\n",
      "Starting Epoch 176\n",
      "1.158208587895269\n",
      "Validation loss: 1.1048115491867065\n",
      "mse 1.104811584933401\n",
      "New best model found at epoch 176 with validation loss 1.1048115491867065\n",
      "Starting Epoch 177\n",
      "1.1570940276850825\n",
      "Validation loss: 1.1040959358215332\n",
      "mse 1.1040959550083833\n",
      "New best model found at epoch 177 with validation loss 1.1040959358215332\n",
      "Starting Epoch 178\n",
      "1.1565343141555786\n",
      "Validation loss: 1.1025670766830444\n",
      "mse 1.1025670443689886\n",
      "New best model found at epoch 178 with validation loss 1.1025670766830444\n",
      "Starting Epoch 179\n",
      "1.1557465662126956\n",
      "Validation loss: 1.1017369031906128\n",
      "mse 1.1017369042399348\n",
      "New best model found at epoch 179 with validation loss 1.1017369031906128\n",
      "Starting Epoch 180\n",
      "1.1546918464743572\n",
      "Validation loss: 1.1005558967590332\n",
      "mse 1.1005558136109606\n",
      "New best model found at epoch 180 with validation loss 1.1005558967590332\n",
      "Starting Epoch 181\n",
      "1.1542325175326804\n",
      "Validation loss: 1.1002745628356934\n",
      "mse 1.100274471168608\n",
      "New best model found at epoch 181 with validation loss 1.1002745628356934\n",
      "Starting Epoch 182\n",
      "1.1531206654465718\n",
      "Validation loss: 1.0989956855773926\n",
      "mse 1.0989956977282995\n",
      "New best model found at epoch 182 with validation loss 1.0989956855773926\n",
      "Starting Epoch 183\n",
      "1.1525066365366397\n",
      "Validation loss: 1.098513126373291\n",
      "mse 1.0985131699884678\n",
      "New best model found at epoch 183 with validation loss 1.098513126373291\n",
      "Starting Epoch 184\n",
      "1.1512000560760498\n",
      "Validation loss: 1.097556471824646\n",
      "mse 1.0975565522327146\n",
      "New best model found at epoch 184 with validation loss 1.097556471824646\n",
      "Starting Epoch 185\n",
      "1.1510441225507986\n",
      "Validation loss: 1.0967482328414917\n",
      "mse 1.0967482541394646\n",
      "New best model found at epoch 185 with validation loss 1.0967482328414917\n",
      "Starting Epoch 186\n",
      "1.1498540691707446\n",
      "Validation loss: 1.0956039428710938\n",
      "mse 1.0956040265813338\n",
      "New best model found at epoch 186 with validation loss 1.0956039428710938\n",
      "Starting Epoch 187\n",
      "1.149212456267813\n",
      "Validation loss: 1.0953260660171509\n",
      "mse 1.0953258829450312\n",
      "New best model found at epoch 187 with validation loss 1.0953260660171509\n",
      "Starting Epoch 188\n",
      "1.1483811347380928\n",
      "Validation loss: 1.0941227674484253\n",
      "mse 1.0941226541118434\n",
      "New best model found at epoch 188 with validation loss 1.0941227674484253\n",
      "Starting Epoch 189\n",
      "1.1477085040963215\n",
      "Validation loss: 1.093454360961914\n",
      "mse 1.0934542503648563\n",
      "New best model found at epoch 189 with validation loss 1.093454360961914\n",
      "Starting Epoch 190\n",
      "1.1469173638716987\n",
      "Validation loss: 1.0932427644729614\n",
      "mse 1.093242765777795\n",
      "New best model found at epoch 190 with validation loss 1.0932427644729614\n",
      "Starting Epoch 191\n",
      "1.146530928819076\n",
      "Validation loss: 1.0918281078338623\n",
      "mse 1.091828208081814\n",
      "New best model found at epoch 191 with validation loss 1.0918281078338623\n",
      "Starting Epoch 192\n",
      "1.144899026207302\n",
      "Validation loss: 1.0908664464950562\n",
      "mse 1.090866488304444\n",
      "New best model found at epoch 192 with validation loss 1.0908664464950562\n",
      "Starting Epoch 193\n",
      "1.1448799993680872\n",
      "Validation loss: 1.0900452136993408\n",
      "mse 1.0900450961901618\n",
      "New best model found at epoch 193 with validation loss 1.0900452136993408\n",
      "Starting Epoch 194\n",
      "1.1441068493801614\n",
      "Validation loss: 1.0887086391448975\n",
      "mse 1.0887086508160204\n",
      "New best model found at epoch 194 with validation loss 1.0887086391448975\n",
      "Starting Epoch 195\n",
      "1.1434975655182549\n",
      "Validation loss: 1.0888981819152832\n",
      "mse 1.0888981266512918\n",
      "Starting Epoch 196\n",
      "1.1420037150382996\n",
      "Validation loss: 1.0879552364349365\n",
      "mse 1.0879553371284993\n",
      "New best model found at epoch 196 with validation loss 1.0879552364349365\n",
      "Starting Epoch 197\n",
      "1.1420085430145264\n",
      "Validation loss: 1.087221384048462\n",
      "mse 1.0872213631149397\n",
      "New best model found at epoch 197 with validation loss 1.087221384048462\n",
      "Starting Epoch 198\n",
      "1.1408503962599712\n",
      "Validation loss: 1.0861061811447144\n",
      "mse 1.0861062250437126\n",
      "New best model found at epoch 198 with validation loss 1.0861061811447144\n",
      "Starting Epoch 199\n",
      "1.1408306308414624\n",
      "Validation loss: 1.0856600999832153\n",
      "mse 1.0856601454898243\n",
      "New best model found at epoch 199 with validation loss 1.0856600999832153\n",
      "Starting Epoch 200\n",
      "1.1396294858144678\n",
      "Validation loss: 1.0845600366592407\n",
      "mse 1.08456012050908\n",
      "New best model found at epoch 200 with validation loss 1.0845600366592407\n",
      "Starting Epoch 201\n",
      "1.1388691845147505\n",
      "Validation loss: 1.0844645500183105\n",
      "mse 1.0844645888119457\n",
      "New best model found at epoch 201 with validation loss 1.0844645500183105\n",
      "Starting Epoch 202\n",
      "1.1387040226355842\n",
      "Validation loss: 1.0837831497192383\n",
      "mse 1.0837830761190188\n",
      "New best model found at epoch 202 with validation loss 1.0837831497192383\n",
      "Starting Epoch 203\n",
      "1.1377561118291772\n",
      "Validation loss: 1.0833522081375122\n",
      "mse 1.0833521898840428\n",
      "New best model found at epoch 203 with validation loss 1.0833522081375122\n",
      "Starting Epoch 204\n",
      "1.1366969165594683\n",
      "Validation loss: 1.0823166370391846\n",
      "mse 1.0823165967194863\n",
      "New best model found at epoch 204 with validation loss 1.0823166370391846\n",
      "Starting Epoch 205\n",
      "1.136644397092902\n",
      "Validation loss: 1.0815987586975098\n",
      "mse 1.0815988304619535\n",
      "New best model found at epoch 205 with validation loss 1.0815987586975098\n",
      "Starting Epoch 206\n",
      "1.1356332846309827\n",
      "Validation loss: 1.080523133277893\n",
      "mse 1.0805232193503886\n",
      "New best model found at epoch 206 with validation loss 1.080523133277893\n",
      "Starting Epoch 207\n",
      "1.1350825480792834\n",
      "Validation loss: 1.0800739526748657\n",
      "mse 1.0800738994871788\n",
      "New best model found at epoch 207 with validation loss 1.0800739526748657\n",
      "Starting Epoch 208\n",
      "1.1347371676693792\n",
      "Validation loss: 1.0793057680130005\n",
      "mse 1.0793056762794049\n",
      "New best model found at epoch 208 with validation loss 1.0793057680130005\n",
      "Starting Epoch 209\n",
      "1.1336802218271338\n",
      "Validation loss: 1.0780171155929565\n",
      "mse 1.078017092552872\n",
      "New best model found at epoch 209 with validation loss 1.0780171155929565\n",
      "Starting Epoch 210\n",
      "1.1332479793092478\n",
      "Validation loss: 1.077858328819275\n",
      "mse 1.0778583248902156\n",
      "New best model found at epoch 210 with validation loss 1.077858328819275\n",
      "Starting Epoch 211\n",
      "1.132855456808339\n",
      "Validation loss: 1.0772058963775635\n",
      "mse 1.0772059027596537\n",
      "New best model found at epoch 211 with validation loss 1.0772058963775635\n",
      "Starting Epoch 212\n",
      "1.1317989333816196\n",
      "Validation loss: 1.0764524936676025\n",
      "mse 1.0764525150291717\n",
      "New best model found at epoch 212 with validation loss 1.0764524936676025\n",
      "Starting Epoch 213\n",
      "1.1314304885656938\n",
      "Validation loss: 1.075696587562561\n",
      "mse 1.075696547070791\n",
      "New best model found at epoch 213 with validation loss 1.075696587562561\n",
      "Starting Epoch 214\n",
      "1.1307746767997742\n",
      "Validation loss: 1.0746320486068726\n",
      "mse 1.07463199315184\n",
      "New best model found at epoch 214 with validation loss 1.0746320486068726\n",
      "Starting Epoch 215\n",
      "1.1301797395167144\n",
      "Validation loss: 1.0741275548934937\n",
      "mse 1.074127601213031\n",
      "New best model found at epoch 215 with validation loss 1.0741275548934937\n",
      "Starting Epoch 216\n",
      "1.1292081216107244\n",
      "Validation loss: 1.0729161500930786\n",
      "mse 1.0729161670386287\n",
      "New best model found at epoch 216 with validation loss 1.0729161500930786\n",
      "Starting Epoch 217\n",
      "1.1283597505610923\n",
      "Validation loss: 1.072091817855835\n",
      "mse 1.072091726386398\n",
      "New best model found at epoch 217 with validation loss 1.072091817855835\n",
      "Starting Epoch 218\n",
      "1.1279380554738252\n",
      "Validation loss: 1.070866584777832\n",
      "mse 1.070866551474664\n",
      "New best model found at epoch 218 with validation loss 1.070866584777832\n",
      "Starting Epoch 219\n",
      "1.1273981876995252\n",
      "Validation loss: 1.0708401203155518\n",
      "mse 1.0708401531223462\n",
      "New best model found at epoch 219 with validation loss 1.0708401203155518\n",
      "Starting Epoch 220\n",
      "1.126709373100944\n",
      "Validation loss: 1.0692377090454102\n",
      "mse 1.0692376793921077\n",
      "New best model found at epoch 220 with validation loss 1.0692377090454102\n",
      "Starting Epoch 221\n",
      "1.1258729618528616\n",
      "Validation loss: 1.0685542821884155\n",
      "mse 1.0685543159145265\n",
      "New best model found at epoch 221 with validation loss 1.0685542821884155\n",
      "Starting Epoch 222\n",
      "1.1250269672145015\n",
      "Validation loss: 1.0676203966140747\n",
      "mse 1.067620349317314\n",
      "New best model found at epoch 222 with validation loss 1.0676203966140747\n",
      "Starting Epoch 223\n",
      "1.1243809902149697\n",
      "Validation loss: 1.0670595169067383\n",
      "mse 1.0670595146686686\n",
      "New best model found at epoch 223 with validation loss 1.0670595169067383\n",
      "Starting Epoch 224\n",
      "1.1238296887148982\n",
      "Validation loss: 1.0666735172271729\n",
      "mse 1.066673505803016\n",
      "New best model found at epoch 224 with validation loss 1.0666735172271729\n",
      "Starting Epoch 225\n",
      "1.1234830047773279\n",
      "Validation loss: 1.0657739639282227\n",
      "mse 1.0657739706251135\n",
      "New best model found at epoch 225 with validation loss 1.0657739639282227\n",
      "Starting Epoch 226\n",
      "1.12282699605693\n",
      "Validation loss: 1.0648201704025269\n",
      "mse 1.0648201951244662\n",
      "New best model found at epoch 226 with validation loss 1.0648201704025269\n",
      "Starting Epoch 227\n",
      "1.122572072174238\n",
      "Validation loss: 1.0645341873168945\n",
      "mse 1.0645342423488224\n",
      "New best model found at epoch 227 with validation loss 1.0645341873168945\n",
      "Starting Epoch 228\n",
      "1.121466014696204\n",
      "Validation loss: 1.0642757415771484\n",
      "mse 1.0642758708803994\n",
      "New best model found at epoch 228 with validation loss 1.0642757415771484\n",
      "Starting Epoch 229\n",
      "1.1214518002841785\n",
      "Validation loss: 1.0631836652755737\n",
      "mse 1.0631836707891882\n",
      "New best model found at epoch 229 with validation loss 1.0631836652755737\n",
      "Starting Epoch 230\n",
      "1.1202279173809548\n",
      "Validation loss: 1.0624791383743286\n",
      "mse 1.062479109272123\n",
      "New best model found at epoch 230 with validation loss 1.0624791383743286\n",
      "Starting Epoch 231\n",
      "1.1200522054796633\n",
      "Validation loss: 1.0619854927062988\n",
      "mse 1.0619853972621145\n",
      "New best model found at epoch 231 with validation loss 1.0619854927062988\n",
      "Starting Epoch 232\n",
      "1.1194051763285762\n",
      "Validation loss: 1.0611870288848877\n",
      "mse 1.0611870007637216\n",
      "New best model found at epoch 232 with validation loss 1.0611870288848877\n",
      "Starting Epoch 233\n",
      "1.1190429018891377\n",
      "Validation loss: 1.0607919692993164\n",
      "mse 1.0607920011904806\n",
      "New best model found at epoch 233 with validation loss 1.0607919692993164\n",
      "Starting Epoch 234\n",
      "1.1176668664683467\n",
      "Validation loss: 1.0603902339935303\n",
      "mse 1.060390152546689\n",
      "New best model found at epoch 234 with validation loss 1.0603902339935303\n",
      "Starting Epoch 235\n",
      "1.1174446111140044\n",
      "Validation loss: 1.0595698356628418\n",
      "mse 1.0595697458118802\n",
      "New best model found at epoch 235 with validation loss 1.0595698356628418\n",
      "Starting Epoch 236\n",
      "1.1169444892717444\n",
      "Validation loss: 1.0588915348052979\n",
      "mse 1.0588916140023579\n",
      "New best model found at epoch 236 with validation loss 1.0588915348052979\n",
      "Starting Epoch 237\n",
      "1.1162106938984082\n",
      "Validation loss: 1.0587626695632935\n",
      "mse 1.058762639731104\n",
      "New best model found at epoch 237 with validation loss 1.0587626695632935\n",
      "Starting Epoch 238\n",
      "1.1157839220503103\n",
      "Validation loss: 1.0580960512161255\n",
      "mse 1.0580960120428549\n",
      "New best model found at epoch 238 with validation loss 1.0580960512161255\n",
      "Starting Epoch 239\n",
      "1.115296174650607\n",
      "Validation loss: 1.0575830936431885\n",
      "mse 1.0575829939876347\n",
      "New best model found at epoch 239 with validation loss 1.0575830936431885\n",
      "Starting Epoch 240\n",
      "1.1148129597954128\n",
      "Validation loss: 1.056816816329956\n",
      "mse 1.0568167259663463\n",
      "New best model found at epoch 240 with validation loss 1.056816816329956\n",
      "Starting Epoch 241\n",
      "1.1139994600544805\n",
      "Validation loss: 1.0561227798461914\n",
      "mse 1.056122760380089\n",
      "New best model found at epoch 241 with validation loss 1.0561227798461914\n",
      "Starting Epoch 242\n",
      "1.114126187303792\n",
      "Validation loss: 1.0557880401611328\n",
      "mse 1.0557880262680206\n",
      "New best model found at epoch 242 with validation loss 1.0557880401611328\n",
      "Starting Epoch 243\n",
      "1.1128160979436792\n",
      "Validation loss: 1.0552386045455933\n",
      "mse 1.0552386710283514\n",
      "New best model found at epoch 243 with validation loss 1.0552386045455933\n",
      "Starting Epoch 244\n",
      "1.1122410064158232\n",
      "Validation loss: 1.0547642707824707\n",
      "mse 1.0547643861258118\n",
      "New best model found at epoch 244 with validation loss 1.0547642707824707\n",
      "Starting Epoch 245\n",
      "1.1120929199716318\n",
      "Validation loss: 1.0542017221450806\n",
      "mse 1.0542016256030582\n",
      "New best model found at epoch 245 with validation loss 1.0542017221450806\n",
      "Starting Epoch 246\n",
      "1.1112563273181086\n",
      "Validation loss: 1.053403615951538\n",
      "mse 1.053403570143714\n",
      "New best model found at epoch 246 with validation loss 1.053403615951538\n",
      "Starting Epoch 247\n",
      "1.1104915841766025\n",
      "Validation loss: 1.0528619289398193\n",
      "mse 1.052861838513871\n",
      "New best model found at epoch 247 with validation loss 1.0528619289398193\n",
      "Starting Epoch 248\n",
      "1.1103774412818577\n",
      "Validation loss: 1.0526279211044312\n",
      "mse 1.0526278700619776\n",
      "New best model found at epoch 248 with validation loss 1.0526279211044312\n",
      "Starting Epoch 249\n",
      "1.1096393155015034\n",
      "Validation loss: 1.05197012424469\n",
      "mse 1.051970203421352\n",
      "New best model found at epoch 249 with validation loss 1.05197012424469\n",
      "Starting Epoch 250\n",
      "1.1090730117714924\n",
      "Validation loss: 1.051504373550415\n",
      "mse 1.0515043635532502\n",
      "New best model found at epoch 250 with validation loss 1.051504373550415\n",
      "Starting Epoch 251\n",
      "1.1085777930591418\n",
      "Validation loss: 1.0507338047027588\n",
      "mse 1.0507336324126784\n",
      "New best model found at epoch 251 with validation loss 1.0507338047027588\n",
      "Starting Epoch 252\n",
      "1.1080471614132756\n",
      "Validation loss: 1.0503991842269897\n",
      "mse 1.0503991777494974\n",
      "New best model found at epoch 252 with validation loss 1.0503991842269897\n",
      "Starting Epoch 253\n",
      "1.1077261878096538\n",
      "Validation loss: 1.050108790397644\n",
      "mse 1.0501087200719492\n",
      "New best model found at epoch 253 with validation loss 1.050108790397644\n",
      "Starting Epoch 254\n",
      "1.1073104272718015\n",
      "Validation loss: 1.0491496324539185\n",
      "mse 1.0491496210745441\n",
      "New best model found at epoch 254 with validation loss 1.0491496324539185\n",
      "Starting Epoch 255\n",
      "1.106678307056427\n",
      "Validation loss: 1.0487245321273804\n",
      "mse 1.048724575070422\n",
      "New best model found at epoch 255 with validation loss 1.0487245321273804\n",
      "Starting Epoch 256\n",
      "1.1058997822844463\n",
      "Validation loss: 1.0480834245681763\n",
      "mse 1.0480834938587258\n",
      "New best model found at epoch 256 with validation loss 1.0480834245681763\n",
      "Starting Epoch 257\n",
      "1.1055564025174016\n",
      "Validation loss: 1.0484418869018555\n",
      "mse 1.0484417925414649\n",
      "Starting Epoch 258\n",
      "1.104729844176251\n",
      "Validation loss: 1.0465449094772339\n",
      "mse 1.0465449879994007\n",
      "New best model found at epoch 258 with validation loss 1.0465449094772339\n",
      "Starting Epoch 259\n",
      "1.1043090483416682\n",
      "Validation loss: 1.0474714040756226\n",
      "mse 1.0474713578163848\n",
      "Starting Epoch 260\n",
      "1.1039715720259624\n",
      "Validation loss: 1.045971393585205\n",
      "mse 1.0459713887322388\n",
      "New best model found at epoch 260 with validation loss 1.045971393585205\n",
      "Starting Epoch 261\n",
      "1.1034165828124336\n",
      "Validation loss: 1.0454659461975098\n",
      "mse 1.0454660190763199\n",
      "New best model found at epoch 261 with validation loss 1.0454659461975098\n",
      "Starting Epoch 262\n",
      "1.1027435245721235\n",
      "Validation loss: 1.0447708368301392\n",
      "mse 1.0447707736627454\n",
      "New best model found at epoch 262 with validation loss 1.0447708368301392\n",
      "Starting Epoch 263\n",
      "1.102134214795154\n",
      "Validation loss: 1.0447152853012085\n",
      "mse 1.04471529159414\n",
      "New best model found at epoch 263 with validation loss 1.0447152853012085\n",
      "Starting Epoch 264\n",
      "1.1014884321585945\n",
      "Validation loss: 1.0436729192733765\n",
      "mse 1.0436729183298998\n",
      "New best model found at epoch 264 with validation loss 1.0436729192733765\n",
      "Starting Epoch 265\n",
      "1.1009844800700312\n",
      "Validation loss: 1.0436979532241821\n",
      "mse 1.0436979453258168\n",
      "Starting Epoch 266\n",
      "1.1006234003149944\n",
      "Validation loss: 1.044089913368225\n",
      "mse 1.0440899393632717\n",
      "Starting Epoch 267\n",
      "1.1003950341888096\n",
      "Validation loss: 1.0423284769058228\n",
      "mse 1.0423284298217383\n",
      "New best model found at epoch 267 with validation loss 1.0423284769058228\n",
      "Starting Epoch 268\n",
      "1.0993759865346162\n",
      "Validation loss: 1.041619062423706\n",
      "mse 1.041619070889624\n",
      "New best model found at epoch 268 with validation loss 1.041619062423706\n",
      "Starting Epoch 269\n",
      "1.0989903600319573\n",
      "Validation loss: 1.0414341688156128\n",
      "mse 1.0414341556667017\n",
      "New best model found at epoch 269 with validation loss 1.0414341688156128\n",
      "Starting Epoch 270\n",
      "1.0987805542738542\n",
      "Validation loss: 1.040842890739441\n",
      "mse 1.0408428104070286\n",
      "New best model found at epoch 270 with validation loss 1.040842890739441\n",
      "Starting Epoch 271\n",
      "1.0980500501135122\n",
      "Validation loss: 1.0404667854309082\n",
      "mse 1.0404666607833812\n",
      "New best model found at epoch 271 with validation loss 1.0404667854309082\n",
      "Starting Epoch 272\n",
      "1.097640724285789\n",
      "Validation loss: 1.0398900508880615\n",
      "mse 1.0398899895243303\n",
      "New best model found at epoch 272 with validation loss 1.0398900508880615\n",
      "Starting Epoch 273\n",
      "1.0968519786129827\n",
      "Validation loss: 1.0396692752838135\n",
      "mse 1.0396691720735076\n",
      "New best model found at epoch 273 with validation loss 1.0396692752838135\n",
      "Starting Epoch 274\n",
      "1.0963085371515024\n",
      "Validation loss: 1.0390907526016235\n",
      "mse 1.0390908606874236\n",
      "New best model found at epoch 274 with validation loss 1.0390907526016235\n",
      "Starting Epoch 275\n",
      "1.0958984105483345\n",
      "Validation loss: 1.038395643234253\n",
      "mse 1.0383955665622198\n",
      "New best model found at epoch 275 with validation loss 1.038395643234253\n",
      "Starting Epoch 276\n",
      "1.0952430237894473\n",
      "Validation loss: 1.0382614135742188\n",
      "mse 1.038261465707202\n",
      "New best model found at epoch 276 with validation loss 1.0382614135742188\n",
      "Starting Epoch 277\n",
      "1.0946046891419783\n",
      "Validation loss: 1.038076639175415\n",
      "mse 1.0380766876951752\n",
      "New best model found at epoch 277 with validation loss 1.038076639175415\n",
      "Starting Epoch 278\n",
      "1.0941745431526848\n",
      "Validation loss: 1.0370951890945435\n",
      "mse 1.0370952036250156\n",
      "New best model found at epoch 278 with validation loss 1.0370951890945435\n",
      "Starting Epoch 279\n",
      "1.0935959634573564\n",
      "Validation loss: 1.0365768671035767\n",
      "mse 1.0365768165967544\n",
      "New best model found at epoch 279 with validation loss 1.0365768671035767\n",
      "Starting Epoch 280\n",
      "1.0934340150459954\n",
      "Validation loss: 1.0367591381072998\n",
      "mse 1.036759161015745\n",
      "Starting Epoch 281\n",
      "1.0930188583291096\n",
      "Validation loss: 1.0357544422149658\n",
      "mse 1.0357543683241055\n",
      "New best model found at epoch 281 with validation loss 1.0357544422149658\n",
      "Starting Epoch 282\n",
      "1.0924735639406287\n",
      "Validation loss: 1.0350145101547241\n",
      "mse 1.0350146618924332\n",
      "New best model found at epoch 282 with validation loss 1.0350145101547241\n",
      "Starting Epoch 283\n",
      "1.0918249150981074\n",
      "Validation loss: 1.0352756977081299\n",
      "mse 1.0352756923537803\n",
      "Starting Epoch 284\n",
      "1.0912195988323377\n",
      "Validation loss: 1.0346462726593018\n",
      "mse 1.034646338067299\n",
      "New best model found at epoch 284 with validation loss 1.0346462726593018\n",
      "Starting Epoch 285\n",
      "1.0910053641899773\n",
      "Validation loss: 1.0340429544448853\n",
      "mse 1.0340429562992972\n",
      "New best model found at epoch 285 with validation loss 1.0340429544448853\n",
      "Starting Epoch 286\n",
      "1.090490724729455\n",
      "Validation loss: 1.0338388681411743\n",
      "mse 1.0338389307005769\n",
      "New best model found at epoch 286 with validation loss 1.0338388681411743\n",
      "Starting Epoch 287\n",
      "1.0905278947042383\n",
      "Validation loss: 1.0330872535705566\n",
      "mse 1.033087213023184\n",
      "New best model found at epoch 287 with validation loss 1.0330872535705566\n",
      "Starting Epoch 288\n",
      "1.0894189813862676\n",
      "Validation loss: 1.0324043035507202\n",
      "mse 1.0324042996970741\n",
      "New best model found at epoch 288 with validation loss 1.0324043035507202\n",
      "Starting Epoch 289\n",
      "1.0891543263974397\n",
      "Validation loss: 1.0323249101638794\n",
      "mse 1.0323249786212352\n",
      "New best model found at epoch 289 with validation loss 1.0323249101638794\n",
      "Starting Epoch 290\n",
      "1.0889044222624407\n",
      "Validation loss: 1.0314029455184937\n",
      "mse 1.0314030029645764\n",
      "New best model found at epoch 290 with validation loss 1.0314029455184937\n",
      "Starting Epoch 291\n",
      "1.0880588759546694\n",
      "Validation loss: 1.0313397645950317\n",
      "mse 1.0313397566711235\n",
      "New best model found at epoch 291 with validation loss 1.0313397645950317\n",
      "Starting Epoch 292\n",
      "1.087965594685596\n",
      "Validation loss: 1.029809832572937\n",
      "mse 1.0298098554440933\n",
      "New best model found at epoch 292 with validation loss 1.029809832572937\n",
      "Starting Epoch 293\n",
      "1.0872881567996482\n",
      "Validation loss: 1.0300567150115967\n",
      "mse 1.0300567327062617\n",
      "Starting Epoch 294\n",
      "1.0871521001276763\n",
      "Validation loss: 1.0305254459381104\n",
      "mse 1.0305254329113216\n",
      "Starting Epoch 295\n",
      "1.0867023960403774\n",
      "Validation loss: 1.0287928581237793\n",
      "mse 1.028792805591817\n",
      "New best model found at epoch 295 with validation loss 1.0287928581237793\n",
      "Starting Epoch 296\n",
      "1.0859802520793418\n",
      "Validation loss: 1.0286340713500977\n",
      "mse 1.0286340665323055\n",
      "New best model found at epoch 296 with validation loss 1.0286340713500977\n",
      "Starting Epoch 297\n",
      "1.085850002972976\n",
      "Validation loss: 1.0294262170791626\n",
      "mse 1.0294263128673578\n",
      "Starting Epoch 298\n",
      "1.0853564661482107\n",
      "Validation loss: 1.0276234149932861\n",
      "mse 1.0276233362398568\n",
      "New best model found at epoch 298 with validation loss 1.0276234149932861\n",
      "Starting Epoch 299\n",
      "1.084885483202727\n",
      "Validation loss: 1.0275139808654785\n",
      "mse 1.027513931168872\n",
      "New best model found at epoch 299 with validation loss 1.0275139808654785\n",
      "Starting Epoch 300\n",
      "1.0846605197243069\n",
      "Validation loss: 1.027500033378601\n",
      "mse 1.0275001696141552\n",
      "New best model found at epoch 300 with validation loss 1.027500033378601\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP: 17-80-50-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "fe5c918e-67e8-48b7-a9f6-90073cee2768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.587345</td>\n",
       "      <td>0.486148</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.480216</td>\n",
       "      <td>0.79731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.490544</td>\n",
       "      <td>0.447684</td>\n",
       "      <td>0.827719</td>\n",
       "      <td>0.591385</td>\n",
       "      <td>0.455429</td>\n",
       "      <td>0.812813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.489989</td>\n",
       "      <td>0.448514</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.573214</td>\n",
       "      <td>0.453536</td>\n",
       "      <td>0.818565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>1.696579</td>\n",
       "      <td>0.788013</td>\n",
       "      <td>0.404154</td>\n",
       "      <td>1.859457</td>\n",
       "      <td>0.828425</td>\n",
       "      <td>0.411439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.741289</td>\n",
       "      <td>0.752971</td>\n",
       "      <td>0.388452</td>\n",
       "      <td>1.829105</td>\n",
       "      <td>0.784481</td>\n",
       "      <td>0.421047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.618412</td>\n",
       "      <td>0.724068</td>\n",
       "      <td>0.431607</td>\n",
       "      <td>1.792327</td>\n",
       "      <td>0.772814</td>\n",
       "      <td>0.432687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-1</th>\n",
       "      <td>1.505071</td>\n",
       "      <td>0.867196</td>\n",
       "      <td>0.471413</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-1</th>\n",
       "      <td>1.554706</td>\n",
       "      <td>0.867515</td>\n",
       "      <td>0.453981</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-1</th>\n",
       "      <td>1.451219</td>\n",
       "      <td>0.828152</td>\n",
       "      <td>0.490326</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-1</th>\n",
       "      <td>1.472163</td>\n",
       "      <td>0.836597</td>\n",
       "      <td>0.482970</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-1</th>\n",
       "      <td>1.444209</td>\n",
       "      <td>0.820480</td>\n",
       "      <td>0.492788</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-1</th>\n",
       "      <td>1.411537</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.504262</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-1</th>\n",
       "      <td>1.400415</td>\n",
       "      <td>0.823216</td>\n",
       "      <td>0.508168</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-1</th>\n",
       "      <td>1.345054</td>\n",
       "      <td>0.802008</td>\n",
       "      <td>0.527611</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-1</th>\n",
       "      <td>1.263771</td>\n",
       "      <td>0.772361</td>\n",
       "      <td>0.556158</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-1</th>\n",
       "      <td>1.388075</td>\n",
       "      <td>0.811131</td>\n",
       "      <td>0.512502</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-1</th>\n",
       "      <td>1.009602</td>\n",
       "      <td>0.684272</td>\n",
       "      <td>0.645424</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-1</th>\n",
       "      <td>1.124673</td>\n",
       "      <td>0.718425</td>\n",
       "      <td>0.605010</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-1</th>\n",
       "      <td>1.027500</td>\n",
       "      <td>0.670468</td>\n",
       "      <td>0.639138</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MSE       MAE        R2       MSE       MAE        R2\n",
       "5-NN             0.587345  0.486148  0.793722  0.640365  0.480216   0.79731\n",
       "Decision tree    0.490544  0.447684  0.827719  0.591385  0.455429  0.812813\n",
       "Random forest    0.489989  0.448514  0.827914  0.573214  0.453536  0.818565\n",
       "SVM linear       1.696579  0.788013  0.404154  1.859457  0.828425  0.411439\n",
       "SVM poly         1.741289  0.752971  0.388452  1.829105  0.784481  0.421047\n",
       "SVM rbf          1.618412  0.724068  0.431607  1.792327  0.772814  0.432687\n",
       "MLP: 17-5-1      1.505071  0.867196  0.471413         -         -         -\n",
       "MLP: 17-10-1     1.554706  0.867515  0.453981         -         -         -\n",
       "MLP: 17-20-1     1.451219  0.828152  0.490326         -         -         -\n",
       "MLP: 17-25-1     1.472163  0.836597  0.482970         -         -         -\n",
       "MLP: 17-40-1     1.444209  0.820480  0.492788         -         -         -\n",
       "MLP: 17-60-1     1.411537  0.821209  0.504262         -         -         -\n",
       "MLP: 17-10-5-1   1.400415  0.823216  0.508168         -         -         -\n",
       "MLP: 17-20-10-1  1.345054  0.802008  0.527611         -         -         -\n",
       "MLP: 17-40-20-1  1.263771  0.772361  0.556158         -         -         -\n",
       "MLP: 17-40-10-1  1.388075  0.811131  0.512502         -         -         -\n",
       "MLP: 17-60-40-1  1.009602  0.684272  0.645424         -         -         -\n",
       "MLP: 17-60-20-1  1.124673  0.718425  0.605010         -         -         -\n",
       "MLP: 17-80-50-1  1.027500  0.670468  0.639138         -         -         -"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc2ad6-88d6-488d-a023-cf626d9e4cc7",
   "metadata": {},
   "source": [
    "best performing model until now: 4 layers, 17-60-40-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2d146-889f-477a-a40e-52cf1fd0e002",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 60 - 40 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "09470076-34c0-4851-9342-98074d61b0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "89b6c3a3-866b-4b4d-8b35-39fd55a271fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,9,14]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,9,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "9bb38635-730a-4728-92fd-6beb6b6ed92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'median(container counts)', 'median(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "5acc06e5-d693-4287-9b6b-1097338ccce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "774cb0f4-1718-4ff1-8d44-32fd9d0551f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.14474966733352\n",
      "Validation loss: 2.4974429607391357\n",
      "mse 2.497442932899975\n",
      "New best model found at epoch 1 with validation loss 2.4974429607391357\n",
      "Starting Epoch 2\n",
      "2.5738632419834966\n",
      "Validation loss: 2.1863224506378174\n",
      "mse 2.1863223770921336\n",
      "New best model found at epoch 2 with validation loss 2.1863224506378174\n",
      "Starting Epoch 3\n",
      "2.2933782390926196\n",
      "Validation loss: 2.0025429725646973\n",
      "mse 2.002542849746114\n",
      "New best model found at epoch 3 with validation loss 2.0025429725646973\n",
      "Starting Epoch 4\n",
      "2.1267647743225098\n",
      "Validation loss: 1.8972216844558716\n",
      "mse 1.8972216429489408\n",
      "New best model found at epoch 4 with validation loss 1.8972216844558716\n",
      "Starting Epoch 5\n",
      "2.0184963734253594\n",
      "Validation loss: 1.8354589939117432\n",
      "mse 1.835458908084179\n",
      "New best model found at epoch 5 with validation loss 1.8354589939117432\n",
      "Starting Epoch 6\n",
      "1.9486321988313093\n",
      "Validation loss: 1.7967991828918457\n",
      "mse 1.796799242865845\n",
      "New best model found at epoch 6 with validation loss 1.7967991828918457\n",
      "Starting Epoch 7\n",
      "1.900272830672886\n",
      "Validation loss: 1.770556092262268\n",
      "mse 1.770555861017615\n",
      "New best model found at epoch 7 with validation loss 1.770556092262268\n",
      "Starting Epoch 8\n",
      "1.8685081938038701\n",
      "Validation loss: 1.7486252784729004\n",
      "mse 1.748625216422784\n",
      "New best model found at epoch 8 with validation loss 1.7486252784729004\n",
      "Starting Epoch 9\n",
      "1.839815098306407\n",
      "Validation loss: 1.7339625358581543\n",
      "mse 1.7339624417568098\n",
      "New best model found at epoch 9 with validation loss 1.7339625358581543\n",
      "Starting Epoch 10\n",
      "1.8186086986375891\n",
      "Validation loss: 1.7222241163253784\n",
      "mse 1.7222239194745204\n",
      "New best model found at epoch 10 with validation loss 1.7222241163253784\n",
      "Starting Epoch 11\n",
      "1.8012325867362644\n",
      "Validation loss: 1.7113873958587646\n",
      "mse 1.7113875178768745\n",
      "New best model found at epoch 11 with validation loss 1.7113873958587646\n",
      "Starting Epoch 12\n",
      "1.7869797945022583\n",
      "Validation loss: 1.7017098665237427\n",
      "mse 1.7017098166018447\n",
      "New best model found at epoch 12 with validation loss 1.7017098665237427\n",
      "Starting Epoch 13\n",
      "1.774726380472598\n",
      "Validation loss: 1.693791151046753\n",
      "mse 1.693791066782896\n",
      "New best model found at epoch 13 with validation loss 1.693791151046753\n",
      "Starting Epoch 14\n",
      "1.7636286590410315\n",
      "Validation loss: 1.679567575454712\n",
      "mse 1.6795675035796507\n",
      "New best model found at epoch 14 with validation loss 1.679567575454712\n",
      "Starting Epoch 15\n",
      "1.7495745368625806\n",
      "Validation loss: 1.666629433631897\n",
      "mse 1.666629451389256\n",
      "New best model found at epoch 15 with validation loss 1.666629433631897\n",
      "Starting Epoch 16\n",
      "1.7380738621172698\n",
      "Validation loss: 1.6586577892303467\n",
      "mse 1.6586579533445427\n",
      "New best model found at epoch 16 with validation loss 1.6586577892303467\n",
      "Starting Epoch 17\n",
      "1.7289816711259924\n",
      "Validation loss: 1.6501147747039795\n",
      "mse 1.650114837433668\n",
      "New best model found at epoch 17 with validation loss 1.6501147747039795\n",
      "Starting Epoch 18\n",
      "1.720683631689652\n",
      "Validation loss: 1.6439635753631592\n",
      "mse 1.6439636045915642\n",
      "New best model found at epoch 18 with validation loss 1.6439635753631592\n",
      "Starting Epoch 19\n",
      "1.7134995771491008\n",
      "Validation loss: 1.6378636360168457\n",
      "mse 1.6378636685350005\n",
      "New best model found at epoch 19 with validation loss 1.6378636360168457\n",
      "Starting Epoch 20\n",
      "1.7071198743322622\n",
      "Validation loss: 1.6327980756759644\n",
      "mse 1.632798145705158\n",
      "New best model found at epoch 20 with validation loss 1.6327980756759644\n",
      "Starting Epoch 21\n",
      "1.7015162447224492\n",
      "Validation loss: 1.6279516220092773\n",
      "mse 1.627951743112972\n",
      "New best model found at epoch 21 with validation loss 1.6279516220092773\n",
      "Starting Epoch 22\n",
      "1.696318496828494\n",
      "Validation loss: 1.623426914215088\n",
      "mse 1.6234270238064172\n",
      "New best model found at epoch 22 with validation loss 1.623426914215088\n",
      "Starting Epoch 23\n",
      "1.6914376849713533\n",
      "Validation loss: 1.6196454763412476\n",
      "mse 1.6196454061732852\n",
      "New best model found at epoch 23 with validation loss 1.6196454763412476\n",
      "Starting Epoch 24\n",
      "1.6871952077616816\n",
      "Validation loss: 1.6161091327667236\n",
      "mse 1.616109071282972\n",
      "New best model found at epoch 24 with validation loss 1.6161091327667236\n",
      "Starting Epoch 25\n",
      "1.6833458050437595\n",
      "Validation loss: 1.6125026941299438\n",
      "mse 1.612502896904685\n",
      "New best model found at epoch 25 with validation loss 1.6125026941299438\n",
      "Starting Epoch 26\n",
      "1.6797073405721914\n",
      "Validation loss: 1.6095936298370361\n",
      "mse 1.6095937114634586\n",
      "New best model found at epoch 26 with validation loss 1.6095936298370361\n",
      "Starting Epoch 27\n",
      "1.6763616230176843\n",
      "Validation loss: 1.6066619157791138\n",
      "mse 1.6066618895622453\n",
      "New best model found at epoch 27 with validation loss 1.6066619157791138\n",
      "Starting Epoch 28\n",
      "1.6733205888582312\n",
      "Validation loss: 1.603935718536377\n",
      "mse 1.6039357071991966\n",
      "New best model found at epoch 28 with validation loss 1.603935718536377\n",
      "Starting Epoch 29\n",
      "1.6703090564064358\n",
      "Validation loss: 1.6010794639587402\n",
      "mse 1.6010794176266474\n",
      "New best model found at epoch 29 with validation loss 1.6010794639587402\n",
      "Starting Epoch 30\n",
      "1.6675022892330005\n",
      "Validation loss: 1.5982818603515625\n",
      "mse 1.5982819640231019\n",
      "New best model found at epoch 30 with validation loss 1.5982818603515625\n",
      "Starting Epoch 31\n",
      "1.664882172708926\n",
      "Validation loss: 1.595513939857483\n",
      "mse 1.5955140910791121\n",
      "New best model found at epoch 31 with validation loss 1.595513939857483\n",
      "Starting Epoch 32\n",
      "1.6621902403624162\n",
      "Validation loss: 1.5931458473205566\n",
      "mse 1.5931456856017525\n",
      "New best model found at epoch 32 with validation loss 1.5931458473205566\n",
      "Starting Epoch 33\n",
      "1.659953718600066\n",
      "Validation loss: 1.5908184051513672\n",
      "mse 1.5908184082848982\n",
      "New best model found at epoch 33 with validation loss 1.5908184051513672\n",
      "Starting Epoch 34\n",
      "1.6576479362404866\n",
      "Validation loss: 1.5886520147323608\n",
      "mse 1.5886519818584453\n",
      "New best model found at epoch 34 with validation loss 1.5886520147323608\n",
      "Starting Epoch 35\n",
      "1.6549583362496418\n",
      "Validation loss: 1.5863754749298096\n",
      "mse 1.5863754384146143\n",
      "New best model found at epoch 35 with validation loss 1.5863754749298096\n",
      "Starting Epoch 36\n",
      "1.652548732964889\n",
      "Validation loss: 1.584257960319519\n",
      "mse 1.5842578809064358\n",
      "New best model found at epoch 36 with validation loss 1.584257960319519\n",
      "Starting Epoch 37\n",
      "1.6503400128820669\n",
      "Validation loss: 1.5822371244430542\n",
      "mse 1.5822370559349934\n",
      "New best model found at epoch 37 with validation loss 1.5822371244430542\n",
      "Starting Epoch 38\n",
      "1.6483509903368743\n",
      "Validation loss: 1.5805549621582031\n",
      "mse 1.58055493986039\n",
      "New best model found at epoch 38 with validation loss 1.5805549621582031\n",
      "Starting Epoch 39\n",
      "1.6464151973309724\n",
      "Validation loss: 1.578576922416687\n",
      "mse 1.5785768777402418\n",
      "New best model found at epoch 39 with validation loss 1.578576922416687\n",
      "Starting Epoch 40\n",
      "1.6445451560227766\n",
      "Validation loss: 1.5769810676574707\n",
      "mse 1.5769809853523187\n",
      "New best model found at epoch 40 with validation loss 1.5769810676574707\n",
      "Starting Epoch 41\n",
      "1.642681748970695\n",
      "Validation loss: 1.5749454498291016\n",
      "mse 1.5749454104625908\n",
      "New best model found at epoch 41 with validation loss 1.5749454498291016\n",
      "Starting Epoch 42\n",
      "1.6408865555472996\n",
      "Validation loss: 1.5728890895843506\n",
      "mse 1.5728891028081977\n",
      "New best model found at epoch 42 with validation loss 1.5728890895843506\n",
      "Starting Epoch 43\n",
      "1.639297013697417\n",
      "Validation loss: 1.5709463357925415\n",
      "mse 1.570946258464999\n",
      "New best model found at epoch 43 with validation loss 1.5709463357925415\n",
      "Starting Epoch 44\n",
      "1.637645996135214\n",
      "Validation loss: 1.5693122148513794\n",
      "mse 1.569312209533566\n",
      "New best model found at epoch 44 with validation loss 1.5693122148513794\n",
      "Starting Epoch 45\n",
      "1.6360494313032732\n",
      "Validation loss: 1.5674601793289185\n",
      "mse 1.5674601992668875\n",
      "New best model found at epoch 45 with validation loss 1.5674601793289185\n",
      "Starting Epoch 46\n",
      "1.634517182474551\n",
      "Validation loss: 1.5657933950424194\n",
      "mse 1.5657931981475095\n",
      "New best model found at epoch 46 with validation loss 1.5657933950424194\n",
      "Starting Epoch 47\n",
      "1.6331438448118127\n",
      "Validation loss: 1.5645045042037964\n",
      "mse 1.5645044983491803\n",
      "New best model found at epoch 47 with validation loss 1.5645045042037964\n",
      "Starting Epoch 48\n",
      "1.631786823272705\n",
      "Validation loss: 1.5632001161575317\n",
      "mse 1.5632001012426213\n",
      "New best model found at epoch 48 with validation loss 1.5632001161575317\n",
      "Starting Epoch 49\n",
      "1.6307252127191294\n",
      "Validation loss: 1.5619263648986816\n",
      "mse 1.5619262313928488\n",
      "New best model found at epoch 49 with validation loss 1.5619263648986816\n",
      "Starting Epoch 50\n",
      "1.6293281524077705\n",
      "Validation loss: 1.5609408617019653\n",
      "mse 1.5609409459618915\n",
      "New best model found at epoch 50 with validation loss 1.5609408617019653\n",
      "Starting Epoch 51\n",
      "1.6280989698741748\n",
      "Validation loss: 1.5599757432937622\n",
      "mse 1.559975743237617\n",
      "New best model found at epoch 51 with validation loss 1.5599757432937622\n",
      "Starting Epoch 52\n",
      "1.6269816833993662\n",
      "Validation loss: 1.5588973760604858\n",
      "mse 1.5588973532569048\n",
      "New best model found at epoch 52 with validation loss 1.5588973760604858\n",
      "Starting Epoch 53\n",
      "1.6259292986081995\n",
      "Validation loss: 1.557695746421814\n",
      "mse 1.5576956632693775\n",
      "New best model found at epoch 53 with validation loss 1.557695746421814\n",
      "Starting Epoch 54\n",
      "1.6247762908106265\n",
      "Validation loss: 1.5567561388015747\n",
      "mse 1.556756129640912\n",
      "New best model found at epoch 54 with validation loss 1.5567561388015747\n",
      "Starting Epoch 55\n",
      "1.623758772145147\n",
      "Validation loss: 1.5558971166610718\n",
      "mse 1.5558969977762591\n",
      "New best model found at epoch 55 with validation loss 1.5558971166610718\n",
      "Starting Epoch 56\n",
      "1.6226984573447185\n",
      "Validation loss: 1.55500328540802\n",
      "mse 1.5550032970039953\n",
      "New best model found at epoch 56 with validation loss 1.55500328540802\n",
      "Starting Epoch 57\n",
      "1.6217252249303071\n",
      "Validation loss: 1.554111361503601\n",
      "mse 1.5541114054222505\n",
      "New best model found at epoch 57 with validation loss 1.554111361503601\n",
      "Starting Epoch 58\n",
      "1.6208117733830991\n",
      "Validation loss: 1.5535823106765747\n",
      "mse 1.553582259567771\n",
      "New best model found at epoch 58 with validation loss 1.5535823106765747\n",
      "Starting Epoch 59\n",
      "1.6198873623557712\n",
      "Validation loss: 1.5525883436203003\n",
      "mse 1.552588303482358\n",
      "New best model found at epoch 59 with validation loss 1.5525883436203003\n",
      "Starting Epoch 60\n",
      "1.6190754874892856\n",
      "Validation loss: 1.5518745183944702\n",
      "mse 1.551874417665727\n",
      "New best model found at epoch 60 with validation loss 1.5518745183944702\n",
      "Starting Epoch 61\n",
      "1.6181511334750964\n",
      "Validation loss: 1.5508437156677246\n",
      "mse 1.5508436645053842\n",
      "New best model found at epoch 61 with validation loss 1.5508437156677246\n",
      "Starting Epoch 62\n",
      "1.6172480635021045\n",
      "Validation loss: 1.5500982999801636\n",
      "mse 1.5500982743348506\n",
      "New best model found at epoch 62 with validation loss 1.5500982999801636\n",
      "Starting Epoch 63\n",
      "1.616246547387994\n",
      "Validation loss: 1.5490984916687012\n",
      "mse 1.5490987613605824\n",
      "New best model found at epoch 63 with validation loss 1.5490984916687012\n",
      "Starting Epoch 64\n",
      "1.614915933298028\n",
      "Validation loss: 1.547992467880249\n",
      "mse 1.5479924622262098\n",
      "New best model found at epoch 64 with validation loss 1.547992467880249\n",
      "Starting Epoch 65\n",
      "1.6135854539663896\n",
      "Validation loss: 1.5471594333648682\n",
      "mse 1.5471595179151147\n",
      "New best model found at epoch 65 with validation loss 1.5471594333648682\n",
      "Starting Epoch 66\n",
      "1.6123764437177908\n",
      "Validation loss: 1.5465892553329468\n",
      "mse 1.5465892247229782\n",
      "New best model found at epoch 66 with validation loss 1.5465892553329468\n",
      "Starting Epoch 67\n",
      "1.6114397567251455\n",
      "Validation loss: 1.5461140871047974\n",
      "mse 1.546114117961141\n",
      "New best model found at epoch 67 with validation loss 1.5461140871047974\n",
      "Starting Epoch 68\n",
      "1.610641977061396\n",
      "Validation loss: 1.5456217527389526\n",
      "mse 1.545621751383718\n",
      "New best model found at epoch 68 with validation loss 1.5456217527389526\n",
      "Starting Epoch 69\n",
      "1.6098337328952292\n",
      "Validation loss: 1.5450949668884277\n",
      "mse 1.5450948786918783\n",
      "New best model found at epoch 69 with validation loss 1.5450949668884277\n",
      "Starting Epoch 70\n",
      "1.608972484650819\n",
      "Validation loss: 1.5443843603134155\n",
      "mse 1.5443843132373487\n",
      "New best model found at epoch 70 with validation loss 1.5443843603134155\n",
      "Starting Epoch 71\n",
      "1.6082299507182578\n",
      "Validation loss: 1.5438135862350464\n",
      "mse 1.5438137003004744\n",
      "New best model found at epoch 71 with validation loss 1.5438135862350464\n",
      "Starting Epoch 72\n",
      "1.6074541807174683\n",
      "Validation loss: 1.5431944131851196\n",
      "mse 1.5431944587695745\n",
      "New best model found at epoch 72 with validation loss 1.5431944131851196\n",
      "Starting Epoch 73\n",
      "1.606701521769814\n",
      "Validation loss: 1.5425522327423096\n",
      "mse 1.5425520808067477\n",
      "New best model found at epoch 73 with validation loss 1.5425522327423096\n",
      "Starting Epoch 74\n",
      "1.6059673091639644\n",
      "Validation loss: 1.5420470237731934\n",
      "mse 1.5420469421857652\n",
      "New best model found at epoch 74 with validation loss 1.5420470237731934\n",
      "Starting Epoch 75\n",
      "1.605306995951611\n",
      "Validation loss: 1.5412532091140747\n",
      "mse 1.5412531743892364\n",
      "New best model found at epoch 75 with validation loss 1.5412532091140747\n",
      "Starting Epoch 76\n",
      "1.6046387164489082\n",
      "Validation loss: 1.5406944751739502\n",
      "mse 1.5406944426680607\n",
      "New best model found at epoch 76 with validation loss 1.5406944751739502\n",
      "Starting Epoch 77\n",
      "1.6040282197620557\n",
      "Validation loss: 1.5402286052703857\n",
      "mse 1.5402284054656092\n",
      "New best model found at epoch 77 with validation loss 1.5402286052703857\n",
      "Starting Epoch 78\n",
      "1.6032298285028208\n",
      "Validation loss: 1.539685606956482\n",
      "mse 1.5396854837258434\n",
      "New best model found at epoch 78 with validation loss 1.539685606956482\n",
      "Starting Epoch 79\n",
      "1.6026446534239727\n",
      "Validation loss: 1.5392131805419922\n",
      "mse 1.5392132967499004\n",
      "New best model found at epoch 79 with validation loss 1.5392131805419922\n",
      "Starting Epoch 80\n",
      "1.6018641876137776\n",
      "Validation loss: 1.5387680530548096\n",
      "mse 1.538768140154562\n",
      "New best model found at epoch 80 with validation loss 1.5387680530548096\n",
      "Starting Epoch 81\n",
      "1.6013388115426768\n",
      "Validation loss: 1.5382282733917236\n",
      "mse 1.5382282449028384\n",
      "New best model found at epoch 81 with validation loss 1.5382282733917236\n",
      "Starting Epoch 82\n",
      "1.6007546030956765\n",
      "Validation loss: 1.5373904705047607\n",
      "mse 1.5373904788524773\n",
      "New best model found at epoch 82 with validation loss 1.5373904705047607\n",
      "Starting Epoch 83\n",
      "1.5985463287519373\n",
      "Validation loss: 1.5343154668807983\n",
      "mse 1.5343155930026353\n",
      "New best model found at epoch 83 with validation loss 1.5343154668807983\n",
      "Starting Epoch 84\n",
      "1.595542257246764\n",
      "Validation loss: 1.5330570936203003\n",
      "mse 1.5330570745778636\n",
      "New best model found at epoch 84 with validation loss 1.5330570936203003\n",
      "Starting Epoch 85\n",
      "1.5921593982240427\n",
      "Validation loss: 1.5304170846939087\n",
      "mse 1.530417000134488\n",
      "New best model found at epoch 85 with validation loss 1.5304170846939087\n",
      "Starting Epoch 86\n",
      "1.5877317242000415\n",
      "Validation loss: 1.5266880989074707\n",
      "mse 1.5266879660576336\n",
      "New best model found at epoch 86 with validation loss 1.5266880989074707\n",
      "Starting Epoch 87\n",
      "1.5857842331347258\n",
      "Validation loss: 1.5252461433410645\n",
      "mse 1.525246225164804\n",
      "New best model found at epoch 87 with validation loss 1.5252461433410645\n",
      "Starting Epoch 88\n",
      "1.584567049275274\n",
      "Validation loss: 1.5252131223678589\n",
      "mse 1.5252131957403898\n",
      "New best model found at epoch 88 with validation loss 1.5252131223678589\n",
      "Starting Epoch 89\n",
      "1.5834962310998335\n",
      "Validation loss: 1.5248985290527344\n",
      "mse 1.5248985003009883\n",
      "New best model found at epoch 89 with validation loss 1.5248985290527344\n",
      "Starting Epoch 90\n",
      "1.582442820072174\n",
      "Validation loss: 1.5245087146759033\n",
      "mse 1.5245088418875834\n",
      "New best model found at epoch 90 with validation loss 1.5245087146759033\n",
      "Starting Epoch 91\n",
      "1.581341414347939\n",
      "Validation loss: 1.5244184732437134\n",
      "mse 1.5244183794355413\n",
      "New best model found at epoch 91 with validation loss 1.5244184732437134\n",
      "Starting Epoch 92\n",
      "1.580338796843653\n",
      "Validation loss: 1.524030089378357\n",
      "mse 1.524030183123976\n",
      "New best model found at epoch 92 with validation loss 1.524030089378357\n",
      "Starting Epoch 93\n",
      "1.5792623110439465\n",
      "Validation loss: 1.5236676931381226\n",
      "mse 1.523667659549918\n",
      "New best model found at epoch 93 with validation loss 1.5236676931381226\n",
      "Starting Epoch 94\n",
      "1.5782111287117004\n",
      "Validation loss: 1.5235378742218018\n",
      "mse 1.5235378925543124\n",
      "New best model found at epoch 94 with validation loss 1.5235378742218018\n",
      "Starting Epoch 95\n",
      "1.577150767264159\n",
      "Validation loss: 1.522821068763733\n",
      "mse 1.5228209277042377\n",
      "New best model found at epoch 95 with validation loss 1.522821068763733\n",
      "Starting Epoch 96\n",
      "1.5762334595555845\n",
      "Validation loss: 1.5226362943649292\n",
      "mse 1.5226362646039178\n",
      "New best model found at epoch 96 with validation loss 1.5226362943649292\n",
      "Starting Epoch 97\n",
      "1.575167205022729\n",
      "Validation loss: 1.5221612453460693\n",
      "mse 1.5221611634298278\n",
      "New best model found at epoch 97 with validation loss 1.5221612453460693\n",
      "Starting Epoch 98\n",
      "1.5743103701135386\n",
      "Validation loss: 1.52169668674469\n",
      "mse 1.5216967363855711\n",
      "New best model found at epoch 98 with validation loss 1.52169668674469\n",
      "Starting Epoch 99\n",
      "1.5733622753101846\n",
      "Validation loss: 1.521225929260254\n",
      "mse 1.5212260896397916\n",
      "New best model found at epoch 99 with validation loss 1.521225929260254\n",
      "Starting Epoch 100\n",
      "1.5724115838175234\n",
      "Validation loss: 1.520825982093811\n",
      "mse 1.5208260657132096\n",
      "New best model found at epoch 100 with validation loss 1.520825982093811\n",
      "Starting Epoch 101\n",
      "1.5714259821435679\n",
      "Validation loss: 1.520322561264038\n",
      "mse 1.5203227015787557\n",
      "New best model found at epoch 101 with validation loss 1.520322561264038\n",
      "Starting Epoch 102\n",
      "1.5704848921817283\n",
      "Validation loss: 1.5197409391403198\n",
      "mse 1.5197408750384653\n",
      "New best model found at epoch 102 with validation loss 1.5197409391403198\n",
      "Starting Epoch 103\n",
      "1.5695189574490422\n",
      "Validation loss: 1.5193030834197998\n",
      "mse 1.519303118711568\n",
      "New best model found at epoch 103 with validation loss 1.5193030834197998\n",
      "Starting Epoch 104\n",
      "1.5686167193495708\n",
      "Validation loss: 1.5187748670578003\n",
      "mse 1.5187748849028566\n",
      "New best model found at epoch 104 with validation loss 1.5187748670578003\n",
      "Starting Epoch 105\n",
      "1.567797355029894\n",
      "Validation loss: 1.5183168649673462\n",
      "mse 1.5183168779233105\n",
      "New best model found at epoch 105 with validation loss 1.5183168649673462\n",
      "Starting Epoch 106\n",
      "1.5668784924175427\n",
      "Validation loss: 1.5179082155227661\n",
      "mse 1.5179081500416933\n",
      "New best model found at epoch 106 with validation loss 1.5179082155227661\n",
      "Starting Epoch 107\n",
      "1.5659900229910146\n",
      "Validation loss: 1.517369031906128\n",
      "mse 1.5173689415120233\n",
      "New best model found at epoch 107 with validation loss 1.517369031906128\n",
      "Starting Epoch 108\n",
      "1.5650985370511594\n",
      "Validation loss: 1.5168585777282715\n",
      "mse 1.5168586325288822\n",
      "New best model found at epoch 108 with validation loss 1.5168585777282715\n",
      "Starting Epoch 109\n",
      "1.5642268009807752\n",
      "Validation loss: 1.5163979530334473\n",
      "mse 1.5163980474571745\n",
      "New best model found at epoch 109 with validation loss 1.5163979530334473\n",
      "Starting Epoch 110\n",
      "1.5634405301964802\n",
      "Validation loss: 1.5158321857452393\n",
      "mse 1.5158322226911543\n",
      "New best model found at epoch 110 with validation loss 1.5158321857452393\n",
      "Starting Epoch 111\n",
      "1.5625185137209685\n",
      "Validation loss: 1.5154212713241577\n",
      "mse 1.5154213559196856\n",
      "New best model found at epoch 111 with validation loss 1.5154212713241577\n",
      "Starting Epoch 112\n",
      "1.5617870843928794\n",
      "Validation loss: 1.5149651765823364\n",
      "mse 1.5149651089597986\n",
      "New best model found at epoch 112 with validation loss 1.5149651765823364\n",
      "Starting Epoch 113\n",
      "1.5609633844831716\n",
      "Validation loss: 1.5146266222000122\n",
      "mse 1.514626553125149\n",
      "New best model found at epoch 113 with validation loss 1.5146266222000122\n",
      "Starting Epoch 114\n",
      "1.5600536621135215\n",
      "Validation loss: 1.5142040252685547\n",
      "mse 1.514203890573948\n",
      "New best model found at epoch 114 with validation loss 1.5142040252685547\n",
      "Starting Epoch 115\n",
      "1.5593267394148784\n",
      "Validation loss: 1.5140578746795654\n",
      "mse 1.514057943659666\n",
      "New best model found at epoch 115 with validation loss 1.5140578746795654\n",
      "Starting Epoch 116\n",
      "1.558424535004989\n",
      "Validation loss: 1.5136886835098267\n",
      "mse 1.51368854459595\n",
      "New best model found at epoch 116 with validation loss 1.5136886835098267\n",
      "Starting Epoch 117\n",
      "1.557744562625885\n",
      "Validation loss: 1.5134739875793457\n",
      "mse 1.5134739119211815\n",
      "New best model found at epoch 117 with validation loss 1.5134739875793457\n",
      "Starting Epoch 118\n",
      "1.5570087458776392\n",
      "Validation loss: 1.5130469799041748\n",
      "mse 1.5130469176139456\n",
      "New best model found at epoch 118 with validation loss 1.5130469799041748\n",
      "Starting Epoch 119\n",
      "1.5561888425246528\n",
      "Validation loss: 1.5126031637191772\n",
      "mse 1.5126031915647202\n",
      "New best model found at epoch 119 with validation loss 1.5126031637191772\n",
      "Starting Epoch 120\n",
      "1.5554988176926323\n",
      "Validation loss: 1.5123897790908813\n",
      "mse 1.5123897418388519\n",
      "New best model found at epoch 120 with validation loss 1.5123897790908813\n",
      "Starting Epoch 121\n",
      "1.5547585591025974\n",
      "Validation loss: 1.5118860006332397\n",
      "mse 1.511886021497497\n",
      "New best model found at epoch 121 with validation loss 1.5118860006332397\n",
      "Starting Epoch 122\n",
      "1.5541104492933855\n",
      "Validation loss: 1.5116660594940186\n",
      "mse 1.5116659740249208\n",
      "New best model found at epoch 122 with validation loss 1.5116660594940186\n",
      "Starting Epoch 123\n",
      "1.5532150916431262\n",
      "Validation loss: 1.5113909244537354\n",
      "mse 1.511390926262365\n",
      "New best model found at epoch 123 with validation loss 1.5113909244537354\n",
      "Starting Epoch 124\n",
      "1.5526255680167156\n",
      "Validation loss: 1.5109277963638306\n",
      "mse 1.5109276451865359\n",
      "New best model found at epoch 124 with validation loss 1.5109277963638306\n",
      "Starting Epoch 125\n",
      "1.551813488421233\n",
      "Validation loss: 1.5107650756835938\n",
      "mse 1.510765123428179\n",
      "New best model found at epoch 125 with validation loss 1.5107650756835938\n",
      "Starting Epoch 126\n",
      "1.5510961154232854\n",
      "Validation loss: 1.510302186012268\n",
      "mse 1.5103024137894996\n",
      "New best model found at epoch 126 with validation loss 1.510302186012268\n",
      "Starting Epoch 127\n",
      "1.5504531212474988\n",
      "Validation loss: 1.5100815296173096\n",
      "mse 1.5100816133393111\n",
      "New best model found at epoch 127 with validation loss 1.5100815296173096\n",
      "Starting Epoch 128\n",
      "1.5497196705445\n",
      "Validation loss: 1.5097092390060425\n",
      "mse 1.5097092055565589\n",
      "New best model found at epoch 128 with validation loss 1.5097092390060425\n",
      "Starting Epoch 129\n",
      "1.5489923357963562\n",
      "Validation loss: 1.5094820261001587\n",
      "mse 1.5094819055310573\n",
      "New best model found at epoch 129 with validation loss 1.5094820261001587\n",
      "Starting Epoch 130\n",
      "1.5483160096666087\n",
      "Validation loss: 1.5090916156768799\n",
      "mse 1.5090916044023532\n",
      "New best model found at epoch 130 with validation loss 1.5090916156768799\n",
      "Starting Epoch 131\n",
      "1.5476105031759844\n",
      "Validation loss: 1.5088508129119873\n",
      "mse 1.5088508332621913\n",
      "New best model found at epoch 131 with validation loss 1.5088508129119873\n",
      "Starting Epoch 132\n",
      "1.546979668347732\n",
      "Validation loss: 1.5083640813827515\n",
      "mse 1.5083640560857996\n",
      "New best model found at epoch 132 with validation loss 1.5083640813827515\n",
      "Starting Epoch 133\n",
      "1.5461949654247449\n",
      "Validation loss: 1.5080451965332031\n",
      "mse 1.5080453044040751\n",
      "New best model found at epoch 133 with validation loss 1.5080451965332031\n",
      "Starting Epoch 134\n",
      "1.5455901674602344\n",
      "Validation loss: 1.5074406862258911\n",
      "mse 1.5074406794923167\n",
      "New best model found at epoch 134 with validation loss 1.5074406862258911\n",
      "Starting Epoch 135\n",
      "1.544838602128236\n",
      "Validation loss: 1.5066471099853516\n",
      "mse 1.506647187993469\n",
      "New best model found at epoch 135 with validation loss 1.5066471099853516\n",
      "Starting Epoch 136\n",
      "1.5441231416619343\n",
      "Validation loss: 1.506439447402954\n",
      "mse 1.5064393230116777\n",
      "New best model found at epoch 136 with validation loss 1.506439447402954\n",
      "Starting Epoch 137\n",
      "1.5431894478590593\n",
      "Validation loss: 1.505573034286499\n",
      "mse 1.5055731679517612\n",
      "New best model found at epoch 137 with validation loss 1.505573034286499\n",
      "Starting Epoch 138\n",
      "1.5420860000278638\n",
      "Validation loss: 1.50447678565979\n",
      "mse 1.504476764871015\n",
      "New best model found at epoch 138 with validation loss 1.50447678565979\n",
      "Starting Epoch 139\n",
      "1.540709023890288\n",
      "Validation loss: 1.503809928894043\n",
      "mse 1.5038099363926936\n",
      "New best model found at epoch 139 with validation loss 1.503809928894043\n",
      "Starting Epoch 140\n",
      "1.539284939351289\n",
      "Validation loss: 1.5027695894241333\n",
      "mse 1.5027696528745007\n",
      "New best model found at epoch 140 with validation loss 1.5027695894241333\n",
      "Starting Epoch 141\n",
      "1.5377001840135325\n",
      "Validation loss: 1.5021060705184937\n",
      "mse 1.502105982039229\n",
      "New best model found at epoch 141 with validation loss 1.5021060705184937\n",
      "Starting Epoch 142\n",
      "1.5365991203681282\n",
      "Validation loss: 1.5016931295394897\n",
      "mse 1.5016930122651695\n",
      "New best model found at epoch 142 with validation loss 1.5016931295394897\n",
      "Starting Epoch 143\n",
      "1.535724199336508\n",
      "Validation loss: 1.5015109777450562\n",
      "mse 1.5015109496466295\n",
      "New best model found at epoch 143 with validation loss 1.5015109777450562\n",
      "Starting Epoch 144\n",
      "1.5350400701813076\n",
      "Validation loss: 1.5013878345489502\n",
      "mse 1.5013878626533042\n",
      "New best model found at epoch 144 with validation loss 1.5013878345489502\n",
      "Starting Epoch 145\n",
      "1.534357216047204\n",
      "Validation loss: 1.5012364387512207\n",
      "mse 1.501236348080742\n",
      "New best model found at epoch 145 with validation loss 1.5012364387512207\n",
      "Starting Epoch 146\n",
      "1.5336795708407527\n",
      "Validation loss: 1.5008771419525146\n",
      "mse 1.5008771337918243\n",
      "New best model found at epoch 146 with validation loss 1.5008771419525146\n",
      "Starting Epoch 147\n",
      "1.5330239974934121\n",
      "Validation loss: 1.5002310276031494\n",
      "mse 1.5002309937965759\n",
      "New best model found at epoch 147 with validation loss 1.5002310276031494\n",
      "Starting Epoch 148\n",
      "1.532367037690204\n",
      "Validation loss: 1.4998703002929688\n",
      "mse 1.4998703795159045\n",
      "New best model found at epoch 148 with validation loss 1.4998703002929688\n",
      "Starting Epoch 149\n",
      "1.5316458733185478\n",
      "Validation loss: 1.4994852542877197\n",
      "mse 1.4994853062302436\n",
      "New best model found at epoch 149 with validation loss 1.4994852542877197\n",
      "Starting Epoch 150\n",
      "1.5309624905171602\n",
      "Validation loss: 1.4992738962173462\n",
      "mse 1.4992737927322561\n",
      "New best model found at epoch 150 with validation loss 1.4992738962173462\n",
      "Starting Epoch 151\n",
      "1.5303516698920208\n",
      "Validation loss: 1.4984817504882812\n",
      "mse 1.49848176344301\n",
      "New best model found at epoch 151 with validation loss 1.4984817504882812\n",
      "Starting Epoch 152\n",
      "1.5296813171842825\n",
      "Validation loss: 1.498232364654541\n",
      "mse 1.498232362857373\n",
      "New best model found at epoch 152 with validation loss 1.498232364654541\n",
      "Starting Epoch 153\n",
      "1.528922894726629\n",
      "Validation loss: 1.4976683855056763\n",
      "mse 1.4976683635217922\n",
      "New best model found at epoch 153 with validation loss 1.4976683855056763\n",
      "Starting Epoch 154\n",
      "1.5282048531200574\n",
      "Validation loss: 1.4973177909851074\n",
      "mse 1.4973177250301253\n",
      "New best model found at epoch 154 with validation loss 1.4973177909851074\n",
      "Starting Epoch 155\n",
      "1.527433973291646\n",
      "Validation loss: 1.4965226650238037\n",
      "mse 1.496522734352137\n",
      "New best model found at epoch 155 with validation loss 1.4965226650238037\n",
      "Starting Epoch 156\n",
      "1.5267806804698447\n",
      "Validation loss: 1.4959681034088135\n",
      "mse 1.4959680929128525\n",
      "New best model found at epoch 156 with validation loss 1.4959681034088135\n",
      "Starting Epoch 157\n",
      "1.5259572345277537\n",
      "Validation loss: 1.495619773864746\n",
      "mse 1.4956195989248813\n",
      "New best model found at epoch 157 with validation loss 1.495619773864746\n",
      "Starting Epoch 158\n",
      "1.5253536027410757\n",
      "Validation loss: 1.4947174787521362\n",
      "mse 1.4947173405362062\n",
      "New best model found at epoch 158 with validation loss 1.4947174787521362\n",
      "Starting Epoch 159\n",
      "1.5245047237562097\n",
      "Validation loss: 1.4944316148757935\n",
      "mse 1.4944316067194194\n",
      "New best model found at epoch 159 with validation loss 1.4944316148757935\n",
      "Starting Epoch 160\n",
      "1.5239213964213496\n",
      "Validation loss: 1.493778944015503\n",
      "mse 1.4937789844834222\n",
      "New best model found at epoch 160 with validation loss 1.493778944015503\n",
      "Starting Epoch 161\n",
      "1.5233042888019397\n",
      "Validation loss: 1.4935044050216675\n",
      "mse 1.4935044647495346\n",
      "New best model found at epoch 161 with validation loss 1.4935044050216675\n",
      "Starting Epoch 162\n",
      "1.522535448488982\n",
      "Validation loss: 1.4931864738464355\n",
      "mse 1.493186422536983\n",
      "New best model found at epoch 162 with validation loss 1.4931864738464355\n",
      "Starting Epoch 163\n",
      "1.5220508834590083\n",
      "Validation loss: 1.4923895597457886\n",
      "mse 1.492389711695423\n",
      "New best model found at epoch 163 with validation loss 1.4923895597457886\n",
      "Starting Epoch 164\n",
      "1.5212440464807593\n",
      "Validation loss: 1.4922338724136353\n",
      "mse 1.4922339650440481\n",
      "New best model found at epoch 164 with validation loss 1.4922338724136353\n",
      "Starting Epoch 165\n",
      "1.5207684065984644\n",
      "Validation loss: 1.4916481971740723\n",
      "mse 1.4916482229647352\n",
      "New best model found at epoch 165 with validation loss 1.4916481971740723\n",
      "Starting Epoch 166\n",
      "1.5201011922048486\n",
      "Validation loss: 1.4909701347351074\n",
      "mse 1.490970084356723\n",
      "New best model found at epoch 166 with validation loss 1.4909701347351074\n",
      "Starting Epoch 167\n",
      "1.5194676907166191\n",
      "Validation loss: 1.4905418157577515\n",
      "mse 1.490541707459524\n",
      "New best model found at epoch 167 with validation loss 1.4905418157577515\n",
      "Starting Epoch 168\n",
      "1.5189444526382114\n",
      "Validation loss: 1.4897832870483398\n",
      "mse 1.489783391508202\n",
      "New best model found at epoch 168 with validation loss 1.4897832870483398\n",
      "Starting Epoch 169\n",
      "1.5181993090588113\n",
      "Validation loss: 1.4896601438522339\n",
      "mse 1.4896601594291978\n",
      "New best model found at epoch 169 with validation loss 1.4896601438522339\n",
      "Starting Epoch 170\n",
      "1.5176009121148482\n",
      "Validation loss: 1.4894123077392578\n",
      "mse 1.4894122908897252\n",
      "New best model found at epoch 170 with validation loss 1.4894123077392578\n",
      "Starting Epoch 171\n",
      "1.5170595153518345\n",
      "Validation loss: 1.4890018701553345\n",
      "mse 1.4890018541947778\n",
      "New best model found at epoch 171 with validation loss 1.4890018701553345\n",
      "Starting Epoch 172\n",
      "1.5164397851280544\n",
      "Validation loss: 1.48858642578125\n",
      "mse 1.488586487624463\n",
      "New best model found at epoch 172 with validation loss 1.48858642578125\n",
      "Starting Epoch 173\n",
      "1.5158251601716746\n",
      "Validation loss: 1.4880671501159668\n",
      "mse 1.488067111176099\n",
      "New best model found at epoch 173 with validation loss 1.4880671501159668\n",
      "Starting Epoch 174\n",
      "1.5152973195780879\n",
      "Validation loss: 1.4874483346939087\n",
      "mse 1.4874484127158236\n",
      "New best model found at epoch 174 with validation loss 1.4874483346939087\n",
      "Starting Epoch 175\n",
      "1.51462176312571\n",
      "Validation loss: 1.486284852027893\n",
      "mse 1.4862846822697175\n",
      "New best model found at epoch 175 with validation loss 1.486284852027893\n",
      "Starting Epoch 176\n",
      "1.514042986475903\n",
      "Validation loss: 1.485355257987976\n",
      "mse 1.4853552819009324\n",
      "New best model found at epoch 176 with validation loss 1.485355257987976\n",
      "Starting Epoch 177\n",
      "1.5132553421932717\n",
      "Validation loss: 1.4848487377166748\n",
      "mse 1.4848486329283876\n",
      "New best model found at epoch 177 with validation loss 1.4848487377166748\n",
      "Starting Epoch 178\n",
      "1.5126435549362847\n",
      "Validation loss: 1.4842476844787598\n",
      "mse 1.4842476673277276\n",
      "New best model found at epoch 178 with validation loss 1.4842476844787598\n",
      "Starting Epoch 179\n",
      "1.512022078037262\n",
      "Validation loss: 1.4830968379974365\n",
      "mse 1.483096973243711\n",
      "New best model found at epoch 179 with validation loss 1.4830968379974365\n",
      "Starting Epoch 180\n",
      "1.5113538555476977\n",
      "Validation loss: 1.482655644416809\n",
      "mse 1.4826557118540031\n",
      "New best model found at epoch 180 with validation loss 1.482655644416809\n",
      "Starting Epoch 181\n",
      "1.5107686545537866\n",
      "Validation loss: 1.481540560722351\n",
      "mse 1.4815406784065892\n",
      "New best model found at epoch 181 with validation loss 1.481540560722351\n",
      "Starting Epoch 182\n",
      "1.5100777797077014\n",
      "Validation loss: 1.4810453653335571\n",
      "mse 1.4810453604523741\n",
      "New best model found at epoch 182 with validation loss 1.4810453653335571\n",
      "Starting Epoch 183\n",
      "1.509493166985719\n",
      "Validation loss: 1.4804656505584717\n",
      "mse 1.480465507206914\n",
      "New best model found at epoch 183 with validation loss 1.4804656505584717\n",
      "Starting Epoch 184\n",
      "1.5088311070981233\n",
      "Validation loss: 1.4799898862838745\n",
      "mse 1.4799898165907368\n",
      "New best model found at epoch 184 with validation loss 1.4799898862838745\n",
      "Starting Epoch 185\n",
      "1.50823401109032\n",
      "Validation loss: 1.479648470878601\n",
      "mse 1.4796485702677855\n",
      "New best model found at epoch 185 with validation loss 1.479648470878601\n",
      "Starting Epoch 186\n",
      "1.5076968125675037\n",
      "Validation loss: 1.4790217876434326\n",
      "mse 1.4790217987454506\n",
      "New best model found at epoch 186 with validation loss 1.4790217876434326\n",
      "Starting Epoch 187\n",
      "1.507014256456624\n",
      "Validation loss: 1.4786041975021362\n",
      "mse 1.4786040450608369\n",
      "New best model found at epoch 187 with validation loss 1.4786041975021362\n",
      "Starting Epoch 188\n",
      "1.5064001731250598\n",
      "Validation loss: 1.4780491590499878\n",
      "mse 1.478049142102615\n",
      "New best model found at epoch 188 with validation loss 1.4780491590499878\n",
      "Starting Epoch 189\n",
      "1.505762421566507\n",
      "Validation loss: 1.4777714014053345\n",
      "mse 1.4777713025540868\n",
      "New best model found at epoch 189 with validation loss 1.4777714014053345\n",
      "Starting Epoch 190\n",
      "1.5052271044772605\n",
      "Validation loss: 1.4771418571472168\n",
      "mse 1.477141646177121\n",
      "New best model found at epoch 190 with validation loss 1.4771418571472168\n",
      "Starting Epoch 191\n",
      "1.5045626344888106\n",
      "Validation loss: 1.4767934083938599\n",
      "mse 1.4767934700480498\n",
      "New best model found at epoch 191 with validation loss 1.4767934083938599\n",
      "Starting Epoch 192\n",
      "1.5039939180664395\n",
      "Validation loss: 1.476304292678833\n",
      "mse 1.476304367621836\n",
      "New best model found at epoch 192 with validation loss 1.476304292678833\n",
      "Starting Epoch 193\n",
      "1.5033669057099714\n",
      "Validation loss: 1.475789189338684\n",
      "mse 1.4757891862101133\n",
      "New best model found at epoch 193 with validation loss 1.475789189338684\n",
      "Starting Epoch 194\n",
      "1.5028006719506306\n",
      "Validation loss: 1.4755624532699585\n",
      "mse 1.4755624178871753\n",
      "New best model found at epoch 194 with validation loss 1.4755624532699585\n",
      "Starting Epoch 195\n",
      "1.502172508965368\n",
      "Validation loss: 1.4751228094100952\n",
      "mse 1.4751227798304787\n",
      "New best model found at epoch 195 with validation loss 1.4751228094100952\n",
      "Starting Epoch 196\n",
      "1.5016442174496858\n",
      "Validation loss: 1.4745659828186035\n",
      "mse 1.4745660249840875\n",
      "New best model found at epoch 196 with validation loss 1.4745659828186035\n",
      "Starting Epoch 197\n",
      "1.5009954364403435\n",
      "Validation loss: 1.474331259727478\n",
      "mse 1.474331396123162\n",
      "New best model found at epoch 197 with validation loss 1.474331259727478\n",
      "Starting Epoch 198\n",
      "1.5003959873448247\n",
      "Validation loss: 1.473691463470459\n",
      "mse 1.4736914581755973\n",
      "New best model found at epoch 198 with validation loss 1.473691463470459\n",
      "Starting Epoch 199\n",
      "1.4998207066370093\n",
      "Validation loss: 1.473390817642212\n",
      "mse 1.4733909849874\n",
      "New best model found at epoch 199 with validation loss 1.473390817642212\n",
      "Starting Epoch 200\n",
      "1.4991622593091882\n",
      "Validation loss: 1.4730056524276733\n",
      "mse 1.4730057297944081\n",
      "New best model found at epoch 200 with validation loss 1.4730056524276733\n",
      "Starting Epoch 201\n",
      "1.4986881665561511\n",
      "Validation loss: 1.4728434085845947\n",
      "mse 1.472843414347229\n",
      "New best model found at epoch 201 with validation loss 1.4728434085845947\n",
      "Starting Epoch 202\n",
      "1.498052646284518\n",
      "Validation loss: 1.4723542928695679\n",
      "mse 1.4723542786636439\n",
      "New best model found at epoch 202 with validation loss 1.4723542928695679\n",
      "Starting Epoch 203\n",
      "1.4974684870761374\n",
      "Validation loss: 1.4719029664993286\n",
      "mse 1.4719029358793545\n",
      "New best model found at epoch 203 with validation loss 1.4719029664993286\n",
      "Starting Epoch 204\n",
      "1.4969513416290283\n",
      "Validation loss: 1.4714851379394531\n",
      "mse 1.4714850852617343\n",
      "New best model found at epoch 204 with validation loss 1.4714851379394531\n",
      "Starting Epoch 205\n",
      "1.4963310879209768\n",
      "Validation loss: 1.471170425415039\n",
      "mse 1.4711704000794172\n",
      "New best model found at epoch 205 with validation loss 1.471170425415039\n",
      "Starting Epoch 206\n",
      "1.495822592921879\n",
      "Validation loss: 1.4706761837005615\n",
      "mse 1.470675994488077\n",
      "New best model found at epoch 206 with validation loss 1.4706761837005615\n",
      "Starting Epoch 207\n",
      "1.4951892546985461\n",
      "Validation loss: 1.4703137874603271\n",
      "mse 1.470313957088946\n",
      "New best model found at epoch 207 with validation loss 1.4703137874603271\n",
      "Starting Epoch 208\n",
      "1.494715822779614\n",
      "Validation loss: 1.4697753190994263\n",
      "mse 1.4697753982847104\n",
      "New best model found at epoch 208 with validation loss 1.4697753190994263\n",
      "Starting Epoch 209\n",
      "1.494071970815244\n",
      "Validation loss: 1.4694383144378662\n",
      "mse 1.4694383520041592\n",
      "New best model found at epoch 209 with validation loss 1.4694383144378662\n",
      "Starting Epoch 210\n",
      "1.4936031025388967\n",
      "Validation loss: 1.4691672325134277\n",
      "mse 1.469167250894686\n",
      "New best model found at epoch 210 with validation loss 1.4691672325134277\n",
      "Starting Epoch 211\n",
      "1.4929921938025432\n",
      "Validation loss: 1.4685558080673218\n",
      "mse 1.4685558823692555\n",
      "New best model found at epoch 211 with validation loss 1.4685558080673218\n",
      "Starting Epoch 212\n",
      "1.4924685747727104\n",
      "Validation loss: 1.4681674242019653\n",
      "mse 1.46816740302107\n",
      "New best model found at epoch 212 with validation loss 1.4681674242019653\n",
      "Starting Epoch 213\n",
      "1.4918940093206323\n",
      "Validation loss: 1.4679571390151978\n",
      "mse 1.4679572261316038\n",
      "New best model found at epoch 213 with validation loss 1.4679571390151978\n",
      "Starting Epoch 214\n",
      "1.491358404574187\n",
      "Validation loss: 1.467344880104065\n",
      "mse 1.4673448863008896\n",
      "New best model found at epoch 214 with validation loss 1.467344880104065\n",
      "Starting Epoch 215\n",
      "1.490726631620656\n",
      "Validation loss: 1.4675312042236328\n",
      "mse 1.4675310845393947\n",
      "Starting Epoch 216\n",
      "1.4903251917465874\n",
      "Validation loss: 1.4669108390808105\n",
      "mse 1.4669108352530145\n",
      "New best model found at epoch 216 with validation loss 1.4669108390808105\n",
      "Starting Epoch 217\n",
      "1.4896690249443054\n",
      "Validation loss: 1.4662251472473145\n",
      "mse 1.466224995167833\n",
      "New best model found at epoch 217 with validation loss 1.4662251472473145\n",
      "Starting Epoch 218\n",
      "1.4891019308048745\n",
      "Validation loss: 1.466299057006836\n",
      "mse 1.4662990651321333\n",
      "Starting Epoch 219\n",
      "1.4885751086732615\n",
      "Validation loss: 1.4655191898345947\n",
      "mse 1.4655192164076436\n",
      "New best model found at epoch 219 with validation loss 1.4655191898345947\n",
      "Starting Epoch 220\n",
      "1.4879545802655427\n",
      "Validation loss: 1.4655139446258545\n",
      "mse 1.4655139341570484\n",
      "New best model found at epoch 220 with validation loss 1.4655139446258545\n",
      "Starting Epoch 221\n",
      "1.4874880080637725\n",
      "Validation loss: 1.4646815061569214\n",
      "mse 1.4646813890353514\n",
      "New best model found at epoch 221 with validation loss 1.4646815061569214\n",
      "Starting Epoch 222\n",
      "1.486772814522619\n",
      "Validation loss: 1.464954137802124\n",
      "mse 1.4649542870885364\n",
      "Starting Epoch 223\n",
      "1.486334246137868\n",
      "Validation loss: 1.4638503789901733\n",
      "mse 1.463850571509015\n",
      "New best model found at epoch 223 with validation loss 1.4638503789901733\n",
      "Starting Epoch 224\n",
      "1.4857232648393381\n",
      "Validation loss: 1.4638233184814453\n",
      "mse 1.4638232394751947\n",
      "New best model found at epoch 224 with validation loss 1.4638233184814453\n",
      "Starting Epoch 225\n",
      "1.4851746170417122\n",
      "Validation loss: 1.4635597467422485\n",
      "mse 1.463559823426429\n",
      "New best model found at epoch 225 with validation loss 1.4635597467422485\n",
      "Starting Epoch 226\n",
      "1.484726864358653\n",
      "Validation loss: 1.4628411531448364\n",
      "mse 1.4628411537024872\n",
      "New best model found at epoch 226 with validation loss 1.4628411531448364\n",
      "Starting Epoch 227\n",
      "1.4840752767479939\n",
      "Validation loss: 1.4628729820251465\n",
      "mse 1.4628730597885113\n",
      "Starting Epoch 228\n",
      "1.4834622377934663\n",
      "Validation loss: 1.462621808052063\n",
      "mse 1.4626218556883077\n",
      "New best model found at epoch 228 with validation loss 1.462621808052063\n",
      "Starting Epoch 229\n",
      "1.4831026766611182\n",
      "Validation loss: 1.4616159200668335\n",
      "mse 1.4616158489236566\n",
      "New best model found at epoch 229 with validation loss 1.4616159200668335\n",
      "Starting Epoch 230\n",
      "1.4824663452480151\n",
      "Validation loss: 1.461673617362976\n",
      "mse 1.461673673202003\n",
      "Starting Epoch 231\n",
      "1.4819489302842512\n",
      "Validation loss: 1.4613982439041138\n",
      "mse 1.4613982914460146\n",
      "New best model found at epoch 231 with validation loss 1.4613982439041138\n",
      "Starting Epoch 232\n",
      "1.4813918834147246\n",
      "Validation loss: 1.4610567092895508\n",
      "mse 1.4610566761163446\n",
      "New best model found at epoch 232 with validation loss 1.4610567092895508\n",
      "Starting Epoch 233\n",
      "1.4808084342790686\n",
      "Validation loss: 1.460834264755249\n",
      "mse 1.460834396421304\n",
      "New best model found at epoch 233 with validation loss 1.460834264755249\n",
      "Starting Epoch 234\n",
      "1.4804066652837007\n",
      "Validation loss: 1.460150122642517\n",
      "mse 1.46015009285306\n",
      "New best model found at epoch 234 with validation loss 1.460150122642517\n",
      "Starting Epoch 235\n",
      "1.479812230752862\n",
      "Validation loss: 1.4595844745635986\n",
      "mse 1.4595845691056666\n",
      "New best model found at epoch 235 with validation loss 1.4595844745635986\n",
      "Starting Epoch 236\n",
      "1.4792933386305105\n",
      "Validation loss: 1.4590526819229126\n",
      "mse 1.459052634660653\n",
      "New best model found at epoch 236 with validation loss 1.4590526819229126\n",
      "Starting Epoch 237\n",
      "1.478691427604012\n",
      "Validation loss: 1.4586045742034912\n",
      "mse 1.458604591512771\n",
      "New best model found at epoch 237 with validation loss 1.4586045742034912\n",
      "Starting Epoch 238\n",
      "1.4781489424083545\n",
      "Validation loss: 1.4579437971115112\n",
      "mse 1.4579438348376377\n",
      "New best model found at epoch 238 with validation loss 1.4579437971115112\n",
      "Starting Epoch 239\n",
      "1.477665486543075\n",
      "Validation loss: 1.4574525356292725\n",
      "mse 1.457452543955449\n",
      "New best model found at epoch 239 with validation loss 1.4574525356292725\n",
      "Starting Epoch 240\n",
      "1.4771138766537542\n",
      "Validation loss: 1.4565775394439697\n",
      "mse 1.4565776169928473\n",
      "New best model found at epoch 240 with validation loss 1.4565775394439697\n",
      "Starting Epoch 241\n",
      "1.476478882457899\n",
      "Validation loss: 1.4561660289764404\n",
      "mse 1.4561660258122384\n",
      "New best model found at epoch 241 with validation loss 1.4561660289764404\n",
      "Starting Epoch 242\n",
      "1.4758839451748391\n",
      "Validation loss: 1.4557602405548096\n",
      "mse 1.4557603245258703\n",
      "New best model found at epoch 242 with validation loss 1.4557602405548096\n",
      "Starting Epoch 243\n",
      "1.4754377188889876\n",
      "Validation loss: 1.455301284790039\n",
      "mse 1.4553012922272113\n",
      "New best model found at epoch 243 with validation loss 1.455301284790039\n",
      "Starting Epoch 244\n",
      "1.474836906661158\n",
      "Validation loss: 1.4542666673660278\n",
      "mse 1.4542666788025955\n",
      "New best model found at epoch 244 with validation loss 1.4542666673660278\n",
      "Starting Epoch 245\n",
      "1.4742558468943057\n",
      "Validation loss: 1.4540655612945557\n",
      "mse 1.4540656017062945\n",
      "New best model found at epoch 245 with validation loss 1.4540655612945557\n",
      "Starting Epoch 246\n",
      "1.473687187485073\n",
      "Validation loss: 1.4535558223724365\n",
      "mse 1.4535559699957743\n",
      "New best model found at epoch 246 with validation loss 1.4535558223724365\n",
      "Starting Epoch 247\n",
      "1.473160849965137\n",
      "Validation loss: 1.4531331062316895\n",
      "mse 1.4531331994860033\n",
      "New best model found at epoch 247 with validation loss 1.4531331062316895\n",
      "Starting Epoch 248\n",
      "1.4726229517356209\n",
      "Validation loss: 1.4525105953216553\n",
      "mse 1.4525106150610363\n",
      "New best model found at epoch 248 with validation loss 1.4525105953216553\n",
      "Starting Epoch 249\n",
      "1.4720024725665217\n",
      "Validation loss: 1.4521520137786865\n",
      "mse 1.452151882668312\n",
      "New best model found at epoch 249 with validation loss 1.4521520137786865\n",
      "Starting Epoch 250\n",
      "1.4715421018393144\n",
      "Validation loss: 1.451490044593811\n",
      "mse 1.451490006912866\n",
      "New best model found at epoch 250 with validation loss 1.451490044593811\n",
      "Starting Epoch 251\n",
      "1.470889977786852\n",
      "Validation loss: 1.4510972499847412\n",
      "mse 1.451097298875542\n",
      "New best model found at epoch 251 with validation loss 1.4510972499847412\n",
      "Starting Epoch 252\n",
      "1.4705285429954529\n",
      "Validation loss: 1.450368046760559\n",
      "mse 1.4503679750536842\n",
      "New best model found at epoch 252 with validation loss 1.450368046760559\n",
      "Starting Epoch 253\n",
      "1.469787957875625\n",
      "Validation loss: 1.4500187635421753\n",
      "mse 1.4500189557320018\n",
      "New best model found at epoch 253 with validation loss 1.4500187635421753\n",
      "Starting Epoch 254\n",
      "1.4692804657894631\n",
      "Validation loss: 1.449305534362793\n",
      "mse 1.449305506954017\n",
      "New best model found at epoch 254 with validation loss 1.449305534362793\n",
      "Starting Epoch 255\n",
      "1.4687059573505237\n",
      "Validation loss: 1.4489198923110962\n",
      "mse 1.4489199178714185\n",
      "New best model found at epoch 255 with validation loss 1.4489198923110962\n",
      "Starting Epoch 256\n",
      "1.4681992945463762\n",
      "Validation loss: 1.4483916759490967\n",
      "mse 1.4483917046325978\n",
      "New best model found at epoch 256 with validation loss 1.4483916759490967\n",
      "Starting Epoch 257\n",
      "1.4676283468370852\n",
      "Validation loss: 1.4480891227722168\n",
      "mse 1.4480889938616195\n",
      "New best model found at epoch 257 with validation loss 1.4480891227722168\n",
      "Starting Epoch 258\n",
      "1.4671066947605298\n",
      "Validation loss: 1.447731852531433\n",
      "mse 1.4477317763026034\n",
      "New best model found at epoch 258 with validation loss 1.447731852531433\n",
      "Starting Epoch 259\n",
      "1.466685370258663\n",
      "Validation loss: 1.4472482204437256\n",
      "mse 1.447248317078263\n",
      "New best model found at epoch 259 with validation loss 1.4472482204437256\n",
      "Starting Epoch 260\n",
      "1.4660824770512788\n",
      "Validation loss: 1.4471023082733154\n",
      "mse 1.4471023988704332\n",
      "New best model found at epoch 260 with validation loss 1.4471023082733154\n",
      "Starting Epoch 261\n",
      "1.4656331280003423\n",
      "Validation loss: 1.4465429782867432\n",
      "mse 1.4465429653432573\n",
      "New best model found at epoch 261 with validation loss 1.4465429782867432\n",
      "Starting Epoch 262\n",
      "1.4650071781614553\n",
      "Validation loss: 1.446280598640442\n",
      "mse 1.446280764405635\n",
      "New best model found at epoch 262 with validation loss 1.446280598640442\n",
      "Starting Epoch 263\n",
      "1.4644245505332947\n",
      "Validation loss: 1.4456799030303955\n",
      "mse 1.4456799612446105\n",
      "New best model found at epoch 263 with validation loss 1.4456799030303955\n",
      "Starting Epoch 264\n",
      "1.4638438535773235\n",
      "Validation loss: 1.4452946186065674\n",
      "mse 1.4452946178199209\n",
      "New best model found at epoch 264 with validation loss 1.4452946186065674\n",
      "Starting Epoch 265\n",
      "1.4632843292277793\n",
      "Validation loss: 1.4449093341827393\n",
      "mse 1.4449093721438293\n",
      "New best model found at epoch 265 with validation loss 1.4449093341827393\n",
      "Starting Epoch 266\n",
      "1.462484561878702\n",
      "Validation loss: 1.444470763206482\n",
      "mse 1.4444708624973142\n",
      "New best model found at epoch 266 with validation loss 1.444470763206482\n",
      "Starting Epoch 267\n",
      "1.4618179564890654\n",
      "Validation loss: 1.4441072940826416\n",
      "mse 1.444107390745505\n",
      "New best model found at epoch 267 with validation loss 1.4441072940826416\n",
      "Starting Epoch 268\n",
      "1.461241294508395\n",
      "Validation loss: 1.4436707496643066\n",
      "mse 1.4436706908105583\n",
      "New best model found at epoch 268 with validation loss 1.4436707496643066\n",
      "Starting Epoch 269\n",
      "1.4606442321901736\n",
      "Validation loss: 1.4432346820831299\n",
      "mse 1.443234621494694\n",
      "New best model found at epoch 269 with validation loss 1.4432346820831299\n",
      "Starting Epoch 270\n",
      "1.460166265135226\n",
      "Validation loss: 1.442899227142334\n",
      "mse 1.4428993288970124\n",
      "New best model found at epoch 270 with validation loss 1.442899227142334\n",
      "Starting Epoch 271\n",
      "1.4595793874367424\n",
      "Validation loss: 1.4426777362823486\n",
      "mse 1.442677742338172\n",
      "New best model found at epoch 271 with validation loss 1.4426777362823486\n",
      "Starting Epoch 272\n",
      "1.4590592099272686\n",
      "Validation loss: 1.4420599937438965\n",
      "mse 1.4420600751710653\n",
      "New best model found at epoch 272 with validation loss 1.4420599937438965\n",
      "Starting Epoch 273\n",
      "1.458583987277487\n",
      "Validation loss: 1.441698670387268\n",
      "mse 1.441698668693838\n",
      "New best model found at epoch 273 with validation loss 1.441698670387268\n",
      "Starting Epoch 274\n",
      "1.4579433876535166\n",
      "Validation loss: 1.4415007829666138\n",
      "mse 1.441500697483742\n",
      "New best model found at epoch 274 with validation loss 1.4415007829666138\n",
      "Starting Epoch 275\n",
      "1.4574992164321567\n",
      "Validation loss: 1.4409489631652832\n",
      "mse 1.4409491110197035\n",
      "New best model found at epoch 275 with validation loss 1.4409489631652832\n",
      "Starting Epoch 276\n",
      "1.4569274213003076\n",
      "Validation loss: 1.4405401945114136\n",
      "mse 1.4405402423510598\n",
      "New best model found at epoch 276 with validation loss 1.4405401945114136\n",
      "Starting Epoch 277\n",
      "1.4564854580423106\n",
      "Validation loss: 1.4402652978897095\n",
      "mse 1.440265286572851\n",
      "New best model found at epoch 277 with validation loss 1.4402652978897095\n",
      "Starting Epoch 278\n",
      "1.4559706190358037\n",
      "Validation loss: 1.4399874210357666\n",
      "mse 1.4399874041932774\n",
      "New best model found at epoch 278 with validation loss 1.4399874210357666\n",
      "Starting Epoch 279\n",
      "1.4554250240325928\n",
      "Validation loss: 1.439587950706482\n",
      "mse 1.4395879469274477\n",
      "New best model found at epoch 279 with validation loss 1.439587950706482\n",
      "Starting Epoch 280\n",
      "1.4549819179203198\n",
      "Validation loss: 1.4391140937805176\n",
      "mse 1.4391141030591785\n",
      "New best model found at epoch 280 with validation loss 1.4391140937805176\n",
      "Starting Epoch 281\n",
      "1.4544173504995264\n",
      "Validation loss: 1.4388340711593628\n",
      "mse 1.4388340773894366\n",
      "New best model found at epoch 281 with validation loss 1.4388340711593628\n",
      "Starting Epoch 282\n",
      "1.4539693257083064\n",
      "Validation loss: 1.4384926557540894\n",
      "mse 1.4384926250638572\n",
      "New best model found at epoch 282 with validation loss 1.4384926557540894\n",
      "Starting Epoch 283\n",
      "1.4535432224688323\n",
      "Validation loss: 1.4379819631576538\n",
      "mse 1.4379820522021793\n",
      "New best model found at epoch 283 with validation loss 1.4379819631576538\n",
      "Starting Epoch 284\n",
      "1.453012632287067\n",
      "Validation loss: 1.4377416372299194\n",
      "mse 1.4377416109706582\n",
      "New best model found at epoch 284 with validation loss 1.4377416372299194\n",
      "Starting Epoch 285\n",
      "1.4524788726931033\n",
      "Validation loss: 1.4372071027755737\n",
      "mse 1.437207183138392\n",
      "New best model found at epoch 285 with validation loss 1.4372071027755737\n",
      "Starting Epoch 286\n",
      "1.4520116370657217\n",
      "Validation loss: 1.4366580247879028\n",
      "mse 1.4366579924011387\n",
      "New best model found at epoch 286 with validation loss 1.4366580247879028\n",
      "Starting Epoch 287\n",
      "1.451529816440914\n",
      "Validation loss: 1.4364402294158936\n",
      "mse 1.4364401700702984\n",
      "New best model found at epoch 287 with validation loss 1.4364402294158936\n",
      "Starting Epoch 288\n",
      "1.4510113648746326\n",
      "Validation loss: 1.435815453529358\n",
      "mse 1.4358153234352062\n",
      "New best model found at epoch 288 with validation loss 1.435815453529358\n",
      "Starting Epoch 289\n",
      "1.4505772720212522\n",
      "Validation loss: 1.435501217842102\n",
      "mse 1.4355012135769893\n",
      "New best model found at epoch 289 with validation loss 1.435501217842102\n",
      "Starting Epoch 290\n",
      "1.4500486151031826\n",
      "Validation loss: 1.4351283311843872\n",
      "mse 1.4351282929787013\n",
      "New best model found at epoch 290 with validation loss 1.4351283311843872\n",
      "Starting Epoch 291\n",
      "1.449545391227888\n",
      "Validation loss: 1.4345831871032715\n",
      "mse 1.4345831660867414\n",
      "New best model found at epoch 291 with validation loss 1.4345831871032715\n",
      "Starting Epoch 292\n",
      "1.4490705754445947\n",
      "Validation loss: 1.4342695474624634\n",
      "mse 1.4342694782687766\n",
      "New best model found at epoch 292 with validation loss 1.4342695474624634\n",
      "Starting Epoch 293\n",
      "1.4486263705336528\n",
      "Validation loss: 1.4338762760162354\n",
      "mse 1.4338763439712248\n",
      "New best model found at epoch 293 with validation loss 1.4338762760162354\n",
      "Starting Epoch 294\n",
      "1.4480792413587156\n",
      "Validation loss: 1.4333964586257935\n",
      "mse 1.4333963606268108\n",
      "New best model found at epoch 294 with validation loss 1.4333964586257935\n",
      "Starting Epoch 295\n",
      "1.4476315690123516\n",
      "Validation loss: 1.4329116344451904\n",
      "mse 1.4329114112993244\n",
      "New best model found at epoch 295 with validation loss 1.4329116344451904\n",
      "Starting Epoch 296\n",
      "1.4471212495928225\n",
      "Validation loss: 1.4326939582824707\n",
      "mse 1.4326940842043832\n",
      "New best model found at epoch 296 with validation loss 1.4326939582824707\n",
      "Starting Epoch 297\n",
      "1.4466198164483774\n",
      "Validation loss: 1.4323501586914062\n",
      "mse 1.4323501171462576\n",
      "New best model found at epoch 297 with validation loss 1.4323501586914062\n",
      "Starting Epoch 298\n",
      "1.446100089860999\n",
      "Validation loss: 1.4318667650222778\n",
      "mse 1.4318665964922557\n",
      "New best model found at epoch 298 with validation loss 1.4318667650222778\n",
      "Starting Epoch 299\n",
      "1.445600302323051\n",
      "Validation loss: 1.4316869974136353\n",
      "mse 1.4316870682844878\n",
      "New best model found at epoch 299 with validation loss 1.4316869974136353\n",
      "Starting Epoch 300\n",
      "1.445114887279013\n",
      "Validation loss: 1.4310230016708374\n",
      "mse 1.4310230490511695\n",
      "New best model found at epoch 300 with validation loss 1.4310230016708374\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-median: 7-60-40-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b278b7",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 60 - 40 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "1afd1a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "d63f6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,7,13]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,7,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "0d637fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'mean(container counts)', 'mean(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "ba2e7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "8a02cc2c-039c-4b0c-a142-bdd9b4541fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.1544028261433477\n",
      "Validation loss: 2.5153324604034424\n",
      "mse 2.515332187857157\n",
      "New best model found at epoch 1 with validation loss 2.5153324604034424\n",
      "Starting Epoch 2\n",
      "2.6316891960475757\n",
      "Validation loss: 2.2497730255126953\n",
      "mse 2.249773058967127\n",
      "New best model found at epoch 2 with validation loss 2.2497730255126953\n",
      "Starting Epoch 3\n",
      "2.3558148249335913\n",
      "Validation loss: 2.0526742935180664\n",
      "mse 2.0526743360100217\n",
      "New best model found at epoch 3 with validation loss 2.0526742935180664\n",
      "Starting Epoch 4\n",
      "2.172580387281335\n",
      "Validation loss: 1.9303889274597168\n",
      "mse 1.930388903813841\n",
      "New best model found at epoch 4 with validation loss 1.9303889274597168\n",
      "Starting Epoch 5\n",
      "2.050890160643536\n",
      "Validation loss: 1.8522522449493408\n",
      "mse 1.852252277930881\n",
      "New best model found at epoch 5 with validation loss 1.8522522449493408\n",
      "Starting Epoch 6\n",
      "1.9693049140598462\n",
      "Validation loss: 1.8003311157226562\n",
      "mse 1.8003310801545545\n",
      "New best model found at epoch 6 with validation loss 1.8003311157226562\n",
      "Starting Epoch 7\n",
      "1.9104026970656023\n",
      "Validation loss: 1.764380931854248\n",
      "mse 1.7643809523309748\n",
      "New best model found at epoch 7 with validation loss 1.764380931854248\n",
      "Starting Epoch 8\n",
      "1.8688790642696878\n",
      "Validation loss: 1.738110065460205\n",
      "mse 1.7381102630234557\n",
      "New best model found at epoch 8 with validation loss 1.738110065460205\n",
      "Starting Epoch 9\n",
      "1.8378041464349497\n",
      "Validation loss: 1.7195510864257812\n",
      "mse 1.7195510536596361\n",
      "New best model found at epoch 9 with validation loss 1.7195510864257812\n",
      "Starting Epoch 10\n",
      "1.8128065907436868\n",
      "Validation loss: 1.7045142650604248\n",
      "mse 1.7045143112302972\n",
      "New best model found at epoch 10 with validation loss 1.7045142650604248\n",
      "Starting Epoch 11\n",
      "1.7932238993437395\n",
      "Validation loss: 1.6907657384872437\n",
      "mse 1.6907658302316166\n",
      "New best model found at epoch 11 with validation loss 1.6907657384872437\n",
      "Starting Epoch 12\n",
      "1.7763890598131262\n",
      "Validation loss: 1.6795638799667358\n",
      "mse 1.6795640500556948\n",
      "New best model found at epoch 12 with validation loss 1.6795638799667358\n",
      "Starting Epoch 13\n",
      "1.7618260953737341\n",
      "Validation loss: 1.6693555116653442\n",
      "mse 1.6693554737139429\n",
      "New best model found at epoch 13 with validation loss 1.6693555116653442\n",
      "Starting Epoch 14\n",
      "1.748326783594878\n",
      "Validation loss: 1.6575058698654175\n",
      "mse 1.6575060001086943\n",
      "New best model found at epoch 14 with validation loss 1.6575058698654175\n",
      "Starting Epoch 15\n",
      "1.7373429847800212\n",
      "Validation loss: 1.6493024826049805\n",
      "mse 1.6493024765012596\n",
      "New best model found at epoch 15 with validation loss 1.6493024826049805\n",
      "Starting Epoch 16\n",
      "1.727593095406242\n",
      "Validation loss: 1.6419322490692139\n",
      "mse 1.6419320829092106\n",
      "New best model found at epoch 16 with validation loss 1.6419322490692139\n",
      "Starting Epoch 17\n",
      "1.7188635701718538\n",
      "Validation loss: 1.6352816820144653\n",
      "mse 1.6352816910058852\n",
      "New best model found at epoch 17 with validation loss 1.6352816820144653\n",
      "Starting Epoch 18\n",
      "1.7110491472741831\n",
      "Validation loss: 1.6289271116256714\n",
      "mse 1.628927116131279\n",
      "New best model found at epoch 18 with validation loss 1.6289271116256714\n",
      "Starting Epoch 19\n",
      "1.7039211677468342\n",
      "Validation loss: 1.6225448846817017\n",
      "mse 1.6225448661957422\n",
      "New best model found at epoch 19 with validation loss 1.6225448846817017\n",
      "Starting Epoch 20\n",
      "1.6971085641695105\n",
      "Validation loss: 1.6167337894439697\n",
      "mse 1.6167338800564521\n",
      "New best model found at epoch 20 with validation loss 1.6167337894439697\n",
      "Starting Epoch 21\n",
      "1.690861676050269\n",
      "Validation loss: 1.6113961935043335\n",
      "mse 1.611396272261221\n",
      "New best model found at epoch 21 with validation loss 1.6113961935043335\n",
      "Starting Epoch 22\n",
      "1.6852499816728674\n",
      "Validation loss: 1.6065460443496704\n",
      "mse 1.6065461975554156\n",
      "New best model found at epoch 22 with validation loss 1.6065460443496704\n",
      "Starting Epoch 23\n",
      "1.6801905061887659\n",
      "Validation loss: 1.601852297782898\n",
      "mse 1.6018523445832893\n",
      "New best model found at epoch 23 with validation loss 1.601852297782898\n",
      "Starting Epoch 24\n",
      "1.675350697144218\n",
      "Validation loss: 1.5977764129638672\n",
      "mse 1.5977763582863513\n",
      "New best model found at epoch 24 with validation loss 1.5977764129638672\n",
      "Starting Epoch 25\n",
      "1.6708627058112102\n",
      "Validation loss: 1.5942535400390625\n",
      "mse 1.5942535827820037\n",
      "New best model found at epoch 25 with validation loss 1.5942535400390625\n",
      "Starting Epoch 26\n",
      "1.6664040192313816\n",
      "Validation loss: 1.5902099609375\n",
      "mse 1.5902099557019163\n",
      "New best model found at epoch 26 with validation loss 1.5902099609375\n",
      "Starting Epoch 27\n",
      "1.662283736726512\n",
      "Validation loss: 1.5864338874816895\n",
      "mse 1.5864339335802646\n",
      "New best model found at epoch 27 with validation loss 1.5864338874816895\n",
      "Starting Epoch 28\n",
      "1.6583186491675999\n",
      "Validation loss: 1.5827248096466064\n",
      "mse 1.5827247827613817\n",
      "New best model found at epoch 28 with validation loss 1.5827248096466064\n",
      "Starting Epoch 29\n",
      "1.6544181937756746\n",
      "Validation loss: 1.5785551071166992\n",
      "mse 1.5785550813560454\n",
      "New best model found at epoch 29 with validation loss 1.5785551071166992\n",
      "Starting Epoch 30\n",
      "1.6506579077762107\n",
      "Validation loss: 1.5741101503372192\n",
      "mse 1.5741100041850546\n",
      "New best model found at epoch 30 with validation loss 1.5741101503372192\n",
      "Starting Epoch 31\n",
      "1.6467681967693826\n",
      "Validation loss: 1.5710785388946533\n",
      "mse 1.571078564050232\n",
      "New best model found at epoch 31 with validation loss 1.5710785388946533\n",
      "Starting Epoch 32\n",
      "1.6431894561518794\n",
      "Validation loss: 1.5676132440567017\n",
      "mse 1.5676133271173818\n",
      "New best model found at epoch 32 with validation loss 1.5676132440567017\n",
      "Starting Epoch 33\n",
      "1.6399437033611795\n",
      "Validation loss: 1.5647900104522705\n",
      "mse 1.5647898676832455\n",
      "New best model found at epoch 33 with validation loss 1.5647900104522705\n",
      "Starting Epoch 34\n",
      "1.6370268230852874\n",
      "Validation loss: 1.56271231174469\n",
      "mse 1.5627122904134583\n",
      "New best model found at epoch 34 with validation loss 1.56271231174469\n",
      "Starting Epoch 35\n",
      "1.6343511135681816\n",
      "Validation loss: 1.5605790615081787\n",
      "mse 1.5605791164656753\n",
      "New best model found at epoch 35 with validation loss 1.5605790615081787\n",
      "Starting Epoch 36\n",
      "1.631703687750775\n",
      "Validation loss: 1.5585607290267944\n",
      "mse 1.5585608029522036\n",
      "New best model found at epoch 36 with validation loss 1.5585607290267944\n",
      "Starting Epoch 37\n",
      "1.6292932551840078\n",
      "Validation loss: 1.556330680847168\n",
      "mse 1.5563306510433943\n",
      "New best model found at epoch 37 with validation loss 1.556330680847168\n",
      "Starting Epoch 38\n",
      "1.6268763283024663\n",
      "Validation loss: 1.5544452667236328\n",
      "mse 1.5544452426660287\n",
      "New best model found at epoch 38 with validation loss 1.5544452667236328\n",
      "Starting Epoch 39\n",
      "1.624597580536552\n",
      "Validation loss: 1.5521713495254517\n",
      "mse 1.5521713820091043\n",
      "New best model found at epoch 39 with validation loss 1.5521713495254517\n",
      "Starting Epoch 40\n",
      "1.6222825620485388\n",
      "Validation loss: 1.5502277612686157\n",
      "mse 1.550227718357956\n",
      "New best model found at epoch 40 with validation loss 1.5502277612686157\n",
      "Starting Epoch 41\n",
      "1.6201508045196533\n",
      "Validation loss: 1.5488907098770142\n",
      "mse 1.5488907384610069\n",
      "New best model found at epoch 41 with validation loss 1.5488907098770142\n",
      "Starting Epoch 42\n",
      "1.6182065839352815\n",
      "Validation loss: 1.547080159187317\n",
      "mse 1.5470802107701676\n",
      "New best model found at epoch 42 with validation loss 1.547080159187317\n",
      "Starting Epoch 43\n",
      "1.6161605897157088\n",
      "Validation loss: 1.5453437566757202\n",
      "mse 1.5453437671561372\n",
      "New best model found at epoch 43 with validation loss 1.5453437566757202\n",
      "Starting Epoch 44\n",
      "1.614199425863183\n",
      "Validation loss: 1.5440534353256226\n",
      "mse 1.5440534183781047\n",
      "New best model found at epoch 44 with validation loss 1.5440534353256226\n",
      "Starting Epoch 45\n",
      "1.6123805357062297\n",
      "Validation loss: 1.5424308776855469\n",
      "mse 1.5424308105840263\n",
      "New best model found at epoch 45 with validation loss 1.5424308776855469\n",
      "Starting Epoch 46\n",
      "1.6105431862499402\n",
      "Validation loss: 1.5410634279251099\n",
      "mse 1.5410632298053553\n",
      "New best model found at epoch 46 with validation loss 1.5410634279251099\n",
      "Starting Epoch 47\n",
      "1.6087427398432856\n",
      "Validation loss: 1.539513349533081\n",
      "mse 1.5395133586298582\n",
      "New best model found at epoch 47 with validation loss 1.539513349533081\n",
      "Starting Epoch 48\n",
      "1.6071978211402893\n",
      "Validation loss: 1.5378347635269165\n",
      "mse 1.5378345542621192\n",
      "New best model found at epoch 48 with validation loss 1.5378347635269165\n",
      "Starting Epoch 49\n",
      "1.6056050813716392\n",
      "Validation loss: 1.5366014242172241\n",
      "mse 1.5366016112233363\n",
      "New best model found at epoch 49 with validation loss 1.5366014242172241\n",
      "Starting Epoch 50\n",
      "1.6040148320405379\n",
      "Validation loss: 1.535225749015808\n",
      "mse 1.5352256922906828\n",
      "New best model found at epoch 50 with validation loss 1.535225749015808\n",
      "Starting Epoch 51\n",
      "1.6024809350138125\n",
      "Validation loss: 1.5341435670852661\n",
      "mse 1.5341434737057775\n",
      "New best model found at epoch 51 with validation loss 1.5341435670852661\n",
      "Starting Epoch 52\n",
      "1.6010326665380727\n",
      "Validation loss: 1.533031702041626\n",
      "mse 1.5330316529042527\n",
      "New best model found at epoch 52 with validation loss 1.533031702041626\n",
      "Starting Epoch 53\n",
      "1.5995187681654226\n",
      "Validation loss: 1.5319931507110596\n",
      "mse 1.531993129065596\n",
      "New best model found at epoch 53 with validation loss 1.5319931507110596\n",
      "Starting Epoch 54\n",
      "1.5981845104176065\n",
      "Validation loss: 1.530866265296936\n",
      "mse 1.5308662594609757\n",
      "New best model found at epoch 54 with validation loss 1.530866265296936\n",
      "Starting Epoch 55\n",
      "1.596740204354991\n",
      "Validation loss: 1.5298694372177124\n",
      "mse 1.529869461959995\n",
      "New best model found at epoch 55 with validation loss 1.5298694372177124\n",
      "Starting Epoch 56\n",
      "1.5953805550285007\n",
      "Validation loss: 1.528747320175171\n",
      "mse 1.5287473933368776\n",
      "New best model found at epoch 56 with validation loss 1.528747320175171\n",
      "Starting Epoch 57\n",
      "1.5939910049023835\n",
      "Validation loss: 1.5278196334838867\n",
      "mse 1.5278196999237206\n",
      "New best model found at epoch 57 with validation loss 1.5278196334838867\n",
      "Starting Epoch 58\n",
      "1.5927683037260305\n",
      "Validation loss: 1.5266793966293335\n",
      "mse 1.5266793569487198\n",
      "New best model found at epoch 58 with validation loss 1.5266793966293335\n",
      "Starting Epoch 59\n",
      "1.5914620135141455\n",
      "Validation loss: 1.5256973505020142\n",
      "mse 1.5256974102400136\n",
      "New best model found at epoch 59 with validation loss 1.5256973505020142\n",
      "Starting Epoch 60\n",
      "1.5902219933012258\n",
      "Validation loss: 1.5247300863265991\n",
      "mse 1.5247302122734956\n",
      "New best model found at epoch 60 with validation loss 1.5247300863265991\n",
      "Starting Epoch 61\n",
      "1.5891063524329143\n",
      "Validation loss: 1.5239228010177612\n",
      "mse 1.5239227003580085\n",
      "New best model found at epoch 61 with validation loss 1.5239228010177612\n",
      "Starting Epoch 62\n",
      "1.5879623034726018\n",
      "Validation loss: 1.5228406190872192\n",
      "mse 1.52284055192821\n",
      "New best model found at epoch 62 with validation loss 1.5228406190872192\n",
      "Starting Epoch 63\n",
      "1.5868600244107454\n",
      "Validation loss: 1.5221737623214722\n",
      "mse 1.5221737440843919\n",
      "New best model found at epoch 63 with validation loss 1.5221737623214722\n",
      "Starting Epoch 64\n",
      "1.5858252100322558\n",
      "Validation loss: 1.5211291313171387\n",
      "mse 1.521129129295163\n",
      "New best model found at epoch 64 with validation loss 1.5211291313171387\n",
      "Starting Epoch 65\n",
      "1.584723747294882\n",
      "Validation loss: 1.5204256772994995\n",
      "mse 1.5204255657856964\n",
      "New best model found at epoch 65 with validation loss 1.5204256772994995\n",
      "Starting Epoch 66\n",
      "1.5836800647818523\n",
      "Validation loss: 1.5193536281585693\n",
      "mse 1.5193533967580726\n",
      "New best model found at epoch 66 with validation loss 1.5193536281585693\n",
      "Starting Epoch 67\n",
      "1.582763874012491\n",
      "Validation loss: 1.5186796188354492\n",
      "mse 1.518679705159981\n",
      "New best model found at epoch 67 with validation loss 1.5186796188354492\n",
      "Starting Epoch 68\n",
      "1.5817086152408435\n",
      "Validation loss: 1.5177314281463623\n",
      "mse 1.5177313849016614\n",
      "New best model found at epoch 68 with validation loss 1.5177314281463623\n",
      "Starting Epoch 69\n",
      "1.5808689231457917\n",
      "Validation loss: 1.5167220830917358\n",
      "mse 1.516721924653419\n",
      "New best model found at epoch 69 with validation loss 1.5167220830917358\n",
      "Starting Epoch 70\n",
      "1.579788169135218\n",
      "Validation loss: 1.5159549713134766\n",
      "mse 1.5159548640334968\n",
      "New best model found at epoch 70 with validation loss 1.5159549713134766\n",
      "Starting Epoch 71\n",
      "1.57850523357806\n",
      "Validation loss: 1.5146290063858032\n",
      "mse 1.5146289346197928\n",
      "New best model found at epoch 71 with validation loss 1.5146290063858032\n",
      "Starting Epoch 72\n",
      "1.5770008589910425\n",
      "Validation loss: 1.513278841972351\n",
      "mse 1.5132786906923426\n",
      "New best model found at epoch 72 with validation loss 1.513278841972351\n",
      "Starting Epoch 73\n",
      "1.5753252972727236\n",
      "Validation loss: 1.5126467943191528\n",
      "mse 1.5126467312144032\n",
      "New best model found at epoch 73 with validation loss 1.5126467943191528\n",
      "Starting Epoch 74\n",
      "1.5741684514543284\n",
      "Validation loss: 1.5125415325164795\n",
      "mse 1.512541516388975\n",
      "New best model found at epoch 74 with validation loss 1.5125415325164795\n",
      "Starting Epoch 75\n",
      "1.5732223287872646\n",
      "Validation loss: 1.511828899383545\n",
      "mse 1.5118288186105635\n",
      "New best model found at epoch 75 with validation loss 1.511828899383545\n",
      "Starting Epoch 76\n",
      "1.5723473740660625\n",
      "Validation loss: 1.5110045671463013\n",
      "mse 1.511004674933086\n",
      "New best model found at epoch 76 with validation loss 1.5110045671463013\n",
      "Starting Epoch 77\n",
      "1.5713995150897815\n",
      "Validation loss: 1.510443925857544\n",
      "mse 1.5104439996180528\n",
      "New best model found at epoch 77 with validation loss 1.510443925857544\n",
      "Starting Epoch 78\n",
      "1.5705398321151733\n",
      "Validation loss: 1.5100470781326294\n",
      "mse 1.5100471180164043\n",
      "New best model found at epoch 78 with validation loss 1.5100470781326294\n",
      "Starting Epoch 79\n",
      "1.5695430040359497\n",
      "Validation loss: 1.5095634460449219\n",
      "mse 1.509563429115867\n",
      "New best model found at epoch 79 with validation loss 1.5095634460449219\n",
      "Starting Epoch 80\n",
      "1.5687726451003032\n",
      "Validation loss: 1.5089805126190186\n",
      "mse 1.5089804759370318\n",
      "New best model found at epoch 80 with validation loss 1.5089805126190186\n",
      "Starting Epoch 81\n",
      "1.5679674874181333\n",
      "Validation loss: 1.5085045099258423\n",
      "mse 1.508504461395533\n",
      "New best model found at epoch 81 with validation loss 1.5085045099258423\n",
      "Starting Epoch 82\n",
      "1.5671064672262773\n",
      "Validation loss: 1.507988452911377\n",
      "mse 1.5079885295217583\n",
      "New best model found at epoch 82 with validation loss 1.507988452911377\n",
      "Starting Epoch 83\n",
      "1.5663575892863066\n",
      "Validation loss: 1.5071429014205933\n",
      "mse 1.5071428620916885\n",
      "New best model found at epoch 83 with validation loss 1.5071429014205933\n",
      "Starting Epoch 84\n",
      "1.5654481053352356\n",
      "Validation loss: 1.5065985918045044\n",
      "mse 1.5065986549771753\n",
      "New best model found at epoch 84 with validation loss 1.5065985918045044\n",
      "Starting Epoch 85\n",
      "1.564700766750004\n",
      "Validation loss: 1.5061758756637573\n",
      "mse 1.5061758167899715\n",
      "New best model found at epoch 85 with validation loss 1.5061758756637573\n",
      "Starting Epoch 86\n",
      "1.5639638615691143\n",
      "Validation loss: 1.5057693719863892\n",
      "mse 1.5057694447371253\n",
      "New best model found at epoch 86 with validation loss 1.5057693719863892\n",
      "Starting Epoch 87\n",
      "1.5631518027056819\n",
      "Validation loss: 1.505234956741333\n",
      "mse 1.5052349048315787\n",
      "New best model found at epoch 87 with validation loss 1.505234956741333\n",
      "Starting Epoch 88\n",
      "1.5623513822970183\n",
      "Validation loss: 1.5047314167022705\n",
      "mse 1.5047313744604671\n",
      "New best model found at epoch 88 with validation loss 1.5047314167022705\n",
      "Starting Epoch 89\n",
      "1.5616100767384404\n",
      "Validation loss: 1.5041624307632446\n",
      "mse 1.5041625185866054\n",
      "New best model found at epoch 89 with validation loss 1.5041624307632446\n",
      "Starting Epoch 90\n",
      "1.560788473357325\n",
      "Validation loss: 1.503605604171753\n",
      "mse 1.5036055606889562\n",
      "New best model found at epoch 90 with validation loss 1.503605604171753\n",
      "Starting Epoch 91\n",
      "1.5602266088775967\n",
      "Validation loss: 1.5030994415283203\n",
      "mse 1.5030995833246625\n",
      "New best model found at epoch 91 with validation loss 1.5030994415283203\n",
      "Starting Epoch 92\n",
      "1.5592346502387004\n",
      "Validation loss: 1.5026460886001587\n",
      "mse 1.502645982160256\n",
      "New best model found at epoch 92 with validation loss 1.5026460886001587\n",
      "Starting Epoch 93\n",
      "1.5584857152855915\n",
      "Validation loss: 1.5022038221359253\n",
      "mse 1.5022037962559647\n",
      "New best model found at epoch 93 with validation loss 1.5022038221359253\n",
      "Starting Epoch 94\n",
      "1.5577898181003074\n",
      "Validation loss: 1.501323938369751\n",
      "mse 1.5013240297873203\n",
      "New best model found at epoch 94 with validation loss 1.501323938369751\n",
      "Starting Epoch 95\n",
      "1.5570769491402998\n",
      "Validation loss: 1.5004074573516846\n",
      "mse 1.5004076362964411\n",
      "New best model found at epoch 95 with validation loss 1.5004074573516846\n",
      "Starting Epoch 96\n",
      "1.5559385107911152\n",
      "Validation loss: 1.499040126800537\n",
      "mse 1.499040175356994\n",
      "New best model found at epoch 96 with validation loss 1.499040126800537\n",
      "Starting Epoch 97\n",
      "1.5540425362794295\n",
      "Validation loss: 1.4978158473968506\n",
      "mse 1.497815964727598\n",
      "New best model found at epoch 97 with validation loss 1.4978158473968506\n",
      "Starting Epoch 98\n",
      "1.5523828579031902\n",
      "Validation loss: 1.4967114925384521\n",
      "mse 1.4967115552128851\n",
      "New best model found at epoch 98 with validation loss 1.4967114925384521\n",
      "Starting Epoch 99\n",
      "1.5505479133647422\n",
      "Validation loss: 1.495566964149475\n",
      "mse 1.4955669003530936\n",
      "New best model found at epoch 99 with validation loss 1.495566964149475\n",
      "Starting Epoch 100\n",
      "1.5487376373747122\n",
      "Validation loss: 1.4945714473724365\n",
      "mse 1.4945713875257767\n",
      "New best model found at epoch 100 with validation loss 1.4945714473724365\n",
      "Starting Epoch 101\n",
      "1.5473579738451086\n",
      "Validation loss: 1.4943126440048218\n",
      "mse 1.4943126654477195\n",
      "New best model found at epoch 101 with validation loss 1.4943126440048218\n",
      "Starting Epoch 102\n",
      "1.5463395533354387\n",
      "Validation loss: 1.4940485954284668\n",
      "mse 1.4940488509909657\n",
      "New best model found at epoch 102 with validation loss 1.4940485954284668\n",
      "Starting Epoch 103\n",
      "1.5456007563549539\n",
      "Validation loss: 1.493670105934143\n",
      "mse 1.493670072659755\n",
      "New best model found at epoch 103 with validation loss 1.493670105934143\n",
      "Starting Epoch 104\n",
      "1.54478476099346\n",
      "Validation loss: 1.4930943250656128\n",
      "mse 1.4930942459856091\n",
      "New best model found at epoch 104 with validation loss 1.4930943250656128\n",
      "Starting Epoch 105\n",
      "1.5440104577852332\n",
      "Validation loss: 1.4923945665359497\n",
      "mse 1.4923945107308838\n",
      "New best model found at epoch 105 with validation loss 1.4923945665359497\n",
      "Starting Epoch 106\n",
      "1.5432121079900991\n",
      "Validation loss: 1.4919148683547974\n",
      "mse 1.49191488440605\n",
      "New best model found at epoch 106 with validation loss 1.4919148683547974\n",
      "Starting Epoch 107\n",
      "1.5425468942393428\n",
      "Validation loss: 1.491315245628357\n",
      "mse 1.4913151845137518\n",
      "New best model found at epoch 107 with validation loss 1.491315245628357\n",
      "Starting Epoch 108\n",
      "1.5417649149894714\n",
      "Validation loss: 1.49069082736969\n",
      "mse 1.490690731364576\n",
      "New best model found at epoch 108 with validation loss 1.49069082736969\n",
      "Starting Epoch 109\n",
      "1.5410070704377217\n",
      "Validation loss: 1.4902012348175049\n",
      "mse 1.490201139145579\n",
      "New best model found at epoch 109 with validation loss 1.4902012348175049\n",
      "Starting Epoch 110\n",
      "1.5403986987860308\n",
      "Validation loss: 1.4897055625915527\n",
      "mse 1.489705613332307\n",
      "New best model found at epoch 110 with validation loss 1.4897055625915527\n",
      "Starting Epoch 111\n",
      "1.539503100125686\n",
      "Validation loss: 1.4890376329421997\n",
      "mse 1.489037819516462\n",
      "New best model found at epoch 111 with validation loss 1.4890376329421997\n",
      "Starting Epoch 112\n",
      "1.538704929144486\n",
      "Validation loss: 1.4886069297790527\n",
      "mse 1.4886069357319527\n",
      "New best model found at epoch 112 with validation loss 1.4886069297790527\n",
      "Starting Epoch 113\n",
      "1.5382560025090757\n",
      "Validation loss: 1.4879523515701294\n",
      "mse 1.487952406338901\n",
      "New best model found at epoch 113 with validation loss 1.4879523515701294\n",
      "Starting Epoch 114\n",
      "1.5373459536096323\n",
      "Validation loss: 1.4874604940414429\n",
      "mse 1.4874605575851954\n",
      "New best model found at epoch 114 with validation loss 1.4874604940414429\n",
      "Starting Epoch 115\n",
      "1.5367612942405369\n",
      "Validation loss: 1.4868981838226318\n",
      "mse 1.48689815010531\n",
      "New best model found at epoch 115 with validation loss 1.4868981838226318\n",
      "Starting Epoch 116\n",
      "1.5359127728835396\n",
      "Validation loss: 1.486441731452942\n",
      "mse 1.486441681624311\n",
      "New best model found at epoch 116 with validation loss 1.486441731452942\n",
      "Starting Epoch 117\n",
      "1.5352430291797803\n",
      "Validation loss: 1.485764503479004\n",
      "mse 1.4857646616412568\n",
      "New best model found at epoch 117 with validation loss 1.485764503479004\n",
      "Starting Epoch 118\n",
      "1.534634582374407\n",
      "Validation loss: 1.484998345375061\n",
      "mse 1.4849982792528846\n",
      "New best model found at epoch 118 with validation loss 1.484998345375061\n",
      "Starting Epoch 119\n",
      "1.5337710069573445\n",
      "Validation loss: 1.4844579696655273\n",
      "mse 1.4844581337272758\n",
      "New best model found at epoch 119 with validation loss 1.4844579696655273\n",
      "Starting Epoch 120\n",
      "1.5331194012061409\n",
      "Validation loss: 1.48386812210083\n",
      "mse 1.4838680685111618\n",
      "New best model found at epoch 120 with validation loss 1.48386812210083\n",
      "Starting Epoch 121\n",
      "1.5324108885682148\n",
      "Validation loss: 1.4833265542984009\n",
      "mse 1.4833263554908516\n",
      "New best model found at epoch 121 with validation loss 1.4833265542984009\n",
      "Starting Epoch 122\n",
      "1.531622948853866\n",
      "Validation loss: 1.4827479124069214\n",
      "mse 1.4827480546943026\n",
      "New best model found at epoch 122 with validation loss 1.4827479124069214\n",
      "Starting Epoch 123\n",
      "1.530940441981606\n",
      "Validation loss: 1.4821562767028809\n",
      "mse 1.482156336405114\n",
      "New best model found at epoch 123 with validation loss 1.4821562767028809\n",
      "Starting Epoch 124\n",
      "1.5301469797673433\n",
      "Validation loss: 1.481691598892212\n",
      "mse 1.4816915716880472\n",
      "New best model found at epoch 124 with validation loss 1.481691598892212\n",
      "Starting Epoch 125\n",
      "1.529443357301795\n",
      "Validation loss: 1.4809870719909668\n",
      "mse 1.480986957252929\n",
      "New best model found at epoch 125 with validation loss 1.4809870719909668\n",
      "Starting Epoch 126\n",
      "1.5286395446113918\n",
      "Validation loss: 1.4805419445037842\n",
      "mse 1.4805420435835288\n",
      "New best model found at epoch 126 with validation loss 1.4805419445037842\n",
      "Starting Epoch 127\n",
      "1.5279866068259529\n",
      "Validation loss: 1.47993004322052\n",
      "mse 1.4799300053771633\n",
      "New best model found at epoch 127 with validation loss 1.47993004322052\n",
      "Starting Epoch 128\n",
      "1.5272521765335747\n",
      "Validation loss: 1.4793384075164795\n",
      "mse 1.4793382502814147\n",
      "New best model found at epoch 128 with validation loss 1.4793384075164795\n",
      "Starting Epoch 129\n",
      "1.5265736968620964\n",
      "Validation loss: 1.4788439273834229\n",
      "mse 1.4788439709956638\n",
      "New best model found at epoch 129 with validation loss 1.4788439273834229\n",
      "Starting Epoch 130\n",
      "1.5258516461952873\n",
      "Validation loss: 1.4786396026611328\n",
      "mse 1.4786395984000602\n",
      "New best model found at epoch 130 with validation loss 1.4786396026611328\n",
      "Starting Epoch 131\n",
      "1.5251654023709504\n",
      "Validation loss: 1.4780597686767578\n",
      "mse 1.4780598512939576\n",
      "New best model found at epoch 131 with validation loss 1.4780597686767578\n",
      "Starting Epoch 132\n",
      "1.5245169971300208\n",
      "Validation loss: 1.4775272607803345\n",
      "mse 1.477527364164958\n",
      "New best model found at epoch 132 with validation loss 1.4775272607803345\n",
      "Starting Epoch 133\n",
      "1.523814724839252\n",
      "Validation loss: 1.4768134355545044\n",
      "mse 1.4768135288078372\n",
      "New best model found at epoch 133 with validation loss 1.4768134355545044\n",
      "Starting Epoch 134\n",
      "1.5231167129848315\n",
      "Validation loss: 1.4765976667404175\n",
      "mse 1.47659757523169\n",
      "New best model found at epoch 134 with validation loss 1.4765976667404175\n",
      "Starting Epoch 135\n",
      "1.522380810716878\n",
      "Validation loss: 1.4760860204696655\n",
      "mse 1.4760861407766572\n",
      "New best model found at epoch 135 with validation loss 1.4760860204696655\n",
      "Starting Epoch 136\n",
      "1.5217465732408606\n",
      "Validation loss: 1.4755264520645142\n",
      "mse 1.4755265638644834\n",
      "New best model found at epoch 136 with validation loss 1.4755264520645142\n",
      "Starting Epoch 137\n",
      "1.5211131261742634\n",
      "Validation loss: 1.4749765396118164\n",
      "mse 1.474976424792113\n",
      "New best model found at epoch 137 with validation loss 1.4749765396118164\n",
      "Starting Epoch 138\n",
      "1.5204151039538176\n",
      "Validation loss: 1.4744888544082642\n",
      "mse 1.4744886121012208\n",
      "New best model found at epoch 138 with validation loss 1.4744888544082642\n",
      "Starting Epoch 139\n",
      "1.5197300962779834\n",
      "Validation loss: 1.4740468263626099\n",
      "mse 1.474046870717202\n",
      "New best model found at epoch 139 with validation loss 1.4740468263626099\n",
      "Starting Epoch 140\n",
      "1.5190825203190679\n",
      "Validation loss: 1.4736658334732056\n",
      "mse 1.4736656704459\n",
      "New best model found at epoch 140 with validation loss 1.4736658334732056\n",
      "Starting Epoch 141\n",
      "1.5183831246002861\n",
      "Validation loss: 1.4729547500610352\n",
      "mse 1.4729547042008295\n",
      "New best model found at epoch 141 with validation loss 1.4729547500610352\n",
      "Starting Epoch 142\n",
      "1.517718053382376\n",
      "Validation loss: 1.472408652305603\n",
      "mse 1.472408797877915\n",
      "New best model found at epoch 142 with validation loss 1.472408652305603\n",
      "Starting Epoch 143\n",
      "1.5170450988023176\n",
      "Validation loss: 1.471909523010254\n",
      "mse 1.471909522477726\n",
      "New best model found at epoch 143 with validation loss 1.471909523010254\n",
      "Starting Epoch 144\n",
      "1.5163778792256895\n",
      "Validation loss: 1.4716229438781738\n",
      "mse 1.4716230664706107\n",
      "New best model found at epoch 144 with validation loss 1.4716229438781738\n",
      "Starting Epoch 145\n",
      "1.5156780429508374\n",
      "Validation loss: 1.4707236289978027\n",
      "mse 1.4707236067629457\n",
      "New best model found at epoch 145 with validation loss 1.4707236289978027\n",
      "Starting Epoch 146\n",
      "1.5149494254070779\n",
      "Validation loss: 1.470105528831482\n",
      "mse 1.4701056577426173\n",
      "New best model found at epoch 146 with validation loss 1.470105528831482\n",
      "Starting Epoch 147\n",
      "1.5142931627190632\n",
      "Validation loss: 1.4694737195968628\n",
      "mse 1.4694739380736006\n",
      "New best model found at epoch 147 with validation loss 1.4694737195968628\n",
      "Starting Epoch 148\n",
      "1.5135398092477217\n",
      "Validation loss: 1.4688575267791748\n",
      "mse 1.4688576413163805\n",
      "New best model found at epoch 148 with validation loss 1.4688575267791748\n",
      "Starting Epoch 149\n",
      "1.5128999145134636\n",
      "Validation loss: 1.4681040048599243\n",
      "mse 1.4681040308716826\n",
      "New best model found at epoch 149 with validation loss 1.4681040048599243\n",
      "Starting Epoch 150\n",
      "1.5121771226758542\n",
      "Validation loss: 1.467666506767273\n",
      "mse 1.4676665606422878\n",
      "New best model found at epoch 150 with validation loss 1.467666506767273\n",
      "Starting Epoch 151\n",
      "1.5115724776102148\n",
      "Validation loss: 1.4669206142425537\n",
      "mse 1.4669207193081713\n",
      "New best model found at epoch 151 with validation loss 1.4669206142425537\n",
      "Starting Epoch 152\n",
      "1.510900855064392\n",
      "Validation loss: 1.4663355350494385\n",
      "mse 1.4663353707807747\n",
      "New best model found at epoch 152 with validation loss 1.4663355350494385\n",
      "Starting Epoch 153\n",
      "1.510296730891518\n",
      "Validation loss: 1.4659630060195923\n",
      "mse 1.4659630249974227\n",
      "New best model found at epoch 153 with validation loss 1.4659630060195923\n",
      "Starting Epoch 154\n",
      "1.5096388718356257\n",
      "Validation loss: 1.4655362367630005\n",
      "mse 1.4655360992113182\n",
      "New best model found at epoch 154 with validation loss 1.4655362367630005\n",
      "Starting Epoch 155\n",
      "1.5090002935865652\n",
      "Validation loss: 1.465147852897644\n",
      "mse 1.4651478479263016\n",
      "New best model found at epoch 155 with validation loss 1.465147852897644\n",
      "Starting Epoch 156\n",
      "1.5084555174993433\n",
      "Validation loss: 1.4643834829330444\n",
      "mse 1.4643833067809409\n",
      "New best model found at epoch 156 with validation loss 1.4643834829330444\n",
      "Starting Epoch 157\n",
      "1.5078737424767537\n",
      "Validation loss: 1.4640253782272339\n",
      "mse 1.4640254534929351\n",
      "New best model found at epoch 157 with validation loss 1.4640253782272339\n",
      "Starting Epoch 158\n",
      "1.5072911433551623\n",
      "Validation loss: 1.4634013175964355\n",
      "mse 1.4634012073627867\n",
      "New best model found at epoch 158 with validation loss 1.4634013175964355\n",
      "Starting Epoch 159\n",
      "1.5066203811894292\n",
      "Validation loss: 1.4631755352020264\n",
      "mse 1.4631752977219004\n",
      "New best model found at epoch 159 with validation loss 1.4631755352020264\n",
      "Starting Epoch 160\n",
      "1.5060216991797737\n",
      "Validation loss: 1.4625530242919922\n",
      "mse 1.4625529812778069\n",
      "New best model found at epoch 160 with validation loss 1.4625530242919922\n",
      "Starting Epoch 161\n",
      "1.5054531693458557\n",
      "Validation loss: 1.4620094299316406\n",
      "mse 1.4620094601612623\n",
      "New best model found at epoch 161 with validation loss 1.4620094299316406\n",
      "Starting Epoch 162\n",
      "1.504823775395103\n",
      "Validation loss: 1.461476445198059\n",
      "mse 1.461476360119865\n",
      "New best model found at epoch 162 with validation loss 1.461476445198059\n",
      "Starting Epoch 163\n",
      "1.504265925158625\n",
      "Validation loss: 1.4611059427261353\n",
      "mse 1.4611060259653668\n",
      "New best model found at epoch 163 with validation loss 1.4611059427261353\n",
      "Starting Epoch 164\n",
      "1.5036896208058232\n",
      "Validation loss: 1.4604129791259766\n",
      "mse 1.4604130142801328\n",
      "New best model found at epoch 164 with validation loss 1.4604129791259766\n",
      "Starting Epoch 165\n",
      "1.502983165823895\n",
      "Validation loss: 1.4595673084259033\n",
      "mse 1.459567297101729\n",
      "New best model found at epoch 165 with validation loss 1.4595673084259033\n",
      "Starting Epoch 166\n",
      "1.5023352089135542\n",
      "Validation loss: 1.458874225616455\n",
      "mse 1.4588742268100168\n",
      "New best model found at epoch 166 with validation loss 1.458874225616455\n",
      "Starting Epoch 167\n",
      "1.5017152376796887\n",
      "Validation loss: 1.4579131603240967\n",
      "mse 1.4579132373015287\n",
      "New best model found at epoch 167 with validation loss 1.4579131603240967\n",
      "Starting Epoch 168\n",
      "1.501043853552445\n",
      "Validation loss: 1.4569289684295654\n",
      "mse 1.4569290438767994\n",
      "New best model found at epoch 168 with validation loss 1.4569289684295654\n",
      "Starting Epoch 169\n",
      "1.5002878489701643\n",
      "Validation loss: 1.456588864326477\n",
      "mse 1.4565887525450998\n",
      "New best model found at epoch 169 with validation loss 1.456588864326477\n",
      "Starting Epoch 170\n",
      "1.4996256802393042\n",
      "Validation loss: 1.4556992053985596\n",
      "mse 1.4556992478032578\n",
      "New best model found at epoch 170 with validation loss 1.4556992053985596\n",
      "Starting Epoch 171\n",
      "1.4990638572236765\n",
      "Validation loss: 1.4548105001449585\n",
      "mse 1.4548104750725261\n",
      "New best model found at epoch 171 with validation loss 1.4548105001449585\n",
      "Starting Epoch 172\n",
      "1.4984621897987698\n",
      "Validation loss: 1.4539824724197388\n",
      "mse 1.4539825027054\n",
      "New best model found at epoch 172 with validation loss 1.4539824724197388\n",
      "Starting Epoch 173\n",
      "1.4977217938589014\n",
      "Validation loss: 1.4537426233291626\n",
      "mse 1.4537426976903771\n",
      "New best model found at epoch 173 with validation loss 1.4537426233291626\n",
      "Starting Epoch 174\n",
      "1.4971705856530562\n",
      "Validation loss: 1.4530247449874878\n",
      "mse 1.453024769936476\n",
      "New best model found at epoch 174 with validation loss 1.4530247449874878\n",
      "Starting Epoch 175\n",
      "1.496501502783402\n",
      "Validation loss: 1.4524624347686768\n",
      "mse 1.452462467004019\n",
      "New best model found at epoch 175 with validation loss 1.4524624347686768\n",
      "Starting Epoch 176\n",
      "1.495789831099303\n",
      "Validation loss: 1.4512501955032349\n",
      "mse 1.4512502950432749\n",
      "New best model found at epoch 176 with validation loss 1.4512501955032349\n",
      "Starting Epoch 177\n",
      "1.4950497642807339\n",
      "Validation loss: 1.450609803199768\n",
      "mse 1.4506099387997597\n",
      "New best model found at epoch 177 with validation loss 1.450609803199768\n",
      "Starting Epoch 178\n",
      "1.4940985544868137\n",
      "Validation loss: 1.4496594667434692\n",
      "mse 1.4496594872927147\n",
      "New best model found at epoch 178 with validation loss 1.4496594667434692\n",
      "Starting Epoch 179\n",
      "1.4933922394462253\n",
      "Validation loss: 1.449109435081482\n",
      "mse 1.4491095148401727\n",
      "New best model found at epoch 179 with validation loss 1.449109435081482\n",
      "Starting Epoch 180\n",
      "1.4926122582477073\n",
      "Validation loss: 1.448602557182312\n",
      "mse 1.4486024280392213\n",
      "New best model found at epoch 180 with validation loss 1.448602557182312\n",
      "Starting Epoch 181\n",
      "1.4920067061548647\n",
      "Validation loss: 1.4483596086502075\n",
      "mse 1.4483595979884607\n",
      "New best model found at epoch 181 with validation loss 1.4483596086502075\n",
      "Starting Epoch 182\n",
      "1.491478391315626\n",
      "Validation loss: 1.4475529193878174\n",
      "mse 1.4475529217842076\n",
      "New best model found at epoch 182 with validation loss 1.4475529193878174\n",
      "Starting Epoch 183\n",
      "1.4908287240111309\n",
      "Validation loss: 1.4471582174301147\n",
      "mse 1.4471582227219342\n",
      "New best model found at epoch 183 with validation loss 1.4471582174301147\n",
      "Starting Epoch 184\n",
      "1.4902295444322669\n",
      "Validation loss: 1.4469008445739746\n",
      "mse 1.4469007332396697\n",
      "New best model found at epoch 184 with validation loss 1.4469008445739746\n",
      "Starting Epoch 185\n",
      "1.489572672740273\n",
      "Validation loss: 1.4464329481124878\n",
      "mse 1.4464329488272847\n",
      "New best model found at epoch 185 with validation loss 1.4464329481124878\n",
      "Starting Epoch 186\n",
      "1.4889130074044932\n",
      "Validation loss: 1.4463169574737549\n",
      "mse 1.4463168370692185\n",
      "New best model found at epoch 186 with validation loss 1.4463169574737549\n",
      "Starting Epoch 187\n",
      "1.4883271378019582\n",
      "Validation loss: 1.4455718994140625\n",
      "mse 1.4455720113277986\n",
      "New best model found at epoch 187 with validation loss 1.4455718994140625\n",
      "Starting Epoch 188\n",
      "1.4879030974014946\n",
      "Validation loss: 1.4452686309814453\n",
      "mse 1.4452686991807544\n",
      "New best model found at epoch 188 with validation loss 1.4452686309814453\n",
      "Starting Epoch 189\n",
      "1.4873226310895837\n",
      "Validation loss: 1.4448744058609009\n",
      "mse 1.4448743334328145\n",
      "New best model found at epoch 189 with validation loss 1.4448744058609009\n",
      "Starting Epoch 190\n",
      "1.486675474954688\n",
      "Validation loss: 1.4447717666625977\n",
      "mse 1.44477166162987\n",
      "New best model found at epoch 190 with validation loss 1.4447717666625977\n",
      "Starting Epoch 191\n",
      "1.4860951148945352\n",
      "Validation loss: 1.4442750215530396\n",
      "mse 1.4442750345288327\n",
      "New best model found at epoch 191 with validation loss 1.4442750215530396\n",
      "Starting Epoch 192\n",
      "1.4855358082315195\n",
      "Validation loss: 1.4439054727554321\n",
      "mse 1.4439054228576613\n",
      "New best model found at epoch 192 with validation loss 1.4439054727554321\n",
      "Starting Epoch 193\n",
      "1.4849476270053699\n",
      "Validation loss: 1.4434213638305664\n",
      "mse 1.4434214944333832\n",
      "New best model found at epoch 193 with validation loss 1.4434213638305664\n",
      "Starting Epoch 194\n",
      "1.4843314937923267\n",
      "Validation loss: 1.4429383277893066\n",
      "mse 1.4429384710575042\n",
      "New best model found at epoch 194 with validation loss 1.4429383277893066\n",
      "Starting Epoch 195\n",
      "1.4838575798532236\n",
      "Validation loss: 1.4424142837524414\n",
      "mse 1.4424141747920818\n",
      "New best model found at epoch 195 with validation loss 1.4424142837524414\n",
      "Starting Epoch 196\n",
      "1.4833082945450493\n",
      "Validation loss: 1.4418962001800537\n",
      "mse 1.4418963221625956\n",
      "New best model found at epoch 196 with validation loss 1.4418962001800537\n",
      "Starting Epoch 197\n",
      "1.4825324986291968\n",
      "Validation loss: 1.4417362213134766\n",
      "mse 1.4417361666948088\n",
      "New best model found at epoch 197 with validation loss 1.4417362213134766\n",
      "Starting Epoch 198\n",
      "1.4821851098019143\n",
      "Validation loss: 1.4412381649017334\n",
      "mse 1.4412382205009253\n",
      "New best model found at epoch 198 with validation loss 1.4412381649017334\n",
      "Starting Epoch 199\n",
      "1.4815837611322817\n",
      "Validation loss: 1.4408208131790161\n",
      "mse 1.4408207251925644\n",
      "New best model found at epoch 199 with validation loss 1.4408208131790161\n",
      "Starting Epoch 200\n",
      "1.4809707610503486\n",
      "Validation loss: 1.440643072128296\n",
      "mse 1.4406430907187078\n",
      "New best model found at epoch 200 with validation loss 1.440643072128296\n",
      "Starting Epoch 201\n",
      "1.480369798515154\n",
      "Validation loss: 1.4403423070907593\n",
      "mse 1.4403423290740396\n",
      "New best model found at epoch 201 with validation loss 1.4403423070907593\n",
      "Starting Epoch 202\n",
      "1.4798433521519536\n",
      "Validation loss: 1.4399688243865967\n",
      "mse 1.439968788734483\n",
      "New best model found at epoch 202 with validation loss 1.4399688243865967\n",
      "Starting Epoch 203\n",
      "1.479293115760969\n",
      "Validation loss: 1.4394451379776\n",
      "mse 1.4394450751838999\n",
      "New best model found at epoch 203 with validation loss 1.4394451379776\n",
      "Starting Epoch 204\n",
      "1.4787338816601296\n",
      "Validation loss: 1.4388549327850342\n",
      "mse 1.4388548713202032\n",
      "New best model found at epoch 204 with validation loss 1.4388549327850342\n",
      "Starting Epoch 205\n",
      "1.4781136745991914\n",
      "Validation loss: 1.4383735656738281\n",
      "mse 1.4383735314734665\n",
      "New best model found at epoch 205 with validation loss 1.4383735656738281\n",
      "Starting Epoch 206\n",
      "1.4775367767914482\n",
      "Validation loss: 1.4379355907440186\n",
      "mse 1.4379355596689127\n",
      "New best model found at epoch 206 with validation loss 1.4379355907440186\n",
      "Starting Epoch 207\n",
      "1.477057184862054\n",
      "Validation loss: 1.437638759613037\n",
      "mse 1.437638755002908\n",
      "New best model found at epoch 207 with validation loss 1.437638759613037\n",
      "Starting Epoch 208\n",
      "1.4764683039292046\n",
      "Validation loss: 1.4374005794525146\n",
      "mse 1.4374005955373943\n",
      "New best model found at epoch 208 with validation loss 1.4374005794525146\n",
      "Starting Epoch 209\n",
      "1.4758946558703547\n",
      "Validation loss: 1.4370478391647339\n",
      "mse 1.4370477485118045\n",
      "New best model found at epoch 209 with validation loss 1.4370478391647339\n",
      "Starting Epoch 210\n",
      "1.4754907281502434\n",
      "Validation loss: 1.4366673231124878\n",
      "mse 1.4366672245337289\n",
      "New best model found at epoch 210 with validation loss 1.4366673231124878\n",
      "Starting Epoch 211\n",
      "1.4748476432717366\n",
      "Validation loss: 1.4360880851745605\n",
      "mse 1.4360879928521424\n",
      "New best model found at epoch 211 with validation loss 1.4360880851745605\n",
      "Starting Epoch 212\n",
      "1.474368823611218\n",
      "Validation loss: 1.4357270002365112\n",
      "mse 1.4357267609466213\n",
      "New best model found at epoch 212 with validation loss 1.4357270002365112\n",
      "Starting Epoch 213\n",
      "1.473734184451725\n",
      "Validation loss: 1.4353113174438477\n",
      "mse 1.4353114372759233\n",
      "New best model found at epoch 213 with validation loss 1.4353113174438477\n",
      "Starting Epoch 214\n",
      "1.473221462705861\n",
      "Validation loss: 1.4348706007003784\n",
      "mse 1.434870646869071\n",
      "New best model found at epoch 214 with validation loss 1.4348706007003784\n",
      "Starting Epoch 215\n",
      "1.4725207790084507\n",
      "Validation loss: 1.434514045715332\n",
      "mse 1.4345141220111974\n",
      "New best model found at epoch 215 with validation loss 1.434514045715332\n",
      "Starting Epoch 216\n",
      "1.4720569201137708\n",
      "Validation loss: 1.4340734481811523\n",
      "mse 1.4340736384381694\n",
      "New best model found at epoch 216 with validation loss 1.4340734481811523\n",
      "Starting Epoch 217\n",
      "1.4714657716129138\n",
      "Validation loss: 1.433578610420227\n",
      "mse 1.4335785465710995\n",
      "New best model found at epoch 217 with validation loss 1.433578610420227\n",
      "Starting Epoch 218\n",
      "1.4709499452425085\n",
      "Validation loss: 1.4331761598587036\n",
      "mse 1.4331761407950423\n",
      "New best model found at epoch 218 with validation loss 1.4331761598587036\n",
      "Starting Epoch 219\n",
      "1.470431130865346\n",
      "Validation loss: 1.4326523542404175\n",
      "mse 1.4326524058765602\n",
      "New best model found at epoch 219 with validation loss 1.4326523542404175\n",
      "Starting Epoch 220\n",
      "1.4697244918864707\n",
      "Validation loss: 1.4323489665985107\n",
      "mse 1.4323488535886673\n",
      "New best model found at epoch 220 with validation loss 1.4323489665985107\n",
      "Starting Epoch 221\n",
      "1.4692688636157825\n",
      "Validation loss: 1.43192720413208\n",
      "mse 1.4319271124755772\n",
      "New best model found at epoch 221 with validation loss 1.43192720413208\n",
      "Starting Epoch 222\n",
      "1.4685946366061335\n",
      "Validation loss: 1.4317151308059692\n",
      "mse 1.4317149808430067\n",
      "New best model found at epoch 222 with validation loss 1.4317151308059692\n",
      "Starting Epoch 223\n",
      "1.4681702955909397\n",
      "Validation loss: 1.4314467906951904\n",
      "mse 1.4314468273181673\n",
      "New best model found at epoch 223 with validation loss 1.4314467906951904\n",
      "Starting Epoch 224\n",
      "1.4673981096433557\n",
      "Validation loss: 1.4309393167495728\n",
      "mse 1.4309393250278106\n",
      "New best model found at epoch 224 with validation loss 1.4309393167495728\n",
      "Starting Epoch 225\n",
      "1.4669354713481406\n",
      "Validation loss: 1.430361032485962\n",
      "mse 1.4303609860623527\n",
      "New best model found at epoch 225 with validation loss 1.430361032485962\n",
      "Starting Epoch 226\n",
      "1.4663155985915142\n",
      "Validation loss: 1.430325984954834\n",
      "mse 1.4303259900696386\n",
      "New best model found at epoch 226 with validation loss 1.430325984954834\n",
      "Starting Epoch 227\n",
      "1.4658347238665042\n",
      "Validation loss: 1.4296910762786865\n",
      "mse 1.4296911286011458\n",
      "New best model found at epoch 227 with validation loss 1.4296910762786865\n",
      "Starting Epoch 228\n",
      "1.4651920354884604\n",
      "Validation loss: 1.4293807744979858\n",
      "mse 1.4293808311463216\n",
      "New best model found at epoch 228 with validation loss 1.4293807744979858\n",
      "Starting Epoch 229\n",
      "1.4647007843722468\n",
      "Validation loss: 1.4290387630462646\n",
      "mse 1.4290386636830852\n",
      "New best model found at epoch 229 with validation loss 1.4290387630462646\n",
      "Starting Epoch 230\n",
      "1.4641557024872822\n",
      "Validation loss: 1.428573727607727\n",
      "mse 1.428573675969303\n",
      "New best model found at epoch 230 with validation loss 1.428573727607727\n",
      "Starting Epoch 231\n",
      "1.4635978911233984\n",
      "Validation loss: 1.4284266233444214\n",
      "mse 1.4284267410304086\n",
      "New best model found at epoch 231 with validation loss 1.4284266233444214\n",
      "Starting Epoch 232\n",
      "1.463048771671627\n",
      "Validation loss: 1.427935242652893\n",
      "mse 1.427935323759569\n",
      "New best model found at epoch 232 with validation loss 1.427935242652893\n",
      "Starting Epoch 233\n",
      "1.4624017217884893\n",
      "Validation loss: 1.4275747537612915\n",
      "mse 1.4275746876516595\n",
      "New best model found at epoch 233 with validation loss 1.4275747537612915\n",
      "Starting Epoch 234\n",
      "1.4619823046352551\n",
      "Validation loss: 1.4270195960998535\n",
      "mse 1.4270195020096175\n",
      "New best model found at epoch 234 with validation loss 1.4270195960998535\n",
      "Starting Epoch 235\n",
      "1.4613343632739524\n",
      "Validation loss: 1.426802158355713\n",
      "mse 1.4268022371220743\n",
      "New best model found at epoch 235 with validation loss 1.426802158355713\n",
      "Starting Epoch 236\n",
      "1.4608449987743213\n",
      "Validation loss: 1.4266492128372192\n",
      "mse 1.4266491944510022\n",
      "New best model found at epoch 236 with validation loss 1.4266492128372192\n",
      "Starting Epoch 237\n",
      "1.460252608941949\n",
      "Validation loss: 1.4259151220321655\n",
      "mse 1.4259152390651526\n",
      "New best model found at epoch 237 with validation loss 1.4259151220321655\n",
      "Starting Epoch 238\n",
      "1.4597997976386028\n",
      "Validation loss: 1.4255427122116089\n",
      "mse 1.4255427280865496\n",
      "New best model found at epoch 238 with validation loss 1.4255427122116089\n",
      "Starting Epoch 239\n",
      "1.4592126763385276\n",
      "Validation loss: 1.4251656532287598\n",
      "mse 1.4251656436355744\n",
      "New best model found at epoch 239 with validation loss 1.4251656532287598\n",
      "Starting Epoch 240\n",
      "1.4586981457212698\n",
      "Validation loss: 1.424854040145874\n",
      "mse 1.4248541722197712\n",
      "New best model found at epoch 240 with validation loss 1.424854040145874\n",
      "Starting Epoch 241\n",
      "1.4581191539764404\n",
      "Validation loss: 1.4244176149368286\n",
      "mse 1.4244174414732163\n",
      "New best model found at epoch 241 with validation loss 1.4244176149368286\n",
      "Starting Epoch 242\n",
      "1.4576398367467134\n",
      "Validation loss: 1.424224853515625\n",
      "mse 1.4242247826106706\n",
      "New best model found at epoch 242 with validation loss 1.424224853515625\n",
      "Starting Epoch 243\n",
      "1.4570240741190703\n",
      "Validation loss: 1.423917531967163\n",
      "mse 1.4239175260910144\n",
      "New best model found at epoch 243 with validation loss 1.423917531967163\n",
      "Starting Epoch 244\n",
      "1.4565392110658728\n",
      "Validation loss: 1.423671007156372\n",
      "mse 1.423671056402701\n",
      "New best model found at epoch 244 with validation loss 1.423671007156372\n",
      "Starting Epoch 245\n",
      "1.456071806990582\n",
      "Validation loss: 1.4230215549468994\n",
      "mse 1.4230215199883292\n",
      "New best model found at epoch 245 with validation loss 1.4230215549468994\n",
      "Starting Epoch 246\n",
      "1.45550769308339\n",
      "Validation loss: 1.422701120376587\n",
      "mse 1.4227010219740746\n",
      "New best model found at epoch 246 with validation loss 1.422701120376587\n",
      "Starting Epoch 247\n",
      "1.4548667073249817\n",
      "Validation loss: 1.4224228858947754\n",
      "mse 1.4224228389697082\n",
      "New best model found at epoch 247 with validation loss 1.4224228858947754\n",
      "Starting Epoch 248\n",
      "1.45449349672898\n",
      "Validation loss: 1.4218569993972778\n",
      "mse 1.4218569051707333\n",
      "New best model found at epoch 248 with validation loss 1.4218569993972778\n",
      "Starting Epoch 249\n",
      "1.4539063261902851\n",
      "Validation loss: 1.4213794469833374\n",
      "mse 1.4213796780427876\n",
      "New best model found at epoch 249 with validation loss 1.4213794469833374\n",
      "Starting Epoch 250\n",
      "1.4534406739732493\n",
      "Validation loss: 1.4211450815200806\n",
      "mse 1.4211450567908315\n",
      "New best model found at epoch 250 with validation loss 1.4211450815200806\n",
      "Starting Epoch 251\n",
      "1.4528285394544187\n",
      "Validation loss: 1.4207476377487183\n",
      "mse 1.4207476516957822\n",
      "New best model found at epoch 251 with validation loss 1.4207476377487183\n",
      "Starting Epoch 252\n",
      "1.4523658337800398\n",
      "Validation loss: 1.4205145835876465\n",
      "mse 1.420514612619272\n",
      "New best model found at epoch 252 with validation loss 1.4205145835876465\n",
      "Starting Epoch 253\n",
      "1.4517933648565542\n",
      "Validation loss: 1.4202916622161865\n",
      "mse 1.4202918233532558\n",
      "New best model found at epoch 253 with validation loss 1.4202916622161865\n",
      "Starting Epoch 254\n",
      "1.451378399911134\n",
      "Validation loss: 1.4196360111236572\n",
      "mse 1.419635924432588\n",
      "New best model found at epoch 254 with validation loss 1.4196360111236572\n",
      "Starting Epoch 255\n",
      "1.450783063536105\n",
      "Validation loss: 1.4194852113723755\n",
      "mse 1.41948533729277\n",
      "New best model found at epoch 255 with validation loss 1.4194852113723755\n",
      "Starting Epoch 256\n",
      "1.4502908457880435\n",
      "Validation loss: 1.4191268682479858\n",
      "mse 1.4191269142835399\n",
      "New best model found at epoch 256 with validation loss 1.4191268682479858\n",
      "Starting Epoch 257\n",
      "1.449929361758025\n",
      "Validation loss: 1.4186663627624512\n",
      "mse 1.4186664163833314\n",
      "New best model found at epoch 257 with validation loss 1.4186663627624512\n",
      "Starting Epoch 258\n",
      "1.4493204925371252\n",
      "Validation loss: 1.4184534549713135\n",
      "mse 1.4184533436401001\n",
      "New best model found at epoch 258 with validation loss 1.4184534549713135\n",
      "Starting Epoch 259\n",
      "1.4488668830498406\n",
      "Validation loss: 1.4177095890045166\n",
      "mse 1.4177096051345348\n",
      "New best model found at epoch 259 with validation loss 1.4177095890045166\n",
      "Starting Epoch 260\n",
      "1.4483639571977698\n",
      "Validation loss: 1.4178065061569214\n",
      "mse 1.4178066660695225\n",
      "Starting Epoch 261\n",
      "1.4478236955145132\n",
      "Validation loss: 1.4173815250396729\n",
      "mse 1.4173816316852519\n",
      "New best model found at epoch 261 with validation loss 1.4173815250396729\n",
      "Starting Epoch 262\n",
      "1.447319587935572\n",
      "Validation loss: 1.4167863130569458\n",
      "mse 1.4167864273634971\n",
      "New best model found at epoch 262 with validation loss 1.4167863130569458\n",
      "Starting Epoch 263\n",
      "1.446917458720829\n",
      "Validation loss: 1.416481614112854\n",
      "mse 1.4164816815456343\n",
      "New best model found at epoch 263 with validation loss 1.416481614112854\n",
      "Starting Epoch 264\n",
      "1.446315215981525\n",
      "Validation loss: 1.4161900281906128\n",
      "mse 1.4161900797092444\n",
      "New best model found at epoch 264 with validation loss 1.4161900281906128\n",
      "Starting Epoch 265\n",
      "1.4458696738533352\n",
      "Validation loss: 1.4158343076705933\n",
      "mse 1.4158342917235693\n",
      "New best model found at epoch 265 with validation loss 1.4158343076705933\n",
      "Starting Epoch 266\n",
      "1.4453582711841748\n",
      "Validation loss: 1.415533423423767\n",
      "mse 1.4155333045869338\n",
      "New best model found at epoch 266 with validation loss 1.415533423423767\n",
      "Starting Epoch 267\n",
      "1.4447813630104065\n",
      "Validation loss: 1.4150500297546387\n",
      "mse 1.4150500668187793\n",
      "New best model found at epoch 267 with validation loss 1.4150500297546387\n",
      "Starting Epoch 268\n",
      "1.444385238315748\n",
      "Validation loss: 1.414996862411499\n",
      "mse 1.4149968436464893\n",
      "New best model found at epoch 268 with validation loss 1.414996862411499\n",
      "Starting Epoch 269\n",
      "1.4438964672710584\n",
      "Validation loss: 1.4144495725631714\n",
      "mse 1.414449644841704\n",
      "New best model found at epoch 269 with validation loss 1.4144495725631714\n",
      "Starting Epoch 270\n",
      "1.443256940530694\n",
      "Validation loss: 1.4141051769256592\n",
      "mse 1.4141051928821244\n",
      "New best model found at epoch 270 with validation loss 1.4141051769256592\n",
      "Starting Epoch 271\n",
      "1.4429505519244983\n",
      "Validation loss: 1.4135669469833374\n",
      "mse 1.4135668413371183\n",
      "New best model found at epoch 271 with validation loss 1.4135669469833374\n",
      "Starting Epoch 272\n",
      "1.4422828632852305\n",
      "Validation loss: 1.4132442474365234\n",
      "mse 1.4132441983825184\n",
      "New best model found at epoch 272 with validation loss 1.4132442474365234\n",
      "Starting Epoch 273\n",
      "1.4419223795766416\n",
      "Validation loss: 1.4127907752990723\n",
      "mse 1.4127906792011922\n",
      "New best model found at epoch 273 with validation loss 1.4127907752990723\n",
      "Starting Epoch 274\n",
      "1.4413266855737437\n",
      "Validation loss: 1.412654161453247\n",
      "mse 1.4126542735024836\n",
      "New best model found at epoch 274 with validation loss 1.412654161453247\n",
      "Starting Epoch 275\n",
      "1.4408553994220237\n",
      "Validation loss: 1.4120635986328125\n",
      "mse 1.4120636076949784\n",
      "New best model found at epoch 275 with validation loss 1.4120635986328125\n",
      "Starting Epoch 276\n",
      "1.440244179704915\n",
      "Validation loss: 1.4118695259094238\n",
      "mse 1.4118695189629373\n",
      "New best model found at epoch 276 with validation loss 1.4118695259094238\n",
      "Starting Epoch 277\n",
      "1.4397627918616585\n",
      "Validation loss: 1.411637306213379\n",
      "mse 1.4116374039631843\n",
      "New best model found at epoch 277 with validation loss 1.411637306213379\n",
      "Starting Epoch 278\n",
      "1.439199994439664\n",
      "Validation loss: 1.4111063480377197\n",
      "mse 1.4111064655182315\n",
      "New best model found at epoch 278 with validation loss 1.4111063480377197\n",
      "Starting Epoch 279\n",
      "1.4387634292892788\n",
      "Validation loss: 1.4108853340148926\n",
      "mse 1.4108852841966693\n",
      "New best model found at epoch 279 with validation loss 1.4108853340148926\n",
      "Starting Epoch 280\n",
      "1.438174895618273\n",
      "Validation loss: 1.4104373455047607\n",
      "mse 1.4104373582132776\n",
      "New best model found at epoch 280 with validation loss 1.4104373455047607\n",
      "Starting Epoch 281\n",
      "1.4377592750217603\n",
      "Validation loss: 1.410049557685852\n",
      "mse 1.4100495381625406\n",
      "New best model found at epoch 281 with validation loss 1.410049557685852\n",
      "Starting Epoch 282\n",
      "1.437113528666289\n",
      "Validation loss: 1.409853219985962\n",
      "mse 1.409853286101665\n",
      "New best model found at epoch 282 with validation loss 1.409853219985962\n",
      "Starting Epoch 283\n",
      "1.4367716752964517\n",
      "Validation loss: 1.4089865684509277\n",
      "mse 1.4089865415106273\n",
      "New best model found at epoch 283 with validation loss 1.4089865684509277\n",
      "Starting Epoch 284\n",
      "1.4360857631849206\n",
      "Validation loss: 1.4090427160263062\n",
      "mse 1.40904271837768\n",
      "Starting Epoch 285\n",
      "1.4355513945869778\n",
      "Validation loss: 1.4087603092193604\n",
      "mse 1.4087602599295581\n",
      "New best model found at epoch 285 with validation loss 1.4087603092193604\n",
      "Starting Epoch 286\n",
      "1.4351613599321116\n",
      "Validation loss: 1.4083000421524048\n",
      "mse 1.4083000178817082\n",
      "New best model found at epoch 286 with validation loss 1.4083000421524048\n",
      "Starting Epoch 287\n",
      "1.4344328304995662\n",
      "Validation loss: 1.4080742597579956\n",
      "mse 1.4080741914407977\n",
      "New best model found at epoch 287 with validation loss 1.4080742597579956\n",
      "Starting Epoch 288\n",
      "1.4340711443320564\n",
      "Validation loss: 1.4074909687042236\n",
      "mse 1.4074909958035842\n",
      "New best model found at epoch 288 with validation loss 1.4074909687042236\n",
      "Starting Epoch 289\n",
      "1.4334588646888733\n",
      "Validation loss: 1.407414436340332\n",
      "mse 1.4074145642183118\n",
      "New best model found at epoch 289 with validation loss 1.407414436340332\n",
      "Starting Epoch 290\n",
      "1.4330772446549458\n",
      "Validation loss: 1.4069222211837769\n",
      "mse 1.4069221345589455\n",
      "New best model found at epoch 290 with validation loss 1.4069222211837769\n",
      "Starting Epoch 291\n",
      "1.4323783361393472\n",
      "Validation loss: 1.4065405130386353\n",
      "mse 1.4065406086616656\n",
      "New best model found at epoch 291 with validation loss 1.4065405130386353\n",
      "Starting Epoch 292\n",
      "1.431977795517963\n",
      "Validation loss: 1.4062726497650146\n",
      "mse 1.4062725262699245\n",
      "New best model found at epoch 292 with validation loss 1.4062726497650146\n",
      "Starting Epoch 293\n",
      "1.4314169987388279\n",
      "Validation loss: 1.4058308601379395\n",
      "mse 1.4058309909897668\n",
      "New best model found at epoch 293 with validation loss 1.4058308601379395\n",
      "Starting Epoch 294\n",
      "1.4308921876160994\n",
      "Validation loss: 1.4054476022720337\n",
      "mse 1.4054476660665043\n",
      "New best model found at epoch 294 with validation loss 1.4054476022720337\n",
      "Starting Epoch 295\n",
      "1.430469380772632\n",
      "Validation loss: 1.4049708843231201\n",
      "mse 1.4049709138068014\n",
      "New best model found at epoch 295 with validation loss 1.4049708843231201\n",
      "Starting Epoch 296\n",
      "1.4298925347950147\n",
      "Validation loss: 1.404761791229248\n",
      "mse 1.40476166362045\n",
      "New best model found at epoch 296 with validation loss 1.404761791229248\n",
      "Starting Epoch 297\n",
      "1.4293272987655972\n",
      "Validation loss: 1.4043171405792236\n",
      "mse 1.4043171249696151\n",
      "New best model found at epoch 297 with validation loss 1.4043171405792236\n",
      "Starting Epoch 298\n",
      "1.4289642935213835\n",
      "Validation loss: 1.403753399848938\n",
      "mse 1.4037534935546772\n",
      "New best model found at epoch 298 with validation loss 1.403753399848938\n",
      "Starting Epoch 299\n",
      "1.4283182154531064\n",
      "Validation loss: 1.4036011695861816\n",
      "mse 1.403601188702469\n",
      "New best model found at epoch 299 with validation loss 1.4036011695861816\n",
      "Starting Epoch 300\n",
      "1.4278831326443215\n",
      "Validation loss: 1.4032102823257446\n",
      "mse 1.4032103616180436\n",
      "New best model found at epoch 300 with validation loss 1.4032102823257446\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-mean: 7-60-40-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9575f",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 3\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 60 - 40 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "d8079886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "d2f91dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,5,11]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,5,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "18b29c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'min(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "f4318012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "7933b17d-1062-4d9c-9f89-30fca214822a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.0978859300198764\n",
      "Validation loss: 2.4760849475860596\n",
      "mse 2.4760848871244927\n",
      "New best model found at epoch 1 with validation loss 2.4760849475860596\n",
      "Starting Epoch 2\n",
      "2.5734352650849717\n",
      "Validation loss: 2.196194887161255\n",
      "mse 2.196195095797577\n",
      "New best model found at epoch 2 with validation loss 2.196194887161255\n",
      "Starting Epoch 3\n",
      "2.3199888104977817\n",
      "Validation loss: 2.030263662338257\n",
      "mse 2.0302639077567157\n",
      "New best model found at epoch 3 with validation loss 2.030263662338257\n",
      "Starting Epoch 4\n",
      "2.1623682353807534\n",
      "Validation loss: 1.9252103567123413\n",
      "mse 1.9252103253394328\n",
      "New best model found at epoch 4 with validation loss 1.9252103567123413\n",
      "Starting Epoch 5\n",
      "2.0537651518116826\n",
      "Validation loss: 1.860530138015747\n",
      "mse 1.8605301532927483\n",
      "New best model found at epoch 5 with validation loss 1.860530138015747\n",
      "Starting Epoch 6\n",
      "1.9820254470991052\n",
      "Validation loss: 1.8173506259918213\n",
      "mse 1.8173508054776457\n",
      "New best model found at epoch 6 with validation loss 1.8173506259918213\n",
      "Starting Epoch 7\n",
      "1.9310903290043706\n",
      "Validation loss: 1.7856450080871582\n",
      "mse 1.7856448982465782\n",
      "New best model found at epoch 7 with validation loss 1.7856450080871582\n",
      "Starting Epoch 8\n",
      "1.8929715830346812\n",
      "Validation loss: 1.7617297172546387\n",
      "mse 1.7617296471823838\n",
      "New best model found at epoch 8 with validation loss 1.7617297172546387\n",
      "Starting Epoch 9\n",
      "1.8636217687440955\n",
      "Validation loss: 1.7431327104568481\n",
      "mse 1.7431326910712328\n",
      "New best model found at epoch 9 with validation loss 1.7431327104568481\n",
      "Starting Epoch 10\n",
      "1.8402044151140295\n",
      "Validation loss: 1.7272299528121948\n",
      "mse 1.7272298698866713\n",
      "New best model found at epoch 10 with validation loss 1.7272299528121948\n",
      "Starting Epoch 11\n",
      "1.82179317785346\n",
      "Validation loss: 1.7136670351028442\n",
      "mse 1.713666972950145\n",
      "New best model found at epoch 11 with validation loss 1.7136670351028442\n",
      "Starting Epoch 12\n",
      "1.8062880298365718\n",
      "Validation loss: 1.702209234237671\n",
      "mse 1.7022092990145645\n",
      "New best model found at epoch 12 with validation loss 1.702209234237671\n",
      "Starting Epoch 13\n",
      "1.7934631938519685\n",
      "Validation loss: 1.6928473711013794\n",
      "mse 1.6928472538876738\n",
      "New best model found at epoch 13 with validation loss 1.6928473711013794\n",
      "Starting Epoch 14\n",
      "1.7824081648950991\n",
      "Validation loss: 1.6837559938430786\n",
      "mse 1.6837558196967042\n",
      "New best model found at epoch 14 with validation loss 1.6837559938430786\n",
      "Starting Epoch 15\n",
      "1.7729442897050276\n",
      "Validation loss: 1.6762984991073608\n",
      "mse 1.6762984512770818\n",
      "New best model found at epoch 15 with validation loss 1.6762984991073608\n",
      "Starting Epoch 16\n",
      "1.7646532939827961\n",
      "Validation loss: 1.670885443687439\n",
      "mse 1.6708854850519665\n",
      "New best model found at epoch 16 with validation loss 1.670885443687439\n",
      "Starting Epoch 17\n",
      "1.7570228110189023\n",
      "Validation loss: 1.6653333902359009\n",
      "mse 1.665333385161427\n",
      "New best model found at epoch 17 with validation loss 1.6653333902359009\n",
      "Starting Epoch 18\n",
      "1.7506500016088071\n",
      "Validation loss: 1.6606391668319702\n",
      "mse 1.6606392422451917\n",
      "New best model found at epoch 18 with validation loss 1.6606391668319702\n",
      "Starting Epoch 19\n",
      "1.74503929718681\n",
      "Validation loss: 1.6559855937957764\n",
      "mse 1.655985505350357\n",
      "New best model found at epoch 19 with validation loss 1.6559855937957764\n",
      "Starting Epoch 20\n",
      "1.74013656636943\n",
      "Validation loss: 1.6522722244262695\n",
      "mse 1.6522721257586428\n",
      "New best model found at epoch 20 with validation loss 1.6522722244262695\n",
      "Starting Epoch 21\n",
      "1.735598113225854\n",
      "Validation loss: 1.6483994722366333\n",
      "mse 1.6483995252339414\n",
      "New best model found at epoch 21 with validation loss 1.6483994722366333\n",
      "Starting Epoch 22\n",
      "1.7316519125648167\n",
      "Validation loss: 1.645063877105713\n",
      "mse 1.6450638839328662\n",
      "New best model found at epoch 22 with validation loss 1.645063877105713\n",
      "Starting Epoch 23\n",
      "1.7278304203696873\n",
      "Validation loss: 1.6416031122207642\n",
      "mse 1.641602901030937\n",
      "New best model found at epoch 23 with validation loss 1.6416031122207642\n",
      "Starting Epoch 24\n",
      "1.7245016927304475\n",
      "Validation loss: 1.6385223865509033\n",
      "mse 1.6385223498281765\n",
      "New best model found at epoch 24 with validation loss 1.6385223865509033\n",
      "Starting Epoch 25\n",
      "1.7214077244634214\n",
      "Validation loss: 1.6358352899551392\n",
      "mse 1.63583529151621\n",
      "New best model found at epoch 25 with validation loss 1.6358352899551392\n",
      "Starting Epoch 26\n",
      "1.7185184229975161\n",
      "Validation loss: 1.63307523727417\n",
      "mse 1.6330752759055065\n",
      "New best model found at epoch 26 with validation loss 1.63307523727417\n",
      "Starting Epoch 27\n",
      "1.7157539699388586\n",
      "Validation loss: 1.6306065320968628\n",
      "mse 1.6306065470179374\n",
      "New best model found at epoch 27 with validation loss 1.6306065320968628\n",
      "Starting Epoch 28\n",
      "1.7133869658345762\n",
      "Validation loss: 1.6282905340194702\n",
      "mse 1.6282905180325131\n",
      "New best model found at epoch 28 with validation loss 1.6282905340194702\n",
      "Starting Epoch 29\n",
      "1.7110298353692759\n",
      "Validation loss: 1.6265102624893188\n",
      "mse 1.626510256609842\n",
      "New best model found at epoch 29 with validation loss 1.6265102624893188\n",
      "Starting Epoch 30\n",
      "1.7087470241214917\n",
      "Validation loss: 1.6244730949401855\n",
      "mse 1.6244730456522853\n",
      "New best model found at epoch 30 with validation loss 1.6244730949401855\n",
      "Starting Epoch 31\n",
      "1.7066212633381719\n",
      "Validation loss: 1.6226903200149536\n",
      "mse 1.6226901771275133\n",
      "New best model found at epoch 31 with validation loss 1.6226903200149536\n",
      "Starting Epoch 32\n",
      "1.7046809248302295\n",
      "Validation loss: 1.620787501335144\n",
      "mse 1.6207875823792541\n",
      "New best model found at epoch 32 with validation loss 1.620787501335144\n",
      "Starting Epoch 33\n",
      "1.7028104533319888\n",
      "Validation loss: 1.6189502477645874\n",
      "mse 1.6189503081680816\n",
      "New best model found at epoch 33 with validation loss 1.6189502477645874\n",
      "Starting Epoch 34\n",
      "1.7009405830632085\n",
      "Validation loss: 1.6168015003204346\n",
      "mse 1.6168015374764064\n",
      "New best model found at epoch 34 with validation loss 1.6168015003204346\n",
      "Starting Epoch 35\n",
      "1.699173963588217\n",
      "Validation loss: 1.615490198135376\n",
      "mse 1.6154903686685307\n",
      "New best model found at epoch 35 with validation loss 1.615490198135376\n",
      "Starting Epoch 36\n",
      "1.6975703187610791\n",
      "Validation loss: 1.6136469841003418\n",
      "mse 1.613647086943638\n",
      "New best model found at epoch 36 with validation loss 1.6136469841003418\n",
      "Starting Epoch 37\n",
      "1.6960011461506719\n",
      "Validation loss: 1.611890196800232\n",
      "mse 1.611890236197713\n",
      "New best model found at epoch 37 with validation loss 1.611890196800232\n",
      "Starting Epoch 38\n",
      "1.6945797308631565\n",
      "Validation loss: 1.6105880737304688\n",
      "mse 1.6105878811860026\n",
      "New best model found at epoch 38 with validation loss 1.6105880737304688\n",
      "Starting Epoch 39\n",
      "1.6930342446202817\n",
      "Validation loss: 1.6091675758361816\n",
      "mse 1.6091674859536038\n",
      "New best model found at epoch 39 with validation loss 1.6091675758361816\n",
      "Starting Epoch 40\n",
      "1.6917789345202239\n",
      "Validation loss: 1.6080361604690552\n",
      "mse 1.6080361032289758\n",
      "New best model found at epoch 40 with validation loss 1.6080361604690552\n",
      "Starting Epoch 41\n",
      "1.6903696578481924\n",
      "Validation loss: 1.6066557168960571\n",
      "mse 1.6066556050254535\n",
      "New best model found at epoch 41 with validation loss 1.6066557168960571\n",
      "Starting Epoch 42\n",
      "1.6892727406128594\n",
      "Validation loss: 1.605269432067871\n",
      "mse 1.605269459518007\n",
      "New best model found at epoch 42 with validation loss 1.605269432067871\n",
      "Starting Epoch 43\n",
      "1.687940001487732\n",
      "Validation loss: 1.604268193244934\n",
      "mse 1.6042681658711975\n",
      "New best model found at epoch 43 with validation loss 1.604268193244934\n",
      "Starting Epoch 44\n",
      "1.6867737303609434\n",
      "Validation loss: 1.6030443906784058\n",
      "mse 1.60304457990715\n",
      "New best model found at epoch 44 with validation loss 1.6030443906784058\n",
      "Starting Epoch 45\n",
      "1.685640195141668\n",
      "Validation loss: 1.602181315422058\n",
      "mse 1.6021812694377082\n",
      "New best model found at epoch 45 with validation loss 1.602181315422058\n",
      "Starting Epoch 46\n",
      "1.684555400972781\n",
      "Validation loss: 1.600733995437622\n",
      "mse 1.6007340520648463\n",
      "New best model found at epoch 46 with validation loss 1.600733995437622\n",
      "Starting Epoch 47\n",
      "1.6835539703783782\n",
      "Validation loss: 1.5999516248703003\n",
      "mse 1.599951613925249\n",
      "New best model found at epoch 47 with validation loss 1.5999516248703003\n",
      "Starting Epoch 48\n",
      "1.6825066027433977\n",
      "Validation loss: 1.5987234115600586\n",
      "mse 1.5987233519926103\n",
      "New best model found at epoch 48 with validation loss 1.5987234115600586\n",
      "Starting Epoch 49\n",
      "1.6815509951632956\n",
      "Validation loss: 1.597872018814087\n",
      "mse 1.5978720039017063\n",
      "New best model found at epoch 49 with validation loss 1.597872018814087\n",
      "Starting Epoch 50\n",
      "1.680642060611559\n",
      "Validation loss: 1.5968831777572632\n",
      "mse 1.5968831853783636\n",
      "New best model found at epoch 50 with validation loss 1.5968831777572632\n",
      "Starting Epoch 51\n",
      "1.679734406263932\n",
      "Validation loss: 1.5959166288375854\n",
      "mse 1.5959166366963868\n",
      "New best model found at epoch 51 with validation loss 1.5959166288375854\n",
      "Starting Epoch 52\n",
      "1.678922767224519\n",
      "Validation loss: 1.5948587656021118\n",
      "mse 1.5948587464608406\n",
      "New best model found at epoch 52 with validation loss 1.5948587656021118\n",
      "Starting Epoch 53\n",
      "1.678086747293887\n",
      "Validation loss: 1.594205379486084\n",
      "mse 1.5942056211607356\n",
      "New best model found at epoch 53 with validation loss 1.594205379486084\n",
      "Starting Epoch 54\n",
      "1.6772496492966362\n",
      "Validation loss: 1.5932327508926392\n",
      "mse 1.5932328907185695\n",
      "New best model found at epoch 54 with validation loss 1.5932327508926392\n",
      "Starting Epoch 55\n",
      "1.6763901866000632\n",
      "Validation loss: 1.5924983024597168\n",
      "mse 1.5924984149496912\n",
      "New best model found at epoch 55 with validation loss 1.5924983024597168\n",
      "Starting Epoch 56\n",
      "1.6755908934966377\n",
      "Validation loss: 1.5916523933410645\n",
      "mse 1.5916523324974805\n",
      "New best model found at epoch 56 with validation loss 1.5916523933410645\n",
      "Starting Epoch 57\n",
      "1.6748110937035603\n",
      "Validation loss: 1.5909615755081177\n",
      "mse 1.5909614755272867\n",
      "New best model found at epoch 57 with validation loss 1.5909615755081177\n",
      "Starting Epoch 58\n",
      "1.6740220007689104\n",
      "Validation loss: 1.5899827480316162\n",
      "mse 1.5899827152718018\n",
      "New best model found at epoch 58 with validation loss 1.5899827480316162\n",
      "Starting Epoch 59\n",
      "1.6732575219610464\n",
      "Validation loss: 1.5893445014953613\n",
      "mse 1.5893444515855997\n",
      "New best model found at epoch 59 with validation loss 1.5893445014953613\n",
      "Starting Epoch 60\n",
      "1.6725668907165527\n",
      "Validation loss: 1.5885608196258545\n",
      "mse 1.5885608686588246\n",
      "New best model found at epoch 60 with validation loss 1.5885608196258545\n",
      "Starting Epoch 61\n",
      "1.6716917390408723\n",
      "Validation loss: 1.5874840021133423\n",
      "mse 1.5874840486064201\n",
      "New best model found at epoch 61 with validation loss 1.5874840021133423\n",
      "Starting Epoch 62\n",
      "1.671067071997601\n",
      "Validation loss: 1.5868929624557495\n",
      "mse 1.586892855544835\n",
      "New best model found at epoch 62 with validation loss 1.5868929624557495\n",
      "Starting Epoch 63\n",
      "1.6702047430950662\n",
      "Validation loss: 1.5859977006912231\n",
      "mse 1.5859978125182634\n",
      "New best model found at epoch 63 with validation loss 1.5859977006912231\n",
      "Starting Epoch 64\n",
      "1.6694701339887537\n",
      "Validation loss: 1.5851540565490723\n",
      "mse 1.5851542730057684\n",
      "New best model found at epoch 64 with validation loss 1.5851540565490723\n",
      "Starting Epoch 65\n",
      "1.6689069374747898\n",
      "Validation loss: 1.584285020828247\n",
      "mse 1.5842851225062224\n",
      "New best model found at epoch 65 with validation loss 1.584285020828247\n",
      "Starting Epoch 66\n",
      "1.668268462885981\n",
      "Validation loss: 1.5835927724838257\n",
      "mse 1.5835925609621415\n",
      "New best model found at epoch 66 with validation loss 1.5835927724838257\n",
      "Starting Epoch 67\n",
      "1.6675959929175999\n",
      "Validation loss: 1.582911491394043\n",
      "mse 1.5829115176496775\n",
      "New best model found at epoch 67 with validation loss 1.582911491394043\n",
      "Starting Epoch 68\n",
      "1.666919091473455\n",
      "Validation loss: 1.5821324586868286\n",
      "mse 1.5821323546224635\n",
      "New best model found at epoch 68 with validation loss 1.5821324586868286\n",
      "Starting Epoch 69\n",
      "1.6662627354912136\n",
      "Validation loss: 1.5815739631652832\n",
      "mse 1.581573926640701\n",
      "New best model found at epoch 69 with validation loss 1.5815739631652832\n",
      "Starting Epoch 70\n",
      "1.6655956299408623\n",
      "Validation loss: 1.5812766551971436\n",
      "mse 1.581276582165363\n",
      "New best model found at epoch 70 with validation loss 1.5812766551971436\n",
      "Starting Epoch 71\n",
      "1.6650666672250498\n",
      "Validation loss: 1.580883264541626\n",
      "mse 1.58088337965064\n",
      "New best model found at epoch 71 with validation loss 1.580883264541626\n",
      "Starting Epoch 72\n",
      "1.664405776106793\n",
      "Validation loss: 1.580271601676941\n",
      "mse 1.580271613706664\n",
      "New best model found at epoch 72 with validation loss 1.580271601676941\n",
      "Starting Epoch 73\n",
      "1.6638013331786445\n",
      "Validation loss: 1.579838514328003\n",
      "mse 1.5798386089660068\n",
      "New best model found at epoch 73 with validation loss 1.579838514328003\n",
      "Starting Epoch 74\n",
      "1.6632078626881475\n",
      "Validation loss: 1.5790666341781616\n",
      "mse 1.579066718583997\n",
      "New best model found at epoch 74 with validation loss 1.5790666341781616\n",
      "Starting Epoch 75\n",
      "1.6625354238178418\n",
      "Validation loss: 1.5787901878356934\n",
      "mse 1.5787901624799332\n",
      "New best model found at epoch 75 with validation loss 1.5787901878356934\n",
      "Starting Epoch 76\n",
      "1.6619581917057866\n",
      "Validation loss: 1.5783771276474\n",
      "mse 1.5783770552754077\n",
      "New best model found at epoch 76 with validation loss 1.5783771276474\n",
      "Starting Epoch 77\n",
      "1.6614502150079478\n",
      "Validation loss: 1.5776681900024414\n",
      "mse 1.5776682114177658\n",
      "New best model found at epoch 77 with validation loss 1.5776681900024414\n",
      "Starting Epoch 78\n",
      "1.660837992377903\n",
      "Validation loss: 1.5773561000823975\n",
      "mse 1.5773560540470821\n",
      "New best model found at epoch 78 with validation loss 1.5773561000823975\n",
      "Starting Epoch 79\n",
      "1.6603342864824377\n",
      "Validation loss: 1.5768849849700928\n",
      "mse 1.5768850157154861\n",
      "New best model found at epoch 79 with validation loss 1.5768849849700928\n",
      "Starting Epoch 80\n",
      "1.6597897384477698\n",
      "Validation loss: 1.576678991317749\n",
      "mse 1.5766791932048934\n",
      "New best model found at epoch 80 with validation loss 1.576678991317749\n",
      "Starting Epoch 81\n",
      "1.6593362766763438\n",
      "Validation loss: 1.5758745670318604\n",
      "mse 1.5758747486711304\n",
      "New best model found at epoch 81 with validation loss 1.5758745670318604\n",
      "Starting Epoch 82\n",
      "1.6589084086210832\n",
      "Validation loss: 1.5755401849746704\n",
      "mse 1.5755402213985406\n",
      "New best model found at epoch 82 with validation loss 1.5755401849746704\n",
      "Starting Epoch 83\n",
      "1.6583817108817722\n",
      "Validation loss: 1.575398564338684\n",
      "mse 1.5753985540323672\n",
      "New best model found at epoch 83 with validation loss 1.575398564338684\n",
      "Starting Epoch 84\n",
      "1.6579242115435393\n",
      "Validation loss: 1.5748822689056396\n",
      "mse 1.574882192435112\n",
      "New best model found at epoch 84 with validation loss 1.5748822689056396\n",
      "Starting Epoch 85\n",
      "1.657395336938941\n",
      "Validation loss: 1.574522614479065\n",
      "mse 1.5745224706395098\n",
      "New best model found at epoch 85 with validation loss 1.574522614479065\n",
      "Starting Epoch 86\n",
      "1.6570505007453586\n",
      "Validation loss: 1.5743743181228638\n",
      "mse 1.5743744048233899\n",
      "New best model found at epoch 86 with validation loss 1.5743743181228638\n",
      "Starting Epoch 87\n",
      "1.6566310032554294\n",
      "Validation loss: 1.5739351511001587\n",
      "mse 1.5739351024451285\n",
      "New best model found at epoch 87 with validation loss 1.5739351511001587\n",
      "Starting Epoch 88\n",
      "1.6561958375184431\n",
      "Validation loss: 1.5737924575805664\n",
      "mse 1.573792353363781\n",
      "New best model found at epoch 88 with validation loss 1.5737924575805664\n",
      "Starting Epoch 89\n",
      "1.6557764903358791\n",
      "Validation loss: 1.5728486776351929\n",
      "mse 1.572848661291979\n",
      "New best model found at epoch 89 with validation loss 1.5728486776351929\n",
      "Starting Epoch 90\n",
      "1.6553617508515068\n",
      "Validation loss: 1.5727968215942383\n",
      "mse 1.572796882106946\n",
      "New best model found at epoch 90 with validation loss 1.5727968215942383\n",
      "Starting Epoch 91\n",
      "1.6549819448719854\n",
      "Validation loss: 1.5723017454147339\n",
      "mse 1.57230174635551\n",
      "New best model found at epoch 91 with validation loss 1.5723017454147339\n",
      "Starting Epoch 92\n",
      "1.6546271469282068\n",
      "Validation loss: 1.5719753503799438\n",
      "mse 1.571975442796031\n",
      "New best model found at epoch 92 with validation loss 1.5719753503799438\n",
      "Starting Epoch 93\n",
      "1.6541102036185886\n",
      "Validation loss: 1.5717841386795044\n",
      "mse 1.5717841111084463\n",
      "New best model found at epoch 93 with validation loss 1.5717841386795044\n",
      "Starting Epoch 94\n",
      "1.65379958567412\n",
      "Validation loss: 1.5716015100479126\n",
      "mse 1.5716015810094213\n",
      "New best model found at epoch 94 with validation loss 1.5716015100479126\n",
      "Starting Epoch 95\n",
      "1.6534791355547698\n",
      "Validation loss: 1.5709646940231323\n",
      "mse 1.570964676934145\n",
      "New best model found at epoch 95 with validation loss 1.5709646940231323\n",
      "Starting Epoch 96\n",
      "1.6530654171238774\n",
      "Validation loss: 1.570965051651001\n",
      "mse 1.5709650868422744\n",
      "Starting Epoch 97\n",
      "1.65264920566393\n",
      "Validation loss: 1.5706089735031128\n",
      "mse 1.5706087931399297\n",
      "New best model found at epoch 97 with validation loss 1.5706089735031128\n",
      "Starting Epoch 98\n",
      "1.6523852244667385\n",
      "Validation loss: 1.5703519582748413\n",
      "mse 1.5703518847217222\n",
      "New best model found at epoch 98 with validation loss 1.5703519582748413\n",
      "Starting Epoch 99\n",
      "1.651977186617644\n",
      "Validation loss: 1.5702016353607178\n",
      "mse 1.5702015131115266\n",
      "New best model found at epoch 99 with validation loss 1.5702016353607178\n",
      "Starting Epoch 100\n",
      "1.651625368906104\n",
      "Validation loss: 1.569830060005188\n",
      "mse 1.5698302844630998\n",
      "New best model found at epoch 100 with validation loss 1.569830060005188\n",
      "Starting Epoch 101\n",
      "1.6513156994529392\n",
      "Validation loss: 1.569564700126648\n",
      "mse 1.5695647093575027\n",
      "New best model found at epoch 101 with validation loss 1.569564700126648\n",
      "Starting Epoch 102\n",
      "1.6509368782458098\n",
      "Validation loss: 1.569257378578186\n",
      "mse 1.569257387146038\n",
      "New best model found at epoch 102 with validation loss 1.569257378578186\n",
      "Starting Epoch 103\n",
      "1.6506125564160554\n",
      "Validation loss: 1.5691592693328857\n",
      "mse 1.5691592079601682\n",
      "New best model found at epoch 103 with validation loss 1.5691592693328857\n",
      "Starting Epoch 104\n",
      "1.6502681555955305\n",
      "Validation loss: 1.5686479806900024\n",
      "mse 1.5686480215865413\n",
      "New best model found at epoch 104 with validation loss 1.5686479806900024\n",
      "Starting Epoch 105\n",
      "1.6499446112176646\n",
      "Validation loss: 1.5683940649032593\n",
      "mse 1.5683940021117166\n",
      "New best model found at epoch 105 with validation loss 1.5683940649032593\n",
      "Starting Epoch 106\n",
      "1.6495874601861704\n",
      "Validation loss: 1.5682945251464844\n",
      "mse 1.568294466518248\n",
      "New best model found at epoch 106 with validation loss 1.5682945251464844\n",
      "Starting Epoch 107\n",
      "1.6491895343946374\n",
      "Validation loss: 1.567804217338562\n",
      "mse 1.5678042371231258\n",
      "New best model found at epoch 107 with validation loss 1.567804217338562\n",
      "Starting Epoch 108\n",
      "1.6488542297612065\n",
      "Validation loss: 1.5677047967910767\n",
      "mse 1.567704687394182\n",
      "New best model found at epoch 108 with validation loss 1.5677047967910767\n",
      "Starting Epoch 109\n",
      "1.6485637322716091\n",
      "Validation loss: 1.5672210454940796\n",
      "mse 1.567221057865544\n",
      "New best model found at epoch 109 with validation loss 1.5672210454940796\n",
      "Starting Epoch 110\n",
      "1.6481942249381023\n",
      "Validation loss: 1.5671391487121582\n",
      "mse 1.567139244304406\n",
      "New best model found at epoch 110 with validation loss 1.5671391487121582\n",
      "Starting Epoch 111\n",
      "1.647885006407033\n",
      "Validation loss: 1.5666502714157104\n",
      "mse 1.5666504645405297\n",
      "New best model found at epoch 111 with validation loss 1.5666502714157104\n",
      "Starting Epoch 112\n",
      "1.6474843802659407\n",
      "Validation loss: 1.5660747289657593\n",
      "mse 1.566074758368381\n",
      "New best model found at epoch 112 with validation loss 1.5660747289657593\n",
      "Starting Epoch 113\n",
      "1.6470785970273225\n",
      "Validation loss: 1.565919041633606\n",
      "mse 1.5659190593373862\n",
      "New best model found at epoch 113 with validation loss 1.565919041633606\n",
      "Starting Epoch 114\n",
      "1.6466710152833357\n",
      "Validation loss: 1.5654698610305786\n",
      "mse 1.5654701193160077\n",
      "New best model found at epoch 114 with validation loss 1.5654698610305786\n",
      "Starting Epoch 115\n",
      "1.6461797227030215\n",
      "Validation loss: 1.5647145509719849\n",
      "mse 1.5647146530319158\n",
      "New best model found at epoch 115 with validation loss 1.5647145509719849\n",
      "Starting Epoch 116\n",
      "1.645770197329314\n",
      "Validation loss: 1.564454436302185\n",
      "mse 1.5644543708484617\n",
      "New best model found at epoch 116 with validation loss 1.564454436302185\n",
      "Starting Epoch 117\n",
      "1.6453061725782312\n",
      "Validation loss: 1.5637730360031128\n",
      "mse 1.5637730395352996\n",
      "New best model found at epoch 117 with validation loss 1.5637730360031128\n",
      "Starting Epoch 118\n",
      "1.644913559374602\n",
      "Validation loss: 1.5634255409240723\n",
      "mse 1.5634254813544863\n",
      "New best model found at epoch 118 with validation loss 1.5634255409240723\n",
      "Starting Epoch 119\n",
      "1.6444477516671885\n",
      "Validation loss: 1.5632308721542358\n",
      "mse 1.563230839324283\n",
      "New best model found at epoch 119 with validation loss 1.5632308721542358\n",
      "Starting Epoch 120\n",
      "1.6442099965136985\n",
      "Validation loss: 1.5626716613769531\n",
      "mse 1.5626716466190163\n",
      "New best model found at epoch 120 with validation loss 1.5626716613769531\n",
      "Starting Epoch 121\n",
      "1.643798537876295\n",
      "Validation loss: 1.5625615119934082\n",
      "mse 1.5625614802214154\n",
      "New best model found at epoch 121 with validation loss 1.5625615119934082\n",
      "Starting Epoch 122\n",
      "1.643479523451432\n",
      "Validation loss: 1.5619717836380005\n",
      "mse 1.5619718586654419\n",
      "New best model found at epoch 122 with validation loss 1.5619717836380005\n",
      "Starting Epoch 123\n",
      "1.6431032367374585\n",
      "Validation loss: 1.5616300106048584\n",
      "mse 1.5616300024480894\n",
      "New best model found at epoch 123 with validation loss 1.5616300106048584\n",
      "Starting Epoch 124\n",
      "1.6427387413771257\n",
      "Validation loss: 1.5613495111465454\n",
      "mse 1.5613496308532169\n",
      "New best model found at epoch 124 with validation loss 1.5613495111465454\n",
      "Starting Epoch 125\n",
      "1.6424060748971028\n",
      "Validation loss: 1.560965657234192\n",
      "mse 1.5609656513850525\n",
      "New best model found at epoch 125 with validation loss 1.560965657234192\n",
      "Starting Epoch 126\n",
      "1.6420677382013071\n",
      "Validation loss: 1.5606621503829956\n",
      "mse 1.560662077365698\n",
      "New best model found at epoch 126 with validation loss 1.5606621503829956\n",
      "Starting Epoch 127\n",
      "1.6415970532790474\n",
      "Validation loss: 1.5603718757629395\n",
      "mse 1.5603718103957542\n",
      "New best model found at epoch 127 with validation loss 1.5603718757629395\n",
      "Starting Epoch 128\n",
      "1.6414214942766272\n",
      "Validation loss: 1.5599313974380493\n",
      "mse 1.5599314182274033\n",
      "New best model found at epoch 128 with validation loss 1.5599313974380493\n",
      "Starting Epoch 129\n",
      "1.6410296481588613\n",
      "Validation loss: 1.559546947479248\n",
      "mse 1.559547018291739\n",
      "New best model found at epoch 129 with validation loss 1.559546947479248\n",
      "Starting Epoch 130\n",
      "1.6406155669170877\n",
      "Validation loss: 1.5594487190246582\n",
      "mse 1.5594487019626926\n",
      "New best model found at epoch 130 with validation loss 1.5594487190246582\n",
      "Starting Epoch 131\n",
      "1.640340012052785\n",
      "Validation loss: 1.559149146080017\n",
      "mse 1.5591490707738649\n",
      "New best model found at epoch 131 with validation loss 1.559149146080017\n",
      "Starting Epoch 132\n",
      "1.6401312973188318\n",
      "Validation loss: 1.558734655380249\n",
      "mse 1.558734603586803\n",
      "New best model found at epoch 132 with validation loss 1.558734655380249\n",
      "Starting Epoch 133\n",
      "1.6397371965905894\n",
      "Validation loss: 1.558483362197876\n",
      "mse 1.558483373692267\n",
      "New best model found at epoch 133 with validation loss 1.558483362197876\n",
      "Starting Epoch 134\n",
      "1.639367533766705\n",
      "Validation loss: 1.5579938888549805\n",
      "mse 1.55799404542542\n",
      "New best model found at epoch 134 with validation loss 1.5579938888549805\n",
      "Starting Epoch 135\n",
      "1.6390214795651643\n",
      "Validation loss: 1.5579380989074707\n",
      "mse 1.5579380863654242\n",
      "New best model found at epoch 135 with validation loss 1.5579380989074707\n",
      "Starting Epoch 136\n",
      "1.63883464232735\n",
      "Validation loss: 1.5575555562973022\n",
      "mse 1.5575555518226423\n",
      "New best model found at epoch 136 with validation loss 1.5575555562973022\n",
      "Starting Epoch 137\n",
      "1.6384639118028723\n",
      "Validation loss: 1.5573962926864624\n",
      "mse 1.5573962669930637\n",
      "New best model found at epoch 137 with validation loss 1.5573962926864624\n",
      "Starting Epoch 138\n",
      "1.638216547344042\n",
      "Validation loss: 1.557235836982727\n",
      "mse 1.5572358745379073\n",
      "New best model found at epoch 138 with validation loss 1.557235836982727\n",
      "Starting Epoch 139\n",
      "1.6379304139510444\n",
      "Validation loss: 1.5567631721496582\n",
      "mse 1.5567631626898353\n",
      "New best model found at epoch 139 with validation loss 1.5567631721496582\n",
      "Starting Epoch 140\n",
      "1.637586464052615\n",
      "Validation loss: 1.556722640991211\n",
      "mse 1.5567226684219857\n",
      "New best model found at epoch 140 with validation loss 1.556722640991211\n",
      "Starting Epoch 141\n",
      "1.637312132379283\n",
      "Validation loss: 1.556326985359192\n",
      "mse 1.556326915490065\n",
      "New best model found at epoch 141 with validation loss 1.556326985359192\n",
      "Starting Epoch 142\n",
      "1.6370141298874565\n",
      "Validation loss: 1.556156873703003\n",
      "mse 1.5561568265029724\n",
      "New best model found at epoch 142 with validation loss 1.556156873703003\n",
      "Starting Epoch 143\n",
      "1.6366463433141294\n",
      "Validation loss: 1.5559239387512207\n",
      "mse 1.5559238749752673\n",
      "New best model found at epoch 143 with validation loss 1.5559239387512207\n",
      "Starting Epoch 144\n",
      "1.636427894882534\n",
      "Validation loss: 1.5557856559753418\n",
      "mse 1.5557856807181631\n",
      "New best model found at epoch 144 with validation loss 1.5557856559753418\n",
      "Starting Epoch 145\n",
      "1.6360656334006267\n",
      "Validation loss: 1.5554698705673218\n",
      "mse 1.5554698755530796\n",
      "New best model found at epoch 145 with validation loss 1.5554698705673218\n",
      "Starting Epoch 146\n",
      "1.6359205038651177\n",
      "Validation loss: 1.5552783012390137\n",
      "mse 1.5552782666113882\n",
      "New best model found at epoch 146 with validation loss 1.5552783012390137\n",
      "Starting Epoch 147\n",
      "1.6355699611746746\n",
      "Validation loss: 1.555067539215088\n",
      "mse 1.5550674661189465\n",
      "New best model found at epoch 147 with validation loss 1.555067539215088\n",
      "Starting Epoch 148\n",
      "1.6352976560592651\n",
      "Validation loss: 1.5553187131881714\n",
      "mse 1.5553186150541798\n",
      "Starting Epoch 149\n",
      "1.6350130775700444\n",
      "Validation loss: 1.554997205734253\n",
      "mse 1.5549969886774215\n",
      "New best model found at epoch 149 with validation loss 1.554997205734253\n",
      "Starting Epoch 150\n",
      "1.6347475414690764\n",
      "Validation loss: 1.5548418760299683\n",
      "mse 1.5548419098151691\n",
      "New best model found at epoch 150 with validation loss 1.5548418760299683\n",
      "Starting Epoch 151\n",
      "1.6345195459282917\n",
      "Validation loss: 1.5544233322143555\n",
      "mse 1.554423273461463\n",
      "New best model found at epoch 151 with validation loss 1.5544233322143555\n",
      "Starting Epoch 152\n",
      "1.6342483551605889\n",
      "Validation loss: 1.5546523332595825\n",
      "mse 1.5546521554595643\n",
      "Starting Epoch 153\n",
      "1.633967451427294\n",
      "Validation loss: 1.554174542427063\n",
      "mse 1.5541747493436875\n",
      "New best model found at epoch 153 with validation loss 1.554174542427063\n",
      "Starting Epoch 154\n",
      "1.6337981120399807\n",
      "Validation loss: 1.5544105768203735\n",
      "mse 1.5544106453301485\n",
      "Starting Epoch 155\n",
      "1.6334951701371565\n",
      "Validation loss: 1.5538122653961182\n",
      "mse 1.5538123281663752\n",
      "New best model found at epoch 155 with validation loss 1.5538122653961182\n",
      "Starting Epoch 156\n",
      "1.633212027342423\n",
      "Validation loss: 1.5539270639419556\n",
      "mse 1.5539272157712918\n",
      "Starting Epoch 157\n",
      "1.6330304612284121\n",
      "Validation loss: 1.5537477731704712\n",
      "mse 1.5537476665415586\n",
      "New best model found at epoch 157 with validation loss 1.5537477731704712\n",
      "Starting Epoch 158\n",
      "1.6327720284461975\n",
      "Validation loss: 1.5537062883377075\n",
      "mse 1.5537063681550225\n",
      "New best model found at epoch 158 with validation loss 1.5537062883377075\n",
      "Starting Epoch 159\n",
      "1.6324564451756685\n",
      "Validation loss: 1.5536385774612427\n",
      "mse 1.5536385857404313\n",
      "New best model found at epoch 159 with validation loss 1.5536385774612427\n",
      "Starting Epoch 160\n",
      "1.6322987908902375\n",
      "Validation loss: 1.5535202026367188\n",
      "mse 1.5535201267075045\n",
      "New best model found at epoch 160 with validation loss 1.5535202026367188\n",
      "Starting Epoch 161\n",
      "1.6320908795232358\n",
      "Validation loss: 1.5531858205795288\n",
      "mse 1.5531859108882136\n",
      "New best model found at epoch 161 with validation loss 1.5531858205795288\n",
      "Starting Epoch 162\n",
      "1.631808392379595\n",
      "Validation loss: 1.5532326698303223\n",
      "mse 1.5532327207720555\n",
      "Starting Epoch 163\n",
      "1.6315490214721016\n",
      "Validation loss: 1.5531867742538452\n",
      "mse 1.5531867900341056\n",
      "Starting Epoch 164\n",
      "1.631293351235597\n",
      "Validation loss: 1.552836298942566\n",
      "mse 1.5528362074721376\n",
      "New best model found at epoch 164 with validation loss 1.552836298942566\n",
      "Starting Epoch 165\n",
      "1.6310672163963318\n",
      "Validation loss: 1.5527135133743286\n",
      "mse 1.5527135656370608\n",
      "New best model found at epoch 165 with validation loss 1.5527135133743286\n",
      "Starting Epoch 166\n",
      "1.6308267246121946\n",
      "Validation loss: 1.552525520324707\n",
      "mse 1.5525255791385946\n",
      "New best model found at epoch 166 with validation loss 1.552525520324707\n",
      "Starting Epoch 167\n",
      "1.6305747731872227\n",
      "Validation loss: 1.5523852109909058\n",
      "mse 1.5523852282377157\n",
      "New best model found at epoch 167 with validation loss 1.5523852109909058\n",
      "Starting Epoch 168\n",
      "1.6304006369217583\n",
      "Validation loss: 1.5522644519805908\n",
      "mse 1.5522644075574745\n",
      "New best model found at epoch 168 with validation loss 1.5522644519805908\n",
      "Starting Epoch 169\n",
      "1.6301155945529109\n",
      "Validation loss: 1.552058219909668\n",
      "mse 1.552058191573012\n",
      "New best model found at epoch 169 with validation loss 1.552058219909668\n",
      "Starting Epoch 170\n",
      "1.6299319189527761\n",
      "Validation loss: 1.5517261028289795\n",
      "mse 1.551726060941374\n",
      "New best model found at epoch 170 with validation loss 1.5517261028289795\n",
      "Starting Epoch 171\n",
      "1.6296451506407366\n",
      "Validation loss: 1.5517154932022095\n",
      "mse 1.5517153856557424\n",
      "New best model found at epoch 171 with validation loss 1.5517154932022095\n",
      "Starting Epoch 172\n",
      "1.6294001936912537\n",
      "Validation loss: 1.5514200925827026\n",
      "mse 1.5514201895783728\n",
      "New best model found at epoch 172 with validation loss 1.5514200925827026\n",
      "Starting Epoch 173\n",
      "1.6291930649591528\n",
      "Validation loss: 1.5513802766799927\n",
      "mse 1.5513803695681232\n",
      "New best model found at epoch 173 with validation loss 1.5513802766799927\n",
      "Starting Epoch 174\n",
      "1.6289705297221309\n",
      "Validation loss: 1.5510883331298828\n",
      "mse 1.5510883136990083\n",
      "New best model found at epoch 174 with validation loss 1.5510883331298828\n",
      "Starting Epoch 175\n",
      "1.628608745077382\n",
      "Validation loss: 1.5509352684020996\n",
      "mse 1.5509351479281293\n",
      "New best model found at epoch 175 with validation loss 1.5509352684020996\n",
      "Starting Epoch 176\n",
      "1.628340244293213\n",
      "Validation loss: 1.5505913496017456\n",
      "mse 1.550591422351236\n",
      "New best model found at epoch 176 with validation loss 1.5505913496017456\n",
      "Starting Epoch 177\n",
      "1.6280424698539402\n",
      "Validation loss: 1.5500859022140503\n",
      "mse 1.5500857971468591\n",
      "New best model found at epoch 177 with validation loss 1.5500859022140503\n",
      "Starting Epoch 178\n",
      "1.6277350005896196\n",
      "Validation loss: 1.5497963428497314\n",
      "mse 1.5497964373342294\n",
      "New best model found at epoch 178 with validation loss 1.5497963428497314\n",
      "Starting Epoch 179\n",
      "1.6273823717366094\n",
      "Validation loss: 1.5496386289596558\n",
      "mse 1.5496386545495358\n",
      "New best model found at epoch 179 with validation loss 1.5496386289596558\n",
      "Starting Epoch 180\n",
      "1.627071378023728\n",
      "Validation loss: 1.5490599870681763\n",
      "mse 1.5490600031476087\n",
      "New best model found at epoch 180 with validation loss 1.5490599870681763\n",
      "Starting Epoch 181\n",
      "1.6267936566601628\n",
      "Validation loss: 1.54892098903656\n",
      "mse 1.5489209216276558\n",
      "New best model found at epoch 181 with validation loss 1.54892098903656\n",
      "Starting Epoch 182\n",
      "1.6264840882757436\n",
      "Validation loss: 1.5486317873001099\n",
      "mse 1.5486317813276183\n",
      "New best model found at epoch 182 with validation loss 1.5486317873001099\n",
      "Starting Epoch 183\n",
      "1.6261473920034326\n",
      "Validation loss: 1.5486139059066772\n",
      "mse 1.5486136749581942\n",
      "New best model found at epoch 183 with validation loss 1.5486139059066772\n",
      "Starting Epoch 184\n",
      "1.6253223030463508\n",
      "Validation loss: 1.5486236810684204\n",
      "mse 1.5486237249081691\n",
      "Starting Epoch 185\n",
      "1.6246475136798362\n",
      "Validation loss: 1.548301339149475\n",
      "mse 1.5483012880485414\n",
      "New best model found at epoch 185 with validation loss 1.548301339149475\n",
      "Starting Epoch 186\n",
      "1.6243842814279639\n",
      "Validation loss: 1.54800546169281\n",
      "mse 1.5480053443033066\n",
      "New best model found at epoch 186 with validation loss 1.54800546169281\n",
      "Starting Epoch 187\n",
      "1.6240720101024793\n",
      "Validation loss: 1.5473837852478027\n",
      "mse 1.5473837835362656\n",
      "New best model found at epoch 187 with validation loss 1.5473837852478027\n",
      "Starting Epoch 188\n",
      "1.6236667555311453\n",
      "Validation loss: 1.5464555025100708\n",
      "mse 1.5464556372685334\n",
      "New best model found at epoch 188 with validation loss 1.5464555025100708\n",
      "Starting Epoch 189\n",
      "1.6232950065446936\n",
      "Validation loss: 1.5462216138839722\n",
      "mse 1.5462214600537891\n",
      "New best model found at epoch 189 with validation loss 1.5462216138839722\n",
      "Starting Epoch 190\n",
      "1.6230371957239897\n",
      "Validation loss: 1.5459895133972168\n",
      "mse 1.5459895845604055\n",
      "New best model found at epoch 190 with validation loss 1.5459895133972168\n",
      "Starting Epoch 191\n",
      "1.6227494711461274\n",
      "Validation loss: 1.5458805561065674\n",
      "mse 1.5458806091865853\n",
      "New best model found at epoch 191 with validation loss 1.5458805561065674\n",
      "Starting Epoch 192\n",
      "1.6225093836369722\n",
      "Validation loss: 1.5459320545196533\n",
      "mse 1.5459320185101513\n",
      "Starting Epoch 193\n",
      "1.6223095292630403\n",
      "Validation loss: 1.5454620122909546\n",
      "mse 1.5454620671091033\n",
      "New best model found at epoch 193 with validation loss 1.5454620122909546\n",
      "Starting Epoch 194\n",
      "1.6220713802005933\n",
      "Validation loss: 1.5456645488739014\n",
      "mse 1.5456645391935153\n",
      "Starting Epoch 195\n",
      "1.6218577597452246\n",
      "Validation loss: 1.5451781749725342\n",
      "mse 1.5451780883123463\n",
      "New best model found at epoch 195 with validation loss 1.5451781749725342\n",
      "Starting Epoch 196\n",
      "1.6216400213863538\n",
      "Validation loss: 1.5452446937561035\n",
      "mse 1.5452447399271563\n",
      "Starting Epoch 197\n",
      "1.6214132697685906\n",
      "Validation loss: 1.5447813272476196\n",
      "mse 1.544781205108577\n",
      "New best model found at epoch 197 with validation loss 1.5447813272476196\n",
      "Starting Epoch 198\n",
      "1.6211934815282407\n",
      "Validation loss: 1.5450196266174316\n",
      "mse 1.5450195307643197\n",
      "Starting Epoch 199\n",
      "1.6209198754766714\n",
      "Validation loss: 1.544631838798523\n",
      "mse 1.544631799530738\n",
      "New best model found at epoch 199 with validation loss 1.544631838798523\n",
      "Starting Epoch 200\n",
      "1.6208185216654902\n",
      "Validation loss: 1.5446363687515259\n",
      "mse 1.5446362142732324\n",
      "Starting Epoch 201\n",
      "1.62052423539369\n",
      "Validation loss: 1.544541358947754\n",
      "mse 1.5445412242153629\n",
      "New best model found at epoch 201 with validation loss 1.544541358947754\n",
      "Starting Epoch 202\n",
      "1.6203115867531819\n",
      "Validation loss: 1.5441797971725464\n",
      "mse 1.5441798130746252\n",
      "New best model found at epoch 202 with validation loss 1.5441797971725464\n",
      "Starting Epoch 203\n",
      "1.6200752258300781\n",
      "Validation loss: 1.544245958328247\n",
      "mse 1.5442459058326654\n",
      "Starting Epoch 204\n",
      "1.6198402928269429\n",
      "Validation loss: 1.5442354679107666\n",
      "mse 1.5442353640166622\n",
      "Starting Epoch 205\n",
      "1.6196418871050295\n",
      "Validation loss: 1.5437673330307007\n",
      "mse 1.5437673490112978\n",
      "New best model found at epoch 205 with validation loss 1.5437673330307007\n",
      "Starting Epoch 206\n",
      "1.6193960568179255\n",
      "Validation loss: 1.5438461303710938\n",
      "mse 1.543846177411781\n",
      "Starting Epoch 207\n",
      "1.619191288948059\n",
      "Validation loss: 1.543923020362854\n",
      "mse 1.543923015161267\n",
      "Starting Epoch 208\n",
      "1.6189567213473113\n",
      "Validation loss: 1.543581485748291\n",
      "mse 1.5435812686987849\n",
      "New best model found at epoch 208 with validation loss 1.543581485748291\n",
      "Starting Epoch 209\n",
      "1.61875653785208\n",
      "Validation loss: 1.5438618659973145\n",
      "mse 1.5438617806554762\n",
      "Starting Epoch 210\n",
      "1.6186220671819604\n",
      "Validation loss: 1.5437952280044556\n",
      "mse 1.543795036881489\n",
      "Starting Epoch 211\n",
      "1.618360242118006\n",
      "Validation loss: 1.5433541536331177\n",
      "mse 1.5433542733825811\n",
      "New best model found at epoch 211 with validation loss 1.5433541536331177\n",
      "Starting Epoch 212\n",
      "1.618112343808879\n",
      "Validation loss: 1.5436056852340698\n",
      "mse 1.5436057541173123\n",
      "Starting Epoch 213\n",
      "1.6179949926293415\n",
      "Validation loss: 1.543276071548462\n",
      "mse 1.5432759227430835\n",
      "New best model found at epoch 213 with validation loss 1.543276071548462\n",
      "Starting Epoch 214\n",
      "1.6176924550014993\n",
      "Validation loss: 1.5430903434753418\n",
      "mse 1.5430903770963469\n",
      "New best model found at epoch 214 with validation loss 1.5430903434753418\n",
      "Starting Epoch 215\n",
      "1.6174785805785137\n",
      "Validation loss: 1.5429943799972534\n",
      "mse 1.5429942495533762\n",
      "New best model found at epoch 215 with validation loss 1.5429943799972534\n",
      "Starting Epoch 216\n",
      "1.6172922124033389\n",
      "Validation loss: 1.5428298711776733\n",
      "mse 1.5428299332263697\n",
      "New best model found at epoch 216 with validation loss 1.5428298711776733\n",
      "Starting Epoch 217\n",
      "1.616958138735398\n",
      "Validation loss: 1.542757272720337\n",
      "mse 1.5427571409736758\n",
      "New best model found at epoch 217 with validation loss 1.542757272720337\n",
      "Starting Epoch 218\n",
      "1.6167220965675686\n",
      "Validation loss: 1.5426701307296753\n",
      "mse 1.5426701425169171\n",
      "New best model found at epoch 218 with validation loss 1.5426701307296753\n",
      "Starting Epoch 219\n",
      "1.6165876440379932\n",
      "Validation loss: 1.5424758195877075\n",
      "mse 1.5424758895065525\n",
      "New best model found at epoch 219 with validation loss 1.5424758195877075\n",
      "Starting Epoch 220\n",
      "1.616311094035273\n",
      "Validation loss: 1.5424110889434814\n",
      "mse 1.5424112013617324\n",
      "New best model found at epoch 220 with validation loss 1.5424110889434814\n",
      "Starting Epoch 221\n",
      "1.616039496401082\n",
      "Validation loss: 1.5421996116638184\n",
      "mse 1.5421994635472809\n",
      "New best model found at epoch 221 with validation loss 1.5421996116638184\n",
      "Starting Epoch 222\n",
      "1.6158327382543813\n",
      "Validation loss: 1.5421112775802612\n",
      "mse 1.542111312031074\n",
      "New best model found at epoch 222 with validation loss 1.5421112775802612\n",
      "Starting Epoch 223\n",
      "1.6156058259632275\n",
      "Validation loss: 1.5419275760650635\n",
      "mse 1.5419275431208295\n",
      "New best model found at epoch 223 with validation loss 1.5419275760650635\n",
      "Starting Epoch 224\n",
      "1.6153395979300789\n",
      "Validation loss: 1.5419362783432007\n",
      "mse 1.5419363110764426\n",
      "Starting Epoch 225\n",
      "1.6151980394902437\n",
      "Validation loss: 1.5415552854537964\n",
      "mse 1.5415553855705593\n",
      "New best model found at epoch 225 with validation loss 1.5415552854537964\n",
      "Starting Epoch 226\n",
      "1.6148819975231006\n",
      "Validation loss: 1.5414341688156128\n",
      "mse 1.5414342483107697\n",
      "New best model found at epoch 226 with validation loss 1.5414341688156128\n",
      "Starting Epoch 227\n",
      "1.6146436307741248\n",
      "Validation loss: 1.541367769241333\n",
      "mse 1.5413677076918917\n",
      "New best model found at epoch 227 with validation loss 1.541367769241333\n",
      "Starting Epoch 228\n",
      "1.614412932292275\n",
      "Validation loss: 1.5412399768829346\n",
      "mse 1.5412399007402433\n",
      "New best model found at epoch 228 with validation loss 1.5412399768829346\n",
      "Starting Epoch 229\n",
      "1.6141624865324602\n",
      "Validation loss: 1.5410523414611816\n",
      "mse 1.541052234112735\n",
      "New best model found at epoch 229 with validation loss 1.5410523414611816\n",
      "Starting Epoch 230\n",
      "1.6139449243960173\n",
      "Validation loss: 1.54094660282135\n",
      "mse 1.5409464878985024\n",
      "New best model found at epoch 230 with validation loss 1.54094660282135\n",
      "Starting Epoch 231\n",
      "1.6137929351433464\n",
      "Validation loss: 1.5408086776733398\n",
      "mse 1.5408088520857244\n",
      "New best model found at epoch 231 with validation loss 1.5408086776733398\n",
      "Starting Epoch 232\n",
      "1.6135515078254368\n",
      "Validation loss: 1.5406060218811035\n",
      "mse 1.5406059791525868\n",
      "New best model found at epoch 232 with validation loss 1.5406060218811035\n",
      "Starting Epoch 233\n",
      "1.61326664686203\n",
      "Validation loss: 1.5405774116516113\n",
      "mse 1.540577422777274\n",
      "New best model found at epoch 233 with validation loss 1.5405774116516113\n",
      "Starting Epoch 234\n",
      "1.6131757653277854\n",
      "Validation loss: 1.5401864051818848\n",
      "mse 1.5401864146668218\n",
      "New best model found at epoch 234 with validation loss 1.5401864051818848\n",
      "Starting Epoch 235\n",
      "1.6128318724424944\n",
      "Validation loss: 1.5401524305343628\n",
      "mse 1.5401523156080785\n",
      "New best model found at epoch 235 with validation loss 1.5401524305343628\n",
      "Starting Epoch 236\n",
      "1.61260491868724\n",
      "Validation loss: 1.5399466753005981\n",
      "mse 1.5399465749353864\n",
      "New best model found at epoch 236 with validation loss 1.5399466753005981\n",
      "Starting Epoch 237\n",
      "1.6124145155367644\n",
      "Validation loss: 1.5398356914520264\n",
      "mse 1.5398355519255407\n",
      "New best model found at epoch 237 with validation loss 1.5398356914520264\n",
      "Starting Epoch 238\n",
      "1.6121555514957593\n",
      "Validation loss: 1.539679765701294\n",
      "mse 1.539679787900237\n",
      "New best model found at epoch 238 with validation loss 1.539679765701294\n",
      "Starting Epoch 239\n",
      "1.6119937689408013\n",
      "Validation loss: 1.5396051406860352\n",
      "mse 1.5396051722862527\n",
      "New best model found at epoch 239 with validation loss 1.5396051406860352\n",
      "Starting Epoch 240\n",
      "1.6117062775985054\n",
      "Validation loss: 1.5393320322036743\n",
      "mse 1.5393320312404706\n",
      "New best model found at epoch 240 with validation loss 1.5393320322036743\n",
      "Starting Epoch 241\n",
      "1.6114932246830151\n",
      "Validation loss: 1.5394171476364136\n",
      "mse 1.5394170336722952\n",
      "Starting Epoch 242\n",
      "1.6112301297809766\n",
      "Validation loss: 1.5392330884933472\n",
      "mse 1.5392331664427925\n",
      "New best model found at epoch 242 with validation loss 1.5392330884933472\n",
      "Starting Epoch 243\n",
      "1.611061446044756\n",
      "Validation loss: 1.5388917922973633\n",
      "mse 1.5388916262523689\n",
      "New best model found at epoch 243 with validation loss 1.5388917922973633\n",
      "Starting Epoch 244\n",
      "1.610818036224531\n",
      "Validation loss: 1.5387814044952393\n",
      "mse 1.538781519653341\n",
      "New best model found at epoch 244 with validation loss 1.5387814044952393\n",
      "Starting Epoch 245\n",
      "1.6106154037558513\n",
      "Validation loss: 1.538730263710022\n",
      "mse 1.538730239863342\n",
      "New best model found at epoch 245 with validation loss 1.538730263710022\n",
      "Starting Epoch 246\n",
      "1.6104529189026875\n",
      "Validation loss: 1.5385545492172241\n",
      "mse 1.5385545944880412\n",
      "New best model found at epoch 246 with validation loss 1.5385545492172241\n",
      "Starting Epoch 247\n",
      "1.6101003677948662\n",
      "Validation loss: 1.5383496284484863\n",
      "mse 1.5383495612882736\n",
      "New best model found at epoch 247 with validation loss 1.5383496284484863\n",
      "Starting Epoch 248\n",
      "1.6099434365396914\n",
      "Validation loss: 1.538313388824463\n",
      "mse 1.5383134094917075\n",
      "New best model found at epoch 248 with validation loss 1.538313388824463\n",
      "Starting Epoch 249\n",
      "1.6097534998603489\n",
      "Validation loss: 1.5380827188491821\n",
      "mse 1.538082793596174\n",
      "New best model found at epoch 249 with validation loss 1.5380827188491821\n",
      "Starting Epoch 250\n",
      "1.6095233689183774\n",
      "Validation loss: 1.5380535125732422\n",
      "mse 1.5380535592535458\n",
      "New best model found at epoch 250 with validation loss 1.5380535125732422\n",
      "Starting Epoch 251\n",
      "1.6092631687288699\n",
      "Validation loss: 1.537975549697876\n",
      "mse 1.5379756959253426\n",
      "New best model found at epoch 251 with validation loss 1.537975549697876\n",
      "Starting Epoch 252\n",
      "1.6091192494268003\n",
      "Validation loss: 1.5380769968032837\n",
      "mse 1.5380770706281794\n",
      "Starting Epoch 253\n",
      "1.608864426612854\n",
      "Validation loss: 1.5377627611160278\n",
      "mse 1.5377626628778704\n",
      "New best model found at epoch 253 with validation loss 1.5377627611160278\n",
      "Starting Epoch 254\n",
      "1.6086310200069263\n",
      "Validation loss: 1.5375128984451294\n",
      "mse 1.5375129613919656\n",
      "New best model found at epoch 254 with validation loss 1.5375128984451294\n",
      "Starting Epoch 255\n",
      "1.608357699021049\n",
      "Validation loss: 1.5375308990478516\n",
      "mse 1.5375307746832305\n",
      "Starting Epoch 256\n",
      "1.608096270457558\n",
      "Validation loss: 1.537374496459961\n",
      "mse 1.537374428647756\n",
      "New best model found at epoch 256 with validation loss 1.537374496459961\n",
      "Starting Epoch 257\n",
      "1.6078963305639185\n",
      "Validation loss: 1.5375940799713135\n",
      "mse 1.537594136734822\n",
      "Starting Epoch 258\n",
      "1.6075636018877444\n",
      "Validation loss: 1.5376911163330078\n",
      "mse 1.5376910800537555\n",
      "Starting Epoch 259\n",
      "1.6073322736698648\n",
      "Validation loss: 1.53745436668396\n",
      "mse 1.5374544231994667\n",
      "Starting Epoch 260\n",
      "1.6070136557454648\n",
      "Validation loss: 1.5377671718597412\n",
      "mse 1.537767227302569\n",
      "Starting Epoch 261\n",
      "1.6067057329675425\n",
      "Validation loss: 1.5377449989318848\n",
      "mse 1.5377449367123057\n",
      "Starting Epoch 262\n",
      "1.6065458137056101\n",
      "Validation loss: 1.5377143621444702\n",
      "mse 1.537714347585915\n",
      "Starting Epoch 263\n",
      "1.6062699089879575\n",
      "Validation loss: 1.5379142761230469\n",
      "mse 1.5379143207071226\n",
      "Starting Epoch 264\n",
      "1.6060341544773267\n",
      "Validation loss: 1.537770390510559\n",
      "mse 1.537770496736113\n",
      "Starting Epoch 265\n",
      "1.6057689189910889\n",
      "Validation loss: 1.5379064083099365\n",
      "mse 1.537906441755404\n",
      "Starting Epoch 266\n",
      "1.6055178564527761\n",
      "Validation loss: 1.5382575988769531\n",
      "mse 1.5382575532956884\n",
      "Starting Epoch 267\n",
      "1.6052581745645274\n",
      "Validation loss: 1.538084864616394\n",
      "mse 1.5380847965669517\n",
      "Starting Epoch 268\n",
      "1.6050530412922734\n",
      "Validation loss: 1.538163185119629\n",
      "mse 1.5381632016074998\n",
      "Starting Epoch 269\n",
      "1.604775167029837\n",
      "Validation loss: 1.5377949476242065\n",
      "mse 1.5377949865275347\n",
      "Starting Epoch 270\n",
      "1.6045138213945471\n",
      "Validation loss: 1.5378389358520508\n",
      "mse 1.537838869777312\n",
      "Starting Epoch 271\n",
      "1.6042325341183206\n",
      "Validation loss: 1.5380223989486694\n",
      "mse 1.538022350384444\n",
      "Starting Epoch 272\n",
      "1.6040276807287466\n",
      "Validation loss: 1.5382612943649292\n",
      "mse 1.5382613233945421\n",
      "Starting Epoch 273\n",
      "1.6038602279580159\n",
      "Validation loss: 1.5377856492996216\n",
      "mse 1.5377855492653423\n",
      "Starting Epoch 274\n",
      "1.603526524875475\n",
      "Validation loss: 1.5378514528274536\n",
      "mse 1.5378512075228552\n",
      "Starting Epoch 275\n",
      "1.6032750321471172\n",
      "Validation loss: 1.5378050804138184\n",
      "mse 1.5378050305024207\n",
      "Starting Epoch 276\n",
      "1.6030588746070862\n",
      "Validation loss: 1.5377488136291504\n",
      "mse 1.5377488823789602\n",
      "Starting Epoch 277\n",
      "1.602819852207018\n",
      "Validation loss: 1.5374658107757568\n",
      "mse 1.5374658330704076\n",
      "Starting Epoch 278\n",
      "1.6024798621302065\n",
      "Validation loss: 1.537706732749939\n",
      "mse 1.5377067851892645\n",
      "Starting Epoch 279\n",
      "1.602344124213509\n",
      "Validation loss: 1.537250280380249\n",
      "mse 1.537250255964087\n",
      "New best model found at epoch 279 with validation loss 1.537250280380249\n",
      "Starting Epoch 280\n",
      "1.6019502411717954\n",
      "Validation loss: 1.537688970565796\n",
      "mse 1.537689187512123\n",
      "Starting Epoch 281\n",
      "1.6017899254094\n",
      "Validation loss: 1.5368596315383911\n",
      "mse 1.536859654384651\n",
      "New best model found at epoch 281 with validation loss 1.5368596315383911\n",
      "Starting Epoch 282\n",
      "1.6015184055203977\n",
      "Validation loss: 1.5371862649917603\n",
      "mse 1.5371863850587042\n",
      "Starting Epoch 283\n",
      "1.6011992122816003\n",
      "Validation loss: 1.5371646881103516\n",
      "mse 1.5371647726032716\n",
      "Starting Epoch 284\n",
      "1.6009989432666614\n",
      "Validation loss: 1.53693425655365\n",
      "mse 1.5369343874024846\n",
      "Starting Epoch 285\n",
      "1.6007549659065579\n",
      "Validation loss: 1.536786675453186\n",
      "mse 1.5367867291576702\n",
      "New best model found at epoch 285 with validation loss 1.536786675453186\n",
      "Starting Epoch 286\n",
      "1.6004348604575447\n",
      "Validation loss: 1.5367817878723145\n",
      "mse 1.5367817941436714\n",
      "New best model found at epoch 286 with validation loss 1.5367817878723145\n",
      "Starting Epoch 287\n",
      "1.6002816454223965\n",
      "Validation loss: 1.5365976095199585\n",
      "mse 1.5365975912854801\n",
      "New best model found at epoch 287 with validation loss 1.5365976095199585\n",
      "Starting Epoch 288\n",
      "1.6000265427257703\n",
      "Validation loss: 1.5363895893096924\n",
      "mse 1.536389522497531\n",
      "New best model found at epoch 288 with validation loss 1.5363895893096924\n",
      "Starting Epoch 289\n",
      "1.599734796130139\n",
      "Validation loss: 1.5364629030227661\n",
      "mse 1.5364628805241238\n",
      "Starting Epoch 290\n",
      "1.5994720433069312\n",
      "Validation loss: 1.5362229347229004\n",
      "mse 1.5362229258705862\n",
      "New best model found at epoch 290 with validation loss 1.5362229347229004\n",
      "Starting Epoch 291\n",
      "1.599116123240927\n",
      "Validation loss: 1.5363370180130005\n",
      "mse 1.5363369661081256\n",
      "Starting Epoch 292\n",
      "1.598935269791147\n",
      "Validation loss: 1.5363876819610596\n",
      "mse 1.5363878278943608\n",
      "Starting Epoch 293\n",
      "1.5987524597541145\n",
      "Validation loss: 1.5357725620269775\n",
      "mse 1.5357726117007482\n",
      "New best model found at epoch 293 with validation loss 1.5357725620269775\n",
      "Starting Epoch 294\n",
      "1.5983780052350915\n",
      "Validation loss: 1.5357617139816284\n",
      "mse 1.5357616636713918\n",
      "New best model found at epoch 294 with validation loss 1.5357617139816284\n",
      "Starting Epoch 295\n",
      "1.5981681891109631\n",
      "Validation loss: 1.5357850790023804\n",
      "mse 1.5357850860810012\n",
      "Starting Epoch 296\n",
      "1.597914001216059\n",
      "Validation loss: 1.5354398488998413\n",
      "mse 1.5354399667018233\n",
      "New best model found at epoch 296 with validation loss 1.5354398488998413\n",
      "Starting Epoch 297\n",
      "1.5976330508356509\n",
      "Validation loss: 1.5354658365249634\n",
      "mse 1.5354657623577248\n",
      "Starting Epoch 298\n",
      "1.5974092120709626\n",
      "Validation loss: 1.5351120233535767\n",
      "mse 1.5351121563111518\n",
      "New best model found at epoch 298 with validation loss 1.5351120233535767\n",
      "Starting Epoch 299\n",
      "1.597078906453174\n",
      "Validation loss: 1.5353766679763794\n",
      "mse 1.5353765921196352\n",
      "Starting Epoch 300\n",
      "1.5968752529310144\n",
      "Validation loss: 1.5348753929138184\n",
      "mse 1.5348754115323273\n",
      "New best model found at epoch 300 with validation loss 1.5348753929138184\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-min: 7-60-40-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e4960",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 60 - 40 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "36dadd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "501b08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,6,12]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,6,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "4e6125ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'max(container counts)', 'max(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "9bf7c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "bed40240-ff36-401d-9b7e-6ad4105ab158",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.093698045481806\n",
      "Validation loss: 2.4301068782806396\n",
      "mse 2.4301069099988664\n",
      "New best model found at epoch 1 with validation loss 2.4301068782806396\n",
      "Starting Epoch 2\n",
      "2.507859504741171\n",
      "Validation loss: 2.130948305130005\n",
      "mse 2.130948296750681\n",
      "New best model found at epoch 2 with validation loss 2.130948305130005\n",
      "Starting Epoch 3\n",
      "2.2079834575238437\n",
      "Validation loss: 1.8918068408966064\n",
      "mse 1.891806690305907\n",
      "New best model found at epoch 3 with validation loss 1.8918068408966064\n",
      "Starting Epoch 4\n",
      "2.0081641000250112\n",
      "Validation loss: 1.7701005935668945\n",
      "mse 1.7701005236880658\n",
      "New best model found at epoch 4 with validation loss 1.7701005935668945\n",
      "Starting Epoch 5\n",
      "1.8964863238127336\n",
      "Validation loss: 1.7025766372680664\n",
      "mse 1.702576604973236\n",
      "New best model found at epoch 5 with validation loss 1.7025766372680664\n",
      "Starting Epoch 6\n",
      "1.82881876696711\n",
      "Validation loss: 1.6601964235305786\n",
      "mse 1.660196540769032\n",
      "New best model found at epoch 6 with validation loss 1.6601964235305786\n",
      "Starting Epoch 7\n",
      "1.7821127953736677\n",
      "Validation loss: 1.6334357261657715\n",
      "mse 1.6334358195262422\n",
      "New best model found at epoch 7 with validation loss 1.6334357261657715\n",
      "Starting Epoch 8\n",
      "1.7514834974123084\n",
      "Validation loss: 1.6157885789871216\n",
      "mse 1.6157885909955918\n",
      "New best model found at epoch 8 with validation loss 1.6157885789871216\n",
      "Starting Epoch 9\n",
      "1.729220986366272\n",
      "Validation loss: 1.601194143295288\n",
      "mse 1.6011942209207193\n",
      "New best model found at epoch 9 with validation loss 1.601194143295288\n",
      "Starting Epoch 10\n",
      "1.7117046117782593\n",
      "Validation loss: 1.5900903940200806\n",
      "mse 1.5900904124193376\n",
      "New best model found at epoch 10 with validation loss 1.5900903940200806\n",
      "Starting Epoch 11\n",
      "1.6978008073309194\n",
      "Validation loss: 1.5803216695785522\n",
      "mse 1.5803215279628267\n",
      "New best model found at epoch 11 with validation loss 1.5803216695785522\n",
      "Starting Epoch 12\n",
      "1.6850418837174126\n",
      "Validation loss: 1.5725977420806885\n",
      "mse 1.5725976444459846\n",
      "New best model found at epoch 12 with validation loss 1.5725977420806885\n",
      "Starting Epoch 13\n",
      "1.6736235929572063\n",
      "Validation loss: 1.564481496810913\n",
      "mse 1.5644815421997094\n",
      "New best model found at epoch 13 with validation loss 1.564481496810913\n",
      "Starting Epoch 14\n",
      "1.6637939422026924\n",
      "Validation loss: 1.5566290616989136\n",
      "mse 1.5566290764910282\n",
      "New best model found at epoch 14 with validation loss 1.5566290616989136\n",
      "Starting Epoch 15\n",
      "1.6549871071525242\n",
      "Validation loss: 1.5496410131454468\n",
      "mse 1.5496410339835556\n",
      "New best model found at epoch 15 with validation loss 1.5496410131454468\n",
      "Starting Epoch 16\n",
      "1.6465879575065945\n",
      "Validation loss: 1.541735291481018\n",
      "mse 1.5417351610289964\n",
      "New best model found at epoch 16 with validation loss 1.541735291481018\n",
      "Starting Epoch 17\n",
      "1.6382155573886374\n",
      "Validation loss: 1.5348708629608154\n",
      "mse 1.5348708778120068\n",
      "New best model found at epoch 17 with validation loss 1.5348708629608154\n",
      "Starting Epoch 18\n",
      "1.6313261156496794\n",
      "Validation loss: 1.5308949947357178\n",
      "mse 1.5308951011125196\n",
      "New best model found at epoch 18 with validation loss 1.5308949947357178\n",
      "Starting Epoch 19\n",
      "1.6253422757853633\n",
      "Validation loss: 1.5263984203338623\n",
      "mse 1.5263983317933871\n",
      "New best model found at epoch 19 with validation loss 1.5263984203338623\n",
      "Starting Epoch 20\n",
      "1.6200381646985593\n",
      "Validation loss: 1.5221906900405884\n",
      "mse 1.5221907552997052\n",
      "New best model found at epoch 20 with validation loss 1.5221906900405884\n",
      "Starting Epoch 21\n",
      "1.615294300991556\n",
      "Validation loss: 1.517888069152832\n",
      "mse 1.5178879966832042\n",
      "New best model found at epoch 21 with validation loss 1.517888069152832\n",
      "Starting Epoch 22\n",
      "1.6104403734207153\n",
      "Validation loss: 1.5131052732467651\n",
      "mse 1.5131053268979653\n",
      "New best model found at epoch 22 with validation loss 1.5131052732467651\n",
      "Starting Epoch 23\n",
      "1.6062797644863958\n",
      "Validation loss: 1.5088633298873901\n",
      "mse 1.5088634050668503\n",
      "New best model found at epoch 23 with validation loss 1.5088633298873901\n",
      "Starting Epoch 24\n",
      "1.6020691550296287\n",
      "Validation loss: 1.5055649280548096\n",
      "mse 1.5055649619820344\n",
      "New best model found at epoch 24 with validation loss 1.5055649280548096\n",
      "Starting Epoch 25\n",
      "1.5982874294985896\n",
      "Validation loss: 1.501160740852356\n",
      "mse 1.5011606260528685\n",
      "New best model found at epoch 25 with validation loss 1.501160740852356\n",
      "Starting Epoch 26\n",
      "1.5947461205980051\n",
      "Validation loss: 1.4984722137451172\n",
      "mse 1.4984721296957957\n",
      "New best model found at epoch 26 with validation loss 1.4984722137451172\n",
      "Starting Epoch 27\n",
      "1.5912973232891248\n",
      "Validation loss: 1.4945595264434814\n",
      "mse 1.494559525744518\n",
      "New best model found at epoch 27 with validation loss 1.4945595264434814\n",
      "Starting Epoch 28\n",
      "1.5879353284835815\n",
      "Validation loss: 1.492004156112671\n",
      "mse 1.4920040573629394\n",
      "New best model found at epoch 28 with validation loss 1.492004156112671\n",
      "Starting Epoch 29\n",
      "1.5848806915075884\n",
      "Validation loss: 1.489314079284668\n",
      "mse 1.489314060452392\n",
      "New best model found at epoch 29 with validation loss 1.489314079284668\n",
      "Starting Epoch 30\n",
      "1.5817806979884272\n",
      "Validation loss: 1.4868699312210083\n",
      "mse 1.4868699631470617\n",
      "New best model found at epoch 30 with validation loss 1.4868699312210083\n",
      "Starting Epoch 31\n",
      "1.5788886365683183\n",
      "Validation loss: 1.483723521232605\n",
      "mse 1.4837236734437105\n",
      "New best model found at epoch 31 with validation loss 1.483723521232605\n",
      "Starting Epoch 32\n",
      "1.5762260608051135\n",
      "Validation loss: 1.4816219806671143\n",
      "mse 1.4816219988032366\n",
      "New best model found at epoch 32 with validation loss 1.4816219806671143\n",
      "Starting Epoch 33\n",
      "1.5736054907674375\n",
      "Validation loss: 1.4794766902923584\n",
      "mse 1.4794768049929643\n",
      "New best model found at epoch 33 with validation loss 1.4794766902923584\n",
      "Starting Epoch 34\n",
      "1.5710626374120298\n",
      "Validation loss: 1.4769197702407837\n",
      "mse 1.47691979597676\n",
      "New best model found at epoch 34 with validation loss 1.4769197702407837\n",
      "Starting Epoch 35\n",
      "1.568517749724181\n",
      "Validation loss: 1.4748003482818604\n",
      "mse 1.4748003203433615\n",
      "New best model found at epoch 35 with validation loss 1.4748003482818604\n",
      "Starting Epoch 36\n",
      "1.5660760506339695\n",
      "Validation loss: 1.4731941223144531\n",
      "mse 1.47319420980305\n",
      "New best model found at epoch 36 with validation loss 1.4731941223144531\n",
      "Starting Epoch 37\n",
      "1.5639425827109295\n",
      "Validation loss: 1.4707647562026978\n",
      "mse 1.4707647235182502\n",
      "New best model found at epoch 37 with validation loss 1.4707647562026978\n",
      "Starting Epoch 38\n",
      "1.5616269137548364\n",
      "Validation loss: 1.46864652633667\n",
      "mse 1.468646487763798\n",
      "New best model found at epoch 38 with validation loss 1.46864652633667\n",
      "Starting Epoch 39\n",
      "1.5594477135202158\n",
      "Validation loss: 1.4663375616073608\n",
      "mse 1.46633766106814\n",
      "New best model found at epoch 39 with validation loss 1.4663375616073608\n",
      "Starting Epoch 40\n",
      "1.5574596627898838\n",
      "Validation loss: 1.4635725021362305\n",
      "mse 1.4635723907950047\n",
      "New best model found at epoch 40 with validation loss 1.4635725021362305\n",
      "Starting Epoch 41\n",
      "1.5552324497181436\n",
      "Validation loss: 1.462044358253479\n",
      "mse 1.4620443974651607\n",
      "New best model found at epoch 41 with validation loss 1.462044358253479\n",
      "Starting Epoch 42\n",
      "1.5532313844432002\n",
      "Validation loss: 1.4597867727279663\n",
      "mse 1.4597868073106564\n",
      "New best model found at epoch 42 with validation loss 1.4597867727279663\n",
      "Starting Epoch 43\n",
      "1.5512215028638425\n",
      "Validation loss: 1.4575053453445435\n",
      "mse 1.4575053749900817\n",
      "New best model found at epoch 43 with validation loss 1.4575053453445435\n",
      "Starting Epoch 44\n",
      "1.5492325554723325\n",
      "Validation loss: 1.4556020498275757\n",
      "mse 1.4556021526454614\n",
      "New best model found at epoch 44 with validation loss 1.4556020498275757\n",
      "Starting Epoch 45\n",
      "1.5471414716347405\n",
      "Validation loss: 1.4540610313415527\n",
      "mse 1.4540609116784007\n",
      "New best model found at epoch 45 with validation loss 1.4540610313415527\n",
      "Starting Epoch 46\n",
      "1.5456079685169717\n",
      "Validation loss: 1.4517093896865845\n",
      "mse 1.4517094328788185\n",
      "New best model found at epoch 46 with validation loss 1.4517093896865845\n",
      "Starting Epoch 47\n",
      "1.5436183732488882\n",
      "Validation loss: 1.449980616569519\n",
      "mse 1.4499804914953704\n",
      "New best model found at epoch 47 with validation loss 1.449980616569519\n",
      "Starting Epoch 48\n",
      "1.5419605737147124\n",
      "Validation loss: 1.4476920366287231\n",
      "mse 1.4476919769014722\n",
      "New best model found at epoch 48 with validation loss 1.4476920366287231\n",
      "Starting Epoch 49\n",
      "1.5402343635973723\n",
      "Validation loss: 1.446508765220642\n",
      "mse 1.4465087460591006\n",
      "New best model found at epoch 49 with validation loss 1.446508765220642\n",
      "Starting Epoch 50\n",
      "1.5384569997372834\n",
      "Validation loss: 1.444520354270935\n",
      "mse 1.4445202685027334\n",
      "New best model found at epoch 50 with validation loss 1.444520354270935\n",
      "Starting Epoch 51\n",
      "1.5368012967317\n",
      "Validation loss: 1.4433537721633911\n",
      "mse 1.4433537118051007\n",
      "New best model found at epoch 51 with validation loss 1.4433537721633911\n",
      "Starting Epoch 52\n",
      "1.5354243387346682\n",
      "Validation loss: 1.4412643909454346\n",
      "mse 1.4412644045976462\n",
      "New best model found at epoch 52 with validation loss 1.4412643909454346\n",
      "Starting Epoch 53\n",
      "1.533898975538171\n",
      "Validation loss: 1.4398314952850342\n",
      "mse 1.4398314565804728\n",
      "New best model found at epoch 53 with validation loss 1.4398314952850342\n",
      "Starting Epoch 54\n",
      "1.5324438603028008\n",
      "Validation loss: 1.4375582933425903\n",
      "mse 1.437558453001608\n",
      "New best model found at epoch 54 with validation loss 1.4375582933425903\n",
      "Starting Epoch 55\n",
      "1.5307909638985344\n",
      "Validation loss: 1.4364302158355713\n",
      "mse 1.436430094487216\n",
      "New best model found at epoch 55 with validation loss 1.4364302158355713\n",
      "Starting Epoch 56\n",
      "1.529182449631069\n",
      "Validation loss: 1.4338481426239014\n",
      "mse 1.4338481321949315\n",
      "New best model found at epoch 56 with validation loss 1.4338481426239014\n",
      "Starting Epoch 57\n",
      "1.5271472568097322\n",
      "Validation loss: 1.4315979480743408\n",
      "mse 1.4315980330723213\n",
      "New best model found at epoch 57 with validation loss 1.4315979480743408\n",
      "Starting Epoch 58\n",
      "1.5257251029429229\n",
      "Validation loss: 1.4297419786453247\n",
      "mse 1.429741987394374\n",
      "New best model found at epoch 58 with validation loss 1.4297419786453247\n",
      "Starting Epoch 59\n",
      "1.5240587384804436\n",
      "Validation loss: 1.4259039163589478\n",
      "mse 1.42590397353853\n",
      "New best model found at epoch 59 with validation loss 1.4259039163589478\n",
      "Starting Epoch 60\n",
      "1.5223411658535833\n",
      "Validation loss: 1.4254202842712402\n",
      "mse 1.4254201728604956\n",
      "New best model found at epoch 60 with validation loss 1.4254202842712402\n",
      "Starting Epoch 61\n",
      "1.5210056175356326\n",
      "Validation loss: 1.4232473373413086\n",
      "mse 1.4232472066229163\n",
      "New best model found at epoch 61 with validation loss 1.4232473373413086\n",
      "Starting Epoch 62\n",
      "1.519662802634032\n",
      "Validation loss: 1.4213143587112427\n",
      "mse 1.421314364963642\n",
      "New best model found at epoch 62 with validation loss 1.4213143587112427\n",
      "Starting Epoch 63\n",
      "1.5181315282116765\n",
      "Validation loss: 1.4209450483322144\n",
      "mse 1.4209449368514462\n",
      "New best model found at epoch 63 with validation loss 1.4209450483322144\n",
      "Starting Epoch 64\n",
      "1.517305895038273\n",
      "Validation loss: 1.4182898998260498\n",
      "mse 1.4182898809755191\n",
      "New best model found at epoch 64 with validation loss 1.4182898998260498\n",
      "Starting Epoch 65\n",
      "1.5153066204941792\n",
      "Validation loss: 1.4181009531021118\n",
      "mse 1.4181009207414357\n",
      "New best model found at epoch 65 with validation loss 1.4181009531021118\n",
      "Starting Epoch 66\n",
      "1.5139344775158425\n",
      "Validation loss: 1.4168603420257568\n",
      "mse 1.4168602990642514\n",
      "New best model found at epoch 66 with validation loss 1.4168603420257568\n",
      "Starting Epoch 67\n",
      "1.5126938301583994\n",
      "Validation loss: 1.4141845703125\n",
      "mse 1.414184509172914\n",
      "New best model found at epoch 67 with validation loss 1.4141845703125\n",
      "Starting Epoch 68\n",
      "1.5114942555842192\n",
      "Validation loss: 1.4125556945800781\n",
      "mse 1.4125556418330714\n",
      "New best model found at epoch 68 with validation loss 1.4125556945800781\n",
      "Starting Epoch 69\n",
      "1.5099189359208811\n",
      "Validation loss: 1.4119856357574463\n",
      "mse 1.41198548891254\n",
      "New best model found at epoch 69 with validation loss 1.4119856357574463\n",
      "Starting Epoch 70\n",
      "1.5088539564091226\n",
      "Validation loss: 1.4097884893417358\n",
      "mse 1.4097884505247598\n",
      "New best model found at epoch 70 with validation loss 1.4097884893417358\n",
      "Starting Epoch 71\n",
      "1.5072098244791445\n",
      "Validation loss: 1.4094771146774292\n",
      "mse 1.4094771826510633\n",
      "New best model found at epoch 71 with validation loss 1.4094771146774292\n",
      "Starting Epoch 72\n",
      "1.5061578232309092\n",
      "Validation loss: 1.4075411558151245\n",
      "mse 1.4075411477352935\n",
      "New best model found at epoch 72 with validation loss 1.4075411558151245\n",
      "Starting Epoch 73\n",
      "1.504846707634304\n",
      "Validation loss: 1.4069304466247559\n",
      "mse 1.4069305384793604\n",
      "New best model found at epoch 73 with validation loss 1.4069304466247559\n",
      "Starting Epoch 74\n",
      "1.5038568766220757\n",
      "Validation loss: 1.4062607288360596\n",
      "mse 1.4062606355387979\n",
      "New best model found at epoch 74 with validation loss 1.4062607288360596\n",
      "Starting Epoch 75\n",
      "1.5025236477022585\n",
      "Validation loss: 1.4051145315170288\n",
      "mse 1.4051145984829383\n",
      "New best model found at epoch 75 with validation loss 1.4051145315170288\n",
      "Starting Epoch 76\n",
      "1.5015997731167336\n",
      "Validation loss: 1.4034667015075684\n",
      "mse 1.4034667511396353\n",
      "New best model found at epoch 76 with validation loss 1.4034667015075684\n",
      "Starting Epoch 77\n",
      "1.500508082949597\n",
      "Validation loss: 1.402402400970459\n",
      "mse 1.4024023979001496\n",
      "New best model found at epoch 77 with validation loss 1.402402400970459\n",
      "Starting Epoch 78\n",
      "1.4995612139287202\n",
      "Validation loss: 1.4012720584869385\n",
      "mse 1.401272090563126\n",
      "New best model found at epoch 78 with validation loss 1.4012720584869385\n",
      "Starting Epoch 79\n",
      "1.4984990928484045\n",
      "Validation loss: 1.3998968601226807\n",
      "mse 1.399896947556969\n",
      "New best model found at epoch 79 with validation loss 1.3998968601226807\n",
      "Starting Epoch 80\n",
      "1.4972420749456987\n",
      "Validation loss: 1.396154761314392\n",
      "mse 1.396154715699471\n",
      "New best model found at epoch 80 with validation loss 1.396154761314392\n",
      "Starting Epoch 81\n",
      "1.4963401219119197\n",
      "Validation loss: 1.3965414762496948\n",
      "mse 1.3965414033068098\n",
      "Starting Epoch 82\n",
      "1.4954793271811113\n",
      "Validation loss: 1.3951797485351562\n",
      "mse 1.3951796833424255\n",
      "New best model found at epoch 82 with validation loss 1.3951797485351562\n",
      "Starting Epoch 83\n",
      "1.4941770771275396\n",
      "Validation loss: 1.3947391510009766\n",
      "mse 1.3947391814280283\n",
      "New best model found at epoch 83 with validation loss 1.3947391510009766\n",
      "Starting Epoch 84\n",
      "1.4933136882989302\n",
      "Validation loss: 1.3912622928619385\n",
      "mse 1.3912623603027994\n",
      "New best model found at epoch 84 with validation loss 1.3912622928619385\n",
      "Starting Epoch 85\n",
      "1.4921760921892913\n",
      "Validation loss: 1.391948938369751\n",
      "mse 1.391948979221366\n",
      "Starting Epoch 86\n",
      "1.4911408087481623\n",
      "Validation loss: 1.389359712600708\n",
      "mse 1.3893597187470823\n",
      "New best model found at epoch 86 with validation loss 1.389359712600708\n",
      "Starting Epoch 87\n",
      "1.4902346963467805\n",
      "Validation loss: 1.3906641006469727\n",
      "mse 1.3906642143475274\n",
      "Starting Epoch 88\n",
      "1.4891890157823977\n",
      "Validation loss: 1.389710545539856\n",
      "mse 1.389710563811913\n",
      "Starting Epoch 89\n",
      "1.4882282070491626\n",
      "Validation loss: 1.3888137340545654\n",
      "mse 1.3888137316840958\n",
      "New best model found at epoch 89 with validation loss 1.3888137340545654\n",
      "Starting Epoch 90\n",
      "1.487274558647819\n",
      "Validation loss: 1.3852885961532593\n",
      "mse 1.3852885937015245\n",
      "New best model found at epoch 90 with validation loss 1.3852885961532593\n",
      "Starting Epoch 91\n",
      "1.4865496858306553\n",
      "Validation loss: 1.3862320184707642\n",
      "mse 1.386231970443721\n",
      "Starting Epoch 92\n",
      "1.485601210075876\n",
      "Validation loss: 1.3830653429031372\n",
      "mse 1.3830652280716627\n",
      "New best model found at epoch 92 with validation loss 1.3830653429031372\n",
      "Starting Epoch 93\n",
      "1.484570614669634\n",
      "Validation loss: 1.3836681842803955\n",
      "mse 1.3836682772192694\n",
      "Starting Epoch 94\n",
      "1.483247899490854\n",
      "Validation loss: 1.3820494413375854\n",
      "mse 1.3820494205439116\n",
      "New best model found at epoch 94 with validation loss 1.3820494413375854\n",
      "Starting Epoch 95\n",
      "1.4823364874590998\n",
      "Validation loss: 1.3808828592300415\n",
      "mse 1.3808828231126236\n",
      "New best model found at epoch 95 with validation loss 1.3808828592300415\n",
      "Starting Epoch 96\n",
      "1.4814351823018945\n",
      "Validation loss: 1.3797062635421753\n",
      "mse 1.3797063016253628\n",
      "New best model found at epoch 96 with validation loss 1.3797062635421753\n",
      "Starting Epoch 97\n",
      "1.480299472808838\n",
      "Validation loss: 1.3767929077148438\n",
      "mse 1.3767927860274896\n",
      "New best model found at epoch 97 with validation loss 1.3767929077148438\n",
      "Starting Epoch 98\n",
      "1.4793766892474631\n",
      "Validation loss: 1.372419834136963\n",
      "mse 1.3724199868361429\n",
      "New best model found at epoch 98 with validation loss 1.372419834136963\n",
      "Starting Epoch 99\n",
      "1.4784569714380347\n",
      "Validation loss: 1.373030185699463\n",
      "mse 1.3730302463410684\n",
      "Starting Epoch 100\n",
      "1.4775774919468423\n",
      "Validation loss: 1.3709924221038818\n",
      "mse 1.370992473671759\n",
      "New best model found at epoch 100 with validation loss 1.3709924221038818\n",
      "Starting Epoch 101\n",
      "1.476855703022169\n",
      "Validation loss: 1.3698718547821045\n",
      "mse 1.3698718640369358\n",
      "New best model found at epoch 101 with validation loss 1.3698718547821045\n",
      "Starting Epoch 102\n",
      "1.4758843960969343\n",
      "Validation loss: 1.3688725233078003\n",
      "mse 1.3688725063078562\n",
      "New best model found at epoch 102 with validation loss 1.3688725233078003\n",
      "Starting Epoch 103\n",
      "1.4751321362412495\n",
      "Validation loss: 1.3676884174346924\n",
      "mse 1.3676883955227659\n",
      "New best model found at epoch 103 with validation loss 1.3676884174346924\n",
      "Starting Epoch 104\n",
      "1.473961239275725\n",
      "Validation loss: 1.3665285110473633\n",
      "mse 1.3665284482743905\n",
      "New best model found at epoch 104 with validation loss 1.3665285110473633\n",
      "Starting Epoch 105\n",
      "1.4730443021525508\n",
      "Validation loss: 1.363340139389038\n",
      "mse 1.3633401168565715\n",
      "New best model found at epoch 105 with validation loss 1.363340139389038\n",
      "Starting Epoch 106\n",
      "1.4722449909085813\n",
      "Validation loss: 1.3638229370117188\n",
      "mse 1.3638228821075689\n",
      "Starting Epoch 107\n",
      "1.4713552386864373\n",
      "Validation loss: 1.3631027936935425\n",
      "mse 1.3631029381511677\n",
      "New best model found at epoch 107 with validation loss 1.3631027936935425\n",
      "Starting Epoch 108\n",
      "1.4704039615133535\n",
      "Validation loss: 1.3624290227890015\n",
      "mse 1.3624289947048092\n",
      "New best model found at epoch 108 with validation loss 1.3624290227890015\n",
      "Starting Epoch 109\n",
      "1.4697323571080747\n",
      "Validation loss: 1.3609428405761719\n",
      "mse 1.3609427714507758\n",
      "New best model found at epoch 109 with validation loss 1.3609428405761719\n",
      "Starting Epoch 110\n",
      "1.4687778405521228\n",
      "Validation loss: 1.3594200611114502\n",
      "mse 1.3594199056921075\n",
      "New best model found at epoch 110 with validation loss 1.3594200611114502\n",
      "Starting Epoch 111\n",
      "1.4681937046672986\n",
      "Validation loss: 1.3579000234603882\n",
      "mse 1.3579000220285775\n",
      "New best model found at epoch 111 with validation loss 1.3579000234603882\n",
      "Starting Epoch 112\n",
      "1.4672545920247617\n",
      "Validation loss: 1.357455849647522\n",
      "mse 1.3574557938619807\n",
      "New best model found at epoch 112 with validation loss 1.357455849647522\n",
      "Starting Epoch 113\n",
      "1.4666218265243198\n",
      "Validation loss: 1.3556143045425415\n",
      "mse 1.3556141836255844\n",
      "New best model found at epoch 113 with validation loss 1.3556143045425415\n",
      "Starting Epoch 114\n",
      "1.4658710075461345\n",
      "Validation loss: 1.352370262145996\n",
      "mse 1.3523703151120827\n",
      "New best model found at epoch 114 with validation loss 1.352370262145996\n",
      "Starting Epoch 115\n",
      "1.4647810666457466\n",
      "Validation loss: 1.3511861562728882\n",
      "mse 1.351185998600307\n",
      "New best model found at epoch 115 with validation loss 1.3511861562728882\n",
      "Starting Epoch 116\n",
      "1.464057269303695\n",
      "Validation loss: 1.3526972532272339\n",
      "mse 1.3526972026811726\n",
      "Starting Epoch 117\n",
      "1.4636294971341672\n",
      "Validation loss: 1.3508542776107788\n",
      "mse 1.3508543167120928\n",
      "New best model found at epoch 117 with validation loss 1.3508542776107788\n",
      "Starting Epoch 118\n",
      "1.4628956266071484\n",
      "Validation loss: 1.350041151046753\n",
      "mse 1.350041225878305\n",
      "New best model found at epoch 118 with validation loss 1.350041151046753\n",
      "Starting Epoch 119\n",
      "1.4620786205581997\n",
      "Validation loss: 1.349161148071289\n",
      "mse 1.3491610731732786\n",
      "New best model found at epoch 119 with validation loss 1.349161148071289\n",
      "Starting Epoch 120\n",
      "1.461523924184882\n",
      "Validation loss: 1.3481532335281372\n",
      "mse 1.3481531593941336\n",
      "New best model found at epoch 120 with validation loss 1.3481532335281372\n",
      "Starting Epoch 121\n",
      "1.4608836199926294\n",
      "Validation loss: 1.3472840785980225\n",
      "mse 1.3472840507084098\n",
      "New best model found at epoch 121 with validation loss 1.3472840785980225\n",
      "Starting Epoch 122\n",
      "1.4599155291267063\n",
      "Validation loss: 1.3461787700653076\n",
      "mse 1.3461787127671896\n",
      "New best model found at epoch 122 with validation loss 1.3461787700653076\n",
      "Starting Epoch 123\n",
      "1.45934694227965\n",
      "Validation loss: 1.3453508615493774\n",
      "mse 1.345350887599003\n",
      "New best model found at epoch 123 with validation loss 1.3453508615493774\n",
      "Starting Epoch 124\n",
      "1.4585731262746064\n",
      "Validation loss: 1.3445743322372437\n",
      "mse 1.3445743484983508\n",
      "New best model found at epoch 124 with validation loss 1.3445743322372437\n",
      "Starting Epoch 125\n",
      "1.4579491148824277\n",
      "Validation loss: 1.3435678482055664\n",
      "mse 1.343567885820641\n",
      "New best model found at epoch 125 with validation loss 1.3435678482055664\n",
      "Starting Epoch 126\n",
      "1.4570848734482476\n",
      "Validation loss: 1.3431110382080078\n",
      "mse 1.343111096084495\n",
      "New best model found at epoch 126 with validation loss 1.3431110382080078\n",
      "Starting Epoch 127\n",
      "1.4563512931699338\n",
      "Validation loss: 1.3425135612487793\n",
      "mse 1.3425134532750025\n",
      "New best model found at epoch 127 with validation loss 1.3425135612487793\n",
      "Starting Epoch 128\n",
      "1.455925850764565\n",
      "Validation loss: 1.3412572145462036\n",
      "mse 1.3412573901612381\n",
      "New best model found at epoch 128 with validation loss 1.3412572145462036\n",
      "Starting Epoch 129\n",
      "1.4553943561471028\n",
      "Validation loss: 1.340418815612793\n",
      "mse 1.3404187844918822\n",
      "New best model found at epoch 129 with validation loss 1.340418815612793\n",
      "Starting Epoch 130\n",
      "1.454474379187045\n",
      "Validation loss: 1.3403315544128418\n",
      "mse 1.340331428770924\n",
      "New best model found at epoch 130 with validation loss 1.3403315544128418\n",
      "Starting Epoch 131\n",
      "1.4541865017103113\n",
      "Validation loss: 1.3391053676605225\n",
      "mse 1.3391052852295542\n",
      "New best model found at epoch 131 with validation loss 1.3391053676605225\n",
      "Starting Epoch 132\n",
      "1.4534126675647239\n",
      "Validation loss: 1.3382512331008911\n",
      "mse 1.3382512072247996\n",
      "New best model found at epoch 132 with validation loss 1.3382512331008911\n",
      "Starting Epoch 133\n",
      "1.452681997547979\n",
      "Validation loss: 1.3383198976516724\n",
      "mse 1.3383199313103726\n",
      "Starting Epoch 134\n",
      "1.451950192451477\n",
      "Validation loss: 1.3367059230804443\n",
      "mse 1.3367058195589538\n",
      "New best model found at epoch 134 with validation loss 1.3367059230804443\n",
      "Starting Epoch 135\n",
      "1.4512554769930632\n",
      "Validation loss: 1.3362277746200562\n",
      "mse 1.3362277634642614\n",
      "New best model found at epoch 135 with validation loss 1.3362277746200562\n",
      "Starting Epoch 136\n",
      "1.4509429672489995\n",
      "Validation loss: 1.3360052108764648\n",
      "mse 1.3360053909832086\n",
      "New best model found at epoch 136 with validation loss 1.3360052108764648\n",
      "Starting Epoch 137\n",
      "1.4501603142074917\n",
      "Validation loss: 1.3346970081329346\n",
      "mse 1.3346968409114477\n",
      "New best model found at epoch 137 with validation loss 1.3346970081329346\n",
      "Starting Epoch 138\n",
      "1.4494233779285266\n",
      "Validation loss: 1.3336857557296753\n",
      "mse 1.3336856867601166\n",
      "New best model found at epoch 138 with validation loss 1.3336857557296753\n",
      "Starting Epoch 139\n",
      "1.448617054068524\n",
      "Validation loss: 1.3330049514770508\n",
      "mse 1.3330049817981844\n",
      "New best model found at epoch 139 with validation loss 1.3330049514770508\n",
      "Starting Epoch 140\n",
      "1.448087215423584\n",
      "Validation loss: 1.3320374488830566\n",
      "mse 1.3320374071288317\n",
      "New best model found at epoch 140 with validation loss 1.3320374488830566\n",
      "Starting Epoch 141\n",
      "1.4474211257437002\n",
      "Validation loss: 1.3314844369888306\n",
      "mse 1.3314843964173244\n",
      "New best model found at epoch 141 with validation loss 1.3314844369888306\n",
      "Starting Epoch 142\n",
      "1.4466742614041204\n",
      "Validation loss: 1.330902338027954\n",
      "mse 1.3309022738490948\n",
      "New best model found at epoch 142 with validation loss 1.330902338027954\n",
      "Starting Epoch 143\n",
      "1.4461352721504543\n",
      "Validation loss: 1.329883098602295\n",
      "mse 1.3298830691000032\n",
      "New best model found at epoch 143 with validation loss 1.329883098602295\n",
      "Starting Epoch 144\n",
      "1.4453125984772393\n",
      "Validation loss: 1.3296393156051636\n",
      "mse 1.3296393364852173\n",
      "New best model found at epoch 144 with validation loss 1.3296393156051636\n",
      "Starting Epoch 145\n",
      "1.4447632846624956\n",
      "Validation loss: 1.3291651010513306\n",
      "mse 1.329165265469461\n",
      "New best model found at epoch 145 with validation loss 1.3291651010513306\n",
      "Starting Epoch 146\n",
      "1.4442965932514356\n",
      "Validation loss: 1.3276734352111816\n",
      "mse 1.327673457923049\n",
      "New best model found at epoch 146 with validation loss 1.3276734352111816\n",
      "Starting Epoch 147\n",
      "1.4434881262157275\n",
      "Validation loss: 1.327609658241272\n",
      "mse 1.3276095859815684\n",
      "New best model found at epoch 147 with validation loss 1.327609658241272\n",
      "Starting Epoch 148\n",
      "1.4431074287580408\n",
      "Validation loss: 1.3268152475357056\n",
      "mse 1.326815163938874\n",
      "New best model found at epoch 148 with validation loss 1.3268152475357056\n",
      "Starting Epoch 149\n",
      "1.442480276460233\n",
      "Validation loss: 1.3260849714279175\n",
      "mse 1.3260850467547503\n",
      "New best model found at epoch 149 with validation loss 1.3260849714279175\n",
      "Starting Epoch 150\n",
      "1.4418708241504172\n",
      "Validation loss: 1.3252335786819458\n",
      "mse 1.325233528311095\n",
      "New best model found at epoch 150 with validation loss 1.3252335786819458\n",
      "Starting Epoch 151\n",
      "1.4411409989647244\n",
      "Validation loss: 1.325236201286316\n",
      "mse 1.3252360978121516\n",
      "Starting Epoch 152\n",
      "1.440503312193829\n",
      "Validation loss: 1.3242589235305786\n",
      "mse 1.3242589703609666\n",
      "New best model found at epoch 152 with validation loss 1.3242589235305786\n",
      "Starting Epoch 153\n",
      "1.4398819234060205\n",
      "Validation loss: 1.323419213294983\n",
      "mse 1.3234191662111454\n",
      "New best model found at epoch 153 with validation loss 1.323419213294983\n",
      "Starting Epoch 154\n",
      "1.4392875199732573\n",
      "Validation loss: 1.322770357131958\n",
      "mse 1.3227702636134941\n",
      "New best model found at epoch 154 with validation loss 1.322770357131958\n",
      "Starting Epoch 155\n",
      "1.4387065690496694\n",
      "Validation loss: 1.3222873210906982\n",
      "mse 1.3222872338376304\n",
      "New best model found at epoch 155 with validation loss 1.3222873210906982\n",
      "Starting Epoch 156\n",
      "1.4382771253585815\n",
      "Validation loss: 1.3216272592544556\n",
      "mse 1.3216273554319409\n",
      "New best model found at epoch 156 with validation loss 1.3216272592544556\n",
      "Starting Epoch 157\n",
      "1.4375914853552114\n",
      "Validation loss: 1.3204243183135986\n",
      "mse 1.32042434583552\n",
      "New best model found at epoch 157 with validation loss 1.3204243183135986\n",
      "Starting Epoch 158\n",
      "1.4371045957440916\n",
      "Validation loss: 1.3196462392807007\n",
      "mse 1.3196462486119336\n",
      "New best model found at epoch 158 with validation loss 1.3196462392807007\n",
      "Starting Epoch 159\n",
      "1.436489771241727\n",
      "Validation loss: 1.319737195968628\n",
      "mse 1.3197371929507908\n",
      "Starting Epoch 160\n",
      "1.436056849749192\n",
      "Validation loss: 1.318683385848999\n",
      "mse 1.318683418407238\n",
      "New best model found at epoch 160 with validation loss 1.318683385848999\n",
      "Starting Epoch 161\n",
      "1.4353053621623828\n",
      "Validation loss: 1.3183670043945312\n",
      "mse 1.3183670035970674\n",
      "New best model found at epoch 161 with validation loss 1.3183670043945312\n",
      "Starting Epoch 162\n",
      "1.4348841827848684\n",
      "Validation loss: 1.317492127418518\n",
      "mse 1.317492014647882\n",
      "New best model found at epoch 162 with validation loss 1.317492127418518\n",
      "Starting Epoch 163\n",
      "1.4342813206755596\n",
      "Validation loss: 1.3170777559280396\n",
      "mse 1.317077749715968\n",
      "New best model found at epoch 163 with validation loss 1.3170777559280396\n",
      "Starting Epoch 164\n",
      "1.433638932912246\n",
      "Validation loss: 1.3169618844985962\n",
      "mse 1.3169619645913275\n",
      "New best model found at epoch 164 with validation loss 1.3169618844985962\n",
      "Starting Epoch 165\n",
      "1.4331260789995608\n",
      "Validation loss: 1.3152177333831787\n",
      "mse 1.315217715382923\n",
      "New best model found at epoch 165 with validation loss 1.3152177333831787\n",
      "Starting Epoch 166\n",
      "1.4323814018912937\n",
      "Validation loss: 1.3146604299545288\n",
      "mse 1.3146604862940257\n",
      "New best model found at epoch 166 with validation loss 1.3146604299545288\n",
      "Starting Epoch 167\n",
      "1.4320209674213245\n",
      "Validation loss: 1.3140183687210083\n",
      "mse 1.3140183450716743\n",
      "New best model found at epoch 167 with validation loss 1.3140183687210083\n",
      "Starting Epoch 168\n",
      "1.43140519183615\n",
      "Validation loss: 1.3137128353118896\n",
      "mse 1.3137128556943378\n",
      "New best model found at epoch 168 with validation loss 1.3137128353118896\n",
      "Starting Epoch 169\n",
      "1.4310164296108743\n",
      "Validation loss: 1.312639832496643\n",
      "mse 1.312639843371773\n",
      "New best model found at epoch 169 with validation loss 1.312639832496643\n",
      "Starting Epoch 170\n",
      "1.430383350538171\n",
      "Validation loss: 1.3125473260879517\n",
      "mse 1.3125472605422552\n",
      "New best model found at epoch 170 with validation loss 1.3125473260879517\n",
      "Starting Epoch 171\n",
      "1.4299217566199924\n",
      "Validation loss: 1.3117544651031494\n",
      "mse 1.3117545219031619\n",
      "New best model found at epoch 171 with validation loss 1.3117544651031494\n",
      "Starting Epoch 172\n",
      "1.4295043815737185\n",
      "Validation loss: 1.3112382888793945\n",
      "mse 1.3112383404634775\n",
      "New best model found at epoch 172 with validation loss 1.3112382888793945\n",
      "Starting Epoch 173\n",
      "1.4289000319397969\n",
      "Validation loss: 1.3104684352874756\n",
      "mse 1.310468453502698\n",
      "New best model found at epoch 173 with validation loss 1.3104684352874756\n",
      "Starting Epoch 174\n",
      "1.4284264652625374\n",
      "Validation loss: 1.3103113174438477\n",
      "mse 1.310311124695784\n",
      "New best model found at epoch 174 with validation loss 1.3103113174438477\n",
      "Starting Epoch 175\n",
      "1.4280403593312139\n",
      "Validation loss: 1.3091657161712646\n",
      "mse 1.309165709575632\n",
      "New best model found at epoch 175 with validation loss 1.3091657161712646\n",
      "Starting Epoch 176\n",
      "1.4274563944858054\n",
      "Validation loss: 1.3082654476165771\n",
      "mse 1.3082654142865497\n",
      "New best model found at epoch 176 with validation loss 1.3082654476165771\n",
      "Starting Epoch 177\n",
      "1.4269231091374937\n",
      "Validation loss: 1.3084564208984375\n",
      "mse 1.308456438132601\n",
      "Starting Epoch 178\n",
      "1.4265705217485842\n",
      "Validation loss: 1.3069974184036255\n",
      "mse 1.3069974915723717\n",
      "New best model found at epoch 178 with validation loss 1.3069974184036255\n",
      "Starting Epoch 179\n",
      "1.4260172584782476\n",
      "Validation loss: 1.307279109954834\n",
      "mse 1.3072790264774556\n",
      "Starting Epoch 180\n",
      "1.4254913304163062\n",
      "Validation loss: 1.3062708377838135\n",
      "mse 1.306270786942011\n",
      "New best model found at epoch 180 with validation loss 1.3062708377838135\n",
      "Starting Epoch 181\n",
      "1.4252063709756602\n",
      "Validation loss: 1.3059924840927124\n",
      "mse 1.3059925219551503\n",
      "New best model found at epoch 181 with validation loss 1.3059924840927124\n",
      "Starting Epoch 182\n",
      "1.4245712575705156\n",
      "Validation loss: 1.304853916168213\n",
      "mse 1.304854074915047\n",
      "New best model found at epoch 182 with validation loss 1.304853916168213\n",
      "Starting Epoch 183\n",
      "1.4241066497305166\n",
      "Validation loss: 1.3052467107772827\n",
      "mse 1.3052467707514726\n",
      "Starting Epoch 184\n",
      "1.4237276548924653\n",
      "Validation loss: 1.303511142730713\n",
      "mse 1.303511106991621\n",
      "New best model found at epoch 184 with validation loss 1.303511142730713\n",
      "Starting Epoch 185\n",
      "1.4234201415725376\n",
      "Validation loss: 1.3005588054656982\n",
      "mse 1.3005587845954563\n",
      "New best model found at epoch 185 with validation loss 1.3005588054656982\n",
      "Starting Epoch 186\n",
      "1.4227946141491765\n",
      "Validation loss: 1.3027287721633911\n",
      "mse 1.3027287263057281\n",
      "Starting Epoch 187\n",
      "1.4224366079206052\n",
      "Validation loss: 1.3025107383728027\n",
      "mse 1.302510769872375\n",
      "Starting Epoch 188\n",
      "1.421831892884296\n",
      "Validation loss: 1.3019973039627075\n",
      "mse 1.3019973007102266\n",
      "Starting Epoch 189\n",
      "1.4213148433229197\n",
      "Validation loss: 1.3016185760498047\n",
      "mse 1.301618516273539\n",
      "Starting Epoch 190\n",
      "1.4210835306540779\n",
      "Validation loss: 1.301653265953064\n",
      "mse 1.3016532725172603\n",
      "Starting Epoch 191\n",
      "1.4204361931137417\n",
      "Validation loss: 1.300013542175293\n",
      "mse 1.300013388755596\n",
      "New best model found at epoch 191 with validation loss 1.300013542175293\n",
      "Starting Epoch 192\n",
      "1.4203738958939263\n",
      "Validation loss: 1.297591209411621\n",
      "mse 1.2975911270904983\n",
      "New best model found at epoch 192 with validation loss 1.297591209411621\n",
      "Starting Epoch 193\n",
      "1.4198078668635825\n",
      "Validation loss: 1.2991164922714233\n",
      "mse 1.2991165413739938\n",
      "Starting Epoch 194\n",
      "1.4194122449211453\n",
      "Validation loss: 1.296971321105957\n",
      "mse 1.2969714185635794\n",
      "New best model found at epoch 194 with validation loss 1.296971321105957\n",
      "Starting Epoch 195\n",
      "1.4189089640327122\n",
      "Validation loss: 1.2979379892349243\n",
      "mse 1.2979379109121842\n",
      "Starting Epoch 196\n",
      "1.4183383817258088\n",
      "Validation loss: 1.2985773086547852\n",
      "mse 1.2985772294686095\n",
      "Starting Epoch 197\n",
      "1.4179724584455076\n",
      "Validation loss: 1.2971192598342896\n",
      "mse 1.297119170279886\n",
      "Starting Epoch 198\n",
      "1.4174403729646101\n",
      "Validation loss: 1.29745614528656\n",
      "mse 1.297456069239004\n",
      "Starting Epoch 199\n",
      "1.417047461737757\n",
      "Validation loss: 1.2953864336013794\n",
      "mse 1.2953864134951354\n",
      "New best model found at epoch 199 with validation loss 1.2953864336013794\n",
      "Starting Epoch 200\n",
      "1.4167449163353962\n",
      "Validation loss: 1.2939345836639404\n",
      "mse 1.2939345342221893\n",
      "New best model found at epoch 200 with validation loss 1.2939345836639404\n",
      "Starting Epoch 201\n",
      "1.416168080723804\n",
      "Validation loss: 1.2952748537063599\n",
      "mse 1.2952746783959328\n",
      "Starting Epoch 202\n",
      "1.415564371191937\n",
      "Validation loss: 1.295458436012268\n",
      "mse 1.2954584995752183\n",
      "Starting Epoch 203\n",
      "1.4153427844462187\n",
      "Validation loss: 1.2922711372375488\n",
      "mse 1.2922710120364376\n",
      "New best model found at epoch 203 with validation loss 1.2922711372375488\n",
      "Starting Epoch 204\n",
      "1.414613480153291\n",
      "Validation loss: 1.2939144372940063\n",
      "mse 1.2939145372818588\n",
      "Starting Epoch 205\n",
      "1.4142414694247039\n",
      "Validation loss: 1.2940847873687744\n",
      "mse 1.2940847912192526\n",
      "Starting Epoch 206\n",
      "1.4136083359303682\n",
      "Validation loss: 1.293945074081421\n",
      "mse 1.293945048735927\n",
      "Starting Epoch 207\n",
      "1.413288186425748\n",
      "Validation loss: 1.293113350868225\n",
      "mse 1.2931132815464519\n",
      "Starting Epoch 208\n",
      "1.4126035545183264\n",
      "Validation loss: 1.2931153774261475\n",
      "mse 1.2931153240765378\n",
      "Starting Epoch 209\n",
      "1.4125706190648286\n",
      "Validation loss: 1.289855718612671\n",
      "mse 1.2898556941183683\n",
      "New best model found at epoch 209 with validation loss 1.289855718612671\n",
      "Starting Epoch 210\n",
      "1.4119474654612334\n",
      "Validation loss: 1.2911561727523804\n",
      "mse 1.2911562115012452\n",
      "Starting Epoch 211\n",
      "1.4113148684087007\n",
      "Validation loss: 1.2912828922271729\n",
      "mse 1.2912829068627334\n",
      "Starting Epoch 212\n",
      "1.4111749970394631\n",
      "Validation loss: 1.2883038520812988\n",
      "mse 1.2883037640160313\n",
      "New best model found at epoch 212 with validation loss 1.2883038520812988\n",
      "Starting Epoch 213\n",
      "1.4103512789892114\n",
      "Validation loss: 1.2904192209243774\n",
      "mse 1.2904191809906411\n",
      "Starting Epoch 214\n",
      "1.4100390128467395\n",
      "Validation loss: 1.2898247241973877\n",
      "mse 1.2898246398134028\n",
      "Starting Epoch 215\n",
      "1.4096867830856987\n",
      "Validation loss: 1.2870348691940308\n",
      "mse 1.2870349234115064\n",
      "New best model found at epoch 215 with validation loss 1.2870348691940308\n",
      "Starting Epoch 216\n",
      "1.4090414176816526\n",
      "Validation loss: 1.288162112236023\n",
      "mse 1.288162137323943\n",
      "Starting Epoch 217\n",
      "1.4084763034530308\n",
      "Validation loss: 1.288543701171875\n",
      "mse 1.2885436920314854\n",
      "Starting Epoch 218\n",
      "1.4083752709886301\n",
      "Validation loss: 1.2851603031158447\n",
      "mse 1.2851602674688445\n",
      "New best model found at epoch 218 with validation loss 1.2851603031158447\n",
      "Starting Epoch 219\n",
      "1.4077168366183406\n",
      "Validation loss: 1.2868794202804565\n",
      "mse 1.2868793945146577\n",
      "Starting Epoch 220\n",
      "1.4071243249851724\n",
      "Validation loss: 1.2870376110076904\n",
      "mse 1.2870377183103177\n",
      "Starting Epoch 221\n",
      "1.4069920959679976\n",
      "Validation loss: 1.283758521080017\n",
      "mse 1.283758481467543\n",
      "New best model found at epoch 221 with validation loss 1.283758521080017\n",
      "Starting Epoch 222\n",
      "1.4062303771143374\n",
      "Validation loss: 1.285874843597412\n",
      "mse 1.2858747872453105\n",
      "Starting Epoch 223\n",
      "1.4058725833892822\n",
      "Validation loss: 1.2851004600524902\n",
      "mse 1.2851004075191526\n",
      "Starting Epoch 224\n",
      "1.4055657438609912\n",
      "Validation loss: 1.2821452617645264\n",
      "mse 1.2821452916543965\n",
      "New best model found at epoch 224 with validation loss 1.2821452617645264\n",
      "Starting Epoch 225\n",
      "1.4050333681313887\n",
      "Validation loss: 1.283859372138977\n",
      "mse 1.2838593029810033\n",
      "Starting Epoch 226\n",
      "1.4045003600742505\n",
      "Validation loss: 1.284116506576538\n",
      "mse 1.2841165525735523\n",
      "Starting Epoch 227\n",
      "1.4042849670285764\n",
      "Validation loss: 1.280707836151123\n",
      "mse 1.2807078441337507\n",
      "New best model found at epoch 227 with validation loss 1.280707836151123\n",
      "Starting Epoch 228\n",
      "1.403646241063657\n",
      "Validation loss: 1.2826824188232422\n",
      "mse 1.2826823538080083\n",
      "Starting Epoch 229\n",
      "1.4033594805261362\n",
      "Validation loss: 1.282272219657898\n",
      "mse 1.2822722483060873\n",
      "Starting Epoch 230\n",
      "1.4029537853987322\n",
      "Validation loss: 1.2797582149505615\n",
      "mse 1.279758337476795\n",
      "New best model found at epoch 230 with validation loss 1.2797582149505615\n",
      "Starting Epoch 231\n",
      "1.4024898461673572\n",
      "Validation loss: 1.280945897102356\n",
      "mse 1.2809458410930565\n",
      "Starting Epoch 232\n",
      "1.4018402902976326\n",
      "Validation loss: 1.2814563512802124\n",
      "mse 1.28145639448201\n",
      "Starting Epoch 233\n",
      "1.4017802917439004\n",
      "Validation loss: 1.27826988697052\n",
      "mse 1.2782698577231433\n",
      "New best model found at epoch 233 with validation loss 1.27826988697052\n",
      "Starting Epoch 234\n",
      "1.40100025612375\n",
      "Validation loss: 1.2803341150283813\n",
      "mse 1.2803341536550914\n",
      "Starting Epoch 235\n",
      "1.4006776213645935\n",
      "Validation loss: 1.2797480821609497\n",
      "mse 1.279747955727998\n",
      "Starting Epoch 236\n",
      "1.4003688537556191\n",
      "Validation loss: 1.2768845558166504\n",
      "mse 1.2768844585965773\n",
      "New best model found at epoch 236 with validation loss 1.2768845558166504\n",
      "Starting Epoch 237\n",
      "1.3999031134273694\n",
      "Validation loss: 1.276284098625183\n",
      "mse 1.2762840722867583\n",
      "New best model found at epoch 237 with validation loss 1.276284098625183\n",
      "Starting Epoch 238\n",
      "1.3994522224301877\n",
      "Validation loss: 1.2784136533737183\n",
      "mse 1.2784135638717773\n",
      "Starting Epoch 239\n",
      "1.3988879063855046\n",
      "Validation loss: 1.278209924697876\n",
      "mse 1.2782098609494168\n",
      "Starting Epoch 240\n",
      "1.3988656297973965\n",
      "Validation loss: 1.2754532098770142\n",
      "mse 1.275453335726703\n",
      "New best model found at epoch 240 with validation loss 1.2754532098770142\n",
      "Starting Epoch 241\n",
      "1.3980909482292507\n",
      "Validation loss: 1.277021884918213\n",
      "mse 1.2770218449501263\n",
      "Starting Epoch 242\n",
      "1.3979516392168791\n",
      "Validation loss: 1.2744297981262207\n",
      "mse 1.274429805205196\n",
      "New best model found at epoch 242 with validation loss 1.2744297981262207\n",
      "Starting Epoch 243\n",
      "1.3973841822665671\n",
      "Validation loss: 1.276252031326294\n",
      "mse 1.2762521628101648\n",
      "Starting Epoch 244\n",
      "1.3968877973763838\n",
      "Validation loss: 1.2760891914367676\n",
      "mse 1.2760893176239592\n",
      "Starting Epoch 245\n",
      "1.396616147912067\n",
      "Validation loss: 1.2756588459014893\n",
      "mse 1.2756588593114249\n",
      "Starting Epoch 246\n",
      "1.3960487764814626\n",
      "Validation loss: 1.275339126586914\n",
      "mse 1.2753390172887153\n",
      "Starting Epoch 247\n",
      "1.395803583704907\n",
      "Validation loss: 1.27474045753479\n",
      "mse 1.2747405333742607\n",
      "Starting Epoch 248\n",
      "1.3952456194421519\n",
      "Validation loss: 1.2744667530059814\n",
      "mse 1.274466850409554\n",
      "Starting Epoch 249\n",
      "1.3949267812397168\n",
      "Validation loss: 1.2740880250930786\n",
      "mse 1.2740879278508603\n",
      "New best model found at epoch 249 with validation loss 1.2740880250930786\n",
      "Starting Epoch 250\n",
      "1.3947728353997935\n",
      "Validation loss: 1.2714320421218872\n",
      "mse 1.2714319262656135\n",
      "New best model found at epoch 250 with validation loss 1.2714320421218872\n",
      "Starting Epoch 251\n",
      "1.3941313391146453\n",
      "Validation loss: 1.2731359004974365\n",
      "mse 1.2731359040211634\n",
      "Starting Epoch 252\n",
      "1.3940211845480877\n",
      "Validation loss: 1.2701739072799683\n",
      "mse 1.2701739532070793\n",
      "New best model found at epoch 252 with validation loss 1.2701739072799683\n",
      "Starting Epoch 253\n",
      "1.3934536394865618\n",
      "Validation loss: 1.2696425914764404\n",
      "mse 1.2696426014674151\n",
      "New best model found at epoch 253 with validation loss 1.2696425914764404\n",
      "Starting Epoch 254\n",
      "1.3928962272146475\n",
      "Validation loss: 1.2717561721801758\n",
      "mse 1.27175618191359\n",
      "Starting Epoch 255\n",
      "1.3926016792007114\n",
      "Validation loss: 1.2709437608718872\n",
      "mse 1.2709437982288525\n",
      "Starting Epoch 256\n",
      "1.3923554213150688\n",
      "Validation loss: 1.2688915729522705\n",
      "mse 1.2688914131132698\n",
      "New best model found at epoch 256 with validation loss 1.2688915729522705\n",
      "Starting Epoch 257\n",
      "1.3917102399079695\n",
      "Validation loss: 1.2703614234924316\n",
      "mse 1.2703614119055067\n",
      "Starting Epoch 258\n",
      "1.391555721345155\n",
      "Validation loss: 1.2679702043533325\n",
      "mse 1.2679700721930804\n",
      "New best model found at epoch 258 with validation loss 1.2679702043533325\n",
      "Starting Epoch 259\n",
      "1.3909395829490994\n",
      "Validation loss: 1.2697428464889526\n",
      "mse 1.2697427627786333\n",
      "Starting Epoch 260\n",
      "1.3908300322035085\n",
      "Validation loss: 1.2668375968933105\n",
      "mse 1.266837524614749\n",
      "New best model found at epoch 260 with validation loss 1.2668375968933105\n",
      "Starting Epoch 261\n",
      "1.3901976372884668\n",
      "Validation loss: 1.26864492893219\n",
      "mse 1.2686449340102015\n",
      "Starting Epoch 262\n",
      "1.3900417581848477\n",
      "Validation loss: 1.2663956880569458\n",
      "mse 1.2663957033634041\n",
      "New best model found at epoch 262 with validation loss 1.2663956880569458\n",
      "Starting Epoch 263\n",
      "1.3894703673279805\n",
      "Validation loss: 1.2680836915969849\n",
      "mse 1.2680837148561832\n",
      "Starting Epoch 264\n",
      "1.3894096690675486\n",
      "Validation loss: 1.2654396295547485\n",
      "mse 1.2654397358626939\n",
      "New best model found at epoch 264 with validation loss 1.2654396295547485\n",
      "Starting Epoch 265\n",
      "1.388749000818833\n",
      "Validation loss: 1.2670081853866577\n",
      "mse 1.267008245483268\n",
      "Starting Epoch 266\n",
      "1.3885233635487764\n",
      "Validation loss: 1.264912486076355\n",
      "mse 1.2649124818119248\n",
      "New best model found at epoch 266 with validation loss 1.264912486076355\n",
      "Starting Epoch 267\n",
      "1.3879498113756594\n",
      "Validation loss: 1.2659327983856201\n",
      "mse 1.2659328550516664\n",
      "Starting Epoch 268\n",
      "1.3878116555835889\n",
      "Validation loss: 1.2641395330429077\n",
      "mse 1.2641395468564813\n",
      "New best model found at epoch 268 with validation loss 1.2641395330429077\n",
      "Starting Epoch 269\n",
      "1.3872353538222935\n",
      "Validation loss: 1.265219807624817\n",
      "mse 1.2652198450608987\n",
      "Starting Epoch 270\n",
      "1.3869120271309563\n",
      "Validation loss: 1.2654540538787842\n",
      "mse 1.2654541242977861\n",
      "Starting Epoch 271\n",
      "1.386761126310929\n",
      "Validation loss: 1.2623698711395264\n",
      "mse 1.262369748104651\n",
      "New best model found at epoch 271 with validation loss 1.2623698711395264\n",
      "Starting Epoch 272\n",
      "1.3862155986868816\n",
      "Validation loss: 1.2641836404800415\n",
      "mse 1.2641835787591302\n",
      "Starting Epoch 273\n",
      "1.385861160962478\n",
      "Validation loss: 1.2639464139938354\n",
      "mse 1.2639464438087278\n",
      "Starting Epoch 274\n",
      "1.3855126189148945\n",
      "Validation loss: 1.263201355934143\n",
      "mse 1.2632014224334862\n",
      "Starting Epoch 275\n",
      "1.3853879622791125\n",
      "Validation loss: 1.2605642080307007\n",
      "mse 1.2605642643864357\n",
      "New best model found at epoch 275 with validation loss 1.2605642080307007\n",
      "Starting Epoch 276\n",
      "1.3848211609798928\n",
      "Validation loss: 1.2624024152755737\n",
      "mse 1.2624023157225983\n",
      "Starting Epoch 277\n",
      "1.3846800430961277\n",
      "Validation loss: 1.2598483562469482\n",
      "mse 1.2598483799585674\n",
      "New best model found at epoch 277 with validation loss 1.2598483562469482\n",
      "Starting Epoch 278\n",
      "1.3841467292412468\n",
      "Validation loss: 1.261683702468872\n",
      "mse 1.261683566811606\n",
      "Starting Epoch 279\n",
      "1.3839807588121165\n",
      "Validation loss: 1.258941411972046\n",
      "mse 1.2589414821804448\n",
      "New best model found at epoch 279 with validation loss 1.258941411972046\n",
      "Starting Epoch 280\n",
      "1.3836205031560815\n",
      "Validation loss: 1.25884211063385\n",
      "mse 1.2588420219353902\n",
      "New best model found at epoch 280 with validation loss 1.25884211063385\n",
      "Starting Epoch 281\n",
      "1.383095075254855\n",
      "Validation loss: 1.260536789894104\n",
      "mse 1.2605366691505753\n",
      "Starting Epoch 282\n",
      "1.3828467597132144\n",
      "Validation loss: 1.26002037525177\n",
      "mse 1.2600202786923476\n",
      "Starting Epoch 283\n",
      "1.382533796455549\n",
      "Validation loss: 1.2598403692245483\n",
      "mse 1.2598404290351701\n",
      "Starting Epoch 284\n",
      "1.382327183433201\n",
      "Validation loss: 1.2576379776000977\n",
      "mse 1.2576379876879482\n",
      "New best model found at epoch 284 with validation loss 1.2576379776000977\n",
      "Starting Epoch 285\n",
      "1.3817709114240564\n",
      "Validation loss: 1.258984923362732\n",
      "mse 1.2589848245509396\n",
      "Starting Epoch 286\n",
      "1.3816859644392263\n",
      "Validation loss: 1.2565666437149048\n",
      "mse 1.2565667264584661\n",
      "New best model found at epoch 286 with validation loss 1.2565666437149048\n",
      "Starting Epoch 287\n",
      "1.3812141107476277\n",
      "Validation loss: 1.2582919597625732\n",
      "mse 1.258291973205848\n",
      "Starting Epoch 288\n",
      "1.3808149254840354\n",
      "Validation loss: 1.2583115100860596\n",
      "mse 1.25831152529967\n",
      "Starting Epoch 289\n",
      "1.3807717043420542\n",
      "Validation loss: 1.2558962106704712\n",
      "mse 1.2558961772764037\n",
      "New best model found at epoch 289 with validation loss 1.2558962106704712\n",
      "Starting Epoch 290\n",
      "1.3801723977793818\n",
      "Validation loss: 1.2577102184295654\n",
      "mse 1.257710267033167\n",
      "Starting Epoch 291\n",
      "1.3798984237339185\n",
      "Validation loss: 1.2572686672210693\n",
      "mse 1.2572685313498595\n",
      "Starting Epoch 292\n",
      "1.379829051701919\n",
      "Validation loss: 1.2549643516540527\n",
      "mse 1.2549641503493552\n",
      "New best model found at epoch 292 with validation loss 1.2549643516540527\n",
      "Starting Epoch 293\n",
      "1.3791900976844456\n",
      "Validation loss: 1.2569077014923096\n",
      "mse 1.2569077906412844\n",
      "Starting Epoch 294\n",
      "1.3791905822961226\n",
      "Validation loss: 1.2539496421813965\n",
      "mse 1.2539495571627246\n",
      "New best model found at epoch 294 with validation loss 1.2539496421813965\n",
      "Starting Epoch 295\n",
      "1.3785578401192375\n",
      "Validation loss: 1.2558649778366089\n",
      "mse 1.2558649576999632\n",
      "Starting Epoch 296\n",
      "1.3784634885580644\n",
      "Validation loss: 1.2532821893692017\n",
      "mse 1.253282181060883\n",
      "New best model found at epoch 296 with validation loss 1.2532821893692017\n",
      "Starting Epoch 297\n",
      "1.3781043887138367\n",
      "Validation loss: 1.253040075302124\n",
      "mse 1.2530400931411465\n",
      "New best model found at epoch 297 with validation loss 1.253040075302124\n",
      "Starting Epoch 298\n",
      "1.3776167760724607\n",
      "Validation loss: 1.2549108266830444\n",
      "mse 1.2549107338675003\n",
      "Starting Epoch 299\n",
      "1.3773836286171623\n",
      "Validation loss: 1.2542195320129395\n",
      "mse 1.2542195305083672\n",
      "Starting Epoch 300\n",
      "1.3770178660102512\n",
      "Validation loss: 1.2542203664779663\n",
      "mse 1.2542203643662797\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-max: 7-60-40-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff9c4b9",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 60 - 40 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.25-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "41a2d11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "65b414a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,8,15]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,8,15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "7f30f63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'q25(container counts)', 'q25(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "e1d1b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "58891e68-90b1-4410-b65f-62ef057535ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.138048213461171\n",
      "Validation loss: 2.548448085784912\n",
      "mse 2.548448311654494\n",
      "New best model found at epoch 1 with validation loss 2.548448085784912\n",
      "Starting Epoch 2\n",
      "2.60272929461106\n",
      "Validation loss: 2.2194857597351074\n",
      "mse 2.2194858682366307\n",
      "New best model found at epoch 2 with validation loss 2.2194857597351074\n",
      "Starting Epoch 3\n",
      "2.3434197488038437\n",
      "Validation loss: 2.0531065464019775\n",
      "mse 2.0531066539742775\n",
      "New best model found at epoch 3 with validation loss 2.0531065464019775\n",
      "Starting Epoch 4\n",
      "2.187763354052668\n",
      "Validation loss: 1.955308437347412\n",
      "mse 1.9553083493279853\n",
      "New best model found at epoch 4 with validation loss 1.955308437347412\n",
      "Starting Epoch 5\n",
      "2.0839657109716665\n",
      "Validation loss: 1.8912159204483032\n",
      "mse 1.891215894955956\n",
      "New best model found at epoch 5 with validation loss 1.8912159204483032\n",
      "Starting Epoch 6\n",
      "2.012622460075047\n",
      "Validation loss: 1.847637414932251\n",
      "mse 1.8476374734636987\n",
      "New best model found at epoch 6 with validation loss 1.847637414932251\n",
      "Starting Epoch 7\n",
      "1.961751533591229\n",
      "Validation loss: 1.813875675201416\n",
      "mse 1.8138756616792113\n",
      "New best model found at epoch 7 with validation loss 1.813875675201416\n",
      "Starting Epoch 8\n",
      "1.9214182781136555\n",
      "Validation loss: 1.7894902229309082\n",
      "mse 1.7894901614094\n",
      "New best model found at epoch 8 with validation loss 1.7894902229309082\n",
      "Starting Epoch 9\n",
      "1.8900017945662788\n",
      "Validation loss: 1.7549291849136353\n",
      "mse 1.7549291279070767\n",
      "New best model found at epoch 9 with validation loss 1.7549291849136353\n",
      "Starting Epoch 10\n",
      "1.8569694394650667\n",
      "Validation loss: 1.7364295721054077\n",
      "mse 1.7364296628971467\n",
      "New best model found at epoch 10 with validation loss 1.7364295721054077\n",
      "Starting Epoch 11\n",
      "1.833466861558997\n",
      "Validation loss: 1.7224242687225342\n",
      "mse 1.7224243004311697\n",
      "New best model found at epoch 11 with validation loss 1.7224242687225342\n",
      "Starting Epoch 12\n",
      "1.8135273301083108\n",
      "Validation loss: 1.7091429233551025\n",
      "mse 1.7091430071379325\n",
      "New best model found at epoch 12 with validation loss 1.7091429233551025\n",
      "Starting Epoch 13\n",
      "1.7964194080104\n",
      "Validation loss: 1.6985875368118286\n",
      "mse 1.6985878151451266\n",
      "New best model found at epoch 13 with validation loss 1.6985875368118286\n",
      "Starting Epoch 14\n",
      "1.7822234682414844\n",
      "Validation loss: 1.689440131187439\n",
      "mse 1.689440047432825\n",
      "New best model found at epoch 14 with validation loss 1.689440131187439\n",
      "Starting Epoch 15\n",
      "1.770691850911016\n",
      "Validation loss: 1.6804351806640625\n",
      "mse 1.6804352941111342\n",
      "New best model found at epoch 15 with validation loss 1.6804351806640625\n",
      "Starting Epoch 16\n",
      "1.760933062304621\n",
      "Validation loss: 1.6724858283996582\n",
      "mse 1.6724859524473832\n",
      "New best model found at epoch 16 with validation loss 1.6724858283996582\n",
      "Starting Epoch 17\n",
      "1.75218855816385\n",
      "Validation loss: 1.6655980348587036\n",
      "mse 1.665598193849891\n",
      "New best model found at epoch 17 with validation loss 1.6655980348587036\n",
      "Starting Epoch 18\n",
      "1.7445767599603403\n",
      "Validation loss: 1.6574329137802124\n",
      "mse 1.657432782134\n",
      "New best model found at epoch 18 with validation loss 1.6574329137802124\n",
      "Starting Epoch 19\n",
      "1.7377876509790835\n",
      "Validation loss: 1.6514692306518555\n",
      "mse 1.6514692252702332\n",
      "New best model found at epoch 19 with validation loss 1.6514692306518555\n",
      "Starting Epoch 20\n",
      "1.7311774129452913\n",
      "Validation loss: 1.6462401151657104\n",
      "mse 1.6462401025580005\n",
      "New best model found at epoch 20 with validation loss 1.6462401151657104\n",
      "Starting Epoch 21\n",
      "1.7250124060589334\n",
      "Validation loss: 1.6410160064697266\n",
      "mse 1.6410158911549777\n",
      "New best model found at epoch 21 with validation loss 1.6410160064697266\n",
      "Starting Epoch 22\n",
      "1.7185034026270327\n",
      "Validation loss: 1.6358909606933594\n",
      "mse 1.6358909257687981\n",
      "New best model found at epoch 22 with validation loss 1.6358909606933594\n",
      "Starting Epoch 23\n",
      "1.7126570266226064\n",
      "Validation loss: 1.6311904191970825\n",
      "mse 1.6311904152746306\n",
      "New best model found at epoch 23 with validation loss 1.6311904191970825\n",
      "Starting Epoch 24\n",
      "1.707869353501693\n",
      "Validation loss: 1.6268376111984253\n",
      "mse 1.6268376961145339\n",
      "New best model found at epoch 24 with validation loss 1.6268376111984253\n",
      "Starting Epoch 25\n",
      "1.7029805442561274\n",
      "Validation loss: 1.62342369556427\n",
      "mse 1.623423623908685\n",
      "New best model found at epoch 25 with validation loss 1.62342369556427\n",
      "Starting Epoch 26\n",
      "1.6990143008854077\n",
      "Validation loss: 1.6194441318511963\n",
      "mse 1.6194439416470836\n",
      "New best model found at epoch 26 with validation loss 1.6194441318511963\n",
      "Starting Epoch 27\n",
      "1.6949746401413628\n",
      "Validation loss: 1.6161253452301025\n",
      "mse 1.6161254069412385\n",
      "New best model found at epoch 27 with validation loss 1.6161253452301025\n",
      "Starting Epoch 28\n",
      "1.6914159577825796\n",
      "Validation loss: 1.6133852005004883\n",
      "mse 1.6133851927905212\n",
      "New best model found at epoch 28 with validation loss 1.6133852005004883\n",
      "Starting Epoch 29\n",
      "1.6879959987557454\n",
      "Validation loss: 1.6100820302963257\n",
      "mse 1.6100821138170085\n",
      "New best model found at epoch 29 with validation loss 1.6100820302963257\n",
      "Starting Epoch 30\n",
      "1.6848970962607341\n",
      "Validation loss: 1.6071264743804932\n",
      "mse 1.6071265201804625\n",
      "New best model found at epoch 30 with validation loss 1.6071264743804932\n",
      "Starting Epoch 31\n",
      "1.6818462454754373\n",
      "Validation loss: 1.6040652990341187\n",
      "mse 1.6040652742402053\n",
      "New best model found at epoch 31 with validation loss 1.6040652990341187\n",
      "Starting Epoch 32\n",
      "1.6786483733550361\n",
      "Validation loss: 1.6007963418960571\n",
      "mse 1.6007962032365\n",
      "New best model found at epoch 32 with validation loss 1.6007963418960571\n",
      "Starting Epoch 33\n",
      "1.6754499155542124\n",
      "Validation loss: 1.5980114936828613\n",
      "mse 1.598011481944683\n",
      "New best model found at epoch 33 with validation loss 1.5980114936828613\n",
      "Starting Epoch 34\n",
      "1.6726319997206978\n",
      "Validation loss: 1.5956904888153076\n",
      "mse 1.5956905644059636\n",
      "New best model found at epoch 34 with validation loss 1.5956904888153076\n",
      "Starting Epoch 35\n",
      "1.6699522941008857\n",
      "Validation loss: 1.5931029319763184\n",
      "mse 1.5931029927472053\n",
      "New best model found at epoch 35 with validation loss 1.5931029319763184\n",
      "Starting Epoch 36\n",
      "1.667286375294561\n",
      "Validation loss: 1.590775489807129\n",
      "mse 1.5907753862239231\n",
      "New best model found at epoch 36 with validation loss 1.590775489807129\n",
      "Starting Epoch 37\n",
      "1.6648371167804883\n",
      "Validation loss: 1.5885645151138306\n",
      "mse 1.588564518610638\n",
      "New best model found at epoch 37 with validation loss 1.5885645151138306\n",
      "Starting Epoch 38\n",
      "1.6625770589579707\n",
      "Validation loss: 1.5869097709655762\n",
      "mse 1.5869097945981407\n",
      "New best model found at epoch 38 with validation loss 1.5869097709655762\n",
      "Starting Epoch 39\n",
      "1.660359906113666\n",
      "Validation loss: 1.585036277770996\n",
      "mse 1.5850362073472142\n",
      "New best model found at epoch 39 with validation loss 1.585036277770996\n",
      "Starting Epoch 40\n",
      "1.658319784247357\n",
      "Validation loss: 1.5829428434371948\n",
      "mse 1.5829428287674316\n",
      "New best model found at epoch 40 with validation loss 1.5829428434371948\n",
      "Starting Epoch 41\n",
      "1.6563000679016113\n",
      "Validation loss: 1.5812393426895142\n",
      "mse 1.5812392591955564\n",
      "New best model found at epoch 41 with validation loss 1.5812393426895142\n",
      "Starting Epoch 42\n",
      "1.6544455859972083\n",
      "Validation loss: 1.5796563625335693\n",
      "mse 1.5796563404514548\n",
      "New best model found at epoch 42 with validation loss 1.5796563625335693\n",
      "Starting Epoch 43\n",
      "1.6526857873667842\n",
      "Validation loss: 1.577754259109497\n",
      "mse 1.5777544190373145\n",
      "New best model found at epoch 43 with validation loss 1.577754259109497\n",
      "Starting Epoch 44\n",
      "1.6508800568787947\n",
      "Validation loss: 1.5763050317764282\n",
      "mse 1.576304989987108\n",
      "New best model found at epoch 44 with validation loss 1.5763050317764282\n",
      "Starting Epoch 45\n",
      "1.6493158651434856\n",
      "Validation loss: 1.5750905275344849\n",
      "mse 1.5750906518586636\n",
      "New best model found at epoch 45 with validation loss 1.5750905275344849\n",
      "Starting Epoch 46\n",
      "1.647535572881284\n",
      "Validation loss: 1.5731996297836304\n",
      "mse 1.5731995422093015\n",
      "New best model found at epoch 46 with validation loss 1.5731996297836304\n",
      "Starting Epoch 47\n",
      "1.6459619998931885\n",
      "Validation loss: 1.571742296218872\n",
      "mse 1.5717423091527838\n",
      "New best model found at epoch 47 with validation loss 1.571742296218872\n",
      "Starting Epoch 48\n",
      "1.6442518804384314\n",
      "Validation loss: 1.5701502561569214\n",
      "mse 1.570150333496078\n",
      "New best model found at epoch 48 with validation loss 1.5701502561569214\n",
      "Starting Epoch 49\n",
      "1.6426052839859673\n",
      "Validation loss: 1.5691086053848267\n",
      "mse 1.569108452544174\n",
      "New best model found at epoch 49 with validation loss 1.5691086053848267\n",
      "Starting Epoch 50\n",
      "1.6412189836087434\n",
      "Validation loss: 1.5677454471588135\n",
      "mse 1.567745569777088\n",
      "New best model found at epoch 50 with validation loss 1.5677454471588135\n",
      "Starting Epoch 51\n",
      "1.639809805413951\n",
      "Validation loss: 1.5661931037902832\n",
      "mse 1.5661929956026563\n",
      "New best model found at epoch 51 with validation loss 1.5661931037902832\n",
      "Starting Epoch 52\n",
      "1.6383472629215405\n",
      "Validation loss: 1.5651390552520752\n",
      "mse 1.5651390403030192\n",
      "New best model found at epoch 52 with validation loss 1.5651390552520752\n",
      "Starting Epoch 53\n",
      "1.6369010987489119\n",
      "Validation loss: 1.5639188289642334\n",
      "mse 1.5639187547271651\n",
      "New best model found at epoch 53 with validation loss 1.5639188289642334\n",
      "Starting Epoch 54\n",
      "1.6355905688327292\n",
      "Validation loss: 1.5629395246505737\n",
      "mse 1.5629394863944377\n",
      "New best model found at epoch 54 with validation loss 1.5629395246505737\n",
      "Starting Epoch 55\n",
      "1.6344680475152058\n",
      "Validation loss: 1.5621302127838135\n",
      "mse 1.5621303347188285\n",
      "New best model found at epoch 55 with validation loss 1.5621302127838135\n",
      "Starting Epoch 56\n",
      "1.6332438147586326\n",
      "Validation loss: 1.5608423948287964\n",
      "mse 1.5608424816936124\n",
      "New best model found at epoch 56 with validation loss 1.5608423948287964\n",
      "Starting Epoch 57\n",
      "1.6321330329646235\n",
      "Validation loss: 1.5598961114883423\n",
      "mse 1.5598962173672322\n",
      "New best model found at epoch 57 with validation loss 1.5598961114883423\n",
      "Starting Epoch 58\n",
      "1.6309438840202664\n",
      "Validation loss: 1.5588871240615845\n",
      "mse 1.5588870631287284\n",
      "New best model found at epoch 58 with validation loss 1.5588871240615845\n",
      "Starting Epoch 59\n",
      "1.6297874398853467\n",
      "Validation loss: 1.5580662488937378\n",
      "mse 1.5580662383967865\n",
      "New best model found at epoch 59 with validation loss 1.5580662488937378\n",
      "Starting Epoch 60\n",
      "1.628566166628962\n",
      "Validation loss: 1.5569950342178345\n",
      "mse 1.5569949446040459\n",
      "New best model found at epoch 60 with validation loss 1.5569950342178345\n",
      "Starting Epoch 61\n",
      "1.627404897109322\n",
      "Validation loss: 1.5559240579605103\n",
      "mse 1.5559240924593982\n",
      "New best model found at epoch 61 with validation loss 1.5559240579605103\n",
      "Starting Epoch 62\n",
      "1.6263020453245745\n",
      "Validation loss: 1.5547810792922974\n",
      "mse 1.5547810305893512\n",
      "New best model found at epoch 62 with validation loss 1.5547810792922974\n",
      "Starting Epoch 63\n",
      "1.6252025521319846\n",
      "Validation loss: 1.5539772510528564\n",
      "mse 1.553977278529598\n",
      "New best model found at epoch 63 with validation loss 1.5539772510528564\n",
      "Starting Epoch 64\n",
      "1.6241948811904243\n",
      "Validation loss: 1.5531500577926636\n",
      "mse 1.5531502175751126\n",
      "New best model found at epoch 64 with validation loss 1.5531500577926636\n",
      "Starting Epoch 65\n",
      "1.6231823019359424\n",
      "Validation loss: 1.5522607564926147\n",
      "mse 1.5522606767908862\n",
      "New best model found at epoch 65 with validation loss 1.5522607564926147\n",
      "Starting Epoch 66\n",
      "1.6222031220145847\n",
      "Validation loss: 1.5514838695526123\n",
      "mse 1.551483753659418\n",
      "New best model found at epoch 66 with validation loss 1.5514838695526123\n",
      "Starting Epoch 67\n",
      "1.6212325873582258\n",
      "Validation loss: 1.550551176071167\n",
      "mse 1.5505510910016833\n",
      "New best model found at epoch 67 with validation loss 1.550551176071167\n",
      "Starting Epoch 68\n",
      "1.6203754311022551\n",
      "Validation loss: 1.549652338027954\n",
      "mse 1.5496524040348374\n",
      "New best model found at epoch 68 with validation loss 1.549652338027954\n",
      "Starting Epoch 69\n",
      "1.6194350823112156\n",
      "Validation loss: 1.5491653680801392\n",
      "mse 1.5491653676585477\n",
      "New best model found at epoch 69 with validation loss 1.5491653680801392\n",
      "Starting Epoch 70\n",
      "1.6186297095340232\n",
      "Validation loss: 1.5480271577835083\n",
      "mse 1.5480271742977418\n",
      "New best model found at epoch 70 with validation loss 1.5480271577835083\n",
      "Starting Epoch 71\n",
      "1.6177062366319739\n",
      "Validation loss: 1.5475274324417114\n",
      "mse 1.5475273924465411\n",
      "New best model found at epoch 71 with validation loss 1.5475274324417114\n",
      "Starting Epoch 72\n",
      "1.6168286126592886\n",
      "Validation loss: 1.5470978021621704\n",
      "mse 1.547097905513645\n",
      "New best model found at epoch 72 with validation loss 1.5470978021621704\n",
      "Starting Epoch 73\n",
      "1.6159331487572712\n",
      "Validation loss: 1.5461176633834839\n",
      "mse 1.5461178032290823\n",
      "New best model found at epoch 73 with validation loss 1.5461176633834839\n",
      "Starting Epoch 74\n",
      "1.6150551516076792\n",
      "Validation loss: 1.5451059341430664\n",
      "mse 1.5451060368657608\n",
      "New best model found at epoch 74 with validation loss 1.5451059341430664\n",
      "Starting Epoch 75\n",
      "1.614051103591919\n",
      "Validation loss: 1.5444608926773071\n",
      "mse 1.544460970709241\n",
      "New best model found at epoch 75 with validation loss 1.5444608926773071\n",
      "Starting Epoch 76\n",
      "1.6129988950231802\n",
      "Validation loss: 1.54340660572052\n",
      "mse 1.5434065221459885\n",
      "New best model found at epoch 76 with validation loss 1.54340660572052\n",
      "Starting Epoch 77\n",
      "1.611904880274897\n",
      "Validation loss: 1.5426000356674194\n",
      "mse 1.5425999461925022\n",
      "New best model found at epoch 77 with validation loss 1.5426000356674194\n",
      "Starting Epoch 78\n",
      "1.6109728243040002\n",
      "Validation loss: 1.541704773902893\n",
      "mse 1.5417048614938251\n",
      "New best model found at epoch 78 with validation loss 1.541704773902893\n",
      "Starting Epoch 79\n",
      "1.6099910839744236\n",
      "Validation loss: 1.540911316871643\n",
      "mse 1.540911377406534\n",
      "New best model found at epoch 79 with validation loss 1.540911316871643\n",
      "Starting Epoch 80\n",
      "1.6092652756234873\n",
      "Validation loss: 1.5402783155441284\n",
      "mse 1.5402782365267875\n",
      "New best model found at epoch 80 with validation loss 1.5402783155441284\n",
      "Starting Epoch 81\n",
      "1.6083182200141575\n",
      "Validation loss: 1.539438009262085\n",
      "mse 1.5394380430537877\n",
      "New best model found at epoch 81 with validation loss 1.539438009262085\n",
      "Starting Epoch 82\n",
      "1.6074170133341914\n",
      "Validation loss: 1.5387120246887207\n",
      "mse 1.5387121760685345\n",
      "New best model found at epoch 82 with validation loss 1.5387120246887207\n",
      "Starting Epoch 83\n",
      "1.6064602577168008\n",
      "Validation loss: 1.5379939079284668\n",
      "mse 1.5379938900813932\n",
      "New best model found at epoch 83 with validation loss 1.5379939079284668\n",
      "Starting Epoch 84\n",
      "1.6055967652279397\n",
      "Validation loss: 1.5374205112457275\n",
      "mse 1.5374207145246868\n",
      "New best model found at epoch 84 with validation loss 1.5374205112457275\n",
      "Starting Epoch 85\n",
      "1.6047161947125974\n",
      "Validation loss: 1.536699891090393\n",
      "mse 1.536700030818524\n",
      "New best model found at epoch 85 with validation loss 1.536699891090393\n",
      "Starting Epoch 86\n",
      "1.6039010338161304\n",
      "Validation loss: 1.5356868505477905\n",
      "mse 1.5356867457150765\n",
      "New best model found at epoch 86 with validation loss 1.5356868505477905\n",
      "Starting Epoch 87\n",
      "1.6031821603360383\n",
      "Validation loss: 1.5351535081863403\n",
      "mse 1.535153569858298\n",
      "New best model found at epoch 87 with validation loss 1.5351535081863403\n",
      "Starting Epoch 88\n",
      "1.602370464283487\n",
      "Validation loss: 1.5343083143234253\n",
      "mse 1.5343082736992477\n",
      "New best model found at epoch 88 with validation loss 1.5343083143234253\n",
      "Starting Epoch 89\n",
      "1.6016784180765566\n",
      "Validation loss: 1.5339571237564087\n",
      "mse 1.5339571075570588\n",
      "New best model found at epoch 89 with validation loss 1.5339571237564087\n",
      "Starting Epoch 90\n",
      "1.6008862438409224\n",
      "Validation loss: 1.5333338975906372\n",
      "mse 1.5333339854024521\n",
      "New best model found at epoch 90 with validation loss 1.5333338975906372\n",
      "Starting Epoch 91\n",
      "1.6001872161160344\n",
      "Validation loss: 1.532750129699707\n",
      "mse 1.5327501928348801\n",
      "New best model found at epoch 91 with validation loss 1.532750129699707\n",
      "Starting Epoch 92\n",
      "1.5994808181472446\n",
      "Validation loss: 1.5320852994918823\n",
      "mse 1.5320850872309795\n",
      "New best model found at epoch 92 with validation loss 1.5320852994918823\n",
      "Starting Epoch 93\n",
      "1.5987994178481724\n",
      "Validation loss: 1.531335473060608\n",
      "mse 1.5313353254487203\n",
      "New best model found at epoch 93 with validation loss 1.531335473060608\n",
      "Starting Epoch 94\n",
      "1.5980798057887866\n",
      "Validation loss: 1.5307185649871826\n",
      "mse 1.5307186803520527\n",
      "New best model found at epoch 94 with validation loss 1.5307185649871826\n",
      "Starting Epoch 95\n",
      "1.5973562364992888\n",
      "Validation loss: 1.529924750328064\n",
      "mse 1.52992465312338\n",
      "New best model found at epoch 95 with validation loss 1.529924750328064\n",
      "Starting Epoch 96\n",
      "1.5967028089191602\n",
      "Validation loss: 1.5293059349060059\n",
      "mse 1.529305873299533\n",
      "New best model found at epoch 96 with validation loss 1.5293059349060059\n",
      "Starting Epoch 97\n",
      "1.5960739928743113\n",
      "Validation loss: 1.5287206172943115\n",
      "mse 1.528720525464022\n",
      "New best model found at epoch 97 with validation loss 1.5287206172943115\n",
      "Starting Epoch 98\n",
      "1.5954377677129663\n",
      "Validation loss: 1.5282725095748901\n",
      "mse 1.528272495532503\n",
      "New best model found at epoch 98 with validation loss 1.5282725095748901\n",
      "Starting Epoch 99\n",
      "1.5947843504988628\n",
      "Validation loss: 1.5277297496795654\n",
      "mse 1.5277296520831387\n",
      "New best model found at epoch 99 with validation loss 1.5277297496795654\n",
      "Starting Epoch 100\n",
      "1.5942719604658044\n",
      "Validation loss: 1.527318000793457\n",
      "mse 1.527318022940731\n",
      "New best model found at epoch 100 with validation loss 1.527318000793457\n",
      "Starting Epoch 101\n",
      "1.593578613322714\n",
      "Validation loss: 1.5265953540802002\n",
      "mse 1.5265953232605431\n",
      "New best model found at epoch 101 with validation loss 1.5265953540802002\n",
      "Starting Epoch 102\n",
      "1.593011094176251\n",
      "Validation loss: 1.526378870010376\n",
      "mse 1.526378773288667\n",
      "New best model found at epoch 102 with validation loss 1.526378870010376\n",
      "Starting Epoch 103\n",
      "1.5924265203268633\n",
      "Validation loss: 1.5256842374801636\n",
      "mse 1.5256842808506035\n",
      "New best model found at epoch 103 with validation loss 1.5256842374801636\n",
      "Starting Epoch 104\n",
      "1.5918234146159629\n",
      "Validation loss: 1.5251847505569458\n",
      "mse 1.5251848632256841\n",
      "New best model found at epoch 104 with validation loss 1.5251847505569458\n",
      "Starting Epoch 105\n",
      "1.591268443542978\n",
      "Validation loss: 1.5251888036727905\n",
      "mse 1.5251887669745419\n",
      "Starting Epoch 106\n",
      "1.5907366016636724\n",
      "Validation loss: 1.5247026681900024\n",
      "mse 1.5247026351814508\n",
      "New best model found at epoch 106 with validation loss 1.5247026681900024\n",
      "Starting Epoch 107\n",
      "1.5901194940442624\n",
      "Validation loss: 1.524829626083374\n",
      "mse 1.5248294110121285\n",
      "Starting Epoch 108\n",
      "1.5896118957063425\n",
      "Validation loss: 1.5239733457565308\n",
      "mse 1.5239733056650675\n",
      "New best model found at epoch 108 with validation loss 1.5239733457565308\n",
      "Starting Epoch 109\n",
      "1.588969165864198\n",
      "Validation loss: 1.5238937139511108\n",
      "mse 1.5238936933294387\n",
      "New best model found at epoch 109 with validation loss 1.5238937139511108\n",
      "Starting Epoch 110\n",
      "1.588457009066706\n",
      "Validation loss: 1.5235824584960938\n",
      "mse 1.5235827058540161\n",
      "New best model found at epoch 110 with validation loss 1.5235824584960938\n",
      "Starting Epoch 111\n",
      "1.5879735765249834\n",
      "Validation loss: 1.5232524871826172\n",
      "mse 1.5232524266644971\n",
      "New best model found at epoch 111 with validation loss 1.5232524871826172\n",
      "Starting Epoch 112\n",
      "1.5873305978982344\n",
      "Validation loss: 1.5227092504501343\n",
      "mse 1.5227091757223592\n",
      "New best model found at epoch 112 with validation loss 1.5227092504501343\n",
      "Starting Epoch 113\n",
      "1.5868259823840598\n",
      "Validation loss: 1.5226680040359497\n",
      "mse 1.5226679610413727\n",
      "New best model found at epoch 113 with validation loss 1.5226680040359497\n",
      "Starting Epoch 114\n",
      "1.58624841078468\n",
      "Validation loss: 1.5219988822937012\n",
      "mse 1.5219988378539324\n",
      "New best model found at epoch 114 with validation loss 1.5219988822937012\n",
      "Starting Epoch 115\n",
      "1.5858139447543933\n",
      "Validation loss: 1.5215810537338257\n",
      "mse 1.5215811232231773\n",
      "New best model found at epoch 115 with validation loss 1.5215810537338257\n",
      "Starting Epoch 116\n",
      "1.5851744620696357\n",
      "Validation loss: 1.5210411548614502\n",
      "mse 1.521041003469575\n",
      "New best model found at epoch 116 with validation loss 1.5210411548614502\n",
      "Starting Epoch 117\n",
      "1.5847162733907285\n",
      "Validation loss: 1.5207672119140625\n",
      "mse 1.5207673342356192\n",
      "New best model found at epoch 117 with validation loss 1.5207672119140625\n",
      "Starting Epoch 118\n",
      "1.5841997887777246\n",
      "Validation loss: 1.5202605724334717\n",
      "mse 1.520260621146854\n",
      "New best model found at epoch 118 with validation loss 1.5202605724334717\n",
      "Starting Epoch 119\n",
      "1.5836306965869407\n",
      "Validation loss: 1.5200505256652832\n",
      "mse 1.5200505360066856\n",
      "New best model found at epoch 119 with validation loss 1.5200505256652832\n",
      "Starting Epoch 120\n",
      "1.583271474941917\n",
      "Validation loss: 1.5195057392120361\n",
      "mse 1.5195058468012994\n",
      "New best model found at epoch 120 with validation loss 1.5195057392120361\n",
      "Starting Epoch 121\n",
      "1.5826815029849177\n",
      "Validation loss: 1.5189088582992554\n",
      "mse 1.51890885510247\n",
      "New best model found at epoch 121 with validation loss 1.5189088582992554\n",
      "Starting Epoch 122\n",
      "1.5821175264275593\n",
      "Validation loss: 1.5188050270080566\n",
      "mse 1.5188049747680934\n",
      "New best model found at epoch 122 with validation loss 1.5188050270080566\n",
      "Starting Epoch 123\n",
      "1.5817620909732322\n",
      "Validation loss: 1.5184205770492554\n",
      "mse 1.5184203931243576\n",
      "New best model found at epoch 123 with validation loss 1.5184205770492554\n",
      "Starting Epoch 124\n",
      "1.5812114114346711\n",
      "Validation loss: 1.5180197954177856\n",
      "mse 1.518019700035618\n",
      "New best model found at epoch 124 with validation loss 1.5180197954177856\n",
      "Starting Epoch 125\n",
      "1.5807076511175737\n",
      "Validation loss: 1.5174695253372192\n",
      "mse 1.5174694514988083\n",
      "New best model found at epoch 125 with validation loss 1.5174695253372192\n",
      "Starting Epoch 126\n",
      "1.5801988891933276\n",
      "Validation loss: 1.5174504518508911\n",
      "mse 1.5174506062527024\n",
      "New best model found at epoch 126 with validation loss 1.5174504518508911\n",
      "Starting Epoch 127\n",
      "1.5798617601394653\n",
      "Validation loss: 1.516793131828308\n",
      "mse 1.516793166193738\n",
      "New best model found at epoch 127 with validation loss 1.516793131828308\n",
      "Starting Epoch 128\n",
      "1.5792951169221296\n",
      "Validation loss: 1.5166630744934082\n",
      "mse 1.5166630680806896\n",
      "New best model found at epoch 128 with validation loss 1.5166630744934082\n",
      "Starting Epoch 129\n",
      "1.5787234384080637\n",
      "Validation loss: 1.516178846359253\n",
      "mse 1.5161787573367018\n",
      "New best model found at epoch 129 with validation loss 1.516178846359253\n",
      "Starting Epoch 130\n",
      "1.5784884846728782\n",
      "Validation loss: 1.5156819820404053\n",
      "mse 1.5156820334096957\n",
      "New best model found at epoch 130 with validation loss 1.5156819820404053\n",
      "Starting Epoch 131\n",
      "1.5779440117918926\n",
      "Validation loss: 1.5155742168426514\n",
      "mse 1.515574253480845\n",
      "New best model found at epoch 131 with validation loss 1.5155742168426514\n",
      "Starting Epoch 132\n",
      "1.5774844340656116\n",
      "Validation loss: 1.515059471130371\n",
      "mse 1.5150593925508218\n",
      "New best model found at epoch 132 with validation loss 1.515059471130371\n",
      "Starting Epoch 133\n",
      "1.5769575186397717\n",
      "Validation loss: 1.514923334121704\n",
      "mse 1.5149233608715107\n",
      "New best model found at epoch 133 with validation loss 1.514923334121704\n",
      "Starting Epoch 134\n",
      "1.5766714889070261\n",
      "Validation loss: 1.5145974159240723\n",
      "mse 1.514597526233186\n",
      "New best model found at epoch 134 with validation loss 1.5145974159240723\n",
      "Starting Epoch 135\n",
      "1.5761315537535625\n",
      "Validation loss: 1.5142496824264526\n",
      "mse 1.5142497926236342\n",
      "New best model found at epoch 135 with validation loss 1.5142496824264526\n",
      "Starting Epoch 136\n",
      "1.575701716153518\n",
      "Validation loss: 1.514037847518921\n",
      "mse 1.5140378634120555\n",
      "New best model found at epoch 136 with validation loss 1.514037847518921\n",
      "Starting Epoch 137\n",
      "1.575188582358153\n",
      "Validation loss: 1.5137988328933716\n",
      "mse 1.5137988271270908\n",
      "New best model found at epoch 137 with validation loss 1.5137988328933716\n",
      "Starting Epoch 138\n",
      "1.574886962123539\n",
      "Validation loss: 1.513552188873291\n",
      "mse 1.5135522123131926\n",
      "New best model found at epoch 138 with validation loss 1.513552188873291\n",
      "Starting Epoch 139\n",
      "1.5743774460709614\n",
      "Validation loss: 1.5132529735565186\n",
      "mse 1.5132529957233432\n",
      "New best model found at epoch 139 with validation loss 1.5132529735565186\n",
      "Starting Epoch 140\n",
      "1.5738920906315679\n",
      "Validation loss: 1.5128346681594849\n",
      "mse 1.5128347828142874\n",
      "New best model found at epoch 140 with validation loss 1.5128346681594849\n",
      "Starting Epoch 141\n",
      "1.57347476741542\n",
      "Validation loss: 1.512338399887085\n",
      "mse 1.5123383726460802\n",
      "New best model found at epoch 141 with validation loss 1.512338399887085\n",
      "Starting Epoch 142\n",
      "1.5730672349100527\n",
      "Validation loss: 1.5119010210037231\n",
      "mse 1.5119011072328603\n",
      "New best model found at epoch 142 with validation loss 1.5119010210037231\n",
      "Starting Epoch 143\n",
      "1.5725201808887979\n",
      "Validation loss: 1.5115159749984741\n",
      "mse 1.5115158959641066\n",
      "New best model found at epoch 143 with validation loss 1.5115159749984741\n",
      "Starting Epoch 144\n",
      "1.5721180413080298\n",
      "Validation loss: 1.5110489130020142\n",
      "mse 1.5110488249719978\n",
      "New best model found at epoch 144 with validation loss 1.5110489130020142\n",
      "Starting Epoch 145\n",
      "1.5716365783110908\n",
      "Validation loss: 1.510726809501648\n",
      "mse 1.5107268654748272\n",
      "New best model found at epoch 145 with validation loss 1.510726809501648\n",
      "Starting Epoch 146\n",
      "1.5712637046109075\n",
      "Validation loss: 1.5104912519454956\n",
      "mse 1.5104911691177254\n",
      "New best model found at epoch 146 with validation loss 1.5104912519454956\n",
      "Starting Epoch 147\n",
      "1.5708226354225823\n",
      "Validation loss: 1.5099432468414307\n",
      "mse 1.5099432907072814\n",
      "New best model found at epoch 147 with validation loss 1.5099432468414307\n",
      "Starting Epoch 148\n",
      "1.5703548529873723\n",
      "Validation loss: 1.5095826387405396\n",
      "mse 1.5095827398582202\n",
      "New best model found at epoch 148 with validation loss 1.5095826387405396\n",
      "Starting Epoch 149\n",
      "1.5699709705684497\n",
      "Validation loss: 1.5090631246566772\n",
      "mse 1.5090631463415771\n",
      "New best model found at epoch 149 with validation loss 1.5090631246566772\n",
      "Starting Epoch 150\n",
      "1.5694639397704082\n",
      "Validation loss: 1.5083539485931396\n",
      "mse 1.5083540574852692\n",
      "New best model found at epoch 150 with validation loss 1.5083539485931396\n",
      "Starting Epoch 151\n",
      "1.5686640869016233\n",
      "Validation loss: 1.5081686973571777\n",
      "mse 1.5081687187371475\n",
      "New best model found at epoch 151 with validation loss 1.5081686973571777\n",
      "Starting Epoch 152\n",
      "1.5677701727203701\n",
      "Validation loss: 1.5077763795852661\n",
      "mse 1.5077763351188187\n",
      "New best model found at epoch 152 with validation loss 1.5077763795852661\n",
      "Starting Epoch 153\n",
      "1.5669489995292996\n",
      "Validation loss: 1.507167100906372\n",
      "mse 1.5071670235652146\n",
      "New best model found at epoch 153 with validation loss 1.507167100906372\n",
      "Starting Epoch 154\n",
      "1.5659745231918667\n",
      "Validation loss: 1.5069917440414429\n",
      "mse 1.5069915339276443\n",
      "New best model found at epoch 154 with validation loss 1.5069917440414429\n",
      "Starting Epoch 155\n",
      "1.5652240644330564\n",
      "Validation loss: 1.5067893266677856\n",
      "mse 1.506789242237893\n",
      "New best model found at epoch 155 with validation loss 1.5067893266677856\n",
      "Starting Epoch 156\n",
      "1.5643475988636846\n",
      "Validation loss: 1.5063532590866089\n",
      "mse 1.5063532871105878\n",
      "New best model found at epoch 156 with validation loss 1.5063532590866089\n",
      "Starting Epoch 157\n",
      "1.563541433085566\n",
      "Validation loss: 1.5059353113174438\n",
      "mse 1.5059353244948541\n",
      "New best model found at epoch 157 with validation loss 1.5059353113174438\n",
      "Starting Epoch 158\n",
      "1.562768886918607\n",
      "Validation loss: 1.5057942867279053\n",
      "mse 1.5057942675560703\n",
      "New best model found at epoch 158 with validation loss 1.5057942867279053\n",
      "Starting Epoch 159\n",
      "1.5620941027351047\n",
      "Validation loss: 1.5056957006454468\n",
      "mse 1.5056956174689544\n",
      "New best model found at epoch 159 with validation loss 1.5056957006454468\n",
      "Starting Epoch 160\n",
      "1.5614761839742246\n",
      "Validation loss: 1.505450963973999\n",
      "mse 1.5054509314015287\n",
      "New best model found at epoch 160 with validation loss 1.505450963973999\n",
      "Starting Epoch 161\n",
      "1.5608562049658403\n",
      "Validation loss: 1.505152940750122\n",
      "mse 1.5051527803355609\n",
      "New best model found at epoch 161 with validation loss 1.505152940750122\n",
      "Starting Epoch 162\n",
      "1.5601954771124797\n",
      "Validation loss: 1.5050067901611328\n",
      "mse 1.5050067527274118\n",
      "New best model found at epoch 162 with validation loss 1.5050067901611328\n",
      "Starting Epoch 163\n",
      "1.5595472843750664\n",
      "Validation loss: 1.5044184923171997\n",
      "mse 1.5044184747341478\n",
      "New best model found at epoch 163 with validation loss 1.5044184923171997\n",
      "Starting Epoch 164\n",
      "1.558731628500897\n",
      "Validation loss: 1.504265546798706\n",
      "mse 1.5042657069243015\n",
      "New best model found at epoch 164 with validation loss 1.504265546798706\n",
      "Starting Epoch 165\n",
      "1.558131067649178\n",
      "Validation loss: 1.5038399696350098\n",
      "mse 1.5038400828904153\n",
      "New best model found at epoch 165 with validation loss 1.5038399696350098\n",
      "Starting Epoch 166\n",
      "1.5574735480806101\n",
      "Validation loss: 1.503797173500061\n",
      "mse 1.503797180804845\n",
      "New best model found at epoch 166 with validation loss 1.503797173500061\n",
      "Starting Epoch 167\n",
      "1.556907208069511\n",
      "Validation loss: 1.503811240196228\n",
      "mse 1.5038112814566593\n",
      "Starting Epoch 168\n",
      "1.5564121655795886\n",
      "Validation loss: 1.5034539699554443\n",
      "mse 1.5034539418484854\n",
      "New best model found at epoch 168 with validation loss 1.5034539699554443\n",
      "Starting Epoch 169\n",
      "1.555854937304621\n",
      "Validation loss: 1.5032292604446411\n",
      "mse 1.503229331043015\n",
      "New best model found at epoch 169 with validation loss 1.5032292604446411\n",
      "Starting Epoch 170\n",
      "1.5553627973017485\n",
      "Validation loss: 1.502910852432251\n",
      "mse 1.5029109381571635\n",
      "New best model found at epoch 170 with validation loss 1.502910852432251\n",
      "Starting Epoch 171\n",
      "1.5548861259999482\n",
      "Validation loss: 1.5027145147323608\n",
      "mse 1.5027147040816649\n",
      "New best model found at epoch 171 with validation loss 1.5027145147323608\n",
      "Starting Epoch 172\n",
      "1.5544297047283337\n",
      "Validation loss: 1.5024083852767944\n",
      "mse 1.5024083524812948\n",
      "New best model found at epoch 172 with validation loss 1.5024083852767944\n",
      "Starting Epoch 173\n",
      "1.5539993229119673\n",
      "Validation loss: 1.5020577907562256\n",
      "mse 1.502057720032434\n",
      "New best model found at epoch 173 with validation loss 1.5020577907562256\n",
      "Starting Epoch 174\n",
      "1.5535003905710967\n",
      "Validation loss: 1.5019227266311646\n",
      "mse 1.501922804124374\n",
      "New best model found at epoch 174 with validation loss 1.5019227266311646\n",
      "Starting Epoch 175\n",
      "1.5530763838602148\n",
      "Validation loss: 1.5016168355941772\n",
      "mse 1.501616801143348\n",
      "New best model found at epoch 175 with validation loss 1.5016168355941772\n",
      "Starting Epoch 176\n",
      "1.552632466606472\n",
      "Validation loss: 1.5011390447616577\n",
      "mse 1.501139052196687\n",
      "New best model found at epoch 176 with validation loss 1.5011390447616577\n",
      "Starting Epoch 177\n",
      "1.5522010144980058\n",
      "Validation loss: 1.5005406141281128\n",
      "mse 1.500540723775222\n",
      "New best model found at epoch 177 with validation loss 1.5005406141281128\n",
      "Starting Epoch 178\n",
      "1.5517766890318498\n",
      "Validation loss: 1.5003652572631836\n",
      "mse 1.5003651924981731\n",
      "New best model found at epoch 178 with validation loss 1.5003652572631836\n",
      "Starting Epoch 179\n",
      "1.5512836808743684\n",
      "Validation loss: 1.5000462532043457\n",
      "mse 1.5000462869782059\n",
      "New best model found at epoch 179 with validation loss 1.5000462532043457\n",
      "Starting Epoch 180\n",
      "1.5508505157802417\n",
      "Validation loss: 1.499680995941162\n",
      "mse 1.499680877103138\n",
      "New best model found at epoch 180 with validation loss 1.499680995941162\n",
      "Starting Epoch 181\n",
      "1.5504565135292385\n",
      "Validation loss: 1.4993815422058105\n",
      "mse 1.4993815058753408\n",
      "New best model found at epoch 181 with validation loss 1.4993815422058105\n",
      "Starting Epoch 182\n",
      "1.549981187219205\n",
      "Validation loss: 1.4991419315338135\n",
      "mse 1.4991418743558673\n",
      "New best model found at epoch 182 with validation loss 1.4991419315338135\n",
      "Starting Epoch 183\n",
      "1.54954622361971\n",
      "Validation loss: 1.4987788200378418\n",
      "mse 1.4987786722573115\n",
      "New best model found at epoch 183 with validation loss 1.4987788200378418\n",
      "Starting Epoch 184\n",
      "1.549122742984606\n",
      "Validation loss: 1.4985387325286865\n",
      "mse 1.498538892441236\n",
      "New best model found at epoch 184 with validation loss 1.4985387325286865\n",
      "Starting Epoch 185\n",
      "1.5486313467440398\n",
      "Validation loss: 1.4982165098190308\n",
      "mse 1.4982165662988063\n",
      "New best model found at epoch 185 with validation loss 1.4982165098190308\n",
      "Starting Epoch 186\n",
      "1.5482221582661504\n",
      "Validation loss: 1.4979517459869385\n",
      "mse 1.4979517232994917\n",
      "New best model found at epoch 186 with validation loss 1.4979517459869385\n",
      "Starting Epoch 187\n",
      "1.5477755173392918\n",
      "Validation loss: 1.4976089000701904\n",
      "mse 1.497608927931059\n",
      "New best model found at epoch 187 with validation loss 1.4976089000701904\n",
      "Starting Epoch 188\n",
      "1.5473599848539934\n",
      "Validation loss: 1.4973546266555786\n",
      "mse 1.4973546949137657\n",
      "New best model found at epoch 188 with validation loss 1.4973546266555786\n",
      "Starting Epoch 189\n",
      "1.5469375693279763\n",
      "Validation loss: 1.4971078634262085\n",
      "mse 1.497107890757222\n",
      "New best model found at epoch 189 with validation loss 1.4971078634262085\n",
      "Starting Epoch 190\n",
      "1.5464954764946648\n",
      "Validation loss: 1.4968597888946533\n",
      "mse 1.496859763256609\n",
      "New best model found at epoch 190 with validation loss 1.4968597888946533\n",
      "Starting Epoch 191\n",
      "1.5460592300995537\n",
      "Validation loss: 1.4965126514434814\n",
      "mse 1.4965125303253537\n",
      "New best model found at epoch 191 with validation loss 1.4965126514434814\n",
      "Starting Epoch 192\n",
      "1.545597027177396\n",
      "Validation loss: 1.4960495233535767\n",
      "mse 1.496049496539341\n",
      "New best model found at epoch 192 with validation loss 1.4960495233535767\n",
      "Starting Epoch 193\n",
      "1.5451802352200383\n",
      "Validation loss: 1.4959306716918945\n",
      "mse 1.4959307128582653\n",
      "New best model found at epoch 193 with validation loss 1.4959306716918945\n",
      "Starting Epoch 194\n",
      "1.544712914072949\n",
      "Validation loss: 1.49546480178833\n",
      "mse 1.4954649356726983\n",
      "New best model found at epoch 194 with validation loss 1.49546480178833\n",
      "Starting Epoch 195\n",
      "1.5443422379701033\n",
      "Validation loss: 1.4949805736541748\n",
      "mse 1.4949805745562315\n",
      "New best model found at epoch 195 with validation loss 1.4949805736541748\n",
      "Starting Epoch 196\n",
      "1.5438171055005945\n",
      "Validation loss: 1.494566559791565\n",
      "mse 1.4945667181478557\n",
      "New best model found at epoch 196 with validation loss 1.494566559791565\n",
      "Starting Epoch 197\n",
      "1.5433507794919221\n",
      "Validation loss: 1.494100570678711\n",
      "mse 1.494100533762422\n",
      "New best model found at epoch 197 with validation loss 1.494100570678711\n",
      "Starting Epoch 198\n",
      "1.5428773579390154\n",
      "Validation loss: 1.4936670064926147\n",
      "mse 1.4936669980020616\n",
      "New best model found at epoch 198 with validation loss 1.4936670064926147\n",
      "Starting Epoch 199\n",
      "1.5424058877903482\n",
      "Validation loss: 1.493050217628479\n",
      "mse 1.4930501237497704\n",
      "New best model found at epoch 199 with validation loss 1.493050217628479\n",
      "Starting Epoch 200\n",
      "1.5418972373008728\n",
      "Validation loss: 1.4925625324249268\n",
      "mse 1.4925626756655457\n",
      "New best model found at epoch 200 with validation loss 1.4925625324249268\n",
      "Starting Epoch 201\n",
      "1.5414643313573755\n",
      "Validation loss: 1.4922778606414795\n",
      "mse 1.4922779600388496\n",
      "New best model found at epoch 201 with validation loss 1.4922778606414795\n",
      "Starting Epoch 202\n",
      "1.5409977202830107\n",
      "Validation loss: 1.4915364980697632\n",
      "mse 1.4915363741856391\n",
      "New best model found at epoch 202 with validation loss 1.4915364980697632\n",
      "Starting Epoch 203\n",
      "1.540502149125804\n",
      "Validation loss: 1.4912536144256592\n",
      "mse 1.4912536445978362\n",
      "New best model found at epoch 203 with validation loss 1.4912536144256592\n",
      "Starting Epoch 204\n",
      "1.5400754006012627\n",
      "Validation loss: 1.4908816814422607\n",
      "mse 1.4908815972376497\n",
      "New best model found at epoch 204 with validation loss 1.4908816814422607\n",
      "Starting Epoch 205\n",
      "1.5396097250606702\n",
      "Validation loss: 1.4904446601867676\n",
      "mse 1.4904448053225388\n",
      "New best model found at epoch 205 with validation loss 1.4904446601867676\n",
      "Starting Epoch 206\n",
      "1.5391461382741514\n",
      "Validation loss: 1.4901381731033325\n",
      "mse 1.4901381528875202\n",
      "New best model found at epoch 206 with validation loss 1.4901381731033325\n",
      "Starting Epoch 207\n",
      "1.5387357214222783\n",
      "Validation loss: 1.4894424676895142\n",
      "mse 1.4894424975788532\n",
      "New best model found at epoch 207 with validation loss 1.4894424676895142\n",
      "Starting Epoch 208\n",
      "1.5383102349613025\n",
      "Validation loss: 1.48910653591156\n",
      "mse 1.4891065746045977\n",
      "New best model found at epoch 208 with validation loss 1.48910653591156\n",
      "Starting Epoch 209\n",
      "1.5378009754678477\n",
      "Validation loss: 1.4887807369232178\n",
      "mse 1.4887806925980054\n",
      "New best model found at epoch 209 with validation loss 1.4887807369232178\n",
      "Starting Epoch 210\n",
      "1.5373099057570747\n",
      "Validation loss: 1.4882237911224365\n",
      "mse 1.4882237428967695\n",
      "New best model found at epoch 210 with validation loss 1.4882237911224365\n",
      "Starting Epoch 211\n",
      "1.5368508281915083\n",
      "Validation loss: 1.4878910779953003\n",
      "mse 1.487891102296605\n",
      "New best model found at epoch 211 with validation loss 1.4878910779953003\n",
      "Starting Epoch 212\n",
      "1.5365200379620427\n",
      "Validation loss: 1.4874686002731323\n",
      "mse 1.4874685965092433\n",
      "New best model found at epoch 212 with validation loss 1.4874686002731323\n",
      "Starting Epoch 213\n",
      "1.5359819324120232\n",
      "Validation loss: 1.4869306087493896\n",
      "mse 1.4869304185899186\n",
      "New best model found at epoch 213 with validation loss 1.4869306087493896\n",
      "Starting Epoch 214\n",
      "1.5356159858081653\n",
      "Validation loss: 1.4867454767227173\n",
      "mse 1.4867456586059822\n",
      "New best model found at epoch 214 with validation loss 1.4867454767227173\n",
      "Starting Epoch 215\n",
      "1.5351253773855127\n",
      "Validation loss: 1.4862686395645142\n",
      "mse 1.486268653159078\n",
      "New best model found at epoch 215 with validation loss 1.4862686395645142\n",
      "Starting Epoch 216\n",
      "1.5347783358200737\n",
      "Validation loss: 1.4861407279968262\n",
      "mse 1.4861407986663684\n",
      "New best model found at epoch 216 with validation loss 1.4861407279968262\n",
      "Starting Epoch 217\n",
      "1.5342837779418281\n",
      "Validation loss: 1.4855543375015259\n",
      "mse 1.485554298826695\n",
      "New best model found at epoch 217 with validation loss 1.4855543375015259\n",
      "Starting Epoch 218\n",
      "1.5339293505834497\n",
      "Validation loss: 1.4851202964782715\n",
      "mse 1.4851203397275967\n",
      "New best model found at epoch 218 with validation loss 1.4851202964782715\n",
      "Starting Epoch 219\n",
      "1.5335603226786074\n",
      "Validation loss: 1.4850021600723267\n",
      "mse 1.4850022265664895\n",
      "New best model found at epoch 219 with validation loss 1.4850021600723267\n",
      "Starting Epoch 220\n",
      "1.533123324746671\n",
      "Validation loss: 1.4845467805862427\n",
      "mse 1.484546809662505\n",
      "New best model found at epoch 220 with validation loss 1.4845467805862427\n",
      "Starting Epoch 221\n",
      "1.5326515798983367\n",
      "Validation loss: 1.4846004247665405\n",
      "mse 1.4846005106972695\n",
      "Starting Epoch 222\n",
      "1.532277744749318\n",
      "Validation loss: 1.484071969985962\n",
      "mse 1.4840719760312358\n",
      "New best model found at epoch 222 with validation loss 1.484071969985962\n",
      "Starting Epoch 223\n",
      "1.5317569737849028\n",
      "Validation loss: 1.4839223623275757\n",
      "mse 1.4839223575571134\n",
      "New best model found at epoch 223 with validation loss 1.4839223623275757\n",
      "Starting Epoch 224\n",
      "1.5314104919848235\n",
      "Validation loss: 1.483425259590149\n",
      "mse 1.4834251354554453\n",
      "New best model found at epoch 224 with validation loss 1.483425259590149\n",
      "Starting Epoch 225\n",
      "1.5309104375217273\n",
      "Validation loss: 1.482802152633667\n",
      "mse 1.4828021115228958\n",
      "New best model found at epoch 225 with validation loss 1.482802152633667\n",
      "Starting Epoch 226\n",
      "1.5303662859875222\n",
      "Validation loss: 1.4823634624481201\n",
      "mse 1.4823635211463597\n",
      "New best model found at epoch 226 with validation loss 1.4823634624481201\n",
      "Starting Epoch 227\n",
      "1.5298972311227217\n",
      "Validation loss: 1.4815729856491089\n",
      "mse 1.481572955542223\n",
      "New best model found at epoch 227 with validation loss 1.4815729856491089\n",
      "Starting Epoch 228\n",
      "1.5293654695801113\n",
      "Validation loss: 1.4811619520187378\n",
      "mse 1.4811619243442005\n",
      "New best model found at epoch 228 with validation loss 1.4811619520187378\n",
      "Starting Epoch 229\n",
      "1.5289162501044895\n",
      "Validation loss: 1.4805892705917358\n",
      "mse 1.4805893186693433\n",
      "New best model found at epoch 229 with validation loss 1.4805892705917358\n",
      "Starting Epoch 230\n",
      "1.5284333462300508\n",
      "Validation loss: 1.4800496101379395\n",
      "mse 1.4800495899631632\n",
      "New best model found at epoch 230 with validation loss 1.4800496101379395\n",
      "Starting Epoch 231\n",
      "1.5279760568038276\n",
      "Validation loss: 1.479437232017517\n",
      "mse 1.4794372239604434\n",
      "New best model found at epoch 231 with validation loss 1.479437232017517\n",
      "Starting Epoch 232\n",
      "1.5274728588435962\n",
      "Validation loss: 1.4790711402893066\n",
      "mse 1.4790712531434274\n",
      "New best model found at epoch 232 with validation loss 1.4790711402893066\n",
      "Starting Epoch 233\n",
      "1.5270476755888567\n",
      "Validation loss: 1.4786138534545898\n",
      "mse 1.4786138278122594\n",
      "New best model found at epoch 233 with validation loss 1.4786138534545898\n",
      "Starting Epoch 234\n",
      "1.5265694960303928\n",
      "Validation loss: 1.4780949354171753\n",
      "mse 1.4780949389182154\n",
      "New best model found at epoch 234 with validation loss 1.4780949354171753\n",
      "Starting Epoch 235\n",
      "1.5261029471521792\n",
      "Validation loss: 1.4774845838546753\n",
      "mse 1.4774846233633652\n",
      "New best model found at epoch 235 with validation loss 1.4774845838546753\n",
      "Starting Epoch 236\n",
      "1.5256359369858452\n",
      "Validation loss: 1.4769933223724365\n",
      "mse 1.4769932890780957\n",
      "New best model found at epoch 236 with validation loss 1.4769933223724365\n",
      "Starting Epoch 237\n",
      "1.5250477842662646\n",
      "Validation loss: 1.476828694343567\n",
      "mse 1.4768287466916212\n",
      "New best model found at epoch 237 with validation loss 1.476828694343567\n",
      "Starting Epoch 238\n",
      "1.5246436129445615\n",
      "Validation loss: 1.4761505126953125\n",
      "mse 1.4761504887955352\n",
      "New best model found at epoch 238 with validation loss 1.4761505126953125\n",
      "Starting Epoch 239\n",
      "1.5241039835888406\n",
      "Validation loss: 1.4759912490844727\n",
      "mse 1.4759911050551464\n",
      "New best model found at epoch 239 with validation loss 1.4759912490844727\n",
      "Starting Epoch 240\n",
      "1.5235920341118523\n",
      "Validation loss: 1.4756369590759277\n",
      "mse 1.475636887872016\n",
      "New best model found at epoch 240 with validation loss 1.4756369590759277\n",
      "Starting Epoch 241\n",
      "1.5231009307114973\n",
      "Validation loss: 1.4753389358520508\n",
      "mse 1.4753387617653893\n",
      "New best model found at epoch 241 with validation loss 1.4753389358520508\n",
      "Starting Epoch 242\n",
      "1.5226792900458626\n",
      "Validation loss: 1.4745324850082397\n",
      "mse 1.4745322956711786\n",
      "New best model found at epoch 242 with validation loss 1.4745324850082397\n",
      "Starting Epoch 243\n",
      "1.5219790417215098\n",
      "Validation loss: 1.474284052848816\n",
      "mse 1.474284097631275\n",
      "New best model found at epoch 243 with validation loss 1.474284052848816\n",
      "Starting Epoch 244\n",
      "1.5213911351950273\n",
      "Validation loss: 1.4734758138656616\n",
      "mse 1.4734757748632628\n",
      "New best model found at epoch 244 with validation loss 1.4734758138656616\n",
      "Starting Epoch 245\n",
      "1.5206158394398896\n",
      "Validation loss: 1.4733221530914307\n",
      "mse 1.473322285819195\n",
      "New best model found at epoch 245 with validation loss 1.4733221530914307\n",
      "Starting Epoch 246\n",
      "1.520144107549087\n",
      "Validation loss: 1.4728020429611206\n",
      "mse 1.4728019874867075\n",
      "New best model found at epoch 246 with validation loss 1.4728020429611206\n",
      "Starting Epoch 247\n",
      "1.519577321798905\n",
      "Validation loss: 1.4729561805725098\n",
      "mse 1.472956128636231\n",
      "Starting Epoch 248\n",
      "1.5191672496173694\n",
      "Validation loss: 1.47259521484375\n",
      "mse 1.4725953168335997\n",
      "New best model found at epoch 248 with validation loss 1.47259521484375\n",
      "Starting Epoch 249\n",
      "1.5187187194824219\n",
      "Validation loss: 1.472446084022522\n",
      "mse 1.4724459819237443\n",
      "New best model found at epoch 249 with validation loss 1.472446084022522\n",
      "Starting Epoch 250\n",
      "1.5183199695918872\n",
      "Validation loss: 1.4722529649734497\n",
      "mse 1.4722530072678721\n",
      "New best model found at epoch 250 with validation loss 1.4722529649734497\n",
      "Starting Epoch 251\n",
      "1.5177987399308577\n",
      "Validation loss: 1.4721623659133911\n",
      "mse 1.4721622192954957\n",
      "New best model found at epoch 251 with validation loss 1.4721623659133911\n",
      "Starting Epoch 252\n",
      "1.5174913950588391\n",
      "Validation loss: 1.4714573621749878\n",
      "mse 1.4714572473004763\n",
      "New best model found at epoch 252 with validation loss 1.4714573621749878\n",
      "Starting Epoch 253\n",
      "1.5170575872711514\n",
      "Validation loss: 1.471388578414917\n",
      "mse 1.4713886340642965\n",
      "New best model found at epoch 253 with validation loss 1.471388578414917\n",
      "Starting Epoch 254\n",
      "1.516534509866134\n",
      "Validation loss: 1.471143364906311\n",
      "mse 1.4711434258021612\n",
      "New best model found at epoch 254 with validation loss 1.471143364906311\n",
      "Starting Epoch 255\n",
      "1.5161950406820879\n",
      "Validation loss: 1.4707614183425903\n",
      "mse 1.4707613266337916\n",
      "New best model found at epoch 255 with validation loss 1.4707614183425903\n",
      "Starting Epoch 256\n",
      "1.5157531888588616\n",
      "Validation loss: 1.4706029891967773\n",
      "mse 1.4706029606646704\n",
      "New best model found at epoch 256 with validation loss 1.4706029891967773\n",
      "Starting Epoch 257\n",
      "1.515313887077829\n",
      "Validation loss: 1.4704086780548096\n",
      "mse 1.4704085359751213\n",
      "New best model found at epoch 257 with validation loss 1.4704086780548096\n",
      "Starting Epoch 258\n",
      "1.5149843355883723\n",
      "Validation loss: 1.4699451923370361\n",
      "mse 1.4699451194965134\n",
      "New best model found at epoch 258 with validation loss 1.4699451923370361\n",
      "Starting Epoch 259\n",
      "1.514534364575925\n",
      "Validation loss: 1.469602346420288\n",
      "mse 1.4696023239134453\n",
      "New best model found at epoch 259 with validation loss 1.469602346420288\n",
      "Starting Epoch 260\n",
      "1.5141775944958562\n",
      "Validation loss: 1.4691418409347534\n",
      "mse 1.4691418246840535\n",
      "New best model found at epoch 260 with validation loss 1.4691418409347534\n",
      "Starting Epoch 261\n",
      "1.513685887274535\n",
      "Validation loss: 1.4690945148468018\n",
      "mse 1.469094551164364\n",
      "New best model found at epoch 261 with validation loss 1.4690945148468018\n",
      "Starting Epoch 262\n",
      "1.5132776654284934\n",
      "Validation loss: 1.4686475992202759\n",
      "mse 1.4686476104284079\n",
      "New best model found at epoch 262 with validation loss 1.4686475992202759\n",
      "Starting Epoch 263\n",
      "1.5128280935080156\n",
      "Validation loss: 1.4687892198562622\n",
      "mse 1.4687892417898227\n",
      "Starting Epoch 264\n",
      "1.5124901844107586\n",
      "Validation loss: 1.4683496952056885\n",
      "mse 1.468349724690134\n",
      "New best model found at epoch 264 with validation loss 1.4683496952056885\n",
      "Starting Epoch 265\n",
      "1.5120251515637273\n",
      "Validation loss: 1.4682639837265015\n",
      "mse 1.4682638698389603\n",
      "New best model found at epoch 265 with validation loss 1.4682639837265015\n",
      "Starting Epoch 266\n",
      "1.5116841663484988\n",
      "Validation loss: 1.467863917350769\n",
      "mse 1.467863920508783\n",
      "New best model found at epoch 266 with validation loss 1.467863917350769\n",
      "Starting Epoch 267\n",
      "1.5112810756849206\n",
      "Validation loss: 1.4676774740219116\n",
      "mse 1.4676775767928982\n",
      "New best model found at epoch 267 with validation loss 1.4676774740219116\n",
      "Starting Epoch 268\n",
      "1.510947100494219\n",
      "Validation loss: 1.4673137664794922\n",
      "mse 1.4673137802946057\n",
      "New best model found at epoch 268 with validation loss 1.4673137664794922\n",
      "Starting Epoch 269\n",
      "1.5104193791099216\n",
      "Validation loss: 1.4673086404800415\n",
      "mse 1.4673087195703653\n",
      "New best model found at epoch 269 with validation loss 1.4673086404800415\n",
      "Starting Epoch 270\n",
      "1.5101866229720737\n",
      "Validation loss: 1.4667198657989502\n",
      "mse 1.4667199735210332\n",
      "New best model found at epoch 270 with validation loss 1.4667198657989502\n",
      "Starting Epoch 271\n",
      "1.5097200974174168\n",
      "Validation loss: 1.4666638374328613\n",
      "mse 1.4666639076933548\n",
      "New best model found at epoch 271 with validation loss 1.4666638374328613\n",
      "Starting Epoch 272\n",
      "1.5093904267186704\n",
      "Validation loss: 1.4661452770233154\n",
      "mse 1.466145307988254\n",
      "New best model found at epoch 272 with validation loss 1.4661452770233154\n",
      "Starting Epoch 273\n",
      "1.508948802947998\n",
      "Validation loss: 1.4661046266555786\n",
      "mse 1.466104545204043\n",
      "New best model found at epoch 273 with validation loss 1.4661046266555786\n",
      "Starting Epoch 274\n",
      "1.508467850477799\n",
      "Validation loss: 1.4659969806671143\n",
      "mse 1.4659970735780612\n",
      "New best model found at epoch 274 with validation loss 1.4659969806671143\n",
      "Starting Epoch 275\n",
      "1.5081915388936582\n",
      "Validation loss: 1.4654749631881714\n",
      "mse 1.4654749341198077\n",
      "New best model found at epoch 275 with validation loss 1.4654749631881714\n",
      "Starting Epoch 276\n",
      "1.50770851580993\n",
      "Validation loss: 1.4653925895690918\n",
      "mse 1.4653926920685965\n",
      "New best model found at epoch 276 with validation loss 1.4653925895690918\n",
      "Starting Epoch 277\n",
      "1.507461148759593\n",
      "Validation loss: 1.4650548696517944\n",
      "mse 1.4650549216268611\n",
      "New best model found at epoch 277 with validation loss 1.4650548696517944\n",
      "Starting Epoch 278\n",
      "1.5070822316667307\n",
      "Validation loss: 1.4645787477493286\n",
      "mse 1.4645787874866172\n",
      "New best model found at epoch 278 with validation loss 1.4645787477493286\n",
      "Starting Epoch 279\n",
      "1.5066642890805784\n",
      "Validation loss: 1.4643317461013794\n",
      "mse 1.4643316510777042\n",
      "New best model found at epoch 279 with validation loss 1.4643317461013794\n",
      "Starting Epoch 280\n",
      "1.5062221521916597\n",
      "Validation loss: 1.464301347732544\n",
      "mse 1.4643013041763426\n",
      "New best model found at epoch 280 with validation loss 1.464301347732544\n",
      "Starting Epoch 281\n",
      "1.5060174905735513\n",
      "Validation loss: 1.4637259244918823\n",
      "mse 1.4637258323886577\n",
      "New best model found at epoch 281 with validation loss 1.4637259244918823\n",
      "Starting Epoch 282\n",
      "1.505519299403481\n",
      "Validation loss: 1.4634077548980713\n",
      "mse 1.4634076904626745\n",
      "New best model found at epoch 282 with validation loss 1.4634077548980713\n",
      "Starting Epoch 283\n",
      "1.5052588659784067\n",
      "Validation loss: 1.4630335569381714\n",
      "mse 1.463033606738758\n",
      "New best model found at epoch 283 with validation loss 1.4630335569381714\n",
      "Starting Epoch 284\n",
      "1.5048422606095024\n",
      "Validation loss: 1.4627853631973267\n",
      "mse 1.4627852711282645\n",
      "New best model found at epoch 284 with validation loss 1.4627853631973267\n",
      "Starting Epoch 285\n",
      "1.5045210123062134\n",
      "Validation loss: 1.4622052907943726\n",
      "mse 1.4622052148314337\n",
      "New best model found at epoch 285 with validation loss 1.4622052907943726\n",
      "Starting Epoch 286\n",
      "1.5041496935098067\n",
      "Validation loss: 1.462448239326477\n",
      "mse 1.4624481201995148\n",
      "Starting Epoch 287\n",
      "1.5038243324860283\n",
      "Validation loss: 1.4618173837661743\n",
      "mse 1.4618175441169636\n",
      "New best model found at epoch 287 with validation loss 1.4618173837661743\n",
      "Starting Epoch 288\n",
      "1.5034204410470051\n",
      "Validation loss: 1.4619897603988647\n",
      "mse 1.4619896653144306\n",
      "Starting Epoch 289\n",
      "1.5030790282332378\n",
      "Validation loss: 1.4617425203323364\n",
      "mse 1.4617425314906793\n",
      "New best model found at epoch 289 with validation loss 1.4617425203323364\n",
      "Starting Epoch 290\n",
      "1.5026761293411255\n",
      "Validation loss: 1.4615870714187622\n",
      "mse 1.4615871749877969\n",
      "New best model found at epoch 290 with validation loss 1.4615870714187622\n",
      "Starting Epoch 291\n",
      "1.502399276132169\n",
      "Validation loss: 1.461268424987793\n",
      "mse 1.4612683552751387\n",
      "New best model found at epoch 291 with validation loss 1.461268424987793\n",
      "Starting Epoch 292\n",
      "1.5020281879798225\n",
      "Validation loss: 1.4606037139892578\n",
      "mse 1.4606038247190194\n",
      "New best model found at epoch 292 with validation loss 1.4606037139892578\n",
      "Starting Epoch 293\n",
      "1.5016172346861467\n",
      "Validation loss: 1.4603805541992188\n",
      "mse 1.4603806130933703\n",
      "New best model found at epoch 293 with validation loss 1.4603805541992188\n",
      "Starting Epoch 294\n",
      "1.501349775687508\n",
      "Validation loss: 1.4601556062698364\n",
      "mse 1.4601553822845261\n",
      "New best model found at epoch 294 with validation loss 1.4601556062698364\n",
      "Starting Epoch 295\n",
      "1.5009929822838826\n",
      "Validation loss: 1.4596844911575317\n",
      "mse 1.4596845028321914\n",
      "New best model found at epoch 295 with validation loss 1.4596844911575317\n",
      "Starting Epoch 296\n",
      "1.5006033519039983\n",
      "Validation loss: 1.4595948457717896\n",
      "mse 1.4595948610550968\n",
      "New best model found at epoch 296 with validation loss 1.4595948457717896\n",
      "Starting Epoch 297\n",
      "1.5002638671709143\n",
      "Validation loss: 1.459456443786621\n",
      "mse 1.4594565145741403\n",
      "New best model found at epoch 297 with validation loss 1.459456443786621\n",
      "Starting Epoch 298\n",
      "1.499809646088144\n",
      "Validation loss: 1.459130883216858\n",
      "mse 1.4591309410281004\n",
      "New best model found at epoch 298 with validation loss 1.459130883216858\n",
      "Starting Epoch 299\n",
      "1.499501197234444\n",
      "Validation loss: 1.4590963125228882\n",
      "mse 1.459096220456695\n",
      "New best model found at epoch 299 with validation loss 1.4590963125228882\n",
      "Starting Epoch 300\n",
      "1.4991183177284573\n",
      "Validation loss: 1.4586296081542969\n",
      "mse 1.4586296264054828\n",
      "New best model found at epoch 300 with validation loss 1.4586296081542969\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-q25: 7-60-40-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c8033",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, smaller feature dataset: Version 6\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 60 - 40 - 1 (best model before)\n",
    "*  For each feature occuring multiple times only using the 0.75-quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "6f433f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "e74a2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_val_small = X_val.iloc[:,[0,1,2,3,4,10,16]]\n",
    "X_test_small = X_test.iloc[:,[0,1,2,3,4,10,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "8544c157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'q75(container counts)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "398817cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "b42e79c6-e7e3-49a0-8adc-89b9559c3d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.1816835869913516\n",
      "Validation loss: 2.5166378021240234\n",
      "mse 2.5166376559241312\n",
      "New best model found at epoch 1 with validation loss 2.5166378021240234\n",
      "Starting Epoch 2\n",
      "2.6440012092175693\n",
      "Validation loss: 2.235067844390869\n",
      "mse 2.2350676837248775\n",
      "New best model found at epoch 2 with validation loss 2.235067844390869\n",
      "Starting Epoch 3\n",
      "2.3570412345554517\n",
      "Validation loss: 2.0174899101257324\n",
      "mse 2.0174899403164757\n",
      "New best model found at epoch 3 with validation loss 2.0174899101257324\n",
      "Starting Epoch 4\n",
      "2.141202045523602\n",
      "Validation loss: 1.8824189901351929\n",
      "mse 1.8824188307882819\n",
      "New best model found at epoch 4 with validation loss 1.8824189901351929\n",
      "Starting Epoch 5\n",
      "2.0083740742310234\n",
      "Validation loss: 1.804777979850769\n",
      "mse 1.8047779329374136\n",
      "New best model found at epoch 5 with validation loss 1.804777979850769\n",
      "Starting Epoch 6\n",
      "1.9239315831142922\n",
      "Validation loss: 1.758162021636963\n",
      "mse 1.758162257392424\n",
      "New best model found at epoch 6 with validation loss 1.758162021636963\n",
      "Starting Epoch 7\n",
      "1.8692261913548345\n",
      "Validation loss: 1.7273273468017578\n",
      "mse 1.7273273656340442\n",
      "New best model found at epoch 7 with validation loss 1.7273273468017578\n",
      "Starting Epoch 8\n",
      "1.8307119245114534\n",
      "Validation loss: 1.7071290016174316\n",
      "mse 1.7071290072895398\n",
      "New best model found at epoch 8 with validation loss 1.7071290016174316\n",
      "Starting Epoch 9\n",
      "1.801720204560653\n",
      "Validation loss: 1.6915961503982544\n",
      "mse 1.6915960977114055\n",
      "New best model found at epoch 9 with validation loss 1.6915961503982544\n",
      "Starting Epoch 10\n",
      "1.779550111812094\n",
      "Validation loss: 1.6784052848815918\n",
      "mse 1.6784052403271699\n",
      "New best model found at epoch 10 with validation loss 1.6784052848815918\n",
      "Starting Epoch 11\n",
      "1.7614754853041277\n",
      "Validation loss: 1.6664644479751587\n",
      "mse 1.6664644973777967\n",
      "New best model found at epoch 11 with validation loss 1.6664644479751587\n",
      "Starting Epoch 12\n",
      "1.7461577653884888\n",
      "Validation loss: 1.6582751274108887\n",
      "mse 1.6582750272363402\n",
      "New best model found at epoch 12 with validation loss 1.6582751274108887\n",
      "Starting Epoch 13\n",
      "1.7328001364417698\n",
      "Validation loss: 1.6495214700698853\n",
      "mse 1.6495214581556743\n",
      "New best model found at epoch 13 with validation loss 1.6495214700698853\n",
      "Starting Epoch 14\n",
      "1.7202478128930796\n",
      "Validation loss: 1.6410681009292603\n",
      "mse 1.6410680577895294\n",
      "New best model found at epoch 14 with validation loss 1.6410681009292603\n",
      "Starting Epoch 15\n",
      "1.7089525668517402\n",
      "Validation loss: 1.633583426475525\n",
      "mse 1.6335833491303526\n",
      "New best model found at epoch 15 with validation loss 1.633583426475525\n",
      "Starting Epoch 16\n",
      "1.6989334977191428\n",
      "Validation loss: 1.6268086433410645\n",
      "mse 1.6268086308213232\n",
      "New best model found at epoch 16 with validation loss 1.6268086433410645\n",
      "Starting Epoch 17\n",
      "1.6902810853460561\n",
      "Validation loss: 1.6203292608261108\n",
      "mse 1.6203292685281632\n",
      "New best model found at epoch 17 with validation loss 1.6203292608261108\n",
      "Starting Epoch 18\n",
      "1.6824458941169407\n",
      "Validation loss: 1.614872694015503\n",
      "mse 1.6148725782956146\n",
      "New best model found at epoch 18 with validation loss 1.614872694015503\n",
      "Starting Epoch 19\n",
      "1.6752380754636682\n",
      "Validation loss: 1.6094470024108887\n",
      "mse 1.6094471010318734\n",
      "New best model found at epoch 19 with validation loss 1.6094470024108887\n",
      "Starting Epoch 20\n",
      "1.6688629803450212\n",
      "Validation loss: 1.604507327079773\n",
      "mse 1.604507204646449\n",
      "New best model found at epoch 20 with validation loss 1.604507327079773\n",
      "Starting Epoch 21\n",
      "1.6627350060836128\n",
      "Validation loss: 1.6003153324127197\n",
      "mse 1.6003154115136469\n",
      "New best model found at epoch 21 with validation loss 1.6003153324127197\n",
      "Starting Epoch 22\n",
      "1.6570535172586855\n",
      "Validation loss: 1.5956292152404785\n",
      "mse 1.5956291507219749\n",
      "New best model found at epoch 22 with validation loss 1.5956292152404785\n",
      "Starting Epoch 23\n",
      "1.6516420789386914\n",
      "Validation loss: 1.5916272401809692\n",
      "mse 1.591627218667767\n",
      "New best model found at epoch 23 with validation loss 1.5916272401809692\n",
      "Starting Epoch 24\n",
      "1.6465842723846436\n",
      "Validation loss: 1.587895154953003\n",
      "mse 1.5878951059738016\n",
      "New best model found at epoch 24 with validation loss 1.587895154953003\n",
      "Starting Epoch 25\n",
      "1.641961237658625\n",
      "Validation loss: 1.5835999250411987\n",
      "mse 1.5835999582837326\n",
      "New best model found at epoch 25 with validation loss 1.5835999250411987\n",
      "Starting Epoch 26\n",
      "1.6372878603313281\n",
      "Validation loss: 1.5799288749694824\n",
      "mse 1.579928859734066\n",
      "New best model found at epoch 26 with validation loss 1.5799288749694824\n",
      "Starting Epoch 27\n",
      "1.634254875390426\n",
      "Validation loss: 1.5758696794509888\n",
      "mse 1.5758697644848223\n",
      "New best model found at epoch 27 with validation loss 1.5758696794509888\n",
      "Starting Epoch 28\n",
      "1.628917994706527\n",
      "Validation loss: 1.5717381238937378\n",
      "mse 1.571738260528998\n",
      "New best model found at epoch 28 with validation loss 1.5717381238937378\n",
      "Starting Epoch 29\n",
      "1.624923472819121\n",
      "Validation loss: 1.568041443824768\n",
      "mse 1.5680413126305066\n",
      "New best model found at epoch 29 with validation loss 1.568041443824768\n",
      "Starting Epoch 30\n",
      "1.6211654854857402\n",
      "Validation loss: 1.563725233078003\n",
      "mse 1.5637252198809215\n",
      "New best model found at epoch 30 with validation loss 1.563725233078003\n",
      "Starting Epoch 31\n",
      "1.6174689298090728\n",
      "Validation loss: 1.5606273412704468\n",
      "mse 1.5606271945072694\n",
      "New best model found at epoch 31 with validation loss 1.5606273412704468\n",
      "Starting Epoch 32\n",
      "1.6142520852710889\n",
      "Validation loss: 1.5567774772644043\n",
      "mse 1.556777434715693\n",
      "New best model found at epoch 32 with validation loss 1.5567774772644043\n",
      "Starting Epoch 33\n",
      "1.6104611158370972\n",
      "Validation loss: 1.5487391948699951\n",
      "mse 1.548739284545616\n",
      "New best model found at epoch 33 with validation loss 1.5487391948699951\n",
      "Starting Epoch 34\n",
      "1.6053439560143843\n",
      "Validation loss: 1.5444979667663574\n",
      "mse 1.5444978361599027\n",
      "New best model found at epoch 34 with validation loss 1.5444979667663574\n",
      "Starting Epoch 35\n",
      "1.6015057641526926\n",
      "Validation loss: 1.5414234399795532\n",
      "mse 1.5414234806017295\n",
      "New best model found at epoch 35 with validation loss 1.5414234399795532\n",
      "Starting Epoch 36\n",
      "1.5981772256934124\n",
      "Validation loss: 1.5378972291946411\n",
      "mse 1.537897195562697\n",
      "New best model found at epoch 36 with validation loss 1.5378972291946411\n",
      "Starting Epoch 37\n",
      "1.5951399673586306\n",
      "Validation loss: 1.5353046655654907\n",
      "mse 1.5353046728633801\n",
      "New best model found at epoch 37 with validation loss 1.5353046655654907\n",
      "Starting Epoch 38\n",
      "1.5922338107357854\n",
      "Validation loss: 1.5329140424728394\n",
      "mse 1.5329140061081645\n",
      "New best model found at epoch 38 with validation loss 1.5329140424728394\n",
      "Starting Epoch 39\n",
      "1.5893921981687131\n",
      "Validation loss: 1.530060052871704\n",
      "mse 1.5300601075969602\n",
      "New best model found at epoch 39 with validation loss 1.530060052871704\n",
      "Starting Epoch 40\n",
      "1.5866850381312163\n",
      "Validation loss: 1.5279009342193604\n",
      "mse 1.5279012199602398\n",
      "New best model found at epoch 40 with validation loss 1.5279009342193604\n",
      "Starting Epoch 41\n",
      "1.584186763867088\n",
      "Validation loss: 1.5258119106292725\n",
      "mse 1.5258119956465133\n",
      "New best model found at epoch 41 with validation loss 1.5258119106292725\n",
      "Starting Epoch 42\n",
      "1.581344661505326\n",
      "Validation loss: 1.5226513147354126\n",
      "mse 1.5226512178324991\n",
      "New best model found at epoch 42 with validation loss 1.5226513147354126\n",
      "Starting Epoch 43\n",
      "1.5784416069155154\n",
      "Validation loss: 1.520491123199463\n",
      "mse 1.520491226921586\n",
      "New best model found at epoch 43 with validation loss 1.520491123199463\n",
      "Starting Epoch 44\n",
      "1.5761739741200986\n",
      "Validation loss: 1.519262433052063\n",
      "mse 1.519262376024826\n",
      "New best model found at epoch 44 with validation loss 1.519262433052063\n",
      "Starting Epoch 45\n",
      "1.5741226439890654\n",
      "Validation loss: 1.5172131061553955\n",
      "mse 1.5172130070572314\n",
      "New best model found at epoch 45 with validation loss 1.5172131061553955\n",
      "Starting Epoch 46\n",
      "1.5721956206404644\n",
      "Validation loss: 1.515160083770752\n",
      "mse 1.515160164419265\n",
      "New best model found at epoch 46 with validation loss 1.515160083770752\n",
      "Starting Epoch 47\n",
      "1.5701012559559033\n",
      "Validation loss: 1.5133427381515503\n",
      "mse 1.513342609080087\n",
      "New best model found at epoch 47 with validation loss 1.5133427381515503\n",
      "Starting Epoch 48\n",
      "1.5682309503140657\n",
      "Validation loss: 1.511570692062378\n",
      "mse 1.511570802712245\n",
      "New best model found at epoch 48 with validation loss 1.511570692062378\n",
      "Starting Epoch 49\n",
      "1.5662461467411206\n",
      "Validation loss: 1.509639024734497\n",
      "mse 1.5096390919675766\n",
      "New best model found at epoch 49 with validation loss 1.509639024734497\n",
      "Starting Epoch 50\n",
      "1.5645085599111475\n",
      "Validation loss: 1.5085368156433105\n",
      "mse 1.5085367525412576\n",
      "New best model found at epoch 50 with validation loss 1.5085368156433105\n",
      "Starting Epoch 51\n",
      "1.5626807705215786\n",
      "Validation loss: 1.507154107093811\n",
      "mse 1.50715423020471\n",
      "New best model found at epoch 51 with validation loss 1.507154107093811\n",
      "Starting Epoch 52\n",
      "1.560980050460152\n",
      "Validation loss: 1.5057276487350464\n",
      "mse 1.5057276184805681\n",
      "New best model found at epoch 52 with validation loss 1.5057276487350464\n",
      "Starting Epoch 53\n",
      "1.5589714179868284\n",
      "Validation loss: 1.5036075115203857\n",
      "mse 1.503607460179487\n",
      "New best model found at epoch 53 with validation loss 1.5036075115203857\n",
      "Starting Epoch 54\n",
      "1.5568061315495034\n",
      "Validation loss: 1.5015403032302856\n",
      "mse 1.5015401246928206\n",
      "New best model found at epoch 54 with validation loss 1.5015403032302856\n",
      "Starting Epoch 55\n",
      "1.5548299343689629\n",
      "Validation loss: 1.4999580383300781\n",
      "mse 1.499958164500184\n",
      "New best model found at epoch 55 with validation loss 1.4999580383300781\n",
      "Starting Epoch 56\n",
      "1.5527645997379138\n",
      "Validation loss: 1.4985194206237793\n",
      "mse 1.498519364912486\n",
      "New best model found at epoch 56 with validation loss 1.4985194206237793\n",
      "Starting Epoch 57\n",
      "1.5510761271352353\n",
      "Validation loss: 1.497241735458374\n",
      "mse 1.4972417537864882\n",
      "New best model found at epoch 57 with validation loss 1.497241735458374\n",
      "Starting Epoch 58\n",
      "1.5495239366655764\n",
      "Validation loss: 1.4962283372879028\n",
      "mse 1.496228274563888\n",
      "New best model found at epoch 58 with validation loss 1.4962283372879028\n",
      "Starting Epoch 59\n",
      "1.5481820806213047\n",
      "Validation loss: 1.4954274892807007\n",
      "mse 1.495427496964715\n",
      "New best model found at epoch 59 with validation loss 1.4954274892807007\n",
      "Starting Epoch 60\n",
      "1.5468069133551225\n",
      "Validation loss: 1.4948196411132812\n",
      "mse 1.494819708689847\n",
      "New best model found at epoch 60 with validation loss 1.4948196411132812\n",
      "Starting Epoch 61\n",
      "1.5455936374871626\n",
      "Validation loss: 1.493546485900879\n",
      "mse 1.4935465703777\n",
      "New best model found at epoch 61 with validation loss 1.493546485900879\n",
      "Starting Epoch 62\n",
      "1.5442921597024668\n",
      "Validation loss: 1.4924771785736084\n",
      "mse 1.4924773987063764\n",
      "New best model found at epoch 62 with validation loss 1.4924771785736084\n",
      "Starting Epoch 63\n",
      "1.5430568793545598\n",
      "Validation loss: 1.4915090799331665\n",
      "mse 1.4915089748364458\n",
      "New best model found at epoch 63 with validation loss 1.4915090799331665\n",
      "Starting Epoch 64\n",
      "1.5417947639589724\n",
      "Validation loss: 1.490856647491455\n",
      "mse 1.4908567913967914\n",
      "New best model found at epoch 64 with validation loss 1.490856647491455\n",
      "Starting Epoch 65\n",
      "1.5405965758406597\n",
      "Validation loss: 1.4898964166641235\n",
      "mse 1.4898964362980722\n",
      "New best model found at epoch 65 with validation loss 1.4898964166641235\n",
      "Starting Epoch 66\n",
      "1.5392396812853606\n",
      "Validation loss: 1.4894680976867676\n",
      "mse 1.4894682845141909\n",
      "New best model found at epoch 66 with validation loss 1.4894680976867676\n",
      "Starting Epoch 67\n",
      "1.5381149286809175\n",
      "Validation loss: 1.4879424571990967\n",
      "mse 1.4879424415469942\n",
      "New best model found at epoch 67 with validation loss 1.4879424571990967\n",
      "Starting Epoch 68\n",
      "1.5363515848698823\n",
      "Validation loss: 1.4868251085281372\n",
      "mse 1.4868251836262043\n",
      "New best model found at epoch 68 with validation loss 1.4868251085281372\n",
      "Starting Epoch 69\n",
      "1.5346571699432705\n",
      "Validation loss: 1.485211730003357\n",
      "mse 1.4852118032426085\n",
      "New best model found at epoch 69 with validation loss 1.485211730003357\n",
      "Starting Epoch 70\n",
      "1.5330329407816348\n",
      "Validation loss: 1.4838069677352905\n",
      "mse 1.4838069403846703\n",
      "New best model found at epoch 70 with validation loss 1.4838069677352905\n",
      "Starting Epoch 71\n",
      "1.5313948237377664\n",
      "Validation loss: 1.4827121496200562\n",
      "mse 1.482711985125704\n",
      "New best model found at epoch 71 with validation loss 1.4827121496200562\n",
      "Starting Epoch 72\n",
      "1.5298859917599221\n",
      "Validation loss: 1.482272982597351\n",
      "mse 1.4822730498953953\n",
      "New best model found at epoch 72 with validation loss 1.482272982597351\n",
      "Starting Epoch 73\n",
      "1.5287992461867954\n",
      "Validation loss: 1.4815850257873535\n",
      "mse 1.481585073866958\n",
      "New best model found at epoch 73 with validation loss 1.4815850257873535\n",
      "Starting Epoch 74\n",
      "1.5277532390926196\n",
      "Validation loss: 1.4808969497680664\n",
      "mse 1.4808969032100971\n",
      "New best model found at epoch 74 with validation loss 1.4808969497680664\n",
      "Starting Epoch 75\n",
      "1.5268870877183003\n",
      "Validation loss: 1.4802263975143433\n",
      "mse 1.4802264597321801\n",
      "New best model found at epoch 75 with validation loss 1.4802263975143433\n",
      "Starting Epoch 76\n",
      "1.5259092165076213\n",
      "Validation loss: 1.4798871278762817\n",
      "mse 1.479887080366208\n",
      "New best model found at epoch 76 with validation loss 1.4798871278762817\n",
      "Starting Epoch 77\n",
      "1.525125239206397\n",
      "Validation loss: 1.479455590248108\n",
      "mse 1.4794554941755005\n",
      "New best model found at epoch 77 with validation loss 1.479455590248108\n",
      "Starting Epoch 78\n",
      "1.5242279742075049\n",
      "Validation loss: 1.4789122343063354\n",
      "mse 1.478912177437074\n",
      "New best model found at epoch 78 with validation loss 1.4789122343063354\n",
      "Starting Epoch 79\n",
      "1.5234183254449263\n",
      "Validation loss: 1.4783015251159668\n",
      "mse 1.4783014936404082\n",
      "New best model found at epoch 79 with validation loss 1.4783015251159668\n",
      "Starting Epoch 80\n",
      "1.5226554119068643\n",
      "Validation loss: 1.4778525829315186\n",
      "mse 1.477852617714831\n",
      "New best model found at epoch 80 with validation loss 1.4778525829315186\n",
      "Starting Epoch 81\n",
      "1.5219044478043267\n",
      "Validation loss: 1.4773869514465332\n",
      "mse 1.4773869421511607\n",
      "New best model found at epoch 81 with validation loss 1.4773869514465332\n",
      "Starting Epoch 82\n",
      "1.521233452403027\n",
      "Validation loss: 1.4769024848937988\n",
      "mse 1.4769025237510107\n",
      "New best model found at epoch 82 with validation loss 1.4769024848937988\n",
      "Starting Epoch 83\n",
      "1.520444903684699\n",
      "Validation loss: 1.4766162633895874\n",
      "mse 1.4766163037761921\n",
      "New best model found at epoch 83 with validation loss 1.4766162633895874\n",
      "Starting Epoch 84\n",
      "1.519711795060531\n",
      "Validation loss: 1.4762502908706665\n",
      "mse 1.4762503883530718\n",
      "New best model found at epoch 84 with validation loss 1.4762502908706665\n",
      "Starting Epoch 85\n",
      "1.519017597903376\n",
      "Validation loss: 1.4755984544754028\n",
      "mse 1.4755984369011426\n",
      "New best model found at epoch 85 with validation loss 1.4755984544754028\n",
      "Starting Epoch 86\n",
      "1.5183143097421397\n",
      "Validation loss: 1.4751514196395874\n",
      "mse 1.4751514496780664\n",
      "New best model found at epoch 86 with validation loss 1.4751514196395874\n",
      "Starting Epoch 87\n",
      "1.517644853695579\n",
      "Validation loss: 1.474791169166565\n",
      "mse 1.474791183283708\n",
      "New best model found at epoch 87 with validation loss 1.474791169166565\n",
      "Starting Epoch 88\n",
      "1.5170042618461277\n",
      "Validation loss: 1.474266767501831\n",
      "mse 1.4742667941281102\n",
      "New best model found at epoch 88 with validation loss 1.474266767501831\n",
      "Starting Epoch 89\n",
      "1.5162943135137144\n",
      "Validation loss: 1.4734382629394531\n",
      "mse 1.4734382998960984\n",
      "New best model found at epoch 89 with validation loss 1.4734382629394531\n",
      "Starting Epoch 90\n",
      "1.5156693251236626\n",
      "Validation loss: 1.473201870918274\n",
      "mse 1.4732017678615805\n",
      "New best model found at epoch 90 with validation loss 1.473201870918274\n",
      "Starting Epoch 91\n",
      "1.5150293941083162\n",
      "Validation loss: 1.4725614786148071\n",
      "mse 1.4725615106729555\n",
      "New best model found at epoch 91 with validation loss 1.4725614786148071\n",
      "Starting Epoch 92\n",
      "1.514472432758497\n",
      "Validation loss: 1.4720317125320435\n",
      "mse 1.4720316364244372\n",
      "New best model found at epoch 92 with validation loss 1.4720317125320435\n",
      "Starting Epoch 93\n",
      "1.5137000394904094\n",
      "Validation loss: 1.471591591835022\n",
      "mse 1.471591294662385\n",
      "New best model found at epoch 93 with validation loss 1.471591591835022\n",
      "Starting Epoch 94\n",
      "1.513096096722976\n",
      "Validation loss: 1.4713213443756104\n",
      "mse 1.4713211793709466\n",
      "New best model found at epoch 94 with validation loss 1.4713213443756104\n",
      "Starting Epoch 95\n",
      "1.5125210803488027\n",
      "Validation loss: 1.4708480834960938\n",
      "mse 1.4708482554780065\n",
      "New best model found at epoch 95 with validation loss 1.4708480834960938\n",
      "Starting Epoch 96\n",
      "1.5119273869887642\n",
      "Validation loss: 1.4707528352737427\n",
      "mse 1.4707528301933448\n",
      "New best model found at epoch 96 with validation loss 1.4707528352737427\n",
      "Starting Epoch 97\n",
      "1.5113648875899937\n",
      "Validation loss: 1.4702798128128052\n",
      "mse 1.4702798775798867\n",
      "New best model found at epoch 97 with validation loss 1.4702798128128052\n",
      "Starting Epoch 98\n",
      "1.510766687600509\n",
      "Validation loss: 1.4697885513305664\n",
      "mse 1.4697885603887575\n",
      "New best model found at epoch 98 with validation loss 1.4697885513305664\n",
      "Starting Epoch 99\n",
      "1.5100913099620654\n",
      "Validation loss: 1.4694098234176636\n",
      "mse 1.4694098494012953\n",
      "New best model found at epoch 99 with validation loss 1.4694098234176636\n",
      "Starting Epoch 100\n",
      "1.5095077234765757\n",
      "Validation loss: 1.4692609310150146\n",
      "mse 1.469260899318884\n",
      "New best model found at epoch 100 with validation loss 1.4692609310150146\n",
      "Starting Epoch 101\n",
      "1.5089871416921201\n",
      "Validation loss: 1.4688366651535034\n",
      "mse 1.4688366911892556\n",
      "New best model found at epoch 101 with validation loss 1.4688366651535034\n",
      "Starting Epoch 102\n",
      "1.5084321213805156\n",
      "Validation loss: 1.4685461521148682\n",
      "mse 1.4685462026268123\n",
      "New best model found at epoch 102 with validation loss 1.4685461521148682\n",
      "Starting Epoch 103\n",
      "1.5078756757404492\n",
      "Validation loss: 1.4682296514511108\n",
      "mse 1.4682296510205441\n",
      "New best model found at epoch 103 with validation loss 1.4682296514511108\n",
      "Starting Epoch 104\n",
      "1.5072096067926157\n",
      "Validation loss: 1.4678903818130493\n",
      "mse 1.4678902202020623\n",
      "New best model found at epoch 104 with validation loss 1.4678903818130493\n",
      "Starting Epoch 105\n",
      "1.5067963418753252\n",
      "Validation loss: 1.467301845550537\n",
      "mse 1.4673018658213446\n",
      "New best model found at epoch 105 with validation loss 1.467301845550537\n",
      "Starting Epoch 106\n",
      "1.506304909353671\n",
      "Validation loss: 1.4669783115386963\n",
      "mse 1.4669783076642366\n",
      "New best model found at epoch 106 with validation loss 1.4669783115386963\n",
      "Starting Epoch 107\n",
      "1.5056819734366045\n",
      "Validation loss: 1.4665050506591797\n",
      "mse 1.4665050650931564\n",
      "New best model found at epoch 107 with validation loss 1.4665050506591797\n",
      "Starting Epoch 108\n",
      "1.5052225719327512\n",
      "Validation loss: 1.4662584066390991\n",
      "mse 1.466258402177078\n",
      "New best model found at epoch 108 with validation loss 1.4662584066390991\n",
      "Starting Epoch 109\n",
      "1.504659670850505\n",
      "Validation loss: 1.4657200574874878\n",
      "mse 1.465720109070684\n",
      "New best model found at epoch 109 with validation loss 1.4657200574874878\n",
      "Starting Epoch 110\n",
      "1.5041333359220754\n",
      "Validation loss: 1.4653620719909668\n",
      "mse 1.4653620469908009\n",
      "New best model found at epoch 110 with validation loss 1.4653620719909668\n",
      "Starting Epoch 111\n",
      "1.5035359444825545\n",
      "Validation loss: 1.465233564376831\n",
      "mse 1.4652335223622674\n",
      "New best model found at epoch 111 with validation loss 1.465233564376831\n",
      "Starting Epoch 112\n",
      "1.503005844095479\n",
      "Validation loss: 1.4645825624465942\n",
      "mse 1.464582656700406\n",
      "New best model found at epoch 112 with validation loss 1.4645825624465942\n",
      "Starting Epoch 113\n",
      "1.5024237010789954\n",
      "Validation loss: 1.464238166809082\n",
      "mse 1.464238100494749\n",
      "New best model found at epoch 113 with validation loss 1.464238166809082\n",
      "Starting Epoch 114\n",
      "1.5019123087758603\n",
      "Validation loss: 1.4639673233032227\n",
      "mse 1.4639672855351549\n",
      "New best model found at epoch 114 with validation loss 1.4639673233032227\n",
      "Starting Epoch 115\n",
      "1.5013303886289182\n",
      "Validation loss: 1.4633913040161133\n",
      "mse 1.4633913452453677\n",
      "New best model found at epoch 115 with validation loss 1.4633913040161133\n",
      "Starting Epoch 116\n",
      "1.5008404203083203\n",
      "Validation loss: 1.463181495666504\n",
      "mse 1.4631815569813593\n",
      "New best model found at epoch 116 with validation loss 1.463181495666504\n",
      "Starting Epoch 117\n",
      "1.5003417445265728\n",
      "Validation loss: 1.462197184562683\n",
      "mse 1.4621971620448033\n",
      "New best model found at epoch 117 with validation loss 1.462197184562683\n",
      "Starting Epoch 118\n",
      "1.499979423440021\n",
      "Validation loss: 1.4625253677368164\n",
      "mse 1.46252531571403\n",
      "Starting Epoch 119\n",
      "1.4993735888729924\n",
      "Validation loss: 1.4619914293289185\n",
      "mse 1.4619913117087486\n",
      "New best model found at epoch 119 with validation loss 1.4619914293289185\n",
      "Starting Epoch 120\n",
      "1.4988863053529158\n",
      "Validation loss: 1.4617244005203247\n",
      "mse 1.4617244738218766\n",
      "New best model found at epoch 120 with validation loss 1.4617244005203247\n",
      "Starting Epoch 121\n",
      "1.498351594676142\n",
      "Validation loss: 1.4612250328063965\n",
      "mse 1.4612251169681245\n",
      "New best model found at epoch 121 with validation loss 1.4612250328063965\n",
      "Starting Epoch 122\n",
      "1.4978519600370657\n",
      "Validation loss: 1.4608492851257324\n",
      "mse 1.460849232500319\n",
      "New best model found at epoch 122 with validation loss 1.4608492851257324\n",
      "Starting Epoch 123\n",
      "1.497451945491459\n",
      "Validation loss: 1.4604517221450806\n",
      "mse 1.4604517554286196\n",
      "New best model found at epoch 123 with validation loss 1.4604517221450806\n",
      "Starting Epoch 124\n",
      "1.4970283560130908\n",
      "Validation loss: 1.4599382877349854\n",
      "mse 1.4599382725435428\n",
      "New best model found at epoch 124 with validation loss 1.4599382877349854\n",
      "Starting Epoch 125\n",
      "1.4964926735214565\n",
      "Validation loss: 1.4596214294433594\n",
      "mse 1.4596212944703253\n",
      "New best model found at epoch 125 with validation loss 1.4596214294433594\n",
      "Starting Epoch 126\n",
      "1.4959493279457092\n",
      "Validation loss: 1.4597986936569214\n",
      "mse 1.459798597456594\n",
      "Starting Epoch 127\n",
      "1.4954887136169102\n",
      "Validation loss: 1.4594011306762695\n",
      "mse 1.459401098126095\n",
      "New best model found at epoch 127 with validation loss 1.4594011306762695\n",
      "Starting Epoch 128\n",
      "1.4950795847436655\n",
      "Validation loss: 1.4583996534347534\n",
      "mse 1.4583996092285874\n",
      "New best model found at epoch 128 with validation loss 1.4583996534347534\n",
      "Starting Epoch 129\n",
      "1.4945363791092583\n",
      "Validation loss: 1.4582197666168213\n",
      "mse 1.458219753681231\n",
      "New best model found at epoch 129 with validation loss 1.4582197666168213\n",
      "Starting Epoch 130\n",
      "1.494064836398415\n",
      "Validation loss: 1.4579318761825562\n",
      "mse 1.457931900364738\n",
      "New best model found at epoch 130 with validation loss 1.4579318761825562\n",
      "Starting Epoch 131\n",
      "1.4935641807058584\n",
      "Validation loss: 1.4575620889663696\n",
      "mse 1.4575621034156157\n",
      "New best model found at epoch 131 with validation loss 1.4575620889663696\n",
      "Starting Epoch 132\n",
      "1.4930301723272905\n",
      "Validation loss: 1.4575462341308594\n",
      "mse 1.4575462037104736\n",
      "New best model found at epoch 132 with validation loss 1.4575462341308594\n",
      "Starting Epoch 133\n",
      "1.4924991364064424\n",
      "Validation loss: 1.4569090604782104\n",
      "mse 1.456909115283193\n",
      "New best model found at epoch 133 with validation loss 1.4569090604782104\n",
      "Starting Epoch 134\n",
      "1.492117772931638\n",
      "Validation loss: 1.4567275047302246\n",
      "mse 1.4567273471802598\n",
      "New best model found at epoch 134 with validation loss 1.4567275047302246\n",
      "Starting Epoch 135\n",
      "1.4916067563969155\n",
      "Validation loss: 1.4563543796539307\n",
      "mse 1.4563544716101893\n",
      "New best model found at epoch 135 with validation loss 1.4563543796539307\n",
      "Starting Epoch 136\n",
      "1.4910997903865317\n",
      "Validation loss: 1.455762267112732\n",
      "mse 1.4557621532795777\n",
      "New best model found at epoch 136 with validation loss 1.455762267112732\n",
      "Starting Epoch 137\n",
      "1.4907232263813848\n",
      "Validation loss: 1.4554303884506226\n",
      "mse 1.4554304360829855\n",
      "New best model found at epoch 137 with validation loss 1.4554303884506226\n",
      "Starting Epoch 138\n",
      "1.4901982079381528\n",
      "Validation loss: 1.4554964303970337\n",
      "mse 1.4554962803490017\n",
      "Starting Epoch 139\n",
      "1.4897196837093518\n",
      "Validation loss: 1.4547488689422607\n",
      "mse 1.4547489750362261\n",
      "New best model found at epoch 139 with validation loss 1.4547488689422607\n",
      "Starting Epoch 140\n",
      "1.4892376583555471\n",
      "Validation loss: 1.454588770866394\n",
      "mse 1.4545887645560205\n",
      "New best model found at epoch 140 with validation loss 1.454588770866394\n",
      "Starting Epoch 141\n",
      "1.4888014275094736\n",
      "Validation loss: 1.4538826942443848\n",
      "mse 1.4538826605476123\n",
      "New best model found at epoch 141 with validation loss 1.4538826942443848\n",
      "Starting Epoch 142\n",
      "1.4882714515147002\n",
      "Validation loss: 1.4536793231964111\n",
      "mse 1.4536793459965025\n",
      "New best model found at epoch 142 with validation loss 1.4536793231964111\n",
      "Starting Epoch 143\n",
      "1.4877294923948206\n",
      "Validation loss: 1.453208088874817\n",
      "mse 1.4532081779418349\n",
      "New best model found at epoch 143 with validation loss 1.453208088874817\n",
      "Starting Epoch 144\n",
      "1.4872612538545027\n",
      "Validation loss: 1.4530284404754639\n",
      "mse 1.4530284774141848\n",
      "New best model found at epoch 144 with validation loss 1.4530284404754639\n",
      "Starting Epoch 145\n",
      "1.4869122012801792\n",
      "Validation loss: 1.452640414237976\n",
      "mse 1.4526404958289063\n",
      "New best model found at epoch 145 with validation loss 1.452640414237976\n",
      "Starting Epoch 146\n",
      "1.4863507721735083\n",
      "Validation loss: 1.452369213104248\n",
      "mse 1.4523691656742115\n",
      "New best model found at epoch 146 with validation loss 1.452369213104248\n",
      "Starting Epoch 147\n",
      "1.4859680948050127\n",
      "Validation loss: 1.4520509243011475\n",
      "mse 1.4520508490405624\n",
      "New best model found at epoch 147 with validation loss 1.4520509243011475\n",
      "Starting Epoch 148\n",
      "1.4853922180507495\n",
      "Validation loss: 1.4518096446990967\n",
      "mse 1.4518096584216882\n",
      "New best model found at epoch 148 with validation loss 1.4518096446990967\n",
      "Starting Epoch 149\n",
      "1.4849744257719621\n",
      "Validation loss: 1.4515573978424072\n",
      "mse 1.4515573292895438\n",
      "New best model found at epoch 149 with validation loss 1.4515573978424072\n",
      "Starting Epoch 150\n",
      "1.4844721503879712\n",
      "Validation loss: 1.4508581161499023\n",
      "mse 1.4508582239786258\n",
      "New best model found at epoch 150 with validation loss 1.4508581161499023\n",
      "Starting Epoch 151\n",
      "1.4840991419294607\n",
      "Validation loss: 1.4507297277450562\n",
      "mse 1.4507296456713137\n",
      "New best model found at epoch 151 with validation loss 1.4507297277450562\n",
      "Starting Epoch 152\n",
      "1.4835446191870647\n",
      "Validation loss: 1.4501968622207642\n",
      "mse 1.450196739539698\n",
      "New best model found at epoch 152 with validation loss 1.4501968622207642\n",
      "Starting Epoch 153\n",
      "1.4831713412118994\n",
      "Validation loss: 1.449921727180481\n",
      "mse 1.4499216992124033\n",
      "New best model found at epoch 153 with validation loss 1.449921727180481\n",
      "Starting Epoch 154\n",
      "1.4826587853224382\n",
      "Validation loss: 1.4492182731628418\n",
      "mse 1.4492183877539349\n",
      "New best model found at epoch 154 with validation loss 1.4492182731628418\n",
      "Starting Epoch 155\n",
      "1.482338037179864\n",
      "Validation loss: 1.4489104747772217\n",
      "mse 1.4489103775502137\n",
      "New best model found at epoch 155 with validation loss 1.4489104747772217\n",
      "Starting Epoch 156\n",
      "1.4819047528764475\n",
      "Validation loss: 1.4484022855758667\n",
      "mse 1.4484022137726378\n",
      "New best model found at epoch 156 with validation loss 1.4484022855758667\n",
      "Starting Epoch 157\n",
      "1.4814663322075554\n",
      "Validation loss: 1.448303461074829\n",
      "mse 1.4483034211732588\n",
      "New best model found at epoch 157 with validation loss 1.448303461074829\n",
      "Starting Epoch 158\n",
      "1.480997471705727\n",
      "Validation loss: 1.447511076927185\n",
      "mse 1.4475109583535877\n",
      "New best model found at epoch 158 with validation loss 1.447511076927185\n",
      "Starting Epoch 159\n",
      "1.4805704096089238\n",
      "Validation loss: 1.447528600692749\n",
      "mse 1.4475285378787046\n",
      "Starting Epoch 160\n",
      "1.4800739055094512\n",
      "Validation loss: 1.4467475414276123\n",
      "mse 1.4467477663944117\n",
      "New best model found at epoch 160 with validation loss 1.4467475414276123\n",
      "Starting Epoch 161\n",
      "1.4796992022058237\n",
      "Validation loss: 1.4463434219360352\n",
      "mse 1.4463434541574776\n",
      "New best model found at epoch 161 with validation loss 1.4463434219360352\n",
      "Starting Epoch 162\n",
      "1.479176155898882\n",
      "Validation loss: 1.446143627166748\n",
      "mse 1.4461436606353126\n",
      "New best model found at epoch 162 with validation loss 1.446143627166748\n",
      "Starting Epoch 163\n",
      "1.4787644121957861\n",
      "Validation loss: 1.4457683563232422\n",
      "mse 1.4457682448981937\n",
      "New best model found at epoch 163 with validation loss 1.4457683563232422\n",
      "Starting Epoch 164\n",
      "1.4783929430920144\n",
      "Validation loss: 1.445475697517395\n",
      "mse 1.4454756989265074\n",
      "New best model found at epoch 164 with validation loss 1.445475697517395\n",
      "Starting Epoch 165\n",
      "1.4779181324917336\n",
      "Validation loss: 1.4448521137237549\n",
      "mse 1.4448520144157266\n",
      "New best model found at epoch 165 with validation loss 1.4448521137237549\n",
      "Starting Epoch 166\n",
      "1.4774837649386863\n",
      "Validation loss: 1.4446055889129639\n",
      "mse 1.4446056263308105\n",
      "New best model found at epoch 166 with validation loss 1.4446055889129639\n",
      "Starting Epoch 167\n",
      "1.4770938676336538\n",
      "Validation loss: 1.444429636001587\n",
      "mse 1.4444295866471215\n",
      "New best model found at epoch 167 with validation loss 1.444429636001587\n",
      "Starting Epoch 168\n",
      "1.4765831102495608\n",
      "Validation loss: 1.4439252614974976\n",
      "mse 1.4439252432365286\n",
      "New best model found at epoch 168 with validation loss 1.4439252614974976\n",
      "Starting Epoch 169\n",
      "1.4762988971627278\n",
      "Validation loss: 1.443514347076416\n",
      "mse 1.4435143746621155\n",
      "New best model found at epoch 169 with validation loss 1.443514347076416\n",
      "Starting Epoch 170\n",
      "1.4756887969763384\n",
      "Validation loss: 1.4432313442230225\n",
      "mse 1.4432312870851585\n",
      "New best model found at epoch 170 with validation loss 1.4432313442230225\n",
      "Starting Epoch 171\n",
      "1.4754393100738525\n",
      "Validation loss: 1.4430265426635742\n",
      "mse 1.4430266443170678\n",
      "New best model found at epoch 171 with validation loss 1.4430265426635742\n",
      "Starting Epoch 172\n",
      "1.4749047315639\n",
      "Validation loss: 1.4427908658981323\n",
      "mse 1.442790974176762\n",
      "New best model found at epoch 172 with validation loss 1.4427908658981323\n",
      "Starting Epoch 173\n",
      "1.4744569140931834\n",
      "Validation loss: 1.4421544075012207\n",
      "mse 1.4421544338792962\n",
      "New best model found at epoch 173 with validation loss 1.4421544075012207\n",
      "Starting Epoch 174\n",
      "1.4741311436114104\n",
      "Validation loss: 1.4418270587921143\n",
      "mse 1.4418270389344747\n",
      "New best model found at epoch 174 with validation loss 1.4418270587921143\n",
      "Starting Epoch 175\n",
      "1.473601159842118\n",
      "Validation loss: 1.4416579008102417\n",
      "mse 1.4416578440171315\n",
      "New best model found at epoch 175 with validation loss 1.4416579008102417\n",
      "Starting Epoch 176\n",
      "1.4732096998587898\n",
      "Validation loss: 1.441150426864624\n",
      "mse 1.441150556581578\n",
      "New best model found at epoch 176 with validation loss 1.441150426864624\n",
      "Starting Epoch 177\n",
      "1.47278370546258\n",
      "Validation loss: 1.4408490657806396\n",
      "mse 1.4408490634645665\n",
      "New best model found at epoch 177 with validation loss 1.4408490657806396\n",
      "Starting Epoch 178\n",
      "1.472296813259954\n",
      "Validation loss: 1.4402663707733154\n",
      "mse 1.4402662989165842\n",
      "New best model found at epoch 178 with validation loss 1.4402663707733154\n",
      "Starting Epoch 179\n",
      "1.4718887650448342\n",
      "Validation loss: 1.4404420852661133\n",
      "mse 1.4404420894342103\n",
      "Starting Epoch 180\n",
      "1.471573513487111\n",
      "Validation loss: 1.4395920038223267\n",
      "mse 1.4395919632339693\n",
      "New best model found at epoch 180 with validation loss 1.4395920038223267\n",
      "Starting Epoch 181\n",
      "1.4710963808971902\n",
      "Validation loss: 1.4395533800125122\n",
      "mse 1.4395534083244645\n",
      "New best model found at epoch 181 with validation loss 1.4395533800125122\n",
      "Starting Epoch 182\n",
      "1.4707561524017998\n",
      "Validation loss: 1.4389992952346802\n",
      "mse 1.4389993539482593\n",
      "New best model found at epoch 182 with validation loss 1.4389992952346802\n",
      "Starting Epoch 183\n",
      "1.4703774348549221\n",
      "Validation loss: 1.4387555122375488\n",
      "mse 1.438755587588467\n",
      "New best model found at epoch 183 with validation loss 1.4387555122375488\n",
      "Starting Epoch 184\n",
      "1.4699532622876375\n",
      "Validation loss: 1.4383258819580078\n",
      "mse 1.438325919507952\n",
      "New best model found at epoch 184 with validation loss 1.4383258819580078\n",
      "Starting Epoch 185\n",
      "1.469525264657062\n",
      "Validation loss: 1.4380494356155396\n",
      "mse 1.4380494259199343\n",
      "New best model found at epoch 185 with validation loss 1.4380494356155396\n",
      "Starting Epoch 186\n",
      "1.469142146732496\n",
      "Validation loss: 1.437620759010315\n",
      "mse 1.4376207717050533\n",
      "New best model found at epoch 186 with validation loss 1.437620759010315\n",
      "Starting Epoch 187\n",
      "1.4686696399813113\n",
      "Validation loss: 1.4373506307601929\n",
      "mse 1.4373505146778274\n",
      "New best model found at epoch 187 with validation loss 1.4373506307601929\n",
      "Starting Epoch 188\n",
      "1.4683354237805242\n",
      "Validation loss: 1.437139868736267\n",
      "mse 1.4371398161096323\n",
      "New best model found at epoch 188 with validation loss 1.437139868736267\n",
      "Starting Epoch 189\n",
      "1.4679402138875879\n",
      "Validation loss: 1.436561942100525\n",
      "mse 1.436562003538939\n",
      "New best model found at epoch 189 with validation loss 1.436561942100525\n",
      "Starting Epoch 190\n",
      "1.467613196891287\n",
      "Validation loss: 1.436379313468933\n",
      "mse 1.4363793165616436\n",
      "New best model found at epoch 190 with validation loss 1.436379313468933\n",
      "Starting Epoch 191\n",
      "1.4671354812124502\n",
      "Validation loss: 1.435905933380127\n",
      "mse 1.435905867078588\n",
      "New best model found at epoch 191 with validation loss 1.435905933380127\n",
      "Starting Epoch 192\n",
      "1.4668585554413174\n",
      "Validation loss: 1.435840129852295\n",
      "mse 1.4358401516261559\n",
      "New best model found at epoch 192 with validation loss 1.435840129852295\n",
      "Starting Epoch 193\n",
      "1.4662540269934612\n",
      "Validation loss: 1.4353423118591309\n",
      "mse 1.435342376667348\n",
      "New best model found at epoch 193 with validation loss 1.4353423118591309\n",
      "Starting Epoch 194\n",
      "1.4660198196120884\n",
      "Validation loss: 1.4352455139160156\n",
      "mse 1.435245446217558\n",
      "New best model found at epoch 194 with validation loss 1.4352455139160156\n",
      "Starting Epoch 195\n",
      "1.4655378642289534\n",
      "Validation loss: 1.4347442388534546\n",
      "mse 1.4347442014668215\n",
      "New best model found at epoch 195 with validation loss 1.4347442388534546\n",
      "Starting Epoch 196\n",
      "1.4652412378269692\n",
      "Validation loss: 1.4345170259475708\n",
      "mse 1.4345170969633283\n",
      "New best model found at epoch 196 with validation loss 1.4345170259475708\n",
      "Starting Epoch 197\n",
      "1.464681397313657\n",
      "Validation loss: 1.434131145477295\n",
      "mse 1.434130917872731\n",
      "New best model found at epoch 197 with validation loss 1.434131145477295\n",
      "Starting Epoch 198\n",
      "1.4644588206125342\n",
      "Validation loss: 1.4340012073516846\n",
      "mse 1.4340012877873196\n",
      "New best model found at epoch 198 with validation loss 1.4340012073516846\n",
      "Starting Epoch 199\n",
      "1.4639740793601326\n",
      "Validation loss: 1.4334884881973267\n",
      "mse 1.4334886039478647\n",
      "New best model found at epoch 199 with validation loss 1.4334884881973267\n",
      "Starting Epoch 200\n",
      "1.463580248148545\n",
      "Validation loss: 1.4332568645477295\n",
      "mse 1.4332569083362074\n",
      "New best model found at epoch 200 with validation loss 1.4332568645477295\n",
      "Starting Epoch 201\n",
      "1.4632115182669267\n",
      "Validation loss: 1.4328011274337769\n",
      "mse 1.4328012416938176\n",
      "New best model found at epoch 201 with validation loss 1.4328011274337769\n",
      "Starting Epoch 202\n",
      "1.4628893992175227\n",
      "Validation loss: 1.4325063228607178\n",
      "mse 1.43250637306884\n",
      "New best model found at epoch 202 with validation loss 1.4325063228607178\n",
      "Starting Epoch 203\n",
      "1.462443364703137\n",
      "Validation loss: 1.4319844245910645\n",
      "mse 1.4319842701190908\n",
      "New best model found at epoch 203 with validation loss 1.4319844245910645\n",
      "Starting Epoch 204\n",
      "1.4621069949606191\n",
      "Validation loss: 1.4317092895507812\n",
      "mse 1.4317092436200498\n",
      "New best model found at epoch 204 with validation loss 1.4317092895507812\n",
      "Starting Epoch 205\n",
      "1.461674381857333\n",
      "Validation loss: 1.4314427375793457\n",
      "mse 1.4314428191483726\n",
      "New best model found at epoch 205 with validation loss 1.4314427375793457\n",
      "Starting Epoch 206\n",
      "1.4612974939138994\n",
      "Validation loss: 1.4310582876205444\n",
      "mse 1.4310582991912084\n",
      "New best model found at epoch 206 with validation loss 1.4310582876205444\n",
      "Starting Epoch 207\n",
      "1.460915207862854\n",
      "Validation loss: 1.4307118654251099\n",
      "mse 1.4307119239111057\n",
      "New best model found at epoch 207 with validation loss 1.4307118654251099\n",
      "Starting Epoch 208\n",
      "1.4605543069217517\n",
      "Validation loss: 1.4305096864700317\n",
      "mse 1.4305096614229627\n",
      "New best model found at epoch 208 with validation loss 1.4305096864700317\n",
      "Starting Epoch 209\n",
      "1.4601010343302852\n",
      "Validation loss: 1.4301241636276245\n",
      "mse 1.4301241099960746\n",
      "New best model found at epoch 209 with validation loss 1.4301241636276245\n",
      "Starting Epoch 210\n",
      "1.4597074000731758\n",
      "Validation loss: 1.4297528266906738\n",
      "mse 1.4297527781672699\n",
      "New best model found at epoch 210 with validation loss 1.4297528266906738\n",
      "Starting Epoch 211\n",
      "1.4593778382176938\n",
      "Validation loss: 1.4294357299804688\n",
      "mse 1.4294357826025226\n",
      "New best model found at epoch 211 with validation loss 1.4294357299804688\n",
      "Starting Epoch 212\n",
      "1.4589200227156929\n",
      "Validation loss: 1.4289871454238892\n",
      "mse 1.4289871664315807\n",
      "New best model found at epoch 212 with validation loss 1.4289871454238892\n",
      "Starting Epoch 213\n",
      "1.458556258160135\n",
      "Validation loss: 1.4288864135742188\n",
      "mse 1.4288864569508315\n",
      "New best model found at epoch 213 with validation loss 1.4288864135742188\n",
      "Starting Epoch 214\n",
      "1.4581781470257302\n",
      "Validation loss: 1.428619623184204\n",
      "mse 1.4286196237144626\n",
      "New best model found at epoch 214 with validation loss 1.428619623184204\n",
      "Starting Epoch 215\n",
      "1.4577684480211008\n",
      "Validation loss: 1.428147792816162\n",
      "mse 1.4281477184172056\n",
      "New best model found at epoch 215 with validation loss 1.428147792816162\n",
      "Starting Epoch 216\n",
      "1.4574305855709573\n",
      "Validation loss: 1.4278894662857056\n",
      "mse 1.4278894777488254\n",
      "New best model found at epoch 216 with validation loss 1.4278894662857056\n",
      "Starting Epoch 217\n",
      "1.4569477231606194\n",
      "Validation loss: 1.4276455640792847\n",
      "mse 1.4276456289703365\n",
      "New best model found at epoch 217 with validation loss 1.4276455640792847\n",
      "Starting Epoch 218\n",
      "1.4565888410029204\n",
      "Validation loss: 1.427214503288269\n",
      "mse 1.4272145606026563\n",
      "New best model found at epoch 218 with validation loss 1.427214503288269\n",
      "Starting Epoch 219\n",
      "1.4562531243199888\n",
      "Validation loss: 1.4267208576202393\n",
      "mse 1.4267209407779862\n",
      "New best model found at epoch 219 with validation loss 1.4267208576202393\n",
      "Starting Epoch 220\n",
      "1.4558439021525176\n",
      "Validation loss: 1.4265497922897339\n",
      "mse 1.426549883197057\n",
      "New best model found at epoch 220 with validation loss 1.4265497922897339\n",
      "Starting Epoch 221\n",
      "1.455421250799428\n",
      "Validation loss: 1.4263412952423096\n",
      "mse 1.426341226004707\n",
      "New best model found at epoch 221 with validation loss 1.4263412952423096\n",
      "Starting Epoch 222\n",
      "1.4550456612006477\n",
      "Validation loss: 1.4259089231491089\n",
      "mse 1.4259088091107093\n",
      "New best model found at epoch 222 with validation loss 1.4259089231491089\n",
      "Starting Epoch 223\n",
      "1.4548011577647666\n",
      "Validation loss: 1.4255841970443726\n",
      "mse 1.425584086677952\n",
      "New best model found at epoch 223 with validation loss 1.4255841970443726\n",
      "Starting Epoch 224\n",
      "1.4542397260665894\n",
      "Validation loss: 1.4253300428390503\n",
      "mse 1.4253299616930601\n",
      "New best model found at epoch 224 with validation loss 1.4253300428390503\n",
      "Starting Epoch 225\n",
      "1.4539457300434941\n",
      "Validation loss: 1.424837589263916\n",
      "mse 1.4248375438999497\n",
      "New best model found at epoch 225 with validation loss 1.424837589263916\n",
      "Starting Epoch 226\n",
      "1.4535054512645886\n",
      "Validation loss: 1.4244850873947144\n",
      "mse 1.4244850909952902\n",
      "New best model found at epoch 226 with validation loss 1.4244850873947144\n",
      "Starting Epoch 227\n",
      "1.4532413949137148\n",
      "Validation loss: 1.4242223501205444\n",
      "mse 1.4242223446753581\n",
      "New best model found at epoch 227 with validation loss 1.4242223501205444\n",
      "Starting Epoch 228\n",
      "1.4527652445046797\n",
      "Validation loss: 1.4239757061004639\n",
      "mse 1.4239757359177347\n",
      "New best model found at epoch 228 with validation loss 1.4239757061004639\n",
      "Starting Epoch 229\n",
      "1.452387651671534\n",
      "Validation loss: 1.4235459566116333\n",
      "mse 1.4235459215165567\n",
      "New best model found at epoch 229 with validation loss 1.4235459566116333\n",
      "Starting Epoch 230\n",
      "1.4520700185195259\n",
      "Validation loss: 1.423233151435852\n",
      "mse 1.423233296922005\n",
      "New best model found at epoch 230 with validation loss 1.423233151435852\n",
      "Starting Epoch 231\n",
      "1.4516486706941023\n",
      "Validation loss: 1.422905445098877\n",
      "mse 1.4229054024280587\n",
      "New best model found at epoch 231 with validation loss 1.422905445098877\n",
      "Starting Epoch 232\n",
      "1.4512833849243496\n",
      "Validation loss: 1.4225456714630127\n",
      "mse 1.422545604549996\n",
      "New best model found at epoch 232 with validation loss 1.4225456714630127\n",
      "Starting Epoch 233\n",
      "1.450860883878625\n",
      "Validation loss: 1.422223448753357\n",
      "mse 1.4222234303830317\n",
      "New best model found at epoch 233 with validation loss 1.422223448753357\n",
      "Starting Epoch 234\n",
      "1.4504589878994485\n",
      "Validation loss: 1.4221447706222534\n",
      "mse 1.4221447833573655\n",
      "New best model found at epoch 234 with validation loss 1.4221447706222534\n",
      "Starting Epoch 235\n",
      "1.450054837309796\n",
      "Validation loss: 1.421502709388733\n",
      "mse 1.4215026957075712\n",
      "New best model found at epoch 235 with validation loss 1.421502709388733\n",
      "Starting Epoch 236\n",
      "1.4497368568959443\n",
      "Validation loss: 1.4212908744812012\n",
      "mse 1.4212908977286296\n",
      "New best model found at epoch 236 with validation loss 1.4212908744812012\n",
      "Starting Epoch 237\n",
      "1.4492794741754946\n",
      "Validation loss: 1.4207985401153564\n",
      "mse 1.4207985647147912\n",
      "New best model found at epoch 237 with validation loss 1.4207985401153564\n",
      "Starting Epoch 238\n",
      "1.4489510629488074\n",
      "Validation loss: 1.4205256700515747\n",
      "mse 1.420525711610581\n",
      "New best model found at epoch 238 with validation loss 1.4205256700515747\n",
      "Starting Epoch 239\n",
      "1.4485505871150806\n",
      "Validation loss: 1.4202686548233032\n",
      "mse 1.4202687225158421\n",
      "New best model found at epoch 239 with validation loss 1.4202686548233032\n",
      "Starting Epoch 240\n",
      "1.448134774747102\n",
      "Validation loss: 1.4197195768356323\n",
      "mse 1.4197196947978232\n",
      "New best model found at epoch 240 with validation loss 1.4197195768356323\n",
      "Starting Epoch 241\n",
      "1.4479105265244194\n",
      "Validation loss: 1.419338583946228\n",
      "mse 1.4193385906155416\n",
      "New best model found at epoch 241 with validation loss 1.419338583946228\n",
      "Starting Epoch 242\n",
      "1.4473898177561553\n",
      "Validation loss: 1.4191139936447144\n",
      "mse 1.4191140062487282\n",
      "New best model found at epoch 242 with validation loss 1.4191139936447144\n",
      "Starting Epoch 243\n",
      "1.4469755006873088\n",
      "Validation loss: 1.4188612699508667\n",
      "mse 1.4188612160489686\n",
      "New best model found at epoch 243 with validation loss 1.4188612699508667\n",
      "Starting Epoch 244\n",
      "1.4466822510180266\n",
      "Validation loss: 1.4186350107192993\n",
      "mse 1.418634983964689\n",
      "New best model found at epoch 244 with validation loss 1.4186350107192993\n",
      "Starting Epoch 245\n",
      "1.446233842683875\n",
      "Validation loss: 1.4181430339813232\n",
      "mse 1.4181431137450509\n",
      "New best model found at epoch 245 with validation loss 1.4181430339813232\n",
      "Starting Epoch 246\n",
      "1.4459954759348994\n",
      "Validation loss: 1.4177335500717163\n",
      "mse 1.4177336462733143\n",
      "New best model found at epoch 246 with validation loss 1.4177335500717163\n",
      "Starting Epoch 247\n",
      "1.4455198127290476\n",
      "Validation loss: 1.4174952507019043\n",
      "mse 1.4174953606464005\n",
      "New best model found at epoch 247 with validation loss 1.4174952507019043\n",
      "Starting Epoch 248\n",
      "1.445159119108449\n",
      "Validation loss: 1.417129635810852\n",
      "mse 1.4171295222830824\n",
      "New best model found at epoch 248 with validation loss 1.417129635810852\n",
      "Starting Epoch 249\n",
      "1.4448384150214817\n",
      "Validation loss: 1.4167519807815552\n",
      "mse 1.416752030298735\n",
      "New best model found at epoch 249 with validation loss 1.4167519807815552\n",
      "Starting Epoch 250\n",
      "1.4444081757379614\n",
      "Validation loss: 1.4165043830871582\n",
      "mse 1.4165046058797552\n",
      "New best model found at epoch 250 with validation loss 1.4165043830871582\n",
      "Starting Epoch 251\n",
      "1.4440584934276084\n",
      "Validation loss: 1.416193962097168\n",
      "mse 1.4161939335195728\n",
      "New best model found at epoch 251 with validation loss 1.416193962097168\n",
      "Starting Epoch 252\n",
      "1.4436901367228965\n",
      "Validation loss: 1.415799856185913\n",
      "mse 1.4157998279892732\n",
      "New best model found at epoch 252 with validation loss 1.415799856185913\n",
      "Starting Epoch 253\n",
      "1.4433680021244546\n",
      "Validation loss: 1.4154139757156372\n",
      "mse 1.4154139404811226\n",
      "New best model found at epoch 253 with validation loss 1.4154139757156372\n",
      "Starting Epoch 254\n",
      "1.4428964620051177\n",
      "Validation loss: 1.4151630401611328\n",
      "mse 1.4151630014003929\n",
      "New best model found at epoch 254 with validation loss 1.4151630401611328\n",
      "Starting Epoch 255\n",
      "1.442599636057149\n",
      "Validation loss: 1.4146703481674194\n",
      "mse 1.4146703182245297\n",
      "New best model found at epoch 255 with validation loss 1.4146703481674194\n",
      "Starting Epoch 256\n",
      "1.442277193069458\n",
      "Validation loss: 1.4144047498703003\n",
      "mse 1.4144046708371\n",
      "New best model found at epoch 256 with validation loss 1.4144047498703003\n",
      "Starting Epoch 257\n",
      "1.4418344808661419\n",
      "Validation loss: 1.4140753746032715\n",
      "mse 1.4140753297442037\n",
      "New best model found at epoch 257 with validation loss 1.4140753746032715\n",
      "Starting Epoch 258\n",
      "1.4414812922477722\n",
      "Validation loss: 1.4136744737625122\n",
      "mse 1.4136743396823812\n",
      "New best model found at epoch 258 with validation loss 1.4136744737625122\n",
      "Starting Epoch 259\n",
      "1.4412034464919048\n",
      "Validation loss: 1.4132957458496094\n",
      "mse 1.4132956810887014\n",
      "New best model found at epoch 259 with validation loss 1.4132957458496094\n",
      "Starting Epoch 260\n",
      "1.440802338330642\n",
      "Validation loss: 1.4130691289901733\n",
      "mse 1.4130689960650626\n",
      "New best model found at epoch 260 with validation loss 1.4130691289901733\n",
      "Starting Epoch 261\n",
      "1.440429925918579\n",
      "Validation loss: 1.4126840829849243\n",
      "mse 1.4126841573786981\n",
      "New best model found at epoch 261 with validation loss 1.4126840829849243\n",
      "Starting Epoch 262\n",
      "1.4400817259498264\n",
      "Validation loss: 1.4124022722244263\n",
      "mse 1.4124022701835164\n",
      "New best model found at epoch 262 with validation loss 1.4124022722244263\n",
      "Starting Epoch 263\n",
      "1.439704936483632\n",
      "Validation loss: 1.4119940996170044\n",
      "mse 1.4119941073664264\n",
      "New best model found at epoch 263 with validation loss 1.4119940996170044\n",
      "Starting Epoch 264\n",
      "1.4394534567128057\n",
      "Validation loss: 1.4117431640625\n",
      "mse 1.4117431691173765\n",
      "New best model found at epoch 264 with validation loss 1.4117431640625\n",
      "Starting Epoch 265\n",
      "1.4390843095986738\n",
      "Validation loss: 1.411324381828308\n",
      "mse 1.4113243778081843\n",
      "New best model found at epoch 265 with validation loss 1.411324381828308\n",
      "Starting Epoch 266\n",
      "1.4387892458749854\n",
      "Validation loss: 1.41102933883667\n",
      "mse 1.4110292900610226\n",
      "New best model found at epoch 266 with validation loss 1.41102933883667\n",
      "Starting Epoch 267\n",
      "1.4383897029835244\n",
      "Validation loss: 1.4107959270477295\n",
      "mse 1.4107959220526087\n",
      "New best model found at epoch 267 with validation loss 1.4107959270477295\n",
      "Starting Epoch 268\n",
      "1.4379959728406824\n",
      "Validation loss: 1.4102463722229004\n",
      "mse 1.4102464363126679\n",
      "New best model found at epoch 268 with validation loss 1.4102463722229004\n",
      "Starting Epoch 269\n",
      "1.4377374312152034\n",
      "Validation loss: 1.4100136756896973\n",
      "mse 1.4100137147643221\n",
      "New best model found at epoch 269 with validation loss 1.4100136756896973\n",
      "Starting Epoch 270\n",
      "1.4373352968174478\n",
      "Validation loss: 1.4097001552581787\n",
      "mse 1.409700153662997\n",
      "New best model found at epoch 270 with validation loss 1.4097001552581787\n",
      "Starting Epoch 271\n",
      "1.4369452440220376\n",
      "Validation loss: 1.4092943668365479\n",
      "mse 1.409294247321815\n",
      "New best model found at epoch 271 with validation loss 1.4092943668365479\n",
      "Starting Epoch 272\n",
      "1.4366911001827405\n",
      "Validation loss: 1.4089059829711914\n",
      "mse 1.4089060356250467\n",
      "New best model found at epoch 272 with validation loss 1.4089059829711914\n",
      "Starting Epoch 273\n",
      "1.4362643749817559\n",
      "Validation loss: 1.4085928201675415\n",
      "mse 1.4085928014864815\n",
      "New best model found at epoch 273 with validation loss 1.4085928201675415\n",
      "Starting Epoch 274\n",
      "1.4358960234600564\n",
      "Validation loss: 1.4082188606262207\n",
      "mse 1.4082189053257614\n",
      "New best model found at epoch 274 with validation loss 1.4082188606262207\n",
      "Starting Epoch 275\n",
      "1.4355349566625513\n",
      "Validation loss: 1.4077931642532349\n",
      "mse 1.4077932771989974\n",
      "New best model found at epoch 275 with validation loss 1.4077931642532349\n",
      "Starting Epoch 276\n",
      "1.4352929566217505\n",
      "Validation loss: 1.4074996709823608\n",
      "mse 1.407499609473153\n",
      "New best model found at epoch 276 with validation loss 1.4074996709823608\n",
      "Starting Epoch 277\n",
      "1.4348714999530627\n",
      "Validation loss: 1.4071519374847412\n",
      "mse 1.4071519993666959\n",
      "New best model found at epoch 277 with validation loss 1.4071519374847412\n",
      "Starting Epoch 278\n",
      "1.4345297269199206\n",
      "Validation loss: 1.4068163633346558\n",
      "mse 1.4068165219083462\n",
      "New best model found at epoch 278 with validation loss 1.4068163633346558\n",
      "Starting Epoch 279\n",
      "1.4342694463937178\n",
      "Validation loss: 1.4064685106277466\n",
      "mse 1.4064684958780256\n",
      "New best model found at epoch 279 with validation loss 1.4064685106277466\n",
      "Starting Epoch 280\n",
      "1.4338360325149868\n",
      "Validation loss: 1.4060884714126587\n",
      "mse 1.4060886199913372\n",
      "New best model found at epoch 280 with validation loss 1.4060884714126587\n",
      "Starting Epoch 281\n",
      "1.4335970878601074\n",
      "Validation loss: 1.4058536291122437\n",
      "mse 1.4058536395394505\n",
      "New best model found at epoch 281 with validation loss 1.4058536291122437\n",
      "Starting Epoch 282\n",
      "1.433199097280917\n",
      "Validation loss: 1.4054409265518188\n",
      "mse 1.4054407388119827\n",
      "New best model found at epoch 282 with validation loss 1.4054409265518188\n",
      "Starting Epoch 283\n",
      "1.4329280309055163\n",
      "Validation loss: 1.4051411151885986\n",
      "mse 1.4051411823219337\n",
      "New best model found at epoch 283 with validation loss 1.4051411151885986\n",
      "Starting Epoch 284\n",
      "1.432519811650981\n",
      "Validation loss: 1.404894471168518\n",
      "mse 1.404894566366637\n",
      "New best model found at epoch 284 with validation loss 1.404894471168518\n",
      "Starting Epoch 285\n",
      "1.43217584879502\n",
      "Validation loss: 1.4045048952102661\n",
      "mse 1.4045049353242192\n",
      "New best model found at epoch 285 with validation loss 1.4045048952102661\n",
      "Starting Epoch 286\n",
      "1.4319367097771687\n",
      "Validation loss: 1.404168963432312\n",
      "mse 1.4041688400346977\n",
      "New best model found at epoch 286 with validation loss 1.404168963432312\n",
      "Starting Epoch 287\n",
      "1.4315548720567122\n",
      "Validation loss: 1.4038922786712646\n",
      "mse 1.4038923067316813\n",
      "New best model found at epoch 287 with validation loss 1.4038922786712646\n",
      "Starting Epoch 288\n",
      "1.431198019048442\n",
      "Validation loss: 1.403475046157837\n",
      "mse 1.403475047946214\n",
      "New best model found at epoch 288 with validation loss 1.403475046157837\n",
      "Starting Epoch 289\n",
      "1.4309023255887239\n",
      "Validation loss: 1.4032618999481201\n",
      "mse 1.4032619573412832\n",
      "New best model found at epoch 289 with validation loss 1.4032618999481201\n",
      "Starting Epoch 290\n",
      "1.4305011163587156\n",
      "Validation loss: 1.4028488397598267\n",
      "mse 1.4028488393993372\n",
      "New best model found at epoch 290 with validation loss 1.4028488397598267\n",
      "Starting Epoch 291\n",
      "1.4302408747051074\n",
      "Validation loss: 1.4026237726211548\n",
      "mse 1.4026238248807101\n",
      "New best model found at epoch 291 with validation loss 1.4026237726211548\n",
      "Starting Epoch 292\n",
      "1.429841046747954\n",
      "Validation loss: 1.402214527130127\n",
      "mse 1.4022145717218168\n",
      "New best model found at epoch 292 with validation loss 1.402214527130127\n",
      "Starting Epoch 293\n",
      "1.4296145672383516\n",
      "Validation loss: 1.4018162488937378\n",
      "mse 1.401816195465814\n",
      "New best model found at epoch 293 with validation loss 1.4018162488937378\n",
      "Starting Epoch 294\n",
      "1.4292300550833992\n",
      "Validation loss: 1.4015415906906128\n",
      "mse 1.4015414666851553\n",
      "New best model found at epoch 294 with validation loss 1.4015415906906128\n",
      "Starting Epoch 295\n",
      "1.428994647834612\n",
      "Validation loss: 1.4012340307235718\n",
      "mse 1.4012340452888887\n",
      "New best model found at epoch 295 with validation loss 1.4012340307235718\n",
      "Starting Epoch 296\n",
      "1.4285404837649802\n",
      "Validation loss: 1.4009332656860352\n",
      "mse 1.4009332760635147\n",
      "New best model found at epoch 296 with validation loss 1.4009332656860352\n",
      "Starting Epoch 297\n",
      "1.428225672763327\n",
      "Validation loss: 1.4005959033966064\n",
      "mse 1.4005959877625298\n",
      "New best model found at epoch 297 with validation loss 1.4005959033966064\n",
      "Starting Epoch 298\n",
      "1.4280070429262908\n",
      "Validation loss: 1.4002888202667236\n",
      "mse 1.4002886711849243\n",
      "New best model found at epoch 298 with validation loss 1.4002888202667236\n",
      "Starting Epoch 299\n",
      "1.4275670751281406\n",
      "Validation loss: 1.3999717235565186\n",
      "mse 1.3999718031961765\n",
      "New best model found at epoch 299 with validation loss 1.3999717235565186\n",
      "Starting Epoch 300\n",
      "1.4273253031398938\n",
      "Validation loss: 1.3996717929840088\n",
      "mse 1.3996718408611861\n",
      "New best model found at epoch 300 with validation loss 1.3996717929840088\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train_small, y1_diff_log_train, X_val_small, y1_diff_log_val, \"MLP, small-q75: 7-60-40-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83e125-5d6a-4e1d-80fe-0d84aaa1d484",
   "metadata": {},
   "source": [
    "##### 4-layer MLP, custom layer\n",
    "*  Layers: 4 (including input and output layer), sizes: 7 - 60 - 40 - 1 (best model before)\n",
    "*  Adding a custom layer, where we group all features occuring multiple times together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "53692139-79bf-48b5-98b8-23dc84f17777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.values).float()  # Convert DataFrame to tensor\n",
    "        self.y = torch.from_numpy(y.values).float()  # Convert DataFrame to tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "d0f81fc6-39ab-40b7-bc3b-7eac2e90e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#relations', '#conditions', '#filters', '#joins', 'depth',\n",
       "       'min(container counts)', 'max(container counts)',\n",
       "       'mean(container counts)', 'q25(container counts)',\n",
       "       'median(container counts)', 'q75(container counts)',\n",
       "       'min(branching factors)', 'max(branching factors)',\n",
       "       'mean(branching factors)', 'median(branching factors)',\n",
       "       'q25(branching factors)', 'q75(branching factors)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "1f909456-53e0-4fa0-a020-f9e11af5bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 1)  \n",
    "        self.fc2 = nn.Linear(1, 1)  \n",
    "        self.fc3 = nn.Linear(1, 1)  \n",
    "        self.fc4 = nn.Linear(1, 1)  \n",
    "        self.fc5 = nn.Linear(1, 1)  \n",
    "        self.fc6 = nn.Linear(6, 1)  \n",
    "        self.fc7 = nn.Linear(6, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        grouped_features = torch.cat((self.fc1(x[:, 0:1]), self.fc2(x[:, 1:2]), self.fc3(x[:, 2:3]), self.fc4(x[:, 3:4]), \n",
    "                                      self.fc5(x[:, 4:5]), self.fc6(x[:, 5:11]), self.fc7(x[:, 11:17])), dim=1)\n",
    "        \n",
    "        return grouped_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "0566a675-fad1-4179-9678-fb60888c43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.custom_layer = CustomLayer()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.custom_layer(x)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "4a677058-419a-49c9-885b-80c3275b0d83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "3.093400908553082\n",
      "Validation loss: 2.5141162872314453\n",
      "mse 2.5141160970722924\n",
      "New best model found at epoch 1 with validation loss 2.5141162872314453\n",
      "Starting Epoch 2\n",
      "2.6803218644598257\n",
      "Validation loss: 2.2201597690582275\n",
      "mse 2.220159713113281\n",
      "New best model found at epoch 2 with validation loss 2.2201597690582275\n",
      "Starting Epoch 3\n",
      "2.3505086587822954\n",
      "Validation loss: 1.994418740272522\n",
      "mse 1.9944186772891648\n",
      "New best model found at epoch 3 with validation loss 1.994418740272522\n",
      "Starting Epoch 4\n",
      "2.1150727375693945\n",
      "Validation loss: 1.8535053730010986\n",
      "mse 1.8535055009078956\n",
      "New best model found at epoch 4 with validation loss 1.8535053730010986\n",
      "Starting Epoch 5\n",
      "1.9666504134302554\n",
      "Validation loss: 1.7718647718429565\n",
      "mse 1.7718646731488723\n",
      "New best model found at epoch 5 with validation loss 1.7718647718429565\n",
      "Starting Epoch 6\n",
      "1.8764366170634394\n",
      "Validation loss: 1.7194154262542725\n",
      "mse 1.719415411516193\n",
      "New best model found at epoch 6 with validation loss 1.7194154262542725\n",
      "Starting Epoch 7\n",
      "1.815543382064156\n",
      "Validation loss: 1.6858464479446411\n",
      "mse 1.6858464695151403\n",
      "New best model found at epoch 7 with validation loss 1.6858464479446411\n",
      "Starting Epoch 8\n",
      "1.7722755618717358\n",
      "Validation loss: 1.6655627489089966\n",
      "mse 1.6655628688230912\n",
      "New best model found at epoch 8 with validation loss 1.6655627489089966\n",
      "Starting Epoch 9\n",
      "1.7415258728939553\n",
      "Validation loss: 1.6498605012893677\n",
      "mse 1.6498605085464135\n",
      "New best model found at epoch 9 with validation loss 1.6498605012893677\n",
      "Starting Epoch 10\n",
      "1.715751984845037\n",
      "Validation loss: 1.637126088142395\n",
      "mse 1.6371261644725523\n",
      "New best model found at epoch 10 with validation loss 1.637126088142395\n",
      "Starting Epoch 11\n",
      "1.6946329966835354\n",
      "Validation loss: 1.6252914667129517\n",
      "mse 1.6252914356674664\n",
      "New best model found at epoch 11 with validation loss 1.6252914667129517\n",
      "Starting Epoch 12\n",
      "1.6771651661914329\n",
      "Validation loss: 1.6140681505203247\n",
      "mse 1.6140682839222966\n",
      "New best model found at epoch 12 with validation loss 1.6140681505203247\n",
      "Starting Epoch 13\n",
      "1.661016531612562\n",
      "Validation loss: 1.6021487712860107\n",
      "mse 1.6021487501920428\n",
      "New best model found at epoch 13 with validation loss 1.6021487712860107\n",
      "Starting Epoch 14\n",
      "1.646541574726934\n",
      "Validation loss: 1.594165563583374\n",
      "mse 1.5941655423583494\n",
      "New best model found at epoch 14 with validation loss 1.594165563583374\n",
      "Starting Epoch 15\n",
      "1.6341573466425356\n",
      "Validation loss: 1.5870925188064575\n",
      "mse 1.5870926031035393\n",
      "New best model found at epoch 15 with validation loss 1.5870925188064575\n",
      "Starting Epoch 16\n",
      "1.6234825383061948\n",
      "Validation loss: 1.5815335512161255\n",
      "mse 1.5815336453789033\n",
      "New best model found at epoch 16 with validation loss 1.5815335512161255\n",
      "Starting Epoch 17\n",
      "1.6138655672902646\n",
      "Validation loss: 1.575329065322876\n",
      "mse 1.5753290650688903\n",
      "New best model found at epoch 17 with validation loss 1.575329065322876\n",
      "Starting Epoch 18\n",
      "1.6046086057372715\n",
      "Validation loss: 1.5695149898529053\n",
      "mse 1.569514982035532\n",
      "New best model found at epoch 18 with validation loss 1.5695149898529053\n",
      "Starting Epoch 19\n",
      "1.59596084770949\n",
      "Validation loss: 1.562066674232483\n",
      "mse 1.5620666370303447\n",
      "New best model found at epoch 19 with validation loss 1.562066674232483\n",
      "Starting Epoch 20\n",
      "1.5876570007075435\n",
      "Validation loss: 1.5560400485992432\n",
      "mse 1.5560401501088603\n",
      "New best model found at epoch 20 with validation loss 1.5560400485992432\n",
      "Starting Epoch 21\n",
      "1.5798531822536304\n",
      "Validation loss: 1.5501399040222168\n",
      "mse 1.550140010915043\n",
      "New best model found at epoch 21 with validation loss 1.5501399040222168\n",
      "Starting Epoch 22\n",
      "1.572667165942814\n",
      "Validation loss: 1.5455622673034668\n",
      "mse 1.5455622806768081\n",
      "New best model found at epoch 22 with validation loss 1.5455622673034668\n",
      "Starting Epoch 23\n",
      "1.5657939340757288\n",
      "Validation loss: 1.5427937507629395\n",
      "mse 1.542793704680574\n",
      "New best model found at epoch 23 with validation loss 1.5427937507629395\n",
      "Starting Epoch 24\n",
      "1.5596648610156516\n",
      "Validation loss: 1.5368350744247437\n",
      "mse 1.5368349980450455\n",
      "New best model found at epoch 24 with validation loss 1.5368350744247437\n",
      "Starting Epoch 25\n",
      "1.553699737009795\n",
      "Validation loss: 1.5325500965118408\n",
      "mse 1.5325501166235986\n",
      "New best model found at epoch 25 with validation loss 1.5325500965118408\n",
      "Starting Epoch 26\n",
      "1.5474872200385383\n",
      "Validation loss: 1.5283238887786865\n",
      "mse 1.5283239314082433\n",
      "New best model found at epoch 26 with validation loss 1.5283238887786865\n",
      "Starting Epoch 27\n",
      "1.5416514899419702\n",
      "Validation loss: 1.5238654613494873\n",
      "mse 1.5238655991042003\n",
      "New best model found at epoch 27 with validation loss 1.5238654613494873\n",
      "Starting Epoch 28\n",
      "1.5360749726710112\n",
      "Validation loss: 1.5198345184326172\n",
      "mse 1.5198345917618148\n",
      "New best model found at epoch 28 with validation loss 1.5198345184326172\n",
      "Starting Epoch 29\n",
      "1.5308966818063154\n",
      "Validation loss: 1.5163438320159912\n",
      "mse 1.516343822064952\n",
      "New best model found at epoch 29 with validation loss 1.5163438320159912\n",
      "Starting Epoch 30\n",
      "1.5256004463071409\n",
      "Validation loss: 1.5127732753753662\n",
      "mse 1.512773398083772\n",
      "New best model found at epoch 30 with validation loss 1.5127732753753662\n",
      "Starting Epoch 31\n",
      "1.5199738507685454\n",
      "Validation loss: 1.5088574886322021\n",
      "mse 1.5088574035640772\n",
      "New best model found at epoch 31 with validation loss 1.5088574886322021\n",
      "Starting Epoch 32\n",
      "1.5144834751668184\n",
      "Validation loss: 1.5050257444381714\n",
      "mse 1.505025753779996\n",
      "New best model found at epoch 32 with validation loss 1.5050257444381714\n",
      "Starting Epoch 33\n",
      "1.5085809178974317\n",
      "Validation loss: 1.5005879402160645\n",
      "mse 1.5005879454698678\n",
      "New best model found at epoch 33 with validation loss 1.5005879402160645\n",
      "Starting Epoch 34\n",
      "1.502667846887008\n",
      "Validation loss: 1.4962358474731445\n",
      "mse 1.4962359398921021\n",
      "New best model found at epoch 34 with validation loss 1.4962358474731445\n",
      "Starting Epoch 35\n",
      "1.497265820917876\n",
      "Validation loss: 1.4922059774398804\n",
      "mse 1.492205952868276\n",
      "New best model found at epoch 35 with validation loss 1.4922059774398804\n",
      "Starting Epoch 36\n",
      "1.4928405103476152\n",
      "Validation loss: 1.488211750984192\n",
      "mse 1.4882117738073346\n",
      "New best model found at epoch 36 with validation loss 1.488211750984192\n",
      "Starting Epoch 37\n",
      "1.4888672414033308\n",
      "Validation loss: 1.4857844114303589\n",
      "mse 1.4857843678052263\n",
      "New best model found at epoch 37 with validation loss 1.4857844114303589\n",
      "Starting Epoch 38\n",
      "1.4846211309018342\n",
      "Validation loss: 1.4811846017837524\n",
      "mse 1.4811845725577315\n",
      "New best model found at epoch 38 with validation loss 1.4811846017837524\n",
      "Starting Epoch 39\n",
      "1.4803170276724773\n",
      "Validation loss: 1.4788578748703003\n",
      "mse 1.478857816976262\n",
      "New best model found at epoch 39 with validation loss 1.4788578748703003\n",
      "Starting Epoch 40\n",
      "1.4760093352069026\n",
      "Validation loss: 1.4746849536895752\n",
      "mse 1.4746849306682108\n",
      "New best model found at epoch 40 with validation loss 1.4746849536895752\n",
      "Starting Epoch 41\n",
      "1.471879622210627\n",
      "Validation loss: 1.4707741737365723\n",
      "mse 1.4707742389317076\n",
      "New best model found at epoch 41 with validation loss 1.4707741737365723\n",
      "Starting Epoch 42\n",
      "1.4679409135942874\n",
      "Validation loss: 1.4672397375106812\n",
      "mse 1.467239840470785\n",
      "New best model found at epoch 42 with validation loss 1.4672397375106812\n",
      "Starting Epoch 43\n",
      "1.4644297128138335\n",
      "Validation loss: 1.464963436126709\n",
      "mse 1.4649635112714237\n",
      "New best model found at epoch 43 with validation loss 1.464963436126709\n",
      "Starting Epoch 44\n",
      "1.4611021280288696\n",
      "Validation loss: 1.4620031118392944\n",
      "mse 1.4620031469522274\n",
      "New best model found at epoch 44 with validation loss 1.4620031118392944\n",
      "Starting Epoch 45\n",
      "1.4578201978102974\n",
      "Validation loss: 1.4594404697418213\n",
      "mse 1.459440439875533\n",
      "New best model found at epoch 45 with validation loss 1.4594404697418213\n",
      "Starting Epoch 46\n",
      "1.4548589664956797\n",
      "Validation loss: 1.4570432901382446\n",
      "mse 1.4570434848826461\n",
      "New best model found at epoch 46 with validation loss 1.4570432901382446\n",
      "Starting Epoch 47\n",
      "1.451869197513746\n",
      "Validation loss: 1.4551829099655151\n",
      "mse 1.4551829040976856\n",
      "New best model found at epoch 47 with validation loss 1.4551829099655151\n",
      "Starting Epoch 48\n",
      "1.4494329587272976\n",
      "Validation loss: 1.452001929283142\n",
      "mse 1.4520018437715616\n",
      "New best model found at epoch 48 with validation loss 1.452001929283142\n",
      "Starting Epoch 49\n",
      "1.4466447285983874\n",
      "Validation loss: 1.449552059173584\n",
      "mse 1.4495521549464692\n",
      "New best model found at epoch 49 with validation loss 1.449552059173584\n",
      "Starting Epoch 50\n",
      "1.4436818257622097\n",
      "Validation loss: 1.4472379684448242\n",
      "mse 1.4472379102192097\n",
      "New best model found at epoch 50 with validation loss 1.4472379684448242\n",
      "Starting Epoch 51\n",
      "1.4408929892208264\n",
      "Validation loss: 1.4446479082107544\n",
      "mse 1.4446479765691644\n",
      "New best model found at epoch 51 with validation loss 1.4446479082107544\n",
      "Starting Epoch 52\n",
      "1.4382586764252705\n",
      "Validation loss: 1.4419959783554077\n",
      "mse 1.4419959126075514\n",
      "New best model found at epoch 52 with validation loss 1.4419959783554077\n",
      "Starting Epoch 53\n",
      "1.4355648496876592\n",
      "Validation loss: 1.4391697645187378\n",
      "mse 1.4391696631392483\n",
      "New best model found at epoch 53 with validation loss 1.4391697645187378\n",
      "Starting Epoch 54\n",
      "1.4329099784726682\n",
      "Validation loss: 1.4373058080673218\n",
      "mse 1.437305867727807\n",
      "New best model found at epoch 54 with validation loss 1.4373058080673218\n",
      "Starting Epoch 55\n",
      "1.4303445219993591\n",
      "Validation loss: 1.4354627132415771\n",
      "mse 1.4354627326871676\n",
      "New best model found at epoch 55 with validation loss 1.4354627132415771\n",
      "Starting Epoch 56\n",
      "1.4276623103929602\n",
      "Validation loss: 1.4332270622253418\n",
      "mse 1.4332271668884715\n",
      "New best model found at epoch 56 with validation loss 1.4332270622253418\n",
      "Starting Epoch 57\n",
      "1.425231827341992\n",
      "Validation loss: 1.430934190750122\n",
      "mse 1.430934131775515\n",
      "New best model found at epoch 57 with validation loss 1.430934190750122\n",
      "Starting Epoch 58\n",
      "1.4227490502855051\n",
      "Validation loss: 1.4289089441299438\n",
      "mse 1.4289090416403694\n",
      "New best model found at epoch 58 with validation loss 1.4289089441299438\n",
      "Starting Epoch 59\n",
      "1.4203258156776428\n",
      "Validation loss: 1.426105260848999\n",
      "mse 1.4261052965713934\n",
      "New best model found at epoch 59 with validation loss 1.426105260848999\n",
      "Starting Epoch 60\n",
      "1.4179489353428716\n",
      "Validation loss: 1.4239037036895752\n",
      "mse 1.4239036766217321\n",
      "New best model found at epoch 60 with validation loss 1.4239037036895752\n",
      "Starting Epoch 61\n",
      "1.4155810190283733\n",
      "Validation loss: 1.4216842651367188\n",
      "mse 1.4216841761363683\n",
      "New best model found at epoch 61 with validation loss 1.4216842651367188\n",
      "Starting Epoch 62\n",
      "1.4130887985229492\n",
      "Validation loss: 1.419231653213501\n",
      "mse 1.4192316898594823\n",
      "New best model found at epoch 62 with validation loss 1.419231653213501\n",
      "Starting Epoch 63\n",
      "1.4106532438941624\n",
      "Validation loss: 1.4170656204223633\n",
      "mse 1.4170656513139785\n",
      "New best model found at epoch 63 with validation loss 1.4170656204223633\n",
      "Starting Epoch 64\n",
      "1.4082953256109487\n",
      "Validation loss: 1.4148374795913696\n",
      "mse 1.4148375403062459\n",
      "New best model found at epoch 64 with validation loss 1.4148374795913696\n",
      "Starting Epoch 65\n",
      "1.40604915826217\n",
      "Validation loss: 1.4127720594406128\n",
      "mse 1.4127719629210371\n",
      "New best model found at epoch 65 with validation loss 1.4127720594406128\n",
      "Starting Epoch 66\n",
      "1.4035908061525095\n",
      "Validation loss: 1.41020929813385\n",
      "mse 1.4102093207514608\n",
      "New best model found at epoch 66 with validation loss 1.41020929813385\n",
      "Starting Epoch 67\n",
      "1.4012831579083982\n",
      "Validation loss: 1.407615065574646\n",
      "mse 1.4076149173478258\n",
      "New best model found at epoch 67 with validation loss 1.407615065574646\n",
      "Starting Epoch 68\n",
      "1.398922500403031\n",
      "Validation loss: 1.4052906036376953\n",
      "mse 1.405290638053771\n",
      "New best model found at epoch 68 with validation loss 1.4052906036376953\n",
      "Starting Epoch 69\n",
      "1.3963976321013079\n",
      "Validation loss: 1.4029152393341064\n",
      "mse 1.402915165226357\n",
      "New best model found at epoch 69 with validation loss 1.4029152393341064\n",
      "Starting Epoch 70\n",
      "1.3941151214682537\n",
      "Validation loss: 1.4008573293685913\n",
      "mse 1.4008574829696545\n",
      "New best model found at epoch 70 with validation loss 1.4008573293685913\n",
      "Starting Epoch 71\n",
      "1.3917975218399712\n",
      "Validation loss: 1.3988765478134155\n",
      "mse 1.3988765819404998\n",
      "New best model found at epoch 71 with validation loss 1.3988765478134155\n",
      "Starting Epoch 72\n",
      "1.389561598715575\n",
      "Validation loss: 1.3969234228134155\n",
      "mse 1.3969235060808454\n",
      "New best model found at epoch 72 with validation loss 1.3969234228134155\n",
      "Starting Epoch 73\n",
      "1.387231829373733\n",
      "Validation loss: 1.3946194648742676\n",
      "mse 1.3946193426164113\n",
      "New best model found at epoch 73 with validation loss 1.3946194648742676\n",
      "Starting Epoch 74\n",
      "1.3848810947459678\n",
      "Validation loss: 1.3923680782318115\n",
      "mse 1.39236817733957\n",
      "New best model found at epoch 74 with validation loss 1.3923680782318115\n",
      "Starting Epoch 75\n",
      "1.3827991796576458\n",
      "Validation loss: 1.3905425071716309\n",
      "mse 1.3905425806998652\n",
      "New best model found at epoch 75 with validation loss 1.3905425071716309\n",
      "Starting Epoch 76\n",
      "1.380486099616341\n",
      "Validation loss: 1.388196587562561\n",
      "mse 1.3881966619592578\n",
      "New best model found at epoch 76 with validation loss 1.388196587562561\n",
      "Starting Epoch 77\n",
      "1.3783402857573137\n",
      "Validation loss: 1.3863774538040161\n",
      "mse 1.3863773262982224\n",
      "New best model found at epoch 77 with validation loss 1.3863774538040161\n",
      "Starting Epoch 78\n",
      "1.37626191066659\n",
      "Validation loss: 1.3847103118896484\n",
      "mse 1.3847102464866514\n",
      "New best model found at epoch 78 with validation loss 1.3847103118896484\n",
      "Starting Epoch 79\n",
      "1.374155342578888\n",
      "Validation loss: 1.382630705833435\n",
      "mse 1.3826307165513672\n",
      "New best model found at epoch 79 with validation loss 1.382630705833435\n",
      "Starting Epoch 80\n",
      "1.372011617473934\n",
      "Validation loss: 1.3806456327438354\n",
      "mse 1.3806455783855436\n",
      "New best model found at epoch 80 with validation loss 1.3806456327438354\n",
      "Starting Epoch 81\n",
      "1.3696933259134707\n",
      "Validation loss: 1.3790199756622314\n",
      "mse 1.3790199794223166\n",
      "New best model found at epoch 81 with validation loss 1.3790199756622314\n",
      "Starting Epoch 82\n",
      "1.3679641899855242\n",
      "Validation loss: 1.3769439458847046\n",
      "mse 1.3769439240808565\n",
      "New best model found at epoch 82 with validation loss 1.3769439458847046\n",
      "Starting Epoch 83\n",
      "1.3660499349884365\n",
      "Validation loss: 1.3750077486038208\n",
      "mse 1.3750078375763\n",
      "New best model found at epoch 83 with validation loss 1.3750077486038208\n",
      "Starting Epoch 84\n",
      "1.36404069610264\n",
      "Validation loss: 1.3736567497253418\n",
      "mse 1.373656713412551\n",
      "New best model found at epoch 84 with validation loss 1.3736567497253418\n",
      "Starting Epoch 85\n",
      "1.36216460103574\n",
      "Validation loss: 1.3716448545455933\n",
      "mse 1.3716448244207802\n",
      "New best model found at epoch 85 with validation loss 1.3716448545455933\n",
      "Starting Epoch 86\n",
      "1.360335173814193\n",
      "Validation loss: 1.3699820041656494\n",
      "mse 1.3699819612197113\n",
      "New best model found at epoch 86 with validation loss 1.3699820041656494\n",
      "Starting Epoch 87\n",
      "1.358606939730437\n",
      "Validation loss: 1.3682845830917358\n",
      "mse 1.3682846847933205\n",
      "New best model found at epoch 87 with validation loss 1.3682845830917358\n",
      "Starting Epoch 88\n",
      "1.3568087557087773\n",
      "Validation loss: 1.3665356636047363\n",
      "mse 1.3665356446597448\n",
      "New best model found at epoch 88 with validation loss 1.3665356636047363\n",
      "Starting Epoch 89\n",
      "1.3551090437432993\n",
      "Validation loss: 1.3647433519363403\n",
      "mse 1.364743252881733\n",
      "New best model found at epoch 89 with validation loss 1.3647433519363403\n",
      "Starting Epoch 90\n",
      "1.3534279491590417\n",
      "Validation loss: 1.3631340265274048\n",
      "mse 1.3631340267468117\n",
      "New best model found at epoch 90 with validation loss 1.3631340265274048\n",
      "Starting Epoch 91\n",
      "1.3516884912615237\n",
      "Validation loss: 1.3616560697555542\n",
      "mse 1.3616559381168243\n",
      "New best model found at epoch 91 with validation loss 1.3616560697555542\n",
      "Starting Epoch 92\n",
      "1.3499943380770476\n",
      "Validation loss: 1.3601245880126953\n",
      "mse 1.3601246014538435\n",
      "New best model found at epoch 92 with validation loss 1.3601245880126953\n",
      "Starting Epoch 93\n",
      "1.3483168197714763\n",
      "Validation loss: 1.358591079711914\n",
      "mse 1.3585910225341518\n",
      "New best model found at epoch 93 with validation loss 1.358591079711914\n",
      "Starting Epoch 94\n",
      "1.346773378227068\n",
      "Validation loss: 1.3570083379745483\n",
      "mse 1.35700842390328\n",
      "New best model found at epoch 94 with validation loss 1.3570083379745483\n",
      "Starting Epoch 95\n",
      "1.345018153605254\n",
      "Validation loss: 1.355432152748108\n",
      "mse 1.355432091815643\n",
      "New best model found at epoch 95 with validation loss 1.355432152748108\n",
      "Starting Epoch 96\n",
      "1.3434558251629705\n",
      "Validation loss: 1.3537532091140747\n",
      "mse 1.35375314777315\n",
      "New best model found at epoch 96 with validation loss 1.3537532091140747\n",
      "Starting Epoch 97\n",
      "1.3418560002161108\n",
      "Validation loss: 1.3517500162124634\n",
      "mse 1.3517499659754644\n",
      "New best model found at epoch 97 with validation loss 1.3517500162124634\n",
      "Starting Epoch 98\n",
      "1.3402925159620203\n",
      "Validation loss: 1.350463628768921\n",
      "mse 1.3504636185291017\n",
      "New best model found at epoch 98 with validation loss 1.350463628768921\n",
      "Starting Epoch 99\n",
      "1.3386516311894292\n",
      "Validation loss: 1.348690390586853\n",
      "mse 1.348690370352715\n",
      "New best model found at epoch 99 with validation loss 1.348690390586853\n",
      "Starting Epoch 100\n",
      "1.337177989275559\n",
      "Validation loss: 1.3468166589736938\n",
      "mse 1.346816650745304\n",
      "New best model found at epoch 100 with validation loss 1.3468166589736938\n",
      "Starting Epoch 101\n",
      "1.3355508291203042\n",
      "Validation loss: 1.3450418710708618\n",
      "mse 1.3450419836623544\n",
      "New best model found at epoch 101 with validation loss 1.3450418710708618\n",
      "Starting Epoch 102\n",
      "1.3339927637058755\n",
      "Validation loss: 1.343269944190979\n",
      "mse 1.3432697980381407\n",
      "New best model found at epoch 102 with validation loss 1.343269944190979\n",
      "Starting Epoch 103\n",
      "1.3323879734329556\n",
      "Validation loss: 1.3418980836868286\n",
      "mse 1.341898056631808\n",
      "New best model found at epoch 103 with validation loss 1.3418980836868286\n",
      "Starting Epoch 104\n",
      "1.3309409177821616\n",
      "Validation loss: 1.3401999473571777\n",
      "mse 1.3402001225371398\n",
      "New best model found at epoch 104 with validation loss 1.3401999473571777\n",
      "Starting Epoch 105\n",
      "1.3291562847469165\n",
      "Validation loss: 1.3386577367782593\n",
      "mse 1.3386577235867791\n",
      "New best model found at epoch 105 with validation loss 1.3386577367782593\n",
      "Starting Epoch 106\n",
      "1.3276416529779849\n",
      "Validation loss: 1.337049961090088\n",
      "mse 1.33704992439651\n",
      "New best model found at epoch 106 with validation loss 1.337049961090088\n",
      "Starting Epoch 107\n",
      "1.326284022434898\n",
      "Validation loss: 1.3355789184570312\n",
      "mse 1.3355789872635626\n",
      "New best model found at epoch 107 with validation loss 1.3355789184570312\n",
      "Starting Epoch 108\n",
      "1.324843414451765\n",
      "Validation loss: 1.3341364860534668\n",
      "mse 1.3341364587841607\n",
      "New best model found at epoch 108 with validation loss 1.3341364860534668\n",
      "Starting Epoch 109\n",
      "1.323661542457083\n",
      "Validation loss: 1.33230721950531\n",
      "mse 1.3323070912092252\n",
      "New best model found at epoch 109 with validation loss 1.33230721950531\n",
      "Starting Epoch 110\n",
      "1.3219793957212698\n",
      "Validation loss: 1.3308703899383545\n",
      "mse 1.3308703941399116\n",
      "New best model found at epoch 110 with validation loss 1.3308703899383545\n",
      "Starting Epoch 111\n",
      "1.320628469404967\n",
      "Validation loss: 1.3289623260498047\n",
      "mse 1.3289622596211854\n",
      "New best model found at epoch 111 with validation loss 1.3289623260498047\n",
      "Starting Epoch 112\n",
      "1.3192223854686902\n",
      "Validation loss: 1.327407717704773\n",
      "mse 1.3274078281403612\n",
      "New best model found at epoch 112 with validation loss 1.327407717704773\n",
      "Starting Epoch 113\n",
      "1.3180496303931526\n",
      "Validation loss: 1.3257946968078613\n",
      "mse 1.3257947103108725\n",
      "New best model found at epoch 113 with validation loss 1.3257946968078613\n",
      "Starting Epoch 114\n",
      "1.316402028436246\n",
      "Validation loss: 1.3241592645645142\n",
      "mse 1.324159110014841\n",
      "New best model found at epoch 114 with validation loss 1.3241592645645142\n",
      "Starting Epoch 115\n",
      "1.3152809324471846\n",
      "Validation loss: 1.3227258920669556\n",
      "mse 1.3227258849623367\n",
      "New best model found at epoch 115 with validation loss 1.3227258920669556\n",
      "Starting Epoch 116\n",
      "1.3136613757713982\n",
      "Validation loss: 1.3215030431747437\n",
      "mse 1.321503110140739\n",
      "New best model found at epoch 116 with validation loss 1.3215030431747437\n",
      "Starting Epoch 117\n",
      "1.3125768718512163\n",
      "Validation loss: 1.3198494911193848\n",
      "mse 1.3198494979048183\n",
      "New best model found at epoch 117 with validation loss 1.3198494911193848\n",
      "Starting Epoch 118\n",
      "1.311147215573684\n",
      "Validation loss: 1.318482518196106\n",
      "mse 1.3184825456924283\n",
      "New best model found at epoch 118 with validation loss 1.318482518196106\n",
      "Starting Epoch 119\n",
      "1.3098335732584414\n",
      "Validation loss: 1.3167026042938232\n",
      "mse 1.3167024598751866\n",
      "New best model found at epoch 119 with validation loss 1.3167026042938232\n",
      "Starting Epoch 120\n",
      "1.3085468281870303\n",
      "Validation loss: 1.3154926300048828\n",
      "mse 1.315492691069744\n",
      "New best model found at epoch 120 with validation loss 1.3154926300048828\n",
      "Starting Epoch 121\n",
      "1.3071953887524812\n",
      "Validation loss: 1.3138381242752075\n",
      "mse 1.3138381140124422\n",
      "New best model found at epoch 121 with validation loss 1.3138381242752075\n",
      "Starting Epoch 122\n",
      "1.305859397286954\n",
      "Validation loss: 1.3127789497375488\n",
      "mse 1.3127789595226385\n",
      "New best model found at epoch 122 with validation loss 1.3127789497375488\n",
      "Starting Epoch 123\n",
      "1.3045225117517554\n",
      "Validation loss: 1.3111108541488647\n",
      "mse 1.3111108938902303\n",
      "New best model found at epoch 123 with validation loss 1.3111108541488647\n",
      "Starting Epoch 124\n",
      "1.3031314093133677\n",
      "Validation loss: 1.3094482421875\n",
      "mse 1.3094482298717456\n",
      "New best model found at epoch 124 with validation loss 1.3094482421875\n",
      "Starting Epoch 125\n",
      "1.3018225379612134\n",
      "Validation loss: 1.3077571392059326\n",
      "mse 1.3077573101599407\n",
      "New best model found at epoch 125 with validation loss 1.3077571392059326\n",
      "Starting Epoch 126\n",
      "1.3005336497140967\n",
      "Validation loss: 1.3063788414001465\n",
      "mse 1.3063787653924284\n",
      "New best model found at epoch 126 with validation loss 1.3063788414001465\n",
      "Starting Epoch 127\n",
      "1.2994412183761597\n",
      "Validation loss: 1.3053288459777832\n",
      "mse 1.3053289168935558\n",
      "New best model found at epoch 127 with validation loss 1.3053288459777832\n",
      "Starting Epoch 128\n",
      "1.2980385966922925\n",
      "Validation loss: 1.3042796850204468\n",
      "mse 1.304279785096886\n",
      "New best model found at epoch 128 with validation loss 1.3042796850204468\n",
      "Starting Epoch 129\n",
      "1.2969064453373784\n",
      "Validation loss: 1.3030236959457397\n",
      "mse 1.3030236960274768\n",
      "New best model found at epoch 129 with validation loss 1.3030236959457397\n",
      "Starting Epoch 130\n",
      "1.2958428626475127\n",
      "Validation loss: 1.302062749862671\n",
      "mse 1.3020628022045155\n",
      "New best model found at epoch 130 with validation loss 1.302062749862671\n",
      "Starting Epoch 131\n",
      "1.2946534053139065\n",
      "Validation loss: 1.3009765148162842\n",
      "mse 1.3009765582651986\n",
      "New best model found at epoch 131 with validation loss 1.3009765148162842\n",
      "Starting Epoch 132\n",
      "1.2931827643643254\n",
      "Validation loss: 1.2996729612350464\n",
      "mse 1.2996729730481291\n",
      "New best model found at epoch 132 with validation loss 1.2996729612350464\n",
      "Starting Epoch 133\n",
      "1.292251654293226\n",
      "Validation loss: 1.298804521560669\n",
      "mse 1.298804616009878\n",
      "New best model found at epoch 133 with validation loss 1.298804521560669\n",
      "Starting Epoch 134\n",
      "1.290841659773951\n",
      "Validation loss: 1.2975026369094849\n",
      "mse 1.2975027001693495\n",
      "New best model found at epoch 134 with validation loss 1.2975026369094849\n",
      "Starting Epoch 135\n",
      "1.2895940879116887\n",
      "Validation loss: 1.2961119413375854\n",
      "mse 1.296112028429072\n",
      "New best model found at epoch 135 with validation loss 1.2961119413375854\n",
      "Starting Epoch 136\n",
      "1.2885236714197241\n",
      "Validation loss: 1.2947570085525513\n",
      "mse 1.2947570377027289\n",
      "New best model found at epoch 136 with validation loss 1.2947570085525513\n",
      "Starting Epoch 137\n",
      "1.28727896835493\n",
      "Validation loss: 1.2935281991958618\n",
      "mse 1.293528192349897\n",
      "New best model found at epoch 137 with validation loss 1.2935281991958618\n",
      "Starting Epoch 138\n",
      "1.2861419812492703\n",
      "Validation loss: 1.2923680543899536\n",
      "mse 1.2923680698708486\n",
      "New best model found at epoch 138 with validation loss 1.2923680543899536\n",
      "Starting Epoch 139\n",
      "1.2849877113881318\n",
      "Validation loss: 1.2910641431808472\n",
      "mse 1.2910641353880983\n",
      "New best model found at epoch 139 with validation loss 1.2910641431808472\n",
      "Starting Epoch 140\n",
      "1.2838557673537212\n",
      "Validation loss: 1.2898145914077759\n",
      "mse 1.289814595362576\n",
      "New best model found at epoch 140 with validation loss 1.2898145914077759\n",
      "Starting Epoch 141\n",
      "1.2828086070392444\n",
      "Validation loss: 1.2884384393692017\n",
      "mse 1.2884386014659972\n",
      "New best model found at epoch 141 with validation loss 1.2884384393692017\n",
      "Starting Epoch 142\n",
      "1.2816672662030095\n",
      "Validation loss: 1.2872339487075806\n",
      "mse 1.2872340686163017\n",
      "New best model found at epoch 142 with validation loss 1.2872339487075806\n",
      "Starting Epoch 143\n",
      "1.2806132332138394\n",
      "Validation loss: 1.28513503074646\n",
      "mse 1.2851349867207742\n",
      "New best model found at epoch 143 with validation loss 1.28513503074646\n",
      "Starting Epoch 144\n",
      "1.2793170680170474\n",
      "Validation loss: 1.2821242809295654\n",
      "mse 1.2821243132906568\n",
      "New best model found at epoch 144 with validation loss 1.2821242809295654\n",
      "Starting Epoch 145\n",
      "1.2777212339898814\n",
      "Validation loss: 1.2789905071258545\n",
      "mse 1.2789904612131626\n",
      "New best model found at epoch 145 with validation loss 1.2789905071258545\n",
      "Starting Epoch 146\n",
      "1.2760890618614529\n",
      "Validation loss: 1.2761425971984863\n",
      "mse 1.2761424957608394\n",
      "New best model found at epoch 146 with validation loss 1.2761425971984863\n",
      "Starting Epoch 147\n",
      "1.2747704516286436\n",
      "Validation loss: 1.2737699747085571\n",
      "mse 1.2737699453117637\n",
      "New best model found at epoch 147 with validation loss 1.2737699747085571\n",
      "Starting Epoch 148\n",
      "1.2734416101289832\n",
      "Validation loss: 1.2721998691558838\n",
      "mse 1.272199840779633\n",
      "New best model found at epoch 148 with validation loss 1.2721998691558838\n",
      "Starting Epoch 149\n",
      "1.2722597381343013\n",
      "Validation loss: 1.2704416513442993\n",
      "mse 1.270441660348145\n",
      "New best model found at epoch 149 with validation loss 1.2704416513442993\n",
      "Starting Epoch 150\n",
      "1.2711175628330396\n",
      "Validation loss: 1.269911766052246\n",
      "mse 1.2699118451118065\n",
      "New best model found at epoch 150 with validation loss 1.269911766052246\n",
      "Starting Epoch 151\n",
      "1.2700674792994624\n",
      "Validation loss: 1.2686524391174316\n",
      "mse 1.268652427393999\n",
      "New best model found at epoch 151 with validation loss 1.2686524391174316\n",
      "Starting Epoch 152\n",
      "1.2689762711524963\n",
      "Validation loss: 1.2675440311431885\n",
      "mse 1.267544028058947\n",
      "New best model found at epoch 152 with validation loss 1.2675440311431885\n",
      "Starting Epoch 153\n",
      "1.2680564315422722\n",
      "Validation loss: 1.26664137840271\n",
      "mse 1.266641330320497\n",
      "New best model found at epoch 153 with validation loss 1.26664137840271\n",
      "Starting Epoch 154\n",
      "1.2669447142144907\n",
      "Validation loss: 1.2654602527618408\n",
      "mse 1.2654602266890864\n",
      "New best model found at epoch 154 with validation loss 1.2654602527618408\n",
      "Starting Epoch 155\n",
      "1.2659433121266572\n",
      "Validation loss: 1.2641818523406982\n",
      "mse 1.2641819178748899\n",
      "New best model found at epoch 155 with validation loss 1.2641818523406982\n",
      "Starting Epoch 156\n",
      "1.265158085719399\n",
      "Validation loss: 1.263120412826538\n",
      "mse 1.2631204886701874\n",
      "New best model found at epoch 156 with validation loss 1.263120412826538\n",
      "Starting Epoch 157\n",
      "1.2640106807584348\n",
      "Validation loss: 1.2615764141082764\n",
      "mse 1.2615764401289384\n",
      "New best model found at epoch 157 with validation loss 1.2615764141082764\n",
      "Starting Epoch 158\n",
      "1.262947556765183\n",
      "Validation loss: 1.2604840993881226\n",
      "mse 1.260484053395984\n",
      "New best model found at epoch 158 with validation loss 1.2604840993881226\n",
      "Starting Epoch 159\n",
      "1.2619260627290476\n",
      "Validation loss: 1.2591986656188965\n",
      "mse 1.259198694266013\n",
      "New best model found at epoch 159 with validation loss 1.2591986656188965\n",
      "Starting Epoch 160\n",
      "1.2610092681387197\n",
      "Validation loss: 1.2580710649490356\n",
      "mse 1.2580711027618832\n",
      "New best model found at epoch 160 with validation loss 1.2580710649490356\n",
      "Starting Epoch 161\n",
      "1.2599956885628079\n",
      "Validation loss: 1.256666898727417\n",
      "mse 1.2566670136825147\n",
      "New best model found at epoch 161 with validation loss 1.256666898727417\n",
      "Starting Epoch 162\n",
      "1.2590579364610754\n",
      "Validation loss: 1.2549266815185547\n",
      "mse 1.254926712143283\n",
      "New best model found at epoch 162 with validation loss 1.2549266815185547\n",
      "Starting Epoch 163\n",
      "1.258021240649016\n",
      "Validation loss: 1.254040241241455\n",
      "mse 1.2540401590540986\n",
      "New best model found at epoch 163 with validation loss 1.254040241241455\n",
      "Starting Epoch 164\n",
      "1.2571191709974538\n",
      "Validation loss: 1.252547025680542\n",
      "mse 1.2525471125987309\n",
      "New best model found at epoch 164 with validation loss 1.252547025680542\n",
      "Starting Epoch 165\n",
      "1.2561260047166243\n",
      "Validation loss: 1.2514891624450684\n",
      "mse 1.2514891490076478\n",
      "New best model found at epoch 165 with validation loss 1.2514891624450684\n",
      "Starting Epoch 166\n",
      "1.2551644807276519\n",
      "Validation loss: 1.250646710395813\n",
      "mse 1.250646714322755\n",
      "New best model found at epoch 166 with validation loss 1.250646710395813\n",
      "Starting Epoch 167\n",
      "1.2541383504867554\n",
      "Validation loss: 1.2502769231796265\n",
      "mse 1.2502768842135599\n",
      "New best model found at epoch 167 with validation loss 1.2502769231796265\n",
      "Starting Epoch 168\n",
      "1.253364438595979\n",
      "Validation loss: 1.2493319511413574\n",
      "mse 1.2493319639658835\n",
      "New best model found at epoch 168 with validation loss 1.2493319511413574\n",
      "Starting Epoch 169\n",
      "1.2523654129194177\n",
      "Validation loss: 1.2488863468170166\n",
      "mse 1.2488862855787595\n",
      "New best model found at epoch 169 with validation loss 1.2488863468170166\n",
      "Starting Epoch 170\n",
      "1.2516136895055356\n",
      "Validation loss: 1.2471054792404175\n",
      "mse 1.2471054907139183\n",
      "New best model found at epoch 170 with validation loss 1.2471054792404175\n",
      "Starting Epoch 171\n",
      "1.25061529615651\n",
      "Validation loss: 1.2464649677276611\n",
      "mse 1.2464649620935462\n",
      "New best model found at epoch 171 with validation loss 1.2464649677276611\n",
      "Starting Epoch 172\n",
      "1.2497876053271086\n",
      "Validation loss: 1.2453229427337646\n",
      "mse 1.2453229938870085\n",
      "New best model found at epoch 172 with validation loss 1.2453229427337646\n",
      "Starting Epoch 173\n",
      "1.2488376239071721\n",
      "Validation loss: 1.2447761297225952\n",
      "mse 1.2447761515382363\n",
      "New best model found at epoch 173 with validation loss 1.2447761297225952\n",
      "Starting Epoch 174\n",
      "1.2479994711668596\n",
      "Validation loss: 1.2434678077697754\n",
      "mse 1.2434678904277683\n",
      "New best model found at epoch 174 with validation loss 1.2434678077697754\n",
      "Starting Epoch 175\n",
      "1.2470317353372988\n",
      "Validation loss: 1.2421880960464478\n",
      "mse 1.2421881238981551\n",
      "New best model found at epoch 175 with validation loss 1.2421880960464478\n",
      "Starting Epoch 176\n",
      "1.2462020309075066\n",
      "Validation loss: 1.2417247295379639\n",
      "mse 1.2417246805556006\n",
      "New best model found at epoch 176 with validation loss 1.2417247295379639\n",
      "Starting Epoch 177\n",
      "1.2453240829965342\n",
      "Validation loss: 1.2406073808670044\n",
      "mse 1.240607330082815\n",
      "New best model found at epoch 177 with validation loss 1.2406073808670044\n",
      "Starting Epoch 178\n",
      "1.2443147483079329\n",
      "Validation loss: 1.239650011062622\n",
      "mse 1.239650106188851\n",
      "New best model found at epoch 178 with validation loss 1.239650011062622\n",
      "Starting Epoch 179\n",
      "1.2433936284935994\n",
      "Validation loss: 1.2393873929977417\n",
      "mse 1.2393872620527409\n",
      "New best model found at epoch 179 with validation loss 1.2393873929977417\n",
      "Starting Epoch 180\n",
      "1.2425773610239443\n",
      "Validation loss: 1.2383230924606323\n",
      "mse 1.2383230479410514\n",
      "New best model found at epoch 180 with validation loss 1.2383230924606323\n",
      "Starting Epoch 181\n",
      "1.2416985864224641\n",
      "Validation loss: 1.2365304231643677\n",
      "mse 1.2365303712606177\n",
      "New best model found at epoch 181 with validation loss 1.2365304231643677\n",
      "Starting Epoch 182\n",
      "1.2406529343646506\n",
      "Validation loss: 1.2353813648223877\n",
      "mse 1.2353812565290287\n",
      "New best model found at epoch 182 with validation loss 1.2353813648223877\n",
      "Starting Epoch 183\n",
      "1.2397040361943452\n",
      "Validation loss: 1.2351975440979004\n",
      "mse 1.2351976483292695\n",
      "New best model found at epoch 183 with validation loss 1.2351975440979004\n",
      "Starting Epoch 184\n",
      "1.2389583587646484\n",
      "Validation loss: 1.2336888313293457\n",
      "mse 1.233688782766493\n",
      "New best model found at epoch 184 with validation loss 1.2336888313293457\n",
      "Starting Epoch 185\n",
      "1.2380511294240537\n",
      "Validation loss: 1.2326747179031372\n",
      "mse 1.2326748412725534\n",
      "New best model found at epoch 185 with validation loss 1.2326747179031372\n",
      "Starting Epoch 186\n",
      "1.2369914858237556\n",
      "Validation loss: 1.2317429780960083\n",
      "mse 1.231742945193911\n",
      "New best model found at epoch 186 with validation loss 1.2317429780960083\n",
      "Starting Epoch 187\n",
      "1.2361896815507307\n",
      "Validation loss: 1.2306880950927734\n",
      "mse 1.2306881405462622\n",
      "New best model found at epoch 187 with validation loss 1.2306880950927734\n",
      "Starting Epoch 188\n",
      "1.2353444021681081\n",
      "Validation loss: 1.2289180755615234\n",
      "mse 1.2289182588122713\n",
      "New best model found at epoch 188 with validation loss 1.2289180755615234\n",
      "Starting Epoch 189\n",
      "1.2345001827115598\n",
      "Validation loss: 1.2289484739303589\n",
      "mse 1.2289485320489513\n",
      "Starting Epoch 190\n",
      "1.2335231926130212\n",
      "Validation loss: 1.227599859237671\n",
      "mse 1.22760004553218\n",
      "New best model found at epoch 190 with validation loss 1.227599859237671\n",
      "Starting Epoch 191\n",
      "1.2325995719951133\n",
      "Validation loss: 1.2264633178710938\n",
      "mse 1.2264633229717201\n",
      "New best model found at epoch 191 with validation loss 1.2264633178710938\n",
      "Starting Epoch 192\n",
      "1.2316771667936575\n",
      "Validation loss: 1.2244682312011719\n",
      "mse 1.2244682072873008\n",
      "New best model found at epoch 192 with validation loss 1.2244682312011719\n",
      "Starting Epoch 193\n",
      "1.2305910405905351\n",
      "Validation loss: 1.2235119342803955\n",
      "mse 1.2235119813415967\n",
      "New best model found at epoch 193 with validation loss 1.2235119342803955\n",
      "Starting Epoch 194\n",
      "1.2297044914701711\n",
      "Validation loss: 1.2216720581054688\n",
      "mse 1.221672010479962\n",
      "New best model found at epoch 194 with validation loss 1.2216720581054688\n",
      "Starting Epoch 195\n",
      "1.2289445374322974\n",
      "Validation loss: 1.2208558320999146\n",
      "mse 1.2208558717805835\n",
      "New best model found at epoch 195 with validation loss 1.2208558320999146\n",
      "Starting Epoch 196\n",
      "1.2279342620269111\n",
      "Validation loss: 1.219433069229126\n",
      "mse 1.2194330937997995\n",
      "New best model found at epoch 196 with validation loss 1.219433069229126\n",
      "Starting Epoch 197\n",
      "1.2271297988684282\n",
      "Validation loss: 1.218536376953125\n",
      "mse 1.2185365549615683\n",
      "New best model found at epoch 197 with validation loss 1.218536376953125\n",
      "Starting Epoch 198\n",
      "1.2261716179225757\n",
      "Validation loss: 1.216507911682129\n",
      "mse 1.21650791468653\n",
      "New best model found at epoch 198 with validation loss 1.216507911682129\n",
      "Starting Epoch 199\n",
      "1.225242606971575\n",
      "Validation loss: 1.2157474756240845\n",
      "mse 1.2157474104323522\n",
      "New best model found at epoch 199 with validation loss 1.2157474756240845\n",
      "Starting Epoch 200\n",
      "1.224355917909871\n",
      "Validation loss: 1.2149428129196167\n",
      "mse 1.2149428024141362\n",
      "New best model found at epoch 200 with validation loss 1.2149428129196167\n",
      "Starting Epoch 201\n",
      "1.2234326212302498\n",
      "Validation loss: 1.213285207748413\n",
      "mse 1.2132852703004127\n",
      "New best model found at epoch 201 with validation loss 1.213285207748413\n",
      "Starting Epoch 202\n",
      "1.2226262299910835\n",
      "Validation loss: 1.212392807006836\n",
      "mse 1.212392808630278\n",
      "New best model found at epoch 202 with validation loss 1.212392807006836\n",
      "Starting Epoch 203\n",
      "1.2218531551568403\n",
      "Validation loss: 1.2114156484603882\n",
      "mse 1.2114155018100885\n",
      "New best model found at epoch 203 with validation loss 1.2114156484603882\n",
      "Starting Epoch 204\n",
      "1.2209571133489194\n",
      "Validation loss: 1.2094122171401978\n",
      "mse 1.2094122382559256\n",
      "New best model found at epoch 204 with validation loss 1.2094122171401978\n",
      "Starting Epoch 205\n",
      "1.220189965289572\n",
      "Validation loss: 1.208566665649414\n",
      "mse 1.2085665240119752\n",
      "New best model found at epoch 205 with validation loss 1.208566665649414\n",
      "Starting Epoch 206\n",
      "1.2193623288818027\n",
      "Validation loss: 1.207594633102417\n",
      "mse 1.207594677572415\n",
      "New best model found at epoch 206 with validation loss 1.207594633102417\n",
      "Starting Epoch 207\n",
      "1.2185476059498994\n",
      "Validation loss: 1.2065913677215576\n",
      "mse 1.2065914234682042\n",
      "New best model found at epoch 207 with validation loss 1.2065913677215576\n",
      "Starting Epoch 208\n",
      "1.2177233333173005\n",
      "Validation loss: 1.2048863172531128\n",
      "mse 1.2048862252964758\n",
      "New best model found at epoch 208 with validation loss 1.2048863172531128\n",
      "Starting Epoch 209\n",
      "1.2168677915697512\n",
      "Validation loss: 1.2042176723480225\n",
      "mse 1.2042176978042078\n",
      "New best model found at epoch 209 with validation loss 1.2042176723480225\n",
      "Starting Epoch 210\n",
      "1.2161214040673298\n",
      "Validation loss: 1.2032244205474854\n",
      "mse 1.2032244168152197\n",
      "New best model found at epoch 210 with validation loss 1.2032244205474854\n",
      "Starting Epoch 211\n",
      "1.2153118926545847\n",
      "Validation loss: 1.2024333477020264\n",
      "mse 1.2024332596536071\n",
      "New best model found at epoch 211 with validation loss 1.2024333477020264\n",
      "Starting Epoch 212\n",
      "1.2145171761512756\n",
      "Validation loss: 1.2015384435653687\n",
      "mse 1.2015382806612198\n",
      "New best model found at epoch 212 with validation loss 1.2015384435653687\n",
      "Starting Epoch 213\n",
      "1.2138647177945012\n",
      "Validation loss: 1.1997804641723633\n",
      "mse 1.1997804356900794\n",
      "New best model found at epoch 213 with validation loss 1.1997804641723633\n",
      "Starting Epoch 214\n",
      "1.2131317076475725\n",
      "Validation loss: 1.1983774900436401\n",
      "mse 1.1983774043262216\n",
      "New best model found at epoch 214 with validation loss 1.1983774900436401\n",
      "Starting Epoch 215\n",
      "1.2122891286145085\n",
      "Validation loss: 1.1977909803390503\n",
      "mse 1.1977910184545815\n",
      "New best model found at epoch 215 with validation loss 1.1977909803390503\n",
      "Starting Epoch 216\n",
      "1.2116000108096912\n",
      "Validation loss: 1.1964141130447388\n",
      "mse 1.1964140162978751\n",
      "New best model found at epoch 216 with validation loss 1.1964141130447388\n",
      "Starting Epoch 217\n",
      "1.2107891673627107\n",
      "Validation loss: 1.1956607103347778\n",
      "mse 1.1956605876110762\n",
      "New best model found at epoch 217 with validation loss 1.1956607103347778\n",
      "Starting Epoch 218\n",
      "1.2101322671641475\n",
      "Validation loss: 1.1946375370025635\n",
      "mse 1.1946376227536684\n",
      "New best model found at epoch 218 with validation loss 1.1946375370025635\n",
      "Starting Epoch 219\n",
      "1.2093228775521982\n",
      "Validation loss: 1.1936606168746948\n",
      "mse 1.1936606637459315\n",
      "New best model found at epoch 219 with validation loss 1.1936606168746948\n",
      "Starting Epoch 220\n",
      "1.2085631308348284\n",
      "Validation loss: 1.192744255065918\n",
      "mse 1.1927442975384301\n",
      "New best model found at epoch 220 with validation loss 1.192744255065918\n",
      "Starting Epoch 221\n",
      "1.2078349331150884\n",
      "Validation loss: 1.1918646097183228\n",
      "mse 1.1918645455300758\n",
      "New best model found at epoch 221 with validation loss 1.1918646097183228\n",
      "Starting Epoch 222\n",
      "1.2071008397185283\n",
      "Validation loss: 1.1910547018051147\n",
      "mse 1.191054678109591\n",
      "New best model found at epoch 222 with validation loss 1.1910547018051147\n",
      "Starting Epoch 223\n",
      "1.2064823534177698\n",
      "Validation loss: 1.1901700496673584\n",
      "mse 1.1901700500043968\n",
      "New best model found at epoch 223 with validation loss 1.1901700496673584\n",
      "Starting Epoch 224\n",
      "1.205760377904643\n",
      "Validation loss: 1.1892832517623901\n",
      "mse 1.1892832087431966\n",
      "New best model found at epoch 224 with validation loss 1.1892832517623901\n",
      "Starting Epoch 225\n",
      "1.2051477846891985\n",
      "Validation loss: 1.1881108283996582\n",
      "mse 1.1881108788858419\n",
      "New best model found at epoch 225 with validation loss 1.1881108283996582\n",
      "Starting Epoch 226\n",
      "1.2043565563533618\n",
      "Validation loss: 1.1872714757919312\n",
      "mse 1.1872715083993544\n",
      "New best model found at epoch 226 with validation loss 1.1872714757919312\n",
      "Starting Epoch 227\n",
      "1.2037018744841865\n",
      "Validation loss: 1.1865887641906738\n",
      "mse 1.1865886964910901\n",
      "New best model found at epoch 227 with validation loss 1.1865887641906738\n",
      "Starting Epoch 228\n",
      "1.203099831290867\n",
      "Validation loss: 1.1856460571289062\n",
      "mse 1.1856460609145592\n",
      "New best model found at epoch 228 with validation loss 1.1856460571289062\n",
      "Starting Epoch 229\n",
      "1.202403345833654\n",
      "Validation loss: 1.1844570636749268\n",
      "mse 1.1844571632586296\n",
      "New best model found at epoch 229 with validation loss 1.1844570636749268\n",
      "Starting Epoch 230\n",
      "1.2017219895901887\n",
      "Validation loss: 1.1838843822479248\n",
      "mse 1.1838844180667967\n",
      "New best model found at epoch 230 with validation loss 1.1838843822479248\n",
      "Starting Epoch 231\n",
      "1.2011056827462239\n",
      "Validation loss: 1.1827847957611084\n",
      "mse 1.182784801080867\n",
      "New best model found at epoch 231 with validation loss 1.1827847957611084\n",
      "Starting Epoch 232\n",
      "1.200451830159063\n",
      "Validation loss: 1.1818848848342896\n",
      "mse 1.1818848522948353\n",
      "New best model found at epoch 232 with validation loss 1.1818848848342896\n",
      "Starting Epoch 233\n",
      "1.1998823207357656\n",
      "Validation loss: 1.181139349937439\n",
      "mse 1.1811394305924818\n",
      "New best model found at epoch 233 with validation loss 1.181139349937439\n",
      "Starting Epoch 234\n",
      "1.199237030485402\n",
      "Validation loss: 1.180182933807373\n",
      "mse 1.1801830444211743\n",
      "New best model found at epoch 234 with validation loss 1.180182933807373\n",
      "Starting Epoch 235\n",
      "1.198599258194799\n",
      "Validation loss: 1.179401159286499\n",
      "mse 1.1794010695112123\n",
      "New best model found at epoch 235 with validation loss 1.179401159286499\n",
      "Starting Epoch 236\n",
      "1.198019978792771\n",
      "Validation loss: 1.1784580945968628\n",
      "mse 1.1784581077932\n",
      "New best model found at epoch 236 with validation loss 1.1784580945968628\n",
      "Starting Epoch 237\n",
      "1.1973856480225273\n",
      "Validation loss: 1.1775438785552979\n",
      "mse 1.1775438359517223\n",
      "New best model found at epoch 237 with validation loss 1.1775438785552979\n",
      "Starting Epoch 238\n",
      "1.1967605559722236\n",
      "Validation loss: 1.1766988039016724\n",
      "mse 1.1766988870869306\n",
      "New best model found at epoch 238 with validation loss 1.1766988039016724\n",
      "Starting Epoch 239\n",
      "1.1962002075236777\n",
      "Validation loss: 1.1758930683135986\n",
      "mse 1.1758930300590833\n",
      "New best model found at epoch 239 with validation loss 1.1758930683135986\n",
      "Starting Epoch 240\n",
      "1.1955744909203572\n",
      "Validation loss: 1.1750158071517944\n",
      "mse 1.1750159113714593\n",
      "New best model found at epoch 240 with validation loss 1.1750158071517944\n",
      "Starting Epoch 241\n",
      "1.1949937265852224\n",
      "Validation loss: 1.174296498298645\n",
      "mse 1.1742964710491444\n",
      "New best model found at epoch 241 with validation loss 1.174296498298645\n",
      "Starting Epoch 242\n",
      "1.1944309058396712\n",
      "Validation loss: 1.1733155250549316\n",
      "mse 1.173315493922019\n",
      "New best model found at epoch 242 with validation loss 1.1733155250549316\n",
      "Starting Epoch 243\n",
      "1.1938328302424888\n",
      "Validation loss: 1.1724207401275635\n",
      "mse 1.1724207138214042\n",
      "New best model found at epoch 243 with validation loss 1.1724207401275635\n",
      "Starting Epoch 244\n",
      "1.1932449003924495\n",
      "Validation loss: 1.1715673208236694\n",
      "mse 1.1715671991755787\n",
      "New best model found at epoch 244 with validation loss 1.1715673208236694\n",
      "Starting Epoch 245\n",
      "1.1926520233568938\n",
      "Validation loss: 1.170710802078247\n",
      "mse 1.1707107768970486\n",
      "New best model found at epoch 245 with validation loss 1.170710802078247\n",
      "Starting Epoch 246\n",
      "1.1920220152191494\n",
      "Validation loss: 1.169930100440979\n",
      "mse 1.1699301771519586\n",
      "New best model found at epoch 246 with validation loss 1.169930100440979\n",
      "Starting Epoch 247\n",
      "1.1914179972980334\n",
      "Validation loss: 1.1691384315490723\n",
      "mse 1.169138570904046\n",
      "New best model found at epoch 247 with validation loss 1.1691384315490723\n",
      "Starting Epoch 248\n",
      "1.1909195184707642\n",
      "Validation loss: 1.1683971881866455\n",
      "mse 1.1683971092846475\n",
      "New best model found at epoch 248 with validation loss 1.1683971881866455\n",
      "Starting Epoch 249\n",
      "1.1903482831042747\n",
      "Validation loss: 1.1677088737487793\n",
      "mse 1.1677089361014406\n",
      "New best model found at epoch 249 with validation loss 1.1677088737487793\n",
      "Starting Epoch 250\n",
      "1.1898532380228457\n",
      "Validation loss: 1.1668838262557983\n",
      "mse 1.1668838390161795\n",
      "New best model found at epoch 250 with validation loss 1.1668838262557983\n",
      "Starting Epoch 251\n",
      "1.189266386239425\n",
      "Validation loss: 1.1660419702529907\n",
      "mse 1.1660420869040715\n",
      "New best model found at epoch 251 with validation loss 1.1660419702529907\n",
      "Starting Epoch 252\n",
      "1.188698841177899\n",
      "Validation loss: 1.165193796157837\n",
      "mse 1.1651937636985001\n",
      "New best model found at epoch 252 with validation loss 1.165193796157837\n",
      "Starting Epoch 253\n",
      "1.188239680684131\n",
      "Validation loss: 1.164520502090454\n",
      "mse 1.164520450860685\n",
      "New best model found at epoch 253 with validation loss 1.164520502090454\n",
      "Starting Epoch 254\n",
      "1.187646316445392\n",
      "Validation loss: 1.1639615297317505\n",
      "mse 1.1639615935538083\n",
      "New best model found at epoch 254 with validation loss 1.1639615297317505\n",
      "Starting Epoch 255\n",
      "1.1870403289794922\n",
      "Validation loss: 1.163032054901123\n",
      "mse 1.1630320345438916\n",
      "New best model found at epoch 255 with validation loss 1.163032054901123\n",
      "Starting Epoch 256\n",
      "1.1864619799282239\n",
      "Validation loss: 1.162268877029419\n",
      "mse 1.1622689886144977\n",
      "New best model found at epoch 256 with validation loss 1.162268877029419\n",
      "Starting Epoch 257\n",
      "1.185979444047679\n",
      "Validation loss: 1.1617333889007568\n",
      "mse 1.1617332749009943\n",
      "New best model found at epoch 257 with validation loss 1.1617333889007568\n",
      "Starting Epoch 258\n",
      "1.1856172862260237\n",
      "Validation loss: 1.1609009504318237\n",
      "mse 1.1609008797006681\n",
      "New best model found at epoch 258 with validation loss 1.1609009504318237\n",
      "Starting Epoch 259\n",
      "1.1849421133165774\n",
      "Validation loss: 1.1601946353912354\n",
      "mse 1.1601947188633979\n",
      "New best model found at epoch 259 with validation loss 1.1601946353912354\n",
      "Starting Epoch 260\n",
      "1.184457724509032\n",
      "Validation loss: 1.1594669818878174\n",
      "mse 1.1594669771118937\n",
      "New best model found at epoch 260 with validation loss 1.1594669818878174\n",
      "Starting Epoch 261\n",
      "1.1838228676630103\n",
      "Validation loss: 1.158914566040039\n",
      "mse 1.1589145586030254\n",
      "New best model found at epoch 261 with validation loss 1.158914566040039\n",
      "Starting Epoch 262\n",
      "1.183274103247601\n",
      "Validation loss: 1.1581956148147583\n",
      "mse 1.1581957582192774\n",
      "New best model found at epoch 262 with validation loss 1.1581956148147583\n",
      "Starting Epoch 263\n",
      "1.182869641677193\n",
      "Validation loss: 1.1575640439987183\n",
      "mse 1.1575639930436157\n",
      "New best model found at epoch 263 with validation loss 1.1575640439987183\n",
      "Starting Epoch 264\n",
      "1.1822687983512878\n",
      "Validation loss: 1.1569057703018188\n",
      "mse 1.156905818624855\n",
      "New best model found at epoch 264 with validation loss 1.1569057703018188\n",
      "Starting Epoch 265\n",
      "1.1818655729293823\n",
      "Validation loss: 1.156140923500061\n",
      "mse 1.1561409038818367\n",
      "New best model found at epoch 265 with validation loss 1.156140923500061\n",
      "Starting Epoch 266\n",
      "1.1812904891760454\n",
      "Validation loss: 1.155430793762207\n",
      "mse 1.1554307438444937\n",
      "New best model found at epoch 266 with validation loss 1.155430793762207\n",
      "Starting Epoch 267\n",
      "1.1808279156684875\n",
      "Validation loss: 1.1547706127166748\n",
      "mse 1.1547707595189602\n",
      "New best model found at epoch 267 with validation loss 1.1547706127166748\n",
      "Starting Epoch 268\n",
      "1.1803251815878826\n",
      "Validation loss: 1.1542588472366333\n",
      "mse 1.154258882633598\n",
      "New best model found at epoch 268 with validation loss 1.1542588472366333\n",
      "Starting Epoch 269\n",
      "1.1798014018846594\n",
      "Validation loss: 1.1536484956741333\n",
      "mse 1.1536485573247786\n",
      "New best model found at epoch 269 with validation loss 1.1536484956741333\n",
      "Starting Epoch 270\n",
      "1.1793399790058965\n",
      "Validation loss: 1.1527806520462036\n",
      "mse 1.152780635686445\n",
      "New best model found at epoch 270 with validation loss 1.1527806520462036\n",
      "Starting Epoch 271\n",
      "1.1788236084191694\n",
      "Validation loss: 1.1521815061569214\n",
      "mse 1.1521815136836795\n",
      "New best model found at epoch 271 with validation loss 1.1521815061569214\n",
      "Starting Epoch 272\n",
      "1.1783208665640459\n",
      "Validation loss: 1.1515229940414429\n",
      "mse 1.151522979319247\n",
      "New best model found at epoch 272 with validation loss 1.1515229940414429\n",
      "Starting Epoch 273\n",
      "1.1777447876722917\n",
      "Validation loss: 1.1508651971817017\n",
      "mse 1.1508653438169543\n",
      "New best model found at epoch 273 with validation loss 1.1508651971817017\n",
      "Starting Epoch 274\n",
      "1.1773813366889954\n",
      "Validation loss: 1.1501394510269165\n",
      "mse 1.1501394054009504\n",
      "New best model found at epoch 274 with validation loss 1.1501394510269165\n",
      "Starting Epoch 275\n",
      "1.1768025341241255\n",
      "Validation loss: 1.1494807004928589\n",
      "mse 1.1494807377879463\n",
      "New best model found at epoch 275 with validation loss 1.1494807004928589\n",
      "Starting Epoch 276\n",
      "1.1763814532238503\n",
      "Validation loss: 1.1489921808242798\n",
      "mse 1.1489922336207163\n",
      "New best model found at epoch 276 with validation loss 1.1489921808242798\n",
      "Starting Epoch 277\n",
      "1.175818629886793\n",
      "Validation loss: 1.1482508182525635\n",
      "mse 1.148250805164797\n",
      "New best model found at epoch 277 with validation loss 1.1482508182525635\n",
      "Starting Epoch 278\n",
      "1.1753462578939355\n",
      "Validation loss: 1.1477255821228027\n",
      "mse 1.1477255121899452\n",
      "New best model found at epoch 278 with validation loss 1.1477255821228027\n",
      "Starting Epoch 279\n",
      "1.1748984352402065\n",
      "Validation loss: 1.1471176147460938\n",
      "mse 1.147117733483936\n",
      "New best model found at epoch 279 with validation loss 1.1471176147460938\n",
      "Starting Epoch 280\n",
      "1.1744500450465991\n",
      "Validation loss: 1.1462458372116089\n",
      "mse 1.146245812941402\n",
      "New best model found at epoch 280 with validation loss 1.1462458372116089\n",
      "Starting Epoch 281\n",
      "1.1739294658536497\n",
      "Validation loss: 1.1456067562103271\n",
      "mse 1.1456068868186349\n",
      "New best model found at epoch 281 with validation loss 1.1456067562103271\n",
      "Starting Epoch 282\n",
      "1.1734569202298704\n",
      "Validation loss: 1.144897222518921\n",
      "mse 1.1448972304477536\n",
      "New best model found at epoch 282 with validation loss 1.144897222518921\n",
      "Starting Epoch 283\n",
      "1.1730139255523682\n",
      "Validation loss: 1.1442582607269287\n",
      "mse 1.1442583292554833\n",
      "New best model found at epoch 283 with validation loss 1.1442582607269287\n",
      "Starting Epoch 284\n",
      "1.1725181418916453\n",
      "Validation loss: 1.1436954736709595\n",
      "mse 1.1436954810783326\n",
      "New best model found at epoch 284 with validation loss 1.1436954736709595\n",
      "Starting Epoch 285\n",
      "1.1720459953598354\n",
      "Validation loss: 1.14301598072052\n",
      "mse 1.143015974436307\n",
      "New best model found at epoch 285 with validation loss 1.14301598072052\n",
      "Starting Epoch 286\n",
      "1.1716021506682686\n",
      "Validation loss: 1.1424167156219482\n",
      "mse 1.1424167669737064\n",
      "New best model found at epoch 286 with validation loss 1.1424167156219482\n",
      "Starting Epoch 287\n",
      "1.1711339898731397\n",
      "Validation loss: 1.141752004623413\n",
      "mse 1.1417520256861418\n",
      "New best model found at epoch 287 with validation loss 1.141752004623413\n",
      "Starting Epoch 288\n",
      "1.1707107424736023\n",
      "Validation loss: 1.1411442756652832\n",
      "mse 1.141144193862547\n",
      "New best model found at epoch 288 with validation loss 1.1411442756652832\n",
      "Starting Epoch 289\n",
      "1.170169876969379\n",
      "Validation loss: 1.1406723260879517\n",
      "mse 1.1406722938570784\n",
      "New best model found at epoch 289 with validation loss 1.1406723260879517\n",
      "Starting Epoch 290\n",
      "1.1696762883144876\n",
      "Validation loss: 1.1399754285812378\n",
      "mse 1.139975423135223\n",
      "New best model found at epoch 290 with validation loss 1.1399754285812378\n",
      "Starting Epoch 291\n",
      "1.169284621010656\n",
      "Validation loss: 1.1393396854400635\n",
      "mse 1.1393397464814101\n",
      "New best model found at epoch 291 with validation loss 1.1393396854400635\n",
      "Starting Epoch 292\n",
      "1.1687248323274695\n",
      "Validation loss: 1.138787865638733\n",
      "mse 1.1387879721484218\n",
      "New best model found at epoch 292 with validation loss 1.138787865638733\n",
      "Starting Epoch 293\n",
      "1.1682625905327175\n",
      "Validation loss: 1.1381778717041016\n",
      "mse 1.1381778837187917\n",
      "New best model found at epoch 293 with validation loss 1.1381778717041016\n",
      "Starting Epoch 294\n",
      "1.1678200882414114\n",
      "Validation loss: 1.137434720993042\n",
      "mse 1.1374347133015559\n",
      "New best model found at epoch 294 with validation loss 1.137434720993042\n",
      "Starting Epoch 295\n",
      "1.1673298581786777\n",
      "Validation loss: 1.1367264986038208\n",
      "mse 1.1367265858118738\n",
      "New best model found at epoch 295 with validation loss 1.1367264986038208\n",
      "Starting Epoch 296\n",
      "1.1668858424476956\n",
      "Validation loss: 1.1361764669418335\n",
      "mse 1.1361765136400057\n",
      "New best model found at epoch 296 with validation loss 1.1361764669418335\n",
      "Starting Epoch 297\n",
      "1.1664171970408896\n",
      "Validation loss: 1.135422945022583\n",
      "mse 1.1354229019428237\n",
      "New best model found at epoch 297 with validation loss 1.135422945022583\n",
      "Starting Epoch 298\n",
      "1.165931338849275\n",
      "Validation loss: 1.1349633932113647\n",
      "mse 1.134963377681109\n",
      "New best model found at epoch 298 with validation loss 1.1349633932113647\n",
      "Starting Epoch 299\n",
      "1.165476029333861\n",
      "Validation loss: 1.1343960762023926\n",
      "mse 1.134395951471122\n",
      "New best model found at epoch 299 with validation loss 1.1343960762023926\n",
      "Starting Epoch 300\n",
      "1.1649666584056357\n",
      "Validation loss: 1.1339646577835083\n",
      "mse 1.1339647154560037\n",
      "New best model found at epoch 300 with validation loss 1.1339646577835083\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "MLP_regression(X_train, y1_diff_log_train, X_val, y1_diff_log_val, \"MLP, custom: 7-60-40-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "9fcd7ca8-4a6c-4b15-8884-35ceb37ad39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.587345</td>\n",
       "      <td>0.486148</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.480216</td>\n",
       "      <td>0.79731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.490544</td>\n",
       "      <td>0.447684</td>\n",
       "      <td>0.827719</td>\n",
       "      <td>0.591385</td>\n",
       "      <td>0.455429</td>\n",
       "      <td>0.812813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.489989</td>\n",
       "      <td>0.448514</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.573214</td>\n",
       "      <td>0.453536</td>\n",
       "      <td>0.818565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>1.696579</td>\n",
       "      <td>0.788013</td>\n",
       "      <td>0.404154</td>\n",
       "      <td>1.859457</td>\n",
       "      <td>0.828425</td>\n",
       "      <td>0.411439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.741289</td>\n",
       "      <td>0.752971</td>\n",
       "      <td>0.388452</td>\n",
       "      <td>1.829105</td>\n",
       "      <td>0.784481</td>\n",
       "      <td>0.421047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.618412</td>\n",
       "      <td>0.724068</td>\n",
       "      <td>0.431607</td>\n",
       "      <td>1.792327</td>\n",
       "      <td>0.772814</td>\n",
       "      <td>0.432687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-1</th>\n",
       "      <td>1.505071</td>\n",
       "      <td>0.867196</td>\n",
       "      <td>0.471413</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-1</th>\n",
       "      <td>1.554706</td>\n",
       "      <td>0.867515</td>\n",
       "      <td>0.453981</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-1</th>\n",
       "      <td>1.451219</td>\n",
       "      <td>0.828152</td>\n",
       "      <td>0.490326</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-1</th>\n",
       "      <td>1.472163</td>\n",
       "      <td>0.836597</td>\n",
       "      <td>0.482970</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-1</th>\n",
       "      <td>1.444209</td>\n",
       "      <td>0.820480</td>\n",
       "      <td>0.492788</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-1</th>\n",
       "      <td>1.411537</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.504262</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-1</th>\n",
       "      <td>1.400415</td>\n",
       "      <td>0.823216</td>\n",
       "      <td>0.508168</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-1</th>\n",
       "      <td>1.345054</td>\n",
       "      <td>0.802008</td>\n",
       "      <td>0.527611</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-1</th>\n",
       "      <td>1.263771</td>\n",
       "      <td>0.772361</td>\n",
       "      <td>0.556158</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-1</th>\n",
       "      <td>1.388075</td>\n",
       "      <td>0.811131</td>\n",
       "      <td>0.512502</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-1</th>\n",
       "      <td>1.009602</td>\n",
       "      <td>0.684272</td>\n",
       "      <td>0.645424</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-1</th>\n",
       "      <td>1.124673</td>\n",
       "      <td>0.718425</td>\n",
       "      <td>0.605010</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-1</th>\n",
       "      <td>1.027500</td>\n",
       "      <td>0.670468</td>\n",
       "      <td>0.639138</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-60-40-1</th>\n",
       "      <td>1.431023</td>\n",
       "      <td>0.786463</td>\n",
       "      <td>0.497419</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-60-40-1</th>\n",
       "      <td>1.403210</td>\n",
       "      <td>0.783605</td>\n",
       "      <td>0.507187</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-60-40-1</th>\n",
       "      <td>1.534875</td>\n",
       "      <td>0.822353</td>\n",
       "      <td>0.460945</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-60-40-1</th>\n",
       "      <td>1.253040</td>\n",
       "      <td>0.759482</td>\n",
       "      <td>0.559927</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-60-40-1</th>\n",
       "      <td>1.458630</td>\n",
       "      <td>0.796491</td>\n",
       "      <td>0.487723</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-60-40-1</th>\n",
       "      <td>1.399672</td>\n",
       "      <td>0.788665</td>\n",
       "      <td>0.508429</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-60-40-1</th>\n",
       "      <td>1.133965</td>\n",
       "      <td>0.721711</td>\n",
       "      <td>0.601747</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   MSE       MAE        R2       MSE  \\\n",
       "5-NN                          0.587345  0.486148  0.793722  0.640365   \n",
       "Decision tree                 0.490544  0.447684  0.827719  0.591385   \n",
       "Random forest                 0.489989  0.448514  0.827914  0.573214   \n",
       "SVM linear                    1.696579  0.788013  0.404154  1.859457   \n",
       "SVM poly                      1.741289  0.752971  0.388452  1.829105   \n",
       "SVM rbf                       1.618412  0.724068  0.431607  1.792327   \n",
       "MLP: 17-5-1                   1.505071  0.867196  0.471413         -   \n",
       "MLP: 17-10-1                  1.554706  0.867515  0.453981         -   \n",
       "MLP: 17-20-1                  1.451219  0.828152  0.490326         -   \n",
       "MLP: 17-25-1                  1.472163  0.836597  0.482970         -   \n",
       "MLP: 17-40-1                  1.444209  0.820480  0.492788         -   \n",
       "MLP: 17-60-1                  1.411537  0.821209  0.504262         -   \n",
       "MLP: 17-10-5-1                1.400415  0.823216  0.508168         -   \n",
       "MLP: 17-20-10-1               1.345054  0.802008  0.527611         -   \n",
       "MLP: 17-40-20-1               1.263771  0.772361  0.556158         -   \n",
       "MLP: 17-40-10-1               1.388075  0.811131  0.512502         -   \n",
       "MLP: 17-60-40-1               1.009602  0.684272  0.645424         -   \n",
       "MLP: 17-60-20-1               1.124673  0.718425  0.605010         -   \n",
       "MLP: 17-80-50-1               1.027500  0.670468  0.639138         -   \n",
       "MLP, small-median: 7-60-40-1  1.431023  0.786463  0.497419         -   \n",
       "MLP, small-mean: 7-60-40-1    1.403210  0.783605  0.507187         -   \n",
       "MLP, small-min: 7-60-40-1     1.534875  0.822353  0.460945         -   \n",
       "MLP, small-max: 7-60-40-1     1.253040  0.759482  0.559927         -   \n",
       "MLP, small-q25: 7-60-40-1     1.458630  0.796491  0.487723         -   \n",
       "MLP, small-q75: 7-60-40-1     1.399672  0.788665  0.508429         -   \n",
       "MLP, custom: 7-60-40-1        1.133965  0.721711  0.601747         -   \n",
       "\n",
       "                                   MAE        R2  \n",
       "5-NN                          0.480216   0.79731  \n",
       "Decision tree                 0.455429  0.812813  \n",
       "Random forest                 0.453536  0.818565  \n",
       "SVM linear                    0.828425  0.411439  \n",
       "SVM poly                      0.784481  0.421047  \n",
       "SVM rbf                       0.772814  0.432687  \n",
       "MLP: 17-5-1                          -         -  \n",
       "MLP: 17-10-1                         -         -  \n",
       "MLP: 17-20-1                         -         -  \n",
       "MLP: 17-25-1                         -         -  \n",
       "MLP: 17-40-1                         -         -  \n",
       "MLP: 17-60-1                         -         -  \n",
       "MLP: 17-10-5-1                       -         -  \n",
       "MLP: 17-20-10-1                      -         -  \n",
       "MLP: 17-40-20-1                      -         -  \n",
       "MLP: 17-40-10-1                      -         -  \n",
       "MLP: 17-60-40-1                      -         -  \n",
       "MLP: 17-60-20-1                      -         -  \n",
       "MLP: 17-80-50-1                      -         -  \n",
       "MLP, small-median: 7-60-40-1         -         -  \n",
       "MLP, small-mean: 7-60-40-1           -         -  \n",
       "MLP, small-min: 7-60-40-1            -         -  \n",
       "MLP, small-max: 7-60-40-1            -         -  \n",
       "MLP, small-q25: 7-60-40-1            -         -  \n",
       "MLP, small-q75: 7-60-40-1            -         -  \n",
       "MLP, custom: 7-60-40-1               -         -  "
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "2e205ea9-b8ef-4a5e-95e5-94aef09edaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2_classes.to_csv('results/table_2_classes_SPA_rounded.csv', index=True)\n",
    "table_3_classes.to_csv('results/table_3_classes_SPA_rounded.csv', index=True)\n",
    "table_time_diff.to_csv('results/table_time_diff_SPA_rounded.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17693281-4753-4a5d-abde-cf2ed5eae98a",
   "metadata": {},
   "source": [
    "### HGNN (Hypergraph neural network) with two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d80d00f-95a8-400e-ae6f-816fcfc0b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, label_series, hypergraph_column_name):\n",
    "        # Extract features and convert to tensor\n",
    "        self.X = torch.from_numpy(dataframe.drop(columns=[hypergraph_column_name]).values).float()\n",
    "        \n",
    "        # Extract labels and convert to tensor\n",
    "        self.y = torch.from_numpy(label_series.values).float()\n",
    "        \n",
    "        # Store hypergraph objects\n",
    "        self.hypergraphs = dataframe[hypergraph_column_name].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.X[index],\n",
    "            'label': self.y[index],\n",
    "            'hypergraph': self.hypergraphs[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363bf22d-cb81-4b98-9da2-e6eb03d5a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HGNN_classification(X_training, y_training, X_validation, y_validation, type, text):\n",
    "    model = HGNN(random_seed = 20)  \n",
    "\n",
    "    dataset = CustomDataset(X_training, y_training, hypergraph_column_name='hypergraph')\n",
    "    validation = CustomDataset(X_validation, y_validation, hypergraph_column_name='hypergraph')\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for item in dataset:\n",
    "            optimizer.zero_grad()\n",
    "            input_features = item[\"data\"]\n",
    "            input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "            label = item[\"label\"].long()\n",
    "            output = model(input_hg)\n",
    "            \n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataset):.4f}')\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for item in validation:\n",
    "                input_features = item[\"data\"]\n",
    "                input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "                label = item[\"label\"].long()\n",
    "                output = model(input_hg)\n",
    "                loss = loss_function(output, label)\n",
    "                val_loss += loss.item()\n",
    "    \n",
    "        val_loss /= len(validation)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "        # Save the model if the validation loss is the best we've seen so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Saved the best model with validation loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for item in validation:\n",
    "            i += 1\n",
    "            output = model(item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0))\n",
    "            _, pred = torch.max(output.data, 0)\n",
    "            predicted.append(pred.item())\n",
    "\n",
    "    if type == \"2_class\":\n",
    "        accuracy = accuracy_score(y_validation, predicted)\n",
    "        recall = recall_score(y_validation, predicted)\n",
    "        conf_matrix = confusion_matrix(y_validation, predicted)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_2_classes.loc[text] = [accuracy, recall, \"-\", \"-\"]\n",
    "\n",
    "    if type == \"3_class\":\n",
    "        accuracy = accuracy_score(y_validation, predicted)\n",
    "        recall_micro = recall_score(y_validation, predicted, average='micro')\n",
    "        recall_macro = recall_score(y_validation, predicted, average='macro')\n",
    "        conf_matrix = confusion_matrix(y_validation, predicted)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_3_classes.loc[text] = [accuracy, recall_micro, recall_macro, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e7baad-8a1f-4c5f-9ca2-168c73140bf7",
   "metadata": {},
   "source": [
    "*  Loss: Cross-Entropy\n",
    "*  Epochs: 100 (saving best model)\n",
    "*  Leaning rate: 0.001\n",
    "*  Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd033f26-cc33-4e57-9843-78c03fc96e33",
   "metadata": {},
   "source": [
    "##### HGNN: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 16 - 32 - 2, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "fa0d74ce-89ee-4362-878a-6f6c491f7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "238ce285-3783-425e-b0a5-a2b56dad9627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5795\n",
      "Validation Loss: 0.4627\n",
      "Saved the best model with validation loss: 0.4627\n",
      "Epoch [2/100], Loss: 0.4556\n",
      "Validation Loss: 0.4188\n",
      "Saved the best model with validation loss: 0.4188\n",
      "Epoch [3/100], Loss: 0.4267\n",
      "Validation Loss: 0.3979\n",
      "Saved the best model with validation loss: 0.3979\n",
      "Epoch [4/100], Loss: 0.4117\n",
      "Validation Loss: 0.3857\n",
      "Saved the best model with validation loss: 0.3857\n",
      "Epoch [5/100], Loss: 0.4020\n",
      "Validation Loss: 0.3813\n",
      "Saved the best model with validation loss: 0.3813\n",
      "Epoch [6/100], Loss: 0.3956\n",
      "Validation Loss: 0.3739\n",
      "Saved the best model with validation loss: 0.3739\n",
      "Epoch [7/100], Loss: 0.3909\n",
      "Validation Loss: 0.3681\n",
      "Saved the best model with validation loss: 0.3681\n",
      "Epoch [8/100], Loss: 0.3877\n",
      "Validation Loss: 0.3660\n",
      "Saved the best model with validation loss: 0.3660\n",
      "Epoch [9/100], Loss: 0.3854\n",
      "Validation Loss: 0.3640\n",
      "Saved the best model with validation loss: 0.3640\n",
      "Epoch [10/100], Loss: 0.3826\n",
      "Validation Loss: 0.3600\n",
      "Saved the best model with validation loss: 0.3600\n",
      "Epoch [11/100], Loss: 0.3809\n",
      "Validation Loss: 0.3559\n",
      "Saved the best model with validation loss: 0.3559\n",
      "Epoch [12/100], Loss: 0.3786\n",
      "Validation Loss: 0.3572\n",
      "Epoch [13/100], Loss: 0.3772\n",
      "Validation Loss: 0.3594\n",
      "Epoch [14/100], Loss: 0.3762\n",
      "Validation Loss: 0.3633\n",
      "Epoch [15/100], Loss: 0.3748\n",
      "Validation Loss: 0.3622\n",
      "Epoch [16/100], Loss: 0.3741\n",
      "Validation Loss: 0.3600\n",
      "Epoch [17/100], Loss: 0.3731\n",
      "Validation Loss: 0.3583\n",
      "Epoch [18/100], Loss: 0.3720\n",
      "Validation Loss: 0.3572\n",
      "Epoch [19/100], Loss: 0.3719\n",
      "Validation Loss: 0.3564\n",
      "Epoch [20/100], Loss: 0.3705\n",
      "Validation Loss: 0.3541\n",
      "Saved the best model with validation loss: 0.3541\n",
      "Epoch [21/100], Loss: 0.3706\n",
      "Validation Loss: 0.3534\n",
      "Saved the best model with validation loss: 0.3534\n",
      "Epoch [22/100], Loss: 0.3688\n",
      "Validation Loss: 0.3533\n",
      "Saved the best model with validation loss: 0.3533\n",
      "Epoch [23/100], Loss: 0.3678\n",
      "Validation Loss: 0.3529\n",
      "Saved the best model with validation loss: 0.3529\n",
      "Epoch [24/100], Loss: 0.3684\n",
      "Validation Loss: 0.3527\n",
      "Saved the best model with validation loss: 0.3527\n",
      "Epoch [25/100], Loss: 0.3676\n",
      "Validation Loss: 0.3517\n",
      "Saved the best model with validation loss: 0.3517\n",
      "Epoch [26/100], Loss: 0.3672\n",
      "Validation Loss: 0.3518\n",
      "Epoch [27/100], Loss: 0.3667\n",
      "Validation Loss: 0.3508\n",
      "Saved the best model with validation loss: 0.3508\n",
      "Epoch [28/100], Loss: 0.3666\n",
      "Validation Loss: 0.3521\n",
      "Epoch [29/100], Loss: 0.3651\n",
      "Validation Loss: 0.3551\n",
      "Epoch [30/100], Loss: 0.3661\n",
      "Validation Loss: 0.3519\n",
      "Epoch [31/100], Loss: 0.3641\n",
      "Validation Loss: 0.3567\n",
      "Epoch [32/100], Loss: 0.3646\n",
      "Validation Loss: 0.3508\n",
      "Epoch [33/100], Loss: 0.3642\n",
      "Validation Loss: 0.3526\n",
      "Epoch [34/100], Loss: 0.3635\n",
      "Validation Loss: 0.3518\n",
      "Epoch [35/100], Loss: 0.3641\n",
      "Validation Loss: 0.3553\n",
      "Epoch [36/100], Loss: 0.3646\n",
      "Validation Loss: 0.3564\n",
      "Epoch [37/100], Loss: 0.3647\n",
      "Validation Loss: 0.3574\n",
      "Epoch [38/100], Loss: 0.3646\n",
      "Validation Loss: 0.3563\n",
      "Epoch [39/100], Loss: 0.3634\n",
      "Validation Loss: 0.3598\n",
      "Epoch [40/100], Loss: 0.3632\n",
      "Validation Loss: 0.3593\n",
      "Epoch [41/100], Loss: 0.3630\n",
      "Validation Loss: 0.3618\n",
      "Epoch [42/100], Loss: 0.3641\n",
      "Validation Loss: 0.3597\n",
      "Epoch [43/100], Loss: 0.3624\n",
      "Validation Loss: 0.3581\n",
      "Epoch [44/100], Loss: 0.3630\n",
      "Validation Loss: 0.3572\n",
      "Epoch [45/100], Loss: 0.3622\n",
      "Validation Loss: 0.3587\n",
      "Epoch [46/100], Loss: 0.3617\n",
      "Validation Loss: 0.3583\n",
      "Epoch [47/100], Loss: 0.3632\n",
      "Validation Loss: 0.3509\n",
      "Epoch [48/100], Loss: 0.3619\n",
      "Validation Loss: 0.3514\n",
      "Epoch [49/100], Loss: 0.3610\n",
      "Validation Loss: 0.3576\n",
      "Epoch [50/100], Loss: 0.3614\n",
      "Validation Loss: 0.3611\n",
      "Epoch [51/100], Loss: 0.3606\n",
      "Validation Loss: 0.3515\n",
      "Epoch [52/100], Loss: 0.3608\n",
      "Validation Loss: 0.3545\n",
      "Epoch [53/100], Loss: 0.3601\n",
      "Validation Loss: 0.3539\n",
      "Epoch [54/100], Loss: 0.3616\n",
      "Validation Loss: 0.3617\n",
      "Epoch [55/100], Loss: 0.3601\n",
      "Validation Loss: 0.3545\n",
      "Epoch [56/100], Loss: 0.3599\n",
      "Validation Loss: 0.3540\n",
      "Epoch [57/100], Loss: 0.3603\n",
      "Validation Loss: 0.3576\n",
      "Epoch [58/100], Loss: 0.3590\n",
      "Validation Loss: 0.3589\n",
      "Epoch [59/100], Loss: 0.3591\n",
      "Validation Loss: 0.3549\n",
      "Epoch [60/100], Loss: 0.3599\n",
      "Validation Loss: 0.3518\n",
      "Epoch [61/100], Loss: 0.3594\n",
      "Validation Loss: 0.3544\n",
      "Epoch [62/100], Loss: 0.3596\n",
      "Validation Loss: 0.3600\n",
      "Epoch [63/100], Loss: 0.3591\n",
      "Validation Loss: 0.3609\n",
      "Epoch [64/100], Loss: 0.3595\n",
      "Validation Loss: 0.3556\n",
      "Epoch [65/100], Loss: 0.3588\n",
      "Validation Loss: 0.3561\n",
      "Epoch [66/100], Loss: 0.3587\n",
      "Validation Loss: 0.3579\n",
      "Epoch [67/100], Loss: 0.3575\n",
      "Validation Loss: 0.3575\n",
      "Epoch [68/100], Loss: 0.3583\n",
      "Validation Loss: 0.3599\n",
      "Epoch [69/100], Loss: 0.3578\n",
      "Validation Loss: 0.3609\n",
      "Epoch [70/100], Loss: 0.3588\n",
      "Validation Loss: 0.3582\n",
      "Epoch [71/100], Loss: 0.3566\n",
      "Validation Loss: 0.3566\n",
      "Epoch [72/100], Loss: 0.3574\n",
      "Validation Loss: 0.3636\n",
      "Epoch [73/100], Loss: 0.3575\n",
      "Validation Loss: 0.3581\n",
      "Epoch [74/100], Loss: 0.3572\n",
      "Validation Loss: 0.3521\n",
      "Epoch [75/100], Loss: 0.3571\n",
      "Validation Loss: 0.3553\n",
      "Epoch [76/100], Loss: 0.3578\n",
      "Validation Loss: 0.3559\n",
      "Epoch [77/100], Loss: 0.3573\n",
      "Validation Loss: 0.3540\n",
      "Epoch [78/100], Loss: 0.3572\n",
      "Validation Loss: 0.3556\n",
      "Epoch [79/100], Loss: 0.3575\n",
      "Validation Loss: 0.3543\n",
      "Epoch [80/100], Loss: 0.3575\n",
      "Validation Loss: 0.3566\n",
      "Epoch [81/100], Loss: 0.3580\n",
      "Validation Loss: 0.3534\n",
      "Epoch [82/100], Loss: 0.3565\n",
      "Validation Loss: 0.3495\n",
      "Saved the best model with validation loss: 0.3495\n",
      "Epoch [83/100], Loss: 0.3560\n",
      "Validation Loss: 0.3538\n",
      "Epoch [84/100], Loss: 0.3566\n",
      "Validation Loss: 0.3519\n",
      "Epoch [85/100], Loss: 0.3555\n",
      "Validation Loss: 0.3547\n",
      "Epoch [86/100], Loss: 0.3554\n",
      "Validation Loss: 0.3556\n",
      "Epoch [87/100], Loss: 0.3549\n",
      "Validation Loss: 0.3551\n",
      "Epoch [88/100], Loss: 0.3556\n",
      "Validation Loss: 0.3551\n",
      "Epoch [89/100], Loss: 0.3555\n",
      "Validation Loss: 0.3560\n",
      "Epoch [90/100], Loss: 0.3550\n",
      "Validation Loss: 0.3558\n",
      "Epoch [91/100], Loss: 0.3543\n",
      "Validation Loss: 0.3559\n",
      "Epoch [92/100], Loss: 0.3547\n",
      "Validation Loss: 0.3559\n",
      "Epoch [93/100], Loss: 0.3545\n",
      "Validation Loss: 0.3565\n",
      "Epoch [94/100], Loss: 0.3544\n",
      "Validation Loss: 0.3558\n",
      "Epoch [95/100], Loss: 0.3547\n",
      "Validation Loss: 0.3526\n",
      "Epoch [96/100], Loss: 0.3548\n",
      "Validation Loss: 0.3536\n",
      "Epoch [97/100], Loss: 0.3538\n",
      "Validation Loss: 0.3541\n",
      "Epoch [98/100], Loss: 0.3554\n",
      "Validation Loss: 0.3488\n",
      "Saved the best model with validation loss: 0.3488\n",
      "Epoch [99/100], Loss: 0.3545\n",
      "Validation Loss: 0.3522\n",
      "Epoch [100/100], Loss: 0.3559\n",
      "Validation Loss: 0.3521\n"
     ]
    }
   ],
   "source": [
    "HGNN_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"HGNN: 1-16-32-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc52885-adb9-4b09-bb3e-cac269cac797",
   "metadata": {},
   "source": [
    "##### HGNN: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 16 - 2, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "d8330110-ec21-4387-8eae-ed78d699b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "eecd8159-7c65-4e70-b700-8e044bcb6419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5915\n",
      "Validation Loss: 0.4722\n",
      "Saved the best model with validation loss: 0.4722\n",
      "Epoch [2/100], Loss: 0.4740\n",
      "Validation Loss: 0.4314\n",
      "Saved the best model with validation loss: 0.4314\n",
      "Epoch [3/100], Loss: 0.4463\n",
      "Validation Loss: 0.4080\n",
      "Saved the best model with validation loss: 0.4080\n",
      "Epoch [4/100], Loss: 0.4287\n",
      "Validation Loss: 0.3938\n",
      "Saved the best model with validation loss: 0.3938\n",
      "Epoch [5/100], Loss: 0.4198\n",
      "Validation Loss: 0.3861\n",
      "Saved the best model with validation loss: 0.3861\n",
      "Epoch [6/100], Loss: 0.4116\n",
      "Validation Loss: 0.3778\n",
      "Saved the best model with validation loss: 0.3778\n",
      "Epoch [7/100], Loss: 0.4066\n",
      "Validation Loss: 0.3719\n",
      "Saved the best model with validation loss: 0.3719\n",
      "Epoch [8/100], Loss: 0.4012\n",
      "Validation Loss: 0.3670\n",
      "Saved the best model with validation loss: 0.3670\n",
      "Epoch [9/100], Loss: 0.3971\n",
      "Validation Loss: 0.3655\n",
      "Saved the best model with validation loss: 0.3655\n",
      "Epoch [10/100], Loss: 0.3950\n",
      "Validation Loss: 0.3594\n",
      "Saved the best model with validation loss: 0.3594\n",
      "Epoch [11/100], Loss: 0.3928\n",
      "Validation Loss: 0.3623\n",
      "Epoch [12/100], Loss: 0.3917\n",
      "Validation Loss: 0.3618\n",
      "Epoch [13/100], Loss: 0.3895\n",
      "Validation Loss: 0.3579\n",
      "Saved the best model with validation loss: 0.3579\n",
      "Epoch [14/100], Loss: 0.3889\n",
      "Validation Loss: 0.3617\n",
      "Epoch [15/100], Loss: 0.3882\n",
      "Validation Loss: 0.3598\n",
      "Epoch [16/100], Loss: 0.3871\n",
      "Validation Loss: 0.3566\n",
      "Saved the best model with validation loss: 0.3566\n",
      "Epoch [17/100], Loss: 0.3858\n",
      "Validation Loss: 0.3595\n",
      "Epoch [18/100], Loss: 0.3856\n",
      "Validation Loss: 0.3583\n",
      "Epoch [19/100], Loss: 0.3837\n",
      "Validation Loss: 0.3613\n",
      "Epoch [20/100], Loss: 0.3833\n",
      "Validation Loss: 0.3600\n",
      "Epoch [21/100], Loss: 0.3830\n",
      "Validation Loss: 0.3574\n",
      "Epoch [22/100], Loss: 0.3820\n",
      "Validation Loss: 0.3562\n",
      "Saved the best model with validation loss: 0.3562\n",
      "Epoch [23/100], Loss: 0.3815\n",
      "Validation Loss: 0.3587\n",
      "Epoch [24/100], Loss: 0.3805\n",
      "Validation Loss: 0.3548\n",
      "Saved the best model with validation loss: 0.3548\n",
      "Epoch [25/100], Loss: 0.3794\n",
      "Validation Loss: 0.3560\n",
      "Epoch [26/100], Loss: 0.3802\n",
      "Validation Loss: 0.3528\n",
      "Saved the best model with validation loss: 0.3528\n",
      "Epoch [27/100], Loss: 0.3789\n",
      "Validation Loss: 0.3554\n",
      "Epoch [28/100], Loss: 0.3791\n",
      "Validation Loss: 0.3577\n",
      "Epoch [29/100], Loss: 0.3784\n",
      "Validation Loss: 0.3562\n",
      "Epoch [30/100], Loss: 0.3789\n",
      "Validation Loss: 0.3552\n",
      "Epoch [31/100], Loss: 0.3776\n",
      "Validation Loss: 0.3591\n",
      "Epoch [32/100], Loss: 0.3781\n",
      "Validation Loss: 0.3587\n",
      "Epoch [33/100], Loss: 0.3763\n",
      "Validation Loss: 0.3578\n",
      "Epoch [34/100], Loss: 0.3775\n",
      "Validation Loss: 0.3585\n",
      "Epoch [35/100], Loss: 0.3771\n",
      "Validation Loss: 0.3552\n",
      "Epoch [36/100], Loss: 0.3773\n",
      "Validation Loss: 0.3572\n",
      "Epoch [37/100], Loss: 0.3754\n",
      "Validation Loss: 0.3551\n",
      "Epoch [38/100], Loss: 0.3756\n",
      "Validation Loss: 0.3567\n",
      "Epoch [39/100], Loss: 0.3748\n",
      "Validation Loss: 0.3606\n",
      "Epoch [40/100], Loss: 0.3744\n",
      "Validation Loss: 0.3595\n",
      "Epoch [41/100], Loss: 0.3749\n",
      "Validation Loss: 0.3566\n",
      "Epoch [42/100], Loss: 0.3740\n",
      "Validation Loss: 0.3558\n",
      "Epoch [43/100], Loss: 0.3732\n",
      "Validation Loss: 0.3548\n",
      "Epoch [44/100], Loss: 0.3735\n",
      "Validation Loss: 0.3560\n",
      "Epoch [45/100], Loss: 0.3726\n",
      "Validation Loss: 0.3599\n",
      "Epoch [46/100], Loss: 0.3731\n",
      "Validation Loss: 0.3566\n",
      "Epoch [47/100], Loss: 0.3739\n",
      "Validation Loss: 0.3543\n",
      "Epoch [48/100], Loss: 0.3721\n",
      "Validation Loss: 0.3606\n",
      "Epoch [49/100], Loss: 0.3726\n",
      "Validation Loss: 0.3567\n",
      "Epoch [50/100], Loss: 0.3726\n",
      "Validation Loss: 0.3568\n",
      "Epoch [51/100], Loss: 0.3727\n",
      "Validation Loss: 0.3571\n",
      "Epoch [52/100], Loss: 0.3720\n",
      "Validation Loss: 0.3581\n",
      "Epoch [53/100], Loss: 0.3726\n",
      "Validation Loss: 0.3596\n",
      "Epoch [54/100], Loss: 0.3732\n",
      "Validation Loss: 0.3572\n",
      "Epoch [55/100], Loss: 0.3718\n",
      "Validation Loss: 0.3577\n",
      "Epoch [56/100], Loss: 0.3721\n",
      "Validation Loss: 0.3563\n",
      "Epoch [57/100], Loss: 0.3725\n",
      "Validation Loss: 0.3569\n",
      "Epoch [58/100], Loss: 0.3722\n",
      "Validation Loss: 0.3623\n",
      "Epoch [59/100], Loss: 0.3717\n",
      "Validation Loss: 0.3572\n",
      "Epoch [60/100], Loss: 0.3712\n",
      "Validation Loss: 0.3613\n",
      "Epoch [61/100], Loss: 0.3710\n",
      "Validation Loss: 0.3544\n",
      "Epoch [62/100], Loss: 0.3728\n",
      "Validation Loss: 0.3566\n",
      "Epoch [63/100], Loss: 0.3722\n",
      "Validation Loss: 0.3578\n",
      "Epoch [64/100], Loss: 0.3710\n",
      "Validation Loss: 0.3588\n",
      "Epoch [65/100], Loss: 0.3710\n",
      "Validation Loss: 0.3583\n",
      "Epoch [66/100], Loss: 0.3703\n",
      "Validation Loss: 0.3579\n",
      "Epoch [67/100], Loss: 0.3705\n",
      "Validation Loss: 0.3554\n",
      "Epoch [68/100], Loss: 0.3702\n",
      "Validation Loss: 0.3564\n",
      "Epoch [69/100], Loss: 0.3699\n",
      "Validation Loss: 0.3552\n",
      "Epoch [70/100], Loss: 0.3693\n",
      "Validation Loss: 0.3538\n",
      "Epoch [71/100], Loss: 0.3698\n",
      "Validation Loss: 0.3541\n",
      "Epoch [72/100], Loss: 0.3699\n",
      "Validation Loss: 0.3563\n",
      "Epoch [73/100], Loss: 0.3688\n",
      "Validation Loss: 0.3551\n",
      "Epoch [74/100], Loss: 0.3693\n",
      "Validation Loss: 0.3569\n",
      "Epoch [75/100], Loss: 0.3693\n",
      "Validation Loss: 0.3530\n",
      "Epoch [76/100], Loss: 0.3690\n",
      "Validation Loss: 0.3542\n",
      "Epoch [77/100], Loss: 0.3695\n",
      "Validation Loss: 0.3545\n",
      "Epoch [78/100], Loss: 0.3696\n",
      "Validation Loss: 0.3645\n",
      "Epoch [79/100], Loss: 0.3689\n",
      "Validation Loss: 0.3575\n",
      "Epoch [80/100], Loss: 0.3689\n",
      "Validation Loss: 0.3565\n",
      "Epoch [81/100], Loss: 0.3683\n",
      "Validation Loss: 0.3543\n",
      "Epoch [82/100], Loss: 0.3681\n",
      "Validation Loss: 0.3549\n",
      "Epoch [83/100], Loss: 0.3682\n",
      "Validation Loss: 0.3576\n",
      "Epoch [84/100], Loss: 0.3687\n",
      "Validation Loss: 0.3540\n",
      "Epoch [85/100], Loss: 0.3685\n",
      "Validation Loss: 0.3512\n",
      "Saved the best model with validation loss: 0.3512\n",
      "Epoch [86/100], Loss: 0.3691\n",
      "Validation Loss: 0.3557\n",
      "Epoch [87/100], Loss: 0.3685\n",
      "Validation Loss: 0.3574\n",
      "Epoch [88/100], Loss: 0.3678\n",
      "Validation Loss: 0.3574\n",
      "Epoch [89/100], Loss: 0.3685\n",
      "Validation Loss: 0.3585\n",
      "Epoch [90/100], Loss: 0.3688\n",
      "Validation Loss: 0.3548\n",
      "Epoch [91/100], Loss: 0.3685\n",
      "Validation Loss: 0.3612\n",
      "Epoch [92/100], Loss: 0.3686\n",
      "Validation Loss: 0.3549\n",
      "Epoch [93/100], Loss: 0.3675\n",
      "Validation Loss: 0.3570\n",
      "Epoch [94/100], Loss: 0.3668\n",
      "Validation Loss: 0.3603\n",
      "Epoch [95/100], Loss: 0.3673\n",
      "Validation Loss: 0.3581\n",
      "Epoch [96/100], Loss: 0.3663\n",
      "Validation Loss: 0.3570\n",
      "Epoch [97/100], Loss: 0.3674\n",
      "Validation Loss: 0.3530\n",
      "Epoch [98/100], Loss: 0.3681\n",
      "Validation Loss: 0.3537\n",
      "Epoch [99/100], Loss: 0.3678\n",
      "Validation Loss: 0.3561\n",
      "Epoch [100/100], Loss: 0.3665\n",
      "Validation Loss: 0.3572\n"
     ]
    }
   ],
   "source": [
    "HGNN_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"HGNN: 1-32-16-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb6eca2-d5c7-4ef8-a355-ea168def346a",
   "metadata": {},
   "source": [
    "##### HGNN: Version 3\n",
    "*  Layers: 5 (including input and output layer), sizes: 1 - 16 - 32 - 16 - 2, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "8819470a-9bd5-4afa-b9b9-d7f22f469f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "c2cf05b9-277d-42b8-b912-0a48ecd28292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5700\n",
      "Validation Loss: 0.4538\n",
      "Saved the best model with validation loss: 0.4538\n",
      "Epoch [2/100], Loss: 0.4522\n",
      "Validation Loss: 0.4055\n",
      "Saved the best model with validation loss: 0.4055\n",
      "Epoch [3/100], Loss: 0.4261\n",
      "Validation Loss: 0.3897\n",
      "Saved the best model with validation loss: 0.3897\n",
      "Epoch [4/100], Loss: 0.4130\n",
      "Validation Loss: 0.3745\n",
      "Saved the best model with validation loss: 0.3745\n",
      "Epoch [5/100], Loss: 0.4043\n",
      "Validation Loss: 0.3589\n",
      "Saved the best model with validation loss: 0.3589\n",
      "Epoch [6/100], Loss: 0.3996\n",
      "Validation Loss: 0.3652\n",
      "Epoch [7/100], Loss: 0.3939\n",
      "Validation Loss: 0.3591\n",
      "Epoch [8/100], Loss: 0.3903\n",
      "Validation Loss: 0.3614\n",
      "Epoch [9/100], Loss: 0.3875\n",
      "Validation Loss: 0.3564\n",
      "Saved the best model with validation loss: 0.3564\n",
      "Epoch [10/100], Loss: 0.3852\n",
      "Validation Loss: 0.3581\n",
      "Epoch [11/100], Loss: 0.3834\n",
      "Validation Loss: 0.3581\n",
      "Epoch [12/100], Loss: 0.3791\n",
      "Validation Loss: 0.3569\n",
      "Epoch [13/100], Loss: 0.3777\n",
      "Validation Loss: 0.3549\n",
      "Saved the best model with validation loss: 0.3549\n",
      "Epoch [14/100], Loss: 0.3760\n",
      "Validation Loss: 0.3552\n",
      "Epoch [15/100], Loss: 0.3748\n",
      "Validation Loss: 0.3512\n",
      "Saved the best model with validation loss: 0.3512\n",
      "Epoch [16/100], Loss: 0.3729\n",
      "Validation Loss: 0.3513\n",
      "Epoch [17/100], Loss: 0.3712\n",
      "Validation Loss: 0.3513\n",
      "Epoch [18/100], Loss: 0.3705\n",
      "Validation Loss: 0.3477\n",
      "Saved the best model with validation loss: 0.3477\n",
      "Epoch [19/100], Loss: 0.3728\n",
      "Validation Loss: 0.3429\n",
      "Saved the best model with validation loss: 0.3429\n",
      "Epoch [20/100], Loss: 0.3691\n",
      "Validation Loss: 0.3430\n",
      "Epoch [21/100], Loss: 0.3672\n",
      "Validation Loss: 0.3490\n",
      "Epoch [22/100], Loss: 0.3677\n",
      "Validation Loss: 0.3461\n",
      "Epoch [23/100], Loss: 0.3669\n",
      "Validation Loss: 0.3446\n",
      "Epoch [24/100], Loss: 0.3651\n",
      "Validation Loss: 0.3546\n",
      "Epoch [25/100], Loss: 0.3661\n",
      "Validation Loss: 0.3546\n",
      "Epoch [26/100], Loss: 0.3644\n",
      "Validation Loss: 0.3567\n",
      "Epoch [27/100], Loss: 0.3636\n",
      "Validation Loss: 0.3587\n",
      "Epoch [28/100], Loss: 0.3633\n",
      "Validation Loss: 0.3503\n",
      "Epoch [29/100], Loss: 0.3629\n",
      "Validation Loss: 0.3453\n",
      "Epoch [30/100], Loss: 0.3614\n",
      "Validation Loss: 0.3468\n",
      "Epoch [31/100], Loss: 0.3615\n",
      "Validation Loss: 0.3446\n",
      "Epoch [32/100], Loss: 0.3607\n",
      "Validation Loss: 0.3503\n",
      "Epoch [33/100], Loss: 0.3594\n",
      "Validation Loss: 0.3499\n",
      "Epoch [34/100], Loss: 0.3597\n",
      "Validation Loss: 0.3562\n",
      "Epoch [35/100], Loss: 0.3607\n",
      "Validation Loss: 0.3527\n",
      "Epoch [36/100], Loss: 0.3573\n",
      "Validation Loss: 0.3574\n",
      "Epoch [37/100], Loss: 0.3573\n",
      "Validation Loss: 0.3593\n",
      "Epoch [38/100], Loss: 0.3586\n",
      "Validation Loss: 0.3597\n",
      "Epoch [39/100], Loss: 0.3577\n",
      "Validation Loss: 0.3632\n",
      "Epoch [40/100], Loss: 0.3585\n",
      "Validation Loss: 0.3625\n",
      "Epoch [41/100], Loss: 0.3594\n",
      "Validation Loss: 0.3617\n",
      "Epoch [42/100], Loss: 0.3569\n",
      "Validation Loss: 0.3637\n",
      "Epoch [43/100], Loss: 0.3574\n",
      "Validation Loss: 0.3630\n",
      "Epoch [44/100], Loss: 0.3550\n",
      "Validation Loss: 0.3658\n",
      "Epoch [45/100], Loss: 0.3577\n",
      "Validation Loss: 0.3608\n",
      "Epoch [46/100], Loss: 0.3571\n",
      "Validation Loss: 0.3598\n",
      "Epoch [47/100], Loss: 0.3553\n",
      "Validation Loss: 0.3541\n",
      "Epoch [48/100], Loss: 0.3572\n",
      "Validation Loss: 0.3510\n",
      "Epoch [49/100], Loss: 0.3555\n",
      "Validation Loss: 0.3510\n",
      "Epoch [50/100], Loss: 0.3564\n",
      "Validation Loss: 0.3476\n",
      "Epoch [51/100], Loss: 0.3564\n",
      "Validation Loss: 0.3463\n",
      "Epoch [52/100], Loss: 0.3551\n",
      "Validation Loss: 0.3470\n",
      "Epoch [53/100], Loss: 0.3566\n",
      "Validation Loss: 0.3485\n",
      "Epoch [54/100], Loss: 0.3531\n",
      "Validation Loss: 0.3504\n",
      "Epoch [55/100], Loss: 0.3532\n",
      "Validation Loss: 0.3462\n",
      "Epoch [56/100], Loss: 0.3547\n",
      "Validation Loss: 0.3488\n",
      "Epoch [57/100], Loss: 0.3523\n",
      "Validation Loss: 0.3501\n",
      "Epoch [58/100], Loss: 0.3531\n",
      "Validation Loss: 0.3506\n",
      "Epoch [59/100], Loss: 0.3547\n",
      "Validation Loss: 0.3492\n",
      "Epoch [60/100], Loss: 0.3531\n",
      "Validation Loss: 0.3441\n",
      "Epoch [61/100], Loss: 0.3525\n",
      "Validation Loss: 0.3460\n",
      "Epoch [62/100], Loss: 0.3514\n",
      "Validation Loss: 0.3537\n",
      "Epoch [63/100], Loss: 0.3512\n",
      "Validation Loss: 0.3574\n",
      "Epoch [64/100], Loss: 0.3543\n",
      "Validation Loss: 0.3560\n",
      "Epoch [65/100], Loss: 0.3538\n",
      "Validation Loss: 0.3534\n",
      "Epoch [66/100], Loss: 0.3525\n",
      "Validation Loss: 0.3743\n",
      "Epoch [67/100], Loss: 0.3558\n",
      "Validation Loss: 0.3690\n",
      "Epoch [68/100], Loss: 0.3546\n",
      "Validation Loss: 0.3584\n",
      "Epoch [69/100], Loss: 0.3539\n",
      "Validation Loss: 0.3658\n",
      "Epoch [70/100], Loss: 0.3539\n",
      "Validation Loss: 0.3674\n",
      "Epoch [71/100], Loss: 0.3535\n",
      "Validation Loss: 0.3577\n",
      "Epoch [72/100], Loss: 0.3546\n",
      "Validation Loss: 0.3632\n",
      "Epoch [73/100], Loss: 0.3536\n",
      "Validation Loss: 0.3578\n",
      "Epoch [74/100], Loss: 0.3528\n",
      "Validation Loss: 0.3563\n",
      "Epoch [75/100], Loss: 0.3518\n",
      "Validation Loss: 0.3665\n",
      "Epoch [76/100], Loss: 0.3537\n",
      "Validation Loss: 0.3579\n",
      "Epoch [77/100], Loss: 0.3541\n",
      "Validation Loss: 0.3576\n",
      "Epoch [78/100], Loss: 0.3531\n",
      "Validation Loss: 0.3563\n",
      "Epoch [79/100], Loss: 0.3527\n",
      "Validation Loss: 0.3503\n",
      "Epoch [80/100], Loss: 0.3520\n",
      "Validation Loss: 0.3631\n",
      "Epoch [81/100], Loss: 0.3521\n",
      "Validation Loss: 0.3582\n",
      "Epoch [82/100], Loss: 0.3556\n",
      "Validation Loss: 0.3515\n",
      "Epoch [83/100], Loss: 0.3516\n",
      "Validation Loss: 0.3479\n",
      "Epoch [84/100], Loss: 0.3523\n",
      "Validation Loss: 0.3593\n",
      "Epoch [85/100], Loss: 0.3551\n",
      "Validation Loss: 0.3624\n",
      "Epoch [86/100], Loss: 0.3557\n",
      "Validation Loss: 0.3580\n",
      "Epoch [87/100], Loss: 0.3501\n",
      "Validation Loss: 0.3538\n",
      "Epoch [88/100], Loss: 0.3503\n",
      "Validation Loss: 0.3541\n",
      "Epoch [89/100], Loss: 0.3525\n",
      "Validation Loss: 0.3560\n",
      "Epoch [90/100], Loss: 0.3526\n",
      "Validation Loss: 0.3586\n",
      "Epoch [91/100], Loss: 0.3522\n",
      "Validation Loss: 0.3598\n",
      "Epoch [92/100], Loss: 0.3533\n",
      "Validation Loss: 0.3563\n",
      "Epoch [93/100], Loss: 0.3514\n",
      "Validation Loss: 0.3582\n",
      "Epoch [94/100], Loss: 0.3517\n",
      "Validation Loss: 0.3475\n",
      "Epoch [95/100], Loss: 0.3509\n",
      "Validation Loss: 0.3509\n",
      "Epoch [96/100], Loss: 0.3505\n",
      "Validation Loss: 0.3485\n",
      "Epoch [97/100], Loss: 0.3511\n",
      "Validation Loss: 0.3490\n",
      "Epoch [98/100], Loss: 0.3508\n",
      "Validation Loss: 0.3436\n",
      "Epoch [99/100], Loss: 0.3500\n",
      "Validation Loss: 0.3508\n",
      "Epoch [100/100], Loss: 0.3502\n",
      "Validation Loss: 0.3467\n"
     ]
    }
   ],
   "source": [
    "HGNN_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"HGNN: 1-16-32-16-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e88723-42c0-4f9f-823c-6d2927d36a78",
   "metadata": {},
   "source": [
    "##### HGNN: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 64 - 2, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "3abf59de-de4b-489a-91d0-d3c86e91856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "796dbb8d-b948-4adb-b6cb-7540440b772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5560\n",
      "Validation Loss: 0.4413\n",
      "Saved the best model with validation loss: 0.4413\n",
      "Epoch [2/100], Loss: 0.4523\n",
      "Validation Loss: 0.4036\n",
      "Saved the best model with validation loss: 0.4036\n",
      "Epoch [3/100], Loss: 0.4251\n",
      "Validation Loss: 0.3863\n",
      "Saved the best model with validation loss: 0.3863\n",
      "Epoch [4/100], Loss: 0.4090\n",
      "Validation Loss: 0.3771\n",
      "Saved the best model with validation loss: 0.3771\n",
      "Epoch [5/100], Loss: 0.3996\n",
      "Validation Loss: 0.3716\n",
      "Saved the best model with validation loss: 0.3716\n",
      "Epoch [6/100], Loss: 0.3931\n",
      "Validation Loss: 0.3614\n",
      "Saved the best model with validation loss: 0.3614\n",
      "Epoch [7/100], Loss: 0.3886\n",
      "Validation Loss: 0.3614\n",
      "Saved the best model with validation loss: 0.3614\n",
      "Epoch [8/100], Loss: 0.3844\n",
      "Validation Loss: 0.3580\n",
      "Saved the best model with validation loss: 0.3580\n",
      "Epoch [9/100], Loss: 0.3831\n",
      "Validation Loss: 0.3499\n",
      "Saved the best model with validation loss: 0.3499\n",
      "Epoch [10/100], Loss: 0.3800\n",
      "Validation Loss: 0.3517\n",
      "Epoch [11/100], Loss: 0.3788\n",
      "Validation Loss: 0.3550\n",
      "Epoch [12/100], Loss: 0.3778\n",
      "Validation Loss: 0.3515\n",
      "Epoch [13/100], Loss: 0.3752\n",
      "Validation Loss: 0.3511\n",
      "Epoch [14/100], Loss: 0.3737\n",
      "Validation Loss: 0.3535\n",
      "Epoch [15/100], Loss: 0.3724\n",
      "Validation Loss: 0.3520\n",
      "Epoch [16/100], Loss: 0.3729\n",
      "Validation Loss: 0.3496\n",
      "Saved the best model with validation loss: 0.3496\n",
      "Epoch [17/100], Loss: 0.3705\n",
      "Validation Loss: 0.3483\n",
      "Saved the best model with validation loss: 0.3483\n",
      "Epoch [18/100], Loss: 0.3695\n",
      "Validation Loss: 0.3503\n",
      "Epoch [19/100], Loss: 0.3682\n",
      "Validation Loss: 0.3482\n",
      "Saved the best model with validation loss: 0.3482\n",
      "Epoch [20/100], Loss: 0.3676\n",
      "Validation Loss: 0.3495\n",
      "Epoch [21/100], Loss: 0.3679\n",
      "Validation Loss: 0.3467\n",
      "Saved the best model with validation loss: 0.3467\n",
      "Epoch [22/100], Loss: 0.3671\n",
      "Validation Loss: 0.3441\n",
      "Saved the best model with validation loss: 0.3441\n",
      "Epoch [23/100], Loss: 0.3652\n",
      "Validation Loss: 0.3472\n",
      "Epoch [24/100], Loss: 0.3653\n",
      "Validation Loss: 0.3567\n",
      "Epoch [25/100], Loss: 0.3654\n",
      "Validation Loss: 0.3492\n",
      "Epoch [26/100], Loss: 0.3645\n",
      "Validation Loss: 0.3470\n",
      "Epoch [27/100], Loss: 0.3649\n",
      "Validation Loss: 0.3579\n",
      "Epoch [28/100], Loss: 0.3653\n",
      "Validation Loss: 0.3466\n",
      "Epoch [29/100], Loss: 0.3636\n",
      "Validation Loss: 0.3485\n",
      "Epoch [30/100], Loss: 0.3620\n",
      "Validation Loss: 0.3506\n",
      "Epoch [31/100], Loss: 0.3631\n",
      "Validation Loss: 0.3449\n",
      "Epoch [32/100], Loss: 0.3625\n",
      "Validation Loss: 0.3443\n",
      "Epoch [33/100], Loss: 0.3625\n",
      "Validation Loss: 0.3474\n",
      "Epoch [34/100], Loss: 0.3617\n",
      "Validation Loss: 0.3470\n",
      "Epoch [35/100], Loss: 0.3608\n",
      "Validation Loss: 0.3452\n",
      "Epoch [36/100], Loss: 0.3604\n",
      "Validation Loss: 0.3461\n",
      "Epoch [37/100], Loss: 0.3598\n",
      "Validation Loss: 0.3464\n",
      "Epoch [38/100], Loss: 0.3591\n",
      "Validation Loss: 0.3474\n",
      "Epoch [39/100], Loss: 0.3589\n",
      "Validation Loss: 0.3420\n",
      "Saved the best model with validation loss: 0.3420\n",
      "Epoch [40/100], Loss: 0.3599\n",
      "Validation Loss: 0.3530\n",
      "Epoch [41/100], Loss: 0.3605\n",
      "Validation Loss: 0.3480\n",
      "Epoch [42/100], Loss: 0.3599\n",
      "Validation Loss: 0.3418\n",
      "Saved the best model with validation loss: 0.3418\n",
      "Epoch [43/100], Loss: 0.3591\n",
      "Validation Loss: 0.3445\n",
      "Epoch [44/100], Loss: 0.3571\n",
      "Validation Loss: 0.3455\n",
      "Epoch [45/100], Loss: 0.3600\n",
      "Validation Loss: 0.3519\n",
      "Epoch [46/100], Loss: 0.3582\n",
      "Validation Loss: 0.3392\n",
      "Saved the best model with validation loss: 0.3392\n",
      "Epoch [47/100], Loss: 0.3569\n",
      "Validation Loss: 0.3542\n",
      "Epoch [48/100], Loss: 0.3577\n",
      "Validation Loss: 0.3445\n",
      "Epoch [49/100], Loss: 0.3569\n",
      "Validation Loss: 0.3441\n",
      "Epoch [50/100], Loss: 0.3566\n",
      "Validation Loss: 0.3455\n",
      "Epoch [51/100], Loss: 0.3560\n",
      "Validation Loss: 0.3508\n",
      "Epoch [52/100], Loss: 0.3566\n",
      "Validation Loss: 0.3448\n",
      "Epoch [53/100], Loss: 0.3545\n",
      "Validation Loss: 0.3516\n",
      "Epoch [54/100], Loss: 0.3545\n",
      "Validation Loss: 0.3474\n",
      "Epoch [55/100], Loss: 0.3559\n",
      "Validation Loss: 0.3503\n",
      "Epoch [56/100], Loss: 0.3546\n",
      "Validation Loss: 0.3458\n",
      "Epoch [57/100], Loss: 0.3552\n",
      "Validation Loss: 0.3485\n",
      "Epoch [58/100], Loss: 0.3555\n",
      "Validation Loss: 0.3489\n",
      "Epoch [59/100], Loss: 0.3578\n",
      "Validation Loss: 0.3445\n",
      "Epoch [60/100], Loss: 0.3553\n",
      "Validation Loss: 0.3488\n",
      "Epoch [61/100], Loss: 0.3540\n",
      "Validation Loss: 0.3481\n",
      "Epoch [62/100], Loss: 0.3541\n",
      "Validation Loss: 0.3460\n",
      "Epoch [63/100], Loss: 0.3566\n",
      "Validation Loss: 0.3443\n",
      "Epoch [64/100], Loss: 0.3546\n",
      "Validation Loss: 0.3456\n",
      "Epoch [65/100], Loss: 0.3548\n",
      "Validation Loss: 0.3463\n",
      "Epoch [66/100], Loss: 0.3547\n",
      "Validation Loss: 0.3439\n",
      "Epoch [67/100], Loss: 0.3540\n",
      "Validation Loss: 0.3534\n",
      "Epoch [68/100], Loss: 0.3537\n",
      "Validation Loss: 0.3474\n",
      "Epoch [69/100], Loss: 0.3537\n",
      "Validation Loss: 0.3480\n",
      "Epoch [70/100], Loss: 0.3541\n",
      "Validation Loss: 0.3493\n",
      "Epoch [71/100], Loss: 0.3544\n",
      "Validation Loss: 0.3498\n",
      "Epoch [72/100], Loss: 0.3531\n",
      "Validation Loss: 0.3490\n",
      "Epoch [73/100], Loss: 0.3528\n",
      "Validation Loss: 0.3466\n",
      "Epoch [74/100], Loss: 0.3530\n",
      "Validation Loss: 0.3471\n",
      "Epoch [75/100], Loss: 0.3531\n",
      "Validation Loss: 0.3449\n",
      "Epoch [76/100], Loss: 0.3532\n",
      "Validation Loss: 0.3514\n",
      "Epoch [77/100], Loss: 0.3533\n",
      "Validation Loss: 0.3433\n",
      "Epoch [78/100], Loss: 0.3523\n",
      "Validation Loss: 0.3670\n",
      "Epoch [79/100], Loss: 0.3519\n",
      "Validation Loss: 0.3518\n",
      "Epoch [80/100], Loss: 0.3530\n",
      "Validation Loss: 0.3515\n",
      "Epoch [81/100], Loss: 0.3517\n",
      "Validation Loss: 0.3468\n",
      "Epoch [82/100], Loss: 0.3511\n",
      "Validation Loss: 0.3478\n",
      "Epoch [83/100], Loss: 0.3508\n",
      "Validation Loss: 0.3478\n",
      "Epoch [84/100], Loss: 0.3507\n",
      "Validation Loss: 0.3492\n",
      "Epoch [85/100], Loss: 0.3513\n",
      "Validation Loss: 0.3559\n",
      "Epoch [86/100], Loss: 0.3520\n",
      "Validation Loss: 0.3472\n",
      "Epoch [87/100], Loss: 0.3524\n",
      "Validation Loss: 0.3618\n",
      "Epoch [88/100], Loss: 0.3511\n",
      "Validation Loss: 0.3618\n",
      "Epoch [89/100], Loss: 0.3500\n",
      "Validation Loss: 0.3618\n",
      "Epoch [90/100], Loss: 0.3520\n",
      "Validation Loss: 0.3650\n",
      "Epoch [91/100], Loss: 0.3512\n",
      "Validation Loss: 0.3642\n",
      "Epoch [92/100], Loss: 0.3503\n",
      "Validation Loss: 0.3571\n",
      "Epoch [93/100], Loss: 0.3505\n",
      "Validation Loss: 0.3571\n",
      "Epoch [94/100], Loss: 0.3495\n",
      "Validation Loss: 0.3590\n",
      "Epoch [95/100], Loss: 0.3509\n",
      "Validation Loss: 0.3519\n",
      "Epoch [96/100], Loss: 0.3498\n",
      "Validation Loss: 0.3547\n",
      "Epoch [97/100], Loss: 0.3512\n",
      "Validation Loss: 0.3496\n",
      "Epoch [98/100], Loss: 0.3508\n",
      "Validation Loss: 0.3456\n",
      "Epoch [99/100], Loss: 0.3494\n",
      "Validation Loss: 0.3462\n",
      "Epoch [100/100], Loss: 0.3494\n",
      "Validation Loss: 0.3494\n"
     ]
    }
   ],
   "source": [
    "HGNN_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"HGNN: 1-32-64-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a80d0-2d9c-4b99-81ec-3b10f2a2fd17",
   "metadata": {},
   "source": [
    "##### HGNN: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 4 - 16 - 2, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "ae8d16b1-91db-4136-b4c2-0e0c0f6db3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "d72ef586-de14-4fc9-ad14-90bd3a2dd245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6475\n",
      "Validation Loss: 0.5565\n",
      "Saved the best model with validation loss: 0.5565\n",
      "Epoch [2/100], Loss: 0.5096\n",
      "Validation Loss: 0.4596\n",
      "Saved the best model with validation loss: 0.4596\n",
      "Epoch [3/100], Loss: 0.4610\n",
      "Validation Loss: 0.4354\n",
      "Saved the best model with validation loss: 0.4354\n",
      "Epoch [4/100], Loss: 0.4443\n",
      "Validation Loss: 0.4214\n",
      "Saved the best model with validation loss: 0.4214\n",
      "Epoch [5/100], Loss: 0.4362\n",
      "Validation Loss: 0.4130\n",
      "Saved the best model with validation loss: 0.4130\n",
      "Epoch [6/100], Loss: 0.4294\n",
      "Validation Loss: 0.4066\n",
      "Saved the best model with validation loss: 0.4066\n",
      "Epoch [7/100], Loss: 0.4244\n",
      "Validation Loss: 0.4007\n",
      "Saved the best model with validation loss: 0.4007\n",
      "Epoch [8/100], Loss: 0.4209\n",
      "Validation Loss: 0.3957\n",
      "Saved the best model with validation loss: 0.3957\n",
      "Epoch [9/100], Loss: 0.4173\n",
      "Validation Loss: 0.3929\n",
      "Saved the best model with validation loss: 0.3929\n",
      "Epoch [10/100], Loss: 0.4150\n",
      "Validation Loss: 0.3885\n",
      "Saved the best model with validation loss: 0.3885\n",
      "Epoch [11/100], Loss: 0.4129\n",
      "Validation Loss: 0.3839\n",
      "Saved the best model with validation loss: 0.3839\n",
      "Epoch [12/100], Loss: 0.4103\n",
      "Validation Loss: 0.3810\n",
      "Saved the best model with validation loss: 0.3810\n",
      "Epoch [13/100], Loss: 0.4088\n",
      "Validation Loss: 0.3792\n",
      "Saved the best model with validation loss: 0.3792\n",
      "Epoch [14/100], Loss: 0.4073\n",
      "Validation Loss: 0.3798\n",
      "Epoch [15/100], Loss: 0.4059\n",
      "Validation Loss: 0.3768\n",
      "Saved the best model with validation loss: 0.3768\n",
      "Epoch [16/100], Loss: 0.4037\n",
      "Validation Loss: 0.3754\n",
      "Saved the best model with validation loss: 0.3754\n",
      "Epoch [17/100], Loss: 0.4028\n",
      "Validation Loss: 0.3720\n",
      "Saved the best model with validation loss: 0.3720\n",
      "Epoch [18/100], Loss: 0.4014\n",
      "Validation Loss: 0.3717\n",
      "Saved the best model with validation loss: 0.3717\n",
      "Epoch [19/100], Loss: 0.4003\n",
      "Validation Loss: 0.3696\n",
      "Saved the best model with validation loss: 0.3696\n",
      "Epoch [20/100], Loss: 0.3992\n",
      "Validation Loss: 0.3679\n",
      "Saved the best model with validation loss: 0.3679\n",
      "Epoch [21/100], Loss: 0.3985\n",
      "Validation Loss: 0.3674\n",
      "Saved the best model with validation loss: 0.3674\n",
      "Epoch [22/100], Loss: 0.3976\n",
      "Validation Loss: 0.3672\n",
      "Saved the best model with validation loss: 0.3672\n",
      "Epoch [23/100], Loss: 0.3968\n",
      "Validation Loss: 0.3679\n",
      "Epoch [24/100], Loss: 0.3963\n",
      "Validation Loss: 0.3660\n",
      "Saved the best model with validation loss: 0.3660\n",
      "Epoch [25/100], Loss: 0.3957\n",
      "Validation Loss: 0.3666\n",
      "Epoch [26/100], Loss: 0.3949\n",
      "Validation Loss: 0.3656\n",
      "Saved the best model with validation loss: 0.3656\n",
      "Epoch [27/100], Loss: 0.3947\n",
      "Validation Loss: 0.3657\n",
      "Epoch [28/100], Loss: 0.3940\n",
      "Validation Loss: 0.3648\n",
      "Saved the best model with validation loss: 0.3648\n",
      "Epoch [29/100], Loss: 0.3938\n",
      "Validation Loss: 0.3637\n",
      "Saved the best model with validation loss: 0.3637\n",
      "Epoch [30/100], Loss: 0.3931\n",
      "Validation Loss: 0.3636\n",
      "Saved the best model with validation loss: 0.3636\n",
      "Epoch [31/100], Loss: 0.3925\n",
      "Validation Loss: 0.3634\n",
      "Saved the best model with validation loss: 0.3634\n",
      "Epoch [32/100], Loss: 0.3921\n",
      "Validation Loss: 0.3638\n",
      "Epoch [33/100], Loss: 0.3922\n",
      "Validation Loss: 0.3643\n",
      "Epoch [34/100], Loss: 0.3919\n",
      "Validation Loss: 0.3593\n",
      "Saved the best model with validation loss: 0.3593\n",
      "Epoch [35/100], Loss: 0.3915\n",
      "Validation Loss: 0.3608\n",
      "Epoch [36/100], Loss: 0.3908\n",
      "Validation Loss: 0.3587\n",
      "Saved the best model with validation loss: 0.3587\n",
      "Epoch [37/100], Loss: 0.3906\n",
      "Validation Loss: 0.3582\n",
      "Saved the best model with validation loss: 0.3582\n",
      "Epoch [38/100], Loss: 0.3898\n",
      "Validation Loss: 0.3592\n",
      "Epoch [39/100], Loss: 0.3901\n",
      "Validation Loss: 0.3596\n",
      "Epoch [40/100], Loss: 0.3895\n",
      "Validation Loss: 0.3564\n",
      "Saved the best model with validation loss: 0.3564\n",
      "Epoch [41/100], Loss: 0.3882\n",
      "Validation Loss: 0.3583\n",
      "Epoch [42/100], Loss: 0.3877\n",
      "Validation Loss: 0.3590\n",
      "Epoch [43/100], Loss: 0.3875\n",
      "Validation Loss: 0.3593\n",
      "Epoch [44/100], Loss: 0.3871\n",
      "Validation Loss: 0.3573\n",
      "Epoch [45/100], Loss: 0.3868\n",
      "Validation Loss: 0.3575\n",
      "Epoch [46/100], Loss: 0.3863\n",
      "Validation Loss: 0.3598\n",
      "Epoch [47/100], Loss: 0.3863\n",
      "Validation Loss: 0.3575\n",
      "Epoch [48/100], Loss: 0.3863\n",
      "Validation Loss: 0.3567\n",
      "Epoch [49/100], Loss: 0.3853\n",
      "Validation Loss: 0.3595\n",
      "Epoch [50/100], Loss: 0.3856\n",
      "Validation Loss: 0.3570\n",
      "Epoch [51/100], Loss: 0.3856\n",
      "Validation Loss: 0.3587\n",
      "Epoch [52/100], Loss: 0.3845\n",
      "Validation Loss: 0.3564\n",
      "Saved the best model with validation loss: 0.3564\n",
      "Epoch [53/100], Loss: 0.3848\n",
      "Validation Loss: 0.3638\n",
      "Epoch [54/100], Loss: 0.3841\n",
      "Validation Loss: 0.3604\n",
      "Epoch [55/100], Loss: 0.3842\n",
      "Validation Loss: 0.3586\n",
      "Epoch [56/100], Loss: 0.3836\n",
      "Validation Loss: 0.3558\n",
      "Saved the best model with validation loss: 0.3558\n",
      "Epoch [57/100], Loss: 0.3835\n",
      "Validation Loss: 0.3596\n",
      "Epoch [58/100], Loss: 0.3833\n",
      "Validation Loss: 0.3561\n",
      "Epoch [59/100], Loss: 0.3831\n",
      "Validation Loss: 0.3547\n",
      "Saved the best model with validation loss: 0.3547\n",
      "Epoch [60/100], Loss: 0.3828\n",
      "Validation Loss: 0.3569\n",
      "Epoch [61/100], Loss: 0.3827\n",
      "Validation Loss: 0.3538\n",
      "Saved the best model with validation loss: 0.3538\n",
      "Epoch [62/100], Loss: 0.3827\n",
      "Validation Loss: 0.3568\n",
      "Epoch [63/100], Loss: 0.3825\n",
      "Validation Loss: 0.3607\n",
      "Epoch [64/100], Loss: 0.3823\n",
      "Validation Loss: 0.3612\n",
      "Epoch [65/100], Loss: 0.3820\n",
      "Validation Loss: 0.3596\n",
      "Epoch [66/100], Loss: 0.3823\n",
      "Validation Loss: 0.3570\n",
      "Epoch [67/100], Loss: 0.3814\n",
      "Validation Loss: 0.3560\n",
      "Epoch [68/100], Loss: 0.3814\n",
      "Validation Loss: 0.3587\n",
      "Epoch [69/100], Loss: 0.3811\n",
      "Validation Loss: 0.3553\n",
      "Epoch [70/100], Loss: 0.3806\n",
      "Validation Loss: 0.3593\n",
      "Epoch [71/100], Loss: 0.3802\n",
      "Validation Loss: 0.3584\n",
      "Epoch [72/100], Loss: 0.3804\n",
      "Validation Loss: 0.3582\n",
      "Epoch [73/100], Loss: 0.3794\n",
      "Validation Loss: 0.3555\n",
      "Epoch [74/100], Loss: 0.3792\n",
      "Validation Loss: 0.3591\n",
      "Epoch [75/100], Loss: 0.3799\n",
      "Validation Loss: 0.3540\n",
      "Epoch [76/100], Loss: 0.3800\n",
      "Validation Loss: 0.3534\n",
      "Saved the best model with validation loss: 0.3534\n",
      "Epoch [77/100], Loss: 0.3799\n",
      "Validation Loss: 0.3587\n",
      "Epoch [78/100], Loss: 0.3792\n",
      "Validation Loss: 0.3552\n",
      "Epoch [79/100], Loss: 0.3801\n",
      "Validation Loss: 0.3573\n",
      "Epoch [80/100], Loss: 0.3789\n",
      "Validation Loss: 0.3576\n",
      "Epoch [81/100], Loss: 0.3785\n",
      "Validation Loss: 0.3565\n",
      "Epoch [82/100], Loss: 0.3781\n",
      "Validation Loss: 0.3573\n",
      "Epoch [83/100], Loss: 0.3782\n",
      "Validation Loss: 0.3544\n",
      "Epoch [84/100], Loss: 0.3783\n",
      "Validation Loss: 0.3561\n",
      "Epoch [85/100], Loss: 0.3783\n",
      "Validation Loss: 0.3523\n",
      "Saved the best model with validation loss: 0.3523\n",
      "Epoch [86/100], Loss: 0.3778\n",
      "Validation Loss: 0.3547\n",
      "Epoch [87/100], Loss: 0.3768\n",
      "Validation Loss: 0.3532\n",
      "Epoch [88/100], Loss: 0.3767\n",
      "Validation Loss: 0.3544\n",
      "Epoch [89/100], Loss: 0.3768\n",
      "Validation Loss: 0.3504\n",
      "Saved the best model with validation loss: 0.3504\n",
      "Epoch [90/100], Loss: 0.3758\n",
      "Validation Loss: 0.3500\n",
      "Saved the best model with validation loss: 0.3500\n",
      "Epoch [91/100], Loss: 0.3748\n",
      "Validation Loss: 0.3505\n",
      "Epoch [92/100], Loss: 0.3746\n",
      "Validation Loss: 0.3500\n",
      "Epoch [93/100], Loss: 0.3736\n",
      "Validation Loss: 0.3501\n",
      "Epoch [94/100], Loss: 0.3733\n",
      "Validation Loss: 0.3472\n",
      "Saved the best model with validation loss: 0.3472\n",
      "Epoch [95/100], Loss: 0.3731\n",
      "Validation Loss: 0.3481\n",
      "Epoch [96/100], Loss: 0.3724\n",
      "Validation Loss: 0.3476\n",
      "Epoch [97/100], Loss: 0.3730\n",
      "Validation Loss: 0.3496\n",
      "Epoch [98/100], Loss: 0.3722\n",
      "Validation Loss: 0.3463\n",
      "Saved the best model with validation loss: 0.3463\n",
      "Epoch [99/100], Loss: 0.3715\n",
      "Validation Loss: 0.3467\n",
      "Epoch [100/100], Loss: 0.3708\n",
      "Validation Loss: 0.3476\n"
     ]
    }
   ],
   "source": [
    "HGNN_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"HGNN: 1-4-16-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "6aed147a-aa7e-40e7-8b5b-632fcd4e08e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.827117</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.667832</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.645688</td>\n",
       "      <td>0.622881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.672494</td>\n",
       "      <td>0.469492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.662393</td>\n",
       "      <td>0.523729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-2</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-2</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-2</th>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-2</th>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-2</th>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-2</th>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-2</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-2</th>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-2</th>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-2</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-2</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-2</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-2</th>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-2</th>\n",
       "      <td>0.713287</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-2</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-2</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-2</th>\n",
       "      <td>0.758741</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-2</th>\n",
       "      <td>0.685315</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-2</th>\n",
       "      <td>0.702797</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-2</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-2</th>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-2</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-2</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-2</th>\n",
       "      <td>0.842657</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-2</th>\n",
       "      <td>0.821678</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   acc       rec       acc       rec\n",
       "5-NN                          0.818182  0.769231  0.811189  0.795763\n",
       "Decision tree                 0.832168  0.776923  0.827506  0.800847\n",
       "Random forest                 0.835664  0.792308  0.827117  0.816949\n",
       "SVM linear                    0.667832  0.584615  0.645688  0.622881\n",
       "SVM poly                      0.716783  0.507692  0.672494  0.469492\n",
       "SVM rbf                       0.720280  0.561538  0.662393  0.523729\n",
       "MLP: 17-5-2                   0.730769  0.669231         -         -\n",
       "MLP: 17-10-2                  0.632867  0.215385         -         -\n",
       "MLP: 17-20-2                  0.765734  0.761538         -         -\n",
       "MLP: 17-25-2                  0.755245  0.761538         -         -\n",
       "MLP: 17-40-2                  0.744755  0.738462         -         -\n",
       "MLP: 17-60-2                  0.755245  0.738462         -         -\n",
       "MLP: 17-10-5-2                0.706294  0.438462         -         -\n",
       "MLP: 17-20-10-2               0.709790  0.723077         -         -\n",
       "MLP: 17-40-20-2               0.776224  0.753846         -         -\n",
       "MLP: 17-40-10-2               0.741259  0.723077         -         -\n",
       "MLP: 17-60-40-2               0.737762  0.723077         -         -\n",
       "MLP: 17-60-20-2               0.737762  0.753846         -         -\n",
       "MLP: 17-80-50-2               0.783217  0.753846         -         -\n",
       "MLP, small-median: 7-80-50-2  0.713287  0.569231         -         -\n",
       "MLP, small-mean: 7-80-50-2    0.706294  0.584615         -         -\n",
       "MLP, small-min: 7-80-50-2     0.706294  0.623077         -         -\n",
       "MLP, small-max: 7-80-50-2     0.758741  0.776923         -         -\n",
       "MLP, small-q25: 7-80-50-2     0.685315  0.592308         -         -\n",
       "MLP, small-q75: 7-80-50-2     0.702797  0.607692         -         -\n",
       "MLP, custom: 7-80-50-2        0.772727  0.707692         -         -\n",
       "HGNN: 1-16-32-2               0.839161  0.884615         -         -\n",
       "HGNN: 1-32-16-2               0.818182  0.876923         -         -\n",
       "HGNN: 1-16-32-16-2            0.835664  0.892308         -         -\n",
       "HGNN: 1-32-64-2               0.842657  0.892308         -         -\n",
       "HGNN: 1-4-16-2                0.821678  0.876923         -         -"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67dc5cd",
   "metadata": {},
   "source": [
    "### HGNN (Hypergraph Neural Network) with three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7c47a",
   "metadata": {},
   "source": [
    "*  Loss: Cross-Entropy\n",
    "*  Epochs: 100 (saving best model)\n",
    "*  Leaning rate: 0.001\n",
    "*  Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176fb80",
   "metadata": {},
   "source": [
    "##### HGNN: Version 1, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 16 - 32 - 3, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b540e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"HGNN 0.5: 1-16-32-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"HGNN 0.1: 1-16-32-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d27fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"HGNN 0.05: 1-16-32-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"HGNN 0.01: 1-16-32-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61750480",
   "metadata": {},
   "source": [
    "##### HGNN: Version 2, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 16 - 3, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"HGNN 0.5: 1-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860cb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"HGNN 0.1: 1-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932cbb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"HGNN 0.05: 1-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"HGNN 0.01: 1-32-16-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6821f8be",
   "metadata": {},
   "source": [
    "##### HGNN: Version 3\n",
    "*  Layers: 5 (including input and output layer), sizes: 1 - 16 - 32 - 16 - 3, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfaf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4035f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"HGNN 0.5: 1-16-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8dfa76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"HGNN 0.1: 1-16-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e09ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"HGNN 0.05: 1-16-32-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa03176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"HGNN 0.01: 1-16-32-16-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844010c",
   "metadata": {},
   "source": [
    "##### HGNN: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 64 - 3, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690e452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c143569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"HGNN 0.5: 1-32-64-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735adb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"HGNN 0.1: 1-32-64-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b9257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"HGNN 0.05: 1-32-64-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0db41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"HGNN 0.01: 1-32-64-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee856a",
   "metadata": {},
   "source": [
    "##### HGNN: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 4 - 16 - 3, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6315ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"HGNN 0.5: 1-4-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862adfdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"HGNN 0.1: 1-4-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c4a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"HGNN 0.05: 1-4-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234e626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HGNN_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"HGNN 0.01: 1-4-16-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13cb72f-4822-4b6c-ae2f-fb26c1523928",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_.to_csv('results/table_time_diff_POS_rounded.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f4151",
   "metadata": {},
   "source": [
    "### HGNN (Hypergraph neural network) with time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "bbb12a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, label_series, hypergraph_column_name):\n",
    "        # Extract features and convert to tensor\n",
    "        self.X = torch.from_numpy(dataframe.drop(columns=[hypergraph_column_name]).values).float()\n",
    "        \n",
    "        # Extract labels and convert to tensor\n",
    "        self.y = torch.from_numpy(label_series.values).float()\n",
    "        \n",
    "        # Store hypergraph objects\n",
    "        self.hypergraphs = dataframe[hypergraph_column_name].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.X[index],\n",
    "            'label': self.y[index],\n",
    "            'hypergraph': self.hypergraphs[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "a4a3f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HGNN_regression(X_training, y_training, X_validation, y_validation, text):\n",
    "    model = HGNN(random_seed = 20)  \n",
    "\n",
    "    dataset = CustomDataset(X_training, y_training, hypergraph_column_name='hypergraph')\n",
    "    validation = CustomDataset(X_validation, y_validation, hypergraph_column_name='hypergraph')\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for item in dataset:\n",
    "            optimizer.zero_grad()\n",
    "            input_features = item[\"data\"]\n",
    "            input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "            label = item[\"label\"].float().squeeze(0)\n",
    "            output = model(input_hg)\n",
    "            \n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataset):.4f}')\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for item in validation:\n",
    "                input_features = item[\"data\"]\n",
    "                input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "                label = item[\"label\"].float().squeeze(0)\n",
    "                output = model(input_hg)\n",
    "                loss = loss_function(output, label)\n",
    "                val_loss += loss.item()\n",
    "    \n",
    "        val_loss /= len(validation)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "        # Save the model if the validation loss is the best we've seen so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Saved the best model with validation loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for item in validation:\n",
    "            i += 1\n",
    "            output = model(item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0))\n",
    "            predicted.append(output.item())\n",
    "\n",
    "    mse = mean_squared_error(y_validation, predicted)\n",
    "    mae = mean_absolute_error(y_validation, predicted)\n",
    "    r2 = r2_score(y_validation, predicted)\n",
    "    \n",
    "    table_time_diff.loc[text] = [mse, mae, r2, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b77604",
   "metadata": {},
   "source": [
    "##### HGNN: Version 1\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 16 - 32 - 1, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "886aa909",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "9aa591ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.9432\n",
      "Validation Loss: 1.1207\n",
      "Saved the best model with validation loss: 1.1207\n",
      "Epoch [2/100], Loss: 1.0132\n",
      "Validation Loss: 0.9440\n",
      "Saved the best model with validation loss: 0.9440\n",
      "Epoch [3/100], Loss: 0.8893\n",
      "Validation Loss: 0.8440\n",
      "Saved the best model with validation loss: 0.8440\n",
      "Epoch [4/100], Loss: 0.8223\n",
      "Validation Loss: 0.7960\n",
      "Saved the best model with validation loss: 0.7960\n",
      "Epoch [5/100], Loss: 0.7887\n",
      "Validation Loss: 0.7635\n",
      "Saved the best model with validation loss: 0.7635\n",
      "Epoch [6/100], Loss: 0.7628\n",
      "Validation Loss: 0.7364\n",
      "Saved the best model with validation loss: 0.7364\n",
      "Epoch [7/100], Loss: 0.7449\n",
      "Validation Loss: 0.7203\n",
      "Saved the best model with validation loss: 0.7203\n",
      "Epoch [8/100], Loss: 0.7286\n",
      "Validation Loss: 0.7045\n",
      "Saved the best model with validation loss: 0.7045\n",
      "Epoch [9/100], Loss: 0.7156\n",
      "Validation Loss: 0.6937\n",
      "Saved the best model with validation loss: 0.6937\n",
      "Epoch [10/100], Loss: 0.7061\n",
      "Validation Loss: 0.6787\n",
      "Saved the best model with validation loss: 0.6787\n",
      "Epoch [11/100], Loss: 0.7020\n",
      "Validation Loss: 0.6872\n",
      "Epoch [12/100], Loss: 0.6943\n",
      "Validation Loss: 0.6731\n",
      "Saved the best model with validation loss: 0.6731\n",
      "Epoch [13/100], Loss: 0.6910\n",
      "Validation Loss: 0.6750\n",
      "Epoch [14/100], Loss: 0.6871\n",
      "Validation Loss: 0.6710\n",
      "Saved the best model with validation loss: 0.6710\n",
      "Epoch [15/100], Loss: 0.6818\n",
      "Validation Loss: 0.6681\n",
      "Saved the best model with validation loss: 0.6681\n",
      "Epoch [16/100], Loss: 0.6783\n",
      "Validation Loss: 0.6541\n",
      "Saved the best model with validation loss: 0.6541\n",
      "Epoch [17/100], Loss: 0.6768\n",
      "Validation Loss: 0.6564\n",
      "Epoch [18/100], Loss: 0.6727\n",
      "Validation Loss: 0.6453\n",
      "Saved the best model with validation loss: 0.6453\n",
      "Epoch [19/100], Loss: 0.6714\n",
      "Validation Loss: 0.6563\n",
      "Epoch [20/100], Loss: 0.6717\n",
      "Validation Loss: 0.6477\n",
      "Epoch [21/100], Loss: 0.6673\n",
      "Validation Loss: 0.6490\n",
      "Epoch [22/100], Loss: 0.6630\n",
      "Validation Loss: 0.6453\n",
      "Saved the best model with validation loss: 0.6453\n",
      "Epoch [23/100], Loss: 0.6634\n",
      "Validation Loss: 0.6395\n",
      "Saved the best model with validation loss: 0.6395\n",
      "Epoch [24/100], Loss: 0.6599\n",
      "Validation Loss: 0.6405\n",
      "Epoch [25/100], Loss: 0.6581\n",
      "Validation Loss: 0.6389\n",
      "Saved the best model with validation loss: 0.6389\n",
      "Epoch [26/100], Loss: 0.6570\n",
      "Validation Loss: 0.6383\n",
      "Saved the best model with validation loss: 0.6383\n",
      "Epoch [27/100], Loss: 0.6539\n",
      "Validation Loss: 0.6357\n",
      "Saved the best model with validation loss: 0.6357\n",
      "Epoch [28/100], Loss: 0.6534\n",
      "Validation Loss: 0.6304\n",
      "Saved the best model with validation loss: 0.6304\n",
      "Epoch [29/100], Loss: 0.6538\n",
      "Validation Loss: 0.6395\n",
      "Epoch [30/100], Loss: 0.6513\n",
      "Validation Loss: 0.6372\n",
      "Epoch [31/100], Loss: 0.6499\n",
      "Validation Loss: 0.6380\n",
      "Epoch [32/100], Loss: 0.6500\n",
      "Validation Loss: 0.6378\n",
      "Epoch [33/100], Loss: 0.6469\n",
      "Validation Loss: 0.6428\n",
      "Epoch [34/100], Loss: 0.6459\n",
      "Validation Loss: 0.6399\n",
      "Epoch [35/100], Loss: 0.6437\n",
      "Validation Loss: 0.6315\n",
      "Epoch [36/100], Loss: 0.6428\n",
      "Validation Loss: 0.6333\n",
      "Epoch [37/100], Loss: 0.6438\n",
      "Validation Loss: 0.6280\n",
      "Saved the best model with validation loss: 0.6280\n",
      "Epoch [38/100], Loss: 0.6437\n",
      "Validation Loss: 0.6417\n",
      "Epoch [39/100], Loss: 0.6443\n",
      "Validation Loss: 0.6331\n",
      "Epoch [40/100], Loss: 0.6448\n",
      "Validation Loss: 0.6488\n",
      "Epoch [41/100], Loss: 0.6426\n",
      "Validation Loss: 0.6447\n",
      "Epoch [42/100], Loss: 0.6420\n",
      "Validation Loss: 0.6443\n",
      "Epoch [43/100], Loss: 0.6395\n",
      "Validation Loss: 0.6470\n",
      "Epoch [44/100], Loss: 0.6408\n",
      "Validation Loss: 0.6377\n",
      "Epoch [45/100], Loss: 0.6396\n",
      "Validation Loss: 0.6464\n",
      "Epoch [46/100], Loss: 0.6395\n",
      "Validation Loss: 0.6440\n",
      "Epoch [47/100], Loss: 0.6388\n",
      "Validation Loss: 0.6420\n",
      "Epoch [48/100], Loss: 0.6392\n",
      "Validation Loss: 0.6368\n",
      "Epoch [49/100], Loss: 0.6387\n",
      "Validation Loss: 0.6309\n",
      "Epoch [50/100], Loss: 0.6389\n",
      "Validation Loss: 0.6382\n",
      "Epoch [51/100], Loss: 0.6413\n",
      "Validation Loss: 0.6376\n",
      "Epoch [52/100], Loss: 0.6379\n",
      "Validation Loss: 0.6348\n",
      "Epoch [53/100], Loss: 0.6370\n",
      "Validation Loss: 0.6281\n",
      "Epoch [54/100], Loss: 0.6355\n",
      "Validation Loss: 0.6282\n",
      "Epoch [55/100], Loss: 0.6340\n",
      "Validation Loss: 0.6278\n",
      "Saved the best model with validation loss: 0.6278\n",
      "Epoch [56/100], Loss: 0.6333\n",
      "Validation Loss: 0.6250\n",
      "Saved the best model with validation loss: 0.6250\n",
      "Epoch [57/100], Loss: 0.6327\n",
      "Validation Loss: 0.6308\n",
      "Epoch [58/100], Loss: 0.6332\n",
      "Validation Loss: 0.6321\n",
      "Epoch [59/100], Loss: 0.6352\n",
      "Validation Loss: 0.6259\n",
      "Epoch [60/100], Loss: 0.6312\n",
      "Validation Loss: 0.6368\n",
      "Epoch [61/100], Loss: 0.6347\n",
      "Validation Loss: 0.6243\n",
      "Saved the best model with validation loss: 0.6243\n",
      "Epoch [62/100], Loss: 0.6312\n",
      "Validation Loss: 0.6196\n",
      "Saved the best model with validation loss: 0.6196\n",
      "Epoch [63/100], Loss: 0.6303\n",
      "Validation Loss: 0.6235\n",
      "Epoch [64/100], Loss: 0.6296\n",
      "Validation Loss: 0.6167\n",
      "Saved the best model with validation loss: 0.6167\n",
      "Epoch [65/100], Loss: 0.6276\n",
      "Validation Loss: 0.6243\n",
      "Epoch [66/100], Loss: 0.6342\n",
      "Validation Loss: 0.6176\n",
      "Epoch [67/100], Loss: 0.6298\n",
      "Validation Loss: 0.6158\n",
      "Saved the best model with validation loss: 0.6158\n",
      "Epoch [68/100], Loss: 0.6285\n",
      "Validation Loss: 0.6142\n",
      "Saved the best model with validation loss: 0.6142\n",
      "Epoch [69/100], Loss: 0.6293\n",
      "Validation Loss: 0.6131\n",
      "Saved the best model with validation loss: 0.6131\n",
      "Epoch [70/100], Loss: 0.6289\n",
      "Validation Loss: 0.6280\n",
      "Epoch [71/100], Loss: 0.6321\n",
      "Validation Loss: 0.6251\n",
      "Epoch [72/100], Loss: 0.6318\n",
      "Validation Loss: 0.6110\n",
      "Saved the best model with validation loss: 0.6110\n",
      "Epoch [73/100], Loss: 0.6275\n",
      "Validation Loss: 0.6218\n",
      "Epoch [74/100], Loss: 0.6287\n",
      "Validation Loss: 0.6216\n",
      "Epoch [75/100], Loss: 0.6298\n",
      "Validation Loss: 0.6194\n",
      "Epoch [76/100], Loss: 0.6280\n",
      "Validation Loss: 0.6165\n",
      "Epoch [77/100], Loss: 0.6260\n",
      "Validation Loss: 0.6216\n",
      "Epoch [78/100], Loss: 0.6296\n",
      "Validation Loss: 0.6222\n",
      "Epoch [79/100], Loss: 0.6274\n",
      "Validation Loss: 0.6166\n",
      "Epoch [80/100], Loss: 0.6293\n",
      "Validation Loss: 0.6191\n",
      "Epoch [81/100], Loss: 0.6279\n",
      "Validation Loss: 0.6307\n",
      "Epoch [82/100], Loss: 0.6281\n",
      "Validation Loss: 0.6207\n",
      "Epoch [83/100], Loss: 0.6280\n",
      "Validation Loss: 0.6198\n",
      "Epoch [84/100], Loss: 0.6263\n",
      "Validation Loss: 0.6174\n",
      "Epoch [85/100], Loss: 0.6263\n",
      "Validation Loss: 0.6215\n",
      "Epoch [86/100], Loss: 0.6253\n",
      "Validation Loss: 0.6131\n",
      "Epoch [87/100], Loss: 0.6263\n",
      "Validation Loss: 0.6121\n",
      "Epoch [88/100], Loss: 0.6248\n",
      "Validation Loss: 0.6170\n",
      "Epoch [89/100], Loss: 0.6251\n",
      "Validation Loss: 0.6259\n",
      "Epoch [90/100], Loss: 0.6222\n",
      "Validation Loss: 0.6308\n",
      "Epoch [91/100], Loss: 0.6282\n",
      "Validation Loss: 0.6223\n",
      "Epoch [92/100], Loss: 0.6263\n",
      "Validation Loss: 0.6305\n",
      "Epoch [93/100], Loss: 0.6260\n",
      "Validation Loss: 0.6345\n",
      "Epoch [94/100], Loss: 0.6279\n",
      "Validation Loss: 0.6267\n",
      "Epoch [95/100], Loss: 0.6236\n",
      "Validation Loss: 0.6284\n",
      "Epoch [96/100], Loss: 0.6230\n",
      "Validation Loss: 0.6233\n",
      "Epoch [97/100], Loss: 0.6251\n",
      "Validation Loss: 0.6114\n",
      "Epoch [98/100], Loss: 0.6215\n",
      "Validation Loss: 0.6173\n",
      "Epoch [99/100], Loss: 0.6224\n",
      "Validation Loss: 0.6237\n",
      "Epoch [100/100], Loss: 0.6263\n",
      "Validation Loss: 0.6348\n"
     ]
    }
   ],
   "source": [
    "HGNN_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"HGNN: 1-16-32-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5649f583",
   "metadata": {},
   "source": [
    "##### HGNN: Version 2\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 16 - 1, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "c73bc508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "15bc52f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.2538\n",
      "Validation Loss: 1.4880\n",
      "Saved the best model with validation loss: 1.4880\n",
      "Epoch [2/100], Loss: 1.2045\n",
      "Validation Loss: 1.1906\n",
      "Saved the best model with validation loss: 1.1906\n",
      "Epoch [3/100], Loss: 1.0029\n",
      "Validation Loss: 1.0485\n",
      "Saved the best model with validation loss: 1.0485\n",
      "Epoch [4/100], Loss: 0.9329\n",
      "Validation Loss: 0.9837\n",
      "Saved the best model with validation loss: 0.9837\n",
      "Epoch [5/100], Loss: 0.8941\n",
      "Validation Loss: 0.9236\n",
      "Saved the best model with validation loss: 0.9236\n",
      "Epoch [6/100], Loss: 0.8637\n",
      "Validation Loss: 0.8740\n",
      "Saved the best model with validation loss: 0.8740\n",
      "Epoch [7/100], Loss: 0.8351\n",
      "Validation Loss: 0.8538\n",
      "Saved the best model with validation loss: 0.8538\n",
      "Epoch [8/100], Loss: 0.8216\n",
      "Validation Loss: 0.8238\n",
      "Saved the best model with validation loss: 0.8238\n",
      "Epoch [9/100], Loss: 0.8043\n",
      "Validation Loss: 0.7936\n",
      "Saved the best model with validation loss: 0.7936\n",
      "Epoch [10/100], Loss: 0.7957\n",
      "Validation Loss: 0.7762\n",
      "Saved the best model with validation loss: 0.7762\n",
      "Epoch [11/100], Loss: 0.7838\n",
      "Validation Loss: 0.7671\n",
      "Saved the best model with validation loss: 0.7671\n",
      "Epoch [12/100], Loss: 0.7749\n",
      "Validation Loss: 0.7665\n",
      "Saved the best model with validation loss: 0.7665\n",
      "Epoch [13/100], Loss: 0.7720\n",
      "Validation Loss: 0.7478\n",
      "Saved the best model with validation loss: 0.7478\n",
      "Epoch [14/100], Loss: 0.7646\n",
      "Validation Loss: 0.7682\n",
      "Epoch [15/100], Loss: 0.7566\n",
      "Validation Loss: 0.7417\n",
      "Saved the best model with validation loss: 0.7417\n",
      "Epoch [16/100], Loss: 0.7542\n",
      "Validation Loss: 0.7348\n",
      "Saved the best model with validation loss: 0.7348\n",
      "Epoch [17/100], Loss: 0.7486\n",
      "Validation Loss: 0.7396\n",
      "Epoch [18/100], Loss: 0.7457\n",
      "Validation Loss: 0.7205\n",
      "Saved the best model with validation loss: 0.7205\n",
      "Epoch [19/100], Loss: 0.7397\n",
      "Validation Loss: 0.7100\n",
      "Saved the best model with validation loss: 0.7100\n",
      "Epoch [20/100], Loss: 0.7358\n",
      "Validation Loss: 0.7051\n",
      "Saved the best model with validation loss: 0.7051\n",
      "Epoch [21/100], Loss: 0.7339\n",
      "Validation Loss: 0.7024\n",
      "Saved the best model with validation loss: 0.7024\n",
      "Epoch [22/100], Loss: 0.7306\n",
      "Validation Loss: 0.7017\n",
      "Saved the best model with validation loss: 0.7017\n",
      "Epoch [23/100], Loss: 0.7293\n",
      "Validation Loss: 0.7007\n",
      "Saved the best model with validation loss: 0.7007\n",
      "Epoch [24/100], Loss: 0.7253\n",
      "Validation Loss: 0.6956\n",
      "Saved the best model with validation loss: 0.6956\n",
      "Epoch [25/100], Loss: 0.7237\n",
      "Validation Loss: 0.6942\n",
      "Saved the best model with validation loss: 0.6942\n",
      "Epoch [26/100], Loss: 0.7206\n",
      "Validation Loss: 0.6892\n",
      "Saved the best model with validation loss: 0.6892\n",
      "Epoch [27/100], Loss: 0.7179\n",
      "Validation Loss: 0.6933\n",
      "Epoch [28/100], Loss: 0.7183\n",
      "Validation Loss: 0.6931\n",
      "Epoch [29/100], Loss: 0.7159\n",
      "Validation Loss: 0.6911\n",
      "Epoch [30/100], Loss: 0.7137\n",
      "Validation Loss: 0.6950\n",
      "Epoch [31/100], Loss: 0.7140\n",
      "Validation Loss: 0.6894\n",
      "Epoch [32/100], Loss: 0.7139\n",
      "Validation Loss: 0.6851\n",
      "Saved the best model with validation loss: 0.6851\n",
      "Epoch [33/100], Loss: 0.7109\n",
      "Validation Loss: 0.6799\n",
      "Saved the best model with validation loss: 0.6799\n",
      "Epoch [34/100], Loss: 0.7103\n",
      "Validation Loss: 0.6880\n",
      "Epoch [35/100], Loss: 0.7120\n",
      "Validation Loss: 0.6856\n",
      "Epoch [36/100], Loss: 0.7080\n",
      "Validation Loss: 0.6785\n",
      "Saved the best model with validation loss: 0.6785\n",
      "Epoch [37/100], Loss: 0.7080\n",
      "Validation Loss: 0.6811\n",
      "Epoch [38/100], Loss: 0.7062\n",
      "Validation Loss: 0.6758\n",
      "Saved the best model with validation loss: 0.6758\n",
      "Epoch [39/100], Loss: 0.7038\n",
      "Validation Loss: 0.6778\n",
      "Epoch [40/100], Loss: 0.7050\n",
      "Validation Loss: 0.6810\n",
      "Epoch [41/100], Loss: 0.7035\n",
      "Validation Loss: 0.6840\n",
      "Epoch [42/100], Loss: 0.7018\n",
      "Validation Loss: 0.6790\n",
      "Epoch [43/100], Loss: 0.7021\n",
      "Validation Loss: 0.6814\n",
      "Epoch [44/100], Loss: 0.7013\n",
      "Validation Loss: 0.6735\n",
      "Saved the best model with validation loss: 0.6735\n",
      "Epoch [45/100], Loss: 0.7016\n",
      "Validation Loss: 0.6744\n",
      "Epoch [46/100], Loss: 0.6997\n",
      "Validation Loss: 0.6767\n",
      "Epoch [47/100], Loss: 0.6979\n",
      "Validation Loss: 0.6731\n",
      "Saved the best model with validation loss: 0.6731\n",
      "Epoch [48/100], Loss: 0.6978\n",
      "Validation Loss: 0.6760\n",
      "Epoch [49/100], Loss: 0.6978\n",
      "Validation Loss: 0.6745\n",
      "Epoch [50/100], Loss: 0.6964\n",
      "Validation Loss: 0.6727\n",
      "Saved the best model with validation loss: 0.6727\n",
      "Epoch [51/100], Loss: 0.6969\n",
      "Validation Loss: 0.6781\n",
      "Epoch [52/100], Loss: 0.6956\n",
      "Validation Loss: 0.6698\n",
      "Saved the best model with validation loss: 0.6698\n",
      "Epoch [53/100], Loss: 0.6959\n",
      "Validation Loss: 0.6760\n",
      "Epoch [54/100], Loss: 0.6957\n",
      "Validation Loss: 0.6685\n",
      "Saved the best model with validation loss: 0.6685\n",
      "Epoch [55/100], Loss: 0.6917\n",
      "Validation Loss: 0.6684\n",
      "Saved the best model with validation loss: 0.6684\n",
      "Epoch [56/100], Loss: 0.6940\n",
      "Validation Loss: 0.6751\n",
      "Epoch [57/100], Loss: 0.6929\n",
      "Validation Loss: 0.6699\n",
      "Epoch [58/100], Loss: 0.6930\n",
      "Validation Loss: 0.6720\n",
      "Epoch [59/100], Loss: 0.6928\n",
      "Validation Loss: 0.6666\n",
      "Saved the best model with validation loss: 0.6666\n",
      "Epoch [60/100], Loss: 0.6917\n",
      "Validation Loss: 0.6668\n",
      "Epoch [61/100], Loss: 0.6927\n",
      "Validation Loss: 0.6739\n",
      "Epoch [62/100], Loss: 0.6916\n",
      "Validation Loss: 0.6691\n",
      "Epoch [63/100], Loss: 0.6906\n",
      "Validation Loss: 0.6712\n",
      "Epoch [64/100], Loss: 0.6893\n",
      "Validation Loss: 0.6734\n",
      "Epoch [65/100], Loss: 0.6885\n",
      "Validation Loss: 0.6755\n",
      "Epoch [66/100], Loss: 0.6869\n",
      "Validation Loss: 0.6704\n",
      "Epoch [67/100], Loss: 0.6900\n",
      "Validation Loss: 0.6690\n",
      "Epoch [68/100], Loss: 0.6878\n",
      "Validation Loss: 0.6696\n",
      "Epoch [69/100], Loss: 0.6877\n",
      "Validation Loss: 0.6685\n",
      "Epoch [70/100], Loss: 0.6878\n",
      "Validation Loss: 0.6710\n",
      "Epoch [71/100], Loss: 0.6853\n",
      "Validation Loss: 0.6691\n",
      "Epoch [72/100], Loss: 0.6888\n",
      "Validation Loss: 0.6732\n",
      "Epoch [73/100], Loss: 0.6867\n",
      "Validation Loss: 0.6770\n",
      "Epoch [74/100], Loss: 0.6872\n",
      "Validation Loss: 0.6717\n",
      "Epoch [75/100], Loss: 0.6841\n",
      "Validation Loss: 0.6687\n",
      "Epoch [76/100], Loss: 0.6846\n",
      "Validation Loss: 0.6686\n",
      "Epoch [77/100], Loss: 0.6839\n",
      "Validation Loss: 0.6712\n",
      "Epoch [78/100], Loss: 0.6839\n",
      "Validation Loss: 0.6690\n",
      "Epoch [79/100], Loss: 0.6843\n",
      "Validation Loss: 0.6727\n",
      "Epoch [80/100], Loss: 0.6826\n",
      "Validation Loss: 0.6676\n",
      "Epoch [81/100], Loss: 0.6807\n",
      "Validation Loss: 0.6703\n",
      "Epoch [82/100], Loss: 0.6806\n",
      "Validation Loss: 0.6632\n",
      "Saved the best model with validation loss: 0.6632\n",
      "Epoch [83/100], Loss: 0.6833\n",
      "Validation Loss: 0.6720\n",
      "Epoch [84/100], Loss: 0.6828\n",
      "Validation Loss: 0.6722\n",
      "Epoch [85/100], Loss: 0.6808\n",
      "Validation Loss: 0.6671\n",
      "Epoch [86/100], Loss: 0.6817\n",
      "Validation Loss: 0.6670\n",
      "Epoch [87/100], Loss: 0.6808\n",
      "Validation Loss: 0.6642\n",
      "Epoch [88/100], Loss: 0.6811\n",
      "Validation Loss: 0.6699\n",
      "Epoch [89/100], Loss: 0.6822\n",
      "Validation Loss: 0.6684\n",
      "Epoch [90/100], Loss: 0.6819\n",
      "Validation Loss: 0.6677\n",
      "Epoch [91/100], Loss: 0.6809\n",
      "Validation Loss: 0.6642\n",
      "Epoch [92/100], Loss: 0.6797\n",
      "Validation Loss: 0.6655\n",
      "Epoch [93/100], Loss: 0.6796\n",
      "Validation Loss: 0.6655\n",
      "Epoch [94/100], Loss: 0.6794\n",
      "Validation Loss: 0.6645\n",
      "Epoch [95/100], Loss: 0.6806\n",
      "Validation Loss: 0.6658\n",
      "Epoch [96/100], Loss: 0.6795\n",
      "Validation Loss: 0.6625\n",
      "Saved the best model with validation loss: 0.6625\n",
      "Epoch [97/100], Loss: 0.6787\n",
      "Validation Loss: 0.6613\n",
      "Saved the best model with validation loss: 0.6613\n",
      "Epoch [98/100], Loss: 0.6775\n",
      "Validation Loss: 0.6629\n",
      "Epoch [99/100], Loss: 0.6785\n",
      "Validation Loss: 0.6710\n",
      "Epoch [100/100], Loss: 0.6798\n",
      "Validation Loss: 0.6607\n",
      "Saved the best model with validation loss: 0.6607\n"
     ]
    }
   ],
   "source": [
    "HGNN_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"HGNN: 1-32-16-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703583a",
   "metadata": {},
   "source": [
    "##### HGNN: Version 3\n",
    "*  Layers: 5 (including input and output layer), sizes: 1 - 16 - 32 - 16 - 1, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "4508ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "ec1bd6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.8012\n",
      "Validation Loss: 0.9929\n",
      "Saved the best model with validation loss: 0.9929\n",
      "Epoch [2/100], Loss: 0.9178\n",
      "Validation Loss: 0.8394\n",
      "Saved the best model with validation loss: 0.8394\n",
      "Epoch [3/100], Loss: 0.8154\n",
      "Validation Loss: 0.7951\n",
      "Saved the best model with validation loss: 0.7951\n",
      "Epoch [4/100], Loss: 0.7671\n",
      "Validation Loss: 0.7501\n",
      "Saved the best model with validation loss: 0.7501\n",
      "Epoch [5/100], Loss: 0.7360\n",
      "Validation Loss: 0.7357\n",
      "Saved the best model with validation loss: 0.7357\n",
      "Epoch [6/100], Loss: 0.7160\n",
      "Validation Loss: 0.7022\n",
      "Saved the best model with validation loss: 0.7022\n",
      "Epoch [7/100], Loss: 0.7050\n",
      "Validation Loss: 0.6675\n",
      "Saved the best model with validation loss: 0.6675\n",
      "Epoch [8/100], Loss: 0.6889\n",
      "Validation Loss: 0.6755\n",
      "Epoch [9/100], Loss: 0.6835\n",
      "Validation Loss: 0.6696\n",
      "Epoch [10/100], Loss: 0.6768\n",
      "Validation Loss: 0.6565\n",
      "Saved the best model with validation loss: 0.6565\n",
      "Epoch [11/100], Loss: 0.6695\n",
      "Validation Loss: 0.6483\n",
      "Saved the best model with validation loss: 0.6483\n",
      "Epoch [12/100], Loss: 0.6682\n",
      "Validation Loss: 0.6572\n",
      "Epoch [13/100], Loss: 0.6634\n",
      "Validation Loss: 0.6611\n",
      "Epoch [14/100], Loss: 0.6623\n",
      "Validation Loss: 0.6402\n",
      "Saved the best model with validation loss: 0.6402\n",
      "Epoch [15/100], Loss: 0.6610\n",
      "Validation Loss: 0.6463\n",
      "Epoch [16/100], Loss: 0.6607\n",
      "Validation Loss: 0.6334\n",
      "Saved the best model with validation loss: 0.6334\n",
      "Epoch [17/100], Loss: 0.6565\n",
      "Validation Loss: 0.6396\n",
      "Epoch [18/100], Loss: 0.6516\n",
      "Validation Loss: 0.6509\n",
      "Epoch [19/100], Loss: 0.6470\n",
      "Validation Loss: 0.6489\n",
      "Epoch [20/100], Loss: 0.6447\n",
      "Validation Loss: 0.6367\n",
      "Epoch [21/100], Loss: 0.6470\n",
      "Validation Loss: 0.6301\n",
      "Saved the best model with validation loss: 0.6301\n",
      "Epoch [22/100], Loss: 0.6441\n",
      "Validation Loss: 0.6294\n",
      "Saved the best model with validation loss: 0.6294\n",
      "Epoch [23/100], Loss: 0.6456\n",
      "Validation Loss: 0.6284\n",
      "Saved the best model with validation loss: 0.6284\n",
      "Epoch [24/100], Loss: 0.6420\n",
      "Validation Loss: 0.6301\n",
      "Epoch [25/100], Loss: 0.6400\n",
      "Validation Loss: 0.6237\n",
      "Saved the best model with validation loss: 0.6237\n",
      "Epoch [26/100], Loss: 0.6411\n",
      "Validation Loss: 0.6297\n",
      "Epoch [27/100], Loss: 0.6371\n",
      "Validation Loss: 0.6239\n",
      "Epoch [28/100], Loss: 0.6422\n",
      "Validation Loss: 0.6145\n",
      "Saved the best model with validation loss: 0.6145\n",
      "Epoch [29/100], Loss: 0.6376\n",
      "Validation Loss: 0.6222\n",
      "Epoch [30/100], Loss: 0.6374\n",
      "Validation Loss: 0.6227\n",
      "Epoch [31/100], Loss: 0.6344\n",
      "Validation Loss: 0.6247\n",
      "Epoch [32/100], Loss: 0.6355\n",
      "Validation Loss: 0.6203\n",
      "Epoch [33/100], Loss: 0.6318\n",
      "Validation Loss: 0.6174\n",
      "Epoch [34/100], Loss: 0.6284\n",
      "Validation Loss: 0.6200\n",
      "Epoch [35/100], Loss: 0.6388\n",
      "Validation Loss: 0.6300\n",
      "Epoch [36/100], Loss: 0.6353\n",
      "Validation Loss: 0.6136\n",
      "Saved the best model with validation loss: 0.6136\n",
      "Epoch [37/100], Loss: 0.6322\n",
      "Validation Loss: 0.6158\n",
      "Epoch [38/100], Loss: 0.6309\n",
      "Validation Loss: 0.6139\n",
      "Epoch [39/100], Loss: 0.6319\n",
      "Validation Loss: 0.6038\n",
      "Saved the best model with validation loss: 0.6038\n",
      "Epoch [40/100], Loss: 0.6311\n",
      "Validation Loss: 0.6138\n",
      "Epoch [41/100], Loss: 0.6333\n",
      "Validation Loss: 0.6288\n",
      "Epoch [42/100], Loss: 0.6267\n",
      "Validation Loss: 0.6204\n",
      "Epoch [43/100], Loss: 0.6241\n",
      "Validation Loss: 0.6215\n",
      "Epoch [44/100], Loss: 0.6253\n",
      "Validation Loss: 0.6350\n",
      "Epoch [45/100], Loss: 0.6267\n",
      "Validation Loss: 0.6287\n",
      "Epoch [46/100], Loss: 0.6267\n",
      "Validation Loss: 0.6379\n",
      "Epoch [47/100], Loss: 0.6240\n",
      "Validation Loss: 0.6258\n",
      "Epoch [48/100], Loss: 0.6278\n",
      "Validation Loss: 0.6223\n",
      "Epoch [49/100], Loss: 0.6271\n",
      "Validation Loss: 0.6245\n",
      "Epoch [50/100], Loss: 0.6260\n",
      "Validation Loss: 0.6120\n",
      "Epoch [51/100], Loss: 0.6252\n",
      "Validation Loss: 0.6243\n",
      "Epoch [52/100], Loss: 0.6257\n",
      "Validation Loss: 0.6025\n",
      "Saved the best model with validation loss: 0.6025\n",
      "Epoch [53/100], Loss: 0.6228\n",
      "Validation Loss: 0.6189\n",
      "Epoch [54/100], Loss: 0.6225\n",
      "Validation Loss: 0.6566\n",
      "Epoch [55/100], Loss: 0.6263\n",
      "Validation Loss: 0.6275\n",
      "Epoch [56/100], Loss: 0.6253\n",
      "Validation Loss: 0.6403\n",
      "Epoch [57/100], Loss: 0.6264\n",
      "Validation Loss: 0.6131\n",
      "Epoch [58/100], Loss: 0.6274\n",
      "Validation Loss: 0.6176\n",
      "Epoch [59/100], Loss: 0.6245\n",
      "Validation Loss: 0.6248\n",
      "Epoch [60/100], Loss: 0.6257\n",
      "Validation Loss: 0.6157\n",
      "Epoch [61/100], Loss: 0.6223\n",
      "Validation Loss: 0.6068\n",
      "Epoch [62/100], Loss: 0.6237\n",
      "Validation Loss: 0.6098\n",
      "Epoch [63/100], Loss: 0.6188\n",
      "Validation Loss: 0.6192\n",
      "Epoch [64/100], Loss: 0.6193\n",
      "Validation Loss: 0.6205\n",
      "Epoch [65/100], Loss: 0.6244\n",
      "Validation Loss: 0.6159\n",
      "Epoch [66/100], Loss: 0.6202\n",
      "Validation Loss: 0.6176\n",
      "Epoch [67/100], Loss: 0.6202\n",
      "Validation Loss: 0.6377\n",
      "Epoch [68/100], Loss: 0.6216\n",
      "Validation Loss: 0.6290\n",
      "Epoch [69/100], Loss: 0.6197\n",
      "Validation Loss: 0.6179\n",
      "Epoch [70/100], Loss: 0.6206\n",
      "Validation Loss: 0.6196\n",
      "Epoch [71/100], Loss: 0.6197\n",
      "Validation Loss: 0.6195\n",
      "Epoch [72/100], Loss: 0.6189\n",
      "Validation Loss: 0.6273\n",
      "Epoch [73/100], Loss: 0.6188\n",
      "Validation Loss: 0.6078\n",
      "Epoch [74/100], Loss: 0.6211\n",
      "Validation Loss: 0.6184\n",
      "Epoch [75/100], Loss: 0.6196\n",
      "Validation Loss: 0.6149\n",
      "Epoch [76/100], Loss: 0.6189\n",
      "Validation Loss: 0.6181\n",
      "Epoch [77/100], Loss: 0.6190\n",
      "Validation Loss: 0.6196\n",
      "Epoch [78/100], Loss: 0.6190\n",
      "Validation Loss: 0.6061\n",
      "Epoch [79/100], Loss: 0.6195\n",
      "Validation Loss: 0.6078\n",
      "Epoch [80/100], Loss: 0.6163\n",
      "Validation Loss: 0.6071\n",
      "Epoch [81/100], Loss: 0.6166\n",
      "Validation Loss: 0.6074\n",
      "Epoch [82/100], Loss: 0.6206\n",
      "Validation Loss: 0.6233\n",
      "Epoch [83/100], Loss: 0.6218\n",
      "Validation Loss: 0.6142\n",
      "Epoch [84/100], Loss: 0.6187\n",
      "Validation Loss: 0.6272\n",
      "Epoch [85/100], Loss: 0.6172\n",
      "Validation Loss: 0.6337\n",
      "Epoch [86/100], Loss: 0.6219\n",
      "Validation Loss: 0.6236\n",
      "Epoch [87/100], Loss: 0.6143\n",
      "Validation Loss: 0.6140\n",
      "Epoch [88/100], Loss: 0.6199\n",
      "Validation Loss: 0.6535\n",
      "Epoch [89/100], Loss: 0.6160\n",
      "Validation Loss: 0.6100\n",
      "Epoch [90/100], Loss: 0.6168\n",
      "Validation Loss: 0.6269\n",
      "Epoch [91/100], Loss: 0.6194\n",
      "Validation Loss: 0.6068\n",
      "Epoch [92/100], Loss: 0.6186\n",
      "Validation Loss: 0.6036\n",
      "Epoch [93/100], Loss: 0.6200\n",
      "Validation Loss: 0.6099\n",
      "Epoch [94/100], Loss: 0.6154\n",
      "Validation Loss: 0.6103\n",
      "Epoch [95/100], Loss: 0.6168\n",
      "Validation Loss: 0.6255\n",
      "Epoch [96/100], Loss: 0.6152\n",
      "Validation Loss: 0.6105\n",
      "Epoch [97/100], Loss: 0.6154\n",
      "Validation Loss: 0.6049\n",
      "Epoch [98/100], Loss: 0.6139\n",
      "Validation Loss: 0.6142\n",
      "Epoch [99/100], Loss: 0.6161\n",
      "Validation Loss: 0.5992\n",
      "Saved the best model with validation loss: 0.5992\n",
      "Epoch [100/100], Loss: 0.6162\n",
      "Validation Loss: 0.6012\n"
     ]
    }
   ],
   "source": [
    "HGNN_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val,  \"HGNN: 1-16-32-16-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041627fc",
   "metadata": {},
   "source": [
    "##### HGNN: Version 4\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 32 - 64 - 1, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "1ade520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "c7561e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.6619\n",
      "Validation Loss: 0.9869\n",
      "Saved the best model with validation loss: 0.9869\n",
      "Epoch [2/100], Loss: 0.9366\n",
      "Validation Loss: 0.8360\n",
      "Saved the best model with validation loss: 0.8360\n",
      "Epoch [3/100], Loss: 0.8359\n",
      "Validation Loss: 0.7660\n",
      "Saved the best model with validation loss: 0.7660\n",
      "Epoch [4/100], Loss: 0.7763\n",
      "Validation Loss: 0.7198\n",
      "Saved the best model with validation loss: 0.7198\n",
      "Epoch [5/100], Loss: 0.7477\n",
      "Validation Loss: 0.6891\n",
      "Saved the best model with validation loss: 0.6891\n",
      "Epoch [6/100], Loss: 0.7279\n",
      "Validation Loss: 0.6719\n",
      "Saved the best model with validation loss: 0.6719\n",
      "Epoch [7/100], Loss: 0.7131\n",
      "Validation Loss: 0.6646\n",
      "Saved the best model with validation loss: 0.6646\n",
      "Epoch [8/100], Loss: 0.7028\n",
      "Validation Loss: 0.6556\n",
      "Saved the best model with validation loss: 0.6556\n",
      "Epoch [9/100], Loss: 0.6949\n",
      "Validation Loss: 0.6530\n",
      "Saved the best model with validation loss: 0.6530\n",
      "Epoch [10/100], Loss: 0.6898\n",
      "Validation Loss: 0.6464\n",
      "Saved the best model with validation loss: 0.6464\n",
      "Epoch [11/100], Loss: 0.6809\n",
      "Validation Loss: 0.6415\n",
      "Saved the best model with validation loss: 0.6415\n",
      "Epoch [12/100], Loss: 0.6770\n",
      "Validation Loss: 0.6410\n",
      "Saved the best model with validation loss: 0.6410\n",
      "Epoch [13/100], Loss: 0.6702\n",
      "Validation Loss: 0.6331\n",
      "Saved the best model with validation loss: 0.6331\n",
      "Epoch [14/100], Loss: 0.6682\n",
      "Validation Loss: 0.6281\n",
      "Saved the best model with validation loss: 0.6281\n",
      "Epoch [15/100], Loss: 0.6628\n",
      "Validation Loss: 0.6290\n",
      "Epoch [16/100], Loss: 0.6626\n",
      "Validation Loss: 0.6212\n",
      "Saved the best model with validation loss: 0.6212\n",
      "Epoch [17/100], Loss: 0.6585\n",
      "Validation Loss: 0.6282\n",
      "Epoch [18/100], Loss: 0.6542\n",
      "Validation Loss: 0.6274\n",
      "Epoch [19/100], Loss: 0.6529\n",
      "Validation Loss: 0.6241\n",
      "Epoch [20/100], Loss: 0.6503\n",
      "Validation Loss: 0.6328\n",
      "Epoch [21/100], Loss: 0.6481\n",
      "Validation Loss: 0.6270\n",
      "Epoch [22/100], Loss: 0.6485\n",
      "Validation Loss: 0.6217\n",
      "Epoch [23/100], Loss: 0.6433\n",
      "Validation Loss: 0.6329\n",
      "Epoch [24/100], Loss: 0.6428\n",
      "Validation Loss: 0.6259\n",
      "Epoch [25/100], Loss: 0.6421\n",
      "Validation Loss: 0.6188\n",
      "Saved the best model with validation loss: 0.6188\n",
      "Epoch [26/100], Loss: 0.6429\n",
      "Validation Loss: 0.6244\n",
      "Epoch [27/100], Loss: 0.6409\n",
      "Validation Loss: 0.6231\n",
      "Epoch [28/100], Loss: 0.6420\n",
      "Validation Loss: 0.6209\n",
      "Epoch [29/100], Loss: 0.6381\n",
      "Validation Loss: 0.6176\n",
      "Saved the best model with validation loss: 0.6176\n",
      "Epoch [30/100], Loss: 0.6377\n",
      "Validation Loss: 0.6235\n",
      "Epoch [31/100], Loss: 0.6365\n",
      "Validation Loss: 0.6187\n",
      "Epoch [32/100], Loss: 0.6375\n",
      "Validation Loss: 0.6203\n",
      "Epoch [33/100], Loss: 0.6340\n",
      "Validation Loss: 0.6221\n",
      "Epoch [34/100], Loss: 0.6374\n",
      "Validation Loss: 0.6204\n",
      "Epoch [35/100], Loss: 0.6344\n",
      "Validation Loss: 0.6197\n",
      "Epoch [36/100], Loss: 0.6335\n",
      "Validation Loss: 0.6156\n",
      "Saved the best model with validation loss: 0.6156\n",
      "Epoch [37/100], Loss: 0.6323\n",
      "Validation Loss: 0.6212\n",
      "Epoch [38/100], Loss: 0.6328\n",
      "Validation Loss: 0.6160\n",
      "Epoch [39/100], Loss: 0.6316\n",
      "Validation Loss: 0.6154\n",
      "Saved the best model with validation loss: 0.6154\n",
      "Epoch [40/100], Loss: 0.6342\n",
      "Validation Loss: 0.6119\n",
      "Saved the best model with validation loss: 0.6119\n",
      "Epoch [41/100], Loss: 0.6345\n",
      "Validation Loss: 0.6081\n",
      "Saved the best model with validation loss: 0.6081\n",
      "Epoch [42/100], Loss: 0.6272\n",
      "Validation Loss: 0.6047\n",
      "Saved the best model with validation loss: 0.6047\n",
      "Epoch [43/100], Loss: 0.6311\n",
      "Validation Loss: 0.6159\n",
      "Epoch [44/100], Loss: 0.6317\n",
      "Validation Loss: 0.6121\n",
      "Epoch [45/100], Loss: 0.6314\n",
      "Validation Loss: 0.6198\n",
      "Epoch [46/100], Loss: 0.6301\n",
      "Validation Loss: 0.6129\n",
      "Epoch [47/100], Loss: 0.6265\n",
      "Validation Loss: 0.6167\n",
      "Epoch [48/100], Loss: 0.6287\n",
      "Validation Loss: 0.6110\n",
      "Epoch [49/100], Loss: 0.6256\n",
      "Validation Loss: 0.6173\n",
      "Epoch [50/100], Loss: 0.6245\n",
      "Validation Loss: 0.6192\n",
      "Epoch [51/100], Loss: 0.6297\n",
      "Validation Loss: 0.6187\n",
      "Epoch [52/100], Loss: 0.6262\n",
      "Validation Loss: 0.6204\n",
      "Epoch [53/100], Loss: 0.6266\n",
      "Validation Loss: 0.6102\n",
      "Epoch [54/100], Loss: 0.6252\n",
      "Validation Loss: 0.6109\n",
      "Epoch [55/100], Loss: 0.6245\n",
      "Validation Loss: 0.6171\n",
      "Epoch [56/100], Loss: 0.6275\n",
      "Validation Loss: 0.6080\n",
      "Epoch [57/100], Loss: 0.6242\n",
      "Validation Loss: 0.6065\n",
      "Epoch [58/100], Loss: 0.6256\n",
      "Validation Loss: 0.6099\n",
      "Epoch [59/100], Loss: 0.6221\n",
      "Validation Loss: 0.6120\n",
      "Epoch [60/100], Loss: 0.6247\n",
      "Validation Loss: 0.6084\n",
      "Epoch [61/100], Loss: 0.6218\n",
      "Validation Loss: 0.6193\n",
      "Epoch [62/100], Loss: 0.6221\n",
      "Validation Loss: 0.6165\n",
      "Epoch [63/100], Loss: 0.6211\n",
      "Validation Loss: 0.6066\n",
      "Epoch [64/100], Loss: 0.6238\n",
      "Validation Loss: 0.6141\n",
      "Epoch [65/100], Loss: 0.6192\n",
      "Validation Loss: 0.6009\n",
      "Saved the best model with validation loss: 0.6009\n",
      "Epoch [66/100], Loss: 0.6194\n",
      "Validation Loss: 0.6181\n",
      "Epoch [67/100], Loss: 0.6207\n",
      "Validation Loss: 0.6043\n",
      "Epoch [68/100], Loss: 0.6181\n",
      "Validation Loss: 0.6130\n",
      "Epoch [69/100], Loss: 0.6223\n",
      "Validation Loss: 0.6151\n",
      "Epoch [70/100], Loss: 0.6172\n",
      "Validation Loss: 0.6080\n",
      "Epoch [71/100], Loss: 0.6227\n",
      "Validation Loss: 0.6170\n",
      "Epoch [72/100], Loss: 0.6184\n",
      "Validation Loss: 0.6088\n",
      "Epoch [73/100], Loss: 0.6177\n",
      "Validation Loss: 0.6057\n",
      "Epoch [74/100], Loss: 0.6180\n",
      "Validation Loss: 0.6129\n",
      "Epoch [75/100], Loss: 0.6201\n",
      "Validation Loss: 0.6161\n",
      "Epoch [76/100], Loss: 0.6206\n",
      "Validation Loss: 0.6252\n",
      "Epoch [77/100], Loss: 0.6174\n",
      "Validation Loss: 0.6205\n",
      "Epoch [78/100], Loss: 0.6187\n",
      "Validation Loss: 0.6276\n",
      "Epoch [79/100], Loss: 0.6174\n",
      "Validation Loss: 0.6297\n",
      "Epoch [80/100], Loss: 0.6173\n",
      "Validation Loss: 0.6359\n",
      "Epoch [81/100], Loss: 0.6205\n",
      "Validation Loss: 0.6244\n",
      "Epoch [82/100], Loss: 0.6163\n",
      "Validation Loss: 0.6189\n",
      "Epoch [83/100], Loss: 0.6172\n",
      "Validation Loss: 0.6127\n",
      "Epoch [84/100], Loss: 0.6169\n",
      "Validation Loss: 0.6144\n",
      "Epoch [85/100], Loss: 0.6138\n",
      "Validation Loss: 0.6045\n",
      "Epoch [86/100], Loss: 0.6137\n",
      "Validation Loss: 0.6096\n",
      "Epoch [87/100], Loss: 0.6139\n",
      "Validation Loss: 0.6100\n",
      "Epoch [88/100], Loss: 0.6142\n",
      "Validation Loss: 0.6082\n",
      "Epoch [89/100], Loss: 0.6166\n",
      "Validation Loss: 0.6122\n",
      "Epoch [90/100], Loss: 0.6164\n",
      "Validation Loss: 0.6033\n",
      "Epoch [91/100], Loss: 0.6125\n",
      "Validation Loss: 0.6061\n",
      "Epoch [92/100], Loss: 0.6136\n",
      "Validation Loss: 0.6096\n",
      "Epoch [93/100], Loss: 0.6146\n",
      "Validation Loss: 0.6214\n",
      "Epoch [94/100], Loss: 0.6156\n",
      "Validation Loss: 0.6039\n",
      "Epoch [95/100], Loss: 0.6146\n",
      "Validation Loss: 0.6074\n",
      "Epoch [96/100], Loss: 0.6167\n",
      "Validation Loss: 0.6101\n",
      "Epoch [97/100], Loss: 0.6146\n",
      "Validation Loss: 0.6100\n",
      "Epoch [98/100], Loss: 0.6151\n",
      "Validation Loss: 0.5969\n",
      "Saved the best model with validation loss: 0.5969\n",
      "Epoch [99/100], Loss: 0.6157\n",
      "Validation Loss: 0.6037\n",
      "Epoch [100/100], Loss: 0.6145\n",
      "Validation Loss: 0.6068\n"
     ]
    }
   ],
   "source": [
    "HGNN_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"HGNN: 1-32-64-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c44ed22",
   "metadata": {},
   "source": [
    "##### HGNN: Version 5\n",
    "*  Layers: 4 (including input and output layer), sizes: 1 - 4 - 16 - 1, kernel: 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "870f43ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "28f79560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.6320\n",
      "Validation Loss: 1.5447\n",
      "Saved the best model with validation loss: 1.5447\n",
      "Epoch [2/100], Loss: 1.2800\n",
      "Validation Loss: 1.0512\n",
      "Saved the best model with validation loss: 1.0512\n",
      "Epoch [3/100], Loss: 0.9992\n",
      "Validation Loss: 0.9252\n",
      "Saved the best model with validation loss: 0.9252\n",
      "Epoch [4/100], Loss: 0.9094\n",
      "Validation Loss: 0.8529\n",
      "Saved the best model with validation loss: 0.8529\n",
      "Epoch [5/100], Loss: 0.8647\n",
      "Validation Loss: 0.8152\n",
      "Saved the best model with validation loss: 0.8152\n",
      "Epoch [6/100], Loss: 0.8314\n",
      "Validation Loss: 0.7912\n",
      "Saved the best model with validation loss: 0.7912\n",
      "Epoch [7/100], Loss: 0.8107\n",
      "Validation Loss: 0.7844\n",
      "Saved the best model with validation loss: 0.7844\n",
      "Epoch [8/100], Loss: 0.7973\n",
      "Validation Loss: 0.7821\n",
      "Saved the best model with validation loss: 0.7821\n",
      "Epoch [9/100], Loss: 0.7875\n",
      "Validation Loss: 0.7727\n",
      "Saved the best model with validation loss: 0.7727\n",
      "Epoch [10/100], Loss: 0.7766\n",
      "Validation Loss: 0.7665\n",
      "Saved the best model with validation loss: 0.7665\n",
      "Epoch [11/100], Loss: 0.7700\n",
      "Validation Loss: 0.7642\n",
      "Saved the best model with validation loss: 0.7642\n",
      "Epoch [12/100], Loss: 0.7633\n",
      "Validation Loss: 0.7503\n",
      "Saved the best model with validation loss: 0.7503\n",
      "Epoch [13/100], Loss: 0.7541\n",
      "Validation Loss: 0.7438\n",
      "Saved the best model with validation loss: 0.7438\n",
      "Epoch [14/100], Loss: 0.7431\n",
      "Validation Loss: 0.7282\n",
      "Saved the best model with validation loss: 0.7282\n",
      "Epoch [15/100], Loss: 0.7352\n",
      "Validation Loss: 0.7195\n",
      "Saved the best model with validation loss: 0.7195\n",
      "Epoch [16/100], Loss: 0.7259\n",
      "Validation Loss: 0.7100\n",
      "Saved the best model with validation loss: 0.7100\n",
      "Epoch [17/100], Loss: 0.7198\n",
      "Validation Loss: 0.7040\n",
      "Saved the best model with validation loss: 0.7040\n",
      "Epoch [18/100], Loss: 0.7148\n",
      "Validation Loss: 0.6978\n",
      "Saved the best model with validation loss: 0.6978\n",
      "Epoch [19/100], Loss: 0.7104\n",
      "Validation Loss: 0.6943\n",
      "Saved the best model with validation loss: 0.6943\n",
      "Epoch [20/100], Loss: 0.7069\n",
      "Validation Loss: 0.6899\n",
      "Saved the best model with validation loss: 0.6899\n",
      "Epoch [21/100], Loss: 0.7038\n",
      "Validation Loss: 0.6957\n",
      "Epoch [22/100], Loss: 0.7010\n",
      "Validation Loss: 0.6938\n",
      "Epoch [23/100], Loss: 0.6995\n",
      "Validation Loss: 0.6807\n",
      "Saved the best model with validation loss: 0.6807\n",
      "Epoch [24/100], Loss: 0.6980\n",
      "Validation Loss: 0.6787\n",
      "Saved the best model with validation loss: 0.6787\n",
      "Epoch [25/100], Loss: 0.6962\n",
      "Validation Loss: 0.6717\n",
      "Saved the best model with validation loss: 0.6717\n",
      "Epoch [26/100], Loss: 0.6935\n",
      "Validation Loss: 0.6771\n",
      "Epoch [27/100], Loss: 0.6896\n",
      "Validation Loss: 0.6730\n",
      "Epoch [28/100], Loss: 0.6892\n",
      "Validation Loss: 0.6641\n",
      "Saved the best model with validation loss: 0.6641\n",
      "Epoch [29/100], Loss: 0.6866\n",
      "Validation Loss: 0.6740\n",
      "Epoch [30/100], Loss: 0.6848\n",
      "Validation Loss: 0.6647\n",
      "Epoch [31/100], Loss: 0.6815\n",
      "Validation Loss: 0.6595\n",
      "Saved the best model with validation loss: 0.6595\n",
      "Epoch [32/100], Loss: 0.6833\n",
      "Validation Loss: 0.6627\n",
      "Epoch [33/100], Loss: 0.6783\n",
      "Validation Loss: 0.6549\n",
      "Saved the best model with validation loss: 0.6549\n",
      "Epoch [34/100], Loss: 0.6778\n",
      "Validation Loss: 0.6538\n",
      "Saved the best model with validation loss: 0.6538\n",
      "Epoch [35/100], Loss: 0.6758\n",
      "Validation Loss: 0.6537\n",
      "Saved the best model with validation loss: 0.6537\n",
      "Epoch [36/100], Loss: 0.6757\n",
      "Validation Loss: 0.6590\n",
      "Epoch [37/100], Loss: 0.6742\n",
      "Validation Loss: 0.6465\n",
      "Saved the best model with validation loss: 0.6465\n",
      "Epoch [38/100], Loss: 0.6726\n",
      "Validation Loss: 0.6535\n",
      "Epoch [39/100], Loss: 0.6715\n",
      "Validation Loss: 0.6406\n",
      "Saved the best model with validation loss: 0.6406\n",
      "Epoch [40/100], Loss: 0.6712\n",
      "Validation Loss: 0.6416\n",
      "Epoch [41/100], Loss: 0.6696\n",
      "Validation Loss: 0.6436\n",
      "Epoch [42/100], Loss: 0.6668\n",
      "Validation Loss: 0.6471\n",
      "Epoch [43/100], Loss: 0.6673\n",
      "Validation Loss: 0.6425\n",
      "Epoch [44/100], Loss: 0.6656\n",
      "Validation Loss: 0.6462\n",
      "Epoch [45/100], Loss: 0.6644\n",
      "Validation Loss: 0.6456\n",
      "Epoch [46/100], Loss: 0.6635\n",
      "Validation Loss: 0.6376\n",
      "Saved the best model with validation loss: 0.6376\n",
      "Epoch [47/100], Loss: 0.6637\n",
      "Validation Loss: 0.6446\n",
      "Epoch [48/100], Loss: 0.6624\n",
      "Validation Loss: 0.6435\n",
      "Epoch [49/100], Loss: 0.6600\n",
      "Validation Loss: 0.6383\n",
      "Epoch [50/100], Loss: 0.6607\n",
      "Validation Loss: 0.6398\n",
      "Epoch [51/100], Loss: 0.6598\n",
      "Validation Loss: 0.6393\n",
      "Epoch [52/100], Loss: 0.6614\n",
      "Validation Loss: 0.6374\n",
      "Saved the best model with validation loss: 0.6374\n",
      "Epoch [53/100], Loss: 0.6615\n",
      "Validation Loss: 0.6327\n",
      "Saved the best model with validation loss: 0.6327\n",
      "Epoch [54/100], Loss: 0.6583\n",
      "Validation Loss: 0.6294\n",
      "Saved the best model with validation loss: 0.6294\n",
      "Epoch [55/100], Loss: 0.6600\n",
      "Validation Loss: 0.6357\n",
      "Epoch [56/100], Loss: 0.6576\n",
      "Validation Loss: 0.6257\n",
      "Saved the best model with validation loss: 0.6257\n",
      "Epoch [57/100], Loss: 0.6592\n",
      "Validation Loss: 0.6376\n",
      "Epoch [58/100], Loss: 0.6568\n",
      "Validation Loss: 0.6366\n",
      "Epoch [59/100], Loss: 0.6572\n",
      "Validation Loss: 0.6312\n",
      "Epoch [60/100], Loss: 0.6571\n",
      "Validation Loss: 0.6351\n",
      "Epoch [61/100], Loss: 0.6550\n",
      "Validation Loss: 0.6292\n",
      "Epoch [62/100], Loss: 0.6555\n",
      "Validation Loss: 0.6266\n",
      "Epoch [63/100], Loss: 0.6567\n",
      "Validation Loss: 0.6222\n",
      "Saved the best model with validation loss: 0.6222\n",
      "Epoch [64/100], Loss: 0.6567\n",
      "Validation Loss: 0.6315\n",
      "Epoch [65/100], Loss: 0.6543\n",
      "Validation Loss: 0.6330\n",
      "Epoch [66/100], Loss: 0.6541\n",
      "Validation Loss: 0.6340\n",
      "Epoch [67/100], Loss: 0.6538\n",
      "Validation Loss: 0.6338\n",
      "Epoch [68/100], Loss: 0.6539\n",
      "Validation Loss: 0.6287\n",
      "Epoch [69/100], Loss: 0.6538\n",
      "Validation Loss: 0.6256\n",
      "Epoch [70/100], Loss: 0.6522\n",
      "Validation Loss: 0.6324\n",
      "Epoch [71/100], Loss: 0.6503\n",
      "Validation Loss: 0.6342\n",
      "Epoch [72/100], Loss: 0.6524\n",
      "Validation Loss: 0.6280\n",
      "Epoch [73/100], Loss: 0.6513\n",
      "Validation Loss: 0.6232\n",
      "Epoch [74/100], Loss: 0.6508\n",
      "Validation Loss: 0.6287\n",
      "Epoch [75/100], Loss: 0.6516\n",
      "Validation Loss: 0.6290\n",
      "Epoch [76/100], Loss: 0.6495\n",
      "Validation Loss: 0.6306\n",
      "Epoch [77/100], Loss: 0.6497\n",
      "Validation Loss: 0.6273\n",
      "Epoch [78/100], Loss: 0.6500\n",
      "Validation Loss: 0.6234\n",
      "Epoch [79/100], Loss: 0.6488\n",
      "Validation Loss: 0.6329\n",
      "Epoch [80/100], Loss: 0.6493\n",
      "Validation Loss: 0.6282\n",
      "Epoch [81/100], Loss: 0.6498\n",
      "Validation Loss: 0.6279\n",
      "Epoch [82/100], Loss: 0.6496\n",
      "Validation Loss: 0.6280\n",
      "Epoch [83/100], Loss: 0.6485\n",
      "Validation Loss: 0.6201\n",
      "Saved the best model with validation loss: 0.6201\n",
      "Epoch [84/100], Loss: 0.6490\n",
      "Validation Loss: 0.6254\n",
      "Epoch [85/100], Loss: 0.6473\n",
      "Validation Loss: 0.6251\n",
      "Epoch [86/100], Loss: 0.6485\n",
      "Validation Loss: 0.6245\n",
      "Epoch [87/100], Loss: 0.6468\n",
      "Validation Loss: 0.6258\n",
      "Epoch [88/100], Loss: 0.6488\n",
      "Validation Loss: 0.6232\n",
      "Epoch [89/100], Loss: 0.6466\n",
      "Validation Loss: 0.6284\n",
      "Epoch [90/100], Loss: 0.6481\n",
      "Validation Loss: 0.6208\n",
      "Epoch [91/100], Loss: 0.6461\n",
      "Validation Loss: 0.6179\n",
      "Saved the best model with validation loss: 0.6179\n",
      "Epoch [92/100], Loss: 0.6463\n",
      "Validation Loss: 0.6185\n",
      "Epoch [93/100], Loss: 0.6479\n",
      "Validation Loss: 0.6168\n",
      "Saved the best model with validation loss: 0.6168\n",
      "Epoch [94/100], Loss: 0.6467\n",
      "Validation Loss: 0.6265\n",
      "Epoch [95/100], Loss: 0.6485\n",
      "Validation Loss: 0.6140\n",
      "Saved the best model with validation loss: 0.6140\n",
      "Epoch [96/100], Loss: 0.6459\n",
      "Validation Loss: 0.6234\n",
      "Epoch [97/100], Loss: 0.6456\n",
      "Validation Loss: 0.6147\n",
      "Epoch [98/100], Loss: 0.6473\n",
      "Validation Loss: 0.6148\n",
      "Epoch [99/100], Loss: 0.6469\n",
      "Validation Loss: 0.6219\n",
      "Epoch [100/100], Loss: 0.6471\n",
      "Validation Loss: 0.6169\n"
     ]
    }
   ],
   "source": [
    "HGNN_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"HGNN: 1-4-16-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "5b602905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.587345</td>\n",
       "      <td>0.486148</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.480216</td>\n",
       "      <td>0.79731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.490544</td>\n",
       "      <td>0.447684</td>\n",
       "      <td>0.827719</td>\n",
       "      <td>0.591385</td>\n",
       "      <td>0.455429</td>\n",
       "      <td>0.812813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.489989</td>\n",
       "      <td>0.448514</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.573214</td>\n",
       "      <td>0.453536</td>\n",
       "      <td>0.818565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>1.696579</td>\n",
       "      <td>0.788013</td>\n",
       "      <td>0.404154</td>\n",
       "      <td>1.859457</td>\n",
       "      <td>0.828425</td>\n",
       "      <td>0.411439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.741289</td>\n",
       "      <td>0.752971</td>\n",
       "      <td>0.388452</td>\n",
       "      <td>1.829105</td>\n",
       "      <td>0.784481</td>\n",
       "      <td>0.421047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.618412</td>\n",
       "      <td>0.724068</td>\n",
       "      <td>0.431607</td>\n",
       "      <td>1.792327</td>\n",
       "      <td>0.772814</td>\n",
       "      <td>0.432687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-1</th>\n",
       "      <td>1.505071</td>\n",
       "      <td>0.867196</td>\n",
       "      <td>0.471413</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-1</th>\n",
       "      <td>1.554706</td>\n",
       "      <td>0.867515</td>\n",
       "      <td>0.453981</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-1</th>\n",
       "      <td>1.451219</td>\n",
       "      <td>0.828152</td>\n",
       "      <td>0.490326</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-1</th>\n",
       "      <td>1.472163</td>\n",
       "      <td>0.836597</td>\n",
       "      <td>0.482970</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-1</th>\n",
       "      <td>1.444209</td>\n",
       "      <td>0.820480</td>\n",
       "      <td>0.492788</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-1</th>\n",
       "      <td>1.411537</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.504262</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-1</th>\n",
       "      <td>1.400415</td>\n",
       "      <td>0.823216</td>\n",
       "      <td>0.508168</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-1</th>\n",
       "      <td>1.345054</td>\n",
       "      <td>0.802008</td>\n",
       "      <td>0.527611</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-1</th>\n",
       "      <td>1.263771</td>\n",
       "      <td>0.772361</td>\n",
       "      <td>0.556158</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-1</th>\n",
       "      <td>1.388075</td>\n",
       "      <td>0.811131</td>\n",
       "      <td>0.512502</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-1</th>\n",
       "      <td>1.009602</td>\n",
       "      <td>0.684272</td>\n",
       "      <td>0.645424</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-1</th>\n",
       "      <td>1.124673</td>\n",
       "      <td>0.718425</td>\n",
       "      <td>0.605010</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-1</th>\n",
       "      <td>1.027500</td>\n",
       "      <td>0.670468</td>\n",
       "      <td>0.639138</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-60-40-1</th>\n",
       "      <td>1.431023</td>\n",
       "      <td>0.786463</td>\n",
       "      <td>0.497419</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-60-40-1</th>\n",
       "      <td>1.403210</td>\n",
       "      <td>0.783605</td>\n",
       "      <td>0.507187</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-60-40-1</th>\n",
       "      <td>1.534875</td>\n",
       "      <td>0.822353</td>\n",
       "      <td>0.460945</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-60-40-1</th>\n",
       "      <td>1.253040</td>\n",
       "      <td>0.759482</td>\n",
       "      <td>0.559927</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-60-40-1</th>\n",
       "      <td>1.458630</td>\n",
       "      <td>0.796491</td>\n",
       "      <td>0.487723</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-60-40-1</th>\n",
       "      <td>1.399672</td>\n",
       "      <td>0.788665</td>\n",
       "      <td>0.508429</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-60-40-1</th>\n",
       "      <td>1.133965</td>\n",
       "      <td>0.721711</td>\n",
       "      <td>0.601747</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-1</th>\n",
       "      <td>0.611047</td>\n",
       "      <td>0.506354</td>\n",
       "      <td>0.785398</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-1</th>\n",
       "      <td>0.660738</td>\n",
       "      <td>0.533360</td>\n",
       "      <td>0.767946</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-1</th>\n",
       "      <td>0.599189</td>\n",
       "      <td>0.501551</td>\n",
       "      <td>0.789562</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-1</th>\n",
       "      <td>0.596895</td>\n",
       "      <td>0.491947</td>\n",
       "      <td>0.790368</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-1</th>\n",
       "      <td>0.613998</td>\n",
       "      <td>0.511419</td>\n",
       "      <td>0.784361</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   MSE       MAE        R2       MSE  \\\n",
       "5-NN                          0.587345  0.486148  0.793722  0.640365   \n",
       "Decision tree                 0.490544  0.447684  0.827719  0.591385   \n",
       "Random forest                 0.489989  0.448514  0.827914  0.573214   \n",
       "SVM linear                    1.696579  0.788013  0.404154  1.859457   \n",
       "SVM poly                      1.741289  0.752971  0.388452  1.829105   \n",
       "SVM rbf                       1.618412  0.724068  0.431607  1.792327   \n",
       "MLP: 17-5-1                   1.505071  0.867196  0.471413         -   \n",
       "MLP: 17-10-1                  1.554706  0.867515  0.453981         -   \n",
       "MLP: 17-20-1                  1.451219  0.828152  0.490326         -   \n",
       "MLP: 17-25-1                  1.472163  0.836597  0.482970         -   \n",
       "MLP: 17-40-1                  1.444209  0.820480  0.492788         -   \n",
       "MLP: 17-60-1                  1.411537  0.821209  0.504262         -   \n",
       "MLP: 17-10-5-1                1.400415  0.823216  0.508168         -   \n",
       "MLP: 17-20-10-1               1.345054  0.802008  0.527611         -   \n",
       "MLP: 17-40-20-1               1.263771  0.772361  0.556158         -   \n",
       "MLP: 17-40-10-1               1.388075  0.811131  0.512502         -   \n",
       "MLP: 17-60-40-1               1.009602  0.684272  0.645424         -   \n",
       "MLP: 17-60-20-1               1.124673  0.718425  0.605010         -   \n",
       "MLP: 17-80-50-1               1.027500  0.670468  0.639138         -   \n",
       "MLP, small-median: 7-60-40-1  1.431023  0.786463  0.497419         -   \n",
       "MLP, small-mean: 7-60-40-1    1.403210  0.783605  0.507187         -   \n",
       "MLP, small-min: 7-60-40-1     1.534875  0.822353  0.460945         -   \n",
       "MLP, small-max: 7-60-40-1     1.253040  0.759482  0.559927         -   \n",
       "MLP, small-q25: 7-60-40-1     1.458630  0.796491  0.487723         -   \n",
       "MLP, small-q75: 7-60-40-1     1.399672  0.788665  0.508429         -   \n",
       "MLP, custom: 7-60-40-1        1.133965  0.721711  0.601747         -   \n",
       "HGNN: 1-16-32-1               0.611047  0.506354  0.785398         -   \n",
       "HGNN: 1-32-16-1               0.660738  0.533360  0.767946         -   \n",
       "HGNN: 1-16-32-16-1            0.599189  0.501551  0.789562         -   \n",
       "HGNN: 1-32-64-1               0.596895  0.491947  0.790368         -   \n",
       "HGNN: 1-4-16-1                0.613998  0.511419  0.784361         -   \n",
       "\n",
       "                                   MAE        R2  \n",
       "5-NN                          0.480216   0.79731  \n",
       "Decision tree                 0.455429  0.812813  \n",
       "Random forest                 0.453536  0.818565  \n",
       "SVM linear                    0.828425  0.411439  \n",
       "SVM poly                      0.784481  0.421047  \n",
       "SVM rbf                       0.772814  0.432687  \n",
       "MLP: 17-5-1                          -         -  \n",
       "MLP: 17-10-1                         -         -  \n",
       "MLP: 17-20-1                         -         -  \n",
       "MLP: 17-25-1                         -         -  \n",
       "MLP: 17-40-1                         -         -  \n",
       "MLP: 17-60-1                         -         -  \n",
       "MLP: 17-10-5-1                       -         -  \n",
       "MLP: 17-20-10-1                      -         -  \n",
       "MLP: 17-40-20-1                      -         -  \n",
       "MLP: 17-40-10-1                      -         -  \n",
       "MLP: 17-60-40-1                      -         -  \n",
       "MLP: 17-60-20-1                      -         -  \n",
       "MLP: 17-80-50-1                      -         -  \n",
       "MLP, small-median: 7-60-40-1         -         -  \n",
       "MLP, small-mean: 7-60-40-1           -         -  \n",
       "MLP, small-min: 7-60-40-1            -         -  \n",
       "MLP, small-max: 7-60-40-1            -         -  \n",
       "MLP, small-q25: 7-60-40-1            -         -  \n",
       "MLP, small-q75: 7-60-40-1            -         -  \n",
       "MLP, custom: 7-60-40-1               -         -  \n",
       "HGNN: 1-16-32-1                      -         -  \n",
       "HGNN: 1-32-16-1                      -         -  \n",
       "HGNN: 1-16-32-16-1                   -         -  \n",
       "HGNN: 1-32-64-1                      -         -  \n",
       "HGNN: 1-4-16-1                       -         -  "
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "e3f3ea2c-7ddb-4990-8c8d-ca557c63f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2_classes.to_csv('results/table_2_classes_DDB_rounded.csv', index=True)\n",
    "table_3_classes.to_csv('results/table_3_classes_DDB_rounded.csv', index=True)\n",
    "table_time_diff.to_csv('results/table_time_diff_DDB_rounded.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f2e9a-cee8-4538-b0fc-ddc20a1445c8",
   "metadata": {},
   "source": [
    "### Combined HGNN+MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24d18a-bd68-4698-9148-95f4d5bab39f",
   "metadata": {},
   "source": [
    "Taking the best MLP and the best HGNN and combining their output with an additional MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "96c82e80-b7d5-4eb9-9178-cfa94dedd41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, label_series, hypergraph_column_name):\n",
    "        # Extract features and convert to tensor\n",
    "        self.X = torch.from_numpy(dataframe.drop(columns=[hypergraph_column_name]).values).float()\n",
    "        \n",
    "        # Extract labels and convert to tensor\n",
    "        self.y = torch.from_numpy(label_series.values).float()\n",
    "        \n",
    "        # Store hypergraph objects\n",
    "        self.hypergraphs = dataframe[hypergraph_column_name].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.X[index],\n",
    "            'label': self.y[index],\n",
    "            'hypergraph': self.hypergraphs[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "da7817ac-52c3-4f3c-a254-1c332f24be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_classification(X_training, y_training, X_validation, y_validation, type, text):\n",
    "    model = CombinedNetwork(random_seed = 20)  \n",
    "\n",
    "    dataset = CustomDataset(X_training, y_training, hypergraph_column_name='hypergraph')\n",
    "    validation = CustomDataset(X_validation, y_validation, hypergraph_column_name='hypergraph')\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for item in dataset:\n",
    "            optimizer.zero_grad()\n",
    "            input_features = item[\"data\"]\n",
    "            input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "            label = item[\"label\"].long()\n",
    "            output = model(input_features, input_hg)\n",
    "            \n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataset):.4f}')\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for item in validation:\n",
    "                input_features = item[\"data\"]\n",
    "                input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "                label = item[\"label\"].long()\n",
    "                output = model(input_features, input_hg)\n",
    "                loss = loss_function(output, label)\n",
    "                val_loss += loss.item()\n",
    "    \n",
    "        val_loss /= len(validation)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "        # Save the model if the validation loss is the best we've seen so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Saved the best model with validation loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for item in validation:\n",
    "            i += 1\n",
    "            output = model(item[\"data\"], item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0))\n",
    "            _, pred = torch.max(output.data, 0)\n",
    "            predicted.append(pred.item())\n",
    "\n",
    "    if type == \"2_class\":\n",
    "        accuracy = accuracy_score(y_validation, predicted)\n",
    "        recall = recall_score(y_validation, predicted)\n",
    "        conf_matrix = confusion_matrix(y_validation, predicted)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_2_classes.loc[text] = [accuracy, recall, \"-\", \"-\"]\n",
    "\n",
    "    if type == \"3_class\":\n",
    "        accuracy = accuracy_score(y_validation, predicted)\n",
    "        recall_micro = recall_score(y_validation, predicted, average='micro')\n",
    "        recall_macro = recall_score(y_validation, predicted, average='macro')\n",
    "        conf_matrix = confusion_matrix(y_validation, predicted)\n",
    "        conf_matrix\n",
    "        \n",
    "        table_3_classes.loc[text] = [accuracy, recall_micro, recall_macro, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ee190-706a-4aec-971d-e5da3bbc6018",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 1\n",
    "*  MLP 17-80-50-2\n",
    "*  HGNN 1-32-64-2\n",
    "*  Combined 4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "7815966c-c67f-4bdb-b4f5-0ce118f314ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(4, 2)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "188d1cd2-3bf0-4a7b-8768-aac909a50d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5724\n",
      "Validation Loss: 0.4373\n",
      "Saved the best model with validation loss: 0.4373\n",
      "Epoch [2/100], Loss: 0.4390\n",
      "Validation Loss: 0.4012\n",
      "Saved the best model with validation loss: 0.4012\n",
      "Epoch [3/100], Loss: 0.4130\n",
      "Validation Loss: 0.3866\n",
      "Saved the best model with validation loss: 0.3866\n",
      "Epoch [4/100], Loss: 0.3995\n",
      "Validation Loss: 0.3778\n",
      "Saved the best model with validation loss: 0.3778\n",
      "Epoch [5/100], Loss: 0.3919\n",
      "Validation Loss: 0.3693\n",
      "Saved the best model with validation loss: 0.3693\n",
      "Epoch [6/100], Loss: 0.3867\n",
      "Validation Loss: 0.3724\n",
      "Epoch [7/100], Loss: 0.3824\n",
      "Validation Loss: 0.3678\n",
      "Saved the best model with validation loss: 0.3678\n",
      "Epoch [8/100], Loss: 0.3787\n",
      "Validation Loss: 0.3711\n",
      "Epoch [9/100], Loss: 0.3775\n",
      "Validation Loss: 0.3607\n",
      "Saved the best model with validation loss: 0.3607\n",
      "Epoch [10/100], Loss: 0.3745\n",
      "Validation Loss: 0.3597\n",
      "Saved the best model with validation loss: 0.3597\n",
      "Epoch [11/100], Loss: 0.3710\n",
      "Validation Loss: 0.3591\n",
      "Saved the best model with validation loss: 0.3591\n",
      "Epoch [12/100], Loss: 0.3712\n",
      "Validation Loss: 0.3573\n",
      "Saved the best model with validation loss: 0.3573\n",
      "Epoch [13/100], Loss: 0.3693\n",
      "Validation Loss: 0.3540\n",
      "Saved the best model with validation loss: 0.3540\n",
      "Epoch [14/100], Loss: 0.3687\n",
      "Validation Loss: 0.3542\n",
      "Epoch [15/100], Loss: 0.3672\n",
      "Validation Loss: 0.3525\n",
      "Saved the best model with validation loss: 0.3525\n",
      "Epoch [16/100], Loss: 0.3661\n",
      "Validation Loss: 0.3532\n",
      "Epoch [17/100], Loss: 0.3652\n",
      "Validation Loss: 0.3524\n",
      "Saved the best model with validation loss: 0.3524\n",
      "Epoch [18/100], Loss: 0.3642\n",
      "Validation Loss: 0.3487\n",
      "Saved the best model with validation loss: 0.3487\n",
      "Epoch [19/100], Loss: 0.3622\n",
      "Validation Loss: 0.3481\n",
      "Saved the best model with validation loss: 0.3481\n",
      "Epoch [20/100], Loss: 0.3624\n",
      "Validation Loss: 0.3486\n",
      "Epoch [21/100], Loss: 0.3621\n",
      "Validation Loss: 0.3480\n",
      "Saved the best model with validation loss: 0.3480\n",
      "Epoch [22/100], Loss: 0.3609\n",
      "Validation Loss: 0.3539\n",
      "Epoch [23/100], Loss: 0.3599\n",
      "Validation Loss: 0.3478\n",
      "Saved the best model with validation loss: 0.3478\n",
      "Epoch [24/100], Loss: 0.3610\n",
      "Validation Loss: 0.3478\n",
      "Saved the best model with validation loss: 0.3478\n",
      "Epoch [25/100], Loss: 0.3595\n",
      "Validation Loss: 0.3519\n",
      "Epoch [26/100], Loss: 0.3593\n",
      "Validation Loss: 0.3495\n",
      "Epoch [27/100], Loss: 0.3598\n",
      "Validation Loss: 0.3511\n",
      "Epoch [28/100], Loss: 0.3589\n",
      "Validation Loss: 0.3498\n",
      "Epoch [29/100], Loss: 0.3583\n",
      "Validation Loss: 0.3491\n",
      "Epoch [30/100], Loss: 0.3566\n",
      "Validation Loss: 0.3501\n",
      "Epoch [31/100], Loss: 0.3571\n",
      "Validation Loss: 0.3542\n",
      "Epoch [32/100], Loss: 0.3579\n",
      "Validation Loss: 0.3516\n",
      "Epoch [33/100], Loss: 0.3555\n",
      "Validation Loss: 0.3467\n",
      "Saved the best model with validation loss: 0.3467\n",
      "Epoch [34/100], Loss: 0.3577\n",
      "Validation Loss: 0.3497\n",
      "Epoch [35/100], Loss: 0.3555\n",
      "Validation Loss: 0.3493\n",
      "Epoch [36/100], Loss: 0.3549\n",
      "Validation Loss: 0.3485\n",
      "Epoch [37/100], Loss: 0.3561\n",
      "Validation Loss: 0.3483\n",
      "Epoch [38/100], Loss: 0.3534\n",
      "Validation Loss: 0.3504\n",
      "Epoch [39/100], Loss: 0.3532\n",
      "Validation Loss: 0.3456\n",
      "Saved the best model with validation loss: 0.3456\n",
      "Epoch [40/100], Loss: 0.3539\n",
      "Validation Loss: 0.3468\n",
      "Epoch [41/100], Loss: 0.3528\n",
      "Validation Loss: 0.3496\n",
      "Epoch [42/100], Loss: 0.3523\n",
      "Validation Loss: 0.3517\n",
      "Epoch [43/100], Loss: 0.3521\n",
      "Validation Loss: 0.3456\n",
      "Epoch [44/100], Loss: 0.3515\n",
      "Validation Loss: 0.3477\n",
      "Epoch [45/100], Loss: 0.3513\n",
      "Validation Loss: 0.3474\n",
      "Epoch [46/100], Loss: 0.3519\n",
      "Validation Loss: 0.3441\n",
      "Saved the best model with validation loss: 0.3441\n",
      "Epoch [47/100], Loss: 0.3520\n",
      "Validation Loss: 0.3431\n",
      "Saved the best model with validation loss: 0.3431\n",
      "Epoch [48/100], Loss: 0.3509\n",
      "Validation Loss: 0.3443\n",
      "Epoch [49/100], Loss: 0.3494\n",
      "Validation Loss: 0.3436\n",
      "Epoch [50/100], Loss: 0.3501\n",
      "Validation Loss: 0.3447\n",
      "Epoch [51/100], Loss: 0.3499\n",
      "Validation Loss: 0.3416\n",
      "Saved the best model with validation loss: 0.3416\n",
      "Epoch [52/100], Loss: 0.3485\n",
      "Validation Loss: 0.3429\n",
      "Epoch [53/100], Loss: 0.3480\n",
      "Validation Loss: 0.3446\n",
      "Epoch [54/100], Loss: 0.3482\n",
      "Validation Loss: 0.3426\n",
      "Epoch [55/100], Loss: 0.3484\n",
      "Validation Loss: 0.3411\n",
      "Saved the best model with validation loss: 0.3411\n",
      "Epoch [56/100], Loss: 0.3499\n",
      "Validation Loss: 0.3441\n",
      "Epoch [57/100], Loss: 0.3472\n",
      "Validation Loss: 0.3496\n",
      "Epoch [58/100], Loss: 0.3476\n",
      "Validation Loss: 0.3468\n",
      "Epoch [59/100], Loss: 0.3472\n",
      "Validation Loss: 0.3462\n",
      "Epoch [60/100], Loss: 0.3470\n",
      "Validation Loss: 0.3469\n",
      "Epoch [61/100], Loss: 0.3464\n",
      "Validation Loss: 0.3466\n",
      "Epoch [62/100], Loss: 0.3462\n",
      "Validation Loss: 0.3511\n",
      "Epoch [63/100], Loss: 0.3463\n",
      "Validation Loss: 0.3466\n",
      "Epoch [64/100], Loss: 0.3454\n",
      "Validation Loss: 0.3476\n",
      "Epoch [65/100], Loss: 0.3460\n",
      "Validation Loss: 0.3463\n",
      "Epoch [66/100], Loss: 0.3441\n",
      "Validation Loss: 0.3465\n",
      "Epoch [67/100], Loss: 0.3467\n",
      "Validation Loss: 0.3465\n",
      "Epoch [68/100], Loss: 0.3450\n",
      "Validation Loss: 0.3496\n",
      "Epoch [69/100], Loss: 0.3460\n",
      "Validation Loss: 0.3468\n",
      "Epoch [70/100], Loss: 0.3445\n",
      "Validation Loss: 0.3484\n",
      "Epoch [71/100], Loss: 0.3443\n",
      "Validation Loss: 0.3487\n",
      "Epoch [72/100], Loss: 0.3439\n",
      "Validation Loss: 0.3465\n",
      "Epoch [73/100], Loss: 0.3442\n",
      "Validation Loss: 0.3448\n",
      "Epoch [74/100], Loss: 0.3445\n",
      "Validation Loss: 0.3451\n",
      "Epoch [75/100], Loss: 0.3442\n",
      "Validation Loss: 0.3470\n",
      "Epoch [76/100], Loss: 0.3440\n",
      "Validation Loss: 0.3456\n",
      "Epoch [77/100], Loss: 0.3422\n",
      "Validation Loss: 0.3482\n",
      "Epoch [78/100], Loss: 0.3434\n",
      "Validation Loss: 0.3490\n",
      "Epoch [79/100], Loss: 0.3431\n",
      "Validation Loss: 0.3450\n",
      "Epoch [80/100], Loss: 0.3419\n",
      "Validation Loss: 0.3457\n",
      "Epoch [81/100], Loss: 0.3423\n",
      "Validation Loss: 0.3467\n",
      "Epoch [82/100], Loss: 0.3407\n",
      "Validation Loss: 0.3464\n",
      "Epoch [83/100], Loss: 0.3426\n",
      "Validation Loss: 0.3469\n",
      "Epoch [84/100], Loss: 0.3418\n",
      "Validation Loss: 0.3496\n",
      "Epoch [85/100], Loss: 0.3415\n",
      "Validation Loss: 0.3474\n",
      "Epoch [86/100], Loss: 0.3417\n",
      "Validation Loss: 0.3466\n",
      "Epoch [87/100], Loss: 0.3414\n",
      "Validation Loss: 0.3457\n",
      "Epoch [88/100], Loss: 0.3414\n",
      "Validation Loss: 0.3461\n",
      "Epoch [89/100], Loss: 0.3399\n",
      "Validation Loss: 0.3446\n",
      "Epoch [90/100], Loss: 0.3404\n",
      "Validation Loss: 0.3455\n",
      "Epoch [91/100], Loss: 0.3398\n",
      "Validation Loss: 0.3468\n",
      "Epoch [92/100], Loss: 0.3400\n",
      "Validation Loss: 0.3461\n",
      "Epoch [93/100], Loss: 0.3381\n",
      "Validation Loss: 0.3478\n",
      "Epoch [94/100], Loss: 0.3397\n",
      "Validation Loss: 0.3481\n",
      "Epoch [95/100], Loss: 0.3388\n",
      "Validation Loss: 0.3471\n",
      "Epoch [96/100], Loss: 0.3396\n",
      "Validation Loss: 0.3452\n",
      "Epoch [97/100], Loss: 0.3396\n",
      "Validation Loss: 0.3472\n",
      "Epoch [98/100], Loss: 0.3394\n",
      "Validation Loss: 0.3452\n",
      "Epoch [99/100], Loss: 0.3392\n",
      "Validation Loss: 0.3442\n",
      "Epoch [100/100], Loss: 0.3392\n",
      "Validation Loss: 0.3433\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"combi: 17-80-40-2/1-32-64-2/4-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6e56f4-8c34-4da2-afa7-eb75ac25c83b",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 2\n",
    "*  MLP 17-80-50-5\n",
    "*  HGNN 1-32-64-5\n",
    "*  Combined 10-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "57327689-8edb-47e5-9236-f570d0e51f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "4570b6bd-4cc4-422f-a225-fb99abdec0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5735\n",
      "Validation Loss: 0.4295\n",
      "Saved the best model with validation loss: 0.4295\n",
      "Epoch [2/100], Loss: 0.4385\n",
      "Validation Loss: 0.3973\n",
      "Saved the best model with validation loss: 0.3973\n",
      "Epoch [3/100], Loss: 0.4133\n",
      "Validation Loss: 0.3861\n",
      "Saved the best model with validation loss: 0.3861\n",
      "Epoch [4/100], Loss: 0.4001\n",
      "Validation Loss: 0.3745\n",
      "Saved the best model with validation loss: 0.3745\n",
      "Epoch [5/100], Loss: 0.3938\n",
      "Validation Loss: 0.3699\n",
      "Saved the best model with validation loss: 0.3699\n",
      "Epoch [6/100], Loss: 0.3859\n",
      "Validation Loss: 0.3647\n",
      "Saved the best model with validation loss: 0.3647\n",
      "Epoch [7/100], Loss: 0.3818\n",
      "Validation Loss: 0.3625\n",
      "Saved the best model with validation loss: 0.3625\n",
      "Epoch [8/100], Loss: 0.3794\n",
      "Validation Loss: 0.3582\n",
      "Saved the best model with validation loss: 0.3582\n",
      "Epoch [9/100], Loss: 0.3773\n",
      "Validation Loss: 0.3628\n",
      "Epoch [10/100], Loss: 0.3762\n",
      "Validation Loss: 0.3623\n",
      "Epoch [11/100], Loss: 0.3742\n",
      "Validation Loss: 0.3640\n",
      "Epoch [12/100], Loss: 0.3729\n",
      "Validation Loss: 0.3585\n",
      "Epoch [13/100], Loss: 0.3698\n",
      "Validation Loss: 0.3564\n",
      "Saved the best model with validation loss: 0.3564\n",
      "Epoch [14/100], Loss: 0.3675\n",
      "Validation Loss: 0.3571\n",
      "Epoch [15/100], Loss: 0.3666\n",
      "Validation Loss: 0.3560\n",
      "Saved the best model with validation loss: 0.3560\n",
      "Epoch [16/100], Loss: 0.3669\n",
      "Validation Loss: 0.3596\n",
      "Epoch [17/100], Loss: 0.3647\n",
      "Validation Loss: 0.3647\n",
      "Epoch [18/100], Loss: 0.3647\n",
      "Validation Loss: 0.3552\n",
      "Saved the best model with validation loss: 0.3552\n",
      "Epoch [19/100], Loss: 0.3644\n",
      "Validation Loss: 0.3563\n",
      "Epoch [20/100], Loss: 0.3629\n",
      "Validation Loss: 0.3531\n",
      "Saved the best model with validation loss: 0.3531\n",
      "Epoch [21/100], Loss: 0.3623\n",
      "Validation Loss: 0.3524\n",
      "Saved the best model with validation loss: 0.3524\n",
      "Epoch [22/100], Loss: 0.3606\n",
      "Validation Loss: 0.3538\n",
      "Epoch [23/100], Loss: 0.3599\n",
      "Validation Loss: 0.3522\n",
      "Saved the best model with validation loss: 0.3522\n",
      "Epoch [24/100], Loss: 0.3592\n",
      "Validation Loss: 0.3581\n",
      "Epoch [25/100], Loss: 0.3577\n",
      "Validation Loss: 0.3610\n",
      "Epoch [26/100], Loss: 0.3590\n",
      "Validation Loss: 0.3606\n",
      "Epoch [27/100], Loss: 0.3551\n",
      "Validation Loss: 0.3588\n",
      "Epoch [28/100], Loss: 0.3547\n",
      "Validation Loss: 0.3756\n",
      "Epoch [29/100], Loss: 0.3562\n",
      "Validation Loss: 0.3597\n",
      "Epoch [30/100], Loss: 0.3536\n",
      "Validation Loss: 0.3585\n",
      "Epoch [31/100], Loss: 0.3529\n",
      "Validation Loss: 0.3616\n",
      "Epoch [32/100], Loss: 0.3536\n",
      "Validation Loss: 0.3576\n",
      "Epoch [33/100], Loss: 0.3530\n",
      "Validation Loss: 0.3614\n",
      "Epoch [34/100], Loss: 0.3528\n",
      "Validation Loss: 0.3574\n",
      "Epoch [35/100], Loss: 0.3526\n",
      "Validation Loss: 0.3546\n",
      "Epoch [36/100], Loss: 0.3510\n",
      "Validation Loss: 0.3574\n",
      "Epoch [37/100], Loss: 0.3510\n",
      "Validation Loss: 0.3548\n",
      "Epoch [38/100], Loss: 0.3493\n",
      "Validation Loss: 0.3533\n",
      "Epoch [39/100], Loss: 0.3502\n",
      "Validation Loss: 0.3540\n",
      "Epoch [40/100], Loss: 0.3502\n",
      "Validation Loss: 0.3529\n",
      "Epoch [41/100], Loss: 0.3494\n",
      "Validation Loss: 0.3565\n",
      "Epoch [42/100], Loss: 0.3507\n",
      "Validation Loss: 0.3555\n",
      "Epoch [43/100], Loss: 0.3503\n",
      "Validation Loss: 0.3550\n",
      "Epoch [44/100], Loss: 0.3485\n",
      "Validation Loss: 0.3578\n",
      "Epoch [45/100], Loss: 0.3483\n",
      "Validation Loss: 0.3569\n",
      "Epoch [46/100], Loss: 0.3487\n",
      "Validation Loss: 0.3547\n",
      "Epoch [47/100], Loss: 0.3481\n",
      "Validation Loss: 0.3626\n",
      "Epoch [48/100], Loss: 0.3471\n",
      "Validation Loss: 0.3571\n",
      "Epoch [49/100], Loss: 0.3452\n",
      "Validation Loss: 0.3661\n",
      "Epoch [50/100], Loss: 0.3460\n",
      "Validation Loss: 0.3637\n",
      "Epoch [51/100], Loss: 0.3457\n",
      "Validation Loss: 0.3659\n",
      "Epoch [52/100], Loss: 0.3457\n",
      "Validation Loss: 0.3629\n",
      "Epoch [53/100], Loss: 0.3458\n",
      "Validation Loss: 0.3645\n",
      "Epoch [54/100], Loss: 0.3445\n",
      "Validation Loss: 0.3699\n",
      "Epoch [55/100], Loss: 0.3453\n",
      "Validation Loss: 0.3688\n",
      "Epoch [56/100], Loss: 0.3455\n",
      "Validation Loss: 0.3630\n",
      "Epoch [57/100], Loss: 0.3451\n",
      "Validation Loss: 0.3589\n",
      "Epoch [58/100], Loss: 0.3439\n",
      "Validation Loss: 0.3624\n",
      "Epoch [59/100], Loss: 0.3446\n",
      "Validation Loss: 0.3562\n",
      "Epoch [60/100], Loss: 0.3466\n",
      "Validation Loss: 0.3563\n",
      "Epoch [61/100], Loss: 0.3451\n",
      "Validation Loss: 0.3566\n",
      "Epoch [62/100], Loss: 0.3436\n",
      "Validation Loss: 0.3568\n",
      "Epoch [63/100], Loss: 0.3437\n",
      "Validation Loss: 0.3582\n",
      "Epoch [64/100], Loss: 0.3431\n",
      "Validation Loss: 0.3565\n",
      "Epoch [65/100], Loss: 0.3421\n",
      "Validation Loss: 0.3597\n",
      "Epoch [66/100], Loss: 0.3439\n",
      "Validation Loss: 0.3684\n",
      "Epoch [67/100], Loss: 0.3415\n",
      "Validation Loss: 0.3659\n",
      "Epoch [68/100], Loss: 0.3423\n",
      "Validation Loss: 0.3657\n",
      "Epoch [69/100], Loss: 0.3413\n",
      "Validation Loss: 0.3668\n",
      "Epoch [70/100], Loss: 0.3419\n",
      "Validation Loss: 0.3753\n",
      "Epoch [71/100], Loss: 0.3412\n",
      "Validation Loss: 0.3696\n",
      "Epoch [72/100], Loss: 0.3394\n",
      "Validation Loss: 0.3707\n",
      "Epoch [73/100], Loss: 0.3408\n",
      "Validation Loss: 0.3732\n",
      "Epoch [74/100], Loss: 0.3407\n",
      "Validation Loss: 0.3693\n",
      "Epoch [75/100], Loss: 0.3399\n",
      "Validation Loss: 0.3698\n",
      "Epoch [76/100], Loss: 0.3425\n",
      "Validation Loss: 0.3677\n",
      "Epoch [77/100], Loss: 0.3416\n",
      "Validation Loss: 0.3678\n",
      "Epoch [78/100], Loss: 0.3413\n",
      "Validation Loss: 0.3649\n",
      "Epoch [79/100], Loss: 0.3407\n",
      "Validation Loss: 0.3689\n",
      "Epoch [80/100], Loss: 0.3403\n",
      "Validation Loss: 0.3699\n",
      "Epoch [81/100], Loss: 0.3399\n",
      "Validation Loss: 0.3681\n",
      "Epoch [82/100], Loss: 0.3390\n",
      "Validation Loss: 0.3658\n",
      "Epoch [83/100], Loss: 0.3403\n",
      "Validation Loss: 0.3684\n",
      "Epoch [84/100], Loss: 0.3399\n",
      "Validation Loss: 0.3671\n",
      "Epoch [85/100], Loss: 0.3404\n",
      "Validation Loss: 0.3701\n",
      "Epoch [86/100], Loss: 0.3388\n",
      "Validation Loss: 0.3737\n",
      "Epoch [87/100], Loss: 0.3391\n",
      "Validation Loss: 0.3724\n",
      "Epoch [88/100], Loss: 0.3379\n",
      "Validation Loss: 0.3762\n",
      "Epoch [89/100], Loss: 0.3381\n",
      "Validation Loss: 0.3819\n",
      "Epoch [90/100], Loss: 0.3375\n",
      "Validation Loss: 0.3777\n",
      "Epoch [91/100], Loss: 0.3380\n",
      "Validation Loss: 0.3807\n",
      "Epoch [92/100], Loss: 0.3382\n",
      "Validation Loss: 0.3785\n",
      "Epoch [93/100], Loss: 0.3384\n",
      "Validation Loss: 0.3748\n",
      "Epoch [94/100], Loss: 0.3392\n",
      "Validation Loss: 0.3763\n",
      "Epoch [95/100], Loss: 0.3392\n",
      "Validation Loss: 0.3733\n",
      "Epoch [96/100], Loss: 0.3377\n",
      "Validation Loss: 0.3695\n",
      "Epoch [97/100], Loss: 0.3379\n",
      "Validation Loss: 0.3719\n",
      "Epoch [98/100], Loss: 0.3382\n",
      "Validation Loss: 0.3705\n",
      "Epoch [99/100], Loss: 0.3376\n",
      "Validation Loss: 0.3713\n",
      "Epoch [100/100], Loss: 0.3382\n",
      "Validation Loss: 0.3644\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"combi: 17-80-50-5/1-32-64-5/10-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7efab64-d410-48eb-9c1e-fd545b6b2c05",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 3\n",
    "*  MLP 17-80-50-5\n",
    "*  HGNN 1-32-64-5\n",
    "*  Combined 10-20-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "2fcd6ff8-da22-4b8b-a056-a0b4d5c4546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "84553275-43ea-4b4b-a1ba-f3439b4044c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5888\n",
      "Validation Loss: 0.4390\n",
      "Saved the best model with validation loss: 0.4390\n",
      "Epoch [2/100], Loss: 0.4451\n",
      "Validation Loss: 0.3977\n",
      "Saved the best model with validation loss: 0.3977\n",
      "Epoch [3/100], Loss: 0.4195\n",
      "Validation Loss: 0.3756\n",
      "Saved the best model with validation loss: 0.3756\n",
      "Epoch [4/100], Loss: 0.4047\n",
      "Validation Loss: 0.3728\n",
      "Saved the best model with validation loss: 0.3728\n",
      "Epoch [5/100], Loss: 0.3979\n",
      "Validation Loss: 0.3670\n",
      "Saved the best model with validation loss: 0.3670\n",
      "Epoch [6/100], Loss: 0.3909\n",
      "Validation Loss: 0.3649\n",
      "Saved the best model with validation loss: 0.3649\n",
      "Epoch [7/100], Loss: 0.3869\n",
      "Validation Loss: 0.3638\n",
      "Saved the best model with validation loss: 0.3638\n",
      "Epoch [8/100], Loss: 0.3832\n",
      "Validation Loss: 0.3603\n",
      "Saved the best model with validation loss: 0.3603\n",
      "Epoch [9/100], Loss: 0.3797\n",
      "Validation Loss: 0.3673\n",
      "Epoch [10/100], Loss: 0.3775\n",
      "Validation Loss: 0.3527\n",
      "Saved the best model with validation loss: 0.3527\n",
      "Epoch [11/100], Loss: 0.3744\n",
      "Validation Loss: 0.3416\n",
      "Saved the best model with validation loss: 0.3416\n",
      "Epoch [12/100], Loss: 0.3732\n",
      "Validation Loss: 0.3487\n",
      "Epoch [13/100], Loss: 0.3689\n",
      "Validation Loss: 0.3627\n",
      "Epoch [14/100], Loss: 0.3654\n",
      "Validation Loss: 0.3423\n",
      "Epoch [15/100], Loss: 0.3649\n",
      "Validation Loss: 0.3492\n",
      "Epoch [16/100], Loss: 0.3660\n",
      "Validation Loss: 0.3454\n",
      "Epoch [17/100], Loss: 0.3620\n",
      "Validation Loss: 0.3540\n",
      "Epoch [18/100], Loss: 0.3599\n",
      "Validation Loss: 0.3554\n",
      "Epoch [19/100], Loss: 0.3568\n",
      "Validation Loss: 0.3559\n",
      "Epoch [20/100], Loss: 0.3570\n",
      "Validation Loss: 0.3413\n",
      "Saved the best model with validation loss: 0.3413\n",
      "Epoch [21/100], Loss: 0.3548\n",
      "Validation Loss: 0.3524\n",
      "Epoch [22/100], Loss: 0.3513\n",
      "Validation Loss: 0.3630\n",
      "Epoch [23/100], Loss: 0.3494\n",
      "Validation Loss: 0.3650\n",
      "Epoch [24/100], Loss: 0.3463\n",
      "Validation Loss: 0.3587\n",
      "Epoch [25/100], Loss: 0.3453\n",
      "Validation Loss: 0.3588\n",
      "Epoch [26/100], Loss: 0.3431\n",
      "Validation Loss: 0.3482\n",
      "Epoch [27/100], Loss: 0.3453\n",
      "Validation Loss: 0.3488\n",
      "Epoch [28/100], Loss: 0.3393\n",
      "Validation Loss: 0.3464\n",
      "Epoch [29/100], Loss: 0.3413\n",
      "Validation Loss: 0.3800\n",
      "Epoch [30/100], Loss: 0.3393\n",
      "Validation Loss: 0.3426\n",
      "Epoch [31/100], Loss: 0.3377\n",
      "Validation Loss: 0.3620\n",
      "Epoch [32/100], Loss: 0.3368\n",
      "Validation Loss: 0.3550\n",
      "Epoch [33/100], Loss: 0.3386\n",
      "Validation Loss: 0.3372\n",
      "Saved the best model with validation loss: 0.3372\n",
      "Epoch [34/100], Loss: 0.3356\n",
      "Validation Loss: 0.3512\n",
      "Epoch [35/100], Loss: 0.3351\n",
      "Validation Loss: 0.3573\n",
      "Epoch [36/100], Loss: 0.3325\n",
      "Validation Loss: 0.3525\n",
      "Epoch [37/100], Loss: 0.3435\n",
      "Validation Loss: 0.3351\n",
      "Saved the best model with validation loss: 0.3351\n",
      "Epoch [38/100], Loss: 0.3342\n",
      "Validation Loss: 0.3833\n",
      "Epoch [39/100], Loss: 0.3304\n",
      "Validation Loss: 0.3734\n",
      "Epoch [40/100], Loss: 0.3293\n",
      "Validation Loss: 0.3764\n",
      "Epoch [41/100], Loss: 0.3289\n",
      "Validation Loss: 0.3637\n",
      "Epoch [42/100], Loss: 0.3324\n",
      "Validation Loss: 0.3436\n",
      "Epoch [43/100], Loss: 0.3285\n",
      "Validation Loss: 0.3644\n",
      "Epoch [44/100], Loss: 0.3276\n",
      "Validation Loss: 0.3432\n",
      "Epoch [45/100], Loss: 0.3271\n",
      "Validation Loss: 0.3685\n",
      "Epoch [46/100], Loss: 0.3251\n",
      "Validation Loss: 0.4069\n",
      "Epoch [47/100], Loss: 0.3268\n",
      "Validation Loss: 0.3815\n",
      "Epoch [48/100], Loss: 0.3270\n",
      "Validation Loss: 0.3915\n",
      "Epoch [49/100], Loss: 0.3276\n",
      "Validation Loss: 0.3701\n",
      "Epoch [50/100], Loss: 0.3269\n",
      "Validation Loss: 0.3544\n",
      "Epoch [51/100], Loss: 0.3257\n",
      "Validation Loss: 0.3940\n",
      "Epoch [52/100], Loss: 0.3262\n",
      "Validation Loss: 0.3971\n",
      "Epoch [53/100], Loss: 0.3261\n",
      "Validation Loss: 0.3976\n",
      "Epoch [54/100], Loss: 0.3229\n",
      "Validation Loss: 0.3341\n",
      "Saved the best model with validation loss: 0.3341\n",
      "Epoch [55/100], Loss: 0.3248\n",
      "Validation Loss: 0.4026\n",
      "Epoch [56/100], Loss: 0.3272\n",
      "Validation Loss: 0.3774\n",
      "Epoch [57/100], Loss: 0.3248\n",
      "Validation Loss: 0.3573\n",
      "Epoch [58/100], Loss: 0.3277\n",
      "Validation Loss: 0.3824\n",
      "Epoch [59/100], Loss: 0.3246\n",
      "Validation Loss: 0.3849\n",
      "Epoch [60/100], Loss: 0.3261\n",
      "Validation Loss: 0.3934\n",
      "Epoch [61/100], Loss: 0.3224\n",
      "Validation Loss: 0.3680\n",
      "Epoch [62/100], Loss: 0.3205\n",
      "Validation Loss: 0.3580\n",
      "Epoch [63/100], Loss: 0.3191\n",
      "Validation Loss: 0.3573\n",
      "Epoch [64/100], Loss: 0.3212\n",
      "Validation Loss: 0.3571\n",
      "Epoch [65/100], Loss: 0.3235\n",
      "Validation Loss: 0.3445\n",
      "Epoch [66/100], Loss: 0.3233\n",
      "Validation Loss: 0.3736\n",
      "Epoch [67/100], Loss: 0.3225\n",
      "Validation Loss: 0.3364\n",
      "Epoch [68/100], Loss: 0.3317\n",
      "Validation Loss: 0.3575\n",
      "Epoch [69/100], Loss: 0.3212\n",
      "Validation Loss: 0.3688\n",
      "Epoch [70/100], Loss: 0.3238\n",
      "Validation Loss: 0.3875\n",
      "Epoch [71/100], Loss: 0.3236\n",
      "Validation Loss: 0.3765\n",
      "Epoch [72/100], Loss: 0.3209\n",
      "Validation Loss: 0.3456\n",
      "Epoch [73/100], Loss: 0.3202\n",
      "Validation Loss: 0.3944\n",
      "Epoch [74/100], Loss: 0.3187\n",
      "Validation Loss: 0.4295\n",
      "Epoch [75/100], Loss: 0.3225\n",
      "Validation Loss: 0.3751\n",
      "Epoch [76/100], Loss: 0.3144\n",
      "Validation Loss: 0.3526\n",
      "Epoch [77/100], Loss: 0.3165\n",
      "Validation Loss: 0.4465\n",
      "Epoch [78/100], Loss: 0.3151\n",
      "Validation Loss: 0.3992\n",
      "Epoch [79/100], Loss: 0.3202\n",
      "Validation Loss: 0.3520\n",
      "Epoch [80/100], Loss: 0.3171\n",
      "Validation Loss: 0.3711\n",
      "Epoch [81/100], Loss: 0.3148\n",
      "Validation Loss: 0.3980\n",
      "Epoch [82/100], Loss: 0.3168\n",
      "Validation Loss: 0.3874\n",
      "Epoch [83/100], Loss: 0.3157\n",
      "Validation Loss: 0.3923\n",
      "Epoch [84/100], Loss: 0.3157\n",
      "Validation Loss: 0.3701\n",
      "Epoch [85/100], Loss: 0.3172\n",
      "Validation Loss: 0.3530\n",
      "Epoch [86/100], Loss: 0.3099\n",
      "Validation Loss: 0.4106\n",
      "Epoch [87/100], Loss: 0.3199\n",
      "Validation Loss: 0.3939\n",
      "Epoch [88/100], Loss: 0.3161\n",
      "Validation Loss: 0.3755\n",
      "Epoch [89/100], Loss: 0.3130\n",
      "Validation Loss: 0.3502\n",
      "Epoch [90/100], Loss: 0.3163\n",
      "Validation Loss: 0.3662\n",
      "Epoch [91/100], Loss: 0.3154\n",
      "Validation Loss: 0.3641\n",
      "Epoch [92/100], Loss: 0.3132\n",
      "Validation Loss: 0.3727\n",
      "Epoch [93/100], Loss: 0.3117\n",
      "Validation Loss: 0.3682\n",
      "Epoch [94/100], Loss: 0.3172\n",
      "Validation Loss: 0.4413\n",
      "Epoch [95/100], Loss: 0.3201\n",
      "Validation Loss: 0.3545\n",
      "Epoch [96/100], Loss: 0.3213\n",
      "Validation Loss: 0.3730\n",
      "Epoch [97/100], Loss: 0.3060\n",
      "Validation Loss: 0.3422\n",
      "Epoch [98/100], Loss: 0.3110\n",
      "Validation Loss: 0.3886\n",
      "Epoch [99/100], Loss: 0.3176\n",
      "Validation Loss: 0.3726\n",
      "Epoch [100/100], Loss: 0.3125\n",
      "Validation Loss: 0.3899\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"combi: 17-80-50-5/1-32-64-5/10-20-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd93d43-fab3-4973-b99b-c1f2dda63143",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 4\n",
    "*  MLP 17-80-50-10\n",
    "*  HGNN 1-32-64-10\n",
    "*  Combined 20-40-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "6d72135c-3168-4fa9-8ea4-78054fd222b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "6b3a113d-b276-4b10-aab3-7b111a417ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5756\n",
      "Validation Loss: 0.4491\n",
      "Saved the best model with validation loss: 0.4491\n",
      "Epoch [2/100], Loss: 0.4474\n",
      "Validation Loss: 0.4055\n",
      "Saved the best model with validation loss: 0.4055\n",
      "Epoch [3/100], Loss: 0.4176\n",
      "Validation Loss: 0.3966\n",
      "Saved the best model with validation loss: 0.3966\n",
      "Epoch [4/100], Loss: 0.4037\n",
      "Validation Loss: 0.3862\n",
      "Saved the best model with validation loss: 0.3862\n",
      "Epoch [5/100], Loss: 0.3960\n",
      "Validation Loss: 0.3728\n",
      "Saved the best model with validation loss: 0.3728\n",
      "Epoch [6/100], Loss: 0.3900\n",
      "Validation Loss: 0.3776\n",
      "Epoch [7/100], Loss: 0.3851\n",
      "Validation Loss: 0.3774\n",
      "Epoch [8/100], Loss: 0.3813\n",
      "Validation Loss: 0.3982\n",
      "Epoch [9/100], Loss: 0.3793\n",
      "Validation Loss: 0.3827\n",
      "Epoch [10/100], Loss: 0.3748\n",
      "Validation Loss: 0.3716\n",
      "Saved the best model with validation loss: 0.3716\n",
      "Epoch [11/100], Loss: 0.3694\n",
      "Validation Loss: 0.3705\n",
      "Saved the best model with validation loss: 0.3705\n",
      "Epoch [12/100], Loss: 0.3650\n",
      "Validation Loss: 0.3719\n",
      "Epoch [13/100], Loss: 0.3601\n",
      "Validation Loss: 0.3771\n",
      "Epoch [14/100], Loss: 0.3579\n",
      "Validation Loss: 0.3702\n",
      "Saved the best model with validation loss: 0.3702\n",
      "Epoch [15/100], Loss: 0.3548\n",
      "Validation Loss: 0.3804\n",
      "Epoch [16/100], Loss: 0.3517\n",
      "Validation Loss: 0.3547\n",
      "Saved the best model with validation loss: 0.3547\n",
      "Epoch [17/100], Loss: 0.3514\n",
      "Validation Loss: 0.3707\n",
      "Epoch [18/100], Loss: 0.3491\n",
      "Validation Loss: 0.3518\n",
      "Saved the best model with validation loss: 0.3518\n",
      "Epoch [19/100], Loss: 0.3475\n",
      "Validation Loss: 0.3628\n",
      "Epoch [20/100], Loss: 0.3460\n",
      "Validation Loss: 0.3462\n",
      "Saved the best model with validation loss: 0.3462\n",
      "Epoch [21/100], Loss: 0.3475\n",
      "Validation Loss: 0.3478\n",
      "Epoch [22/100], Loss: 0.3462\n",
      "Validation Loss: 0.3528\n",
      "Epoch [23/100], Loss: 0.3419\n",
      "Validation Loss: 0.3619\n",
      "Epoch [24/100], Loss: 0.3433\n",
      "Validation Loss: 0.3619\n",
      "Epoch [25/100], Loss: 0.3422\n",
      "Validation Loss: 0.3516\n",
      "Epoch [26/100], Loss: 0.3401\n",
      "Validation Loss: 0.3865\n",
      "Epoch [27/100], Loss: 0.3402\n",
      "Validation Loss: 0.4073\n",
      "Epoch [28/100], Loss: 0.3356\n",
      "Validation Loss: 0.3553\n",
      "Epoch [29/100], Loss: 0.3399\n",
      "Validation Loss: 0.3646\n",
      "Epoch [30/100], Loss: 0.3355\n",
      "Validation Loss: 0.3493\n",
      "Epoch [31/100], Loss: 0.3350\n",
      "Validation Loss: 0.3391\n",
      "Saved the best model with validation loss: 0.3391\n",
      "Epoch [32/100], Loss: 0.3393\n",
      "Validation Loss: 0.3408\n",
      "Epoch [33/100], Loss: 0.3334\n",
      "Validation Loss: 0.3430\n",
      "Epoch [34/100], Loss: 0.3347\n",
      "Validation Loss: 0.3669\n",
      "Epoch [35/100], Loss: 0.3364\n",
      "Validation Loss: 0.3560\n",
      "Epoch [36/100], Loss: 0.3399\n",
      "Validation Loss: 0.3460\n",
      "Epoch [37/100], Loss: 0.3310\n",
      "Validation Loss: 0.3530\n",
      "Epoch [38/100], Loss: 0.3297\n",
      "Validation Loss: 0.3674\n",
      "Epoch [39/100], Loss: 0.3319\n",
      "Validation Loss: 0.3775\n",
      "Epoch [40/100], Loss: 0.3263\n",
      "Validation Loss: 0.3826\n",
      "Epoch [41/100], Loss: 0.3339\n",
      "Validation Loss: 0.3475\n",
      "Epoch [42/100], Loss: 0.3243\n",
      "Validation Loss: 0.3615\n",
      "Epoch [43/100], Loss: 0.3262\n",
      "Validation Loss: 0.3566\n",
      "Epoch [44/100], Loss: 0.3314\n",
      "Validation Loss: 0.3443\n",
      "Epoch [45/100], Loss: 0.3286\n",
      "Validation Loss: 0.3251\n",
      "Saved the best model with validation loss: 0.3251\n",
      "Epoch [46/100], Loss: 0.3257\n",
      "Validation Loss: 0.3682\n",
      "Epoch [47/100], Loss: 0.3367\n",
      "Validation Loss: 0.3396\n",
      "Epoch [48/100], Loss: 0.3294\n",
      "Validation Loss: 0.3639\n",
      "Epoch [49/100], Loss: 0.3303\n",
      "Validation Loss: 0.3796\n",
      "Epoch [50/100], Loss: 0.3287\n",
      "Validation Loss: 0.3641\n",
      "Epoch [51/100], Loss: 0.3291\n",
      "Validation Loss: 0.3680\n",
      "Epoch [52/100], Loss: 0.3232\n",
      "Validation Loss: 0.3993\n",
      "Epoch [53/100], Loss: 0.3267\n",
      "Validation Loss: 0.3711\n",
      "Epoch [54/100], Loss: 0.3235\n",
      "Validation Loss: 0.3479\n",
      "Epoch [55/100], Loss: 0.3323\n",
      "Validation Loss: 0.3360\n",
      "Epoch [56/100], Loss: 0.3240\n",
      "Validation Loss: 0.3708\n",
      "Epoch [57/100], Loss: 0.3223\n",
      "Validation Loss: 0.3671\n",
      "Epoch [58/100], Loss: 0.3215\n",
      "Validation Loss: 0.3928\n",
      "Epoch [59/100], Loss: 0.3332\n",
      "Validation Loss: 0.3655\n",
      "Epoch [60/100], Loss: 0.3306\n",
      "Validation Loss: 0.3705\n",
      "Epoch [61/100], Loss: 0.3317\n",
      "Validation Loss: 0.3440\n",
      "Epoch [62/100], Loss: 0.3226\n",
      "Validation Loss: 0.3940\n",
      "Epoch [63/100], Loss: 0.3263\n",
      "Validation Loss: 0.3556\n",
      "Epoch [64/100], Loss: 0.3242\n",
      "Validation Loss: 0.3635\n",
      "Epoch [65/100], Loss: 0.3202\n",
      "Validation Loss: 0.4077\n",
      "Epoch [66/100], Loss: 0.3216\n",
      "Validation Loss: 0.6618\n",
      "Epoch [67/100], Loss: 0.3368\n",
      "Validation Loss: 0.3715\n",
      "Epoch [68/100], Loss: 0.3221\n",
      "Validation Loss: 0.4061\n",
      "Epoch [69/100], Loss: 0.3230\n",
      "Validation Loss: 0.3843\n",
      "Epoch [70/100], Loss: 0.3352\n",
      "Validation Loss: 0.3607\n",
      "Epoch [71/100], Loss: 0.3217\n",
      "Validation Loss: 0.4218\n",
      "Epoch [72/100], Loss: 0.3270\n",
      "Validation Loss: 0.3542\n",
      "Epoch [73/100], Loss: 0.3248\n",
      "Validation Loss: 0.3660\n",
      "Epoch [74/100], Loss: 0.3230\n",
      "Validation Loss: 0.4617\n",
      "Epoch [75/100], Loss: 0.3236\n",
      "Validation Loss: 0.3779\n",
      "Epoch [76/100], Loss: 0.3329\n",
      "Validation Loss: 0.3927\n",
      "Epoch [77/100], Loss: 0.3275\n",
      "Validation Loss: 0.4085\n",
      "Epoch [78/100], Loss: 0.3210\n",
      "Validation Loss: 0.4123\n",
      "Epoch [79/100], Loss: 0.3293\n",
      "Validation Loss: 0.3948\n",
      "Epoch [80/100], Loss: 0.3235\n",
      "Validation Loss: 0.3809\n",
      "Epoch [81/100], Loss: 0.3247\n",
      "Validation Loss: 0.3913\n",
      "Epoch [82/100], Loss: 0.3284\n",
      "Validation Loss: 0.3933\n",
      "Epoch [83/100], Loss: 0.3250\n",
      "Validation Loss: 0.3345\n",
      "Epoch [84/100], Loss: 0.3283\n",
      "Validation Loss: 0.3549\n",
      "Epoch [85/100], Loss: 0.3248\n",
      "Validation Loss: 0.4371\n",
      "Epoch [86/100], Loss: 0.3241\n",
      "Validation Loss: 0.4073\n",
      "Epoch [87/100], Loss: 0.3322\n",
      "Validation Loss: 0.3159\n",
      "Saved the best model with validation loss: 0.3159\n",
      "Epoch [88/100], Loss: 0.3252\n",
      "Validation Loss: 0.3865\n",
      "Epoch [89/100], Loss: 0.3219\n",
      "Validation Loss: 0.3956\n",
      "Epoch [90/100], Loss: 0.3383\n",
      "Validation Loss: 0.4350\n",
      "Epoch [91/100], Loss: 0.3284\n",
      "Validation Loss: 0.3730\n",
      "Epoch [92/100], Loss: 0.3226\n",
      "Validation Loss: 0.4358\n",
      "Epoch [93/100], Loss: 0.3224\n",
      "Validation Loss: 0.4161\n",
      "Epoch [94/100], Loss: 0.3316\n",
      "Validation Loss: 0.3788\n",
      "Epoch [95/100], Loss: 0.3256\n",
      "Validation Loss: 0.3601\n",
      "Epoch [96/100], Loss: 0.3243\n",
      "Validation Loss: 0.3627\n",
      "Epoch [97/100], Loss: 0.3199\n",
      "Validation Loss: 0.3561\n",
      "Epoch [98/100], Loss: 0.3250\n",
      "Validation Loss: 0.4740\n",
      "Epoch [99/100], Loss: 0.3240\n",
      "Validation Loss: 0.4356\n",
      "Epoch [100/100], Loss: 0.3257\n",
      "Validation Loss: 0.4527\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"combi: 17-80-50-10/1-32-64-10/20-40-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0edada4-75ec-4607-8a74-9def9f50f527",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 5\n",
    "*  MLP 17-80-50-10\n",
    "*  HGNN 1-32-64-10\n",
    "*  Combined 20-80-20-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "866ada28-2a5e-4b65-82f0-291b8895375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "4057aade-9775-42e1-b2a4-08c5281897cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6234\n",
      "Validation Loss: 0.4815\n",
      "Saved the best model with validation loss: 0.4815\n",
      "Epoch [2/100], Loss: 0.4580\n",
      "Validation Loss: 0.4075\n",
      "Saved the best model with validation loss: 0.4075\n",
      "Epoch [3/100], Loss: 0.4258\n",
      "Validation Loss: 0.4012\n",
      "Saved the best model with validation loss: 0.4012\n",
      "Epoch [4/100], Loss: 0.4115\n",
      "Validation Loss: 0.3816\n",
      "Saved the best model with validation loss: 0.3816\n",
      "Epoch [5/100], Loss: 0.3982\n",
      "Validation Loss: 0.3755\n",
      "Saved the best model with validation loss: 0.3755\n",
      "Epoch [6/100], Loss: 0.3922\n",
      "Validation Loss: 0.3767\n",
      "Epoch [7/100], Loss: 0.3836\n",
      "Validation Loss: 0.3991\n",
      "Epoch [8/100], Loss: 0.3795\n",
      "Validation Loss: 0.3931\n",
      "Epoch [9/100], Loss: 0.3804\n",
      "Validation Loss: 0.3527\n",
      "Saved the best model with validation loss: 0.3527\n",
      "Epoch [10/100], Loss: 0.3707\n",
      "Validation Loss: 0.4921\n",
      "Epoch [11/100], Loss: 0.3758\n",
      "Validation Loss: 0.3851\n",
      "Epoch [12/100], Loss: 0.3682\n",
      "Validation Loss: 0.3503\n",
      "Saved the best model with validation loss: 0.3503\n",
      "Epoch [13/100], Loss: 0.3695\n",
      "Validation Loss: 0.3530\n",
      "Epoch [14/100], Loss: 0.3617\n",
      "Validation Loss: 0.3601\n",
      "Epoch [15/100], Loss: 0.3625\n",
      "Validation Loss: 0.3615\n",
      "Epoch [16/100], Loss: 0.3591\n",
      "Validation Loss: 0.5098\n",
      "Epoch [17/100], Loss: 0.3594\n",
      "Validation Loss: 0.3640\n",
      "Epoch [18/100], Loss: 0.3553\n",
      "Validation Loss: 0.5232\n",
      "Epoch [19/100], Loss: 0.3579\n",
      "Validation Loss: 0.3700\n",
      "Epoch [20/100], Loss: 0.3530\n",
      "Validation Loss: 0.3740\n",
      "Epoch [21/100], Loss: 0.3548\n",
      "Validation Loss: 0.3804\n",
      "Epoch [22/100], Loss: 0.3525\n",
      "Validation Loss: 0.3903\n",
      "Epoch [23/100], Loss: 0.3467\n",
      "Validation Loss: 0.3820\n",
      "Epoch [24/100], Loss: 0.3449\n",
      "Validation Loss: 0.3857\n",
      "Epoch [25/100], Loss: 0.3535\n",
      "Validation Loss: 0.3938\n",
      "Epoch [26/100], Loss: 0.3414\n",
      "Validation Loss: 0.4148\n",
      "Epoch [27/100], Loss: 0.3374\n",
      "Validation Loss: 0.4255\n",
      "Epoch [28/100], Loss: 0.3423\n",
      "Validation Loss: 0.3897\n",
      "Epoch [29/100], Loss: 0.3340\n",
      "Validation Loss: 0.4045\n",
      "Epoch [30/100], Loss: 0.3367\n",
      "Validation Loss: 0.4154\n",
      "Epoch [31/100], Loss: 0.3344\n",
      "Validation Loss: 0.4578\n",
      "Epoch [32/100], Loss: 0.3349\n",
      "Validation Loss: 0.3842\n",
      "Epoch [33/100], Loss: 0.3342\n",
      "Validation Loss: 0.3646\n",
      "Epoch [34/100], Loss: 0.3299\n",
      "Validation Loss: 0.3944\n",
      "Epoch [35/100], Loss: 0.3309\n",
      "Validation Loss: 0.3996\n",
      "Epoch [36/100], Loss: 0.3276\n",
      "Validation Loss: 0.3802\n",
      "Epoch [37/100], Loss: 0.3359\n",
      "Validation Loss: 0.4254\n",
      "Epoch [38/100], Loss: 0.3267\n",
      "Validation Loss: 0.5836\n",
      "Epoch [39/100], Loss: 0.3336\n",
      "Validation Loss: 0.3735\n",
      "Epoch [40/100], Loss: 0.3225\n",
      "Validation Loss: 0.4597\n",
      "Epoch [41/100], Loss: 0.3293\n",
      "Validation Loss: 0.4320\n",
      "Epoch [42/100], Loss: 0.3301\n",
      "Validation Loss: 0.3816\n",
      "Epoch [43/100], Loss: 0.3179\n",
      "Validation Loss: 0.4128\n",
      "Epoch [44/100], Loss: 0.3313\n",
      "Validation Loss: 0.4009\n",
      "Epoch [45/100], Loss: 0.3218\n",
      "Validation Loss: 0.4448\n",
      "Epoch [46/100], Loss: 0.3197\n",
      "Validation Loss: 0.4036\n",
      "Epoch [47/100], Loss: 0.3272\n",
      "Validation Loss: 0.4255\n",
      "Epoch [48/100], Loss: 0.3199\n",
      "Validation Loss: 0.4061\n",
      "Epoch [49/100], Loss: 0.3218\n",
      "Validation Loss: 0.3532\n",
      "Epoch [50/100], Loss: 0.3168\n",
      "Validation Loss: 0.3882\n",
      "Epoch [51/100], Loss: 0.3295\n",
      "Validation Loss: 0.3840\n",
      "Epoch [52/100], Loss: 0.3164\n",
      "Validation Loss: 0.3523\n",
      "Epoch [53/100], Loss: 0.3223\n",
      "Validation Loss: 0.3649\n",
      "Epoch [54/100], Loss: 0.3217\n",
      "Validation Loss: 0.3487\n",
      "Saved the best model with validation loss: 0.3487\n",
      "Epoch [55/100], Loss: 0.3251\n",
      "Validation Loss: 0.4308\n",
      "Epoch [56/100], Loss: 0.3167\n",
      "Validation Loss: 0.3656\n",
      "Epoch [57/100], Loss: 0.3232\n",
      "Validation Loss: 0.4180\n",
      "Epoch [58/100], Loss: 0.3151\n",
      "Validation Loss: 0.4103\n",
      "Epoch [59/100], Loss: 0.3159\n",
      "Validation Loss: 0.4137\n",
      "Epoch [60/100], Loss: 0.3222\n",
      "Validation Loss: 0.4015\n",
      "Epoch [61/100], Loss: 0.3145\n",
      "Validation Loss: 0.3972\n",
      "Epoch [62/100], Loss: 0.3164\n",
      "Validation Loss: 0.3940\n",
      "Epoch [63/100], Loss: 0.3254\n",
      "Validation Loss: 0.4288\n",
      "Epoch [64/100], Loss: 0.3152\n",
      "Validation Loss: 0.4079\n",
      "Epoch [65/100], Loss: 0.3230\n",
      "Validation Loss: 0.4379\n",
      "Epoch [66/100], Loss: 0.3318\n",
      "Validation Loss: 0.4026\n",
      "Epoch [67/100], Loss: 0.3211\n",
      "Validation Loss: 0.4522\n",
      "Epoch [68/100], Loss: 0.3136\n",
      "Validation Loss: 0.4365\n",
      "Epoch [69/100], Loss: 0.3164\n",
      "Validation Loss: 0.4907\n",
      "Epoch [70/100], Loss: 0.3226\n",
      "Validation Loss: 0.3982\n",
      "Epoch [71/100], Loss: 0.3117\n",
      "Validation Loss: 0.4079\n",
      "Epoch [72/100], Loss: 0.3262\n",
      "Validation Loss: 0.3753\n",
      "Epoch [73/100], Loss: 0.3123\n",
      "Validation Loss: 0.3872\n",
      "Epoch [74/100], Loss: 0.3271\n",
      "Validation Loss: 0.3751\n",
      "Epoch [75/100], Loss: 0.3120\n",
      "Validation Loss: 0.4227\n",
      "Epoch [76/100], Loss: 0.3175\n",
      "Validation Loss: 0.3969\n",
      "Epoch [77/100], Loss: 0.3172\n",
      "Validation Loss: 0.3727\n",
      "Epoch [78/100], Loss: 0.3256\n",
      "Validation Loss: 0.4534\n",
      "Epoch [79/100], Loss: 0.3127\n",
      "Validation Loss: 1.0103\n",
      "Epoch [80/100], Loss: 0.3145\n",
      "Validation Loss: 0.6571\n",
      "Epoch [81/100], Loss: 0.3129\n",
      "Validation Loss: 0.3895\n",
      "Epoch [82/100], Loss: 0.3111\n",
      "Validation Loss: 0.5411\n",
      "Epoch [83/100], Loss: 0.3172\n",
      "Validation Loss: 0.6239\n",
      "Epoch [84/100], Loss: 0.3214\n",
      "Validation Loss: 0.4310\n",
      "Epoch [85/100], Loss: 0.3190\n",
      "Validation Loss: 0.4768\n",
      "Epoch [86/100], Loss: 0.3165\n",
      "Validation Loss: 0.3958\n",
      "Epoch [87/100], Loss: 0.3097\n",
      "Validation Loss: 0.4022\n",
      "Epoch [88/100], Loss: 0.3137\n",
      "Validation Loss: 0.4036\n",
      "Epoch [89/100], Loss: 0.3186\n",
      "Validation Loss: 0.4595\n",
      "Epoch [90/100], Loss: 0.3176\n",
      "Validation Loss: 0.4321\n",
      "Epoch [91/100], Loss: 0.3166\n",
      "Validation Loss: 0.4335\n",
      "Epoch [92/100], Loss: 0.3145\n",
      "Validation Loss: 0.5432\n",
      "Epoch [93/100], Loss: 0.3366\n",
      "Validation Loss: 0.4258\n",
      "Epoch [94/100], Loss: 0.3083\n",
      "Validation Loss: 0.6081\n",
      "Epoch [95/100], Loss: 0.3190\n",
      "Validation Loss: 0.4461\n",
      "Epoch [96/100], Loss: 0.3266\n",
      "Validation Loss: 0.4212\n",
      "Epoch [97/100], Loss: 0.3154\n",
      "Validation Loss: 0.4835\n",
      "Epoch [98/100], Loss: 0.3131\n",
      "Validation Loss: 0.4844\n",
      "Epoch [99/100], Loss: 0.3099\n",
      "Validation Loss: 0.4418\n",
      "Epoch [100/100], Loss: 0.3132\n",
      "Validation Loss: 0.4430\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_train, X_val_hg, y1_val, \"2_class\", \"combi: 17-80-50-10/1-32-64-10/20-60-20-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "15257cb7-4057-4bb4-bf95-bb431b9ac53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.827117</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.667832</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.645688</td>\n",
       "      <td>0.622881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.672494</td>\n",
       "      <td>0.469492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.662393</td>\n",
       "      <td>0.523729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-2</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-2</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-2</th>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-2</th>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-2</th>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-2</th>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-2</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-2</th>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-2</th>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-2</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-2</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-2</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-2</th>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-2</th>\n",
       "      <td>0.713287</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-2</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-2</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-2</th>\n",
       "      <td>0.758741</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-2</th>\n",
       "      <td>0.685315</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-2</th>\n",
       "      <td>0.702797</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-2</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-2</th>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-2</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-2</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-2</th>\n",
       "      <td>0.842657</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-2</th>\n",
       "      <td>0.821678</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-40-2/1-32-64-2/4-2</th>\n",
       "      <td>0.842657</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-32-64-5/10-2</th>\n",
       "      <td>0.842657</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-32-64-5/10-20-2</th>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-32-64-10/20-40-2</th>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-32-64-10/20-60-20-2</th>\n",
       "      <td>0.853147</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               acc       rec       acc  \\\n",
       "5-NN                                      0.818182  0.769231  0.811189   \n",
       "Decision tree                             0.832168  0.776923  0.827506   \n",
       "Random forest                             0.835664  0.792308  0.827117   \n",
       "SVM linear                                0.667832  0.584615  0.645688   \n",
       "SVM poly                                  0.716783  0.507692  0.672494   \n",
       "SVM rbf                                   0.720280  0.561538  0.662393   \n",
       "MLP: 17-5-2                               0.730769  0.669231         -   \n",
       "MLP: 17-10-2                              0.632867  0.215385         -   \n",
       "MLP: 17-20-2                              0.765734  0.761538         -   \n",
       "MLP: 17-25-2                              0.755245  0.761538         -   \n",
       "MLP: 17-40-2                              0.744755  0.738462         -   \n",
       "MLP: 17-60-2                              0.755245  0.738462         -   \n",
       "MLP: 17-10-5-2                            0.706294  0.438462         -   \n",
       "MLP: 17-20-10-2                           0.709790  0.723077         -   \n",
       "MLP: 17-40-20-2                           0.776224  0.753846         -   \n",
       "MLP: 17-40-10-2                           0.741259  0.723077         -   \n",
       "MLP: 17-60-40-2                           0.737762  0.723077         -   \n",
       "MLP: 17-60-20-2                           0.737762  0.753846         -   \n",
       "MLP: 17-80-50-2                           0.783217  0.753846         -   \n",
       "MLP, small-median: 7-80-50-2              0.713287  0.569231         -   \n",
       "MLP, small-mean: 7-80-50-2                0.706294  0.584615         -   \n",
       "MLP, small-min: 7-80-50-2                 0.706294  0.623077         -   \n",
       "MLP, small-max: 7-80-50-2                 0.758741  0.776923         -   \n",
       "MLP, small-q25: 7-80-50-2                 0.685315  0.592308         -   \n",
       "MLP, small-q75: 7-80-50-2                 0.702797  0.607692         -   \n",
       "MLP, custom: 7-80-50-2                    0.772727  0.707692         -   \n",
       "HGNN: 1-16-32-2                           0.839161  0.884615         -   \n",
       "HGNN: 1-32-16-2                           0.818182  0.876923         -   \n",
       "HGNN: 1-16-32-16-2                        0.835664  0.892308         -   \n",
       "HGNN: 1-32-64-2                           0.842657  0.892308         -   \n",
       "HGNN: 1-4-16-2                            0.821678  0.876923         -   \n",
       "combi: 17-80-40-2/1-32-64-2/4-2           0.842657  0.869231         -   \n",
       "combi: 17-80-50-5/1-32-64-5/10-2          0.842657  0.900000         -   \n",
       "combi: 17-80-50-5/1-32-64-5/10-20-2       0.863636  0.830769         -   \n",
       "combi: 17-80-50-10/1-32-64-10/20-40-2     0.856643  0.784615         -   \n",
       "combi: 17-80-50-10/1-32-64-10/20-60-20-2  0.853147  0.784615         -   \n",
       "\n",
       "                                               rec  \n",
       "5-NN                                      0.795763  \n",
       "Decision tree                             0.800847  \n",
       "Random forest                             0.816949  \n",
       "SVM linear                                0.622881  \n",
       "SVM poly                                  0.469492  \n",
       "SVM rbf                                   0.523729  \n",
       "MLP: 17-5-2                                      -  \n",
       "MLP: 17-10-2                                     -  \n",
       "MLP: 17-20-2                                     -  \n",
       "MLP: 17-25-2                                     -  \n",
       "MLP: 17-40-2                                     -  \n",
       "MLP: 17-60-2                                     -  \n",
       "MLP: 17-10-5-2                                   -  \n",
       "MLP: 17-20-10-2                                  -  \n",
       "MLP: 17-40-20-2                                  -  \n",
       "MLP: 17-40-10-2                                  -  \n",
       "MLP: 17-60-40-2                                  -  \n",
       "MLP: 17-60-20-2                                  -  \n",
       "MLP: 17-80-50-2                                  -  \n",
       "MLP, small-median: 7-80-50-2                     -  \n",
       "MLP, small-mean: 7-80-50-2                       -  \n",
       "MLP, small-min: 7-80-50-2                        -  \n",
       "MLP, small-max: 7-80-50-2                        -  \n",
       "MLP, small-q25: 7-80-50-2                        -  \n",
       "MLP, small-q75: 7-80-50-2                        -  \n",
       "MLP, custom: 7-80-50-2                           -  \n",
       "HGNN: 1-16-32-2                                  -  \n",
       "HGNN: 1-32-16-2                                  -  \n",
       "HGNN: 1-16-32-16-2                               -  \n",
       "HGNN: 1-32-64-2                                  -  \n",
       "HGNN: 1-4-16-2                                   -  \n",
       "combi: 17-80-40-2/1-32-64-2/4-2                  -  \n",
       "combi: 17-80-50-5/1-32-64-5/10-2                 -  \n",
       "combi: 17-80-50-5/1-32-64-5/10-20-2              -  \n",
       "combi: 17-80-50-10/1-32-64-10/20-40-2            -  \n",
       "combi: 17-80-50-10/1-32-64-10/20-60-20-2         -  "
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "3126ed9a-5270-4f45-ba04-93296a67a062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2526/692307941.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  table_2_classes = table_2_classes.applymap(round_if_number)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.8182</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.7958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.7769</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>0.8008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.8169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>0.6678</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>0.6457</td>\n",
       "      <td>0.6229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.4695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.5615</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>0.5237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-2</th>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-2</th>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-2</th>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.7615</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-2</th>\n",
       "      <td>0.7552</td>\n",
       "      <td>0.7615</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-2</th>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.7385</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-2</th>\n",
       "      <td>0.7552</td>\n",
       "      <td>0.7385</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-2</th>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.4385</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-2</th>\n",
       "      <td>0.7098</td>\n",
       "      <td>0.7231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-2</th>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-2</th>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.7231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-2</th>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.7231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-2</th>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-2</th>\n",
       "      <td>0.7832</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-80-50-2</th>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.5692</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-80-50-2</th>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-80-50-2</th>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.6231</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-80-50-2</th>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7769</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-80-50-2</th>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.5923</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-80-50-2</th>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-80-50-2</th>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.7077</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-2</th>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-2</th>\n",
       "      <td>0.8182</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-2</th>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-2</th>\n",
       "      <td>0.8427</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-2</th>\n",
       "      <td>0.8217</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-40-2/1-32-64-2/4-2</th>\n",
       "      <td>0.8427</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-32-64-5/10-2</th>\n",
       "      <td>0.8427</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-5/1-32-64-5/10-20-2</th>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-32-64-10/20-40-2</th>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.7846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-80-50-10/1-32-64-10/20-60-20-2</th>\n",
       "      <td>0.8531</td>\n",
       "      <td>0.7846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             acc     rec     acc     rec\n",
       "5-NN                                      0.8182  0.7692  0.8112  0.7958\n",
       "Decision tree                             0.8322  0.7769  0.8275  0.8008\n",
       "Random forest                             0.8357  0.7923  0.8271  0.8169\n",
       "SVM linear                                0.6678  0.5846  0.6457  0.6229\n",
       "SVM poly                                  0.7168  0.5077  0.6725  0.4695\n",
       "SVM rbf                                   0.7203  0.5615  0.6624  0.5237\n",
       "MLP: 17-5-2                               0.7308  0.6692       -       -\n",
       "MLP: 17-10-2                              0.6329  0.2154       -       -\n",
       "MLP: 17-20-2                              0.7657  0.7615       -       -\n",
       "MLP: 17-25-2                              0.7552  0.7615       -       -\n",
       "MLP: 17-40-2                              0.7448  0.7385       -       -\n",
       "MLP: 17-60-2                              0.7552  0.7385       -       -\n",
       "MLP: 17-10-5-2                            0.7063  0.4385       -       -\n",
       "MLP: 17-20-10-2                           0.7098  0.7231       -       -\n",
       "MLP: 17-40-20-2                           0.7762  0.7538       -       -\n",
       "MLP: 17-40-10-2                           0.7413  0.7231       -       -\n",
       "MLP: 17-60-40-2                           0.7378  0.7231       -       -\n",
       "MLP: 17-60-20-2                           0.7378  0.7538       -       -\n",
       "MLP: 17-80-50-2                           0.7832  0.7538       -       -\n",
       "MLP, small-median: 7-80-50-2              0.7133  0.5692       -       -\n",
       "MLP, small-mean: 7-80-50-2                0.7063  0.5846       -       -\n",
       "MLP, small-min: 7-80-50-2                 0.7063  0.6231       -       -\n",
       "MLP, small-max: 7-80-50-2                 0.7587  0.7769       -       -\n",
       "MLP, small-q25: 7-80-50-2                 0.6853  0.5923       -       -\n",
       "MLP, small-q75: 7-80-50-2                 0.7028  0.6077       -       -\n",
       "MLP, custom: 7-80-50-2                    0.7727  0.7077       -       -\n",
       "HGNN: 1-16-32-2                           0.8392  0.8846       -       -\n",
       "HGNN: 1-32-16-2                           0.8182  0.8769       -       -\n",
       "HGNN: 1-16-32-16-2                        0.8357  0.8923       -       -\n",
       "HGNN: 1-32-64-2                           0.8427  0.8923       -       -\n",
       "HGNN: 1-4-16-2                            0.8217  0.8769       -       -\n",
       "combi: 17-80-40-2/1-32-64-2/4-2           0.8427  0.8692       -       -\n",
       "combi: 17-80-50-5/1-32-64-5/10-2          0.8427  0.9000       -       -\n",
       "combi: 17-80-50-5/1-32-64-5/10-20-2       0.8636  0.8308       -       -\n",
       "combi: 17-80-50-10/1-32-64-10/20-40-2     0.8566  0.7846       -       -\n",
       "combi: 17-80-50-10/1-32-64-10/20-60-20-2  0.8531  0.7846       -       -"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def round_if_number(x):\n",
    "    try:\n",
    "        return round(float(x), 4)\n",
    "    except ValueError:\n",
    "        return x\n",
    "\n",
    "table_2_classes = table_2_classes.applymap(round_if_number)\n",
    "table_2_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "9c6ca5bf-8483-47e6-bb63-e68cdfe093df",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2_classes.to_csv('results/table_2_classes_DDB_rounded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80cd325",
   "metadata": {},
   "source": [
    "### Combined HGNN with three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd1a2f",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 1, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  MLP 17-80-50-3\n",
    "*  HGNN 1-16-32-3\n",
    "*  Combined 6-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "c5f3d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(6, 3)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "8ef380f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.8083\n",
      "Validation Loss: 0.5781\n",
      "Saved the best model with validation loss: 0.5781\n",
      "Epoch [2/100], Loss: 0.5791\n",
      "Validation Loss: 0.4997\n",
      "Saved the best model with validation loss: 0.4997\n",
      "Epoch [3/100], Loss: 0.5259\n",
      "Validation Loss: 0.4772\n",
      "Saved the best model with validation loss: 0.4772\n",
      "Epoch [4/100], Loss: 0.5036\n",
      "Validation Loss: 0.4664\n",
      "Saved the best model with validation loss: 0.4664\n",
      "Epoch [5/100], Loss: 0.4890\n",
      "Validation Loss: 0.4583\n",
      "Saved the best model with validation loss: 0.4583\n",
      "Epoch [6/100], Loss: 0.4799\n",
      "Validation Loss: 0.4465\n",
      "Saved the best model with validation loss: 0.4465\n",
      "Epoch [7/100], Loss: 0.4736\n",
      "Validation Loss: 0.4471\n",
      "Epoch [8/100], Loss: 0.4672\n",
      "Validation Loss: 0.4427\n",
      "Saved the best model with validation loss: 0.4427\n",
      "Epoch [9/100], Loss: 0.4618\n",
      "Validation Loss: 0.4346\n",
      "Saved the best model with validation loss: 0.4346\n",
      "Epoch [10/100], Loss: 0.4624\n",
      "Validation Loss: 0.4359\n",
      "Epoch [11/100], Loss: 0.4577\n",
      "Validation Loss: 0.4348\n",
      "Epoch [12/100], Loss: 0.4555\n",
      "Validation Loss: 0.4404\n",
      "Epoch [13/100], Loss: 0.4525\n",
      "Validation Loss: 0.4308\n",
      "Saved the best model with validation loss: 0.4308\n",
      "Epoch [14/100], Loss: 0.4485\n",
      "Validation Loss: 0.4320\n",
      "Epoch [15/100], Loss: 0.4460\n",
      "Validation Loss: 0.4360\n",
      "Epoch [16/100], Loss: 0.4437\n",
      "Validation Loss: 0.4389\n",
      "Epoch [17/100], Loss: 0.4423\n",
      "Validation Loss: 0.4378\n",
      "Epoch [18/100], Loss: 0.4425\n",
      "Validation Loss: 0.4353\n",
      "Epoch [19/100], Loss: 0.4402\n",
      "Validation Loss: 0.4231\n",
      "Saved the best model with validation loss: 0.4231\n",
      "Epoch [20/100], Loss: 0.4380\n",
      "Validation Loss: 0.4323\n",
      "Epoch [21/100], Loss: 0.4370\n",
      "Validation Loss: 0.4178\n",
      "Saved the best model with validation loss: 0.4178\n",
      "Epoch [22/100], Loss: 0.4351\n",
      "Validation Loss: 0.4311\n",
      "Epoch [23/100], Loss: 0.4345\n",
      "Validation Loss: 0.4343\n",
      "Epoch [24/100], Loss: 0.4323\n",
      "Validation Loss: 0.4185\n",
      "Epoch [25/100], Loss: 0.4308\n",
      "Validation Loss: 0.4287\n",
      "Epoch [26/100], Loss: 0.4321\n",
      "Validation Loss: 0.4038\n",
      "Saved the best model with validation loss: 0.4038\n",
      "Epoch [27/100], Loss: 0.4282\n",
      "Validation Loss: 0.4189\n",
      "Epoch [28/100], Loss: 0.4269\n",
      "Validation Loss: 0.4160\n",
      "Epoch [29/100], Loss: 0.4261\n",
      "Validation Loss: 0.4273\n",
      "Epoch [30/100], Loss: 0.4253\n",
      "Validation Loss: 0.4147\n",
      "Epoch [31/100], Loss: 0.4221\n",
      "Validation Loss: 0.4115\n",
      "Epoch [32/100], Loss: 0.4215\n",
      "Validation Loss: 0.4141\n",
      "Epoch [33/100], Loss: 0.4196\n",
      "Validation Loss: 0.4040\n",
      "Epoch [34/100], Loss: 0.4194\n",
      "Validation Loss: 0.4005\n",
      "Saved the best model with validation loss: 0.4005\n",
      "Epoch [35/100], Loss: 0.4168\n",
      "Validation Loss: 0.4014\n",
      "Epoch [36/100], Loss: 0.4181\n",
      "Validation Loss: 0.3931\n",
      "Saved the best model with validation loss: 0.3931\n",
      "Epoch [37/100], Loss: 0.4145\n",
      "Validation Loss: 0.4122\n",
      "Epoch [38/100], Loss: 0.4175\n",
      "Validation Loss: 0.4175\n",
      "Epoch [39/100], Loss: 0.4170\n",
      "Validation Loss: 0.3965\n",
      "Epoch [40/100], Loss: 0.4139\n",
      "Validation Loss: 0.4036\n",
      "Epoch [41/100], Loss: 0.4135\n",
      "Validation Loss: 0.3941\n",
      "Epoch [42/100], Loss: 0.4129\n",
      "Validation Loss: 0.4203\n",
      "Epoch [43/100], Loss: 0.4113\n",
      "Validation Loss: 0.4005\n",
      "Epoch [44/100], Loss: 0.4108\n",
      "Validation Loss: 0.4086\n",
      "Epoch [45/100], Loss: 0.4096\n",
      "Validation Loss: 0.4006\n",
      "Epoch [46/100], Loss: 0.4099\n",
      "Validation Loss: 0.3905\n",
      "Saved the best model with validation loss: 0.3905\n",
      "Epoch [47/100], Loss: 0.4109\n",
      "Validation Loss: 0.3893\n",
      "Saved the best model with validation loss: 0.3893\n",
      "Epoch [48/100], Loss: 0.4085\n",
      "Validation Loss: 0.3958\n",
      "Epoch [49/100], Loss: 0.4080\n",
      "Validation Loss: 0.4027\n",
      "Epoch [50/100], Loss: 0.4093\n",
      "Validation Loss: 0.4045\n",
      "Epoch [51/100], Loss: 0.4062\n",
      "Validation Loss: 0.4011\n",
      "Epoch [52/100], Loss: 0.4090\n",
      "Validation Loss: 0.3937\n",
      "Epoch [53/100], Loss: 0.4069\n",
      "Validation Loss: 0.3981\n",
      "Epoch [54/100], Loss: 0.4070\n",
      "Validation Loss: 0.4083\n",
      "Epoch [55/100], Loss: 0.4055\n",
      "Validation Loss: 0.4194\n",
      "Epoch [56/100], Loss: 0.4058\n",
      "Validation Loss: 0.3958\n",
      "Epoch [57/100], Loss: 0.4066\n",
      "Validation Loss: 0.3993\n",
      "Epoch [58/100], Loss: 0.4054\n",
      "Validation Loss: 0.4424\n",
      "Epoch [59/100], Loss: 0.4082\n",
      "Validation Loss: 0.4266\n",
      "Epoch [60/100], Loss: 0.4063\n",
      "Validation Loss: 0.3981\n",
      "Epoch [61/100], Loss: 0.4050\n",
      "Validation Loss: 0.4081\n",
      "Epoch [62/100], Loss: 0.4048\n",
      "Validation Loss: 0.4017\n",
      "Epoch [63/100], Loss: 0.4071\n",
      "Validation Loss: 0.3986\n",
      "Epoch [64/100], Loss: 0.4049\n",
      "Validation Loss: 0.4032\n",
      "Epoch [65/100], Loss: 0.4040\n",
      "Validation Loss: 0.3957\n",
      "Epoch [66/100], Loss: 0.4066\n",
      "Validation Loss: 0.3994\n",
      "Epoch [67/100], Loss: 0.4034\n",
      "Validation Loss: 0.3865\n",
      "Saved the best model with validation loss: 0.3865\n",
      "Epoch [68/100], Loss: 0.4011\n",
      "Validation Loss: 0.4080\n",
      "Epoch [69/100], Loss: 0.4028\n",
      "Validation Loss: 0.4053\n",
      "Epoch [70/100], Loss: 0.4023\n",
      "Validation Loss: 0.3820\n",
      "Saved the best model with validation loss: 0.3820\n",
      "Epoch [71/100], Loss: 0.3994\n",
      "Validation Loss: 0.4030\n",
      "Epoch [72/100], Loss: 0.4012\n",
      "Validation Loss: 0.3989\n",
      "Epoch [73/100], Loss: 0.4006\n",
      "Validation Loss: 0.3827\n",
      "Epoch [74/100], Loss: 0.4014\n",
      "Validation Loss: 0.3760\n",
      "Saved the best model with validation loss: 0.3760\n",
      "Epoch [75/100], Loss: 0.4001\n",
      "Validation Loss: 0.3798\n",
      "Epoch [76/100], Loss: 0.4015\n",
      "Validation Loss: 0.3813\n",
      "Epoch [77/100], Loss: 0.3977\n",
      "Validation Loss: 0.4230\n",
      "Epoch [78/100], Loss: 0.4001\n",
      "Validation Loss: 0.3896\n",
      "Epoch [79/100], Loss: 0.3997\n",
      "Validation Loss: 0.4181\n",
      "Epoch [80/100], Loss: 0.3988\n",
      "Validation Loss: 0.4001\n",
      "Epoch [81/100], Loss: 0.3970\n",
      "Validation Loss: 0.3941\n",
      "Epoch [82/100], Loss: 0.3991\n",
      "Validation Loss: 0.3926\n",
      "Epoch [83/100], Loss: 0.3981\n",
      "Validation Loss: 0.3928\n",
      "Epoch [84/100], Loss: 0.3981\n",
      "Validation Loss: 0.3977\n",
      "Epoch [85/100], Loss: 0.3991\n",
      "Validation Loss: 0.4146\n",
      "Epoch [86/100], Loss: 0.3978\n",
      "Validation Loss: 0.4062\n",
      "Epoch [87/100], Loss: 0.3986\n",
      "Validation Loss: 0.4114\n",
      "Epoch [88/100], Loss: 0.3995\n",
      "Validation Loss: 0.3976\n",
      "Epoch [89/100], Loss: 0.3984\n",
      "Validation Loss: 0.4179\n",
      "Epoch [90/100], Loss: 0.3975\n",
      "Validation Loss: 0.4090\n",
      "Epoch [91/100], Loss: 0.3990\n",
      "Validation Loss: 0.4009\n",
      "Epoch [92/100], Loss: 0.3958\n",
      "Validation Loss: 0.4301\n",
      "Epoch [93/100], Loss: 0.3985\n",
      "Validation Loss: 0.4217\n",
      "Epoch [94/100], Loss: 0.3968\n",
      "Validation Loss: 0.3944\n",
      "Epoch [95/100], Loss: 0.3950\n",
      "Validation Loss: 0.4020\n",
      "Epoch [96/100], Loss: 0.3961\n",
      "Validation Loss: 0.3990\n",
      "Epoch [97/100], Loss: 0.3956\n",
      "Validation Loss: 0.4122\n",
      "Epoch [98/100], Loss: 0.3951\n",
      "Validation Loss: 0.4178\n",
      "Epoch [99/100], Loss: 0.3967\n",
      "Validation Loss: 0.4073\n",
      "Epoch [100/100], Loss: 0.3960\n",
      "Validation Loss: 0.4149\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"combi 0.5: 17-80-50-3/1-16-32-3/6-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "f4ea4ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.9386\n",
      "Validation Loss: 0.8015\n",
      "Saved the best model with validation loss: 0.8015\n",
      "Epoch [2/100], Loss: 0.7428\n",
      "Validation Loss: 0.7343\n",
      "Saved the best model with validation loss: 0.7343\n",
      "Epoch [3/100], Loss: 0.6910\n",
      "Validation Loss: 0.7130\n",
      "Saved the best model with validation loss: 0.7130\n",
      "Epoch [4/100], Loss: 0.6676\n",
      "Validation Loss: 0.7081\n",
      "Saved the best model with validation loss: 0.7081\n",
      "Epoch [5/100], Loss: 0.6558\n",
      "Validation Loss: 0.6985\n",
      "Saved the best model with validation loss: 0.6985\n",
      "Epoch [6/100], Loss: 0.6459\n",
      "Validation Loss: 0.6950\n",
      "Saved the best model with validation loss: 0.6950\n",
      "Epoch [7/100], Loss: 0.6390\n",
      "Validation Loss: 0.6822\n",
      "Saved the best model with validation loss: 0.6822\n",
      "Epoch [8/100], Loss: 0.6315\n",
      "Validation Loss: 0.6827\n",
      "Epoch [9/100], Loss: 0.6269\n",
      "Validation Loss: 0.6697\n",
      "Saved the best model with validation loss: 0.6697\n",
      "Epoch [10/100], Loss: 0.6212\n",
      "Validation Loss: 0.6747\n",
      "Epoch [11/100], Loss: 0.6168\n",
      "Validation Loss: 0.6683\n",
      "Saved the best model with validation loss: 0.6683\n",
      "Epoch [12/100], Loss: 0.6111\n",
      "Validation Loss: 0.6588\n",
      "Saved the best model with validation loss: 0.6588\n",
      "Epoch [13/100], Loss: 0.6085\n",
      "Validation Loss: 0.6581\n",
      "Saved the best model with validation loss: 0.6581\n",
      "Epoch [14/100], Loss: 0.6056\n",
      "Validation Loss: 0.6558\n",
      "Saved the best model with validation loss: 0.6558\n",
      "Epoch [15/100], Loss: 0.6020\n",
      "Validation Loss: 0.6584\n",
      "Epoch [16/100], Loss: 0.5989\n",
      "Validation Loss: 0.6611\n",
      "Epoch [17/100], Loss: 0.5978\n",
      "Validation Loss: 0.6547\n",
      "Saved the best model with validation loss: 0.6547\n",
      "Epoch [18/100], Loss: 0.5945\n",
      "Validation Loss: 0.6551\n",
      "Epoch [19/100], Loss: 0.5937\n",
      "Validation Loss: 0.6596\n",
      "Epoch [20/100], Loss: 0.5919\n",
      "Validation Loss: 0.6602\n",
      "Epoch [21/100], Loss: 0.5911\n",
      "Validation Loss: 0.6593\n",
      "Epoch [22/100], Loss: 0.5892\n",
      "Validation Loss: 0.6554\n",
      "Epoch [23/100], Loss: 0.5899\n",
      "Validation Loss: 0.6454\n",
      "Saved the best model with validation loss: 0.6454\n",
      "Epoch [24/100], Loss: 0.5878\n",
      "Validation Loss: 0.6474\n",
      "Epoch [25/100], Loss: 0.5850\n",
      "Validation Loss: 0.6451\n",
      "Saved the best model with validation loss: 0.6451\n",
      "Epoch [26/100], Loss: 0.5841\n",
      "Validation Loss: 0.6446\n",
      "Saved the best model with validation loss: 0.6446\n",
      "Epoch [27/100], Loss: 0.5825\n",
      "Validation Loss: 0.6415\n",
      "Saved the best model with validation loss: 0.6415\n",
      "Epoch [28/100], Loss: 0.5803\n",
      "Validation Loss: 0.6460\n",
      "Epoch [29/100], Loss: 0.5790\n",
      "Validation Loss: 0.6466\n",
      "Epoch [30/100], Loss: 0.5766\n",
      "Validation Loss: 0.6439\n",
      "Epoch [31/100], Loss: 0.5771\n",
      "Validation Loss: 0.6451\n",
      "Epoch [32/100], Loss: 0.5758\n",
      "Validation Loss: 0.6446\n",
      "Epoch [33/100], Loss: 0.5745\n",
      "Validation Loss: 0.6450\n",
      "Epoch [34/100], Loss: 0.5735\n",
      "Validation Loss: 0.6423\n",
      "Epoch [35/100], Loss: 0.5717\n",
      "Validation Loss: 0.6465\n",
      "Epoch [36/100], Loss: 0.5722\n",
      "Validation Loss: 0.6421\n",
      "Epoch [37/100], Loss: 0.5692\n",
      "Validation Loss: 0.6419\n",
      "Epoch [38/100], Loss: 0.5696\n",
      "Validation Loss: 0.6435\n",
      "Epoch [39/100], Loss: 0.5707\n",
      "Validation Loss: 0.6403\n",
      "Saved the best model with validation loss: 0.6403\n",
      "Epoch [40/100], Loss: 0.5684\n",
      "Validation Loss: 0.6422\n",
      "Epoch [41/100], Loss: 0.5670\n",
      "Validation Loss: 0.6486\n",
      "Epoch [42/100], Loss: 0.5676\n",
      "Validation Loss: 0.6533\n",
      "Epoch [43/100], Loss: 0.5662\n",
      "Validation Loss: 0.6419\n",
      "Epoch [44/100], Loss: 0.5646\n",
      "Validation Loss: 0.6411\n",
      "Epoch [45/100], Loss: 0.5650\n",
      "Validation Loss: 0.6426\n",
      "Epoch [46/100], Loss: 0.5648\n",
      "Validation Loss: 0.6457\n",
      "Epoch [47/100], Loss: 0.5647\n",
      "Validation Loss: 0.6422\n",
      "Epoch [48/100], Loss: 0.5648\n",
      "Validation Loss: 0.6458\n",
      "Epoch [49/100], Loss: 0.5648\n",
      "Validation Loss: 0.6449\n",
      "Epoch [50/100], Loss: 0.5632\n",
      "Validation Loss: 0.6489\n",
      "Epoch [51/100], Loss: 0.5619\n",
      "Validation Loss: 0.6458\n",
      "Epoch [52/100], Loss: 0.5611\n",
      "Validation Loss: 0.6423\n",
      "Epoch [53/100], Loss: 0.5589\n",
      "Validation Loss: 0.6382\n",
      "Saved the best model with validation loss: 0.6382\n",
      "Epoch [54/100], Loss: 0.5590\n",
      "Validation Loss: 0.6436\n",
      "Epoch [55/100], Loss: 0.5599\n",
      "Validation Loss: 0.6465\n",
      "Epoch [56/100], Loss: 0.5594\n",
      "Validation Loss: 0.6377\n",
      "Saved the best model with validation loss: 0.6377\n",
      "Epoch [57/100], Loss: 0.5575\n",
      "Validation Loss: 0.6370\n",
      "Saved the best model with validation loss: 0.6370\n",
      "Epoch [58/100], Loss: 0.5578\n",
      "Validation Loss: 0.6391\n",
      "Epoch [59/100], Loss: 0.5608\n",
      "Validation Loss: 0.6400\n",
      "Epoch [60/100], Loss: 0.5587\n",
      "Validation Loss: 0.6381\n",
      "Epoch [61/100], Loss: 0.5578\n",
      "Validation Loss: 0.6410\n",
      "Epoch [62/100], Loss: 0.5590\n",
      "Validation Loss: 0.6368\n",
      "Saved the best model with validation loss: 0.6368\n",
      "Epoch [63/100], Loss: 0.5574\n",
      "Validation Loss: 0.6339\n",
      "Saved the best model with validation loss: 0.6339\n",
      "Epoch [64/100], Loss: 0.5563\n",
      "Validation Loss: 0.6387\n",
      "Epoch [65/100], Loss: 0.5550\n",
      "Validation Loss: 0.6396\n",
      "Epoch [66/100], Loss: 0.5558\n",
      "Validation Loss: 0.6354\n",
      "Epoch [67/100], Loss: 0.5551\n",
      "Validation Loss: 0.6402\n",
      "Epoch [68/100], Loss: 0.5545\n",
      "Validation Loss: 0.6418\n",
      "Epoch [69/100], Loss: 0.5540\n",
      "Validation Loss: 0.6448\n",
      "Epoch [70/100], Loss: 0.5521\n",
      "Validation Loss: 0.6384\n",
      "Epoch [71/100], Loss: 0.5522\n",
      "Validation Loss: 0.6377\n",
      "Epoch [72/100], Loss: 0.5538\n",
      "Validation Loss: 0.6372\n",
      "Epoch [73/100], Loss: 0.5517\n",
      "Validation Loss: 0.6360\n",
      "Epoch [74/100], Loss: 0.5523\n",
      "Validation Loss: 0.6379\n",
      "Epoch [75/100], Loss: 0.5514\n",
      "Validation Loss: 0.6366\n",
      "Epoch [76/100], Loss: 0.5489\n",
      "Validation Loss: 0.6364\n",
      "Epoch [77/100], Loss: 0.5504\n",
      "Validation Loss: 0.6297\n",
      "Saved the best model with validation loss: 0.6297\n",
      "Epoch [78/100], Loss: 0.5499\n",
      "Validation Loss: 0.6300\n",
      "Epoch [79/100], Loss: 0.5498\n",
      "Validation Loss: 0.6381\n",
      "Epoch [80/100], Loss: 0.5476\n",
      "Validation Loss: 0.6291\n",
      "Saved the best model with validation loss: 0.6291\n",
      "Epoch [81/100], Loss: 0.5462\n",
      "Validation Loss: 0.6305\n",
      "Epoch [82/100], Loss: 0.5482\n",
      "Validation Loss: 0.6391\n",
      "Epoch [83/100], Loss: 0.5461\n",
      "Validation Loss: 0.6347\n",
      "Epoch [84/100], Loss: 0.5446\n",
      "Validation Loss: 0.6337\n",
      "Epoch [85/100], Loss: 0.5469\n",
      "Validation Loss: 0.6426\n",
      "Epoch [86/100], Loss: 0.5470\n",
      "Validation Loss: 0.6436\n",
      "Epoch [87/100], Loss: 0.5451\n",
      "Validation Loss: 0.6360\n",
      "Epoch [88/100], Loss: 0.5459\n",
      "Validation Loss: 0.6490\n",
      "Epoch [89/100], Loss: 0.5472\n",
      "Validation Loss: 0.6379\n",
      "Epoch [90/100], Loss: 0.5454\n",
      "Validation Loss: 0.6406\n",
      "Epoch [91/100], Loss: 0.5464\n",
      "Validation Loss: 0.6379\n",
      "Epoch [92/100], Loss: 0.5455\n",
      "Validation Loss: 0.6456\n",
      "Epoch [93/100], Loss: 0.5477\n",
      "Validation Loss: 0.6425\n",
      "Epoch [94/100], Loss: 0.5463\n",
      "Validation Loss: 0.6424\n",
      "Epoch [95/100], Loss: 0.5469\n",
      "Validation Loss: 0.6437\n",
      "Epoch [96/100], Loss: 0.5478\n",
      "Validation Loss: 0.6373\n",
      "Epoch [97/100], Loss: 0.5459\n",
      "Validation Loss: 0.6331\n",
      "Epoch [98/100], Loss: 0.5467\n",
      "Validation Loss: 0.6438\n",
      "Epoch [99/100], Loss: 0.5456\n",
      "Validation Loss: 0.6471\n",
      "Epoch [100/100], Loss: 0.5445\n",
      "Validation Loss: 0.6400\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"combi 0.1: 17-80-50-3/1-16-32-3/6-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "1beb4d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.8848\n",
      "Validation Loss: 0.7385\n",
      "Saved the best model with validation loss: 0.7385\n",
      "Epoch [2/100], Loss: 0.7064\n",
      "Validation Loss: 0.6816\n",
      "Saved the best model with validation loss: 0.6816\n",
      "Epoch [3/100], Loss: 0.6626\n",
      "Validation Loss: 0.6659\n",
      "Saved the best model with validation loss: 0.6659\n",
      "Epoch [4/100], Loss: 0.6422\n",
      "Validation Loss: 0.6566\n",
      "Saved the best model with validation loss: 0.6566\n",
      "Epoch [5/100], Loss: 0.6249\n",
      "Validation Loss: 0.6430\n",
      "Saved the best model with validation loss: 0.6430\n",
      "Epoch [6/100], Loss: 0.6137\n",
      "Validation Loss: 0.6270\n",
      "Saved the best model with validation loss: 0.6270\n",
      "Epoch [7/100], Loss: 0.6033\n",
      "Validation Loss: 0.6204\n",
      "Saved the best model with validation loss: 0.6204\n",
      "Epoch [8/100], Loss: 0.5959\n",
      "Validation Loss: 0.6181\n",
      "Saved the best model with validation loss: 0.6181\n",
      "Epoch [9/100], Loss: 0.5908\n",
      "Validation Loss: 0.6177\n",
      "Saved the best model with validation loss: 0.6177\n",
      "Epoch [10/100], Loss: 0.5858\n",
      "Validation Loss: 0.6094\n",
      "Saved the best model with validation loss: 0.6094\n",
      "Epoch [11/100], Loss: 0.5801\n",
      "Validation Loss: 0.6109\n",
      "Epoch [12/100], Loss: 0.5756\n",
      "Validation Loss: 0.6070\n",
      "Saved the best model with validation loss: 0.6070\n",
      "Epoch [13/100], Loss: 0.5727\n",
      "Validation Loss: 0.6007\n",
      "Saved the best model with validation loss: 0.6007\n",
      "Epoch [14/100], Loss: 0.5702\n",
      "Validation Loss: 0.5998\n",
      "Saved the best model with validation loss: 0.5998\n",
      "Epoch [15/100], Loss: 0.5670\n",
      "Validation Loss: 0.6085\n",
      "Epoch [16/100], Loss: 0.5630\n",
      "Validation Loss: 0.6096\n",
      "Epoch [17/100], Loss: 0.5631\n",
      "Validation Loss: 0.6125\n",
      "Epoch [18/100], Loss: 0.5618\n",
      "Validation Loss: 0.6013\n",
      "Epoch [19/100], Loss: 0.5598\n",
      "Validation Loss: 0.6032\n",
      "Epoch [20/100], Loss: 0.5562\n",
      "Validation Loss: 0.5941\n",
      "Saved the best model with validation loss: 0.5941\n",
      "Epoch [21/100], Loss: 0.5551\n",
      "Validation Loss: 0.6044\n",
      "Epoch [22/100], Loss: 0.5557\n",
      "Validation Loss: 0.5990\n",
      "Epoch [23/100], Loss: 0.5535\n",
      "Validation Loss: 0.5982\n",
      "Epoch [24/100], Loss: 0.5510\n",
      "Validation Loss: 0.5975\n",
      "Epoch [25/100], Loss: 0.5503\n",
      "Validation Loss: 0.6029\n",
      "Epoch [26/100], Loss: 0.5482\n",
      "Validation Loss: 0.5957\n",
      "Epoch [27/100], Loss: 0.5478\n",
      "Validation Loss: 0.5943\n",
      "Epoch [28/100], Loss: 0.5464\n",
      "Validation Loss: 0.5897\n",
      "Saved the best model with validation loss: 0.5897\n",
      "Epoch [29/100], Loss: 0.5454\n",
      "Validation Loss: 0.5924\n",
      "Epoch [30/100], Loss: 0.5446\n",
      "Validation Loss: 0.5965\n",
      "Epoch [31/100], Loss: 0.5442\n",
      "Validation Loss: 0.5940\n",
      "Epoch [32/100], Loss: 0.5417\n",
      "Validation Loss: 0.5994\n",
      "Epoch [33/100], Loss: 0.5410\n",
      "Validation Loss: 0.5960\n",
      "Epoch [34/100], Loss: 0.5390\n",
      "Validation Loss: 0.5951\n",
      "Epoch [35/100], Loss: 0.5392\n",
      "Validation Loss: 0.5935\n",
      "Epoch [36/100], Loss: 0.5396\n",
      "Validation Loss: 0.5933\n",
      "Epoch [37/100], Loss: 0.5369\n",
      "Validation Loss: 0.5914\n",
      "Epoch [38/100], Loss: 0.5356\n",
      "Validation Loss: 0.5951\n",
      "Epoch [39/100], Loss: 0.5369\n",
      "Validation Loss: 0.5977\n",
      "Epoch [40/100], Loss: 0.5356\n",
      "Validation Loss: 0.5920\n",
      "Epoch [41/100], Loss: 0.5343\n",
      "Validation Loss: 0.5960\n",
      "Epoch [42/100], Loss: 0.5344\n",
      "Validation Loss: 0.5994\n",
      "Epoch [43/100], Loss: 0.5338\n",
      "Validation Loss: 0.5907\n",
      "Epoch [44/100], Loss: 0.5334\n",
      "Validation Loss: 0.6008\n",
      "Epoch [45/100], Loss: 0.5326\n",
      "Validation Loss: 0.5962\n",
      "Epoch [46/100], Loss: 0.5309\n",
      "Validation Loss: 0.5932\n",
      "Epoch [47/100], Loss: 0.5316\n",
      "Validation Loss: 0.5983\n",
      "Epoch [48/100], Loss: 0.5312\n",
      "Validation Loss: 0.5972\n",
      "Epoch [49/100], Loss: 0.5289\n",
      "Validation Loss: 0.5936\n",
      "Epoch [50/100], Loss: 0.5292\n",
      "Validation Loss: 0.6091\n",
      "Epoch [51/100], Loss: 0.5284\n",
      "Validation Loss: 0.5972\n",
      "Epoch [52/100], Loss: 0.5269\n",
      "Validation Loss: 0.5979\n",
      "Epoch [53/100], Loss: 0.5267\n",
      "Validation Loss: 0.5927\n",
      "Epoch [54/100], Loss: 0.5277\n",
      "Validation Loss: 0.5902\n",
      "Epoch [55/100], Loss: 0.5261\n",
      "Validation Loss: 0.5892\n",
      "Saved the best model with validation loss: 0.5892\n",
      "Epoch [56/100], Loss: 0.5263\n",
      "Validation Loss: 0.5932\n",
      "Epoch [57/100], Loss: 0.5240\n",
      "Validation Loss: 0.5898\n",
      "Epoch [58/100], Loss: 0.5230\n",
      "Validation Loss: 0.5945\n",
      "Epoch [59/100], Loss: 0.5219\n",
      "Validation Loss: 0.5843\n",
      "Saved the best model with validation loss: 0.5843\n",
      "Epoch [60/100], Loss: 0.5239\n",
      "Validation Loss: 0.5917\n",
      "Epoch [61/100], Loss: 0.5221\n",
      "Validation Loss: 0.5967\n",
      "Epoch [62/100], Loss: 0.5218\n",
      "Validation Loss: 0.5963\n",
      "Epoch [63/100], Loss: 0.5219\n",
      "Validation Loss: 0.5895\n",
      "Epoch [64/100], Loss: 0.5216\n",
      "Validation Loss: 0.5994\n",
      "Epoch [65/100], Loss: 0.5215\n",
      "Validation Loss: 0.6003\n",
      "Epoch [66/100], Loss: 0.5213\n",
      "Validation Loss: 0.5943\n",
      "Epoch [67/100], Loss: 0.5204\n",
      "Validation Loss: 0.5901\n",
      "Epoch [68/100], Loss: 0.5221\n",
      "Validation Loss: 0.5877\n",
      "Epoch [69/100], Loss: 0.5221\n",
      "Validation Loss: 0.5874\n",
      "Epoch [70/100], Loss: 0.5185\n",
      "Validation Loss: 0.5866\n",
      "Epoch [71/100], Loss: 0.5184\n",
      "Validation Loss: 0.5912\n",
      "Epoch [72/100], Loss: 0.5204\n",
      "Validation Loss: 0.5848\n",
      "Epoch [73/100], Loss: 0.5203\n",
      "Validation Loss: 0.5892\n",
      "Epoch [74/100], Loss: 0.5200\n",
      "Validation Loss: 0.6031\n",
      "Epoch [75/100], Loss: 0.5220\n",
      "Validation Loss: 0.5951\n",
      "Epoch [76/100], Loss: 0.5230\n",
      "Validation Loss: 0.5870\n",
      "Epoch [77/100], Loss: 0.5214\n",
      "Validation Loss: 0.6069\n",
      "Epoch [78/100], Loss: 0.5189\n",
      "Validation Loss: 0.5970\n",
      "Epoch [79/100], Loss: 0.5211\n",
      "Validation Loss: 0.5940\n",
      "Epoch [80/100], Loss: 0.5177\n",
      "Validation Loss: 0.5849\n",
      "Epoch [81/100], Loss: 0.5181\n",
      "Validation Loss: 0.5942\n",
      "Epoch [82/100], Loss: 0.5200\n",
      "Validation Loss: 0.5917\n",
      "Epoch [83/100], Loss: 0.5188\n",
      "Validation Loss: 0.6094\n",
      "Epoch [84/100], Loss: 0.5169\n",
      "Validation Loss: 0.5966\n",
      "Epoch [85/100], Loss: 0.5193\n",
      "Validation Loss: 0.5839\n",
      "Saved the best model with validation loss: 0.5839\n",
      "Epoch [86/100], Loss: 0.5193\n",
      "Validation Loss: 0.6058\n",
      "Epoch [87/100], Loss: 0.5169\n",
      "Validation Loss: 0.6031\n",
      "Epoch [88/100], Loss: 0.5182\n",
      "Validation Loss: 0.5940\n",
      "Epoch [89/100], Loss: 0.5171\n",
      "Validation Loss: 0.6024\n",
      "Epoch [90/100], Loss: 0.5164\n",
      "Validation Loss: 0.5879\n",
      "Epoch [91/100], Loss: 0.5160\n",
      "Validation Loss: 0.5974\n",
      "Epoch [92/100], Loss: 0.5135\n",
      "Validation Loss: 0.5911\n",
      "Epoch [93/100], Loss: 0.5162\n",
      "Validation Loss: 0.5891\n",
      "Epoch [94/100], Loss: 0.5155\n",
      "Validation Loss: 0.5941\n",
      "Epoch [95/100], Loss: 0.5135\n",
      "Validation Loss: 0.5912\n",
      "Epoch [96/100], Loss: 0.5151\n",
      "Validation Loss: 0.5920\n",
      "Epoch [97/100], Loss: 0.5156\n",
      "Validation Loss: 0.5832\n",
      "Saved the best model with validation loss: 0.5832\n",
      "Epoch [98/100], Loss: 0.5143\n",
      "Validation Loss: 0.5910\n",
      "Epoch [99/100], Loss: 0.5143\n",
      "Validation Loss: 0.5837\n",
      "Epoch [100/100], Loss: 0.5127\n",
      "Validation Loss: 0.5845\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"combi 0.05: 17-80-50-3/1-16-32-3/6-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "c14721ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7034\n",
      "Validation Loss: 0.5364\n",
      "Saved the best model with validation loss: 0.5364\n",
      "Epoch [2/100], Loss: 0.5533\n",
      "Validation Loss: 0.4889\n",
      "Saved the best model with validation loss: 0.4889\n",
      "Epoch [3/100], Loss: 0.5219\n",
      "Validation Loss: 0.4671\n",
      "Saved the best model with validation loss: 0.4671\n",
      "Epoch [4/100], Loss: 0.5047\n",
      "Validation Loss: 0.4568\n",
      "Saved the best model with validation loss: 0.4568\n",
      "Epoch [5/100], Loss: 0.4948\n",
      "Validation Loss: 0.4509\n",
      "Saved the best model with validation loss: 0.4509\n",
      "Epoch [6/100], Loss: 0.4887\n",
      "Validation Loss: 0.4392\n",
      "Saved the best model with validation loss: 0.4392\n",
      "Epoch [7/100], Loss: 0.4824\n",
      "Validation Loss: 0.4371\n",
      "Saved the best model with validation loss: 0.4371\n",
      "Epoch [8/100], Loss: 0.4789\n",
      "Validation Loss: 0.4337\n",
      "Saved the best model with validation loss: 0.4337\n",
      "Epoch [9/100], Loss: 0.4745\n",
      "Validation Loss: 0.4373\n",
      "Epoch [10/100], Loss: 0.4729\n",
      "Validation Loss: 0.4331\n",
      "Saved the best model with validation loss: 0.4331\n",
      "Epoch [11/100], Loss: 0.4697\n",
      "Validation Loss: 0.4328\n",
      "Saved the best model with validation loss: 0.4328\n",
      "Epoch [12/100], Loss: 0.4702\n",
      "Validation Loss: 0.4329\n",
      "Epoch [13/100], Loss: 0.4674\n",
      "Validation Loss: 0.4274\n",
      "Saved the best model with validation loss: 0.4274\n",
      "Epoch [14/100], Loss: 0.4658\n",
      "Validation Loss: 0.4254\n",
      "Saved the best model with validation loss: 0.4254\n",
      "Epoch [15/100], Loss: 0.4635\n",
      "Validation Loss: 0.4233\n",
      "Saved the best model with validation loss: 0.4233\n",
      "Epoch [16/100], Loss: 0.4629\n",
      "Validation Loss: 0.4267\n",
      "Epoch [17/100], Loss: 0.4623\n",
      "Validation Loss: 0.4296\n",
      "Epoch [18/100], Loss: 0.4612\n",
      "Validation Loss: 0.4227\n",
      "Saved the best model with validation loss: 0.4227\n",
      "Epoch [19/100], Loss: 0.4593\n",
      "Validation Loss: 0.4198\n",
      "Saved the best model with validation loss: 0.4198\n",
      "Epoch [20/100], Loss: 0.4583\n",
      "Validation Loss: 0.4195\n",
      "Saved the best model with validation loss: 0.4195\n",
      "Epoch [21/100], Loss: 0.4560\n",
      "Validation Loss: 0.4251\n",
      "Epoch [22/100], Loss: 0.4560\n",
      "Validation Loss: 0.4234\n",
      "Epoch [23/100], Loss: 0.4539\n",
      "Validation Loss: 0.4232\n",
      "Epoch [24/100], Loss: 0.4526\n",
      "Validation Loss: 0.4222\n",
      "Epoch [25/100], Loss: 0.4514\n",
      "Validation Loss: 0.4263\n",
      "Epoch [26/100], Loss: 0.4511\n",
      "Validation Loss: 0.4207\n",
      "Epoch [27/100], Loss: 0.4500\n",
      "Validation Loss: 0.4245\n",
      "Epoch [28/100], Loss: 0.4498\n",
      "Validation Loss: 0.4251\n",
      "Epoch [29/100], Loss: 0.4491\n",
      "Validation Loss: 0.4229\n",
      "Epoch [30/100], Loss: 0.4488\n",
      "Validation Loss: 0.4207\n",
      "Epoch [31/100], Loss: 0.4478\n",
      "Validation Loss: 0.4203\n",
      "Epoch [32/100], Loss: 0.4458\n",
      "Validation Loss: 0.4176\n",
      "Saved the best model with validation loss: 0.4176\n",
      "Epoch [33/100], Loss: 0.4448\n",
      "Validation Loss: 0.4183\n",
      "Epoch [34/100], Loss: 0.4437\n",
      "Validation Loss: 0.4177\n",
      "Epoch [35/100], Loss: 0.4444\n",
      "Validation Loss: 0.4157\n",
      "Saved the best model with validation loss: 0.4157\n",
      "Epoch [36/100], Loss: 0.4431\n",
      "Validation Loss: 0.4257\n",
      "Epoch [37/100], Loss: 0.4417\n",
      "Validation Loss: 0.4206\n",
      "Epoch [38/100], Loss: 0.4422\n",
      "Validation Loss: 0.4194\n",
      "Epoch [39/100], Loss: 0.4411\n",
      "Validation Loss: 0.4191\n",
      "Epoch [40/100], Loss: 0.4405\n",
      "Validation Loss: 0.4247\n",
      "Epoch [41/100], Loss: 0.4396\n",
      "Validation Loss: 0.4223\n",
      "Epoch [42/100], Loss: 0.4404\n",
      "Validation Loss: 0.4209\n",
      "Epoch [43/100], Loss: 0.4386\n",
      "Validation Loss: 0.4339\n",
      "Epoch [44/100], Loss: 0.4393\n",
      "Validation Loss: 0.4218\n",
      "Epoch [45/100], Loss: 0.4389\n",
      "Validation Loss: 0.4279\n",
      "Epoch [46/100], Loss: 0.4379\n",
      "Validation Loss: 0.4242\n",
      "Epoch [47/100], Loss: 0.4382\n",
      "Validation Loss: 0.4286\n",
      "Epoch [48/100], Loss: 0.4376\n",
      "Validation Loss: 0.4242\n",
      "Epoch [49/100], Loss: 0.4358\n",
      "Validation Loss: 0.4149\n",
      "Saved the best model with validation loss: 0.4149\n",
      "Epoch [50/100], Loss: 0.4356\n",
      "Validation Loss: 0.4242\n",
      "Epoch [51/100], Loss: 0.4358\n",
      "Validation Loss: 0.4195\n",
      "Epoch [52/100], Loss: 0.4365\n",
      "Validation Loss: 0.4185\n",
      "Epoch [53/100], Loss: 0.4350\n",
      "Validation Loss: 0.4234\n",
      "Epoch [54/100], Loss: 0.4361\n",
      "Validation Loss: 0.4158\n",
      "Epoch [55/100], Loss: 0.4366\n",
      "Validation Loss: 0.4429\n",
      "Epoch [56/100], Loss: 0.4356\n",
      "Validation Loss: 0.4188\n",
      "Epoch [57/100], Loss: 0.4348\n",
      "Validation Loss: 0.4145\n",
      "Saved the best model with validation loss: 0.4145\n",
      "Epoch [58/100], Loss: 0.4359\n",
      "Validation Loss: 0.4358\n",
      "Epoch [59/100], Loss: 0.4360\n",
      "Validation Loss: 0.4165\n",
      "Epoch [60/100], Loss: 0.4354\n",
      "Validation Loss: 0.4260\n",
      "Epoch [61/100], Loss: 0.4345\n",
      "Validation Loss: 0.4157\n",
      "Epoch [62/100], Loss: 0.4338\n",
      "Validation Loss: 0.4202\n",
      "Epoch [63/100], Loss: 0.4342\n",
      "Validation Loss: 0.4265\n",
      "Epoch [64/100], Loss: 0.4339\n",
      "Validation Loss: 0.4179\n",
      "Epoch [65/100], Loss: 0.4350\n",
      "Validation Loss: 0.4165\n",
      "Epoch [66/100], Loss: 0.4322\n",
      "Validation Loss: 0.4203\n",
      "Epoch [67/100], Loss: 0.4321\n",
      "Validation Loss: 0.4158\n",
      "Epoch [68/100], Loss: 0.4314\n",
      "Validation Loss: 0.4146\n",
      "Epoch [69/100], Loss: 0.4324\n",
      "Validation Loss: 0.4174\n",
      "Epoch [70/100], Loss: 0.4323\n",
      "Validation Loss: 0.4176\n",
      "Epoch [71/100], Loss: 0.4311\n",
      "Validation Loss: 0.4221\n",
      "Epoch [72/100], Loss: 0.4309\n",
      "Validation Loss: 0.4235\n",
      "Epoch [73/100], Loss: 0.4307\n",
      "Validation Loss: 0.4161\n",
      "Epoch [74/100], Loss: 0.4316\n",
      "Validation Loss: 0.4155\n",
      "Epoch [75/100], Loss: 0.4317\n",
      "Validation Loss: 0.4202\n",
      "Epoch [76/100], Loss: 0.4308\n",
      "Validation Loss: 0.4235\n",
      "Epoch [77/100], Loss: 0.4298\n",
      "Validation Loss: 0.4170\n",
      "Epoch [78/100], Loss: 0.4305\n",
      "Validation Loss: 0.4153\n",
      "Epoch [79/100], Loss: 0.4292\n",
      "Validation Loss: 0.4148\n",
      "Epoch [80/100], Loss: 0.4293\n",
      "Validation Loss: 0.4143\n",
      "Saved the best model with validation loss: 0.4143\n",
      "Epoch [81/100], Loss: 0.4304\n",
      "Validation Loss: 0.4218\n",
      "Epoch [82/100], Loss: 0.4294\n",
      "Validation Loss: 0.4081\n",
      "Saved the best model with validation loss: 0.4081\n",
      "Epoch [83/100], Loss: 0.4294\n",
      "Validation Loss: 0.4199\n",
      "Epoch [84/100], Loss: 0.4290\n",
      "Validation Loss: 0.4161\n",
      "Epoch [85/100], Loss: 0.4295\n",
      "Validation Loss: 0.4242\n",
      "Epoch [86/100], Loss: 0.4280\n",
      "Validation Loss: 0.4129\n",
      "Epoch [87/100], Loss: 0.4284\n",
      "Validation Loss: 0.4060\n",
      "Saved the best model with validation loss: 0.4060\n",
      "Epoch [88/100], Loss: 0.4290\n",
      "Validation Loss: 0.4175\n",
      "Epoch [89/100], Loss: 0.4259\n",
      "Validation Loss: 0.4056\n",
      "Saved the best model with validation loss: 0.4056\n",
      "Epoch [90/100], Loss: 0.4265\n",
      "Validation Loss: 0.4069\n",
      "Epoch [91/100], Loss: 0.4264\n",
      "Validation Loss: 0.4174\n",
      "Epoch [92/100], Loss: 0.4258\n",
      "Validation Loss: 0.4128\n",
      "Epoch [93/100], Loss: 0.4257\n",
      "Validation Loss: 0.4143\n",
      "Epoch [94/100], Loss: 0.4255\n",
      "Validation Loss: 0.4087\n",
      "Epoch [95/100], Loss: 0.4250\n",
      "Validation Loss: 0.4138\n",
      "Epoch [96/100], Loss: 0.4261\n",
      "Validation Loss: 0.4199\n",
      "Epoch [97/100], Loss: 0.4245\n",
      "Validation Loss: 0.4057\n",
      "Epoch [98/100], Loss: 0.4250\n",
      "Validation Loss: 0.4159\n",
      "Epoch [99/100], Loss: 0.4266\n",
      "Validation Loss: 0.4114\n",
      "Epoch [100/100], Loss: 0.4243\n",
      "Validation Loss: 0.4052\n",
      "Saved the best model with validation loss: 0.4052\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"combi 0.01: 17-80-50-3/1-16-32-3/6-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352815a",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 2, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  MLP 17-80-50-5\n",
    "*  HGNN 1-16-32-5\n",
    "*  Combined 10-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "97c43284",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(10, 3)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "c3a27e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.8185\n",
      "Validation Loss: 0.6003\n",
      "Saved the best model with validation loss: 0.6003\n",
      "Epoch [2/100], Loss: 0.6086\n",
      "Validation Loss: 0.5097\n",
      "Saved the best model with validation loss: 0.5097\n",
      "Epoch [3/100], Loss: 0.5435\n",
      "Validation Loss: 0.4816\n",
      "Saved the best model with validation loss: 0.4816\n",
      "Epoch [4/100], Loss: 0.5178\n",
      "Validation Loss: 0.4704\n",
      "Saved the best model with validation loss: 0.4704\n",
      "Epoch [5/100], Loss: 0.5018\n",
      "Validation Loss: 0.4641\n",
      "Saved the best model with validation loss: 0.4641\n",
      "Epoch [6/100], Loss: 0.4897\n",
      "Validation Loss: 0.4576\n",
      "Saved the best model with validation loss: 0.4576\n",
      "Epoch [7/100], Loss: 0.4811\n",
      "Validation Loss: 0.4487\n",
      "Saved the best model with validation loss: 0.4487\n",
      "Epoch [8/100], Loss: 0.4740\n",
      "Validation Loss: 0.4410\n",
      "Saved the best model with validation loss: 0.4410\n",
      "Epoch [9/100], Loss: 0.4702\n",
      "Validation Loss: 0.4340\n",
      "Saved the best model with validation loss: 0.4340\n",
      "Epoch [10/100], Loss: 0.4651\n",
      "Validation Loss: 0.4342\n",
      "Epoch [11/100], Loss: 0.4598\n",
      "Validation Loss: 0.4411\n",
      "Epoch [12/100], Loss: 0.4563\n",
      "Validation Loss: 0.4366\n",
      "Epoch [13/100], Loss: 0.4534\n",
      "Validation Loss: 0.4381\n",
      "Epoch [14/100], Loss: 0.4512\n",
      "Validation Loss: 0.4444\n",
      "Epoch [15/100], Loss: 0.4489\n",
      "Validation Loss: 0.4464\n",
      "Epoch [16/100], Loss: 0.4448\n",
      "Validation Loss: 0.4483\n",
      "Epoch [17/100], Loss: 0.4422\n",
      "Validation Loss: 0.4602\n",
      "Epoch [18/100], Loss: 0.4397\n",
      "Validation Loss: 0.4607\n",
      "Epoch [19/100], Loss: 0.4398\n",
      "Validation Loss: 0.4260\n",
      "Saved the best model with validation loss: 0.4260\n",
      "Epoch [20/100], Loss: 0.4367\n",
      "Validation Loss: 0.4349\n",
      "Epoch [21/100], Loss: 0.4374\n",
      "Validation Loss: 0.4319\n",
      "Epoch [22/100], Loss: 0.4339\n",
      "Validation Loss: 0.4387\n",
      "Epoch [23/100], Loss: 0.4333\n",
      "Validation Loss: 0.4279\n",
      "Epoch [24/100], Loss: 0.4307\n",
      "Validation Loss: 0.4334\n",
      "Epoch [25/100], Loss: 0.4304\n",
      "Validation Loss: 0.4219\n",
      "Saved the best model with validation loss: 0.4219\n",
      "Epoch [26/100], Loss: 0.4294\n",
      "Validation Loss: 0.4295\n",
      "Epoch [27/100], Loss: 0.4285\n",
      "Validation Loss: 0.4618\n",
      "Epoch [28/100], Loss: 0.4290\n",
      "Validation Loss: 0.4285\n",
      "Epoch [29/100], Loss: 0.4268\n",
      "Validation Loss: 0.4245\n",
      "Epoch [30/100], Loss: 0.4272\n",
      "Validation Loss: 0.4266\n",
      "Epoch [31/100], Loss: 0.4243\n",
      "Validation Loss: 0.4192\n",
      "Saved the best model with validation loss: 0.4192\n",
      "Epoch [32/100], Loss: 0.4235\n",
      "Validation Loss: 0.4156\n",
      "Saved the best model with validation loss: 0.4156\n",
      "Epoch [33/100], Loss: 0.4234\n",
      "Validation Loss: 0.4233\n",
      "Epoch [34/100], Loss: 0.4230\n",
      "Validation Loss: 0.4128\n",
      "Saved the best model with validation loss: 0.4128\n",
      "Epoch [35/100], Loss: 0.4216\n",
      "Validation Loss: 0.4205\n",
      "Epoch [36/100], Loss: 0.4208\n",
      "Validation Loss: 0.4141\n",
      "Epoch [37/100], Loss: 0.4248\n",
      "Validation Loss: 0.4084\n",
      "Saved the best model with validation loss: 0.4084\n",
      "Epoch [38/100], Loss: 0.4193\n",
      "Validation Loss: 0.4140\n",
      "Epoch [39/100], Loss: 0.4206\n",
      "Validation Loss: 0.4763\n",
      "Epoch [40/100], Loss: 0.4209\n",
      "Validation Loss: 0.4172\n",
      "Epoch [41/100], Loss: 0.4199\n",
      "Validation Loss: 0.4292\n",
      "Epoch [42/100], Loss: 0.4182\n",
      "Validation Loss: 0.4161\n",
      "Epoch [43/100], Loss: 0.4168\n",
      "Validation Loss: 0.4562\n",
      "Epoch [44/100], Loss: 0.4166\n",
      "Validation Loss: 0.4130\n",
      "Epoch [45/100], Loss: 0.4175\n",
      "Validation Loss: 0.4112\n",
      "Epoch [46/100], Loss: 0.4165\n",
      "Validation Loss: 0.4192\n",
      "Epoch [47/100], Loss: 0.4192\n",
      "Validation Loss: 0.4191\n",
      "Epoch [48/100], Loss: 0.4159\n",
      "Validation Loss: 0.4432\n",
      "Epoch [49/100], Loss: 0.4192\n",
      "Validation Loss: 0.4148\n",
      "Epoch [50/100], Loss: 0.4136\n",
      "Validation Loss: 0.4360\n",
      "Epoch [51/100], Loss: 0.4168\n",
      "Validation Loss: 0.4250\n",
      "Epoch [52/100], Loss: 0.4146\n",
      "Validation Loss: 0.4521\n",
      "Epoch [53/100], Loss: 0.4143\n",
      "Validation Loss: 0.4318\n",
      "Epoch [54/100], Loss: 0.4116\n",
      "Validation Loss: 0.4170\n",
      "Epoch [55/100], Loss: 0.4112\n",
      "Validation Loss: 0.4116\n",
      "Epoch [56/100], Loss: 0.4118\n",
      "Validation Loss: 0.4363\n",
      "Epoch [57/100], Loss: 0.4114\n",
      "Validation Loss: 0.4587\n",
      "Epoch [58/100], Loss: 0.4086\n",
      "Validation Loss: 0.4549\n",
      "Epoch [59/100], Loss: 0.4115\n",
      "Validation Loss: 0.4719\n",
      "Epoch [60/100], Loss: 0.4102\n",
      "Validation Loss: 0.4664\n",
      "Epoch [61/100], Loss: 0.4081\n",
      "Validation Loss: 0.4298\n",
      "Epoch [62/100], Loss: 0.4095\n",
      "Validation Loss: 0.4419\n",
      "Epoch [63/100], Loss: 0.4109\n",
      "Validation Loss: 0.4395\n",
      "Epoch [64/100], Loss: 0.4114\n",
      "Validation Loss: 0.4465\n",
      "Epoch [65/100], Loss: 0.4079\n",
      "Validation Loss: 0.4557\n",
      "Epoch [66/100], Loss: 0.4088\n",
      "Validation Loss: 0.4248\n",
      "Epoch [67/100], Loss: 0.4095\n",
      "Validation Loss: 0.4225\n",
      "Epoch [68/100], Loss: 0.4090\n",
      "Validation Loss: 0.4145\n",
      "Epoch [69/100], Loss: 0.4066\n",
      "Validation Loss: 0.4093\n",
      "Epoch [70/100], Loss: 0.4093\n",
      "Validation Loss: 0.4234\n",
      "Epoch [71/100], Loss: 0.4068\n",
      "Validation Loss: 0.4189\n",
      "Epoch [72/100], Loss: 0.4058\n",
      "Validation Loss: 0.4159\n",
      "Epoch [73/100], Loss: 0.4056\n",
      "Validation Loss: 0.4342\n",
      "Epoch [74/100], Loss: 0.4079\n",
      "Validation Loss: 0.4134\n",
      "Epoch [75/100], Loss: 0.4078\n",
      "Validation Loss: 0.4099\n",
      "Epoch [76/100], Loss: 0.4064\n",
      "Validation Loss: 0.4074\n",
      "Saved the best model with validation loss: 0.4074\n",
      "Epoch [77/100], Loss: 0.4080\n",
      "Validation Loss: 0.4245\n",
      "Epoch [78/100], Loss: 0.4043\n",
      "Validation Loss: 0.4125\n",
      "Epoch [79/100], Loss: 0.4059\n",
      "Validation Loss: 0.4131\n",
      "Epoch [80/100], Loss: 0.4037\n",
      "Validation Loss: 0.4085\n",
      "Epoch [81/100], Loss: 0.4075\n",
      "Validation Loss: 0.3951\n",
      "Saved the best model with validation loss: 0.3951\n",
      "Epoch [82/100], Loss: 0.4047\n",
      "Validation Loss: 0.4099\n",
      "Epoch [83/100], Loss: 0.4053\n",
      "Validation Loss: 0.4073\n",
      "Epoch [84/100], Loss: 0.4049\n",
      "Validation Loss: 0.4078\n",
      "Epoch [85/100], Loss: 0.4086\n",
      "Validation Loss: 0.4084\n",
      "Epoch [86/100], Loss: 0.4041\n",
      "Validation Loss: 0.4190\n",
      "Epoch [87/100], Loss: 0.4057\n",
      "Validation Loss: 0.4137\n",
      "Epoch [88/100], Loss: 0.4022\n",
      "Validation Loss: 0.4551\n",
      "Epoch [89/100], Loss: 0.4061\n",
      "Validation Loss: 0.4064\n",
      "Epoch [90/100], Loss: 0.4035\n",
      "Validation Loss: 0.4111\n",
      "Epoch [91/100], Loss: 0.4045\n",
      "Validation Loss: 0.4350\n",
      "Epoch [92/100], Loss: 0.4054\n",
      "Validation Loss: 0.4089\n",
      "Epoch [93/100], Loss: 0.4026\n",
      "Validation Loss: 0.4121\n",
      "Epoch [94/100], Loss: 0.4044\n",
      "Validation Loss: 0.4077\n",
      "Epoch [95/100], Loss: 0.4057\n",
      "Validation Loss: 0.4168\n",
      "Epoch [96/100], Loss: 0.4036\n",
      "Validation Loss: 0.4179\n",
      "Epoch [97/100], Loss: 0.4036\n",
      "Validation Loss: 0.4227\n",
      "Epoch [98/100], Loss: 0.4061\n",
      "Validation Loss: 0.4132\n",
      "Epoch [99/100], Loss: 0.4016\n",
      "Validation Loss: 0.4146\n",
      "Epoch [100/100], Loss: 0.4044\n",
      "Validation Loss: 0.4141\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"combi 0.5: 17-80-50-5/1-16-32-5/10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "51d63488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.9138\n",
      "Validation Loss: 0.7750\n",
      "Saved the best model with validation loss: 0.7750\n",
      "Epoch [2/100], Loss: 0.7332\n",
      "Validation Loss: 0.7224\n",
      "Saved the best model with validation loss: 0.7224\n",
      "Epoch [3/100], Loss: 0.6872\n",
      "Validation Loss: 0.7042\n",
      "Saved the best model with validation loss: 0.7042\n",
      "Epoch [4/100], Loss: 0.6641\n",
      "Validation Loss: 0.6955\n",
      "Saved the best model with validation loss: 0.6955\n",
      "Epoch [5/100], Loss: 0.6499\n",
      "Validation Loss: 0.6793\n",
      "Saved the best model with validation loss: 0.6793\n",
      "Epoch [6/100], Loss: 0.6394\n",
      "Validation Loss: 0.6764\n",
      "Saved the best model with validation loss: 0.6764\n",
      "Epoch [7/100], Loss: 0.6323\n",
      "Validation Loss: 0.6642\n",
      "Saved the best model with validation loss: 0.6642\n",
      "Epoch [8/100], Loss: 0.6255\n",
      "Validation Loss: 0.6586\n",
      "Saved the best model with validation loss: 0.6586\n",
      "Epoch [9/100], Loss: 0.6189\n",
      "Validation Loss: 0.6581\n",
      "Saved the best model with validation loss: 0.6581\n",
      "Epoch [10/100], Loss: 0.6151\n",
      "Validation Loss: 0.6528\n",
      "Saved the best model with validation loss: 0.6528\n",
      "Epoch [11/100], Loss: 0.6106\n",
      "Validation Loss: 0.6507\n",
      "Saved the best model with validation loss: 0.6507\n",
      "Epoch [12/100], Loss: 0.6074\n",
      "Validation Loss: 0.6480\n",
      "Saved the best model with validation loss: 0.6480\n",
      "Epoch [13/100], Loss: 0.6045\n",
      "Validation Loss: 0.6431\n",
      "Saved the best model with validation loss: 0.6431\n",
      "Epoch [14/100], Loss: 0.6017\n",
      "Validation Loss: 0.6401\n",
      "Saved the best model with validation loss: 0.6401\n",
      "Epoch [15/100], Loss: 0.5995\n",
      "Validation Loss: 0.6379\n",
      "Saved the best model with validation loss: 0.6379\n",
      "Epoch [16/100], Loss: 0.5972\n",
      "Validation Loss: 0.6369\n",
      "Saved the best model with validation loss: 0.6369\n",
      "Epoch [17/100], Loss: 0.5943\n",
      "Validation Loss: 0.6370\n",
      "Epoch [18/100], Loss: 0.5934\n",
      "Validation Loss: 0.6362\n",
      "Saved the best model with validation loss: 0.6362\n",
      "Epoch [19/100], Loss: 0.5937\n",
      "Validation Loss: 0.6329\n",
      "Saved the best model with validation loss: 0.6329\n",
      "Epoch [20/100], Loss: 0.5917\n",
      "Validation Loss: 0.6326\n",
      "Saved the best model with validation loss: 0.6326\n",
      "Epoch [21/100], Loss: 0.5871\n",
      "Validation Loss: 0.6300\n",
      "Saved the best model with validation loss: 0.6300\n",
      "Epoch [22/100], Loss: 0.5874\n",
      "Validation Loss: 0.6297\n",
      "Saved the best model with validation loss: 0.6297\n",
      "Epoch [23/100], Loss: 0.5847\n",
      "Validation Loss: 0.6330\n",
      "Epoch [24/100], Loss: 0.5837\n",
      "Validation Loss: 0.6375\n",
      "Epoch [25/100], Loss: 0.5844\n",
      "Validation Loss: 0.6359\n",
      "Epoch [26/100], Loss: 0.5818\n",
      "Validation Loss: 0.6364\n",
      "Epoch [27/100], Loss: 0.5816\n",
      "Validation Loss: 0.6379\n",
      "Epoch [28/100], Loss: 0.5780\n",
      "Validation Loss: 0.6425\n",
      "Epoch [29/100], Loss: 0.5798\n",
      "Validation Loss: 0.6361\n",
      "Epoch [30/100], Loss: 0.5788\n",
      "Validation Loss: 0.6341\n",
      "Epoch [31/100], Loss: 0.5760\n",
      "Validation Loss: 0.6353\n",
      "Epoch [32/100], Loss: 0.5746\n",
      "Validation Loss: 0.6324\n",
      "Epoch [33/100], Loss: 0.5745\n",
      "Validation Loss: 0.6422\n",
      "Epoch [34/100], Loss: 0.5754\n",
      "Validation Loss: 0.6384\n",
      "Epoch [35/100], Loss: 0.5719\n",
      "Validation Loss: 0.6463\n",
      "Epoch [36/100], Loss: 0.5719\n",
      "Validation Loss: 0.6444\n",
      "Epoch [37/100], Loss: 0.5721\n",
      "Validation Loss: 0.6403\n",
      "Epoch [38/100], Loss: 0.5684\n",
      "Validation Loss: 0.6363\n",
      "Epoch [39/100], Loss: 0.5674\n",
      "Validation Loss: 0.6326\n",
      "Epoch [40/100], Loss: 0.5681\n",
      "Validation Loss: 0.6363\n",
      "Epoch [41/100], Loss: 0.5674\n",
      "Validation Loss: 0.6329\n",
      "Epoch [42/100], Loss: 0.5677\n",
      "Validation Loss: 0.6306\n",
      "Epoch [43/100], Loss: 0.5653\n",
      "Validation Loss: 0.6390\n",
      "Epoch [44/100], Loss: 0.5662\n",
      "Validation Loss: 0.6388\n",
      "Epoch [45/100], Loss: 0.5652\n",
      "Validation Loss: 0.6337\n",
      "Epoch [46/100], Loss: 0.5646\n",
      "Validation Loss: 0.6357\n",
      "Epoch [47/100], Loss: 0.5629\n",
      "Validation Loss: 0.6346\n",
      "Epoch [48/100], Loss: 0.5649\n",
      "Validation Loss: 0.6354\n",
      "Epoch [49/100], Loss: 0.5621\n",
      "Validation Loss: 0.6362\n",
      "Epoch [50/100], Loss: 0.5609\n",
      "Validation Loss: 0.6389\n",
      "Epoch [51/100], Loss: 0.5615\n",
      "Validation Loss: 0.6335\n",
      "Epoch [52/100], Loss: 0.5617\n",
      "Validation Loss: 0.6320\n",
      "Epoch [53/100], Loss: 0.5620\n",
      "Validation Loss: 0.6357\n",
      "Epoch [54/100], Loss: 0.5577\n",
      "Validation Loss: 0.6306\n",
      "Epoch [55/100], Loss: 0.5583\n",
      "Validation Loss: 0.6351\n",
      "Epoch [56/100], Loss: 0.5579\n",
      "Validation Loss: 0.6350\n",
      "Epoch [57/100], Loss: 0.5592\n",
      "Validation Loss: 0.6376\n",
      "Epoch [58/100], Loss: 0.5559\n",
      "Validation Loss: 0.6339\n",
      "Epoch [59/100], Loss: 0.5571\n",
      "Validation Loss: 0.6438\n",
      "Epoch [60/100], Loss: 0.5579\n",
      "Validation Loss: 0.6267\n",
      "Saved the best model with validation loss: 0.6267\n",
      "Epoch [61/100], Loss: 0.5531\n",
      "Validation Loss: 0.6321\n",
      "Epoch [62/100], Loss: 0.5550\n",
      "Validation Loss: 0.6316\n",
      "Epoch [63/100], Loss: 0.5536\n",
      "Validation Loss: 0.6268\n",
      "Epoch [64/100], Loss: 0.5545\n",
      "Validation Loss: 0.6288\n",
      "Epoch [65/100], Loss: 0.5548\n",
      "Validation Loss: 0.6249\n",
      "Saved the best model with validation loss: 0.6249\n",
      "Epoch [66/100], Loss: 0.5527\n",
      "Validation Loss: 0.6290\n",
      "Epoch [67/100], Loss: 0.5525\n",
      "Validation Loss: 0.6271\n",
      "Epoch [68/100], Loss: 0.5534\n",
      "Validation Loss: 0.6311\n",
      "Epoch [69/100], Loss: 0.5512\n",
      "Validation Loss: 0.6309\n",
      "Epoch [70/100], Loss: 0.5543\n",
      "Validation Loss: 0.6295\n",
      "Epoch [71/100], Loss: 0.5486\n",
      "Validation Loss: 0.6242\n",
      "Saved the best model with validation loss: 0.6242\n",
      "Epoch [72/100], Loss: 0.5507\n",
      "Validation Loss: 0.6260\n",
      "Epoch [73/100], Loss: 0.5500\n",
      "Validation Loss: 0.6281\n",
      "Epoch [74/100], Loss: 0.5495\n",
      "Validation Loss: 0.6276\n",
      "Epoch [75/100], Loss: 0.5482\n",
      "Validation Loss: 0.6333\n",
      "Epoch [76/100], Loss: 0.5496\n",
      "Validation Loss: 0.6302\n",
      "Epoch [77/100], Loss: 0.5493\n",
      "Validation Loss: 0.6286\n",
      "Epoch [78/100], Loss: 0.5497\n",
      "Validation Loss: 0.6257\n",
      "Epoch [79/100], Loss: 0.5471\n",
      "Validation Loss: 0.6264\n",
      "Epoch [80/100], Loss: 0.5458\n",
      "Validation Loss: 0.6274\n",
      "Epoch [81/100], Loss: 0.5438\n",
      "Validation Loss: 0.6277\n",
      "Epoch [82/100], Loss: 0.5473\n",
      "Validation Loss: 0.6289\n",
      "Epoch [83/100], Loss: 0.5485\n",
      "Validation Loss: 0.6238\n",
      "Saved the best model with validation loss: 0.6238\n",
      "Epoch [84/100], Loss: 0.5471\n",
      "Validation Loss: 0.6256\n",
      "Epoch [85/100], Loss: 0.5463\n",
      "Validation Loss: 0.6239\n",
      "Epoch [86/100], Loss: 0.5445\n",
      "Validation Loss: 0.6228\n",
      "Saved the best model with validation loss: 0.6228\n",
      "Epoch [87/100], Loss: 0.5444\n",
      "Validation Loss: 0.6250\n",
      "Epoch [88/100], Loss: 0.5435\n",
      "Validation Loss: 0.6282\n",
      "Epoch [89/100], Loss: 0.5455\n",
      "Validation Loss: 0.6279\n",
      "Epoch [90/100], Loss: 0.5431\n",
      "Validation Loss: 0.6289\n",
      "Epoch [91/100], Loss: 0.5458\n",
      "Validation Loss: 0.6347\n",
      "Epoch [92/100], Loss: 0.5425\n",
      "Validation Loss: 0.6277\n",
      "Epoch [93/100], Loss: 0.5439\n",
      "Validation Loss: 0.6335\n",
      "Epoch [94/100], Loss: 0.5448\n",
      "Validation Loss: 0.6277\n",
      "Epoch [95/100], Loss: 0.5413\n",
      "Validation Loss: 0.6350\n",
      "Epoch [96/100], Loss: 0.5436\n",
      "Validation Loss: 0.6389\n",
      "Epoch [97/100], Loss: 0.5410\n",
      "Validation Loss: 0.6323\n",
      "Epoch [98/100], Loss: 0.5411\n",
      "Validation Loss: 0.6324\n",
      "Epoch [99/100], Loss: 0.5395\n",
      "Validation Loss: 0.6360\n",
      "Epoch [100/100], Loss: 0.5415\n",
      "Validation Loss: 0.6376\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"combi 0.1: 17-80-50-5/1-16-32-5/10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "6b081dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.8593\n",
      "Validation Loss: 0.7429\n",
      "Saved the best model with validation loss: 0.7429\n",
      "Epoch [2/100], Loss: 0.6992\n",
      "Validation Loss: 0.7142\n",
      "Saved the best model with validation loss: 0.7142\n",
      "Epoch [3/100], Loss: 0.6610\n",
      "Validation Loss: 0.6857\n",
      "Saved the best model with validation loss: 0.6857\n",
      "Epoch [4/100], Loss: 0.6387\n",
      "Validation Loss: 0.6765\n",
      "Saved the best model with validation loss: 0.6765\n",
      "Epoch [5/100], Loss: 0.6242\n",
      "Validation Loss: 0.6535\n",
      "Saved the best model with validation loss: 0.6535\n",
      "Epoch [6/100], Loss: 0.6116\n",
      "Validation Loss: 0.6483\n",
      "Saved the best model with validation loss: 0.6483\n",
      "Epoch [7/100], Loss: 0.6024\n",
      "Validation Loss: 0.6310\n",
      "Saved the best model with validation loss: 0.6310\n",
      "Epoch [8/100], Loss: 0.5954\n",
      "Validation Loss: 0.6284\n",
      "Saved the best model with validation loss: 0.6284\n",
      "Epoch [9/100], Loss: 0.5899\n",
      "Validation Loss: 0.6306\n",
      "Epoch [10/100], Loss: 0.5853\n",
      "Validation Loss: 0.6248\n",
      "Saved the best model with validation loss: 0.6248\n",
      "Epoch [11/100], Loss: 0.5805\n",
      "Validation Loss: 0.6137\n",
      "Saved the best model with validation loss: 0.6137\n",
      "Epoch [12/100], Loss: 0.5767\n",
      "Validation Loss: 0.6267\n",
      "Epoch [13/100], Loss: 0.5737\n",
      "Validation Loss: 0.6178\n",
      "Epoch [14/100], Loss: 0.5705\n",
      "Validation Loss: 0.6169\n",
      "Epoch [15/100], Loss: 0.5670\n",
      "Validation Loss: 0.6170\n",
      "Epoch [16/100], Loss: 0.5637\n",
      "Validation Loss: 0.6154\n",
      "Epoch [17/100], Loss: 0.5621\n",
      "Validation Loss: 0.6069\n",
      "Saved the best model with validation loss: 0.6069\n",
      "Epoch [18/100], Loss: 0.5589\n",
      "Validation Loss: 0.5995\n",
      "Saved the best model with validation loss: 0.5995\n",
      "Epoch [19/100], Loss: 0.5578\n",
      "Validation Loss: 0.6057\n",
      "Epoch [20/100], Loss: 0.5566\n",
      "Validation Loss: 0.6041\n",
      "Epoch [21/100], Loss: 0.5533\n",
      "Validation Loss: 0.6028\n",
      "Epoch [22/100], Loss: 0.5519\n",
      "Validation Loss: 0.6076\n",
      "Epoch [23/100], Loss: 0.5522\n",
      "Validation Loss: 0.6058\n",
      "Epoch [24/100], Loss: 0.5487\n",
      "Validation Loss: 0.6084\n",
      "Epoch [25/100], Loss: 0.5494\n",
      "Validation Loss: 0.6083\n",
      "Epoch [26/100], Loss: 0.5471\n",
      "Validation Loss: 0.6056\n",
      "Epoch [27/100], Loss: 0.5475\n",
      "Validation Loss: 0.6012\n",
      "Epoch [28/100], Loss: 0.5465\n",
      "Validation Loss: 0.6069\n",
      "Epoch [29/100], Loss: 0.5441\n",
      "Validation Loss: 0.6091\n",
      "Epoch [30/100], Loss: 0.5433\n",
      "Validation Loss: 0.6092\n",
      "Epoch [31/100], Loss: 0.5412\n",
      "Validation Loss: 0.6025\n",
      "Epoch [32/100], Loss: 0.5408\n",
      "Validation Loss: 0.6049\n",
      "Epoch [33/100], Loss: 0.5397\n",
      "Validation Loss: 0.6134\n",
      "Epoch [34/100], Loss: 0.5391\n",
      "Validation Loss: 0.6070\n",
      "Epoch [35/100], Loss: 0.5380\n",
      "Validation Loss: 0.5997\n",
      "Epoch [36/100], Loss: 0.5414\n",
      "Validation Loss: 0.5986\n",
      "Saved the best model with validation loss: 0.5986\n",
      "Epoch [37/100], Loss: 0.5432\n",
      "Validation Loss: 0.6008\n",
      "Epoch [38/100], Loss: 0.5396\n",
      "Validation Loss: 0.6027\n",
      "Epoch [39/100], Loss: 0.5414\n",
      "Validation Loss: 0.5953\n",
      "Saved the best model with validation loss: 0.5953\n",
      "Epoch [40/100], Loss: 0.5381\n",
      "Validation Loss: 0.5970\n",
      "Epoch [41/100], Loss: 0.5366\n",
      "Validation Loss: 0.5994\n",
      "Epoch [42/100], Loss: 0.5357\n",
      "Validation Loss: 0.5961\n",
      "Epoch [43/100], Loss: 0.5351\n",
      "Validation Loss: 0.5938\n",
      "Saved the best model with validation loss: 0.5938\n",
      "Epoch [44/100], Loss: 0.5340\n",
      "Validation Loss: 0.6006\n",
      "Epoch [45/100], Loss: 0.5337\n",
      "Validation Loss: 0.5988\n",
      "Epoch [46/100], Loss: 0.5336\n",
      "Validation Loss: 0.6067\n",
      "Epoch [47/100], Loss: 0.5337\n",
      "Validation Loss: 0.6071\n",
      "Epoch [48/100], Loss: 0.5335\n",
      "Validation Loss: 0.6052\n",
      "Epoch [49/100], Loss: 0.5316\n",
      "Validation Loss: 0.6034\n",
      "Epoch [50/100], Loss: 0.5305\n",
      "Validation Loss: 0.5984\n",
      "Epoch [51/100], Loss: 0.5303\n",
      "Validation Loss: 0.6028\n",
      "Epoch [52/100], Loss: 0.5286\n",
      "Validation Loss: 0.6015\n",
      "Epoch [53/100], Loss: 0.5300\n",
      "Validation Loss: 0.5996\n",
      "Epoch [54/100], Loss: 0.5291\n",
      "Validation Loss: 0.6048\n",
      "Epoch [55/100], Loss: 0.5287\n",
      "Validation Loss: 0.6009\n",
      "Epoch [56/100], Loss: 0.5279\n",
      "Validation Loss: 0.6027\n",
      "Epoch [57/100], Loss: 0.5273\n",
      "Validation Loss: 0.6036\n",
      "Epoch [58/100], Loss: 0.5292\n",
      "Validation Loss: 0.5995\n",
      "Epoch [59/100], Loss: 0.5259\n",
      "Validation Loss: 0.6053\n",
      "Epoch [60/100], Loss: 0.5267\n",
      "Validation Loss: 0.6000\n",
      "Epoch [61/100], Loss: 0.5255\n",
      "Validation Loss: 0.5986\n",
      "Epoch [62/100], Loss: 0.5267\n",
      "Validation Loss: 0.6000\n",
      "Epoch [63/100], Loss: 0.5257\n",
      "Validation Loss: 0.6023\n",
      "Epoch [64/100], Loss: 0.5249\n",
      "Validation Loss: 0.5991\n",
      "Epoch [65/100], Loss: 0.5252\n",
      "Validation Loss: 0.6031\n",
      "Epoch [66/100], Loss: 0.5245\n",
      "Validation Loss: 0.5991\n",
      "Epoch [67/100], Loss: 0.5283\n",
      "Validation Loss: 0.5905\n",
      "Saved the best model with validation loss: 0.5905\n",
      "Epoch [68/100], Loss: 0.5264\n",
      "Validation Loss: 0.5961\n",
      "Epoch [69/100], Loss: 0.5250\n",
      "Validation Loss: 0.6001\n",
      "Epoch [70/100], Loss: 0.5250\n",
      "Validation Loss: 0.5988\n",
      "Epoch [71/100], Loss: 0.5266\n",
      "Validation Loss: 0.5897\n",
      "Saved the best model with validation loss: 0.5897\n",
      "Epoch [72/100], Loss: 0.5223\n",
      "Validation Loss: 0.5971\n",
      "Epoch [73/100], Loss: 0.5243\n",
      "Validation Loss: 0.5927\n",
      "Epoch [74/100], Loss: 0.5236\n",
      "Validation Loss: 0.5939\n",
      "Epoch [75/100], Loss: 0.5231\n",
      "Validation Loss: 0.5916\n",
      "Epoch [76/100], Loss: 0.5220\n",
      "Validation Loss: 0.5960\n",
      "Epoch [77/100], Loss: 0.5216\n",
      "Validation Loss: 0.5986\n",
      "Epoch [78/100], Loss: 0.5235\n",
      "Validation Loss: 0.6001\n",
      "Epoch [79/100], Loss: 0.5208\n",
      "Validation Loss: 0.5976\n",
      "Epoch [80/100], Loss: 0.5202\n",
      "Validation Loss: 0.6091\n",
      "Epoch [81/100], Loss: 0.5239\n",
      "Validation Loss: 0.6010\n",
      "Epoch [82/100], Loss: 0.5207\n",
      "Validation Loss: 0.5943\n",
      "Epoch [83/100], Loss: 0.5206\n",
      "Validation Loss: 0.5991\n",
      "Epoch [84/100], Loss: 0.5185\n",
      "Validation Loss: 0.6008\n",
      "Epoch [85/100], Loss: 0.5203\n",
      "Validation Loss: 0.5999\n",
      "Epoch [86/100], Loss: 0.5182\n",
      "Validation Loss: 0.6001\n",
      "Epoch [87/100], Loss: 0.5189\n",
      "Validation Loss: 0.5944\n",
      "Epoch [88/100], Loss: 0.5192\n",
      "Validation Loss: 0.6026\n",
      "Epoch [89/100], Loss: 0.5173\n",
      "Validation Loss: 0.5968\n",
      "Epoch [90/100], Loss: 0.5149\n",
      "Validation Loss: 0.5992\n",
      "Epoch [91/100], Loss: 0.5177\n",
      "Validation Loss: 0.6037\n",
      "Epoch [92/100], Loss: 0.5165\n",
      "Validation Loss: 0.5991\n",
      "Epoch [93/100], Loss: 0.5147\n",
      "Validation Loss: 0.5955\n",
      "Epoch [94/100], Loss: 0.5164\n",
      "Validation Loss: 0.5909\n",
      "Epoch [95/100], Loss: 0.5152\n",
      "Validation Loss: 0.5913\n",
      "Epoch [96/100], Loss: 0.5145\n",
      "Validation Loss: 0.5859\n",
      "Saved the best model with validation loss: 0.5859\n",
      "Epoch [97/100], Loss: 0.5152\n",
      "Validation Loss: 0.5867\n",
      "Epoch [98/100], Loss: 0.5180\n",
      "Validation Loss: 0.5858\n",
      "Saved the best model with validation loss: 0.5858\n",
      "Epoch [99/100], Loss: 0.5146\n",
      "Validation Loss: 0.5860\n",
      "Epoch [100/100], Loss: 0.5135\n",
      "Validation Loss: 0.5862\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"combi 0.05: 17-80-50-5/1-16-32-5/10-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "4d033f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7031\n",
      "Validation Loss: 0.5377\n",
      "Saved the best model with validation loss: 0.5377\n",
      "Epoch [2/100], Loss: 0.5591\n",
      "Validation Loss: 0.4974\n",
      "Saved the best model with validation loss: 0.4974\n",
      "Epoch [3/100], Loss: 0.5263\n",
      "Validation Loss: 0.4778\n",
      "Saved the best model with validation loss: 0.4778\n",
      "Epoch [4/100], Loss: 0.5093\n",
      "Validation Loss: 0.4608\n",
      "Saved the best model with validation loss: 0.4608\n",
      "Epoch [5/100], Loss: 0.4976\n",
      "Validation Loss: 0.4517\n",
      "Saved the best model with validation loss: 0.4517\n",
      "Epoch [6/100], Loss: 0.4892\n",
      "Validation Loss: 0.4432\n",
      "Saved the best model with validation loss: 0.4432\n",
      "Epoch [7/100], Loss: 0.4843\n",
      "Validation Loss: 0.4341\n",
      "Saved the best model with validation loss: 0.4341\n",
      "Epoch [8/100], Loss: 0.4800\n",
      "Validation Loss: 0.4325\n",
      "Saved the best model with validation loss: 0.4325\n",
      "Epoch [9/100], Loss: 0.4766\n",
      "Validation Loss: 0.4289\n",
      "Saved the best model with validation loss: 0.4289\n",
      "Epoch [10/100], Loss: 0.4731\n",
      "Validation Loss: 0.4335\n",
      "Epoch [11/100], Loss: 0.4704\n",
      "Validation Loss: 0.4342\n",
      "Epoch [12/100], Loss: 0.4688\n",
      "Validation Loss: 0.4251\n",
      "Saved the best model with validation loss: 0.4251\n",
      "Epoch [13/100], Loss: 0.4656\n",
      "Validation Loss: 0.4316\n",
      "Epoch [14/100], Loss: 0.4636\n",
      "Validation Loss: 0.4291\n",
      "Epoch [15/100], Loss: 0.4613\n",
      "Validation Loss: 0.4236\n",
      "Saved the best model with validation loss: 0.4236\n",
      "Epoch [16/100], Loss: 0.4602\n",
      "Validation Loss: 0.4266\n",
      "Epoch [17/100], Loss: 0.4589\n",
      "Validation Loss: 0.4237\n",
      "Epoch [18/100], Loss: 0.4571\n",
      "Validation Loss: 0.4215\n",
      "Saved the best model with validation loss: 0.4215\n",
      "Epoch [19/100], Loss: 0.4559\n",
      "Validation Loss: 0.4233\n",
      "Epoch [20/100], Loss: 0.4541\n",
      "Validation Loss: 0.4259\n",
      "Epoch [21/100], Loss: 0.4540\n",
      "Validation Loss: 0.4253\n",
      "Epoch [22/100], Loss: 0.4529\n",
      "Validation Loss: 0.4169\n",
      "Saved the best model with validation loss: 0.4169\n",
      "Epoch [23/100], Loss: 0.4511\n",
      "Validation Loss: 0.4193\n",
      "Epoch [24/100], Loss: 0.4500\n",
      "Validation Loss: 0.4199\n",
      "Epoch [25/100], Loss: 0.4499\n",
      "Validation Loss: 0.4175\n",
      "Epoch [26/100], Loss: 0.4480\n",
      "Validation Loss: 0.4233\n",
      "Epoch [27/100], Loss: 0.4478\n",
      "Validation Loss: 0.4231\n",
      "Epoch [28/100], Loss: 0.4469\n",
      "Validation Loss: 0.4204\n",
      "Epoch [29/100], Loss: 0.4457\n",
      "Validation Loss: 0.4278\n",
      "Epoch [30/100], Loss: 0.4453\n",
      "Validation Loss: 0.4188\n",
      "Epoch [31/100], Loss: 0.4450\n",
      "Validation Loss: 0.4170\n",
      "Epoch [32/100], Loss: 0.4453\n",
      "Validation Loss: 0.4149\n",
      "Saved the best model with validation loss: 0.4149\n",
      "Epoch [33/100], Loss: 0.4448\n",
      "Validation Loss: 0.4210\n",
      "Epoch [34/100], Loss: 0.4434\n",
      "Validation Loss: 0.4173\n",
      "Epoch [35/100], Loss: 0.4447\n",
      "Validation Loss: 0.4232\n",
      "Epoch [36/100], Loss: 0.4435\n",
      "Validation Loss: 0.4147\n",
      "Saved the best model with validation loss: 0.4147\n",
      "Epoch [37/100], Loss: 0.4412\n",
      "Validation Loss: 0.4231\n",
      "Epoch [38/100], Loss: 0.4413\n",
      "Validation Loss: 0.4177\n",
      "Epoch [39/100], Loss: 0.4414\n",
      "Validation Loss: 0.4151\n",
      "Epoch [40/100], Loss: 0.4416\n",
      "Validation Loss: 0.4162\n",
      "Epoch [41/100], Loss: 0.4402\n",
      "Validation Loss: 0.4180\n",
      "Epoch [42/100], Loss: 0.4403\n",
      "Validation Loss: 0.4171\n",
      "Epoch [43/100], Loss: 0.4401\n",
      "Validation Loss: 0.4134\n",
      "Saved the best model with validation loss: 0.4134\n",
      "Epoch [44/100], Loss: 0.4397\n",
      "Validation Loss: 0.4182\n",
      "Epoch [45/100], Loss: 0.4381\n",
      "Validation Loss: 0.4154\n",
      "Epoch [46/100], Loss: 0.4388\n",
      "Validation Loss: 0.4143\n",
      "Epoch [47/100], Loss: 0.4394\n",
      "Validation Loss: 0.4104\n",
      "Saved the best model with validation loss: 0.4104\n",
      "Epoch [48/100], Loss: 0.4373\n",
      "Validation Loss: 0.4152\n",
      "Epoch [49/100], Loss: 0.4371\n",
      "Validation Loss: 0.4120\n",
      "Epoch [50/100], Loss: 0.4381\n",
      "Validation Loss: 0.4150\n",
      "Epoch [51/100], Loss: 0.4361\n",
      "Validation Loss: 0.4141\n",
      "Epoch [52/100], Loss: 0.4366\n",
      "Validation Loss: 0.4107\n",
      "Epoch [53/100], Loss: 0.4370\n",
      "Validation Loss: 0.4125\n",
      "Epoch [54/100], Loss: 0.4359\n",
      "Validation Loss: 0.4132\n",
      "Epoch [55/100], Loss: 0.4352\n",
      "Validation Loss: 0.4106\n",
      "Epoch [56/100], Loss: 0.4353\n",
      "Validation Loss: 0.4116\n",
      "Epoch [57/100], Loss: 0.4334\n",
      "Validation Loss: 0.4146\n",
      "Epoch [58/100], Loss: 0.4336\n",
      "Validation Loss: 0.4124\n",
      "Epoch [59/100], Loss: 0.4336\n",
      "Validation Loss: 0.4225\n",
      "Epoch [60/100], Loss: 0.4329\n",
      "Validation Loss: 0.4138\n",
      "Epoch [61/100], Loss: 0.4326\n",
      "Validation Loss: 0.4124\n",
      "Epoch [62/100], Loss: 0.4335\n",
      "Validation Loss: 0.4131\n",
      "Epoch [63/100], Loss: 0.4326\n",
      "Validation Loss: 0.4176\n",
      "Epoch [64/100], Loss: 0.4313\n",
      "Validation Loss: 0.4232\n",
      "Epoch [65/100], Loss: 0.4325\n",
      "Validation Loss: 0.4188\n",
      "Epoch [66/100], Loss: 0.4320\n",
      "Validation Loss: 0.4160\n",
      "Epoch [67/100], Loss: 0.4308\n",
      "Validation Loss: 0.4180\n",
      "Epoch [68/100], Loss: 0.4299\n",
      "Validation Loss: 0.4219\n",
      "Epoch [69/100], Loss: 0.4298\n",
      "Validation Loss: 0.4205\n",
      "Epoch [70/100], Loss: 0.4297\n",
      "Validation Loss: 0.4207\n",
      "Epoch [71/100], Loss: 0.4307\n",
      "Validation Loss: 0.4165\n",
      "Epoch [72/100], Loss: 0.4305\n",
      "Validation Loss: 0.4184\n",
      "Epoch [73/100], Loss: 0.4307\n",
      "Validation Loss: 0.4155\n",
      "Epoch [74/100], Loss: 0.4291\n",
      "Validation Loss: 0.4201\n",
      "Epoch [75/100], Loss: 0.4301\n",
      "Validation Loss: 0.4250\n",
      "Epoch [76/100], Loss: 0.4289\n",
      "Validation Loss: 0.4186\n",
      "Epoch [77/100], Loss: 0.4282\n",
      "Validation Loss: 0.4173\n",
      "Epoch [78/100], Loss: 0.4293\n",
      "Validation Loss: 0.4165\n",
      "Epoch [79/100], Loss: 0.4288\n",
      "Validation Loss: 0.4153\n",
      "Epoch [80/100], Loss: 0.4295\n",
      "Validation Loss: 0.4154\n",
      "Epoch [81/100], Loss: 0.4286\n",
      "Validation Loss: 0.4124\n",
      "Epoch [82/100], Loss: 0.4298\n",
      "Validation Loss: 0.4140\n",
      "Epoch [83/100], Loss: 0.4268\n",
      "Validation Loss: 0.4129\n",
      "Epoch [84/100], Loss: 0.4290\n",
      "Validation Loss: 0.4132\n",
      "Epoch [85/100], Loss: 0.4285\n",
      "Validation Loss: 0.4146\n",
      "Epoch [86/100], Loss: 0.4276\n",
      "Validation Loss: 0.4188\n",
      "Epoch [87/100], Loss: 0.4265\n",
      "Validation Loss: 0.4206\n",
      "Epoch [88/100], Loss: 0.4281\n",
      "Validation Loss: 0.4184\n",
      "Epoch [89/100], Loss: 0.4345\n",
      "Validation Loss: 0.4150\n",
      "Epoch [90/100], Loss: 0.4311\n",
      "Validation Loss: 0.4201\n",
      "Epoch [91/100], Loss: 0.4332\n",
      "Validation Loss: 0.4169\n",
      "Epoch [92/100], Loss: 0.4298\n",
      "Validation Loss: 0.4213\n",
      "Epoch [93/100], Loss: 0.4286\n",
      "Validation Loss: 0.4156\n",
      "Epoch [94/100], Loss: 0.4292\n",
      "Validation Loss: 0.4169\n",
      "Epoch [95/100], Loss: 0.4285\n",
      "Validation Loss: 0.4199\n",
      "Epoch [96/100], Loss: 0.4284\n",
      "Validation Loss: 0.4227\n",
      "Epoch [97/100], Loss: 0.4265\n",
      "Validation Loss: 0.4178\n",
      "Epoch [98/100], Loss: 0.4272\n",
      "Validation Loss: 0.4177\n",
      "Epoch [99/100], Loss: 0.4271\n",
      "Validation Loss: 0.4140\n",
      "Epoch [100/100], Loss: 0.4278\n",
      "Validation Loss: 0.4214\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"combi 0.01: 17-80-50-5/1-16-32-5/10-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6353b02e",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 3, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  MLP 17-80-50-5\n",
    "*  HGNN 1-16-32-5\n",
    "*  Combined 10-20-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "d4d95cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "51a7359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.8015\n",
      "Validation Loss: 0.5549\n",
      "Saved the best model with validation loss: 0.5549\n",
      "Epoch [2/100], Loss: 0.6018\n",
      "Validation Loss: 0.5011\n",
      "Saved the best model with validation loss: 0.5011\n",
      "Epoch [3/100], Loss: 0.5528\n",
      "Validation Loss: 0.4710\n",
      "Saved the best model with validation loss: 0.4710\n",
      "Epoch [4/100], Loss: 0.5277\n",
      "Validation Loss: 0.4572\n",
      "Saved the best model with validation loss: 0.4572\n",
      "Epoch [5/100], Loss: 0.5120\n",
      "Validation Loss: 0.4468\n",
      "Saved the best model with validation loss: 0.4468\n",
      "Epoch [6/100], Loss: 0.5003\n",
      "Validation Loss: 0.4376\n",
      "Saved the best model with validation loss: 0.4376\n",
      "Epoch [7/100], Loss: 0.4918\n",
      "Validation Loss: 0.4300\n",
      "Saved the best model with validation loss: 0.4300\n",
      "Epoch [8/100], Loss: 0.4845\n",
      "Validation Loss: 0.4251\n",
      "Saved the best model with validation loss: 0.4251\n",
      "Epoch [9/100], Loss: 0.4804\n",
      "Validation Loss: 0.4266\n",
      "Epoch [10/100], Loss: 0.4732\n",
      "Validation Loss: 0.4144\n",
      "Saved the best model with validation loss: 0.4144\n",
      "Epoch [11/100], Loss: 0.4642\n",
      "Validation Loss: 0.4077\n",
      "Saved the best model with validation loss: 0.4077\n",
      "Epoch [12/100], Loss: 0.4584\n",
      "Validation Loss: 0.3978\n",
      "Saved the best model with validation loss: 0.3978\n",
      "Epoch [13/100], Loss: 0.4511\n",
      "Validation Loss: 0.4027\n",
      "Epoch [14/100], Loss: 0.4479\n",
      "Validation Loss: 0.3883\n",
      "Saved the best model with validation loss: 0.3883\n",
      "Epoch [15/100], Loss: 0.4375\n",
      "Validation Loss: 0.3866\n",
      "Saved the best model with validation loss: 0.3866\n",
      "Epoch [16/100], Loss: 0.4320\n",
      "Validation Loss: 0.3788\n",
      "Saved the best model with validation loss: 0.3788\n",
      "Epoch [17/100], Loss: 0.4298\n",
      "Validation Loss: 0.3748\n",
      "Saved the best model with validation loss: 0.3748\n",
      "Epoch [18/100], Loss: 0.4266\n",
      "Validation Loss: 0.3760\n",
      "Epoch [19/100], Loss: 0.4265\n",
      "Validation Loss: 0.3693\n",
      "Saved the best model with validation loss: 0.3693\n",
      "Epoch [20/100], Loss: 0.4261\n",
      "Validation Loss: 0.3725\n",
      "Epoch [21/100], Loss: 0.4181\n",
      "Validation Loss: 0.3659\n",
      "Saved the best model with validation loss: 0.3659\n",
      "Epoch [22/100], Loss: 0.4218\n",
      "Validation Loss: 0.3674\n",
      "Epoch [23/100], Loss: 0.4197\n",
      "Validation Loss: 0.3703\n",
      "Epoch [24/100], Loss: 0.4157\n",
      "Validation Loss: 0.3728\n",
      "Epoch [25/100], Loss: 0.4101\n",
      "Validation Loss: 0.3593\n",
      "Saved the best model with validation loss: 0.3593\n",
      "Epoch [26/100], Loss: 0.4107\n",
      "Validation Loss: 0.3666\n",
      "Epoch [27/100], Loss: 0.4085\n",
      "Validation Loss: 0.3605\n",
      "Epoch [28/100], Loss: 0.4061\n",
      "Validation Loss: 0.3564\n",
      "Saved the best model with validation loss: 0.3564\n",
      "Epoch [29/100], Loss: 0.4043\n",
      "Validation Loss: 0.3585\n",
      "Epoch [30/100], Loss: 0.4035\n",
      "Validation Loss: 0.3593\n",
      "Epoch [31/100], Loss: 0.4014\n",
      "Validation Loss: 0.3509\n",
      "Saved the best model with validation loss: 0.3509\n",
      "Epoch [32/100], Loss: 0.3987\n",
      "Validation Loss: 0.3612\n",
      "Epoch [33/100], Loss: 0.4060\n",
      "Validation Loss: 0.3542\n",
      "Epoch [34/100], Loss: 0.3983\n",
      "Validation Loss: 0.3855\n",
      "Epoch [35/100], Loss: 0.4003\n",
      "Validation Loss: 0.3653\n",
      "Epoch [36/100], Loss: 0.3910\n",
      "Validation Loss: 0.3567\n",
      "Epoch [37/100], Loss: 0.3955\n",
      "Validation Loss: 0.3519\n",
      "Epoch [38/100], Loss: 0.3967\n",
      "Validation Loss: 0.3610\n",
      "Epoch [39/100], Loss: 0.3929\n",
      "Validation Loss: 0.3536\n",
      "Epoch [40/100], Loss: 0.3956\n",
      "Validation Loss: 0.3520\n",
      "Epoch [41/100], Loss: 0.3984\n",
      "Validation Loss: 0.3446\n",
      "Saved the best model with validation loss: 0.3446\n",
      "Epoch [42/100], Loss: 0.3946\n",
      "Validation Loss: 0.3427\n",
      "Saved the best model with validation loss: 0.3427\n",
      "Epoch [43/100], Loss: 0.3901\n",
      "Validation Loss: 0.3478\n",
      "Epoch [44/100], Loss: 0.3872\n",
      "Validation Loss: 0.3358\n",
      "Saved the best model with validation loss: 0.3358\n",
      "Epoch [45/100], Loss: 0.3876\n",
      "Validation Loss: 0.3409\n",
      "Epoch [46/100], Loss: 0.3893\n",
      "Validation Loss: 0.3304\n",
      "Saved the best model with validation loss: 0.3304\n",
      "Epoch [47/100], Loss: 0.3859\n",
      "Validation Loss: 0.3429\n",
      "Epoch [48/100], Loss: 0.3877\n",
      "Validation Loss: 0.3390\n",
      "Epoch [49/100], Loss: 0.3909\n",
      "Validation Loss: 0.3338\n",
      "Epoch [50/100], Loss: 0.3903\n",
      "Validation Loss: 0.3675\n",
      "Epoch [51/100], Loss: 0.3832\n",
      "Validation Loss: 0.3367\n",
      "Epoch [52/100], Loss: 0.3906\n",
      "Validation Loss: 0.3476\n",
      "Epoch [53/100], Loss: 0.3826\n",
      "Validation Loss: 0.3326\n",
      "Epoch [54/100], Loss: 0.3783\n",
      "Validation Loss: 0.3381\n",
      "Epoch [55/100], Loss: 0.3815\n",
      "Validation Loss: 0.3708\n",
      "Epoch [56/100], Loss: 0.3775\n",
      "Validation Loss: 0.3281\n",
      "Saved the best model with validation loss: 0.3281\n",
      "Epoch [57/100], Loss: 0.3796\n",
      "Validation Loss: 0.3279\n",
      "Saved the best model with validation loss: 0.3279\n",
      "Epoch [58/100], Loss: 0.3832\n",
      "Validation Loss: 0.3473\n",
      "Epoch [59/100], Loss: 0.3727\n",
      "Validation Loss: 0.6050\n",
      "Epoch [60/100], Loss: 0.3763\n",
      "Validation Loss: 0.3445\n",
      "Epoch [61/100], Loss: 0.3772\n",
      "Validation Loss: 0.3373\n",
      "Epoch [62/100], Loss: 0.3733\n",
      "Validation Loss: 0.3269\n",
      "Saved the best model with validation loss: 0.3269\n",
      "Epoch [63/100], Loss: 0.3694\n",
      "Validation Loss: 0.3384\n",
      "Epoch [64/100], Loss: 0.3695\n",
      "Validation Loss: 0.3384\n",
      "Epoch [65/100], Loss: 0.3713\n",
      "Validation Loss: 0.3269\n",
      "Saved the best model with validation loss: 0.3269\n",
      "Epoch [66/100], Loss: 0.3744\n",
      "Validation Loss: 0.3272\n",
      "Epoch [67/100], Loss: 0.3752\n",
      "Validation Loss: 0.3619\n",
      "Epoch [68/100], Loss: 0.3685\n",
      "Validation Loss: 0.3436\n",
      "Epoch [69/100], Loss: 0.3718\n",
      "Validation Loss: 0.3353\n",
      "Epoch [70/100], Loss: 0.3721\n",
      "Validation Loss: 0.3388\n",
      "Epoch [71/100], Loss: 0.3698\n",
      "Validation Loss: 0.3464\n",
      "Epoch [72/100], Loss: 0.3655\n",
      "Validation Loss: 0.3414\n",
      "Epoch [73/100], Loss: 0.3728\n",
      "Validation Loss: 0.3390\n",
      "Epoch [74/100], Loss: 0.3662\n",
      "Validation Loss: 0.3459\n",
      "Epoch [75/100], Loss: 0.3732\n",
      "Validation Loss: 0.3257\n",
      "Saved the best model with validation loss: 0.3257\n",
      "Epoch [76/100], Loss: 0.3658\n",
      "Validation Loss: 0.3367\n",
      "Epoch [77/100], Loss: 0.3757\n",
      "Validation Loss: 0.3308\n",
      "Epoch [78/100], Loss: 0.3609\n",
      "Validation Loss: 0.3199\n",
      "Saved the best model with validation loss: 0.3199\n",
      "Epoch [79/100], Loss: 0.3603\n",
      "Validation Loss: 0.3223\n",
      "Epoch [80/100], Loss: 0.3714\n",
      "Validation Loss: 0.3352\n",
      "Epoch [81/100], Loss: 0.3655\n",
      "Validation Loss: 0.3283\n",
      "Epoch [82/100], Loss: 0.3628\n",
      "Validation Loss: 0.3218\n",
      "Epoch [83/100], Loss: 0.3656\n",
      "Validation Loss: 0.3227\n",
      "Epoch [84/100], Loss: 0.3542\n",
      "Validation Loss: 0.3212\n",
      "Epoch [85/100], Loss: 0.3607\n",
      "Validation Loss: 0.3387\n",
      "Epoch [86/100], Loss: 0.3589\n",
      "Validation Loss: 0.3316\n",
      "Epoch [87/100], Loss: 0.3591\n",
      "Validation Loss: 0.3308\n",
      "Epoch [88/100], Loss: 0.3550\n",
      "Validation Loss: 0.3315\n",
      "Epoch [89/100], Loss: 0.3555\n",
      "Validation Loss: 0.3301\n",
      "Epoch [90/100], Loss: 0.3627\n",
      "Validation Loss: 0.3301\n",
      "Epoch [91/100], Loss: 0.3596\n",
      "Validation Loss: 0.3262\n",
      "Epoch [92/100], Loss: 0.3522\n",
      "Validation Loss: 0.3240\n",
      "Epoch [93/100], Loss: 0.3563\n",
      "Validation Loss: 0.3386\n",
      "Epoch [94/100], Loss: 0.3591\n",
      "Validation Loss: 0.3205\n",
      "Epoch [95/100], Loss: 0.3612\n",
      "Validation Loss: 0.3122\n",
      "Saved the best model with validation loss: 0.3122\n",
      "Epoch [96/100], Loss: 0.3666\n",
      "Validation Loss: 0.3468\n",
      "Epoch [97/100], Loss: 0.3483\n",
      "Validation Loss: 0.3471\n",
      "Epoch [98/100], Loss: 0.3576\n",
      "Validation Loss: 0.3343\n",
      "Epoch [99/100], Loss: 0.3564\n",
      "Validation Loss: 0.3782\n",
      "Epoch [100/100], Loss: 0.3566\n",
      "Validation Loss: 0.3311\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"combi 0.5: 17-80-50-5/1-16-32-5/10-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "ff275836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.9558\n",
      "Validation Loss: 0.8008\n",
      "Saved the best model with validation loss: 0.8008\n",
      "Epoch [2/100], Loss: 0.7368\n",
      "Validation Loss: 0.7307\n",
      "Saved the best model with validation loss: 0.7307\n",
      "Epoch [3/100], Loss: 0.6920\n",
      "Validation Loss: 0.7031\n",
      "Saved the best model with validation loss: 0.7031\n",
      "Epoch [4/100], Loss: 0.6659\n",
      "Validation Loss: 0.6957\n",
      "Saved the best model with validation loss: 0.6957\n",
      "Epoch [5/100], Loss: 0.6487\n",
      "Validation Loss: 0.6935\n",
      "Saved the best model with validation loss: 0.6935\n",
      "Epoch [6/100], Loss: 0.6401\n",
      "Validation Loss: 0.6948\n",
      "Epoch [7/100], Loss: 0.6320\n",
      "Validation Loss: 0.6858\n",
      "Saved the best model with validation loss: 0.6858\n",
      "Epoch [8/100], Loss: 0.6251\n",
      "Validation Loss: 0.6863\n",
      "Epoch [9/100], Loss: 0.6207\n",
      "Validation Loss: 0.6749\n",
      "Saved the best model with validation loss: 0.6749\n",
      "Epoch [10/100], Loss: 0.6113\n",
      "Validation Loss: 0.6723\n",
      "Saved the best model with validation loss: 0.6723\n",
      "Epoch [11/100], Loss: 0.6051\n",
      "Validation Loss: 0.6632\n",
      "Saved the best model with validation loss: 0.6632\n",
      "Epoch [12/100], Loss: 0.6002\n",
      "Validation Loss: 0.6616\n",
      "Saved the best model with validation loss: 0.6616\n",
      "Epoch [13/100], Loss: 0.5942\n",
      "Validation Loss: 0.6684\n",
      "Epoch [14/100], Loss: 0.5915\n",
      "Validation Loss: 0.6573\n",
      "Saved the best model with validation loss: 0.6573\n",
      "Epoch [15/100], Loss: 0.5832\n",
      "Validation Loss: 0.6510\n",
      "Saved the best model with validation loss: 0.6510\n",
      "Epoch [16/100], Loss: 0.5858\n",
      "Validation Loss: 0.6602\n",
      "Epoch [17/100], Loss: 0.5773\n",
      "Validation Loss: 0.6556\n",
      "Epoch [18/100], Loss: 0.5738\n",
      "Validation Loss: 0.6462\n",
      "Saved the best model with validation loss: 0.6462\n",
      "Epoch [19/100], Loss: 0.5682\n",
      "Validation Loss: 0.6419\n",
      "Saved the best model with validation loss: 0.6419\n",
      "Epoch [20/100], Loss: 0.5657\n",
      "Validation Loss: 0.6480\n",
      "Epoch [21/100], Loss: 0.5668\n",
      "Validation Loss: 0.6456\n",
      "Epoch [22/100], Loss: 0.5629\n",
      "Validation Loss: 0.6443\n",
      "Epoch [23/100], Loss: 0.5623\n",
      "Validation Loss: 0.6522\n",
      "Epoch [24/100], Loss: 0.5608\n",
      "Validation Loss: 0.6481\n",
      "Epoch [25/100], Loss: 0.5587\n",
      "Validation Loss: 0.6275\n",
      "Saved the best model with validation loss: 0.6275\n",
      "Epoch [26/100], Loss: 0.5601\n",
      "Validation Loss: 0.6383\n",
      "Epoch [27/100], Loss: 0.5571\n",
      "Validation Loss: 0.6480\n",
      "Epoch [28/100], Loss: 0.5579\n",
      "Validation Loss: 0.6274\n",
      "Saved the best model with validation loss: 0.6274\n",
      "Epoch [29/100], Loss: 0.5490\n",
      "Validation Loss: 0.6360\n",
      "Epoch [30/100], Loss: 0.5482\n",
      "Validation Loss: 0.6262\n",
      "Saved the best model with validation loss: 0.6262\n",
      "Epoch [31/100], Loss: 0.5496\n",
      "Validation Loss: 0.6326\n",
      "Epoch [32/100], Loss: 0.5474\n",
      "Validation Loss: 0.6278\n",
      "Epoch [33/100], Loss: 0.5461\n",
      "Validation Loss: 0.6204\n",
      "Saved the best model with validation loss: 0.6204\n",
      "Epoch [34/100], Loss: 0.5427\n",
      "Validation Loss: 0.6139\n",
      "Saved the best model with validation loss: 0.6139\n",
      "Epoch [35/100], Loss: 0.5425\n",
      "Validation Loss: 0.6265\n",
      "Epoch [36/100], Loss: 0.5413\n",
      "Validation Loss: 0.6280\n",
      "Epoch [37/100], Loss: 0.5405\n",
      "Validation Loss: 0.6280\n",
      "Epoch [38/100], Loss: 0.5417\n",
      "Validation Loss: 0.6158\n",
      "Epoch [39/100], Loss: 0.5407\n",
      "Validation Loss: 0.6020\n",
      "Saved the best model with validation loss: 0.6020\n",
      "Epoch [40/100], Loss: 0.5456\n",
      "Validation Loss: 0.6043\n",
      "Epoch [41/100], Loss: 0.5414\n",
      "Validation Loss: 0.6083\n",
      "Epoch [42/100], Loss: 0.5343\n",
      "Validation Loss: 0.6219\n",
      "Epoch [43/100], Loss: 0.5410\n",
      "Validation Loss: 0.6221\n",
      "Epoch [44/100], Loss: 0.5347\n",
      "Validation Loss: 0.6317\n",
      "Epoch [45/100], Loss: 0.5384\n",
      "Validation Loss: 0.6360\n",
      "Epoch [46/100], Loss: 0.5360\n",
      "Validation Loss: 0.6309\n",
      "Epoch [47/100], Loss: 0.5327\n",
      "Validation Loss: 0.6237\n",
      "Epoch [48/100], Loss: 0.5356\n",
      "Validation Loss: 0.6174\n",
      "Epoch [49/100], Loss: 0.5322\n",
      "Validation Loss: 0.6071\n",
      "Epoch [50/100], Loss: 0.5319\n",
      "Validation Loss: 0.6084\n",
      "Epoch [51/100], Loss: 0.5361\n",
      "Validation Loss: 0.6354\n",
      "Epoch [52/100], Loss: 0.5408\n",
      "Validation Loss: 0.6376\n",
      "Epoch [53/100], Loss: 0.5294\n",
      "Validation Loss: 0.6188\n",
      "Epoch [54/100], Loss: 0.5310\n",
      "Validation Loss: 0.6412\n",
      "Epoch [55/100], Loss: 0.5332\n",
      "Validation Loss: 0.6271\n",
      "Epoch [56/100], Loss: 0.5322\n",
      "Validation Loss: 0.6302\n",
      "Epoch [57/100], Loss: 0.5314\n",
      "Validation Loss: 0.6131\n",
      "Epoch [58/100], Loss: 0.5383\n",
      "Validation Loss: 0.6325\n",
      "Epoch [59/100], Loss: 0.5290\n",
      "Validation Loss: 0.6080\n",
      "Epoch [60/100], Loss: 0.5266\n",
      "Validation Loss: 0.6231\n",
      "Epoch [61/100], Loss: 0.5253\n",
      "Validation Loss: 0.6145\n",
      "Epoch [62/100], Loss: 0.5242\n",
      "Validation Loss: 0.6135\n",
      "Epoch [63/100], Loss: 0.5231\n",
      "Validation Loss: 0.6005\n",
      "Saved the best model with validation loss: 0.6005\n",
      "Epoch [64/100], Loss: 0.5258\n",
      "Validation Loss: 0.6116\n",
      "Epoch [65/100], Loss: 0.5233\n",
      "Validation Loss: 0.6071\n",
      "Epoch [66/100], Loss: 0.5189\n",
      "Validation Loss: 0.6281\n",
      "Epoch [67/100], Loss: 0.5194\n",
      "Validation Loss: 0.6383\n",
      "Epoch [68/100], Loss: 0.5164\n",
      "Validation Loss: 0.6170\n",
      "Epoch [69/100], Loss: 0.5197\n",
      "Validation Loss: 0.6347\n",
      "Epoch [70/100], Loss: 0.5276\n",
      "Validation Loss: 0.7428\n",
      "Epoch [71/100], Loss: 0.5252\n",
      "Validation Loss: 0.6479\n",
      "Epoch [72/100], Loss: 0.5201\n",
      "Validation Loss: 0.6134\n",
      "Epoch [73/100], Loss: 0.5171\n",
      "Validation Loss: 0.6381\n",
      "Epoch [74/100], Loss: 0.5191\n",
      "Validation Loss: 0.6190\n",
      "Epoch [75/100], Loss: 0.5184\n",
      "Validation Loss: 0.6306\n",
      "Epoch [76/100], Loss: 0.5183\n",
      "Validation Loss: 0.6132\n",
      "Epoch [77/100], Loss: 0.5189\n",
      "Validation Loss: 0.6242\n",
      "Epoch [78/100], Loss: 0.5265\n",
      "Validation Loss: 0.6374\n",
      "Epoch [79/100], Loss: 0.5199\n",
      "Validation Loss: 0.6419\n",
      "Epoch [80/100], Loss: 0.5233\n",
      "Validation Loss: 0.6458\n",
      "Epoch [81/100], Loss: 0.5167\n",
      "Validation Loss: 0.6543\n",
      "Epoch [82/100], Loss: 0.5199\n",
      "Validation Loss: 0.6533\n",
      "Epoch [83/100], Loss: 0.5212\n",
      "Validation Loss: 0.6536\n",
      "Epoch [84/100], Loss: 0.5338\n",
      "Validation Loss: 0.6663\n",
      "Epoch [85/100], Loss: 0.5133\n",
      "Validation Loss: 0.6336\n",
      "Epoch [86/100], Loss: 0.5125\n",
      "Validation Loss: 0.6456\n",
      "Epoch [87/100], Loss: 0.5204\n",
      "Validation Loss: 0.6359\n",
      "Epoch [88/100], Loss: 0.5125\n",
      "Validation Loss: 0.6342\n",
      "Epoch [89/100], Loss: 0.5140\n",
      "Validation Loss: 0.6613\n",
      "Epoch [90/100], Loss: 0.5117\n",
      "Validation Loss: 0.6375\n",
      "Epoch [91/100], Loss: 0.5092\n",
      "Validation Loss: 0.6531\n",
      "Epoch [92/100], Loss: 0.5154\n",
      "Validation Loss: 0.6586\n",
      "Epoch [93/100], Loss: 0.5185\n",
      "Validation Loss: 0.6513\n",
      "Epoch [94/100], Loss: 0.5164\n",
      "Validation Loss: 0.6576\n",
      "Epoch [95/100], Loss: 0.5162\n",
      "Validation Loss: 0.6690\n",
      "Epoch [96/100], Loss: 0.5135\n",
      "Validation Loss: 0.6597\n",
      "Epoch [97/100], Loss: 0.5107\n",
      "Validation Loss: 0.6444\n",
      "Epoch [98/100], Loss: 0.5142\n",
      "Validation Loss: 0.6567\n",
      "Epoch [99/100], Loss: 0.5115\n",
      "Validation Loss: 0.6749\n",
      "Epoch [100/100], Loss: 0.5168\n",
      "Validation Loss: 0.6425\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"combi 0.1: 17-80-50-5/1-16-32-5/10-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "30d569b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.9145\n",
      "Validation Loss: 0.7451\n",
      "Saved the best model with validation loss: 0.7451\n",
      "Epoch [2/100], Loss: 0.7210\n",
      "Validation Loss: 0.7104\n",
      "Saved the best model with validation loss: 0.7104\n",
      "Epoch [3/100], Loss: 0.6787\n",
      "Validation Loss: 0.6865\n",
      "Saved the best model with validation loss: 0.6865\n",
      "Epoch [4/100], Loss: 0.6560\n",
      "Validation Loss: 0.6759\n",
      "Saved the best model with validation loss: 0.6759\n",
      "Epoch [5/100], Loss: 0.6386\n",
      "Validation Loss: 0.6638\n",
      "Saved the best model with validation loss: 0.6638\n",
      "Epoch [6/100], Loss: 0.6249\n",
      "Validation Loss: 0.6476\n",
      "Saved the best model with validation loss: 0.6476\n",
      "Epoch [7/100], Loss: 0.6132\n",
      "Validation Loss: 0.6492\n",
      "Epoch [8/100], Loss: 0.6030\n",
      "Validation Loss: 0.6331\n",
      "Saved the best model with validation loss: 0.6331\n",
      "Epoch [9/100], Loss: 0.5943\n",
      "Validation Loss: 0.6316\n",
      "Saved the best model with validation loss: 0.6316\n",
      "Epoch [10/100], Loss: 0.5898\n",
      "Validation Loss: 0.6381\n",
      "Epoch [11/100], Loss: 0.5844\n",
      "Validation Loss: 0.6260\n",
      "Saved the best model with validation loss: 0.6260\n",
      "Epoch [12/100], Loss: 0.5811\n",
      "Validation Loss: 0.6083\n",
      "Saved the best model with validation loss: 0.6083\n",
      "Epoch [13/100], Loss: 0.5767\n",
      "Validation Loss: 0.6077\n",
      "Saved the best model with validation loss: 0.6077\n",
      "Epoch [14/100], Loss: 0.5716\n",
      "Validation Loss: 0.6155\n",
      "Epoch [15/100], Loss: 0.5664\n",
      "Validation Loss: 0.6222\n",
      "Epoch [16/100], Loss: 0.5609\n",
      "Validation Loss: 0.6126\n",
      "Epoch [17/100], Loss: 0.5563\n",
      "Validation Loss: 0.6009\n",
      "Saved the best model with validation loss: 0.6009\n",
      "Epoch [18/100], Loss: 0.5548\n",
      "Validation Loss: 0.6274\n",
      "Epoch [19/100], Loss: 0.5488\n",
      "Validation Loss: 0.6326\n",
      "Epoch [20/100], Loss: 0.5456\n",
      "Validation Loss: 0.6229\n",
      "Epoch [21/100], Loss: 0.5445\n",
      "Validation Loss: 0.6313\n",
      "Epoch [22/100], Loss: 0.5390\n",
      "Validation Loss: 0.6488\n",
      "Epoch [23/100], Loss: 0.5372\n",
      "Validation Loss: 0.6491\n",
      "Epoch [24/100], Loss: 0.5341\n",
      "Validation Loss: 0.6709\n",
      "Epoch [25/100], Loss: 0.5293\n",
      "Validation Loss: 0.6288\n",
      "Epoch [26/100], Loss: 0.5260\n",
      "Validation Loss: 0.6408\n",
      "Epoch [27/100], Loss: 0.5289\n",
      "Validation Loss: 0.6664\n",
      "Epoch [28/100], Loss: 0.5257\n",
      "Validation Loss: 0.6538\n",
      "Epoch [29/100], Loss: 0.5271\n",
      "Validation Loss: 0.6508\n",
      "Epoch [30/100], Loss: 0.5198\n",
      "Validation Loss: 0.6478\n",
      "Epoch [31/100], Loss: 0.5172\n",
      "Validation Loss: 0.6779\n",
      "Epoch [32/100], Loss: 0.5231\n",
      "Validation Loss: 0.6517\n",
      "Epoch [33/100], Loss: 0.5125\n",
      "Validation Loss: 0.6732\n",
      "Epoch [34/100], Loss: 0.5118\n",
      "Validation Loss: 0.7053\n",
      "Epoch [35/100], Loss: 0.5104\n",
      "Validation Loss: 0.6743\n",
      "Epoch [36/100], Loss: 0.5168\n",
      "Validation Loss: 0.6884\n",
      "Epoch [37/100], Loss: 0.5074\n",
      "Validation Loss: 0.6617\n",
      "Epoch [38/100], Loss: 0.5109\n",
      "Validation Loss: 0.6850\n",
      "Epoch [39/100], Loss: 0.5076\n",
      "Validation Loss: 0.6427\n",
      "Epoch [40/100], Loss: 0.5018\n",
      "Validation Loss: 0.6267\n",
      "Epoch [41/100], Loss: 0.5044\n",
      "Validation Loss: 0.6936\n",
      "Epoch [42/100], Loss: 0.5073\n",
      "Validation Loss: 0.7012\n",
      "Epoch [43/100], Loss: 0.4979\n",
      "Validation Loss: 0.6760\n",
      "Epoch [44/100], Loss: 0.4989\n",
      "Validation Loss: 0.6539\n",
      "Epoch [45/100], Loss: 0.4972\n",
      "Validation Loss: 0.6360\n",
      "Epoch [46/100], Loss: 0.4973\n",
      "Validation Loss: 0.6283\n",
      "Epoch [47/100], Loss: 0.4914\n",
      "Validation Loss: 0.6763\n",
      "Epoch [48/100], Loss: 0.5013\n",
      "Validation Loss: 0.6809\n",
      "Epoch [49/100], Loss: 0.4896\n",
      "Validation Loss: 0.6923\n",
      "Epoch [50/100], Loss: 0.4883\n",
      "Validation Loss: 0.7343\n",
      "Epoch [51/100], Loss: 0.4946\n",
      "Validation Loss: 0.6759\n",
      "Epoch [52/100], Loss: 0.4851\n",
      "Validation Loss: 0.7138\n",
      "Epoch [53/100], Loss: 0.4895\n",
      "Validation Loss: 0.6624\n",
      "Epoch [54/100], Loss: 0.4891\n",
      "Validation Loss: 0.6134\n",
      "Epoch [55/100], Loss: 0.4836\n",
      "Validation Loss: 0.7515\n",
      "Epoch [56/100], Loss: 0.4858\n",
      "Validation Loss: 0.7016\n",
      "Epoch [57/100], Loss: 0.4864\n",
      "Validation Loss: 0.9516\n",
      "Epoch [58/100], Loss: 0.4833\n",
      "Validation Loss: 0.8001\n",
      "Epoch [59/100], Loss: 0.4878\n",
      "Validation Loss: 0.6992\n",
      "Epoch [60/100], Loss: 0.4831\n",
      "Validation Loss: 0.6882\n",
      "Epoch [61/100], Loss: 0.4864\n",
      "Validation Loss: 0.6880\n",
      "Epoch [62/100], Loss: 0.4812\n",
      "Validation Loss: 0.7110\n",
      "Epoch [63/100], Loss: 0.4796\n",
      "Validation Loss: 0.7438\n",
      "Epoch [64/100], Loss: 0.4796\n",
      "Validation Loss: 0.6407\n",
      "Epoch [65/100], Loss: 0.4841\n",
      "Validation Loss: 0.7731\n",
      "Epoch [66/100], Loss: 0.4761\n",
      "Validation Loss: 0.7315\n",
      "Epoch [67/100], Loss: 0.4818\n",
      "Validation Loss: 0.7628\n",
      "Epoch [68/100], Loss: 0.4767\n",
      "Validation Loss: 0.7022\n",
      "Epoch [69/100], Loss: 0.4876\n",
      "Validation Loss: 0.7336\n",
      "Epoch [70/100], Loss: 0.4799\n",
      "Validation Loss: 0.6396\n",
      "Epoch [71/100], Loss: 0.4818\n",
      "Validation Loss: 0.7170\n",
      "Epoch [72/100], Loss: 0.4819\n",
      "Validation Loss: 0.7628\n",
      "Epoch [73/100], Loss: 0.4737\n",
      "Validation Loss: 0.7247\n",
      "Epoch [74/100], Loss: 0.4786\n",
      "Validation Loss: 0.7287\n",
      "Epoch [75/100], Loss: 0.4776\n",
      "Validation Loss: 0.6811\n",
      "Epoch [76/100], Loss: 0.4764\n",
      "Validation Loss: 0.6963\n",
      "Epoch [77/100], Loss: 0.4768\n",
      "Validation Loss: 0.7148\n",
      "Epoch [78/100], Loss: 0.4841\n",
      "Validation Loss: 0.6791\n",
      "Epoch [79/100], Loss: 0.4748\n",
      "Validation Loss: 0.6436\n",
      "Epoch [80/100], Loss: 0.4803\n",
      "Validation Loss: 0.7165\n",
      "Epoch [81/100], Loss: 0.4850\n",
      "Validation Loss: 0.6266\n",
      "Epoch [82/100], Loss: 0.4738\n",
      "Validation Loss: 0.7285\n",
      "Epoch [83/100], Loss: 0.4747\n",
      "Validation Loss: 0.6664\n",
      "Epoch [84/100], Loss: 0.4706\n",
      "Validation Loss: 0.6698\n",
      "Epoch [85/100], Loss: 0.4707\n",
      "Validation Loss: 0.6112\n",
      "Epoch [86/100], Loss: 0.4724\n",
      "Validation Loss: 0.6293\n",
      "Epoch [87/100], Loss: 0.4694\n",
      "Validation Loss: 0.6209\n",
      "Epoch [88/100], Loss: 0.4722\n",
      "Validation Loss: 0.6714\n",
      "Epoch [89/100], Loss: 0.4754\n",
      "Validation Loss: 0.6979\n",
      "Epoch [90/100], Loss: 0.4669\n",
      "Validation Loss: 0.6659\n",
      "Epoch [91/100], Loss: 0.4733\n",
      "Validation Loss: 0.6053\n",
      "Epoch [92/100], Loss: 0.4675\n",
      "Validation Loss: 0.6699\n",
      "Epoch [93/100], Loss: 0.4710\n",
      "Validation Loss: 0.6059\n",
      "Epoch [94/100], Loss: 0.4729\n",
      "Validation Loss: 0.6160\n",
      "Epoch [95/100], Loss: 0.4746\n",
      "Validation Loss: 0.6117\n",
      "Epoch [96/100], Loss: 0.4779\n",
      "Validation Loss: 0.6118\n",
      "Epoch [97/100], Loss: 0.4723\n",
      "Validation Loss: 0.6075\n",
      "Epoch [98/100], Loss: 0.4722\n",
      "Validation Loss: 0.5782\n",
      "Saved the best model with validation loss: 0.5782\n",
      "Epoch [99/100], Loss: 0.4736\n",
      "Validation Loss: 0.6045\n",
      "Epoch [100/100], Loss: 0.4680\n",
      "Validation Loss: 0.5855\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"combi 0.05: 17-80-50-5/1-16-32-5/10-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "38a5f13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7549\n",
      "Validation Loss: 0.5508\n",
      "Saved the best model with validation loss: 0.5508\n",
      "Epoch [2/100], Loss: 0.5778\n",
      "Validation Loss: 0.5177\n",
      "Saved the best model with validation loss: 0.5177\n",
      "Epoch [3/100], Loss: 0.5432\n",
      "Validation Loss: 0.5060\n",
      "Saved the best model with validation loss: 0.5060\n",
      "Epoch [4/100], Loss: 0.5266\n",
      "Validation Loss: 0.4924\n",
      "Saved the best model with validation loss: 0.4924\n",
      "Epoch [5/100], Loss: 0.5129\n",
      "Validation Loss: 0.4752\n",
      "Saved the best model with validation loss: 0.4752\n",
      "Epoch [6/100], Loss: 0.5028\n",
      "Validation Loss: 0.4637\n",
      "Saved the best model with validation loss: 0.4637\n",
      "Epoch [7/100], Loss: 0.4964\n",
      "Validation Loss: 0.4549\n",
      "Saved the best model with validation loss: 0.4549\n",
      "Epoch [8/100], Loss: 0.4907\n",
      "Validation Loss: 0.4402\n",
      "Saved the best model with validation loss: 0.4402\n",
      "Epoch [9/100], Loss: 0.4869\n",
      "Validation Loss: 0.4390\n",
      "Saved the best model with validation loss: 0.4390\n",
      "Epoch [10/100], Loss: 0.4812\n",
      "Validation Loss: 0.4373\n",
      "Saved the best model with validation loss: 0.4373\n",
      "Epoch [11/100], Loss: 0.4771\n",
      "Validation Loss: 0.4433\n",
      "Epoch [12/100], Loss: 0.4743\n",
      "Validation Loss: 0.4277\n",
      "Saved the best model with validation loss: 0.4277\n",
      "Epoch [13/100], Loss: 0.4714\n",
      "Validation Loss: 0.4260\n",
      "Saved the best model with validation loss: 0.4260\n",
      "Epoch [14/100], Loss: 0.4686\n",
      "Validation Loss: 0.4326\n",
      "Epoch [15/100], Loss: 0.4674\n",
      "Validation Loss: 0.4427\n",
      "Epoch [16/100], Loss: 0.4637\n",
      "Validation Loss: 0.4316\n",
      "Epoch [17/100], Loss: 0.4620\n",
      "Validation Loss: 0.4288\n",
      "Epoch [18/100], Loss: 0.4592\n",
      "Validation Loss: 0.4267\n",
      "Epoch [19/100], Loss: 0.4580\n",
      "Validation Loss: 0.4256\n",
      "Saved the best model with validation loss: 0.4256\n",
      "Epoch [20/100], Loss: 0.4560\n",
      "Validation Loss: 0.4323\n",
      "Epoch [21/100], Loss: 0.4562\n",
      "Validation Loss: 0.4244\n",
      "Saved the best model with validation loss: 0.4244\n",
      "Epoch [22/100], Loss: 0.4506\n",
      "Validation Loss: 0.4254\n",
      "Epoch [23/100], Loss: 0.4503\n",
      "Validation Loss: 0.4261\n",
      "Epoch [24/100], Loss: 0.4502\n",
      "Validation Loss: 0.4214\n",
      "Saved the best model with validation loss: 0.4214\n",
      "Epoch [25/100], Loss: 0.4467\n",
      "Validation Loss: 0.4190\n",
      "Saved the best model with validation loss: 0.4190\n",
      "Epoch [26/100], Loss: 0.4468\n",
      "Validation Loss: 0.4231\n",
      "Epoch [27/100], Loss: 0.4425\n",
      "Validation Loss: 0.4255\n",
      "Epoch [28/100], Loss: 0.4453\n",
      "Validation Loss: 0.4182\n",
      "Saved the best model with validation loss: 0.4182\n",
      "Epoch [29/100], Loss: 0.4418\n",
      "Validation Loss: 0.4207\n",
      "Epoch [30/100], Loss: 0.4414\n",
      "Validation Loss: 0.4297\n",
      "Epoch [31/100], Loss: 0.4410\n",
      "Validation Loss: 0.4230\n",
      "Epoch [32/100], Loss: 0.4389\n",
      "Validation Loss: 0.4316\n",
      "Epoch [33/100], Loss: 0.4369\n",
      "Validation Loss: 0.4229\n",
      "Epoch [34/100], Loss: 0.4356\n",
      "Validation Loss: 0.4205\n",
      "Epoch [35/100], Loss: 0.4364\n",
      "Validation Loss: 0.4390\n",
      "Epoch [36/100], Loss: 0.4312\n",
      "Validation Loss: 0.4228\n",
      "Epoch [37/100], Loss: 0.4306\n",
      "Validation Loss: 0.4379\n",
      "Epoch [38/100], Loss: 0.4347\n",
      "Validation Loss: 0.4272\n",
      "Epoch [39/100], Loss: 0.4338\n",
      "Validation Loss: 0.4457\n",
      "Epoch [40/100], Loss: 0.4334\n",
      "Validation Loss: 0.4215\n",
      "Epoch [41/100], Loss: 0.4307\n",
      "Validation Loss: 0.4278\n",
      "Epoch [42/100], Loss: 0.4348\n",
      "Validation Loss: 0.4321\n",
      "Epoch [43/100], Loss: 0.4276\n",
      "Validation Loss: 0.4151\n",
      "Saved the best model with validation loss: 0.4151\n",
      "Epoch [44/100], Loss: 0.4246\n",
      "Validation Loss: 0.4215\n",
      "Epoch [45/100], Loss: 0.4301\n",
      "Validation Loss: 0.4221\n",
      "Epoch [46/100], Loss: 0.4209\n",
      "Validation Loss: 0.4144\n",
      "Saved the best model with validation loss: 0.4144\n",
      "Epoch [47/100], Loss: 0.4277\n",
      "Validation Loss: 0.4313\n",
      "Epoch [48/100], Loss: 0.4233\n",
      "Validation Loss: 0.4059\n",
      "Saved the best model with validation loss: 0.4059\n",
      "Epoch [49/100], Loss: 0.4220\n",
      "Validation Loss: 0.4126\n",
      "Epoch [50/100], Loss: 0.4158\n",
      "Validation Loss: 0.4469\n",
      "Epoch [51/100], Loss: 0.4213\n",
      "Validation Loss: 0.4055\n",
      "Saved the best model with validation loss: 0.4055\n",
      "Epoch [52/100], Loss: 0.4202\n",
      "Validation Loss: 0.4078\n",
      "Epoch [53/100], Loss: 0.4157\n",
      "Validation Loss: 0.4365\n",
      "Epoch [54/100], Loss: 0.4156\n",
      "Validation Loss: 0.4166\n",
      "Epoch [55/100], Loss: 0.4160\n",
      "Validation Loss: 0.4231\n",
      "Epoch [56/100], Loss: 0.4136\n",
      "Validation Loss: 0.4180\n",
      "Epoch [57/100], Loss: 0.4147\n",
      "Validation Loss: 0.4410\n",
      "Epoch [58/100], Loss: 0.4128\n",
      "Validation Loss: 0.4144\n",
      "Epoch [59/100], Loss: 0.4135\n",
      "Validation Loss: 0.3961\n",
      "Saved the best model with validation loss: 0.3961\n",
      "Epoch [60/100], Loss: 0.4076\n",
      "Validation Loss: 0.4012\n",
      "Epoch [61/100], Loss: 0.4134\n",
      "Validation Loss: 0.4037\n",
      "Epoch [62/100], Loss: 0.4102\n",
      "Validation Loss: 0.4184\n",
      "Epoch [63/100], Loss: 0.4118\n",
      "Validation Loss: 0.3941\n",
      "Saved the best model with validation loss: 0.3941\n",
      "Epoch [64/100], Loss: 0.4087\n",
      "Validation Loss: 0.4052\n",
      "Epoch [65/100], Loss: 0.4101\n",
      "Validation Loss: 0.4015\n",
      "Epoch [66/100], Loss: 0.4120\n",
      "Validation Loss: 0.4078\n",
      "Epoch [67/100], Loss: 0.4141\n",
      "Validation Loss: 0.4202\n",
      "Epoch [68/100], Loss: 0.4152\n",
      "Validation Loss: 0.4011\n",
      "Epoch [69/100], Loss: 0.4049\n",
      "Validation Loss: 0.4265\n",
      "Epoch [70/100], Loss: 0.4039\n",
      "Validation Loss: 0.4132\n",
      "Epoch [71/100], Loss: 0.4069\n",
      "Validation Loss: 0.4309\n",
      "Epoch [72/100], Loss: 0.4132\n",
      "Validation Loss: 0.4190\n",
      "Epoch [73/100], Loss: 0.4015\n",
      "Validation Loss: 0.4115\n",
      "Epoch [74/100], Loss: 0.4061\n",
      "Validation Loss: 0.4265\n",
      "Epoch [75/100], Loss: 0.4030\n",
      "Validation Loss: 0.4135\n",
      "Epoch [76/100], Loss: 0.4073\n",
      "Validation Loss: 0.4182\n",
      "Epoch [77/100], Loss: 0.3996\n",
      "Validation Loss: 0.4146\n",
      "Epoch [78/100], Loss: 0.4005\n",
      "Validation Loss: 0.4346\n",
      "Epoch [79/100], Loss: 0.4049\n",
      "Validation Loss: 0.4242\n",
      "Epoch [80/100], Loss: 0.4033\n",
      "Validation Loss: 0.4095\n",
      "Epoch [81/100], Loss: 0.4055\n",
      "Validation Loss: 0.4054\n",
      "Epoch [82/100], Loss: 0.4035\n",
      "Validation Loss: 0.4138\n",
      "Epoch [83/100], Loss: 0.4086\n",
      "Validation Loss: 0.4494\n",
      "Epoch [84/100], Loss: 0.4022\n",
      "Validation Loss: 0.4130\n",
      "Epoch [85/100], Loss: 0.4021\n",
      "Validation Loss: 0.4120\n",
      "Epoch [86/100], Loss: 0.4078\n",
      "Validation Loss: 0.4115\n",
      "Epoch [87/100], Loss: 0.4061\n",
      "Validation Loss: 0.4265\n",
      "Epoch [88/100], Loss: 0.4103\n",
      "Validation Loss: 0.4098\n",
      "Epoch [89/100], Loss: 0.4002\n",
      "Validation Loss: 0.4054\n",
      "Epoch [90/100], Loss: 0.3995\n",
      "Validation Loss: 0.4111\n",
      "Epoch [91/100], Loss: 0.4040\n",
      "Validation Loss: 0.4091\n",
      "Epoch [92/100], Loss: 0.3990\n",
      "Validation Loss: 0.4310\n",
      "Epoch [93/100], Loss: 0.4006\n",
      "Validation Loss: 0.4059\n",
      "Epoch [94/100], Loss: 0.3912\n",
      "Validation Loss: 0.4185\n",
      "Epoch [95/100], Loss: 0.3969\n",
      "Validation Loss: 0.4094\n",
      "Epoch [96/100], Loss: 0.3986\n",
      "Validation Loss: 0.4253\n",
      "Epoch [97/100], Loss: 0.4028\n",
      "Validation Loss: 0.3935\n",
      "Saved the best model with validation loss: 0.3935\n",
      "Epoch [98/100], Loss: 0.3964\n",
      "Validation Loss: 0.4063\n",
      "Epoch [99/100], Loss: 0.4002\n",
      "Validation Loss: 0.4061\n",
      "Epoch [100/100], Loss: 0.3983\n",
      "Validation Loss: 0.4101\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"combi 0.01: 17-80-50-5/1-16-32-5/10-20-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88943826",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 4, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  MLP 17-80-50-10\n",
    "*  HGNN 1-16-32-10\n",
    "*  Combined 20-40-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "ac88ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "b195dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.8051\n",
      "Validation Loss: 0.5659\n",
      "Saved the best model with validation loss: 0.5659\n",
      "Epoch [2/100], Loss: 0.5908\n",
      "Validation Loss: 0.4976\n",
      "Saved the best model with validation loss: 0.4976\n",
      "Epoch [3/100], Loss: 0.5456\n",
      "Validation Loss: 0.4809\n",
      "Saved the best model with validation loss: 0.4809\n",
      "Epoch [4/100], Loss: 0.5250\n",
      "Validation Loss: 0.4554\n",
      "Saved the best model with validation loss: 0.4554\n",
      "Epoch [5/100], Loss: 0.5099\n",
      "Validation Loss: 0.4566\n",
      "Epoch [6/100], Loss: 0.4952\n",
      "Validation Loss: 0.4448\n",
      "Saved the best model with validation loss: 0.4448\n",
      "Epoch [7/100], Loss: 0.4839\n",
      "Validation Loss: 0.4385\n",
      "Saved the best model with validation loss: 0.4385\n",
      "Epoch [8/100], Loss: 0.4732\n",
      "Validation Loss: 0.4340\n",
      "Saved the best model with validation loss: 0.4340\n",
      "Epoch [9/100], Loss: 0.4623\n",
      "Validation Loss: 0.4280\n",
      "Saved the best model with validation loss: 0.4280\n",
      "Epoch [10/100], Loss: 0.4528\n",
      "Validation Loss: 0.4216\n",
      "Saved the best model with validation loss: 0.4216\n",
      "Epoch [11/100], Loss: 0.4437\n",
      "Validation Loss: 0.4140\n",
      "Saved the best model with validation loss: 0.4140\n",
      "Epoch [12/100], Loss: 0.4430\n",
      "Validation Loss: 0.4215\n",
      "Epoch [13/100], Loss: 0.4348\n",
      "Validation Loss: 0.4056\n",
      "Saved the best model with validation loss: 0.4056\n",
      "Epoch [14/100], Loss: 0.4320\n",
      "Validation Loss: 0.4246\n",
      "Epoch [15/100], Loss: 0.4263\n",
      "Validation Loss: 0.4097\n",
      "Epoch [16/100], Loss: 0.4192\n",
      "Validation Loss: 0.4087\n",
      "Epoch [17/100], Loss: 0.4225\n",
      "Validation Loss: 0.3972\n",
      "Saved the best model with validation loss: 0.3972\n",
      "Epoch [18/100], Loss: 0.4160\n",
      "Validation Loss: 0.4002\n",
      "Epoch [19/100], Loss: 0.4129\n",
      "Validation Loss: 0.4002\n",
      "Epoch [20/100], Loss: 0.4124\n",
      "Validation Loss: 0.4177\n",
      "Epoch [21/100], Loss: 0.4119\n",
      "Validation Loss: 0.4255\n",
      "Epoch [22/100], Loss: 0.4113\n",
      "Validation Loss: 0.4302\n",
      "Epoch [23/100], Loss: 0.4042\n",
      "Validation Loss: 0.4316\n",
      "Epoch [24/100], Loss: 0.4067\n",
      "Validation Loss: 0.4097\n",
      "Epoch [25/100], Loss: 0.4051\n",
      "Validation Loss: 0.4231\n",
      "Epoch [26/100], Loss: 0.4018\n",
      "Validation Loss: 0.4461\n",
      "Epoch [27/100], Loss: 0.3960\n",
      "Validation Loss: 0.4857\n",
      "Epoch [28/100], Loss: 0.3997\n",
      "Validation Loss: 0.3797\n",
      "Saved the best model with validation loss: 0.3797\n",
      "Epoch [29/100], Loss: 0.3956\n",
      "Validation Loss: 0.4471\n",
      "Epoch [30/100], Loss: 0.3938\n",
      "Validation Loss: 0.4066\n",
      "Epoch [31/100], Loss: 0.3968\n",
      "Validation Loss: 0.4110\n",
      "Epoch [32/100], Loss: 0.3943\n",
      "Validation Loss: 0.3794\n",
      "Saved the best model with validation loss: 0.3794\n",
      "Epoch [33/100], Loss: 0.3962\n",
      "Validation Loss: 0.3551\n",
      "Saved the best model with validation loss: 0.3551\n",
      "Epoch [34/100], Loss: 0.3944\n",
      "Validation Loss: 0.3931\n",
      "Epoch [35/100], Loss: 0.3943\n",
      "Validation Loss: 0.3556\n",
      "Epoch [36/100], Loss: 0.3858\n",
      "Validation Loss: 0.4241\n",
      "Epoch [37/100], Loss: 0.3947\n",
      "Validation Loss: 0.3918\n",
      "Epoch [38/100], Loss: 0.3866\n",
      "Validation Loss: 0.4279\n",
      "Epoch [39/100], Loss: 0.3845\n",
      "Validation Loss: 0.3880\n",
      "Epoch [40/100], Loss: 0.3891\n",
      "Validation Loss: 0.3766\n",
      "Epoch [41/100], Loss: 0.3818\n",
      "Validation Loss: 0.3846\n",
      "Epoch [42/100], Loss: 0.3777\n",
      "Validation Loss: 0.3784\n",
      "Epoch [43/100], Loss: 0.3768\n",
      "Validation Loss: 0.4162\n",
      "Epoch [44/100], Loss: 0.3817\n",
      "Validation Loss: 0.3599\n",
      "Epoch [45/100], Loss: 0.3761\n",
      "Validation Loss: 0.3868\n",
      "Epoch [46/100], Loss: 0.3698\n",
      "Validation Loss: 0.3657\n",
      "Epoch [47/100], Loss: 0.3777\n",
      "Validation Loss: 0.3617\n",
      "Epoch [48/100], Loss: 0.3659\n",
      "Validation Loss: 0.3848\n",
      "Epoch [49/100], Loss: 0.3761\n",
      "Validation Loss: 0.3627\n",
      "Epoch [50/100], Loss: 0.3685\n",
      "Validation Loss: 0.3938\n",
      "Epoch [51/100], Loss: 0.3696\n",
      "Validation Loss: 0.4196\n",
      "Epoch [52/100], Loss: 0.3716\n",
      "Validation Loss: 0.3736\n",
      "Epoch [53/100], Loss: 0.3674\n",
      "Validation Loss: 0.3602\n",
      "Epoch [54/100], Loss: 0.3612\n",
      "Validation Loss: 0.3580\n",
      "Epoch [55/100], Loss: 0.3595\n",
      "Validation Loss: 0.3833\n",
      "Epoch [56/100], Loss: 0.3634\n",
      "Validation Loss: 0.3541\n",
      "Saved the best model with validation loss: 0.3541\n",
      "Epoch [57/100], Loss: 0.3620\n",
      "Validation Loss: 0.3585\n",
      "Epoch [58/100], Loss: 0.3600\n",
      "Validation Loss: 0.3623\n",
      "Epoch [59/100], Loss: 0.3593\n",
      "Validation Loss: 0.3347\n",
      "Saved the best model with validation loss: 0.3347\n",
      "Epoch [60/100], Loss: 0.3548\n",
      "Validation Loss: 0.3888\n",
      "Epoch [61/100], Loss: 0.3625\n",
      "Validation Loss: 0.4152\n",
      "Epoch [62/100], Loss: 0.3574\n",
      "Validation Loss: 0.3261\n",
      "Saved the best model with validation loss: 0.3261\n",
      "Epoch [63/100], Loss: 0.3658\n",
      "Validation Loss: 0.3304\n",
      "Epoch [64/100], Loss: 0.3559\n",
      "Validation Loss: 0.3114\n",
      "Saved the best model with validation loss: 0.3114\n",
      "Epoch [65/100], Loss: 0.3674\n",
      "Validation Loss: 0.3261\n",
      "Epoch [66/100], Loss: 0.3547\n",
      "Validation Loss: 0.3161\n",
      "Epoch [67/100], Loss: 0.3658\n",
      "Validation Loss: 0.3557\n",
      "Epoch [68/100], Loss: 0.3557\n",
      "Validation Loss: 0.3273\n",
      "Epoch [69/100], Loss: 0.3507\n",
      "Validation Loss: 0.3253\n",
      "Epoch [70/100], Loss: 0.3530\n",
      "Validation Loss: 0.3412\n",
      "Epoch [71/100], Loss: 0.3487\n",
      "Validation Loss: 0.3390\n",
      "Epoch [72/100], Loss: 0.3593\n",
      "Validation Loss: 0.3376\n",
      "Epoch [73/100], Loss: 0.3511\n",
      "Validation Loss: 0.3735\n",
      "Epoch [74/100], Loss: 0.3499\n",
      "Validation Loss: 0.3120\n",
      "Epoch [75/100], Loss: 0.3554\n",
      "Validation Loss: 0.3030\n",
      "Saved the best model with validation loss: 0.3030\n",
      "Epoch [76/100], Loss: 0.3516\n",
      "Validation Loss: 0.5146\n",
      "Epoch [77/100], Loss: 0.3548\n",
      "Validation Loss: 0.3234\n",
      "Epoch [78/100], Loss: 0.3548\n",
      "Validation Loss: 0.3292\n",
      "Epoch [79/100], Loss: 0.3522\n",
      "Validation Loss: 0.3560\n",
      "Epoch [80/100], Loss: 0.3495\n",
      "Validation Loss: 0.3155\n",
      "Epoch [81/100], Loss: 0.3462\n",
      "Validation Loss: 0.3130\n",
      "Epoch [82/100], Loss: 0.3472\n",
      "Validation Loss: 0.3289\n",
      "Epoch [83/100], Loss: 0.3522\n",
      "Validation Loss: 0.3278\n",
      "Epoch [84/100], Loss: 0.3577\n",
      "Validation Loss: 0.3129\n",
      "Epoch [85/100], Loss: 0.3465\n",
      "Validation Loss: 0.3606\n",
      "Epoch [86/100], Loss: 0.3520\n",
      "Validation Loss: 0.3745\n",
      "Epoch [87/100], Loss: 0.3443\n",
      "Validation Loss: 0.3249\n",
      "Epoch [88/100], Loss: 0.3478\n",
      "Validation Loss: 0.3349\n",
      "Epoch [89/100], Loss: 0.3445\n",
      "Validation Loss: 0.3237\n",
      "Epoch [90/100], Loss: 0.3560\n",
      "Validation Loss: 0.3405\n",
      "Epoch [91/100], Loss: 0.3427\n",
      "Validation Loss: 0.3262\n",
      "Epoch [92/100], Loss: 0.3434\n",
      "Validation Loss: 0.3082\n",
      "Epoch [93/100], Loss: 0.3589\n",
      "Validation Loss: 0.3389\n",
      "Epoch [94/100], Loss: 0.3668\n",
      "Validation Loss: 0.3086\n",
      "Epoch [95/100], Loss: 0.3451\n",
      "Validation Loss: 0.3292\n",
      "Epoch [96/100], Loss: 0.3443\n",
      "Validation Loss: 0.3373\n",
      "Epoch [97/100], Loss: 0.3418\n",
      "Validation Loss: 0.3387\n",
      "Epoch [98/100], Loss: 0.3496\n",
      "Validation Loss: 0.3086\n",
      "Epoch [99/100], Loss: 0.3404\n",
      "Validation Loss: 0.3542\n",
      "Epoch [100/100], Loss: 0.3406\n",
      "Validation Loss: 0.3400\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"combi 0.5: 17-80-50-10/1-16-32-10/20-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "b00f1bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.9396\n",
      "Validation Loss: 0.7942\n",
      "Saved the best model with validation loss: 0.7942\n",
      "Epoch [2/100], Loss: 0.7406\n",
      "Validation Loss: 0.7554\n",
      "Saved the best model with validation loss: 0.7554\n",
      "Epoch [3/100], Loss: 0.6938\n",
      "Validation Loss: 0.7310\n",
      "Saved the best model with validation loss: 0.7310\n",
      "Epoch [4/100], Loss: 0.6644\n",
      "Validation Loss: 0.7129\n",
      "Saved the best model with validation loss: 0.7129\n",
      "Epoch [5/100], Loss: 0.6475\n",
      "Validation Loss: 0.6982\n",
      "Saved the best model with validation loss: 0.6982\n",
      "Epoch [6/100], Loss: 0.6362\n",
      "Validation Loss: 0.6897\n",
      "Saved the best model with validation loss: 0.6897\n",
      "Epoch [7/100], Loss: 0.6250\n",
      "Validation Loss: 0.6848\n",
      "Saved the best model with validation loss: 0.6848\n",
      "Epoch [8/100], Loss: 0.6169\n",
      "Validation Loss: 0.6738\n",
      "Saved the best model with validation loss: 0.6738\n",
      "Epoch [9/100], Loss: 0.6072\n",
      "Validation Loss: 0.6714\n",
      "Saved the best model with validation loss: 0.6714\n",
      "Epoch [10/100], Loss: 0.6005\n",
      "Validation Loss: 0.6669\n",
      "Saved the best model with validation loss: 0.6669\n",
      "Epoch [11/100], Loss: 0.5964\n",
      "Validation Loss: 0.6520\n",
      "Saved the best model with validation loss: 0.6520\n",
      "Epoch [12/100], Loss: 0.5890\n",
      "Validation Loss: 0.6558\n",
      "Epoch [13/100], Loss: 0.5848\n",
      "Validation Loss: 0.6533\n",
      "Epoch [14/100], Loss: 0.5782\n",
      "Validation Loss: 0.6743\n",
      "Epoch [15/100], Loss: 0.5739\n",
      "Validation Loss: 0.6749\n",
      "Epoch [16/100], Loss: 0.5738\n",
      "Validation Loss: 0.6664\n",
      "Epoch [17/100], Loss: 0.5696\n",
      "Validation Loss: 0.6748\n",
      "Epoch [18/100], Loss: 0.5632\n",
      "Validation Loss: 0.6639\n",
      "Epoch [19/100], Loss: 0.5619\n",
      "Validation Loss: 0.6645\n",
      "Epoch [20/100], Loss: 0.5590\n",
      "Validation Loss: 0.6581\n",
      "Epoch [21/100], Loss: 0.5603\n",
      "Validation Loss: 0.6488\n",
      "Saved the best model with validation loss: 0.6488\n",
      "Epoch [22/100], Loss: 0.5553\n",
      "Validation Loss: 0.6484\n",
      "Saved the best model with validation loss: 0.6484\n",
      "Epoch [23/100], Loss: 0.5527\n",
      "Validation Loss: 0.6762\n",
      "Epoch [24/100], Loss: 0.5534\n",
      "Validation Loss: 0.6388\n",
      "Saved the best model with validation loss: 0.6388\n",
      "Epoch [25/100], Loss: 0.5499\n",
      "Validation Loss: 0.6541\n",
      "Epoch [26/100], Loss: 0.5478\n",
      "Validation Loss: 0.6531\n",
      "Epoch [27/100], Loss: 0.5483\n",
      "Validation Loss: 0.6602\n",
      "Epoch [28/100], Loss: 0.5415\n",
      "Validation Loss: 0.6594\n",
      "Epoch [29/100], Loss: 0.5440\n",
      "Validation Loss: 0.6510\n",
      "Epoch [30/100], Loss: 0.5419\n",
      "Validation Loss: 0.6420\n",
      "Epoch [31/100], Loss: 0.5377\n",
      "Validation Loss: 0.6465\n",
      "Epoch [32/100], Loss: 0.5412\n",
      "Validation Loss: 0.6657\n",
      "Epoch [33/100], Loss: 0.5385\n",
      "Validation Loss: 0.6296\n",
      "Saved the best model with validation loss: 0.6296\n",
      "Epoch [34/100], Loss: 0.5353\n",
      "Validation Loss: 0.7313\n",
      "Epoch [35/100], Loss: 0.5374\n",
      "Validation Loss: 0.6968\n",
      "Epoch [36/100], Loss: 0.5370\n",
      "Validation Loss: 0.6590\n",
      "Epoch [37/100], Loss: 0.5308\n",
      "Validation Loss: 0.7494\n",
      "Epoch [38/100], Loss: 0.5311\n",
      "Validation Loss: 0.6482\n",
      "Epoch [39/100], Loss: 0.5263\n",
      "Validation Loss: 0.7062\n",
      "Epoch [40/100], Loss: 0.5318\n",
      "Validation Loss: 0.7010\n",
      "Epoch [41/100], Loss: 0.5277\n",
      "Validation Loss: 0.6886\n",
      "Epoch [42/100], Loss: 0.5301\n",
      "Validation Loss: 0.6522\n",
      "Epoch [43/100], Loss: 0.5291\n",
      "Validation Loss: 0.6194\n",
      "Saved the best model with validation loss: 0.6194\n",
      "Epoch [44/100], Loss: 0.5301\n",
      "Validation Loss: 0.6132\n",
      "Saved the best model with validation loss: 0.6132\n",
      "Epoch [45/100], Loss: 0.5292\n",
      "Validation Loss: 0.6234\n",
      "Epoch [46/100], Loss: 0.5278\n",
      "Validation Loss: 0.6428\n",
      "Epoch [47/100], Loss: 0.5267\n",
      "Validation Loss: 0.6672\n",
      "Epoch [48/100], Loss: 0.5256\n",
      "Validation Loss: 0.6470\n",
      "Epoch [49/100], Loss: 0.5231\n",
      "Validation Loss: 0.6234\n",
      "Epoch [50/100], Loss: 0.5215\n",
      "Validation Loss: 0.6507\n",
      "Epoch [51/100], Loss: 0.5296\n",
      "Validation Loss: 0.6434\n",
      "Epoch [52/100], Loss: 0.5275\n",
      "Validation Loss: 0.6487\n",
      "Epoch [53/100], Loss: 0.5228\n",
      "Validation Loss: 0.6628\n",
      "Epoch [54/100], Loss: 0.5253\n",
      "Validation Loss: 0.6668\n",
      "Epoch [55/100], Loss: 0.5228\n",
      "Validation Loss: 0.6696\n",
      "Epoch [56/100], Loss: 0.5219\n",
      "Validation Loss: 0.6452\n",
      "Epoch [57/100], Loss: 0.5183\n",
      "Validation Loss: 0.6504\n",
      "Epoch [58/100], Loss: 0.5204\n",
      "Validation Loss: 0.6842\n",
      "Epoch [59/100], Loss: 0.5192\n",
      "Validation Loss: 0.6848\n",
      "Epoch [60/100], Loss: 0.5192\n",
      "Validation Loss: 0.7130\n",
      "Epoch [61/100], Loss: 0.5190\n",
      "Validation Loss: 0.6516\n",
      "Epoch [62/100], Loss: 0.5151\n",
      "Validation Loss: 0.6731\n",
      "Epoch [63/100], Loss: 0.5182\n",
      "Validation Loss: 0.7353\n",
      "Epoch [64/100], Loss: 0.5130\n",
      "Validation Loss: 0.7409\n",
      "Epoch [65/100], Loss: 0.5287\n",
      "Validation Loss: 0.6964\n",
      "Epoch [66/100], Loss: 0.5141\n",
      "Validation Loss: 0.6647\n",
      "Epoch [67/100], Loss: 0.5131\n",
      "Validation Loss: 0.7265\n",
      "Epoch [68/100], Loss: 0.5208\n",
      "Validation Loss: 0.6994\n",
      "Epoch [69/100], Loss: 0.5123\n",
      "Validation Loss: 0.6970\n",
      "Epoch [70/100], Loss: 0.5110\n",
      "Validation Loss: 0.7141\n",
      "Epoch [71/100], Loss: 0.5138\n",
      "Validation Loss: 0.6999\n",
      "Epoch [72/100], Loss: 0.5141\n",
      "Validation Loss: 0.7790\n",
      "Epoch [73/100], Loss: 0.5115\n",
      "Validation Loss: 0.6823\n",
      "Epoch [74/100], Loss: 0.5131\n",
      "Validation Loss: 0.7066\n",
      "Epoch [75/100], Loss: 0.5121\n",
      "Validation Loss: 0.7247\n",
      "Epoch [76/100], Loss: 0.5128\n",
      "Validation Loss: 0.7766\n",
      "Epoch [77/100], Loss: 0.5078\n",
      "Validation Loss: 0.8243\n",
      "Epoch [78/100], Loss: 0.5113\n",
      "Validation Loss: 0.7967\n",
      "Epoch [79/100], Loss: 0.5060\n",
      "Validation Loss: 0.7395\n",
      "Epoch [80/100], Loss: 0.5093\n",
      "Validation Loss: 0.7594\n",
      "Epoch [81/100], Loss: 0.5111\n",
      "Validation Loss: 0.7561\n",
      "Epoch [82/100], Loss: 0.5037\n",
      "Validation Loss: 0.7778\n",
      "Epoch [83/100], Loss: 0.5056\n",
      "Validation Loss: 0.8057\n",
      "Epoch [84/100], Loss: 0.5072\n",
      "Validation Loss: 0.8911\n",
      "Epoch [85/100], Loss: 0.5074\n",
      "Validation Loss: 0.7620\n",
      "Epoch [86/100], Loss: 0.5044\n",
      "Validation Loss: 0.7394\n",
      "Epoch [87/100], Loss: 0.5066\n",
      "Validation Loss: 0.8166\n",
      "Epoch [88/100], Loss: 0.5060\n",
      "Validation Loss: 0.7864\n",
      "Epoch [89/100], Loss: 0.5018\n",
      "Validation Loss: 0.8531\n",
      "Epoch [90/100], Loss: 0.5060\n",
      "Validation Loss: 0.7549\n",
      "Epoch [91/100], Loss: 0.5082\n",
      "Validation Loss: 0.7257\n",
      "Epoch [92/100], Loss: 0.5070\n",
      "Validation Loss: 0.7739\n",
      "Epoch [93/100], Loss: 0.5082\n",
      "Validation Loss: 0.7705\n",
      "Epoch [94/100], Loss: 0.5044\n",
      "Validation Loss: 0.7479\n",
      "Epoch [95/100], Loss: 0.5024\n",
      "Validation Loss: 0.8505\n",
      "Epoch [96/100], Loss: 0.5033\n",
      "Validation Loss: 0.8480\n",
      "Epoch [97/100], Loss: 0.4988\n",
      "Validation Loss: 0.7932\n",
      "Epoch [98/100], Loss: 0.5048\n",
      "Validation Loss: 0.8049\n",
      "Epoch [99/100], Loss: 0.5019\n",
      "Validation Loss: 0.7987\n",
      "Epoch [100/100], Loss: 0.5042\n",
      "Validation Loss: 0.8259\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"combi 0.1: 17-80-50-10/1-16-32-10/20-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "bf9fee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.8979\n",
      "Validation Loss: 0.7381\n",
      "Saved the best model with validation loss: 0.7381\n",
      "Epoch [2/100], Loss: 0.7176\n",
      "Validation Loss: 0.7074\n",
      "Saved the best model with validation loss: 0.7074\n",
      "Epoch [3/100], Loss: 0.6785\n",
      "Validation Loss: 0.6979\n",
      "Saved the best model with validation loss: 0.6979\n",
      "Epoch [4/100], Loss: 0.6558\n",
      "Validation Loss: 0.6834\n",
      "Saved the best model with validation loss: 0.6834\n",
      "Epoch [5/100], Loss: 0.6346\n",
      "Validation Loss: 0.6599\n",
      "Saved the best model with validation loss: 0.6599\n",
      "Epoch [6/100], Loss: 0.6220\n",
      "Validation Loss: 0.6512\n",
      "Saved the best model with validation loss: 0.6512\n",
      "Epoch [7/100], Loss: 0.6088\n",
      "Validation Loss: 0.6421\n",
      "Saved the best model with validation loss: 0.6421\n",
      "Epoch [8/100], Loss: 0.5975\n",
      "Validation Loss: 0.6333\n",
      "Saved the best model with validation loss: 0.6333\n",
      "Epoch [9/100], Loss: 0.5884\n",
      "Validation Loss: 0.6204\n",
      "Saved the best model with validation loss: 0.6204\n",
      "Epoch [10/100], Loss: 0.5774\n",
      "Validation Loss: 0.6132\n",
      "Saved the best model with validation loss: 0.6132\n",
      "Epoch [11/100], Loss: 0.5702\n",
      "Validation Loss: 0.6152\n",
      "Epoch [12/100], Loss: 0.5625\n",
      "Validation Loss: 0.5911\n",
      "Saved the best model with validation loss: 0.5911\n",
      "Epoch [13/100], Loss: 0.5518\n",
      "Validation Loss: 0.6044\n",
      "Epoch [14/100], Loss: 0.5469\n",
      "Validation Loss: 0.5985\n",
      "Epoch [15/100], Loss: 0.5429\n",
      "Validation Loss: 0.6135\n",
      "Epoch [16/100], Loss: 0.5371\n",
      "Validation Loss: 0.6053\n",
      "Epoch [17/100], Loss: 0.5315\n",
      "Validation Loss: 0.6038\n",
      "Epoch [18/100], Loss: 0.5296\n",
      "Validation Loss: 0.5716\n",
      "Saved the best model with validation loss: 0.5716\n",
      "Epoch [19/100], Loss: 0.5283\n",
      "Validation Loss: 0.5797\n",
      "Epoch [20/100], Loss: 0.5232\n",
      "Validation Loss: 0.6783\n",
      "Epoch [21/100], Loss: 0.5220\n",
      "Validation Loss: 0.5982\n",
      "Epoch [22/100], Loss: 0.5180\n",
      "Validation Loss: 0.6032\n",
      "Epoch [23/100], Loss: 0.5161\n",
      "Validation Loss: 0.6066\n",
      "Epoch [24/100], Loss: 0.5131\n",
      "Validation Loss: 0.5954\n",
      "Epoch [25/100], Loss: 0.5126\n",
      "Validation Loss: 0.5907\n",
      "Epoch [26/100], Loss: 0.5089\n",
      "Validation Loss: 0.6105\n",
      "Epoch [27/100], Loss: 0.5116\n",
      "Validation Loss: 0.6101\n",
      "Epoch [28/100], Loss: 0.5041\n",
      "Validation Loss: 0.6009\n",
      "Epoch [29/100], Loss: 0.4998\n",
      "Validation Loss: 0.6320\n",
      "Epoch [30/100], Loss: 0.4983\n",
      "Validation Loss: 0.6366\n",
      "Epoch [31/100], Loss: 0.4961\n",
      "Validation Loss: 0.6258\n",
      "Epoch [32/100], Loss: 0.4903\n",
      "Validation Loss: 0.6358\n",
      "Epoch [33/100], Loss: 0.4941\n",
      "Validation Loss: 0.6815\n",
      "Epoch [34/100], Loss: 0.4898\n",
      "Validation Loss: 0.6432\n",
      "Epoch [35/100], Loss: 0.4842\n",
      "Validation Loss: 0.6445\n",
      "Epoch [36/100], Loss: 0.4883\n",
      "Validation Loss: 0.6318\n",
      "Epoch [37/100], Loss: 0.4874\n",
      "Validation Loss: 0.6132\n",
      "Epoch [38/100], Loss: 0.4856\n",
      "Validation Loss: 0.6518\n",
      "Epoch [39/100], Loss: 0.4833\n",
      "Validation Loss: 0.6058\n",
      "Epoch [40/100], Loss: 0.4783\n",
      "Validation Loss: 0.6185\n",
      "Epoch [41/100], Loss: 0.4792\n",
      "Validation Loss: 0.6372\n",
      "Epoch [42/100], Loss: 0.4850\n",
      "Validation Loss: 0.6506\n",
      "Epoch [43/100], Loss: 0.4819\n",
      "Validation Loss: 0.6442\n",
      "Epoch [44/100], Loss: 0.4785\n",
      "Validation Loss: 0.6211\n",
      "Epoch [45/100], Loss: 0.4809\n",
      "Validation Loss: 0.6419\n",
      "Epoch [46/100], Loss: 0.4740\n",
      "Validation Loss: 0.6115\n",
      "Epoch [47/100], Loss: 0.4770\n",
      "Validation Loss: 0.5907\n",
      "Epoch [48/100], Loss: 0.4794\n",
      "Validation Loss: 0.6482\n",
      "Epoch [49/100], Loss: 0.4777\n",
      "Validation Loss: 0.6684\n",
      "Epoch [50/100], Loss: 0.4802\n",
      "Validation Loss: 0.6812\n",
      "Epoch [51/100], Loss: 0.4759\n",
      "Validation Loss: 0.6970\n",
      "Epoch [52/100], Loss: 0.4729\n",
      "Validation Loss: 0.6206\n",
      "Epoch [53/100], Loss: 0.4783\n",
      "Validation Loss: 0.7825\n",
      "Epoch [54/100], Loss: 0.4720\n",
      "Validation Loss: 0.6683\n",
      "Epoch [55/100], Loss: 0.4760\n",
      "Validation Loss: 0.6792\n",
      "Epoch [56/100], Loss: 0.4721\n",
      "Validation Loss: 0.6293\n",
      "Epoch [57/100], Loss: 0.4843\n",
      "Validation Loss: 0.5685\n",
      "Saved the best model with validation loss: 0.5685\n",
      "Epoch [58/100], Loss: 0.4767\n",
      "Validation Loss: 0.6453\n",
      "Epoch [59/100], Loss: 0.4732\n",
      "Validation Loss: 0.6315\n",
      "Epoch [60/100], Loss: 0.4816\n",
      "Validation Loss: 0.6582\n",
      "Epoch [61/100], Loss: 0.4726\n",
      "Validation Loss: 0.6638\n",
      "Epoch [62/100], Loss: 0.4739\n",
      "Validation Loss: 0.6134\n",
      "Epoch [63/100], Loss: 0.4746\n",
      "Validation Loss: 0.6321\n",
      "Epoch [64/100], Loss: 0.4689\n",
      "Validation Loss: 0.6377\n",
      "Epoch [65/100], Loss: 0.4751\n",
      "Validation Loss: 0.5953\n",
      "Epoch [66/100], Loss: 0.4759\n",
      "Validation Loss: 0.6278\n",
      "Epoch [67/100], Loss: 0.4632\n",
      "Validation Loss: 0.6798\n",
      "Epoch [68/100], Loss: 0.4694\n",
      "Validation Loss: 0.6492\n",
      "Epoch [69/100], Loss: 0.4768\n",
      "Validation Loss: 0.6666\n",
      "Epoch [70/100], Loss: 0.4657\n",
      "Validation Loss: 0.6718\n",
      "Epoch [71/100], Loss: 0.4758\n",
      "Validation Loss: 0.7107\n",
      "Epoch [72/100], Loss: 0.4686\n",
      "Validation Loss: 0.6734\n",
      "Epoch [73/100], Loss: 0.4688\n",
      "Validation Loss: 0.6095\n",
      "Epoch [74/100], Loss: 0.4606\n",
      "Validation Loss: 0.5980\n",
      "Epoch [75/100], Loss: 0.4670\n",
      "Validation Loss: 0.6303\n",
      "Epoch [76/100], Loss: 0.4646\n",
      "Validation Loss: 0.6447\n",
      "Epoch [77/100], Loss: 0.4661\n",
      "Validation Loss: 0.6752\n",
      "Epoch [78/100], Loss: 0.4712\n",
      "Validation Loss: 0.6094\n",
      "Epoch [79/100], Loss: 0.4722\n",
      "Validation Loss: 0.6316\n",
      "Epoch [80/100], Loss: 0.4788\n",
      "Validation Loss: 0.6286\n",
      "Epoch [81/100], Loss: 0.4675\n",
      "Validation Loss: 0.6577\n",
      "Epoch [82/100], Loss: 0.4716\n",
      "Validation Loss: 0.6686\n",
      "Epoch [83/100], Loss: 0.4693\n",
      "Validation Loss: 0.6667\n",
      "Epoch [84/100], Loss: 0.4725\n",
      "Validation Loss: 0.6482\n",
      "Epoch [85/100], Loss: 0.4724\n",
      "Validation Loss: 0.6870\n",
      "Epoch [86/100], Loss: 0.4710\n",
      "Validation Loss: 0.6808\n",
      "Epoch [87/100], Loss: 0.4696\n",
      "Validation Loss: 0.6715\n",
      "Epoch [88/100], Loss: 0.4623\n",
      "Validation Loss: 0.6718\n",
      "Epoch [89/100], Loss: 0.4673\n",
      "Validation Loss: 0.6969\n",
      "Epoch [90/100], Loss: 0.4726\n",
      "Validation Loss: 0.6332\n",
      "Epoch [91/100], Loss: 0.4547\n",
      "Validation Loss: 0.7112\n",
      "Epoch [92/100], Loss: 0.4658\n",
      "Validation Loss: 0.6921\n",
      "Epoch [93/100], Loss: 0.4689\n",
      "Validation Loss: 0.6772\n",
      "Epoch [94/100], Loss: 0.4647\n",
      "Validation Loss: 0.6272\n",
      "Epoch [95/100], Loss: 0.4637\n",
      "Validation Loss: 0.7285\n",
      "Epoch [96/100], Loss: 0.4693\n",
      "Validation Loss: 0.7072\n",
      "Epoch [97/100], Loss: 0.4617\n",
      "Validation Loss: 0.7352\n",
      "Epoch [98/100], Loss: 0.4782\n",
      "Validation Loss: 0.6976\n",
      "Epoch [99/100], Loss: 0.5080\n",
      "Validation Loss: 0.6815\n",
      "Epoch [100/100], Loss: 0.4601\n",
      "Validation Loss: 0.7228\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"combi 0.05: 17-80-50-10/1-16-32-10/20-40-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "b8882651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7331\n",
      "Validation Loss: 0.5406\n",
      "Saved the best model with validation loss: 0.5406\n",
      "Epoch [2/100], Loss: 0.5664\n",
      "Validation Loss: 0.5061\n",
      "Saved the best model with validation loss: 0.5061\n",
      "Epoch [3/100], Loss: 0.5332\n",
      "Validation Loss: 0.4944\n",
      "Saved the best model with validation loss: 0.4944\n",
      "Epoch [4/100], Loss: 0.5167\n",
      "Validation Loss: 0.4858\n",
      "Saved the best model with validation loss: 0.4858\n",
      "Epoch [5/100], Loss: 0.5064\n",
      "Validation Loss: 0.4720\n",
      "Saved the best model with validation loss: 0.4720\n",
      "Epoch [6/100], Loss: 0.4980\n",
      "Validation Loss: 0.4742\n",
      "Epoch [7/100], Loss: 0.4909\n",
      "Validation Loss: 0.4595\n",
      "Saved the best model with validation loss: 0.4595\n",
      "Epoch [8/100], Loss: 0.4861\n",
      "Validation Loss: 0.4675\n",
      "Epoch [9/100], Loss: 0.4791\n",
      "Validation Loss: 0.4518\n",
      "Saved the best model with validation loss: 0.4518\n",
      "Epoch [10/100], Loss: 0.4734\n",
      "Validation Loss: 0.4570\n",
      "Epoch [11/100], Loss: 0.4705\n",
      "Validation Loss: 0.4383\n",
      "Saved the best model with validation loss: 0.4383\n",
      "Epoch [12/100], Loss: 0.4672\n",
      "Validation Loss: 0.4423\n",
      "Epoch [13/100], Loss: 0.4662\n",
      "Validation Loss: 0.4534\n",
      "Epoch [14/100], Loss: 0.4633\n",
      "Validation Loss: 0.4661\n",
      "Epoch [15/100], Loss: 0.4626\n",
      "Validation Loss: 0.4430\n",
      "Epoch [16/100], Loss: 0.4594\n",
      "Validation Loss: 0.4410\n",
      "Epoch [17/100], Loss: 0.4558\n",
      "Validation Loss: 0.4303\n",
      "Saved the best model with validation loss: 0.4303\n",
      "Epoch [18/100], Loss: 0.4562\n",
      "Validation Loss: 0.4270\n",
      "Saved the best model with validation loss: 0.4270\n",
      "Epoch [19/100], Loss: 0.4499\n",
      "Validation Loss: 0.4356\n",
      "Epoch [20/100], Loss: 0.4477\n",
      "Validation Loss: 0.4181\n",
      "Saved the best model with validation loss: 0.4181\n",
      "Epoch [21/100], Loss: 0.4459\n",
      "Validation Loss: 0.4149\n",
      "Saved the best model with validation loss: 0.4149\n",
      "Epoch [22/100], Loss: 0.4416\n",
      "Validation Loss: 0.4104\n",
      "Saved the best model with validation loss: 0.4104\n",
      "Epoch [23/100], Loss: 0.4403\n",
      "Validation Loss: 0.4211\n",
      "Epoch [24/100], Loss: 0.4390\n",
      "Validation Loss: 0.4164\n",
      "Epoch [25/100], Loss: 0.4390\n",
      "Validation Loss: 0.4168\n",
      "Epoch [26/100], Loss: 0.4360\n",
      "Validation Loss: 0.4119\n",
      "Epoch [27/100], Loss: 0.4351\n",
      "Validation Loss: 0.4045\n",
      "Saved the best model with validation loss: 0.4045\n",
      "Epoch [28/100], Loss: 0.4312\n",
      "Validation Loss: 0.4214\n",
      "Epoch [29/100], Loss: 0.4269\n",
      "Validation Loss: 0.4269\n",
      "Epoch [30/100], Loss: 0.4310\n",
      "Validation Loss: 0.4133\n",
      "Epoch [31/100], Loss: 0.4233\n",
      "Validation Loss: 0.4072\n",
      "Epoch [32/100], Loss: 0.4257\n",
      "Validation Loss: 0.4078\n",
      "Epoch [33/100], Loss: 0.4195\n",
      "Validation Loss: 0.4259\n",
      "Epoch [34/100], Loss: 0.4207\n",
      "Validation Loss: 0.4010\n",
      "Saved the best model with validation loss: 0.4010\n",
      "Epoch [35/100], Loss: 0.4177\n",
      "Validation Loss: 0.3921\n",
      "Saved the best model with validation loss: 0.3921\n",
      "Epoch [36/100], Loss: 0.4218\n",
      "Validation Loss: 0.3965\n",
      "Epoch [37/100], Loss: 0.4165\n",
      "Validation Loss: 0.4339\n",
      "Epoch [38/100], Loss: 0.4194\n",
      "Validation Loss: 0.3973\n",
      "Epoch [39/100], Loss: 0.4159\n",
      "Validation Loss: 0.4044\n",
      "Epoch [40/100], Loss: 0.4135\n",
      "Validation Loss: 0.3973\n",
      "Epoch [41/100], Loss: 0.4151\n",
      "Validation Loss: 0.4006\n",
      "Epoch [42/100], Loss: 0.4150\n",
      "Validation Loss: 0.4065\n",
      "Epoch [43/100], Loss: 0.4133\n",
      "Validation Loss: 0.3933\n",
      "Epoch [44/100], Loss: 0.4129\n",
      "Validation Loss: 0.3938\n",
      "Epoch [45/100], Loss: 0.4039\n",
      "Validation Loss: 0.3840\n",
      "Saved the best model with validation loss: 0.3840\n",
      "Epoch [46/100], Loss: 0.4166\n",
      "Validation Loss: 0.3951\n",
      "Epoch [47/100], Loss: 0.4148\n",
      "Validation Loss: 0.4152\n",
      "Epoch [48/100], Loss: 0.4144\n",
      "Validation Loss: 0.3848\n",
      "Epoch [49/100], Loss: 0.4107\n",
      "Validation Loss: 0.3952\n",
      "Epoch [50/100], Loss: 0.4131\n",
      "Validation Loss: 0.3884\n",
      "Epoch [51/100], Loss: 0.4065\n",
      "Validation Loss: 0.4038\n",
      "Epoch [52/100], Loss: 0.4058\n",
      "Validation Loss: 0.3915\n",
      "Epoch [53/100], Loss: 0.4105\n",
      "Validation Loss: 0.3853\n",
      "Epoch [54/100], Loss: 0.4060\n",
      "Validation Loss: 0.4082\n",
      "Epoch [55/100], Loss: 0.4075\n",
      "Validation Loss: 0.4046\n",
      "Epoch [56/100], Loss: 0.4043\n",
      "Validation Loss: 0.4425\n",
      "Epoch [57/100], Loss: 0.4097\n",
      "Validation Loss: 0.3895\n",
      "Epoch [58/100], Loss: 0.4116\n",
      "Validation Loss: 0.3868\n",
      "Epoch [59/100], Loss: 0.3958\n",
      "Validation Loss: 0.3921\n",
      "Epoch [60/100], Loss: 0.4090\n",
      "Validation Loss: 0.4156\n",
      "Epoch [61/100], Loss: 0.4050\n",
      "Validation Loss: 0.4023\n",
      "Epoch [62/100], Loss: 0.4006\n",
      "Validation Loss: 0.4245\n",
      "Epoch [63/100], Loss: 0.4060\n",
      "Validation Loss: 0.4007\n",
      "Epoch [64/100], Loss: 0.4038\n",
      "Validation Loss: 0.4083\n",
      "Epoch [65/100], Loss: 0.4028\n",
      "Validation Loss: 0.4013\n",
      "Epoch [66/100], Loss: 0.4078\n",
      "Validation Loss: 0.3914\n",
      "Epoch [67/100], Loss: 0.4045\n",
      "Validation Loss: 0.3868\n",
      "Epoch [68/100], Loss: 0.4065\n",
      "Validation Loss: 0.4337\n",
      "Epoch [69/100], Loss: 0.4022\n",
      "Validation Loss: 0.4054\n",
      "Epoch [70/100], Loss: 0.4062\n",
      "Validation Loss: 0.4027\n",
      "Epoch [71/100], Loss: 0.4029\n",
      "Validation Loss: 0.3934\n",
      "Epoch [72/100], Loss: 0.4062\n",
      "Validation Loss: 0.4071\n",
      "Epoch [73/100], Loss: 0.4002\n",
      "Validation Loss: 0.4289\n",
      "Epoch [74/100], Loss: 0.4038\n",
      "Validation Loss: 0.4260\n",
      "Epoch [75/100], Loss: 0.3990\n",
      "Validation Loss: 0.4008\n",
      "Epoch [76/100], Loss: 0.3959\n",
      "Validation Loss: 0.3860\n",
      "Epoch [77/100], Loss: 0.4081\n",
      "Validation Loss: 0.4071\n",
      "Epoch [78/100], Loss: 0.3999\n",
      "Validation Loss: 0.3937\n",
      "Epoch [79/100], Loss: 0.3965\n",
      "Validation Loss: 0.3961\n",
      "Epoch [80/100], Loss: 0.3991\n",
      "Validation Loss: 0.3834\n",
      "Saved the best model with validation loss: 0.3834\n",
      "Epoch [81/100], Loss: 0.3956\n",
      "Validation Loss: 0.4538\n",
      "Epoch [82/100], Loss: 0.4022\n",
      "Validation Loss: 0.3842\n",
      "Epoch [83/100], Loss: 0.3943\n",
      "Validation Loss: 0.3904\n",
      "Epoch [84/100], Loss: 0.4060\n",
      "Validation Loss: 0.3981\n",
      "Epoch [85/100], Loss: 0.4105\n",
      "Validation Loss: 0.4223\n",
      "Epoch [86/100], Loss: 0.3995\n",
      "Validation Loss: 0.4034\n",
      "Epoch [87/100], Loss: 0.4006\n",
      "Validation Loss: 0.3924\n",
      "Epoch [88/100], Loss: 0.4047\n",
      "Validation Loss: 0.4303\n",
      "Epoch [89/100], Loss: 0.4014\n",
      "Validation Loss: 0.3962\n",
      "Epoch [90/100], Loss: 0.4070\n",
      "Validation Loss: 0.4148\n",
      "Epoch [91/100], Loss: 0.4035\n",
      "Validation Loss: 0.3947\n",
      "Epoch [92/100], Loss: 0.4002\n",
      "Validation Loss: 0.4181\n",
      "Epoch [93/100], Loss: 0.4143\n",
      "Validation Loss: 0.4071\n",
      "Epoch [94/100], Loss: 0.3994\n",
      "Validation Loss: 0.3911\n",
      "Epoch [95/100], Loss: 0.3961\n",
      "Validation Loss: 0.3901\n",
      "Epoch [96/100], Loss: 0.3991\n",
      "Validation Loss: 0.4002\n",
      "Epoch [97/100], Loss: 0.4074\n",
      "Validation Loss: 0.4048\n",
      "Epoch [98/100], Loss: 0.3983\n",
      "Validation Loss: 0.4074\n",
      "Epoch [99/100], Loss: 0.4072\n",
      "Validation Loss: 0.3961\n",
      "Epoch [100/100], Loss: 0.4108\n",
      "Validation Loss: 0.4141\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"combi 0.01: 17-80-50-10/1-16-32-10/20-40-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca99a07",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 5, equal cut-off: 0.5, 0.1, 0.05, 0.01\n",
    "*  MLP 17-80-50-10\n",
    "*  HGNN 1-16-32-10\n",
    "*  Combined 20-60-20-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "06788c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "73b91d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.8453\n",
      "Validation Loss: 0.7056\n",
      "Saved the best model with validation loss: 0.7056\n",
      "Epoch [2/100], Loss: 0.6209\n",
      "Validation Loss: 0.5008\n",
      "Saved the best model with validation loss: 0.5008\n",
      "Epoch [3/100], Loss: 0.5663\n",
      "Validation Loss: 0.4573\n",
      "Saved the best model with validation loss: 0.4573\n",
      "Epoch [4/100], Loss: 0.5449\n",
      "Validation Loss: 0.4412\n",
      "Saved the best model with validation loss: 0.4412\n",
      "Epoch [5/100], Loss: 0.5260\n",
      "Validation Loss: 0.4285\n",
      "Saved the best model with validation loss: 0.4285\n",
      "Epoch [6/100], Loss: 0.5086\n",
      "Validation Loss: 0.4157\n",
      "Saved the best model with validation loss: 0.4157\n",
      "Epoch [7/100], Loss: 0.4961\n",
      "Validation Loss: 0.4057\n",
      "Saved the best model with validation loss: 0.4057\n",
      "Epoch [8/100], Loss: 0.4834\n",
      "Validation Loss: 0.4033\n",
      "Saved the best model with validation loss: 0.4033\n",
      "Epoch [9/100], Loss: 0.4704\n",
      "Validation Loss: 0.3955\n",
      "Saved the best model with validation loss: 0.3955\n",
      "Epoch [10/100], Loss: 0.4614\n",
      "Validation Loss: 0.3858\n",
      "Saved the best model with validation loss: 0.3858\n",
      "Epoch [11/100], Loss: 0.4536\n",
      "Validation Loss: 0.3836\n",
      "Saved the best model with validation loss: 0.3836\n",
      "Epoch [12/100], Loss: 0.4487\n",
      "Validation Loss: 0.3790\n",
      "Saved the best model with validation loss: 0.3790\n",
      "Epoch [13/100], Loss: 0.4405\n",
      "Validation Loss: 0.3809\n",
      "Epoch [14/100], Loss: 0.4374\n",
      "Validation Loss: 0.3858\n",
      "Epoch [15/100], Loss: 0.4336\n",
      "Validation Loss: 0.3810\n",
      "Epoch [16/100], Loss: 0.4300\n",
      "Validation Loss: 0.3733\n",
      "Saved the best model with validation loss: 0.3733\n",
      "Epoch [17/100], Loss: 0.4265\n",
      "Validation Loss: 0.3950\n",
      "Epoch [18/100], Loss: 0.4285\n",
      "Validation Loss: 0.3836\n",
      "Epoch [19/100], Loss: 0.4226\n",
      "Validation Loss: 0.3829\n",
      "Epoch [20/100], Loss: 0.4231\n",
      "Validation Loss: 0.3637\n",
      "Saved the best model with validation loss: 0.3637\n",
      "Epoch [21/100], Loss: 0.4162\n",
      "Validation Loss: 0.3896\n",
      "Epoch [22/100], Loss: 0.4206\n",
      "Validation Loss: 0.3718\n",
      "Epoch [23/100], Loss: 0.4153\n",
      "Validation Loss: 0.3710\n",
      "Epoch [24/100], Loss: 0.4114\n",
      "Validation Loss: 0.3641\n",
      "Epoch [25/100], Loss: 0.4001\n",
      "Validation Loss: 0.3712\n",
      "Epoch [26/100], Loss: 0.3987\n",
      "Validation Loss: 0.3632\n",
      "Saved the best model with validation loss: 0.3632\n",
      "Epoch [27/100], Loss: 0.3952\n",
      "Validation Loss: 0.3572\n",
      "Saved the best model with validation loss: 0.3572\n",
      "Epoch [28/100], Loss: 0.4043\n",
      "Validation Loss: 0.3517\n",
      "Saved the best model with validation loss: 0.3517\n",
      "Epoch [29/100], Loss: 0.3935\n",
      "Validation Loss: 0.3484\n",
      "Saved the best model with validation loss: 0.3484\n",
      "Epoch [30/100], Loss: 0.3938\n",
      "Validation Loss: 0.3644\n",
      "Epoch [31/100], Loss: 0.3877\n",
      "Validation Loss: 0.3502\n",
      "Epoch [32/100], Loss: 0.3864\n",
      "Validation Loss: 0.3510\n",
      "Epoch [33/100], Loss: 0.3814\n",
      "Validation Loss: 0.3534\n",
      "Epoch [34/100], Loss: 0.3885\n",
      "Validation Loss: 0.3446\n",
      "Saved the best model with validation loss: 0.3446\n",
      "Epoch [35/100], Loss: 0.3760\n",
      "Validation Loss: 0.3484\n",
      "Epoch [36/100], Loss: 0.3787\n",
      "Validation Loss: 0.3536\n",
      "Epoch [37/100], Loss: 0.3739\n",
      "Validation Loss: 0.3775\n",
      "Epoch [38/100], Loss: 0.3812\n",
      "Validation Loss: 0.3555\n",
      "Epoch [39/100], Loss: 0.3898\n",
      "Validation Loss: 0.4420\n",
      "Epoch [40/100], Loss: 0.3752\n",
      "Validation Loss: 0.3374\n",
      "Saved the best model with validation loss: 0.3374\n",
      "Epoch [41/100], Loss: 0.3656\n",
      "Validation Loss: 0.3759\n",
      "Epoch [42/100], Loss: 0.3701\n",
      "Validation Loss: 0.3457\n",
      "Epoch [43/100], Loss: 0.3697\n",
      "Validation Loss: 0.3934\n",
      "Epoch [44/100], Loss: 0.3620\n",
      "Validation Loss: 0.3850\n",
      "Epoch [45/100], Loss: 0.3710\n",
      "Validation Loss: 0.3531\n",
      "Epoch [46/100], Loss: 0.3698\n",
      "Validation Loss: 0.3403\n",
      "Epoch [47/100], Loss: 0.3600\n",
      "Validation Loss: 0.3616\n",
      "Epoch [48/100], Loss: 0.3694\n",
      "Validation Loss: 0.4386\n",
      "Epoch [49/100], Loss: 0.3711\n",
      "Validation Loss: 0.3597\n",
      "Epoch [50/100], Loss: 0.3635\n",
      "Validation Loss: 0.4337\n",
      "Epoch [51/100], Loss: 0.3630\n",
      "Validation Loss: 0.3223\n",
      "Saved the best model with validation loss: 0.3223\n",
      "Epoch [52/100], Loss: 0.3511\n",
      "Validation Loss: 0.3897\n",
      "Epoch [53/100], Loss: 0.3644\n",
      "Validation Loss: 0.3328\n",
      "Epoch [54/100], Loss: 0.3555\n",
      "Validation Loss: 0.3329\n",
      "Epoch [55/100], Loss: 0.3592\n",
      "Validation Loss: 0.3276\n",
      "Epoch [56/100], Loss: 0.3606\n",
      "Validation Loss: 0.3336\n",
      "Epoch [57/100], Loss: 0.3549\n",
      "Validation Loss: 0.3199\n",
      "Saved the best model with validation loss: 0.3199\n",
      "Epoch [58/100], Loss: 0.3595\n",
      "Validation Loss: 0.3428\n",
      "Epoch [59/100], Loss: 0.3552\n",
      "Validation Loss: 0.4382\n",
      "Epoch [60/100], Loss: 0.3593\n",
      "Validation Loss: 0.3944\n",
      "Epoch [61/100], Loss: 0.3583\n",
      "Validation Loss: 0.3102\n",
      "Saved the best model with validation loss: 0.3102\n",
      "Epoch [62/100], Loss: 0.3590\n",
      "Validation Loss: 0.3187\n",
      "Epoch [63/100], Loss: 0.3529\n",
      "Validation Loss: 0.3443\n",
      "Epoch [64/100], Loss: 0.3472\n",
      "Validation Loss: 0.3593\n",
      "Epoch [65/100], Loss: 0.3655\n",
      "Validation Loss: 0.4109\n",
      "Epoch [66/100], Loss: 0.3587\n",
      "Validation Loss: 0.3484\n",
      "Epoch [67/100], Loss: 0.3602\n",
      "Validation Loss: 0.3452\n",
      "Epoch [68/100], Loss: 0.3476\n",
      "Validation Loss: 0.3579\n",
      "Epoch [69/100], Loss: 0.3550\n",
      "Validation Loss: 0.4138\n",
      "Epoch [70/100], Loss: 0.3531\n",
      "Validation Loss: 0.3494\n",
      "Epoch [71/100], Loss: 0.3558\n",
      "Validation Loss: 0.3631\n",
      "Epoch [72/100], Loss: 0.3490\n",
      "Validation Loss: 0.3517\n",
      "Epoch [73/100], Loss: 0.3628\n",
      "Validation Loss: 0.3312\n",
      "Epoch [74/100], Loss: 0.3512\n",
      "Validation Loss: 0.3558\n",
      "Epoch [75/100], Loss: 0.3439\n",
      "Validation Loss: 0.4492\n",
      "Epoch [76/100], Loss: 0.3596\n",
      "Validation Loss: 0.3337\n",
      "Epoch [77/100], Loss: 0.3427\n",
      "Validation Loss: 0.3363\n",
      "Epoch [78/100], Loss: 0.3502\n",
      "Validation Loss: 0.3663\n",
      "Epoch [79/100], Loss: 0.3535\n",
      "Validation Loss: 0.3330\n",
      "Epoch [80/100], Loss: 0.3559\n",
      "Validation Loss: 0.3298\n",
      "Epoch [81/100], Loss: 0.3422\n",
      "Validation Loss: 0.3475\n",
      "Epoch [82/100], Loss: 0.3615\n",
      "Validation Loss: 0.3346\n",
      "Epoch [83/100], Loss: 0.3441\n",
      "Validation Loss: 0.4685\n",
      "Epoch [84/100], Loss: 0.3578\n",
      "Validation Loss: 0.4060\n",
      "Epoch [85/100], Loss: 0.3533\n",
      "Validation Loss: 0.3621\n",
      "Epoch [86/100], Loss: 0.3511\n",
      "Validation Loss: 0.4407\n",
      "Epoch [87/100], Loss: 0.3424\n",
      "Validation Loss: 0.3699\n",
      "Epoch [88/100], Loss: 0.3485\n",
      "Validation Loss: 0.3250\n",
      "Epoch [89/100], Loss: 0.3633\n",
      "Validation Loss: 0.3245\n",
      "Epoch [90/100], Loss: 0.3375\n",
      "Validation Loss: 0.3213\n",
      "Epoch [91/100], Loss: 0.3477\n",
      "Validation Loss: 0.3223\n",
      "Epoch [92/100], Loss: 0.3413\n",
      "Validation Loss: 0.3246\n",
      "Epoch [93/100], Loss: 0.3455\n",
      "Validation Loss: 0.3315\n",
      "Epoch [94/100], Loss: 0.3515\n",
      "Validation Loss: 0.3695\n",
      "Epoch [95/100], Loss: 0.3377\n",
      "Validation Loss: 0.3566\n",
      "Epoch [96/100], Loss: 0.3466\n",
      "Validation Loss: 0.3532\n",
      "Epoch [97/100], Loss: 0.3417\n",
      "Validation Loss: 0.6899\n",
      "Epoch [98/100], Loss: 0.3424\n",
      "Validation Loss: 0.3513\n",
      "Epoch [99/100], Loss: 0.3483\n",
      "Validation Loss: 0.3553\n",
      "Epoch [100/100], Loss: 0.3616\n",
      "Validation Loss: 0.3643\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_05_train_mlp, X_val_hg, y1_equal_05_val_mlp, \"3_class\", \"combi 0.5: 17-80-50-10/1-16-32-10/20-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "00679a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.9779\n",
      "Validation Loss: 0.8415\n",
      "Saved the best model with validation loss: 0.8415\n",
      "Epoch [2/100], Loss: 0.7608\n",
      "Validation Loss: 0.7586\n",
      "Saved the best model with validation loss: 0.7586\n",
      "Epoch [3/100], Loss: 0.7148\n",
      "Validation Loss: 0.7323\n",
      "Saved the best model with validation loss: 0.7323\n",
      "Epoch [4/100], Loss: 0.6833\n",
      "Validation Loss: 0.7044\n",
      "Saved the best model with validation loss: 0.7044\n",
      "Epoch [5/100], Loss: 0.6576\n",
      "Validation Loss: 0.6856\n",
      "Saved the best model with validation loss: 0.6856\n",
      "Epoch [6/100], Loss: 0.6415\n",
      "Validation Loss: 0.6742\n",
      "Saved the best model with validation loss: 0.6742\n",
      "Epoch [7/100], Loss: 0.6303\n",
      "Validation Loss: 0.6687\n",
      "Saved the best model with validation loss: 0.6687\n",
      "Epoch [8/100], Loss: 0.6232\n",
      "Validation Loss: 0.6549\n",
      "Saved the best model with validation loss: 0.6549\n",
      "Epoch [9/100], Loss: 0.6118\n",
      "Validation Loss: 0.6648\n",
      "Epoch [10/100], Loss: 0.6059\n",
      "Validation Loss: 0.6650\n",
      "Epoch [11/100], Loss: 0.6063\n",
      "Validation Loss: 0.6527\n",
      "Saved the best model with validation loss: 0.6527\n",
      "Epoch [12/100], Loss: 0.5913\n",
      "Validation Loss: 0.6534\n",
      "Epoch [13/100], Loss: 0.5885\n",
      "Validation Loss: 0.6479\n",
      "Saved the best model with validation loss: 0.6479\n",
      "Epoch [14/100], Loss: 0.5796\n",
      "Validation Loss: 0.6530\n",
      "Epoch [15/100], Loss: 0.5790\n",
      "Validation Loss: 0.6442\n",
      "Saved the best model with validation loss: 0.6442\n",
      "Epoch [16/100], Loss: 0.5665\n",
      "Validation Loss: 0.6514\n",
      "Epoch [17/100], Loss: 0.5672\n",
      "Validation Loss: 0.6492\n",
      "Epoch [18/100], Loss: 0.5598\n",
      "Validation Loss: 0.6588\n",
      "Epoch [19/100], Loss: 0.5567\n",
      "Validation Loss: 0.6648\n",
      "Epoch [20/100], Loss: 0.5593\n",
      "Validation Loss: 0.6373\n",
      "Saved the best model with validation loss: 0.6373\n",
      "Epoch [21/100], Loss: 0.5530\n",
      "Validation Loss: 0.6199\n",
      "Saved the best model with validation loss: 0.6199\n",
      "Epoch [22/100], Loss: 0.5534\n",
      "Validation Loss: 0.6227\n",
      "Epoch [23/100], Loss: 0.5485\n",
      "Validation Loss: 0.6382\n",
      "Epoch [24/100], Loss: 0.5539\n",
      "Validation Loss: 0.6519\n",
      "Epoch [25/100], Loss: 0.5433\n",
      "Validation Loss: 0.6707\n",
      "Epoch [26/100], Loss: 0.5456\n",
      "Validation Loss: 0.6573\n",
      "Epoch [27/100], Loss: 0.5404\n",
      "Validation Loss: 0.6427\n",
      "Epoch [28/100], Loss: 0.5356\n",
      "Validation Loss: 0.6241\n",
      "Epoch [29/100], Loss: 0.5352\n",
      "Validation Loss: 0.6553\n",
      "Epoch [30/100], Loss: 0.5334\n",
      "Validation Loss: 0.6420\n",
      "Epoch [31/100], Loss: 0.5312\n",
      "Validation Loss: 0.6305\n",
      "Epoch [32/100], Loss: 0.5347\n",
      "Validation Loss: 0.6385\n",
      "Epoch [33/100], Loss: 0.5308\n",
      "Validation Loss: 0.7310\n",
      "Epoch [34/100], Loss: 0.5249\n",
      "Validation Loss: 0.6640\n",
      "Epoch [35/100], Loss: 0.5231\n",
      "Validation Loss: 0.6736\n",
      "Epoch [36/100], Loss: 0.5223\n",
      "Validation Loss: 0.6823\n",
      "Epoch [37/100], Loss: 0.5233\n",
      "Validation Loss: 0.6649\n",
      "Epoch [38/100], Loss: 0.5404\n",
      "Validation Loss: 0.6294\n",
      "Epoch [39/100], Loss: 0.5134\n",
      "Validation Loss: 0.6504\n",
      "Epoch [40/100], Loss: 0.5103\n",
      "Validation Loss: 0.6522\n",
      "Epoch [41/100], Loss: 0.5095\n",
      "Validation Loss: 0.6646\n",
      "Epoch [42/100], Loss: 0.5144\n",
      "Validation Loss: 0.6424\n",
      "Epoch [43/100], Loss: 0.5041\n",
      "Validation Loss: 0.6687\n",
      "Epoch [44/100], Loss: 0.5151\n",
      "Validation Loss: 0.6542\n",
      "Epoch [45/100], Loss: 0.5064\n",
      "Validation Loss: 0.7083\n",
      "Epoch [46/100], Loss: 0.5085\n",
      "Validation Loss: 0.7009\n",
      "Epoch [47/100], Loss: 0.5144\n",
      "Validation Loss: 0.6974\n",
      "Epoch [48/100], Loss: 0.5103\n",
      "Validation Loss: 0.6422\n",
      "Epoch [49/100], Loss: 0.5040\n",
      "Validation Loss: 0.6773\n",
      "Epoch [50/100], Loss: 0.5179\n",
      "Validation Loss: 0.6826\n",
      "Epoch [51/100], Loss: 0.5078\n",
      "Validation Loss: 0.7500\n",
      "Epoch [52/100], Loss: 0.5116\n",
      "Validation Loss: 0.6379\n",
      "Epoch [53/100], Loss: 0.5153\n",
      "Validation Loss: 0.7969\n",
      "Epoch [54/100], Loss: 0.5062\n",
      "Validation Loss: 0.7006\n",
      "Epoch [55/100], Loss: 0.5264\n",
      "Validation Loss: 0.6430\n",
      "Epoch [56/100], Loss: 0.5095\n",
      "Validation Loss: 0.7273\n",
      "Epoch [57/100], Loss: 0.5117\n",
      "Validation Loss: 0.7431\n",
      "Epoch [58/100], Loss: 0.5002\n",
      "Validation Loss: 0.7449\n",
      "Epoch [59/100], Loss: 0.5232\n",
      "Validation Loss: 0.7307\n",
      "Epoch [60/100], Loss: 0.5135\n",
      "Validation Loss: 0.6689\n",
      "Epoch [61/100], Loss: 0.5102\n",
      "Validation Loss: 0.6763\n",
      "Epoch [62/100], Loss: 0.4973\n",
      "Validation Loss: 0.8498\n",
      "Epoch [63/100], Loss: 0.5085\n",
      "Validation Loss: 0.8280\n",
      "Epoch [64/100], Loss: 0.5088\n",
      "Validation Loss: 0.7995\n",
      "Epoch [65/100], Loss: 0.5174\n",
      "Validation Loss: 0.6434\n",
      "Epoch [66/100], Loss: 0.5106\n",
      "Validation Loss: 0.6538\n",
      "Epoch [67/100], Loss: 0.5171\n",
      "Validation Loss: 0.7891\n",
      "Epoch [68/100], Loss: 0.5083\n",
      "Validation Loss: 0.8396\n",
      "Epoch [69/100], Loss: 0.5085\n",
      "Validation Loss: 0.7848\n",
      "Epoch [70/100], Loss: 0.5159\n",
      "Validation Loss: 0.9130\n",
      "Epoch [71/100], Loss: 0.5099\n",
      "Validation Loss: 0.8758\n",
      "Epoch [72/100], Loss: 0.4964\n",
      "Validation Loss: 0.8506\n",
      "Epoch [73/100], Loss: 0.5096\n",
      "Validation Loss: 0.8013\n",
      "Epoch [74/100], Loss: 0.4990\n",
      "Validation Loss: 0.7598\n",
      "Epoch [75/100], Loss: 0.5102\n",
      "Validation Loss: 0.7571\n",
      "Epoch [76/100], Loss: 0.5024\n",
      "Validation Loss: 0.9731\n",
      "Epoch [77/100], Loss: 0.5015\n",
      "Validation Loss: 0.7900\n",
      "Epoch [78/100], Loss: 0.5109\n",
      "Validation Loss: 0.7164\n",
      "Epoch [79/100], Loss: 0.5091\n",
      "Validation Loss: 0.8085\n",
      "Epoch [80/100], Loss: 0.5042\n",
      "Validation Loss: 0.9189\n",
      "Epoch [81/100], Loss: 0.5159\n",
      "Validation Loss: 0.7539\n",
      "Epoch [82/100], Loss: 0.4990\n",
      "Validation Loss: 0.8580\n",
      "Epoch [83/100], Loss: 0.5155\n",
      "Validation Loss: 0.7423\n",
      "Epoch [84/100], Loss: 0.4983\n",
      "Validation Loss: 0.7408\n",
      "Epoch [85/100], Loss: 0.5073\n",
      "Validation Loss: 0.8311\n",
      "Epoch [86/100], Loss: 0.5104\n",
      "Validation Loss: 1.1231\n",
      "Epoch [87/100], Loss: 0.5110\n",
      "Validation Loss: 0.7455\n",
      "Epoch [88/100], Loss: 0.5018\n",
      "Validation Loss: 0.8544\n",
      "Epoch [89/100], Loss: 0.5006\n",
      "Validation Loss: 0.7581\n",
      "Epoch [90/100], Loss: 0.5051\n",
      "Validation Loss: 0.6385\n",
      "Epoch [91/100], Loss: 0.4969\n",
      "Validation Loss: 0.8240\n",
      "Epoch [92/100], Loss: 0.5008\n",
      "Validation Loss: 0.7188\n",
      "Epoch [93/100], Loss: 0.5001\n",
      "Validation Loss: 0.8047\n",
      "Epoch [94/100], Loss: 0.4845\n",
      "Validation Loss: 0.7471\n",
      "Epoch [95/100], Loss: 0.4951\n",
      "Validation Loss: 0.6820\n",
      "Epoch [96/100], Loss: 0.4854\n",
      "Validation Loss: 0.7109\n",
      "Epoch [97/100], Loss: 0.5007\n",
      "Validation Loss: 0.6997\n",
      "Epoch [98/100], Loss: 0.4928\n",
      "Validation Loss: 0.7051\n",
      "Epoch [99/100], Loss: 0.4929\n",
      "Validation Loss: 0.6878\n",
      "Epoch [100/100], Loss: 0.4948\n",
      "Validation Loss: 0.7277\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_01_train_mlp, X_val_hg, y1_equal_01_val_mlp, \"3_class\", \"combi 0.1: 17-80-50-10/1-16-32-10/20-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "9cd9386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.9323\n",
      "Validation Loss: 0.7489\n",
      "Saved the best model with validation loss: 0.7489\n",
      "Epoch [2/100], Loss: 0.7278\n",
      "Validation Loss: 0.7042\n",
      "Saved the best model with validation loss: 0.7042\n",
      "Epoch [3/100], Loss: 0.6817\n",
      "Validation Loss: 0.7010\n",
      "Saved the best model with validation loss: 0.7010\n",
      "Epoch [4/100], Loss: 0.6548\n",
      "Validation Loss: 0.6835\n",
      "Saved the best model with validation loss: 0.6835\n",
      "Epoch [5/100], Loss: 0.6391\n",
      "Validation Loss: 0.6564\n",
      "Saved the best model with validation loss: 0.6564\n",
      "Epoch [6/100], Loss: 0.6244\n",
      "Validation Loss: 0.6495\n",
      "Saved the best model with validation loss: 0.6495\n",
      "Epoch [7/100], Loss: 0.6130\n",
      "Validation Loss: 0.6358\n",
      "Saved the best model with validation loss: 0.6358\n",
      "Epoch [8/100], Loss: 0.5996\n",
      "Validation Loss: 0.6466\n",
      "Epoch [9/100], Loss: 0.5870\n",
      "Validation Loss: 0.6529\n",
      "Epoch [10/100], Loss: 0.5782\n",
      "Validation Loss: 0.6417\n",
      "Epoch [11/100], Loss: 0.5687\n",
      "Validation Loss: 0.6314\n",
      "Saved the best model with validation loss: 0.6314\n",
      "Epoch [12/100], Loss: 0.5615\n",
      "Validation Loss: 0.6209\n",
      "Saved the best model with validation loss: 0.6209\n",
      "Epoch [13/100], Loss: 0.5589\n",
      "Validation Loss: 0.6343\n",
      "Epoch [14/100], Loss: 0.5506\n",
      "Validation Loss: 0.6357\n",
      "Epoch [15/100], Loss: 0.5399\n",
      "Validation Loss: 0.6146\n",
      "Saved the best model with validation loss: 0.6146\n",
      "Epoch [16/100], Loss: 0.5402\n",
      "Validation Loss: 0.5956\n",
      "Saved the best model with validation loss: 0.5956\n",
      "Epoch [17/100], Loss: 0.5352\n",
      "Validation Loss: 0.6480\n",
      "Epoch [18/100], Loss: 0.5302\n",
      "Validation Loss: 0.6017\n",
      "Epoch [19/100], Loss: 0.5305\n",
      "Validation Loss: 0.6034\n",
      "Epoch [20/100], Loss: 0.5278\n",
      "Validation Loss: 0.6261\n",
      "Epoch [21/100], Loss: 0.5192\n",
      "Validation Loss: 0.6121\n",
      "Epoch [22/100], Loss: 0.5138\n",
      "Validation Loss: 0.6123\n",
      "Epoch [23/100], Loss: 0.5128\n",
      "Validation Loss: 0.6130\n",
      "Epoch [24/100], Loss: 0.5121\n",
      "Validation Loss: 0.6433\n",
      "Epoch [25/100], Loss: 0.5083\n",
      "Validation Loss: 0.6514\n",
      "Epoch [26/100], Loss: 0.5075\n",
      "Validation Loss: 0.6466\n",
      "Epoch [27/100], Loss: 0.5040\n",
      "Validation Loss: 0.6363\n",
      "Epoch [28/100], Loss: 0.5100\n",
      "Validation Loss: 0.6420\n",
      "Epoch [29/100], Loss: 0.5053\n",
      "Validation Loss: 0.6555\n",
      "Epoch [30/100], Loss: 0.5101\n",
      "Validation Loss: 0.6670\n",
      "Epoch [31/100], Loss: 0.5070\n",
      "Validation Loss: 0.5833\n",
      "Saved the best model with validation loss: 0.5833\n",
      "Epoch [32/100], Loss: 0.5039\n",
      "Validation Loss: 0.6137\n",
      "Epoch [33/100], Loss: 0.4995\n",
      "Validation Loss: 0.6247\n",
      "Epoch [34/100], Loss: 0.5006\n",
      "Validation Loss: 0.6308\n",
      "Epoch [35/100], Loss: 0.4967\n",
      "Validation Loss: 0.6371\n",
      "Epoch [36/100], Loss: 0.4958\n",
      "Validation Loss: 0.6744\n",
      "Epoch [37/100], Loss: 0.4927\n",
      "Validation Loss: 0.7147\n",
      "Epoch [38/100], Loss: 0.5016\n",
      "Validation Loss: 0.7046\n",
      "Epoch [39/100], Loss: 0.4906\n",
      "Validation Loss: 0.7070\n",
      "Epoch [40/100], Loss: 0.4957\n",
      "Validation Loss: 0.6819\n",
      "Epoch [41/100], Loss: 0.4894\n",
      "Validation Loss: 0.7366\n",
      "Epoch [42/100], Loss: 0.4926\n",
      "Validation Loss: 0.7557\n",
      "Epoch [43/100], Loss: 0.4867\n",
      "Validation Loss: 0.6385\n",
      "Epoch [44/100], Loss: 0.4843\n",
      "Validation Loss: 0.7060\n",
      "Epoch [45/100], Loss: 0.4831\n",
      "Validation Loss: 0.7075\n",
      "Epoch [46/100], Loss: 0.4776\n",
      "Validation Loss: 0.7938\n",
      "Epoch [47/100], Loss: 0.4754\n",
      "Validation Loss: 0.7324\n",
      "Epoch [48/100], Loss: 0.4805\n",
      "Validation Loss: 0.6716\n",
      "Epoch [49/100], Loss: 0.4914\n",
      "Validation Loss: 0.6938\n",
      "Epoch [50/100], Loss: 0.4833\n",
      "Validation Loss: 0.6771\n",
      "Epoch [51/100], Loss: 0.4909\n",
      "Validation Loss: 0.6112\n",
      "Epoch [52/100], Loss: 0.4767\n",
      "Validation Loss: 0.7942\n",
      "Epoch [53/100], Loss: 0.5062\n",
      "Validation Loss: 0.6060\n",
      "Epoch [54/100], Loss: 0.4887\n",
      "Validation Loss: 0.6378\n",
      "Epoch [55/100], Loss: 0.4856\n",
      "Validation Loss: 0.6171\n",
      "Epoch [56/100], Loss: 0.4877\n",
      "Validation Loss: 0.6341\n",
      "Epoch [57/100], Loss: 0.4933\n",
      "Validation Loss: 0.6441\n",
      "Epoch [58/100], Loss: 0.4827\n",
      "Validation Loss: 0.7356\n",
      "Epoch [59/100], Loss: 0.4882\n",
      "Validation Loss: 0.5743\n",
      "Saved the best model with validation loss: 0.5743\n",
      "Epoch [60/100], Loss: 0.4800\n",
      "Validation Loss: 0.5485\n",
      "Saved the best model with validation loss: 0.5485\n",
      "Epoch [61/100], Loss: 0.4874\n",
      "Validation Loss: 0.6665\n",
      "Epoch [62/100], Loss: 0.4880\n",
      "Validation Loss: 0.6490\n",
      "Epoch [63/100], Loss: 0.4787\n",
      "Validation Loss: 0.6141\n",
      "Epoch [64/100], Loss: 0.4763\n",
      "Validation Loss: 0.6100\n",
      "Epoch [65/100], Loss: 0.4846\n",
      "Validation Loss: 0.6473\n",
      "Epoch [66/100], Loss: 0.4933\n",
      "Validation Loss: 0.6722\n",
      "Epoch [67/100], Loss: 0.4783\n",
      "Validation Loss: 0.7054\n",
      "Epoch [68/100], Loss: 0.4833\n",
      "Validation Loss: 0.6400\n",
      "Epoch [69/100], Loss: 0.4763\n",
      "Validation Loss: 0.6807\n",
      "Epoch [70/100], Loss: 0.4858\n",
      "Validation Loss: 0.6404\n",
      "Epoch [71/100], Loss: 0.4817\n",
      "Validation Loss: 0.6597\n",
      "Epoch [72/100], Loss: 0.4712\n",
      "Validation Loss: 0.6559\n",
      "Epoch [73/100], Loss: 0.4733\n",
      "Validation Loss: 0.6480\n",
      "Epoch [74/100], Loss: 0.4718\n",
      "Validation Loss: 0.6406\n",
      "Epoch [75/100], Loss: 0.4775\n",
      "Validation Loss: 0.6450\n",
      "Epoch [76/100], Loss: 0.4777\n",
      "Validation Loss: 0.6608\n",
      "Epoch [77/100], Loss: 0.4698\n",
      "Validation Loss: 0.7124\n",
      "Epoch [78/100], Loss: 0.4689\n",
      "Validation Loss: 0.6899\n",
      "Epoch [79/100], Loss: 0.4801\n",
      "Validation Loss: 0.6162\n",
      "Epoch [80/100], Loss: 0.4682\n",
      "Validation Loss: 0.6214\n",
      "Epoch [81/100], Loss: 0.4739\n",
      "Validation Loss: 0.6011\n",
      "Epoch [82/100], Loss: 0.4815\n",
      "Validation Loss: 0.5525\n",
      "Epoch [83/100], Loss: 0.4794\n",
      "Validation Loss: 0.5933\n",
      "Epoch [84/100], Loss: 0.4665\n",
      "Validation Loss: 0.6348\n",
      "Epoch [85/100], Loss: 0.4634\n",
      "Validation Loss: 0.6424\n",
      "Epoch [86/100], Loss: 0.4961\n",
      "Validation Loss: 0.6230\n",
      "Epoch [87/100], Loss: 0.4664\n",
      "Validation Loss: 0.5840\n",
      "Epoch [88/100], Loss: 0.4722\n",
      "Validation Loss: 0.6250\n",
      "Epoch [89/100], Loss: 0.4728\n",
      "Validation Loss: 0.5991\n",
      "Epoch [90/100], Loss: 0.4643\n",
      "Validation Loss: 0.6275\n",
      "Epoch [91/100], Loss: 0.4661\n",
      "Validation Loss: 0.6249\n",
      "Epoch [92/100], Loss: 0.4687\n",
      "Validation Loss: 0.6126\n",
      "Epoch [93/100], Loss: 0.4689\n",
      "Validation Loss: 0.5946\n",
      "Epoch [94/100], Loss: 0.4673\n",
      "Validation Loss: 0.6426\n",
      "Epoch [95/100], Loss: 0.4733\n",
      "Validation Loss: 0.6214\n",
      "Epoch [96/100], Loss: 0.4679\n",
      "Validation Loss: 0.5902\n",
      "Epoch [97/100], Loss: 0.4646\n",
      "Validation Loss: 0.7021\n",
      "Epoch [98/100], Loss: 0.4707\n",
      "Validation Loss: 0.6140\n",
      "Epoch [99/100], Loss: 0.4721\n",
      "Validation Loss: 0.5552\n",
      "Epoch [100/100], Loss: 0.4631\n",
      "Validation Loss: 0.8109\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_005_train_mlp, X_val_hg, y1_equal_005_val_mlp, \"3_class\", \"combi 0.05: 17-80-50-10/1-16-32-10/20-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "aa1702e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7717\n",
      "Validation Loss: 0.5500\n",
      "Saved the best model with validation loss: 0.5500\n",
      "Epoch [2/100], Loss: 0.5819\n",
      "Validation Loss: 0.5221\n",
      "Saved the best model with validation loss: 0.5221\n",
      "Epoch [3/100], Loss: 0.5456\n",
      "Validation Loss: 0.4863\n",
      "Saved the best model with validation loss: 0.4863\n",
      "Epoch [4/100], Loss: 0.5276\n",
      "Validation Loss: 0.4660\n",
      "Saved the best model with validation loss: 0.4660\n",
      "Epoch [5/100], Loss: 0.5129\n",
      "Validation Loss: 0.4573\n",
      "Saved the best model with validation loss: 0.4573\n",
      "Epoch [6/100], Loss: 0.5013\n",
      "Validation Loss: 0.4616\n",
      "Epoch [7/100], Loss: 0.4939\n",
      "Validation Loss: 0.4525\n",
      "Saved the best model with validation loss: 0.4525\n",
      "Epoch [8/100], Loss: 0.4867\n",
      "Validation Loss: 0.4437\n",
      "Saved the best model with validation loss: 0.4437\n",
      "Epoch [9/100], Loss: 0.4821\n",
      "Validation Loss: 0.4350\n",
      "Saved the best model with validation loss: 0.4350\n",
      "Epoch [10/100], Loss: 0.4757\n",
      "Validation Loss: 0.4395\n",
      "Epoch [11/100], Loss: 0.4735\n",
      "Validation Loss: 0.4399\n",
      "Epoch [12/100], Loss: 0.4693\n",
      "Validation Loss: 0.4245\n",
      "Saved the best model with validation loss: 0.4245\n",
      "Epoch [13/100], Loss: 0.4677\n",
      "Validation Loss: 0.4360\n",
      "Epoch [14/100], Loss: 0.4646\n",
      "Validation Loss: 0.4242\n",
      "Saved the best model with validation loss: 0.4242\n",
      "Epoch [15/100], Loss: 0.4627\n",
      "Validation Loss: 0.4604\n",
      "Epoch [16/100], Loss: 0.4578\n",
      "Validation Loss: 0.4522\n",
      "Epoch [17/100], Loss: 0.4548\n",
      "Validation Loss: 0.4167\n",
      "Saved the best model with validation loss: 0.4167\n",
      "Epoch [18/100], Loss: 0.4535\n",
      "Validation Loss: 0.4218\n",
      "Epoch [19/100], Loss: 0.4523\n",
      "Validation Loss: 0.4181\n",
      "Epoch [20/100], Loss: 0.4503\n",
      "Validation Loss: 0.4434\n",
      "Epoch [21/100], Loss: 0.4451\n",
      "Validation Loss: 0.4119\n",
      "Saved the best model with validation loss: 0.4119\n",
      "Epoch [22/100], Loss: 0.4411\n",
      "Validation Loss: 0.4421\n",
      "Epoch [23/100], Loss: 0.4478\n",
      "Validation Loss: 1.2692\n",
      "Epoch [24/100], Loss: 0.4461\n",
      "Validation Loss: 0.4191\n",
      "Epoch [25/100], Loss: 0.4345\n",
      "Validation Loss: 0.4079\n",
      "Saved the best model with validation loss: 0.4079\n",
      "Epoch [26/100], Loss: 0.4362\n",
      "Validation Loss: 0.4214\n",
      "Epoch [27/100], Loss: 0.4314\n",
      "Validation Loss: 0.4071\n",
      "Saved the best model with validation loss: 0.4071\n",
      "Epoch [28/100], Loss: 0.4325\n",
      "Validation Loss: 0.3928\n",
      "Saved the best model with validation loss: 0.3928\n",
      "Epoch [29/100], Loss: 0.4341\n",
      "Validation Loss: 0.4048\n",
      "Epoch [30/100], Loss: 0.4332\n",
      "Validation Loss: 0.4252\n",
      "Epoch [31/100], Loss: 0.4296\n",
      "Validation Loss: 0.4162\n",
      "Epoch [32/100], Loss: 0.4321\n",
      "Validation Loss: 0.4034\n",
      "Epoch [33/100], Loss: 0.4348\n",
      "Validation Loss: 0.4087\n",
      "Epoch [34/100], Loss: 0.4323\n",
      "Validation Loss: 0.4086\n",
      "Epoch [35/100], Loss: 0.4312\n",
      "Validation Loss: 0.4082\n",
      "Epoch [36/100], Loss: 0.4254\n",
      "Validation Loss: 0.4013\n",
      "Epoch [37/100], Loss: 0.4262\n",
      "Validation Loss: 0.4142\n",
      "Epoch [38/100], Loss: 0.4203\n",
      "Validation Loss: 0.4025\n",
      "Epoch [39/100], Loss: 0.4233\n",
      "Validation Loss: 0.4322\n",
      "Epoch [40/100], Loss: 0.4208\n",
      "Validation Loss: 0.4049\n",
      "Epoch [41/100], Loss: 0.4171\n",
      "Validation Loss: 0.4033\n",
      "Epoch [42/100], Loss: 0.4196\n",
      "Validation Loss: 0.4233\n",
      "Epoch [43/100], Loss: 0.4199\n",
      "Validation Loss: 0.4211\n",
      "Epoch [44/100], Loss: 0.4116\n",
      "Validation Loss: 0.4158\n",
      "Epoch [45/100], Loss: 0.4214\n",
      "Validation Loss: 0.4131\n",
      "Epoch [46/100], Loss: 0.4180\n",
      "Validation Loss: 0.4059\n",
      "Epoch [47/100], Loss: 0.4230\n",
      "Validation Loss: 0.4049\n",
      "Epoch [48/100], Loss: 0.4180\n",
      "Validation Loss: 0.3953\n",
      "Epoch [49/100], Loss: 0.4122\n",
      "Validation Loss: 0.4146\n",
      "Epoch [50/100], Loss: 0.4166\n",
      "Validation Loss: 0.3967\n",
      "Epoch [51/100], Loss: 0.4179\n",
      "Validation Loss: 0.4180\n",
      "Epoch [52/100], Loss: 0.4140\n",
      "Validation Loss: 0.4159\n",
      "Epoch [53/100], Loss: 0.4192\n",
      "Validation Loss: 0.5169\n",
      "Epoch [54/100], Loss: 0.4197\n",
      "Validation Loss: 0.4266\n",
      "Epoch [55/100], Loss: 0.4127\n",
      "Validation Loss: 0.4014\n",
      "Epoch [56/100], Loss: 0.4110\n",
      "Validation Loss: 0.4026\n",
      "Epoch [57/100], Loss: 0.4084\n",
      "Validation Loss: 0.4375\n",
      "Epoch [58/100], Loss: 0.4043\n",
      "Validation Loss: 0.4039\n",
      "Epoch [59/100], Loss: 0.4080\n",
      "Validation Loss: 0.4161\n",
      "Epoch [60/100], Loss: 0.4091\n",
      "Validation Loss: 0.3800\n",
      "Saved the best model with validation loss: 0.3800\n",
      "Epoch [61/100], Loss: 0.4172\n",
      "Validation Loss: 0.4093\n",
      "Epoch [62/100], Loss: 0.4094\n",
      "Validation Loss: 0.4066\n",
      "Epoch [63/100], Loss: 0.4199\n",
      "Validation Loss: 0.4159\n",
      "Epoch [64/100], Loss: 0.4149\n",
      "Validation Loss: 0.3842\n",
      "Epoch [65/100], Loss: 0.4060\n",
      "Validation Loss: 0.3829\n",
      "Epoch [66/100], Loss: 0.4086\n",
      "Validation Loss: 0.3767\n",
      "Saved the best model with validation loss: 0.3767\n",
      "Epoch [67/100], Loss: 0.4092\n",
      "Validation Loss: 0.4390\n",
      "Epoch [68/100], Loss: 0.3997\n",
      "Validation Loss: 0.5856\n",
      "Epoch [69/100], Loss: 0.4087\n",
      "Validation Loss: 0.3904\n",
      "Epoch [70/100], Loss: 0.4023\n",
      "Validation Loss: 0.4067\n",
      "Epoch [71/100], Loss: 0.4093\n",
      "Validation Loss: 0.4232\n",
      "Epoch [72/100], Loss: 0.4039\n",
      "Validation Loss: 0.3967\n",
      "Epoch [73/100], Loss: 0.4079\n",
      "Validation Loss: 0.4516\n",
      "Epoch [74/100], Loss: 0.4010\n",
      "Validation Loss: 0.4171\n",
      "Epoch [75/100], Loss: 0.3990\n",
      "Validation Loss: 0.4443\n",
      "Epoch [76/100], Loss: 0.4055\n",
      "Validation Loss: 0.4185\n",
      "Epoch [77/100], Loss: 0.4046\n",
      "Validation Loss: 0.4332\n",
      "Epoch [78/100], Loss: 0.4055\n",
      "Validation Loss: 0.3851\n",
      "Epoch [79/100], Loss: 0.4107\n",
      "Validation Loss: 0.4133\n",
      "Epoch [80/100], Loss: 0.4056\n",
      "Validation Loss: 0.4028\n",
      "Epoch [81/100], Loss: 0.4067\n",
      "Validation Loss: 0.4138\n",
      "Epoch [82/100], Loss: 0.4032\n",
      "Validation Loss: 0.4072\n",
      "Epoch [83/100], Loss: 0.4005\n",
      "Validation Loss: 0.4266\n",
      "Epoch [84/100], Loss: 0.4115\n",
      "Validation Loss: 0.3842\n",
      "Epoch [85/100], Loss: 0.3984\n",
      "Validation Loss: 0.4804\n",
      "Epoch [86/100], Loss: 0.4047\n",
      "Validation Loss: 0.4051\n",
      "Epoch [87/100], Loss: 0.4008\n",
      "Validation Loss: 0.4747\n",
      "Epoch [88/100], Loss: 0.4010\n",
      "Validation Loss: 0.3891\n",
      "Epoch [89/100], Loss: 0.4026\n",
      "Validation Loss: 0.4328\n",
      "Epoch [90/100], Loss: 0.3963\n",
      "Validation Loss: 0.4246\n",
      "Epoch [91/100], Loss: 0.4025\n",
      "Validation Loss: 0.3960\n",
      "Epoch [92/100], Loss: 0.3967\n",
      "Validation Loss: 0.4072\n",
      "Epoch [93/100], Loss: 0.3989\n",
      "Validation Loss: 0.4019\n",
      "Epoch [94/100], Loss: 0.3954\n",
      "Validation Loss: 0.4049\n",
      "Epoch [95/100], Loss: 0.4077\n",
      "Validation Loss: 0.3965\n",
      "Epoch [96/100], Loss: 0.3992\n",
      "Validation Loss: 0.4120\n",
      "Epoch [97/100], Loss: 0.3971\n",
      "Validation Loss: 0.4026\n",
      "Epoch [98/100], Loss: 0.3994\n",
      "Validation Loss: 0.4183\n",
      "Epoch [99/100], Loss: 0.4034\n",
      "Validation Loss: 0.4873\n",
      "Epoch [100/100], Loss: 0.4059\n",
      "Validation Loss: 0.3867\n"
     ]
    }
   ],
   "source": [
    "combined_classification(X_train_hg, y1_equal_001_train_mlp, X_val_hg, y1_equal_001_val_mlp, \"3_class\", \"combi 0.01: 17-80-50-10/1-16-32-10/20-60-20-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "5a3a3f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.683465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.618305</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.736985</td>\n",
       "      <td>0.665572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.550265</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.553518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.760851</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.757245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.740482</td>\n",
       "      <td>0.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.695954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.574264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.807304</td>\n",
       "      <td>0.757205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.678266</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.718758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.761849</td>\n",
       "      <td>0.702517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.565671</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.573835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.609769</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.686092</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.523886</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>0.563887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.463788</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.576535</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>0.456894</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.617075</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.691531</td>\n",
       "      <td>0.59247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.513986</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.5051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.511805</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.601787</td>\n",
       "      <td>0.484145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.709790</td>\n",
       "      <td>0.472144</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.441541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.5</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.636436</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>0.623458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.1</th>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.489240</td>\n",
       "      <td>0.528749</td>\n",
       "      <td>0.528749</td>\n",
       "      <td>0.500062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.05</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.503794</td>\n",
       "      <td>0.583916</td>\n",
       "      <td>0.583916</td>\n",
       "      <td>0.465141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.01</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.472767</td>\n",
       "      <td>0.646076</td>\n",
       "      <td>0.646076</td>\n",
       "      <td>0.436033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-5-3</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.496341</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-5-3</th>\n",
       "      <td>0.391608</td>\n",
       "      <td>0.391608</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-5-3</th>\n",
       "      <td>0.458042</td>\n",
       "      <td>0.458042</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-5-3</th>\n",
       "      <td>0.678322</td>\n",
       "      <td>0.678322</td>\n",
       "      <td>0.458606</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-10-3</th>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.695804</td>\n",
       "      <td>0.594275</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-10-3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492483</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-10-3</th>\n",
       "      <td>0.503497</td>\n",
       "      <td>0.503497</td>\n",
       "      <td>0.388088</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-10-3</th>\n",
       "      <td>0.643357</td>\n",
       "      <td>0.643357</td>\n",
       "      <td>0.437753</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-20-3</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.671711</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-20-3</th>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.530143</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-20-3</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.533248</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-20-3</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.485372</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-25-3</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.652741</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-25-3</th>\n",
       "      <td>0.562937</td>\n",
       "      <td>0.562937</td>\n",
       "      <td>0.549527</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-25-3</th>\n",
       "      <td>0.604895</td>\n",
       "      <td>0.604895</td>\n",
       "      <td>0.506931</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-25-3</th>\n",
       "      <td>0.702797</td>\n",
       "      <td>0.702797</td>\n",
       "      <td>0.475257</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-40-3</th>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.658649</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-40-3</th>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.544795</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-40-3</th>\n",
       "      <td>0.643357</td>\n",
       "      <td>0.643357</td>\n",
       "      <td>0.543378</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-40-3</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.496421</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-60-3</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.661118</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-60-3</th>\n",
       "      <td>0.604895</td>\n",
       "      <td>0.604895</td>\n",
       "      <td>0.588332</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-60-3</th>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.531787</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-60-3</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.501556</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-10-5-3</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.566226</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-10-5-3</th>\n",
       "      <td>0.489510</td>\n",
       "      <td>0.489510</td>\n",
       "      <td>0.458104</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-10-5-3</th>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.426636</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-10-5-3</th>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.458917</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-20-10-3</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.705431</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-20-10-3</th>\n",
       "      <td>0.566434</td>\n",
       "      <td>0.566434</td>\n",
       "      <td>0.551893</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-20-10-3</th>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.646853</td>\n",
       "      <td>0.510838</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-20-10-3</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.503890</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-40-20-3</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.646443</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-40-20-3</th>\n",
       "      <td>0.566434</td>\n",
       "      <td>0.566434</td>\n",
       "      <td>0.553457</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-40-20-3</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.534119</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-40-20-3</th>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.514939</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-40-10-3</th>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.692229</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-40-10-3</th>\n",
       "      <td>0.503497</td>\n",
       "      <td>0.503497</td>\n",
       "      <td>0.499542</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-40-10-3</th>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.577871</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-40-10-3</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.510893</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-60-40-3</th>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.709484</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-60-40-3</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.617140</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-60-40-3</th>\n",
       "      <td>0.671329</td>\n",
       "      <td>0.671329</td>\n",
       "      <td>0.584635</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-60-40-3</th>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.511049</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-60-20-3</th>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.717879</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-60-20-3</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.613935</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-60-20-3</th>\n",
       "      <td>0.643357</td>\n",
       "      <td>0.643357</td>\n",
       "      <td>0.545875</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-60-20-3</th>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.505913</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-80-50-3</th>\n",
       "      <td>0.779720</td>\n",
       "      <td>0.779720</td>\n",
       "      <td>0.700232</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-80-50-3</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.604968</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-80-50-3</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.584421</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-80-50-3</th>\n",
       "      <td>0.758741</td>\n",
       "      <td>0.758741</td>\n",
       "      <td>0.517118</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_median: 7-80-50-3</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.688100</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_median: 7-80-50-3</th>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.552448</td>\n",
       "      <td>0.541819</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_median: 7-80-50-3</th>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.526862</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_median: 7-80-50-3</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.487084</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_mean: 7-80-50-3</th>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.655918</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_mean: 7-80-50-3</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.527053</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_mean: 7-80-50-3</th>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.546843</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_mean: 7-80-50-3</th>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.476502</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_min: 7-80-50-3</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.677507</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_min: 7-80-50-3</th>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.526175</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_min: 7-80-50-3</th>\n",
       "      <td>0.583916</td>\n",
       "      <td>0.583916</td>\n",
       "      <td>0.494161</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_min: 7-80-50-3</th>\n",
       "      <td>0.702797</td>\n",
       "      <td>0.702797</td>\n",
       "      <td>0.478058</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_max: 7-80-50-3</th>\n",
       "      <td>0.793706</td>\n",
       "      <td>0.793706</td>\n",
       "      <td>0.715280</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_max: 7-80-50-3</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_max: 7-80-50-3</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.578085</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_max: 7-80-50-3</th>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.522409</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_q25: 7-80-50-3</th>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.686386</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_q25: 7-80-50-3</th>\n",
       "      <td>0.566434</td>\n",
       "      <td>0.566434</td>\n",
       "      <td>0.542430</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_q25: 7-80-50-3</th>\n",
       "      <td>0.643357</td>\n",
       "      <td>0.643357</td>\n",
       "      <td>0.539043</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_q25: 7-80-50-3</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.470121</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_q75: 7-80-50-3</th>\n",
       "      <td>0.758741</td>\n",
       "      <td>0.758741</td>\n",
       "      <td>0.663409</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_q75: 7-80-50-3</th>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.541171</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_q75: 7-80-50-3</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.513056</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_q75: 7-80-50-3</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.497043</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, custom: 7-80-50-3</th>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.720348</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, custom: 7-80-50-3</th>\n",
       "      <td>0.625874</td>\n",
       "      <td>0.625874</td>\n",
       "      <td>0.606265</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, custom: 7-80-50-3</th>\n",
       "      <td>0.699301</td>\n",
       "      <td>0.699301</td>\n",
       "      <td>0.619176</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, custom: 7-80-50-3</th>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.510582</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.5: 1-16-32-3</th>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.821218</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.1: 1-16-32-3</th>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.747444</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.05: 1-16-32-3</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.679542</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.01: 1-16-32-3</th>\n",
       "      <td>0.828671</td>\n",
       "      <td>0.828671</td>\n",
       "      <td>0.566760</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.5: 1-32-16-3</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.793732</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.1: 1-32-16-3</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.730655</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.05: 1-32-16-3</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.681167</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.01: 1-32-16-3</th>\n",
       "      <td>0.828671</td>\n",
       "      <td>0.828671</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.5: 1-16-32-16-3</th>\n",
       "      <td>0.842657</td>\n",
       "      <td>0.842657</td>\n",
       "      <td>0.817910</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.1: 1-16-32-16-3</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.717682</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.05: 1-16-32-16-3</th>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.720280</td>\n",
       "      <td>0.676456</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.01: 1-16-32-16-3</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.570806</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.5: 1-32-64-3</th>\n",
       "      <td>0.828671</td>\n",
       "      <td>0.828671</td>\n",
       "      <td>0.800132</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.1: 1-32-64-3</th>\n",
       "      <td>0.723776</td>\n",
       "      <td>0.723776</td>\n",
       "      <td>0.723024</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.05: 1-32-64-3</th>\n",
       "      <td>0.713287</td>\n",
       "      <td>0.713287</td>\n",
       "      <td>0.662813</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.01: 1-32-64-3</th>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.568472</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.5: 1-4-16-3</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.819242</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.1: 1-4-16-3</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.740499</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.05: 1-4-16-3</th>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.691723</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.01: 1-4-16-3</th>\n",
       "      <td>0.828671</td>\n",
       "      <td>0.828671</td>\n",
       "      <td>0.566760</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.5: 17-80-50-3/1-16-32-3/6-3</th>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.813083</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.1: 17-80-50-3/1-16-32-3/6-3</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.713980</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.05: 17-80-50-3/1-16-32-3/6-3</th>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.702444</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.01: 17-80-50-3/1-16-32-3/6-3</th>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.564581</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.5: 17-80-50-5/1-16-32-5/10-3</th>\n",
       "      <td>0.828671</td>\n",
       "      <td>0.828671</td>\n",
       "      <td>0.806794</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.1: 17-80-50-5/1-16-32-5/10-3</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.729472</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.05: 17-80-50-5/1-16-32-5/10-3</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.707911</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.01: 17-80-50-5/1-16-32-5/10-3</th>\n",
       "      <td>0.821678</td>\n",
       "      <td>0.821678</td>\n",
       "      <td>0.561936</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.5: 17-80-50-5/1-16-32-5/10-20-3</th>\n",
       "      <td>0.877622</td>\n",
       "      <td>0.877622</td>\n",
       "      <td>0.846301</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.1: 17-80-50-5/1-16-32-5/10-20-3</th>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.737762</td>\n",
       "      <td>0.731227</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.05: 17-80-50-5/1-16-32-5/10-20-3</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.728596</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.01: 17-80-50-5/1-16-32-5/10-20-3</th>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.572362</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.5: 17-80-50-10/1-16-32-10/20-40-3</th>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.1: 17-80-50-10/1-16-32-10/20-40-3</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.709287</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.05: 17-80-50-10/1-16-32-10/20-40-3</th>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.679541</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.01: 17-80-50-10/1-16-32-10/20-40-3</th>\n",
       "      <td>0.860140</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.5: 17-80-50-10/1-16-32-10/20-60-20-3</th>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.855059</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.1: 17-80-50-10/1-16-32-10/20-60-20-3</th>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.716783</td>\n",
       "      <td>0.709592</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.05: 17-80-50-10/1-16-32-10/20-60-20-3</th>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.704447</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.01: 17-80-50-10/1-16-32-10/20-60-20-3</th>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.835664</td>\n",
       "      <td>0.571117</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    acc   rec-mic   rec_mac  \\\n",
       "5-NN 0.5                                       0.772727  0.772727  0.732079   \n",
       "5-NN 0.1                                       0.646853  0.646853  0.627251   \n",
       "5-NN 0.05                                      0.692308  0.692308  0.618305   \n",
       "5-NN 0.01                                      0.811189  0.811189  0.550265   \n",
       "Decision tree 0.5                              0.807692  0.807692  0.760851   \n",
       "Decision tree 0.1                              0.706294  0.706294  0.685897   \n",
       "Decision tree 0.05                             0.734266  0.734266  0.655555   \n",
       "Decision tree 0.01                             0.832168  0.832168  0.564270   \n",
       "Random forest 0.5                              0.814685  0.814685  0.763079   \n",
       "Random forest 0.1                              0.695804  0.695804  0.678266   \n",
       "Random forest 0.05                             0.727273  0.727273  0.655013   \n",
       "Random forest 0.01                             0.832168  0.832168  0.565671   \n",
       "SVM linear 0.5                                 0.720280  0.720280  0.609769   \n",
       "SVM linear 0.1                                 0.524476  0.524476  0.523886   \n",
       "SVM linear 0.05                                0.587413  0.587413  0.463788   \n",
       "SVM linear 0.01                                0.674825  0.674825  0.456894   \n",
       "SVM poly 0.5                                   0.727273  0.727273  0.617075   \n",
       "SVM poly 0.1                                   0.513986  0.513986  0.495726   \n",
       "SVM poly 0.05                                  0.639860  0.639860  0.511805   \n",
       "SVM poly 0.01                                  0.709790  0.709790  0.472144   \n",
       "SVM rbf 0.5                                    0.741259  0.741259  0.636436   \n",
       "SVM rbf 0.1                                    0.510490  0.510490  0.489240   \n",
       "SVM rbf 0.05                                   0.632867  0.632867  0.503794   \n",
       "SVM rbf 0.01                                   0.706294  0.706294  0.472767   \n",
       "MLP 0.5: 17-5-3                                0.646853  0.646853  0.496341   \n",
       "MLP 0.1: 17-5-3                                0.391608  0.391608  0.333333   \n",
       "MLP 0.05: 17-5-3                               0.458042  0.458042  0.333333   \n",
       "MLP 0.01: 17-5-3                               0.678322  0.678322  0.458606   \n",
       "MLP 0.5: 17-10-3                               0.695804  0.695804  0.594275   \n",
       "MLP 0.1: 17-10-3                               0.500000  0.500000  0.492483   \n",
       "MLP 0.05: 17-10-3                              0.503497  0.503497  0.388088   \n",
       "MLP 0.01: 17-10-3                              0.643357  0.643357  0.437753   \n",
       "MLP 0.5: 17-20-3                               0.741259  0.741259  0.671711   \n",
       "MLP 0.1: 17-20-3                               0.548951  0.548951  0.530143   \n",
       "MLP 0.05: 17-20-3                              0.632867  0.632867  0.533248   \n",
       "MLP 0.01: 17-20-3                              0.716783  0.716783  0.485372   \n",
       "MLP 0.5: 17-25-3                               0.737762  0.737762  0.652741   \n",
       "MLP 0.1: 17-25-3                               0.562937  0.562937  0.549527   \n",
       "MLP 0.05: 17-25-3                              0.604895  0.604895  0.506931   \n",
       "MLP 0.01: 17-25-3                              0.702797  0.702797  0.475257   \n",
       "MLP 0.5: 17-40-3                               0.748252  0.748252  0.658649   \n",
       "MLP 0.1: 17-40-3                               0.548951  0.548951  0.544795   \n",
       "MLP 0.05: 17-40-3                              0.643357  0.643357  0.543378   \n",
       "MLP 0.01: 17-40-3                              0.730769  0.730769  0.496421   \n",
       "MLP 0.5: 17-60-3                               0.741259  0.741259  0.661118   \n",
       "MLP 0.1: 17-60-3                               0.604895  0.604895  0.588332   \n",
       "MLP 0.05: 17-60-3                              0.629371  0.629371  0.531787   \n",
       "MLP 0.01: 17-60-3                              0.730769  0.730769  0.501556   \n",
       "MLP 0.5: 17-10-5-3                             0.636364  0.636364  0.566226   \n",
       "MLP 0.1: 17-10-5-3                             0.489510  0.489510  0.458104   \n",
       "MLP 0.05: 17-10-5-3                            0.510490  0.510490  0.426636   \n",
       "MLP 0.01: 17-10-5-3                            0.681818  0.681818  0.458917   \n",
       "MLP 0.5: 17-20-10-3                            0.772727  0.772727  0.705431   \n",
       "MLP 0.1: 17-20-10-3                            0.566434  0.566434  0.551893   \n",
       "MLP 0.05: 17-20-10-3                           0.646853  0.646853  0.510838   \n",
       "MLP 0.01: 17-20-10-3                           0.741259  0.741259  0.503890   \n",
       "MLP 0.5: 17-40-20-3                            0.716783  0.716783  0.646443   \n",
       "MLP 0.1: 17-40-20-3                            0.566434  0.566434  0.553457   \n",
       "MLP 0.05: 17-40-20-3                           0.632867  0.632867  0.534119   \n",
       "MLP 0.01: 17-40-20-3                           0.744755  0.744755  0.514939   \n",
       "MLP 0.5: 17-40-10-3                            0.765734  0.765734  0.692229   \n",
       "MLP 0.1: 17-40-10-3                            0.503497  0.503497  0.499542   \n",
       "MLP 0.05: 17-40-10-3                           0.681818  0.681818  0.577871   \n",
       "MLP 0.01: 17-40-10-3                           0.741259  0.741259  0.510893   \n",
       "MLP 0.5: 17-60-40-3                            0.765734  0.765734  0.709484   \n",
       "MLP 0.1: 17-60-40-3                            0.632867  0.632867  0.617140   \n",
       "MLP 0.05: 17-60-40-3                           0.671329  0.671329  0.584635   \n",
       "MLP 0.01: 17-60-40-3                           0.748252  0.748252  0.511049   \n",
       "MLP 0.5: 17-60-20-3                            0.790210  0.790210  0.717879   \n",
       "MLP 0.1: 17-60-20-3                            0.632867  0.632867  0.613935   \n",
       "MLP 0.05: 17-60-20-3                           0.643357  0.643357  0.545875   \n",
       "MLP 0.01: 17-60-20-3                           0.748252  0.748252  0.505913   \n",
       "MLP 0.5: 17-80-50-3                            0.779720  0.779720  0.700232   \n",
       "MLP 0.1: 17-80-50-3                            0.632867  0.632867  0.604968   \n",
       "MLP 0.05: 17-80-50-3                           0.692308  0.692308  0.584421   \n",
       "MLP 0.01: 17-80-50-3                           0.758741  0.758741  0.517118   \n",
       "MLP 0.5, small_median: 7-80-50-3               0.769231  0.769231  0.688100   \n",
       "MLP 0.1, small_median: 7-80-50-3               0.552448  0.552448  0.541819   \n",
       "MLP 0.05, small_median: 7-80-50-3              0.632867  0.632867  0.526862   \n",
       "MLP 0.01, small_median: 7-80-50-3              0.720280  0.720280  0.487084   \n",
       "MLP 0.5, small_mean: 7-80-50-3                 0.748252  0.748252  0.655918   \n",
       "MLP 0.1, small_mean: 7-80-50-3                 0.545455  0.545455  0.527053   \n",
       "MLP 0.05, small_mean: 7-80-50-3                0.629371  0.629371  0.546843   \n",
       "MLP 0.01, small_mean: 7-80-50-3                0.706294  0.706294  0.476502   \n",
       "MLP 0.5, small_min: 7-80-50-3                  0.769231  0.769231  0.677507   \n",
       "MLP 0.1, small_min: 7-80-50-3                  0.548951  0.548951  0.526175   \n",
       "MLP 0.05, small_min: 7-80-50-3                 0.583916  0.583916  0.494161   \n",
       "MLP 0.01, small_min: 7-80-50-3                 0.702797  0.702797  0.478058   \n",
       "MLP 0.5, small_max: 7-80-50-3                  0.793706  0.793706  0.715280   \n",
       "MLP 0.1, small_max: 7-80-50-3                  0.636364  0.636364  0.611111   \n",
       "MLP 0.05, small_max: 7-80-50-3                 0.653846  0.653846  0.578085   \n",
       "MLP 0.01, small_max: 7-80-50-3                 0.765734  0.765734  0.522409   \n",
       "MLP 0.5, small_q25: 7-80-50-3                  0.765734  0.765734  0.686386   \n",
       "MLP 0.1, small_q25: 7-80-50-3                  0.566434  0.566434  0.542430   \n",
       "MLP 0.05, small_q25: 7-80-50-3                 0.643357  0.643357  0.539043   \n",
       "MLP 0.01, small_q25: 7-80-50-3                 0.692308  0.692308  0.470121   \n",
       "MLP 0.5, small_q75: 7-80-50-3                  0.758741  0.758741  0.663409   \n",
       "MLP 0.1, small_q75: 7-80-50-3                  0.559441  0.559441  0.541171   \n",
       "MLP 0.05, small_q75: 7-80-50-3                 0.615385  0.615385  0.513056   \n",
       "MLP 0.01, small_q75: 7-80-50-3                 0.737762  0.737762  0.497043   \n",
       "MLP 0.5, custom: 7-80-50-3                     0.783217  0.783217  0.720348   \n",
       "MLP 0.1, custom: 7-80-50-3                     0.625874  0.625874  0.606265   \n",
       "MLP 0.05, custom: 7-80-50-3                    0.699301  0.699301  0.619176   \n",
       "MLP 0.01, custom: 7-80-50-3                    0.748252  0.748252  0.510582   \n",
       "HGNN 0.5: 1-16-32-3                            0.856643  0.856643  0.821218   \n",
       "HGNN 0.1: 1-16-32-3                            0.748252  0.748252  0.747444   \n",
       "HGNN 0.05: 1-16-32-3                           0.730769  0.730769  0.679542   \n",
       "HGNN 0.01: 1-16-32-3                           0.828671  0.828671  0.566760   \n",
       "HGNN 0.5: 1-32-16-3                            0.835664  0.835664  0.793732   \n",
       "HGNN 0.1: 1-32-16-3                            0.734266  0.734266  0.730655   \n",
       "HGNN 0.05: 1-32-16-3                           0.730769  0.730769  0.681167   \n",
       "HGNN 0.01: 1-32-16-3                           0.828671  0.828671  0.568627   \n",
       "HGNN 0.5: 1-16-32-16-3                         0.842657  0.842657  0.817910   \n",
       "HGNN 0.1: 1-16-32-16-3                         0.716783  0.716783  0.717682   \n",
       "HGNN 0.05: 1-16-32-16-3                        0.720280  0.720280  0.676456   \n",
       "HGNN 0.01: 1-16-32-16-3                        0.832168  0.832168  0.570806   \n",
       "HGNN 0.5: 1-32-64-3                            0.828671  0.828671  0.800132   \n",
       "HGNN 0.1: 1-32-64-3                            0.723776  0.723776  0.723024   \n",
       "HGNN 0.05: 1-32-64-3                           0.713287  0.713287  0.662813   \n",
       "HGNN 0.01: 1-32-64-3                           0.832168  0.832168  0.568472   \n",
       "HGNN 0.5: 1-4-16-3                             0.846154  0.846154  0.819242   \n",
       "HGNN 0.1: 1-4-16-3                             0.741259  0.741259  0.740499   \n",
       "HGNN 0.05: 1-4-16-3                            0.734266  0.734266  0.691723   \n",
       "HGNN 0.01: 1-4-16-3                            0.828671  0.828671  0.566760   \n",
       "combi 0.5: 17-80-50-3/1-16-32-3/6-3            0.839161  0.839161  0.813083   \n",
       "combi 0.1: 17-80-50-3/1-16-32-3/6-3            0.716783  0.716783  0.713980   \n",
       "combi 0.05: 17-80-50-3/1-16-32-3/6-3           0.741259  0.741259  0.702444   \n",
       "combi 0.01: 17-80-50-3/1-16-32-3/6-3           0.825175  0.825175  0.564581   \n",
       "combi 0.5: 17-80-50-5/1-16-32-5/10-3           0.828671  0.828671  0.806794   \n",
       "combi 0.1: 17-80-50-5/1-16-32-5/10-3           0.730769  0.730769  0.729472   \n",
       "combi 0.05: 17-80-50-5/1-16-32-5/10-3          0.737762  0.737762  0.707911   \n",
       "combi 0.01: 17-80-50-5/1-16-32-5/10-3          0.821678  0.821678  0.561936   \n",
       "combi 0.5: 17-80-50-5/1-16-32-5/10-20-3        0.877622  0.877622  0.846301   \n",
       "combi 0.1: 17-80-50-5/1-16-32-5/10-20-3        0.737762  0.737762  0.731227   \n",
       "combi 0.05: 17-80-50-5/1-16-32-5/10-20-3       0.772727  0.772727  0.728596   \n",
       "combi 0.01: 17-80-50-5/1-16-32-5/10-20-3       0.839161  0.839161  0.572362   \n",
       "combi 0.5: 17-80-50-10/1-16-32-10/20-40-3      0.884615  0.884615  0.852459   \n",
       "combi 0.1: 17-80-50-10/1-16-32-10/20-40-3      0.716783  0.716783  0.709287   \n",
       "combi 0.05: 17-80-50-10/1-16-32-10/20-40-3     0.744755  0.744755  0.679541   \n",
       "combi 0.01: 17-80-50-10/1-16-32-10/20-40-3     0.860140  0.860140  0.587302   \n",
       "combi 0.5: 17-80-50-10/1-16-32-10/20-60-20-3   0.881119  0.881119  0.855059   \n",
       "combi 0.1: 17-80-50-10/1-16-32-10/20-60-20-3   0.716783  0.716783  0.709592   \n",
       "combi 0.05: 17-80-50-10/1-16-32-10/20-60-20-3  0.744755  0.744755  0.704447   \n",
       "combi 0.01: 17-80-50-10/1-16-32-10/20-60-20-3  0.835664  0.835664  0.571117   \n",
       "\n",
       "                                                    acc   rec-mic   rec-mac  \n",
       "5-NN 0.5                                       0.794095  0.794095  0.754179  \n",
       "5-NN 0.1                                       0.703186  0.703186  0.683465  \n",
       "5-NN 0.05                                      0.736985  0.736985  0.665572  \n",
       "5-NN 0.01                                      0.796037  0.796037  0.553518  \n",
       "Decision tree 0.5                              0.804196  0.804196  0.757245  \n",
       "Decision tree 0.1                              0.740482  0.740482  0.721371  \n",
       "Decision tree 0.05                             0.760684  0.760684  0.695954  \n",
       "Decision tree 0.01                             0.813908  0.813908  0.574264  \n",
       "Random forest 0.5                              0.807304  0.807304  0.757205  \n",
       "Random forest 0.1                              0.736597  0.736597  0.718758  \n",
       "Random forest 0.05                             0.761849  0.761849  0.702517  \n",
       "Random forest 0.01                             0.811966  0.811966  0.573835  \n",
       "SVM linear 0.5                                 0.686092  0.686092  0.592452  \n",
       "SVM linear 0.1                                 0.561383  0.561383  0.563887  \n",
       "SVM linear 0.05                                0.576535  0.576535  0.458361  \n",
       "SVM linear 0.01                                0.634033  0.634033  0.433962  \n",
       "SVM poly 0.5                                   0.691531  0.691531   0.59247  \n",
       "SVM poly 0.1                                   0.535354  0.535354    0.5051  \n",
       "SVM poly 0.05                                  0.601787  0.601787  0.484145  \n",
       "SVM poly 0.01                                  0.658508  0.658508  0.441541  \n",
       "SVM rbf 0.5                                    0.703186  0.703186  0.623458  \n",
       "SVM rbf 0.1                                    0.528749  0.528749  0.500062  \n",
       "SVM rbf 0.05                                   0.583916  0.583916  0.465141  \n",
       "SVM rbf 0.01                                   0.646076  0.646076  0.436033  \n",
       "MLP 0.5: 17-5-3                                       -         -         -  \n",
       "MLP 0.1: 17-5-3                                       -         -         -  \n",
       "MLP 0.05: 17-5-3                                      -         -         -  \n",
       "MLP 0.01: 17-5-3                                      -         -         -  \n",
       "MLP 0.5: 17-10-3                                      -         -         -  \n",
       "MLP 0.1: 17-10-3                                      -         -         -  \n",
       "MLP 0.05: 17-10-3                                     -         -         -  \n",
       "MLP 0.01: 17-10-3                                     -         -         -  \n",
       "MLP 0.5: 17-20-3                                      -         -         -  \n",
       "MLP 0.1: 17-20-3                                      -         -         -  \n",
       "MLP 0.05: 17-20-3                                     -         -         -  \n",
       "MLP 0.01: 17-20-3                                     -         -         -  \n",
       "MLP 0.5: 17-25-3                                      -         -         -  \n",
       "MLP 0.1: 17-25-3                                      -         -         -  \n",
       "MLP 0.05: 17-25-3                                     -         -         -  \n",
       "MLP 0.01: 17-25-3                                     -         -         -  \n",
       "MLP 0.5: 17-40-3                                      -         -         -  \n",
       "MLP 0.1: 17-40-3                                      -         -         -  \n",
       "MLP 0.05: 17-40-3                                     -         -         -  \n",
       "MLP 0.01: 17-40-3                                     -         -         -  \n",
       "MLP 0.5: 17-60-3                                      -         -         -  \n",
       "MLP 0.1: 17-60-3                                      -         -         -  \n",
       "MLP 0.05: 17-60-3                                     -         -         -  \n",
       "MLP 0.01: 17-60-3                                     -         -         -  \n",
       "MLP 0.5: 17-10-5-3                                    -         -         -  \n",
       "MLP 0.1: 17-10-5-3                                    -         -         -  \n",
       "MLP 0.05: 17-10-5-3                                   -         -         -  \n",
       "MLP 0.01: 17-10-5-3                                   -         -         -  \n",
       "MLP 0.5: 17-20-10-3                                   -         -         -  \n",
       "MLP 0.1: 17-20-10-3                                   -         -         -  \n",
       "MLP 0.05: 17-20-10-3                                  -         -         -  \n",
       "MLP 0.01: 17-20-10-3                                  -         -         -  \n",
       "MLP 0.5: 17-40-20-3                                   -         -         -  \n",
       "MLP 0.1: 17-40-20-3                                   -         -         -  \n",
       "MLP 0.05: 17-40-20-3                                  -         -         -  \n",
       "MLP 0.01: 17-40-20-3                                  -         -         -  \n",
       "MLP 0.5: 17-40-10-3                                   -         -         -  \n",
       "MLP 0.1: 17-40-10-3                                   -         -         -  \n",
       "MLP 0.05: 17-40-10-3                                  -         -         -  \n",
       "MLP 0.01: 17-40-10-3                                  -         -         -  \n",
       "MLP 0.5: 17-60-40-3                                   -         -         -  \n",
       "MLP 0.1: 17-60-40-3                                   -         -         -  \n",
       "MLP 0.05: 17-60-40-3                                  -         -         -  \n",
       "MLP 0.01: 17-60-40-3                                  -         -         -  \n",
       "MLP 0.5: 17-60-20-3                                   -         -         -  \n",
       "MLP 0.1: 17-60-20-3                                   -         -         -  \n",
       "MLP 0.05: 17-60-20-3                                  -         -         -  \n",
       "MLP 0.01: 17-60-20-3                                  -         -         -  \n",
       "MLP 0.5: 17-80-50-3                                   -         -         -  \n",
       "MLP 0.1: 17-80-50-3                                   -         -         -  \n",
       "MLP 0.05: 17-80-50-3                                  -         -         -  \n",
       "MLP 0.01: 17-80-50-3                                  -         -         -  \n",
       "MLP 0.5, small_median: 7-80-50-3                      -         -         -  \n",
       "MLP 0.1, small_median: 7-80-50-3                      -         -         -  \n",
       "MLP 0.05, small_median: 7-80-50-3                     -         -         -  \n",
       "MLP 0.01, small_median: 7-80-50-3                     -         -         -  \n",
       "MLP 0.5, small_mean: 7-80-50-3                        -         -         -  \n",
       "MLP 0.1, small_mean: 7-80-50-3                        -         -         -  \n",
       "MLP 0.05, small_mean: 7-80-50-3                       -         -         -  \n",
       "MLP 0.01, small_mean: 7-80-50-3                       -         -         -  \n",
       "MLP 0.5, small_min: 7-80-50-3                         -         -         -  \n",
       "MLP 0.1, small_min: 7-80-50-3                         -         -         -  \n",
       "MLP 0.05, small_min: 7-80-50-3                        -         -         -  \n",
       "MLP 0.01, small_min: 7-80-50-3                        -         -         -  \n",
       "MLP 0.5, small_max: 7-80-50-3                         -         -         -  \n",
       "MLP 0.1, small_max: 7-80-50-3                         -         -         -  \n",
       "MLP 0.05, small_max: 7-80-50-3                        -         -         -  \n",
       "MLP 0.01, small_max: 7-80-50-3                        -         -         -  \n",
       "MLP 0.5, small_q25: 7-80-50-3                         -         -         -  \n",
       "MLP 0.1, small_q25: 7-80-50-3                         -         -         -  \n",
       "MLP 0.05, small_q25: 7-80-50-3                        -         -         -  \n",
       "MLP 0.01, small_q25: 7-80-50-3                        -         -         -  \n",
       "MLP 0.5, small_q75: 7-80-50-3                         -         -         -  \n",
       "MLP 0.1, small_q75: 7-80-50-3                         -         -         -  \n",
       "MLP 0.05, small_q75: 7-80-50-3                        -         -         -  \n",
       "MLP 0.01, small_q75: 7-80-50-3                        -         -         -  \n",
       "MLP 0.5, custom: 7-80-50-3                            -         -         -  \n",
       "MLP 0.1, custom: 7-80-50-3                            -         -         -  \n",
       "MLP 0.05, custom: 7-80-50-3                           -         -         -  \n",
       "MLP 0.01, custom: 7-80-50-3                           -         -         -  \n",
       "HGNN 0.5: 1-16-32-3                                   -         -         -  \n",
       "HGNN 0.1: 1-16-32-3                                   -         -         -  \n",
       "HGNN 0.05: 1-16-32-3                                  -         -         -  \n",
       "HGNN 0.01: 1-16-32-3                                  -         -         -  \n",
       "HGNN 0.5: 1-32-16-3                                   -         -         -  \n",
       "HGNN 0.1: 1-32-16-3                                   -         -         -  \n",
       "HGNN 0.05: 1-32-16-3                                  -         -         -  \n",
       "HGNN 0.01: 1-32-16-3                                  -         -         -  \n",
       "HGNN 0.5: 1-16-32-16-3                                -         -         -  \n",
       "HGNN 0.1: 1-16-32-16-3                                -         -         -  \n",
       "HGNN 0.05: 1-16-32-16-3                               -         -         -  \n",
       "HGNN 0.01: 1-16-32-16-3                               -         -         -  \n",
       "HGNN 0.5: 1-32-64-3                                   -         -         -  \n",
       "HGNN 0.1: 1-32-64-3                                   -         -         -  \n",
       "HGNN 0.05: 1-32-64-3                                  -         -         -  \n",
       "HGNN 0.01: 1-32-64-3                                  -         -         -  \n",
       "HGNN 0.5: 1-4-16-3                                    -         -         -  \n",
       "HGNN 0.1: 1-4-16-3                                    -         -         -  \n",
       "HGNN 0.05: 1-4-16-3                                   -         -         -  \n",
       "HGNN 0.01: 1-4-16-3                                   -         -         -  \n",
       "combi 0.5: 17-80-50-3/1-16-32-3/6-3                   -         -         -  \n",
       "combi 0.1: 17-80-50-3/1-16-32-3/6-3                   -         -         -  \n",
       "combi 0.05: 17-80-50-3/1-16-32-3/6-3                  -         -         -  \n",
       "combi 0.01: 17-80-50-3/1-16-32-3/6-3                  -         -         -  \n",
       "combi 0.5: 17-80-50-5/1-16-32-5/10-3                  -         -         -  \n",
       "combi 0.1: 17-80-50-5/1-16-32-5/10-3                  -         -         -  \n",
       "combi 0.05: 17-80-50-5/1-16-32-5/10-3                 -         -         -  \n",
       "combi 0.01: 17-80-50-5/1-16-32-5/10-3                 -         -         -  \n",
       "combi 0.5: 17-80-50-5/1-16-32-5/10-20-3               -         -         -  \n",
       "combi 0.1: 17-80-50-5/1-16-32-5/10-20-3               -         -         -  \n",
       "combi 0.05: 17-80-50-5/1-16-32-5/10-20-3              -         -         -  \n",
       "combi 0.01: 17-80-50-5/1-16-32-5/10-20-3              -         -         -  \n",
       "combi 0.5: 17-80-50-10/1-16-32-10/20-40-3             -         -         -  \n",
       "combi 0.1: 17-80-50-10/1-16-32-10/20-40-3             -         -         -  \n",
       "combi 0.05: 17-80-50-10/1-16-32-10/20-40-3            -         -         -  \n",
       "combi 0.01: 17-80-50-10/1-16-32-10/20-40-3            -         -         -  \n",
       "combi 0.5: 17-80-50-10/1-16-32-10/20-60-20-3          -         -         -  \n",
       "combi 0.1: 17-80-50-10/1-16-32-10/20-60-20-3          -         -         -  \n",
       "combi 0.05: 17-80-50-10/1-16-32-10/20-60-20-3         -         -         -  \n",
       "combi 0.01: 17-80-50-10/1-16-32-10/20-60-20-3         -         -         -  "
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_3_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "afffde5c-ec83-4d8d-8936-cacf26ddfde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2526/3096664064.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  table_3_classes = table_3_classes.applymap(round_if_number)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec-mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN 0.5</th>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.7321</td>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.7941</td>\n",
       "      <td>0.7542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.1</th>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.6273</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>0.6835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.05</th>\n",
       "      <td>0.6923</td>\n",
       "      <td>0.6923</td>\n",
       "      <td>0.6183</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.6656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-NN 0.01</th>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.5503</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.5535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.7609</td>\n",
       "      <td>0.8042</td>\n",
       "      <td>0.8042</td>\n",
       "      <td>0.7572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.6859</td>\n",
       "      <td>0.7405</td>\n",
       "      <td>0.7405</td>\n",
       "      <td>0.7214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.7607</td>\n",
       "      <td>0.7607</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.8139</td>\n",
       "      <td>0.8139</td>\n",
       "      <td>0.5743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.8147</td>\n",
       "      <td>0.8147</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.8073</td>\n",
       "      <td>0.8073</td>\n",
       "      <td>0.7572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.6783</td>\n",
       "      <td>0.7366</td>\n",
       "      <td>0.7366</td>\n",
       "      <td>0.7188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.7618</td>\n",
       "      <td>0.7618</td>\n",
       "      <td>0.7025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.5657</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.5738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.5</th>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.6098</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.5925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.1</th>\n",
       "      <td>0.5245</td>\n",
       "      <td>0.5245</td>\n",
       "      <td>0.5239</td>\n",
       "      <td>0.5614</td>\n",
       "      <td>0.5614</td>\n",
       "      <td>0.5639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.05</th>\n",
       "      <td>0.5874</td>\n",
       "      <td>0.5874</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.4584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear 0.01</th>\n",
       "      <td>0.6748</td>\n",
       "      <td>0.6748</td>\n",
       "      <td>0.4569</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.5</th>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.6171</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.5925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.1</th>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.5354</td>\n",
       "      <td>0.5354</td>\n",
       "      <td>0.5051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.05</th>\n",
       "      <td>0.6399</td>\n",
       "      <td>0.6399</td>\n",
       "      <td>0.5118</td>\n",
       "      <td>0.6018</td>\n",
       "      <td>0.6018</td>\n",
       "      <td>0.4841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly 0.01</th>\n",
       "      <td>0.7098</td>\n",
       "      <td>0.7098</td>\n",
       "      <td>0.4721</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.4415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.5</th>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>0.6235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.1</th>\n",
       "      <td>0.5105</td>\n",
       "      <td>0.5105</td>\n",
       "      <td>0.4892</td>\n",
       "      <td>0.5287</td>\n",
       "      <td>0.5287</td>\n",
       "      <td>0.5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.05</th>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.5038</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.4651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf 0.01</th>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.4728</td>\n",
       "      <td>0.6461</td>\n",
       "      <td>0.6461</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-5-3</th>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.4963</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-5-3</th>\n",
       "      <td>0.3916</td>\n",
       "      <td>0.3916</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-5-3</th>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-5-3</th>\n",
       "      <td>0.6783</td>\n",
       "      <td>0.6783</td>\n",
       "      <td>0.4586</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-10-3</th>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.5943</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-10-3</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4925</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-10-3</th>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.3881</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-10-3</th>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-20-3</th>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.6717</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-20-3</th>\n",
       "      <td>0.5490</td>\n",
       "      <td>0.5490</td>\n",
       "      <td>0.5301</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-20-3</th>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-20-3</th>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.4854</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-25-3</th>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-25-3</th>\n",
       "      <td>0.5629</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>0.5495</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-25-3</th>\n",
       "      <td>0.6049</td>\n",
       "      <td>0.6049</td>\n",
       "      <td>0.5069</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-25-3</th>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.4753</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-40-3</th>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-40-3</th>\n",
       "      <td>0.5490</td>\n",
       "      <td>0.5490</td>\n",
       "      <td>0.5448</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-40-3</th>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-40-3</th>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.4964</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-60-3</th>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.6611</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-60-3</th>\n",
       "      <td>0.6049</td>\n",
       "      <td>0.6049</td>\n",
       "      <td>0.5883</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-60-3</th>\n",
       "      <td>0.6294</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-60-3</th>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-10-5-3</th>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.5662</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-10-5-3</th>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.4581</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-10-5-3</th>\n",
       "      <td>0.5105</td>\n",
       "      <td>0.5105</td>\n",
       "      <td>0.4266</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-10-5-3</th>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.4589</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-20-10-3</th>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.7054</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-20-10-3</th>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.5519</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-20-10-3</th>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.5108</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-20-10-3</th>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-40-20-3</th>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.6464</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-40-20-3</th>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.5535</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-40-20-3</th>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-40-20-3</th>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.5149</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-40-10-3</th>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.6922</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-40-10-3</th>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-40-10-3</th>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.5779</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-40-10-3</th>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.5109</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-60-40-3</th>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-60-40-3</th>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6171</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-60-40-3</th>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-60-40-3</th>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-60-20-3</th>\n",
       "      <td>0.7902</td>\n",
       "      <td>0.7902</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-60-20-3</th>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6139</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-60-20-3</th>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-60-20-3</th>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5: 17-80-50-3</th>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1: 17-80-50-3</th>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05: 17-80-50-3</th>\n",
       "      <td>0.6923</td>\n",
       "      <td>0.6923</td>\n",
       "      <td>0.5844</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01: 17-80-50-3</th>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.5171</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_median: 7-80-50-3</th>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_median: 7-80-50-3</th>\n",
       "      <td>0.5524</td>\n",
       "      <td>0.5524</td>\n",
       "      <td>0.5418</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_median: 7-80-50-3</th>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.5269</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_median: 7-80-50-3</th>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.4871</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_mean: 7-80-50-3</th>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_mean: 7-80-50-3</th>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.5271</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_mean: 7-80-50-3</th>\n",
       "      <td>0.6294</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_mean: 7-80-50-3</th>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.4765</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_min: 7-80-50-3</th>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_min: 7-80-50-3</th>\n",
       "      <td>0.5490</td>\n",
       "      <td>0.5490</td>\n",
       "      <td>0.5262</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_min: 7-80-50-3</th>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.4942</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_min: 7-80-50-3</th>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.4781</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_max: 7-80-50-3</th>\n",
       "      <td>0.7937</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_max: 7-80-50-3</th>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_max: 7-80-50-3</th>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.5781</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_max: 7-80-50-3</th>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.5224</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_q25: 7-80-50-3</th>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_q25: 7-80-50-3</th>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.5424</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_q25: 7-80-50-3</th>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_q25: 7-80-50-3</th>\n",
       "      <td>0.6923</td>\n",
       "      <td>0.6923</td>\n",
       "      <td>0.4701</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, small_q75: 7-80-50-3</th>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.6634</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, small_q75: 7-80-50-3</th>\n",
       "      <td>0.5594</td>\n",
       "      <td>0.5594</td>\n",
       "      <td>0.5412</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, small_q75: 7-80-50-3</th>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.5131</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, small_q75: 7-80-50-3</th>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.4970</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.5, custom: 7-80-50-3</th>\n",
       "      <td>0.7832</td>\n",
       "      <td>0.7832</td>\n",
       "      <td>0.7203</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.1, custom: 7-80-50-3</th>\n",
       "      <td>0.6259</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>0.6063</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.05, custom: 7-80-50-3</th>\n",
       "      <td>0.6993</td>\n",
       "      <td>0.6993</td>\n",
       "      <td>0.6192</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP 0.01, custom: 7-80-50-3</th>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.5: 1-16-32-3</th>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.8212</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.1: 1-16-32-3</th>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.7474</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.05: 1-16-32-3</th>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.6795</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.01: 1-16-32-3</th>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.5668</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.5: 1-32-16-3</th>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.1: 1-32-16-3</th>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.7307</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.05: 1-32-16-3</th>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.01: 1-32-16-3</th>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.5: 1-16-32-16-3</th>\n",
       "      <td>0.8427</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>0.8179</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.1: 1-16-32-16-3</th>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.7177</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.05: 1-16-32-16-3</th>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.01: 1-16-32-16-3</th>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.5708</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.5: 1-32-64-3</th>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.8001</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.1: 1-32-64-3</th>\n",
       "      <td>0.7238</td>\n",
       "      <td>0.7238</td>\n",
       "      <td>0.7230</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.05: 1-32-64-3</th>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.6628</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.01: 1-32-64-3</th>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.5685</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.5: 1-4-16-3</th>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.8192</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.1: 1-4-16-3</th>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.7405</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.05: 1-4-16-3</th>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN 0.01: 1-4-16-3</th>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.5668</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.5: 17-80-50-3/1-16-32-3/6-3</th>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.1: 17-80-50-3/1-16-32-3/6-3</th>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.05: 17-80-50-3/1-16-32-3/6-3</th>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.7024</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.01: 17-80-50-3/1-16-32-3/6-3</th>\n",
       "      <td>0.8252</td>\n",
       "      <td>0.8252</td>\n",
       "      <td>0.5646</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.5: 17-80-50-5/1-16-32-5/10-3</th>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.8068</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.1: 17-80-50-5/1-16-32-5/10-3</th>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.7295</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.05: 17-80-50-5/1-16-32-5/10-3</th>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.7079</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.01: 17-80-50-5/1-16-32-5/10-3</th>\n",
       "      <td>0.8217</td>\n",
       "      <td>0.8217</td>\n",
       "      <td>0.5619</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.5: 17-80-50-5/1-16-32-5/10-20-3</th>\n",
       "      <td>0.8776</td>\n",
       "      <td>0.8776</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.1: 17-80-50-5/1-16-32-5/10-20-3</th>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.05: 17-80-50-5/1-16-32-5/10-20-3</th>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.01: 17-80-50-5/1-16-32-5/10-20-3</th>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.5724</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.5: 17-80-50-10/1-16-32-10/20-40-3</th>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.8525</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.1: 17-80-50-10/1-16-32-10/20-40-3</th>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.7093</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.05: 17-80-50-10/1-16-32-10/20-40-3</th>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.6795</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.01: 17-80-50-10/1-16-32-10/20-40-3</th>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.5: 17-80-50-10/1-16-32-10/20-60-20-3</th>\n",
       "      <td>0.8811</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>0.8551</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.1: 17-80-50-10/1-16-32-10/20-60-20-3</th>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.05: 17-80-50-10/1-16-32-10/20-60-20-3</th>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi 0.01: 17-80-50-10/1-16-32-10/20-60-20-3</th>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.5711</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  acc rec-mic  rec_mac  \\\n",
       "5-NN 0.5                                       0.7727  0.7727   0.7321   \n",
       "5-NN 0.1                                       0.6469  0.6469   0.6273   \n",
       "5-NN 0.05                                      0.6923  0.6923   0.6183   \n",
       "5-NN 0.01                                      0.8112  0.8112   0.5503   \n",
       "Decision tree 0.5                              0.8077  0.8077   0.7609   \n",
       "Decision tree 0.1                              0.7063  0.7063   0.6859   \n",
       "Decision tree 0.05                             0.7343  0.7343   0.6556   \n",
       "Decision tree 0.01                             0.8322  0.8322   0.5643   \n",
       "Random forest 0.5                              0.8147  0.8147   0.7631   \n",
       "Random forest 0.1                              0.6958  0.6958   0.6783   \n",
       "Random forest 0.05                             0.7273  0.7273   0.6550   \n",
       "Random forest 0.01                             0.8322  0.8322   0.5657   \n",
       "SVM linear 0.5                                 0.7203  0.7203   0.6098   \n",
       "SVM linear 0.1                                 0.5245  0.5245   0.5239   \n",
       "SVM linear 0.05                                0.5874  0.5874   0.4638   \n",
       "SVM linear 0.01                                0.6748  0.6748   0.4569   \n",
       "SVM poly 0.5                                   0.7273  0.7273   0.6171   \n",
       "SVM poly 0.1                                   0.5140  0.5140   0.4957   \n",
       "SVM poly 0.05                                  0.6399  0.6399   0.5118   \n",
       "SVM poly 0.01                                  0.7098  0.7098   0.4721   \n",
       "SVM rbf 0.5                                    0.7413  0.7413   0.6364   \n",
       "SVM rbf 0.1                                    0.5105  0.5105   0.4892   \n",
       "SVM rbf 0.05                                   0.6329  0.6329   0.5038   \n",
       "SVM rbf 0.01                                   0.7063  0.7063   0.4728   \n",
       "MLP 0.5: 17-5-3                                0.6469  0.6469   0.4963   \n",
       "MLP 0.1: 17-5-3                                0.3916  0.3916   0.3333   \n",
       "MLP 0.05: 17-5-3                               0.4580  0.4580   0.3333   \n",
       "MLP 0.01: 17-5-3                               0.6783  0.6783   0.4586   \n",
       "MLP 0.5: 17-10-3                               0.6958  0.6958   0.5943   \n",
       "MLP 0.1: 17-10-3                               0.5000  0.5000   0.4925   \n",
       "MLP 0.05: 17-10-3                              0.5035  0.5035   0.3881   \n",
       "MLP 0.01: 17-10-3                              0.6434  0.6434   0.4378   \n",
       "MLP 0.5: 17-20-3                               0.7413  0.7413   0.6717   \n",
       "MLP 0.1: 17-20-3                               0.5490  0.5490   0.5301   \n",
       "MLP 0.05: 17-20-3                              0.6329  0.6329   0.5332   \n",
       "MLP 0.01: 17-20-3                              0.7168  0.7168   0.4854   \n",
       "MLP 0.5: 17-25-3                               0.7378  0.7378   0.6527   \n",
       "MLP 0.1: 17-25-3                               0.5629  0.5629   0.5495   \n",
       "MLP 0.05: 17-25-3                              0.6049  0.6049   0.5069   \n",
       "MLP 0.01: 17-25-3                              0.7028  0.7028   0.4753   \n",
       "MLP 0.5: 17-40-3                               0.7483  0.7483   0.6586   \n",
       "MLP 0.1: 17-40-3                               0.5490  0.5490   0.5448   \n",
       "MLP 0.05: 17-40-3                              0.6434  0.6434   0.5434   \n",
       "MLP 0.01: 17-40-3                              0.7308  0.7308   0.4964   \n",
       "MLP 0.5: 17-60-3                               0.7413  0.7413   0.6611   \n",
       "MLP 0.1: 17-60-3                               0.6049  0.6049   0.5883   \n",
       "MLP 0.05: 17-60-3                              0.6294  0.6294   0.5318   \n",
       "MLP 0.01: 17-60-3                              0.7308  0.7308   0.5016   \n",
       "MLP 0.5: 17-10-5-3                             0.6364  0.6364   0.5662   \n",
       "MLP 0.1: 17-10-5-3                             0.4895  0.4895   0.4581   \n",
       "MLP 0.05: 17-10-5-3                            0.5105  0.5105   0.4266   \n",
       "MLP 0.01: 17-10-5-3                            0.6818  0.6818   0.4589   \n",
       "MLP 0.5: 17-20-10-3                            0.7727  0.7727   0.7054   \n",
       "MLP 0.1: 17-20-10-3                            0.5664  0.5664   0.5519   \n",
       "MLP 0.05: 17-20-10-3                           0.6469  0.6469   0.5108   \n",
       "MLP 0.01: 17-20-10-3                           0.7413  0.7413   0.5039   \n",
       "MLP 0.5: 17-40-20-3                            0.7168  0.7168   0.6464   \n",
       "MLP 0.1: 17-40-20-3                            0.5664  0.5664   0.5535   \n",
       "MLP 0.05: 17-40-20-3                           0.6329  0.6329   0.5341   \n",
       "MLP 0.01: 17-40-20-3                           0.7448  0.7448   0.5149   \n",
       "MLP 0.5: 17-40-10-3                            0.7657  0.7657   0.6922   \n",
       "MLP 0.1: 17-40-10-3                            0.5035  0.5035   0.4995   \n",
       "MLP 0.05: 17-40-10-3                           0.6818  0.6818   0.5779   \n",
       "MLP 0.01: 17-40-10-3                           0.7413  0.7413   0.5109   \n",
       "MLP 0.5: 17-60-40-3                            0.7657  0.7657   0.7095   \n",
       "MLP 0.1: 17-60-40-3                            0.6329  0.6329   0.6171   \n",
       "MLP 0.05: 17-60-40-3                           0.6713  0.6713   0.5846   \n",
       "MLP 0.01: 17-60-40-3                           0.7483  0.7483   0.5110   \n",
       "MLP 0.5: 17-60-20-3                            0.7902  0.7902   0.7179   \n",
       "MLP 0.1: 17-60-20-3                            0.6329  0.6329   0.6139   \n",
       "MLP 0.05: 17-60-20-3                           0.6434  0.6434   0.5459   \n",
       "MLP 0.01: 17-60-20-3                           0.7483  0.7483   0.5059   \n",
       "MLP 0.5: 17-80-50-3                            0.7797  0.7797   0.7002   \n",
       "MLP 0.1: 17-80-50-3                            0.6329  0.6329   0.6050   \n",
       "MLP 0.05: 17-80-50-3                           0.6923  0.6923   0.5844   \n",
       "MLP 0.01: 17-80-50-3                           0.7587  0.7587   0.5171   \n",
       "MLP 0.5, small_median: 7-80-50-3               0.7692  0.7692   0.6881   \n",
       "MLP 0.1, small_median: 7-80-50-3               0.5524  0.5524   0.5418   \n",
       "MLP 0.05, small_median: 7-80-50-3              0.6329  0.6329   0.5269   \n",
       "MLP 0.01, small_median: 7-80-50-3              0.7203  0.7203   0.4871   \n",
       "MLP 0.5, small_mean: 7-80-50-3                 0.7483  0.7483   0.6559   \n",
       "MLP 0.1, small_mean: 7-80-50-3                 0.5455  0.5455   0.5271   \n",
       "MLP 0.05, small_mean: 7-80-50-3                0.6294  0.6294   0.5468   \n",
       "MLP 0.01, small_mean: 7-80-50-3                0.7063  0.7063   0.4765   \n",
       "MLP 0.5, small_min: 7-80-50-3                  0.7692  0.7692   0.6775   \n",
       "MLP 0.1, small_min: 7-80-50-3                  0.5490  0.5490   0.5262   \n",
       "MLP 0.05, small_min: 7-80-50-3                 0.5839  0.5839   0.4942   \n",
       "MLP 0.01, small_min: 7-80-50-3                 0.7028  0.7028   0.4781   \n",
       "MLP 0.5, small_max: 7-80-50-3                  0.7937  0.7937   0.7153   \n",
       "MLP 0.1, small_max: 7-80-50-3                  0.6364  0.6364   0.6111   \n",
       "MLP 0.05, small_max: 7-80-50-3                 0.6538  0.6538   0.5781   \n",
       "MLP 0.01, small_max: 7-80-50-3                 0.7657  0.7657   0.5224   \n",
       "MLP 0.5, small_q25: 7-80-50-3                  0.7657  0.7657   0.6864   \n",
       "MLP 0.1, small_q25: 7-80-50-3                  0.5664  0.5664   0.5424   \n",
       "MLP 0.05, small_q25: 7-80-50-3                 0.6434  0.6434   0.5390   \n",
       "MLP 0.01, small_q25: 7-80-50-3                 0.6923  0.6923   0.4701   \n",
       "MLP 0.5, small_q75: 7-80-50-3                  0.7587  0.7587   0.6634   \n",
       "MLP 0.1, small_q75: 7-80-50-3                  0.5594  0.5594   0.5412   \n",
       "MLP 0.05, small_q75: 7-80-50-3                 0.6154  0.6154   0.5131   \n",
       "MLP 0.01, small_q75: 7-80-50-3                 0.7378  0.7378   0.4970   \n",
       "MLP 0.5, custom: 7-80-50-3                     0.7832  0.7832   0.7203   \n",
       "MLP 0.1, custom: 7-80-50-3                     0.6259  0.6259   0.6063   \n",
       "MLP 0.05, custom: 7-80-50-3                    0.6993  0.6993   0.6192   \n",
       "MLP 0.01, custom: 7-80-50-3                    0.7483  0.7483   0.5106   \n",
       "HGNN 0.5: 1-16-32-3                            0.8566  0.8566   0.8212   \n",
       "HGNN 0.1: 1-16-32-3                            0.7483  0.7483   0.7474   \n",
       "HGNN 0.05: 1-16-32-3                           0.7308  0.7308   0.6795   \n",
       "HGNN 0.01: 1-16-32-3                           0.8287  0.8287   0.5668   \n",
       "HGNN 0.5: 1-32-16-3                            0.8357  0.8357   0.7937   \n",
       "HGNN 0.1: 1-32-16-3                            0.7343  0.7343   0.7307   \n",
       "HGNN 0.05: 1-32-16-3                           0.7308  0.7308   0.6812   \n",
       "HGNN 0.01: 1-32-16-3                           0.8287  0.8287   0.5686   \n",
       "HGNN 0.5: 1-16-32-16-3                         0.8427  0.8427   0.8179   \n",
       "HGNN 0.1: 1-16-32-16-3                         0.7168  0.7168   0.7177   \n",
       "HGNN 0.05: 1-16-32-16-3                        0.7203  0.7203   0.6765   \n",
       "HGNN 0.01: 1-16-32-16-3                        0.8322  0.8322   0.5708   \n",
       "HGNN 0.5: 1-32-64-3                            0.8287  0.8287   0.8001   \n",
       "HGNN 0.1: 1-32-64-3                            0.7238  0.7238   0.7230   \n",
       "HGNN 0.05: 1-32-64-3                           0.7133  0.7133   0.6628   \n",
       "HGNN 0.01: 1-32-64-3                           0.8322  0.8322   0.5685   \n",
       "HGNN 0.5: 1-4-16-3                             0.8462  0.8462   0.8192   \n",
       "HGNN 0.1: 1-4-16-3                             0.7413  0.7413   0.7405   \n",
       "HGNN 0.05: 1-4-16-3                            0.7343  0.7343   0.6917   \n",
       "HGNN 0.01: 1-4-16-3                            0.8287  0.8287   0.5668   \n",
       "combi 0.5: 17-80-50-3/1-16-32-3/6-3            0.8392  0.8392   0.8131   \n",
       "combi 0.1: 17-80-50-3/1-16-32-3/6-3            0.7168  0.7168   0.7140   \n",
       "combi 0.05: 17-80-50-3/1-16-32-3/6-3           0.7413  0.7413   0.7024   \n",
       "combi 0.01: 17-80-50-3/1-16-32-3/6-3           0.8252  0.8252   0.5646   \n",
       "combi 0.5: 17-80-50-5/1-16-32-5/10-3           0.8287  0.8287   0.8068   \n",
       "combi 0.1: 17-80-50-5/1-16-32-5/10-3           0.7308  0.7308   0.7295   \n",
       "combi 0.05: 17-80-50-5/1-16-32-5/10-3          0.7378  0.7378   0.7079   \n",
       "combi 0.01: 17-80-50-5/1-16-32-5/10-3          0.8217  0.8217   0.5619   \n",
       "combi 0.5: 17-80-50-5/1-16-32-5/10-20-3        0.8776  0.8776   0.8463   \n",
       "combi 0.1: 17-80-50-5/1-16-32-5/10-20-3        0.7378  0.7378   0.7312   \n",
       "combi 0.05: 17-80-50-5/1-16-32-5/10-20-3       0.7727  0.7727   0.7286   \n",
       "combi 0.01: 17-80-50-5/1-16-32-5/10-20-3       0.8392  0.8392   0.5724   \n",
       "combi 0.5: 17-80-50-10/1-16-32-10/20-40-3      0.8846  0.8846   0.8525   \n",
       "combi 0.1: 17-80-50-10/1-16-32-10/20-40-3      0.7168  0.7168   0.7093   \n",
       "combi 0.05: 17-80-50-10/1-16-32-10/20-40-3     0.7448  0.7448   0.6795   \n",
       "combi 0.01: 17-80-50-10/1-16-32-10/20-40-3     0.8601  0.8601   0.5873   \n",
       "combi 0.5: 17-80-50-10/1-16-32-10/20-60-20-3   0.8811  0.8811   0.8551   \n",
       "combi 0.1: 17-80-50-10/1-16-32-10/20-60-20-3   0.7168  0.7168   0.7096   \n",
       "combi 0.05: 17-80-50-10/1-16-32-10/20-60-20-3  0.7448  0.7448   0.7044   \n",
       "combi 0.01: 17-80-50-10/1-16-32-10/20-60-20-3  0.8357  0.8357   0.5711   \n",
       "\n",
       "                                                  acc rec-mic rec-mac  \n",
       "5-NN 0.5                                       0.7941  0.7941  0.7542  \n",
       "5-NN 0.1                                       0.7032  0.7032  0.6835  \n",
       "5-NN 0.05                                       0.737   0.737  0.6656  \n",
       "5-NN 0.01                                       0.796   0.796  0.5535  \n",
       "Decision tree 0.5                              0.8042  0.8042  0.7572  \n",
       "Decision tree 0.1                              0.7405  0.7405  0.7214  \n",
       "Decision tree 0.05                             0.7607  0.7607   0.696  \n",
       "Decision tree 0.01                             0.8139  0.8139  0.5743  \n",
       "Random forest 0.5                              0.8073  0.8073  0.7572  \n",
       "Random forest 0.1                              0.7366  0.7366  0.7188  \n",
       "Random forest 0.05                             0.7618  0.7618  0.7025  \n",
       "Random forest 0.01                              0.812   0.812  0.5738  \n",
       "SVM linear 0.5                                 0.6861  0.6861  0.5925  \n",
       "SVM linear 0.1                                 0.5614  0.5614  0.5639  \n",
       "SVM linear 0.05                                0.5765  0.5765  0.4584  \n",
       "SVM linear 0.01                                 0.634   0.634   0.434  \n",
       "SVM poly 0.5                                   0.6915  0.6915  0.5925  \n",
       "SVM poly 0.1                                   0.5354  0.5354  0.5051  \n",
       "SVM poly 0.05                                  0.6018  0.6018  0.4841  \n",
       "SVM poly 0.01                                  0.6585  0.6585  0.4415  \n",
       "SVM rbf 0.5                                    0.7032  0.7032  0.6235  \n",
       "SVM rbf 0.1                                    0.5287  0.5287  0.5001  \n",
       "SVM rbf 0.05                                   0.5839  0.5839  0.4651  \n",
       "SVM rbf 0.01                                   0.6461  0.6461   0.436  \n",
       "MLP 0.5: 17-5-3                                     -       -       -  \n",
       "MLP 0.1: 17-5-3                                     -       -       -  \n",
       "MLP 0.05: 17-5-3                                    -       -       -  \n",
       "MLP 0.01: 17-5-3                                    -       -       -  \n",
       "MLP 0.5: 17-10-3                                    -       -       -  \n",
       "MLP 0.1: 17-10-3                                    -       -       -  \n",
       "MLP 0.05: 17-10-3                                   -       -       -  \n",
       "MLP 0.01: 17-10-3                                   -       -       -  \n",
       "MLP 0.5: 17-20-3                                    -       -       -  \n",
       "MLP 0.1: 17-20-3                                    -       -       -  \n",
       "MLP 0.05: 17-20-3                                   -       -       -  \n",
       "MLP 0.01: 17-20-3                                   -       -       -  \n",
       "MLP 0.5: 17-25-3                                    -       -       -  \n",
       "MLP 0.1: 17-25-3                                    -       -       -  \n",
       "MLP 0.05: 17-25-3                                   -       -       -  \n",
       "MLP 0.01: 17-25-3                                   -       -       -  \n",
       "MLP 0.5: 17-40-3                                    -       -       -  \n",
       "MLP 0.1: 17-40-3                                    -       -       -  \n",
       "MLP 0.05: 17-40-3                                   -       -       -  \n",
       "MLP 0.01: 17-40-3                                   -       -       -  \n",
       "MLP 0.5: 17-60-3                                    -       -       -  \n",
       "MLP 0.1: 17-60-3                                    -       -       -  \n",
       "MLP 0.05: 17-60-3                                   -       -       -  \n",
       "MLP 0.01: 17-60-3                                   -       -       -  \n",
       "MLP 0.5: 17-10-5-3                                  -       -       -  \n",
       "MLP 0.1: 17-10-5-3                                  -       -       -  \n",
       "MLP 0.05: 17-10-5-3                                 -       -       -  \n",
       "MLP 0.01: 17-10-5-3                                 -       -       -  \n",
       "MLP 0.5: 17-20-10-3                                 -       -       -  \n",
       "MLP 0.1: 17-20-10-3                                 -       -       -  \n",
       "MLP 0.05: 17-20-10-3                                -       -       -  \n",
       "MLP 0.01: 17-20-10-3                                -       -       -  \n",
       "MLP 0.5: 17-40-20-3                                 -       -       -  \n",
       "MLP 0.1: 17-40-20-3                                 -       -       -  \n",
       "MLP 0.05: 17-40-20-3                                -       -       -  \n",
       "MLP 0.01: 17-40-20-3                                -       -       -  \n",
       "MLP 0.5: 17-40-10-3                                 -       -       -  \n",
       "MLP 0.1: 17-40-10-3                                 -       -       -  \n",
       "MLP 0.05: 17-40-10-3                                -       -       -  \n",
       "MLP 0.01: 17-40-10-3                                -       -       -  \n",
       "MLP 0.5: 17-60-40-3                                 -       -       -  \n",
       "MLP 0.1: 17-60-40-3                                 -       -       -  \n",
       "MLP 0.05: 17-60-40-3                                -       -       -  \n",
       "MLP 0.01: 17-60-40-3                                -       -       -  \n",
       "MLP 0.5: 17-60-20-3                                 -       -       -  \n",
       "MLP 0.1: 17-60-20-3                                 -       -       -  \n",
       "MLP 0.05: 17-60-20-3                                -       -       -  \n",
       "MLP 0.01: 17-60-20-3                                -       -       -  \n",
       "MLP 0.5: 17-80-50-3                                 -       -       -  \n",
       "MLP 0.1: 17-80-50-3                                 -       -       -  \n",
       "MLP 0.05: 17-80-50-3                                -       -       -  \n",
       "MLP 0.01: 17-80-50-3                                -       -       -  \n",
       "MLP 0.5, small_median: 7-80-50-3                    -       -       -  \n",
       "MLP 0.1, small_median: 7-80-50-3                    -       -       -  \n",
       "MLP 0.05, small_median: 7-80-50-3                   -       -       -  \n",
       "MLP 0.01, small_median: 7-80-50-3                   -       -       -  \n",
       "MLP 0.5, small_mean: 7-80-50-3                      -       -       -  \n",
       "MLP 0.1, small_mean: 7-80-50-3                      -       -       -  \n",
       "MLP 0.05, small_mean: 7-80-50-3                     -       -       -  \n",
       "MLP 0.01, small_mean: 7-80-50-3                     -       -       -  \n",
       "MLP 0.5, small_min: 7-80-50-3                       -       -       -  \n",
       "MLP 0.1, small_min: 7-80-50-3                       -       -       -  \n",
       "MLP 0.05, small_min: 7-80-50-3                      -       -       -  \n",
       "MLP 0.01, small_min: 7-80-50-3                      -       -       -  \n",
       "MLP 0.5, small_max: 7-80-50-3                       -       -       -  \n",
       "MLP 0.1, small_max: 7-80-50-3                       -       -       -  \n",
       "MLP 0.05, small_max: 7-80-50-3                      -       -       -  \n",
       "MLP 0.01, small_max: 7-80-50-3                      -       -       -  \n",
       "MLP 0.5, small_q25: 7-80-50-3                       -       -       -  \n",
       "MLP 0.1, small_q25: 7-80-50-3                       -       -       -  \n",
       "MLP 0.05, small_q25: 7-80-50-3                      -       -       -  \n",
       "MLP 0.01, small_q25: 7-80-50-3                      -       -       -  \n",
       "MLP 0.5, small_q75: 7-80-50-3                       -       -       -  \n",
       "MLP 0.1, small_q75: 7-80-50-3                       -       -       -  \n",
       "MLP 0.05, small_q75: 7-80-50-3                      -       -       -  \n",
       "MLP 0.01, small_q75: 7-80-50-3                      -       -       -  \n",
       "MLP 0.5, custom: 7-80-50-3                          -       -       -  \n",
       "MLP 0.1, custom: 7-80-50-3                          -       -       -  \n",
       "MLP 0.05, custom: 7-80-50-3                         -       -       -  \n",
       "MLP 0.01, custom: 7-80-50-3                         -       -       -  \n",
       "HGNN 0.5: 1-16-32-3                                 -       -       -  \n",
       "HGNN 0.1: 1-16-32-3                                 -       -       -  \n",
       "HGNN 0.05: 1-16-32-3                                -       -       -  \n",
       "HGNN 0.01: 1-16-32-3                                -       -       -  \n",
       "HGNN 0.5: 1-32-16-3                                 -       -       -  \n",
       "HGNN 0.1: 1-32-16-3                                 -       -       -  \n",
       "HGNN 0.05: 1-32-16-3                                -       -       -  \n",
       "HGNN 0.01: 1-32-16-3                                -       -       -  \n",
       "HGNN 0.5: 1-16-32-16-3                              -       -       -  \n",
       "HGNN 0.1: 1-16-32-16-3                              -       -       -  \n",
       "HGNN 0.05: 1-16-32-16-3                             -       -       -  \n",
       "HGNN 0.01: 1-16-32-16-3                             -       -       -  \n",
       "HGNN 0.5: 1-32-64-3                                 -       -       -  \n",
       "HGNN 0.1: 1-32-64-3                                 -       -       -  \n",
       "HGNN 0.05: 1-32-64-3                                -       -       -  \n",
       "HGNN 0.01: 1-32-64-3                                -       -       -  \n",
       "HGNN 0.5: 1-4-16-3                                  -       -       -  \n",
       "HGNN 0.1: 1-4-16-3                                  -       -       -  \n",
       "HGNN 0.05: 1-4-16-3                                 -       -       -  \n",
       "HGNN 0.01: 1-4-16-3                                 -       -       -  \n",
       "combi 0.5: 17-80-50-3/1-16-32-3/6-3                 -       -       -  \n",
       "combi 0.1: 17-80-50-3/1-16-32-3/6-3                 -       -       -  \n",
       "combi 0.05: 17-80-50-3/1-16-32-3/6-3                -       -       -  \n",
       "combi 0.01: 17-80-50-3/1-16-32-3/6-3                -       -       -  \n",
       "combi 0.5: 17-80-50-5/1-16-32-5/10-3                -       -       -  \n",
       "combi 0.1: 17-80-50-5/1-16-32-5/10-3                -       -       -  \n",
       "combi 0.05: 17-80-50-5/1-16-32-5/10-3               -       -       -  \n",
       "combi 0.01: 17-80-50-5/1-16-32-5/10-3               -       -       -  \n",
       "combi 0.5: 17-80-50-5/1-16-32-5/10-20-3             -       -       -  \n",
       "combi 0.1: 17-80-50-5/1-16-32-5/10-20-3             -       -       -  \n",
       "combi 0.05: 17-80-50-5/1-16-32-5/10-20-3            -       -       -  \n",
       "combi 0.01: 17-80-50-5/1-16-32-5/10-20-3            -       -       -  \n",
       "combi 0.5: 17-80-50-10/1-16-32-10/20-40-3           -       -       -  \n",
       "combi 0.1: 17-80-50-10/1-16-32-10/20-40-3           -       -       -  \n",
       "combi 0.05: 17-80-50-10/1-16-32-10/20-40-3          -       -       -  \n",
       "combi 0.01: 17-80-50-10/1-16-32-10/20-40-3          -       -       -  \n",
       "combi 0.5: 17-80-50-10/1-16-32-10/20-60-20-3        -       -       -  \n",
       "combi 0.1: 17-80-50-10/1-16-32-10/20-60-20-3        -       -       -  \n",
       "combi 0.05: 17-80-50-10/1-16-32-10/20-60-20-3       -       -       -  \n",
       "combi 0.01: 17-80-50-10/1-16-32-10/20-60-20-3       -       -       -  "
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def round_if_number(x):\n",
    "    try:\n",
    "        return round(float(x), 4)\n",
    "    except ValueError:\n",
    "        return x\n",
    "\n",
    "table_3_classes = table_3_classes.applymap(round_if_number)\n",
    "table_3_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "9f23ecec-bf12-4021-a8d9-8dee0411dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes.to_csv('results/table_3_classes_DDB_rounded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b86c9-50da-4715-9643-c508df55ce90",
   "metadata": {},
   "source": [
    "Save the tables of each cut off seperately, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "5f565165-abb6-48f6-ac35-aa00db55a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes[::4].to_csv(\"results/table_3_classes_05_DDB_rounded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "e313741f-ba1c-4537-9932-b6be32a6e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes[1::4].to_csv(\"results/table_3_classes_01_DDB_rounded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "2d2d985f-8bec-447c-804d-a257ade21189",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes[2::4].to_csv(\"results/table_3_classes_005_DDB_rounded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "d8d31728-15be-4cd3-b3d3-0025626dcefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3_classes[3::4].to_csv(\"results/table_3_classes_001_DDB_rounded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e1b57a-f307-4ce1-bc33-dee8d4910fba",
   "metadata": {},
   "source": [
    "### Combined HGNN for time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "239fda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, label_series, hypergraph_column_name):\n",
    "        # Extract features and convert to tensor\n",
    "        self.X = torch.from_numpy(dataframe.drop(columns=[hypergraph_column_name]).values).float()\n",
    "        \n",
    "        # Extract labels and convert to tensor\n",
    "        self.y = torch.from_numpy(label_series.values).float()\n",
    "        \n",
    "        # Store hypergraph objects\n",
    "        self.hypergraphs = dataframe[hypergraph_column_name].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'data': self.X[index],\n",
    "            'label': self.y[index],\n",
    "            'hypergraph': self.hypergraphs[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "5de8de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_regression(X_training, y_training, X_validation, y_validation, text):\n",
    "    model = CombinedNetwork(random_seed = 20)  \n",
    "\n",
    "    dataset = CustomDataset(X_training, y_training, hypergraph_column_name='hypergraph')\n",
    "    validation = CustomDataset(X_validation, y_validation, hypergraph_column_name='hypergraph')\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for item in dataset:\n",
    "            optimizer.zero_grad()\n",
    "            input_features = item[\"data\"]\n",
    "            input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "            label = item[\"label\"].float().unsqueeze(0)\n",
    "            #print(label.size())\n",
    "            output = model(input_features, input_hg)\n",
    "\n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataset):.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for item in validation:\n",
    "                input_features = item[\"data\"]\n",
    "                input_hg = item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0)\n",
    "                label = item[\"label\"].float().unsqueeze(0)\n",
    "                output = model(input_features, input_hg)\n",
    "                loss = loss_function(output, label)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(validation)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Save the model if the validation loss is the best we've seen so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Saved the best model with validation loss: {val_loss:.4f}')\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for item in validation:\n",
    "            i += 1\n",
    "            output = model(item[\"data\"], item[\"hypergraph\"].H.to_dense().unsqueeze(0).unsqueeze(0))\n",
    "            predicted.append(output.item())\n",
    "\n",
    "    mse = mean_squared_error(y_validation, predicted)\n",
    "    mae = mean_absolute_error(y_validation, predicted)\n",
    "    r2 = r2_score(y_validation, predicted)\n",
    "    \n",
    "    table_time_diff.loc[text] = [mse, mae, r2, \"-\", \"-\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec22f9",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 1\n",
    "*  MLP 17-60-40-2\n",
    "*  HGNN 1-32-64-2\n",
    "*  Combined 4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "a7aeafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(4, 1)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "486ba98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.6797\n",
      "Validation Loss: 0.9763\n",
      "Saved the best model with validation loss: 0.9763\n",
      "Epoch [2/100], Loss: 0.9039\n",
      "Validation Loss: 0.8048\n",
      "Saved the best model with validation loss: 0.8048\n",
      "Epoch [3/100], Loss: 0.8066\n",
      "Validation Loss: 0.7546\n",
      "Saved the best model with validation loss: 0.7546\n",
      "Epoch [4/100], Loss: 0.7622\n",
      "Validation Loss: 0.7224\n",
      "Saved the best model with validation loss: 0.7224\n",
      "Epoch [5/100], Loss: 0.7360\n",
      "Validation Loss: 0.7061\n",
      "Saved the best model with validation loss: 0.7061\n",
      "Epoch [6/100], Loss: 0.7218\n",
      "Validation Loss: 0.7157\n",
      "Epoch [7/100], Loss: 0.7110\n",
      "Validation Loss: 0.6837\n",
      "Saved the best model with validation loss: 0.6837\n",
      "Epoch [8/100], Loss: 0.6964\n",
      "Validation Loss: 0.6680\n",
      "Saved the best model with validation loss: 0.6680\n",
      "Epoch [9/100], Loss: 0.6872\n",
      "Validation Loss: 0.6641\n",
      "Saved the best model with validation loss: 0.6641\n",
      "Epoch [10/100], Loss: 0.6830\n",
      "Validation Loss: 0.6609\n",
      "Saved the best model with validation loss: 0.6609\n",
      "Epoch [11/100], Loss: 0.6760\n",
      "Validation Loss: 0.6590\n",
      "Saved the best model with validation loss: 0.6590\n",
      "Epoch [12/100], Loss: 0.6681\n",
      "Validation Loss: 0.6550\n",
      "Saved the best model with validation loss: 0.6550\n",
      "Epoch [13/100], Loss: 0.6628\n",
      "Validation Loss: 0.6459\n",
      "Saved the best model with validation loss: 0.6459\n",
      "Epoch [14/100], Loss: 0.6553\n",
      "Validation Loss: 0.6464\n",
      "Epoch [15/100], Loss: 0.6490\n",
      "Validation Loss: 0.6529\n",
      "Epoch [16/100], Loss: 0.6457\n",
      "Validation Loss: 0.6376\n",
      "Saved the best model with validation loss: 0.6376\n",
      "Epoch [17/100], Loss: 0.6397\n",
      "Validation Loss: 0.6280\n",
      "Saved the best model with validation loss: 0.6280\n",
      "Epoch [18/100], Loss: 0.6346\n",
      "Validation Loss: 0.6232\n",
      "Saved the best model with validation loss: 0.6232\n",
      "Epoch [19/100], Loss: 0.6327\n",
      "Validation Loss: 0.6361\n",
      "Epoch [20/100], Loss: 0.6286\n",
      "Validation Loss: 0.6277\n",
      "Epoch [21/100], Loss: 0.6254\n",
      "Validation Loss: 0.6197\n",
      "Saved the best model with validation loss: 0.6197\n",
      "Epoch [22/100], Loss: 0.6219\n",
      "Validation Loss: 0.6179\n",
      "Saved the best model with validation loss: 0.6179\n",
      "Epoch [23/100], Loss: 0.6195\n",
      "Validation Loss: 0.6151\n",
      "Saved the best model with validation loss: 0.6151\n",
      "Epoch [24/100], Loss: 0.6157\n",
      "Validation Loss: 0.6214\n",
      "Epoch [25/100], Loss: 0.6127\n",
      "Validation Loss: 0.6284\n",
      "Epoch [26/100], Loss: 0.6150\n",
      "Validation Loss: 0.6209\n",
      "Epoch [27/100], Loss: 0.6117\n",
      "Validation Loss: 0.6059\n",
      "Saved the best model with validation loss: 0.6059\n",
      "Epoch [28/100], Loss: 0.6068\n",
      "Validation Loss: 0.6173\n",
      "Epoch [29/100], Loss: 0.6096\n",
      "Validation Loss: 0.6062\n",
      "Epoch [30/100], Loss: 0.6072\n",
      "Validation Loss: 0.6104\n",
      "Epoch [31/100], Loss: 0.6072\n",
      "Validation Loss: 0.6037\n",
      "Saved the best model with validation loss: 0.6037\n",
      "Epoch [32/100], Loss: 0.6021\n",
      "Validation Loss: 0.6145\n",
      "Epoch [33/100], Loss: 0.6043\n",
      "Validation Loss: 0.6040\n",
      "Epoch [34/100], Loss: 0.6045\n",
      "Validation Loss: 0.6202\n",
      "Epoch [35/100], Loss: 0.5971\n",
      "Validation Loss: 0.6114\n",
      "Epoch [36/100], Loss: 0.5952\n",
      "Validation Loss: 0.6152\n",
      "Epoch [37/100], Loss: 0.5994\n",
      "Validation Loss: 0.6069\n",
      "Epoch [38/100], Loss: 0.5942\n",
      "Validation Loss: 0.6098\n",
      "Epoch [39/100], Loss: 0.5978\n",
      "Validation Loss: 0.6005\n",
      "Saved the best model with validation loss: 0.6005\n",
      "Epoch [40/100], Loss: 0.5926\n",
      "Validation Loss: 0.6133\n",
      "Epoch [41/100], Loss: 0.5918\n",
      "Validation Loss: 0.6113\n",
      "Epoch [42/100], Loss: 0.5923\n",
      "Validation Loss: 0.5905\n",
      "Saved the best model with validation loss: 0.5905\n",
      "Epoch [43/100], Loss: 0.5924\n",
      "Validation Loss: 0.5984\n",
      "Epoch [44/100], Loss: 0.5879\n",
      "Validation Loss: 0.5908\n",
      "Epoch [45/100], Loss: 0.5879\n",
      "Validation Loss: 0.5881\n",
      "Saved the best model with validation loss: 0.5881\n",
      "Epoch [46/100], Loss: 0.5848\n",
      "Validation Loss: 0.5889\n",
      "Epoch [47/100], Loss: 0.5798\n",
      "Validation Loss: 0.5926\n",
      "Epoch [48/100], Loss: 0.5828\n",
      "Validation Loss: 0.5889\n",
      "Epoch [49/100], Loss: 0.5830\n",
      "Validation Loss: 0.5913\n",
      "Epoch [50/100], Loss: 0.5835\n",
      "Validation Loss: 0.5932\n",
      "Epoch [51/100], Loss: 0.5809\n",
      "Validation Loss: 0.6013\n",
      "Epoch [52/100], Loss: 0.5827\n",
      "Validation Loss: 0.5924\n",
      "Epoch [53/100], Loss: 0.5803\n",
      "Validation Loss: 0.5960\n",
      "Epoch [54/100], Loss: 0.5793\n",
      "Validation Loss: 0.5803\n",
      "Saved the best model with validation loss: 0.5803\n",
      "Epoch [55/100], Loss: 0.5807\n",
      "Validation Loss: 0.5784\n",
      "Saved the best model with validation loss: 0.5784\n",
      "Epoch [56/100], Loss: 0.5778\n",
      "Validation Loss: 0.5786\n",
      "Epoch [57/100], Loss: 0.5773\n",
      "Validation Loss: 0.5797\n",
      "Epoch [58/100], Loss: 0.5744\n",
      "Validation Loss: 0.5727\n",
      "Saved the best model with validation loss: 0.5727\n",
      "Epoch [59/100], Loss: 0.5751\n",
      "Validation Loss: 0.5642\n",
      "Saved the best model with validation loss: 0.5642\n",
      "Epoch [60/100], Loss: 0.5776\n",
      "Validation Loss: 0.5667\n",
      "Epoch [61/100], Loss: 0.5739\n",
      "Validation Loss: 0.5619\n",
      "Saved the best model with validation loss: 0.5619\n",
      "Epoch [62/100], Loss: 0.5728\n",
      "Validation Loss: 0.5584\n",
      "Saved the best model with validation loss: 0.5584\n",
      "Epoch [63/100], Loss: 0.5698\n",
      "Validation Loss: 0.5550\n",
      "Saved the best model with validation loss: 0.5550\n",
      "Epoch [64/100], Loss: 0.5719\n",
      "Validation Loss: 0.5661\n",
      "Epoch [65/100], Loss: 0.5673\n",
      "Validation Loss: 0.5607\n",
      "Epoch [66/100], Loss: 0.5738\n",
      "Validation Loss: 0.5677\n",
      "Epoch [67/100], Loss: 0.5698\n",
      "Validation Loss: 0.5669\n",
      "Epoch [68/100], Loss: 0.5654\n",
      "Validation Loss: 0.5568\n",
      "Epoch [69/100], Loss: 0.5708\n",
      "Validation Loss: 0.5606\n",
      "Epoch [70/100], Loss: 0.5666\n",
      "Validation Loss: 0.5460\n",
      "Saved the best model with validation loss: 0.5460\n",
      "Epoch [71/100], Loss: 0.5703\n",
      "Validation Loss: 0.5554\n",
      "Epoch [72/100], Loss: 0.5712\n",
      "Validation Loss: 0.5429\n",
      "Saved the best model with validation loss: 0.5429\n",
      "Epoch [73/100], Loss: 0.5677\n",
      "Validation Loss: 0.5387\n",
      "Saved the best model with validation loss: 0.5387\n",
      "Epoch [74/100], Loss: 0.5663\n",
      "Validation Loss: 0.5480\n",
      "Epoch [75/100], Loss: 0.5643\n",
      "Validation Loss: 0.5533\n",
      "Epoch [76/100], Loss: 0.5667\n",
      "Validation Loss: 0.5653\n",
      "Epoch [77/100], Loss: 0.5606\n",
      "Validation Loss: 0.5606\n",
      "Epoch [78/100], Loss: 0.5641\n",
      "Validation Loss: 0.5618\n",
      "Epoch [79/100], Loss: 0.5587\n",
      "Validation Loss: 0.5507\n",
      "Epoch [80/100], Loss: 0.5625\n",
      "Validation Loss: 0.5472\n",
      "Epoch [81/100], Loss: 0.5599\n",
      "Validation Loss: 0.5576\n",
      "Epoch [82/100], Loss: 0.5591\n",
      "Validation Loss: 0.5636\n",
      "Epoch [83/100], Loss: 0.5679\n",
      "Validation Loss: 0.5701\n",
      "Epoch [84/100], Loss: 0.5653\n",
      "Validation Loss: 0.5553\n",
      "Epoch [85/100], Loss: 0.5604\n",
      "Validation Loss: 0.5511\n",
      "Epoch [86/100], Loss: 0.5652\n",
      "Validation Loss: 0.5526\n",
      "Epoch [87/100], Loss: 0.5651\n",
      "Validation Loss: 0.5464\n",
      "Epoch [88/100], Loss: 0.5654\n",
      "Validation Loss: 0.5403\n",
      "Epoch [89/100], Loss: 0.5630\n",
      "Validation Loss: 0.5383\n",
      "Saved the best model with validation loss: 0.5383\n",
      "Epoch [90/100], Loss: 0.5619\n",
      "Validation Loss: 0.5513\n",
      "Epoch [91/100], Loss: 0.5603\n",
      "Validation Loss: 0.5439\n",
      "Epoch [92/100], Loss: 0.5598\n",
      "Validation Loss: 0.5636\n",
      "Epoch [93/100], Loss: 0.5628\n",
      "Validation Loss: 0.5593\n",
      "Epoch [94/100], Loss: 0.5604\n",
      "Validation Loss: 0.5352\n",
      "Saved the best model with validation loss: 0.5352\n",
      "Epoch [95/100], Loss: 0.5571\n",
      "Validation Loss: 0.5437\n",
      "Epoch [96/100], Loss: 0.5578\n",
      "Validation Loss: 0.5461\n",
      "Epoch [97/100], Loss: 0.5563\n",
      "Validation Loss: 0.5591\n",
      "Epoch [98/100], Loss: 0.5533\n",
      "Validation Loss: 0.5562\n",
      "Epoch [99/100], Loss: 0.5557\n",
      "Validation Loss: 0.5680\n",
      "Epoch [100/100], Loss: 0.5597\n",
      "Validation Loss: 0.5518\n"
     ]
    }
   ],
   "source": [
    "combined_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"combi: 17-60-40-2/1-32-64-2/4-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f134e",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 2\n",
    "*  MLP 17-60-40-5\n",
    "*  HGNN 1-32-64-5\n",
    "*  Combined 10-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "19e2002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "f7b4de78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.6826\n",
      "Validation Loss: 0.9440\n",
      "Saved the best model with validation loss: 0.9440\n",
      "Epoch [2/100], Loss: 0.8867\n",
      "Validation Loss: 0.8009\n",
      "Saved the best model with validation loss: 0.8009\n",
      "Epoch [3/100], Loss: 0.8024\n",
      "Validation Loss: 0.7415\n",
      "Saved the best model with validation loss: 0.7415\n",
      "Epoch [4/100], Loss: 0.7649\n",
      "Validation Loss: 0.7082\n",
      "Saved the best model with validation loss: 0.7082\n",
      "Epoch [5/100], Loss: 0.7375\n",
      "Validation Loss: 0.6869\n",
      "Saved the best model with validation loss: 0.6869\n",
      "Epoch [6/100], Loss: 0.7247\n",
      "Validation Loss: 0.6780\n",
      "Saved the best model with validation loss: 0.6780\n",
      "Epoch [7/100], Loss: 0.7122\n",
      "Validation Loss: 0.6849\n",
      "Epoch [8/100], Loss: 0.7012\n",
      "Validation Loss: 0.6564\n",
      "Saved the best model with validation loss: 0.6564\n",
      "Epoch [9/100], Loss: 0.6930\n",
      "Validation Loss: 0.6530\n",
      "Saved the best model with validation loss: 0.6530\n",
      "Epoch [10/100], Loss: 0.6831\n",
      "Validation Loss: 0.6452\n",
      "Saved the best model with validation loss: 0.6452\n",
      "Epoch [11/100], Loss: 0.6749\n",
      "Validation Loss: 0.6377\n",
      "Saved the best model with validation loss: 0.6377\n",
      "Epoch [12/100], Loss: 0.6730\n",
      "Validation Loss: 0.6445\n",
      "Epoch [13/100], Loss: 0.6699\n",
      "Validation Loss: 0.6421\n",
      "Epoch [14/100], Loss: 0.6653\n",
      "Validation Loss: 0.6325\n",
      "Saved the best model with validation loss: 0.6325\n",
      "Epoch [15/100], Loss: 0.6585\n",
      "Validation Loss: 0.6499\n",
      "Epoch [16/100], Loss: 0.6539\n",
      "Validation Loss: 0.6323\n",
      "Saved the best model with validation loss: 0.6323\n",
      "Epoch [17/100], Loss: 0.6477\n",
      "Validation Loss: 0.6234\n",
      "Saved the best model with validation loss: 0.6234\n",
      "Epoch [18/100], Loss: 0.6452\n",
      "Validation Loss: 0.6112\n",
      "Saved the best model with validation loss: 0.6112\n",
      "Epoch [19/100], Loss: 0.6434\n",
      "Validation Loss: 0.6080\n",
      "Saved the best model with validation loss: 0.6080\n",
      "Epoch [20/100], Loss: 0.6360\n",
      "Validation Loss: 0.5953\n",
      "Saved the best model with validation loss: 0.5953\n",
      "Epoch [21/100], Loss: 0.6302\n",
      "Validation Loss: 0.5898\n",
      "Saved the best model with validation loss: 0.5898\n",
      "Epoch [22/100], Loss: 0.6277\n",
      "Validation Loss: 0.5840\n",
      "Saved the best model with validation loss: 0.5840\n",
      "Epoch [23/100], Loss: 0.6227\n",
      "Validation Loss: 0.5819\n",
      "Saved the best model with validation loss: 0.5819\n",
      "Epoch [24/100], Loss: 0.6205\n",
      "Validation Loss: 0.5707\n",
      "Saved the best model with validation loss: 0.5707\n",
      "Epoch [25/100], Loss: 0.6145\n",
      "Validation Loss: 0.5694\n",
      "Saved the best model with validation loss: 0.5694\n",
      "Epoch [26/100], Loss: 0.6099\n",
      "Validation Loss: 0.5638\n",
      "Saved the best model with validation loss: 0.5638\n",
      "Epoch [27/100], Loss: 0.6074\n",
      "Validation Loss: 0.5605\n",
      "Saved the best model with validation loss: 0.5605\n",
      "Epoch [28/100], Loss: 0.6104\n",
      "Validation Loss: 0.5778\n",
      "Epoch [29/100], Loss: 0.6114\n",
      "Validation Loss: 0.5690\n",
      "Epoch [30/100], Loss: 0.6096\n",
      "Validation Loss: 0.5625\n",
      "Epoch [31/100], Loss: 0.6051\n",
      "Validation Loss: 0.5678\n",
      "Epoch [32/100], Loss: 0.6032\n",
      "Validation Loss: 0.5604\n",
      "Saved the best model with validation loss: 0.5604\n",
      "Epoch [33/100], Loss: 0.5994\n",
      "Validation Loss: 0.5501\n",
      "Saved the best model with validation loss: 0.5501\n",
      "Epoch [34/100], Loss: 0.6016\n",
      "Validation Loss: 0.5557\n",
      "Epoch [35/100], Loss: 0.5983\n",
      "Validation Loss: 0.5618\n",
      "Epoch [36/100], Loss: 0.5968\n",
      "Validation Loss: 0.5675\n",
      "Epoch [37/100], Loss: 0.5962\n",
      "Validation Loss: 0.5618\n",
      "Epoch [38/100], Loss: 0.5934\n",
      "Validation Loss: 0.5593\n",
      "Epoch [39/100], Loss: 0.5935\n",
      "Validation Loss: 0.5573\n",
      "Epoch [40/100], Loss: 0.5879\n",
      "Validation Loss: 0.5554\n",
      "Epoch [41/100], Loss: 0.5887\n",
      "Validation Loss: 0.5584\n",
      "Epoch [42/100], Loss: 0.5852\n",
      "Validation Loss: 0.5551\n",
      "Epoch [43/100], Loss: 0.5829\n",
      "Validation Loss: 0.5533\n",
      "Epoch [44/100], Loss: 0.5838\n",
      "Validation Loss: 0.5519\n",
      "Epoch [45/100], Loss: 0.5796\n",
      "Validation Loss: 0.5492\n",
      "Saved the best model with validation loss: 0.5492\n",
      "Epoch [46/100], Loss: 0.5781\n",
      "Validation Loss: 0.5536\n",
      "Epoch [47/100], Loss: 0.5799\n",
      "Validation Loss: 0.5613\n",
      "Epoch [48/100], Loss: 0.5769\n",
      "Validation Loss: 0.5638\n",
      "Epoch [49/100], Loss: 0.5770\n",
      "Validation Loss: 0.5616\n",
      "Epoch [50/100], Loss: 0.5729\n",
      "Validation Loss: 0.5632\n",
      "Epoch [51/100], Loss: 0.5722\n",
      "Validation Loss: 0.5703\n",
      "Epoch [52/100], Loss: 0.5743\n",
      "Validation Loss: 0.5681\n",
      "Epoch [53/100], Loss: 0.5745\n",
      "Validation Loss: 0.5651\n",
      "Epoch [54/100], Loss: 0.5717\n",
      "Validation Loss: 0.5712\n",
      "Epoch [55/100], Loss: 0.5723\n",
      "Validation Loss: 0.5633\n",
      "Epoch [56/100], Loss: 0.5748\n",
      "Validation Loss: 0.5680\n",
      "Epoch [57/100], Loss: 0.5739\n",
      "Validation Loss: 0.5684\n",
      "Epoch [58/100], Loss: 0.5682\n",
      "Validation Loss: 0.5612\n",
      "Epoch [59/100], Loss: 0.5693\n",
      "Validation Loss: 0.5657\n",
      "Epoch [60/100], Loss: 0.5681\n",
      "Validation Loss: 0.5632\n",
      "Epoch [61/100], Loss: 0.5667\n",
      "Validation Loss: 0.5596\n",
      "Epoch [62/100], Loss: 0.5646\n",
      "Validation Loss: 0.5666\n",
      "Epoch [63/100], Loss: 0.5648\n",
      "Validation Loss: 0.5490\n",
      "Saved the best model with validation loss: 0.5490\n",
      "Epoch [64/100], Loss: 0.5643\n",
      "Validation Loss: 0.5476\n",
      "Saved the best model with validation loss: 0.5476\n",
      "Epoch [65/100], Loss: 0.5663\n",
      "Validation Loss: 0.5594\n",
      "Epoch [66/100], Loss: 0.5615\n",
      "Validation Loss: 0.5640\n",
      "Epoch [67/100], Loss: 0.5672\n",
      "Validation Loss: 0.5591\n",
      "Epoch [68/100], Loss: 0.5617\n",
      "Validation Loss: 0.5467\n",
      "Saved the best model with validation loss: 0.5467\n",
      "Epoch [69/100], Loss: 0.5624\n",
      "Validation Loss: 0.5473\n",
      "Epoch [70/100], Loss: 0.5616\n",
      "Validation Loss: 0.5562\n",
      "Epoch [71/100], Loss: 0.5587\n",
      "Validation Loss: 0.5561\n",
      "Epoch [72/100], Loss: 0.5588\n",
      "Validation Loss: 0.5539\n",
      "Epoch [73/100], Loss: 0.5581\n",
      "Validation Loss: 0.5548\n",
      "Epoch [74/100], Loss: 0.5584\n",
      "Validation Loss: 0.5478\n",
      "Epoch [75/100], Loss: 0.5583\n",
      "Validation Loss: 0.5420\n",
      "Saved the best model with validation loss: 0.5420\n",
      "Epoch [76/100], Loss: 0.5570\n",
      "Validation Loss: 0.5516\n",
      "Epoch [77/100], Loss: 0.5570\n",
      "Validation Loss: 0.5491\n",
      "Epoch [78/100], Loss: 0.5581\n",
      "Validation Loss: 0.5441\n",
      "Epoch [79/100], Loss: 0.5570\n",
      "Validation Loss: 0.5569\n",
      "Epoch [80/100], Loss: 0.5545\n",
      "Validation Loss: 0.5462\n",
      "Epoch [81/100], Loss: 0.5562\n",
      "Validation Loss: 0.5486\n",
      "Epoch [82/100], Loss: 0.5541\n",
      "Validation Loss: 0.5612\n",
      "Epoch [83/100], Loss: 0.5558\n",
      "Validation Loss: 0.5517\n",
      "Epoch [84/100], Loss: 0.5527\n",
      "Validation Loss: 0.5580\n",
      "Epoch [85/100], Loss: 0.5553\n",
      "Validation Loss: 0.5592\n",
      "Epoch [86/100], Loss: 0.5538\n",
      "Validation Loss: 0.5554\n",
      "Epoch [87/100], Loss: 0.5518\n",
      "Validation Loss: 0.5506\n",
      "Epoch [88/100], Loss: 0.5566\n",
      "Validation Loss: 0.5519\n",
      "Epoch [89/100], Loss: 0.5543\n",
      "Validation Loss: 0.5421\n",
      "Epoch [90/100], Loss: 0.5536\n",
      "Validation Loss: 0.5536\n",
      "Epoch [91/100], Loss: 0.5499\n",
      "Validation Loss: 0.5462\n",
      "Epoch [92/100], Loss: 0.5499\n",
      "Validation Loss: 0.5504\n",
      "Epoch [93/100], Loss: 0.5521\n",
      "Validation Loss: 0.5529\n",
      "Epoch [94/100], Loss: 0.5545\n",
      "Validation Loss: 0.5537\n",
      "Epoch [95/100], Loss: 0.5510\n",
      "Validation Loss: 0.5537\n",
      "Epoch [96/100], Loss: 0.5521\n",
      "Validation Loss: 0.5553\n",
      "Epoch [97/100], Loss: 0.5510\n",
      "Validation Loss: 0.5532\n",
      "Epoch [98/100], Loss: 0.5546\n",
      "Validation Loss: 0.5508\n",
      "Epoch [99/100], Loss: 0.5562\n",
      "Validation Loss: 0.5443\n",
      "Epoch [100/100], Loss: 0.5504\n",
      "Validation Loss: 0.5601\n"
     ]
    }
   ],
   "source": [
    "combined_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"combi: 17-60-40-5/1-32-64-5/10-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442903ed",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 3\n",
    "*  MLP 17-60-40-5\n",
    "*  HGNN 1-32-64-5\n",
    "*  Combined 10-20-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "da80b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "0bf95640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.9510\n",
      "Validation Loss: 1.0361\n",
      "Saved the best model with validation loss: 1.0361\n",
      "Epoch [2/100], Loss: 0.9253\n",
      "Validation Loss: 0.7500\n",
      "Saved the best model with validation loss: 0.7500\n",
      "Epoch [3/100], Loss: 0.8017\n",
      "Validation Loss: 0.6858\n",
      "Saved the best model with validation loss: 0.6858\n",
      "Epoch [4/100], Loss: 0.7672\n",
      "Validation Loss: 0.6698\n",
      "Saved the best model with validation loss: 0.6698\n",
      "Epoch [5/100], Loss: 0.7413\n",
      "Validation Loss: 0.6537\n",
      "Saved the best model with validation loss: 0.6537\n",
      "Epoch [6/100], Loss: 0.7301\n",
      "Validation Loss: 0.6471\n",
      "Saved the best model with validation loss: 0.6471\n",
      "Epoch [7/100], Loss: 0.7100\n",
      "Validation Loss: 0.6504\n",
      "Epoch [8/100], Loss: 0.6919\n",
      "Validation Loss: 0.6457\n",
      "Saved the best model with validation loss: 0.6457\n",
      "Epoch [9/100], Loss: 0.6801\n",
      "Validation Loss: 0.6492\n",
      "Epoch [10/100], Loss: 0.6687\n",
      "Validation Loss: 0.6469\n",
      "Epoch [11/100], Loss: 0.6599\n",
      "Validation Loss: 0.6516\n",
      "Epoch [12/100], Loss: 0.6419\n",
      "Validation Loss: 0.6527\n",
      "Epoch [13/100], Loss: 0.6251\n",
      "Validation Loss: 0.6821\n",
      "Epoch [14/100], Loss: 0.6151\n",
      "Validation Loss: 0.6345\n",
      "Saved the best model with validation loss: 0.6345\n",
      "Epoch [15/100], Loss: 0.6030\n",
      "Validation Loss: 0.5963\n",
      "Saved the best model with validation loss: 0.5963\n",
      "Epoch [16/100], Loss: 0.5925\n",
      "Validation Loss: 0.5864\n",
      "Saved the best model with validation loss: 0.5864\n",
      "Epoch [17/100], Loss: 0.5912\n",
      "Validation Loss: 0.5686\n",
      "Saved the best model with validation loss: 0.5686\n",
      "Epoch [18/100], Loss: 0.5858\n",
      "Validation Loss: 0.5452\n",
      "Saved the best model with validation loss: 0.5452\n",
      "Epoch [19/100], Loss: 0.5791\n",
      "Validation Loss: 0.5572\n",
      "Epoch [20/100], Loss: 0.5743\n",
      "Validation Loss: 0.5540\n",
      "Epoch [21/100], Loss: 0.5745\n",
      "Validation Loss: 0.5418\n",
      "Saved the best model with validation loss: 0.5418\n",
      "Epoch [22/100], Loss: 0.5704\n",
      "Validation Loss: 0.5247\n",
      "Saved the best model with validation loss: 0.5247\n",
      "Epoch [23/100], Loss: 0.5665\n",
      "Validation Loss: 0.5296\n",
      "Epoch [24/100], Loss: 0.5604\n",
      "Validation Loss: 0.5204\n",
      "Saved the best model with validation loss: 0.5204\n",
      "Epoch [25/100], Loss: 0.5570\n",
      "Validation Loss: 0.5111\n",
      "Saved the best model with validation loss: 0.5111\n",
      "Epoch [26/100], Loss: 0.5532\n",
      "Validation Loss: 0.4985\n",
      "Saved the best model with validation loss: 0.4985\n",
      "Epoch [27/100], Loss: 0.5450\n",
      "Validation Loss: 0.5017\n",
      "Epoch [28/100], Loss: 0.5478\n",
      "Validation Loss: 0.4852\n",
      "Saved the best model with validation loss: 0.4852\n",
      "Epoch [29/100], Loss: 0.5380\n",
      "Validation Loss: 0.4828\n",
      "Saved the best model with validation loss: 0.4828\n",
      "Epoch [30/100], Loss: 0.5406\n",
      "Validation Loss: 0.4714\n",
      "Saved the best model with validation loss: 0.4714\n",
      "Epoch [31/100], Loss: 0.5382\n",
      "Validation Loss: 0.4849\n",
      "Epoch [32/100], Loss: 0.5324\n",
      "Validation Loss: 0.4723\n",
      "Epoch [33/100], Loss: 0.5322\n",
      "Validation Loss: 0.4656\n",
      "Saved the best model with validation loss: 0.4656\n",
      "Epoch [34/100], Loss: 0.5347\n",
      "Validation Loss: 0.4702\n",
      "Epoch [35/100], Loss: 0.5350\n",
      "Validation Loss: 0.4583\n",
      "Saved the best model with validation loss: 0.4583\n",
      "Epoch [36/100], Loss: 0.5306\n",
      "Validation Loss: 0.4619\n",
      "Epoch [37/100], Loss: 0.5260\n",
      "Validation Loss: 0.4695\n",
      "Epoch [38/100], Loss: 0.5284\n",
      "Validation Loss: 0.4792\n",
      "Epoch [39/100], Loss: 0.5266\n",
      "Validation Loss: 0.4578\n",
      "Saved the best model with validation loss: 0.4578\n",
      "Epoch [40/100], Loss: 0.5200\n",
      "Validation Loss: 0.4637\n",
      "Epoch [41/100], Loss: 0.5216\n",
      "Validation Loss: 0.4491\n",
      "Saved the best model with validation loss: 0.4491\n",
      "Epoch [42/100], Loss: 0.5219\n",
      "Validation Loss: 0.4488\n",
      "Saved the best model with validation loss: 0.4488\n",
      "Epoch [43/100], Loss: 0.5144\n",
      "Validation Loss: 0.4487\n",
      "Saved the best model with validation loss: 0.4487\n",
      "Epoch [44/100], Loss: 0.5186\n",
      "Validation Loss: 0.4309\n",
      "Saved the best model with validation loss: 0.4309\n",
      "Epoch [45/100], Loss: 0.5160\n",
      "Validation Loss: 0.4569\n",
      "Epoch [46/100], Loss: 0.5103\n",
      "Validation Loss: 0.4641\n",
      "Epoch [47/100], Loss: 0.5180\n",
      "Validation Loss: 0.4703\n",
      "Epoch [48/100], Loss: 0.5101\n",
      "Validation Loss: 0.4776\n",
      "Epoch [49/100], Loss: 0.5126\n",
      "Validation Loss: 0.4466\n",
      "Epoch [50/100], Loss: 0.5102\n",
      "Validation Loss: 0.4499\n",
      "Epoch [51/100], Loss: 0.5092\n",
      "Validation Loss: 0.4670\n",
      "Epoch [52/100], Loss: 0.5055\n",
      "Validation Loss: 0.4699\n",
      "Epoch [53/100], Loss: 0.5071\n",
      "Validation Loss: 0.4390\n",
      "Epoch [54/100], Loss: 0.5008\n",
      "Validation Loss: 0.4517\n",
      "Epoch [55/100], Loss: 0.5007\n",
      "Validation Loss: 0.4605\n",
      "Epoch [56/100], Loss: 0.5032\n",
      "Validation Loss: 0.4589\n",
      "Epoch [57/100], Loss: 0.4951\n",
      "Validation Loss: 0.4631\n",
      "Epoch [58/100], Loss: 0.4943\n",
      "Validation Loss: 0.4659\n",
      "Epoch [59/100], Loss: 0.4910\n",
      "Validation Loss: 0.4576\n",
      "Epoch [60/100], Loss: 0.4908\n",
      "Validation Loss: 0.4420\n",
      "Epoch [61/100], Loss: 0.4898\n",
      "Validation Loss: 0.4433\n",
      "Epoch [62/100], Loss: 0.4946\n",
      "Validation Loss: 0.4450\n",
      "Epoch [63/100], Loss: 0.4865\n",
      "Validation Loss: 0.4440\n",
      "Epoch [64/100], Loss: 0.4874\n",
      "Validation Loss: 0.4533\n",
      "Epoch [65/100], Loss: 0.4859\n",
      "Validation Loss: 0.4521\n",
      "Epoch [66/100], Loss: 0.4922\n",
      "Validation Loss: 0.4547\n",
      "Epoch [67/100], Loss: 0.4871\n",
      "Validation Loss: 0.4630\n",
      "Epoch [68/100], Loss: 0.4895\n",
      "Validation Loss: 0.4529\n",
      "Epoch [69/100], Loss: 0.4889\n",
      "Validation Loss: 0.4249\n",
      "Saved the best model with validation loss: 0.4249\n",
      "Epoch [70/100], Loss: 0.4890\n",
      "Validation Loss: 0.4474\n",
      "Epoch [71/100], Loss: 0.4856\n",
      "Validation Loss: 0.4361\n",
      "Epoch [72/100], Loss: 0.4844\n",
      "Validation Loss: 0.4158\n",
      "Saved the best model with validation loss: 0.4158\n",
      "Epoch [73/100], Loss: 0.4793\n",
      "Validation Loss: 0.4236\n",
      "Epoch [74/100], Loss: 0.4844\n",
      "Validation Loss: 0.4176\n",
      "Epoch [75/100], Loss: 0.4744\n",
      "Validation Loss: 0.4153\n",
      "Saved the best model with validation loss: 0.4153\n",
      "Epoch [76/100], Loss: 0.4711\n",
      "Validation Loss: 0.4093\n",
      "Saved the best model with validation loss: 0.4093\n",
      "Epoch [77/100], Loss: 0.4811\n",
      "Validation Loss: 0.4196\n",
      "Epoch [78/100], Loss: 0.4798\n",
      "Validation Loss: 0.4161\n",
      "Epoch [79/100], Loss: 0.4725\n",
      "Validation Loss: 0.4060\n",
      "Saved the best model with validation loss: 0.4060\n",
      "Epoch [80/100], Loss: 0.4777\n",
      "Validation Loss: 0.4279\n",
      "Epoch [81/100], Loss: 0.4775\n",
      "Validation Loss: 0.4275\n",
      "Epoch [82/100], Loss: 0.4750\n",
      "Validation Loss: 0.4149\n",
      "Epoch [83/100], Loss: 0.4727\n",
      "Validation Loss: 0.4044\n",
      "Saved the best model with validation loss: 0.4044\n",
      "Epoch [84/100], Loss: 0.4749\n",
      "Validation Loss: 0.4021\n",
      "Saved the best model with validation loss: 0.4021\n",
      "Epoch [85/100], Loss: 0.4773\n",
      "Validation Loss: 0.4249\n",
      "Epoch [86/100], Loss: 0.4752\n",
      "Validation Loss: 0.4186\n",
      "Epoch [87/100], Loss: 0.4784\n",
      "Validation Loss: 0.3933\n",
      "Saved the best model with validation loss: 0.3933\n",
      "Epoch [88/100], Loss: 0.4716\n",
      "Validation Loss: 0.3946\n",
      "Epoch [89/100], Loss: 0.4764\n",
      "Validation Loss: 0.3927\n",
      "Saved the best model with validation loss: 0.3927\n",
      "Epoch [90/100], Loss: 0.4774\n",
      "Validation Loss: 0.3949\n",
      "Epoch [91/100], Loss: 0.4775\n",
      "Validation Loss: 0.4114\n",
      "Epoch [92/100], Loss: 0.4744\n",
      "Validation Loss: 0.4045\n",
      "Epoch [93/100], Loss: 0.4654\n",
      "Validation Loss: 0.3861\n",
      "Saved the best model with validation loss: 0.3861\n",
      "Epoch [94/100], Loss: 0.4828\n",
      "Validation Loss: 0.4167\n",
      "Epoch [95/100], Loss: 0.4694\n",
      "Validation Loss: 0.4033\n",
      "Epoch [96/100], Loss: 0.4728\n",
      "Validation Loss: 0.3947\n",
      "Epoch [97/100], Loss: 0.4760\n",
      "Validation Loss: 0.4209\n",
      "Epoch [98/100], Loss: 0.4751\n",
      "Validation Loss: 0.4070\n",
      "Epoch [99/100], Loss: 0.4794\n",
      "Validation Loss: 0.3992\n",
      "Epoch [100/100], Loss: 0.4703\n",
      "Validation Loss: 0.4106\n"
     ]
    }
   ],
   "source": [
    "combined_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"combi: 17-60-40-5/1-32-64-5/10-20-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b86f7",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 4\n",
    "*  MLP 17-60-40-10\n",
    "*  HGNN 1-32-64-10\n",
    "*  Combined 20-40-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "54f658dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "53479f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7321\n",
      "Validation Loss: 0.9497\n",
      "Saved the best model with validation loss: 0.9497\n",
      "Epoch [2/100], Loss: 0.9119\n",
      "Validation Loss: 0.7165\n",
      "Saved the best model with validation loss: 0.7165\n",
      "Epoch [3/100], Loss: 0.8300\n",
      "Validation Loss: 0.6729\n",
      "Saved the best model with validation loss: 0.6729\n",
      "Epoch [4/100], Loss: 0.7878\n",
      "Validation Loss: 0.6666\n",
      "Saved the best model with validation loss: 0.6666\n",
      "Epoch [5/100], Loss: 0.7620\n",
      "Validation Loss: 0.6836\n",
      "Epoch [6/100], Loss: 0.7380\n",
      "Validation Loss: 0.6739\n",
      "Epoch [7/100], Loss: 0.7207\n",
      "Validation Loss: 0.6390\n",
      "Saved the best model with validation loss: 0.6390\n",
      "Epoch [8/100], Loss: 0.6878\n",
      "Validation Loss: 0.6173\n",
      "Saved the best model with validation loss: 0.6173\n",
      "Epoch [9/100], Loss: 0.6642\n",
      "Validation Loss: 0.6116\n",
      "Saved the best model with validation loss: 0.6116\n",
      "Epoch [10/100], Loss: 0.6475\n",
      "Validation Loss: 0.5922\n",
      "Saved the best model with validation loss: 0.5922\n",
      "Epoch [11/100], Loss: 0.6306\n",
      "Validation Loss: 0.5545\n",
      "Saved the best model with validation loss: 0.5545\n",
      "Epoch [12/100], Loss: 0.6190\n",
      "Validation Loss: 0.6061\n",
      "Epoch [13/100], Loss: 0.6025\n",
      "Validation Loss: 0.5549\n",
      "Epoch [14/100], Loss: 0.5941\n",
      "Validation Loss: 0.5267\n",
      "Saved the best model with validation loss: 0.5267\n",
      "Epoch [15/100], Loss: 0.5854\n",
      "Validation Loss: 0.5069\n",
      "Saved the best model with validation loss: 0.5069\n",
      "Epoch [16/100], Loss: 0.5790\n",
      "Validation Loss: 0.5018\n",
      "Saved the best model with validation loss: 0.5018\n",
      "Epoch [17/100], Loss: 0.5735\n",
      "Validation Loss: 0.5265\n",
      "Epoch [18/100], Loss: 0.5694\n",
      "Validation Loss: 0.4912\n",
      "Saved the best model with validation loss: 0.4912\n",
      "Epoch [19/100], Loss: 0.5678\n",
      "Validation Loss: 0.5419\n",
      "Epoch [20/100], Loss: 0.5631\n",
      "Validation Loss: 0.5218\n",
      "Epoch [21/100], Loss: 0.5625\n",
      "Validation Loss: 0.4753\n",
      "Saved the best model with validation loss: 0.4753\n",
      "Epoch [22/100], Loss: 0.5611\n",
      "Validation Loss: 0.4919\n",
      "Epoch [23/100], Loss: 0.5527\n",
      "Validation Loss: 0.4661\n",
      "Saved the best model with validation loss: 0.4661\n",
      "Epoch [24/100], Loss: 0.5541\n",
      "Validation Loss: 0.4931\n",
      "Epoch [25/100], Loss: 0.5508\n",
      "Validation Loss: 0.4906\n",
      "Epoch [26/100], Loss: 0.5527\n",
      "Validation Loss: 0.4804\n",
      "Epoch [27/100], Loss: 0.5410\n",
      "Validation Loss: 0.4424\n",
      "Saved the best model with validation loss: 0.4424\n",
      "Epoch [28/100], Loss: 0.5357\n",
      "Validation Loss: 0.4610\n",
      "Epoch [29/100], Loss: 0.5340\n",
      "Validation Loss: 0.4785\n",
      "Epoch [30/100], Loss: 0.5429\n",
      "Validation Loss: 0.4651\n",
      "Epoch [31/100], Loss: 0.5303\n",
      "Validation Loss: 0.4545\n",
      "Epoch [32/100], Loss: 0.5314\n",
      "Validation Loss: 0.4741\n",
      "Epoch [33/100], Loss: 0.5257\n",
      "Validation Loss: 0.4561\n",
      "Epoch [34/100], Loss: 0.5282\n",
      "Validation Loss: 0.4564\n",
      "Epoch [35/100], Loss: 0.5231\n",
      "Validation Loss: 0.4645\n",
      "Epoch [36/100], Loss: 0.5216\n",
      "Validation Loss: 0.4377\n",
      "Saved the best model with validation loss: 0.4377\n",
      "Epoch [37/100], Loss: 0.5238\n",
      "Validation Loss: 0.4312\n",
      "Saved the best model with validation loss: 0.4312\n",
      "Epoch [38/100], Loss: 0.5180\n",
      "Validation Loss: 0.4388\n",
      "Epoch [39/100], Loss: 0.5140\n",
      "Validation Loss: 0.4457\n",
      "Epoch [40/100], Loss: 0.5128\n",
      "Validation Loss: 0.4596\n",
      "Epoch [41/100], Loss: 0.5153\n",
      "Validation Loss: 0.4509\n",
      "Epoch [42/100], Loss: 0.5106\n",
      "Validation Loss: 0.4462\n",
      "Epoch [43/100], Loss: 0.5191\n",
      "Validation Loss: 0.4370\n",
      "Epoch [44/100], Loss: 0.5100\n",
      "Validation Loss: 0.4383\n",
      "Epoch [45/100], Loss: 0.5086\n",
      "Validation Loss: 0.4199\n",
      "Saved the best model with validation loss: 0.4199\n",
      "Epoch [46/100], Loss: 0.5005\n",
      "Validation Loss: 0.4480\n",
      "Epoch [47/100], Loss: 0.5000\n",
      "Validation Loss: 0.4177\n",
      "Saved the best model with validation loss: 0.4177\n",
      "Epoch [48/100], Loss: 0.5061\n",
      "Validation Loss: 0.4261\n",
      "Epoch [49/100], Loss: 0.5012\n",
      "Validation Loss: 0.4350\n",
      "Epoch [50/100], Loss: 0.5025\n",
      "Validation Loss: 0.4266\n",
      "Epoch [51/100], Loss: 0.5093\n",
      "Validation Loss: 0.4219\n",
      "Epoch [52/100], Loss: 0.5005\n",
      "Validation Loss: 0.4363\n",
      "Epoch [53/100], Loss: 0.5127\n",
      "Validation Loss: 0.4371\n",
      "Epoch [54/100], Loss: 0.5079\n",
      "Validation Loss: 0.4318\n",
      "Epoch [55/100], Loss: 0.4972\n",
      "Validation Loss: 0.4212\n",
      "Epoch [56/100], Loss: 0.5009\n",
      "Validation Loss: 0.4320\n",
      "Epoch [57/100], Loss: 0.4953\n",
      "Validation Loss: 0.4277\n",
      "Epoch [58/100], Loss: 0.5006\n",
      "Validation Loss: 0.4286\n",
      "Epoch [59/100], Loss: 0.4946\n",
      "Validation Loss: 0.4219\n",
      "Epoch [60/100], Loss: 0.5007\n",
      "Validation Loss: 0.4341\n",
      "Epoch [61/100], Loss: 0.5082\n",
      "Validation Loss: 0.4269\n",
      "Epoch [62/100], Loss: 0.4923\n",
      "Validation Loss: 0.4451\n",
      "Epoch [63/100], Loss: 0.4901\n",
      "Validation Loss: 0.4302\n",
      "Epoch [64/100], Loss: 0.4986\n",
      "Validation Loss: 0.4327\n",
      "Epoch [65/100], Loss: 0.4879\n",
      "Validation Loss: 0.4166\n",
      "Saved the best model with validation loss: 0.4166\n",
      "Epoch [66/100], Loss: 0.4947\n",
      "Validation Loss: 0.4303\n",
      "Epoch [67/100], Loss: 0.4845\n",
      "Validation Loss: 0.4205\n",
      "Epoch [68/100], Loss: 0.4928\n",
      "Validation Loss: 0.4474\n",
      "Epoch [69/100], Loss: 0.4900\n",
      "Validation Loss: 0.4222\n",
      "Epoch [70/100], Loss: 0.4954\n",
      "Validation Loss: 0.4235\n",
      "Epoch [71/100], Loss: 0.4900\n",
      "Validation Loss: 0.4362\n",
      "Epoch [72/100], Loss: 0.4966\n",
      "Validation Loss: 0.4072\n",
      "Saved the best model with validation loss: 0.4072\n",
      "Epoch [73/100], Loss: 0.4897\n",
      "Validation Loss: 0.4079\n",
      "Epoch [74/100], Loss: 0.4934\n",
      "Validation Loss: 0.4365\n",
      "Epoch [75/100], Loss: 0.4852\n",
      "Validation Loss: 0.4195\n",
      "Epoch [76/100], Loss: 0.4925\n",
      "Validation Loss: 0.4066\n",
      "Saved the best model with validation loss: 0.4066\n",
      "Epoch [77/100], Loss: 0.4897\n",
      "Validation Loss: 0.4274\n",
      "Epoch [78/100], Loss: 0.4809\n",
      "Validation Loss: 0.4025\n",
      "Saved the best model with validation loss: 0.4025\n",
      "Epoch [79/100], Loss: 0.4813\n",
      "Validation Loss: 0.3993\n",
      "Saved the best model with validation loss: 0.3993\n",
      "Epoch [80/100], Loss: 0.4917\n",
      "Validation Loss: 0.4131\n",
      "Epoch [81/100], Loss: 0.4849\n",
      "Validation Loss: 0.4067\n",
      "Epoch [82/100], Loss: 0.4846\n",
      "Validation Loss: 0.4101\n",
      "Epoch [83/100], Loss: 0.4966\n",
      "Validation Loss: 0.4190\n",
      "Epoch [84/100], Loss: 0.4829\n",
      "Validation Loss: 0.4069\n",
      "Epoch [85/100], Loss: 0.4846\n",
      "Validation Loss: 0.4049\n",
      "Epoch [86/100], Loss: 0.4775\n",
      "Validation Loss: 0.4040\n",
      "Epoch [87/100], Loss: 0.4840\n",
      "Validation Loss: 0.3796\n",
      "Saved the best model with validation loss: 0.3796\n",
      "Epoch [88/100], Loss: 0.4769\n",
      "Validation Loss: 0.3900\n",
      "Epoch [89/100], Loss: 0.4736\n",
      "Validation Loss: 0.4084\n",
      "Epoch [90/100], Loss: 0.4738\n",
      "Validation Loss: 0.3858\n",
      "Epoch [91/100], Loss: 0.4780\n",
      "Validation Loss: 0.4110\n",
      "Epoch [92/100], Loss: 0.4781\n",
      "Validation Loss: 0.4230\n",
      "Epoch [93/100], Loss: 0.4800\n",
      "Validation Loss: 0.3888\n",
      "Epoch [94/100], Loss: 0.4821\n",
      "Validation Loss: 0.4189\n",
      "Epoch [95/100], Loss: 0.4957\n",
      "Validation Loss: 0.4189\n",
      "Epoch [96/100], Loss: 0.4842\n",
      "Validation Loss: 0.3922\n",
      "Epoch [97/100], Loss: 0.4783\n",
      "Validation Loss: 0.3993\n",
      "Epoch [98/100], Loss: 0.4844\n",
      "Validation Loss: 0.3906\n",
      "Epoch [99/100], Loss: 0.4760\n",
      "Validation Loss: 0.3892\n",
      "Epoch [100/100], Loss: 0.4725\n",
      "Validation Loss: 0.3851\n"
     ]
    }
   ],
   "source": [
    "combined_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"combi: 17-60-40-10/1-32-64-10/20-40-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae2026",
   "metadata": {},
   "source": [
    "#### Combined HGNN: Version 5\n",
    "*  MLP 17-60-40-10\n",
    "*  HGNN 1-32-64-10\n",
    "*  Combined 20-60-20-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "66fe07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, random_seed=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(17, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "class HGNN(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveMaxPool2d((1, 1))  \n",
    "\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        output = self.fc1(x)\n",
    "        return output\n",
    "\n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, random_seed = None):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.feature_net = MLP(random_seed = random_seed)\n",
    "        self.hypergraph_net = HGNN(random_seed = random_seed)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, x):\n",
    "        feature_output = self.feature_net(features)\n",
    "        hypergraph_output = self.hypergraph_net(x)\n",
    "\n",
    "        combined = torch.cat([feature_output] + [hypergraph_output.squeeze()])\n",
    "        \n",
    "        output = self.fc(combined)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "88b22c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7520\n",
      "Validation Loss: 0.9548\n",
      "Saved the best model with validation loss: 0.9548\n",
      "Epoch [2/100], Loss: 0.9366\n",
      "Validation Loss: 0.7204\n",
      "Saved the best model with validation loss: 0.7204\n",
      "Epoch [3/100], Loss: 0.8239\n",
      "Validation Loss: 0.7007\n",
      "Saved the best model with validation loss: 0.7007\n",
      "Epoch [4/100], Loss: 0.7845\n",
      "Validation Loss: 0.6957\n",
      "Saved the best model with validation loss: 0.6957\n",
      "Epoch [5/100], Loss: 0.7628\n",
      "Validation Loss: 0.6958\n",
      "Epoch [6/100], Loss: 0.7350\n",
      "Validation Loss: 0.6887\n",
      "Saved the best model with validation loss: 0.6887\n",
      "Epoch [7/100], Loss: 0.7172\n",
      "Validation Loss: 0.6434\n",
      "Saved the best model with validation loss: 0.6434\n",
      "Epoch [8/100], Loss: 0.6946\n",
      "Validation Loss: 0.6358\n",
      "Saved the best model with validation loss: 0.6358\n",
      "Epoch [9/100], Loss: 0.6784\n",
      "Validation Loss: 0.6507\n",
      "Epoch [10/100], Loss: 0.6631\n",
      "Validation Loss: 0.6337\n",
      "Saved the best model with validation loss: 0.6337\n",
      "Epoch [11/100], Loss: 0.6564\n",
      "Validation Loss: 0.6657\n",
      "Epoch [12/100], Loss: 0.6392\n",
      "Validation Loss: 0.6822\n",
      "Epoch [13/100], Loss: 0.6312\n",
      "Validation Loss: 0.5247\n",
      "Saved the best model with validation loss: 0.5247\n",
      "Epoch [14/100], Loss: 0.6370\n",
      "Validation Loss: 0.5970\n",
      "Epoch [15/100], Loss: 0.6318\n",
      "Validation Loss: 0.6556\n",
      "Epoch [16/100], Loss: 0.6316\n",
      "Validation Loss: 0.5034\n",
      "Saved the best model with validation loss: 0.5034\n",
      "Epoch [17/100], Loss: 0.6135\n",
      "Validation Loss: 0.5057\n",
      "Epoch [18/100], Loss: 0.5988\n",
      "Validation Loss: 0.5029\n",
      "Saved the best model with validation loss: 0.5029\n",
      "Epoch [19/100], Loss: 0.6079\n",
      "Validation Loss: 0.4822\n",
      "Saved the best model with validation loss: 0.4822\n",
      "Epoch [20/100], Loss: 0.5899\n",
      "Validation Loss: 0.5324\n",
      "Epoch [21/100], Loss: 0.5844\n",
      "Validation Loss: 0.5742\n",
      "Epoch [22/100], Loss: 0.5796\n",
      "Validation Loss: 0.4838\n",
      "Epoch [23/100], Loss: 0.5764\n",
      "Validation Loss: 0.4886\n",
      "Epoch [24/100], Loss: 0.5918\n",
      "Validation Loss: 0.5050\n",
      "Epoch [25/100], Loss: 0.5807\n",
      "Validation Loss: 0.4927\n",
      "Epoch [26/100], Loss: 0.5661\n",
      "Validation Loss: 0.5223\n",
      "Epoch [27/100], Loss: 0.5778\n",
      "Validation Loss: 0.5128\n",
      "Epoch [28/100], Loss: 0.5716\n",
      "Validation Loss: 0.4945\n",
      "Epoch [29/100], Loss: 0.5559\n",
      "Validation Loss: 0.4841\n",
      "Epoch [30/100], Loss: 0.5589\n",
      "Validation Loss: 0.4824\n",
      "Epoch [31/100], Loss: 0.5613\n",
      "Validation Loss: 0.4764\n",
      "Saved the best model with validation loss: 0.4764\n",
      "Epoch [32/100], Loss: 0.5452\n",
      "Validation Loss: 0.4727\n",
      "Saved the best model with validation loss: 0.4727\n",
      "Epoch [33/100], Loss: 0.5510\n",
      "Validation Loss: 0.4704\n",
      "Saved the best model with validation loss: 0.4704\n",
      "Epoch [34/100], Loss: 0.5395\n",
      "Validation Loss: 0.4567\n",
      "Saved the best model with validation loss: 0.4567\n",
      "Epoch [35/100], Loss: 0.5489\n",
      "Validation Loss: 0.4754\n",
      "Epoch [36/100], Loss: 0.5415\n",
      "Validation Loss: 0.4863\n",
      "Epoch [37/100], Loss: 0.5380\n",
      "Validation Loss: 0.4646\n",
      "Epoch [38/100], Loss: 0.5354\n",
      "Validation Loss: 0.4242\n",
      "Saved the best model with validation loss: 0.4242\n",
      "Epoch [39/100], Loss: 0.5280\n",
      "Validation Loss: 0.4556\n",
      "Epoch [40/100], Loss: 0.5206\n",
      "Validation Loss: 0.4420\n",
      "Epoch [41/100], Loss: 0.5278\n",
      "Validation Loss: 0.4344\n",
      "Epoch [42/100], Loss: 0.5129\n",
      "Validation Loss: 0.4417\n",
      "Epoch [43/100], Loss: 0.5137\n",
      "Validation Loss: 0.4457\n",
      "Epoch [44/100], Loss: 0.5157\n",
      "Validation Loss: 0.4526\n",
      "Epoch [45/100], Loss: 0.5155\n",
      "Validation Loss: 0.4460\n",
      "Epoch [46/100], Loss: 0.5101\n",
      "Validation Loss: 0.4498\n",
      "Epoch [47/100], Loss: 0.5131\n",
      "Validation Loss: 0.4220\n",
      "Saved the best model with validation loss: 0.4220\n",
      "Epoch [48/100], Loss: 0.5086\n",
      "Validation Loss: 0.4288\n",
      "Epoch [49/100], Loss: 0.5001\n",
      "Validation Loss: 0.4414\n",
      "Epoch [50/100], Loss: 0.5095\n",
      "Validation Loss: 0.4321\n",
      "Epoch [51/100], Loss: 0.5010\n",
      "Validation Loss: 0.4633\n",
      "Epoch [52/100], Loss: 0.5094\n",
      "Validation Loss: 0.4046\n",
      "Saved the best model with validation loss: 0.4046\n",
      "Epoch [53/100], Loss: 0.5058\n",
      "Validation Loss: 0.4206\n",
      "Epoch [54/100], Loss: 0.5027\n",
      "Validation Loss: 0.4275\n",
      "Epoch [55/100], Loss: 0.5102\n",
      "Validation Loss: 0.4148\n",
      "Epoch [56/100], Loss: 0.5084\n",
      "Validation Loss: 0.4069\n",
      "Epoch [57/100], Loss: 0.5049\n",
      "Validation Loss: 0.4153\n",
      "Epoch [58/100], Loss: 0.4970\n",
      "Validation Loss: 0.4351\n",
      "Epoch [59/100], Loss: 0.4915\n",
      "Validation Loss: 0.4296\n",
      "Epoch [60/100], Loss: 0.5028\n",
      "Validation Loss: 0.4000\n",
      "Saved the best model with validation loss: 0.4000\n",
      "Epoch [61/100], Loss: 0.4884\n",
      "Validation Loss: 0.4117\n",
      "Epoch [62/100], Loss: 0.4935\n",
      "Validation Loss: 0.4094\n",
      "Epoch [63/100], Loss: 0.4828\n",
      "Validation Loss: 0.4212\n",
      "Epoch [64/100], Loss: 0.4973\n",
      "Validation Loss: 0.4043\n",
      "Epoch [65/100], Loss: 0.4939\n",
      "Validation Loss: 0.4036\n",
      "Epoch [66/100], Loss: 0.4974\n",
      "Validation Loss: 0.4174\n",
      "Epoch [67/100], Loss: 0.4858\n",
      "Validation Loss: 0.4113\n",
      "Epoch [68/100], Loss: 0.4774\n",
      "Validation Loss: 0.4062\n",
      "Epoch [69/100], Loss: 0.4841\n",
      "Validation Loss: 0.4303\n",
      "Epoch [70/100], Loss: 0.4851\n",
      "Validation Loss: 0.4177\n",
      "Epoch [71/100], Loss: 0.4894\n",
      "Validation Loss: 0.3781\n",
      "Saved the best model with validation loss: 0.3781\n",
      "Epoch [72/100], Loss: 0.4690\n",
      "Validation Loss: 0.4163\n",
      "Epoch [73/100], Loss: 0.4859\n",
      "Validation Loss: 0.4001\n",
      "Epoch [74/100], Loss: 0.4898\n",
      "Validation Loss: 0.4083\n",
      "Epoch [75/100], Loss: 0.4848\n",
      "Validation Loss: 0.4465\n",
      "Epoch [76/100], Loss: 0.4827\n",
      "Validation Loss: 0.4120\n",
      "Epoch [77/100], Loss: 0.4807\n",
      "Validation Loss: 0.4162\n",
      "Epoch [78/100], Loss: 0.4756\n",
      "Validation Loss: 0.4052\n",
      "Epoch [79/100], Loss: 0.4726\n",
      "Validation Loss: 0.4539\n",
      "Epoch [80/100], Loss: 0.4803\n",
      "Validation Loss: 0.4187\n",
      "Epoch [81/100], Loss: 0.4954\n",
      "Validation Loss: 0.4250\n",
      "Epoch [82/100], Loss: 0.4848\n",
      "Validation Loss: 0.3805\n",
      "Epoch [83/100], Loss: 0.4888\n",
      "Validation Loss: 0.3927\n",
      "Epoch [84/100], Loss: 0.4777\n",
      "Validation Loss: 0.4038\n",
      "Epoch [85/100], Loss: 0.4848\n",
      "Validation Loss: 0.3954\n",
      "Epoch [86/100], Loss: 0.4780\n",
      "Validation Loss: 0.3840\n",
      "Epoch [87/100], Loss: 0.4913\n",
      "Validation Loss: 0.3778\n",
      "Saved the best model with validation loss: 0.3778\n",
      "Epoch [88/100], Loss: 0.4740\n",
      "Validation Loss: 0.3799\n",
      "Epoch [89/100], Loss: 0.4903\n",
      "Validation Loss: 0.4254\n",
      "Epoch [90/100], Loss: 0.4797\n",
      "Validation Loss: 0.3891\n",
      "Epoch [91/100], Loss: 0.4762\n",
      "Validation Loss: 0.4031\n",
      "Epoch [92/100], Loss: 0.4647\n",
      "Validation Loss: 0.3918\n",
      "Epoch [93/100], Loss: 0.4954\n",
      "Validation Loss: 0.4028\n",
      "Epoch [94/100], Loss: 0.4810\n",
      "Validation Loss: 0.3923\n",
      "Epoch [95/100], Loss: 0.4720\n",
      "Validation Loss: 0.4099\n",
      "Epoch [96/100], Loss: 0.4838\n",
      "Validation Loss: 0.3795\n",
      "Epoch [97/100], Loss: 0.4756\n",
      "Validation Loss: 0.3854\n",
      "Epoch [98/100], Loss: 0.4689\n",
      "Validation Loss: 0.3927\n",
      "Epoch [99/100], Loss: 0.4767\n",
      "Validation Loss: 0.4060\n",
      "Epoch [100/100], Loss: 0.4660\n",
      "Validation Loss: 0.3851\n"
     ]
    }
   ],
   "source": [
    "combined_regression(X_train_hg, y1_diff_log_train, X_val_hg, y1_diff_log_val, \"combi: 17-60-40-10/1-32-64-10/20-60-20-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "8aedd500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.587345</td>\n",
       "      <td>0.486148</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.480216</td>\n",
       "      <td>0.79731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.490544</td>\n",
       "      <td>0.447684</td>\n",
       "      <td>0.827719</td>\n",
       "      <td>0.591385</td>\n",
       "      <td>0.455429</td>\n",
       "      <td>0.812813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.489989</td>\n",
       "      <td>0.448514</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.573214</td>\n",
       "      <td>0.453536</td>\n",
       "      <td>0.818565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>1.696579</td>\n",
       "      <td>0.788013</td>\n",
       "      <td>0.404154</td>\n",
       "      <td>1.859457</td>\n",
       "      <td>0.828425</td>\n",
       "      <td>0.411439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.741289</td>\n",
       "      <td>0.752971</td>\n",
       "      <td>0.388452</td>\n",
       "      <td>1.829105</td>\n",
       "      <td>0.784481</td>\n",
       "      <td>0.421047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.618412</td>\n",
       "      <td>0.724068</td>\n",
       "      <td>0.431607</td>\n",
       "      <td>1.792327</td>\n",
       "      <td>0.772814</td>\n",
       "      <td>0.432687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-1</th>\n",
       "      <td>1.505071</td>\n",
       "      <td>0.867196</td>\n",
       "      <td>0.471413</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-1</th>\n",
       "      <td>1.554706</td>\n",
       "      <td>0.867515</td>\n",
       "      <td>0.453981</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-1</th>\n",
       "      <td>1.451219</td>\n",
       "      <td>0.828152</td>\n",
       "      <td>0.490326</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-1</th>\n",
       "      <td>1.472163</td>\n",
       "      <td>0.836597</td>\n",
       "      <td>0.482970</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-1</th>\n",
       "      <td>1.444209</td>\n",
       "      <td>0.820480</td>\n",
       "      <td>0.492788</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-1</th>\n",
       "      <td>1.411537</td>\n",
       "      <td>0.821209</td>\n",
       "      <td>0.504262</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-1</th>\n",
       "      <td>1.400415</td>\n",
       "      <td>0.823216</td>\n",
       "      <td>0.508168</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-1</th>\n",
       "      <td>1.345054</td>\n",
       "      <td>0.802008</td>\n",
       "      <td>0.527611</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-1</th>\n",
       "      <td>1.263771</td>\n",
       "      <td>0.772361</td>\n",
       "      <td>0.556158</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-1</th>\n",
       "      <td>1.388075</td>\n",
       "      <td>0.811131</td>\n",
       "      <td>0.512502</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-1</th>\n",
       "      <td>1.009602</td>\n",
       "      <td>0.684272</td>\n",
       "      <td>0.645424</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-1</th>\n",
       "      <td>1.124673</td>\n",
       "      <td>0.718425</td>\n",
       "      <td>0.605010</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-1</th>\n",
       "      <td>1.027500</td>\n",
       "      <td>0.670468</td>\n",
       "      <td>0.639138</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-60-40-1</th>\n",
       "      <td>1.431023</td>\n",
       "      <td>0.786463</td>\n",
       "      <td>0.497419</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-60-40-1</th>\n",
       "      <td>1.403210</td>\n",
       "      <td>0.783605</td>\n",
       "      <td>0.507187</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-60-40-1</th>\n",
       "      <td>1.534875</td>\n",
       "      <td>0.822353</td>\n",
       "      <td>0.460945</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-60-40-1</th>\n",
       "      <td>1.253040</td>\n",
       "      <td>0.759482</td>\n",
       "      <td>0.559927</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-60-40-1</th>\n",
       "      <td>1.458630</td>\n",
       "      <td>0.796491</td>\n",
       "      <td>0.487723</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-60-40-1</th>\n",
       "      <td>1.399672</td>\n",
       "      <td>0.788665</td>\n",
       "      <td>0.508429</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-60-40-1</th>\n",
       "      <td>1.133965</td>\n",
       "      <td>0.721711</td>\n",
       "      <td>0.601747</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-1</th>\n",
       "      <td>0.611047</td>\n",
       "      <td>0.506354</td>\n",
       "      <td>0.785398</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-1</th>\n",
       "      <td>0.660738</td>\n",
       "      <td>0.533360</td>\n",
       "      <td>0.767946</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-1</th>\n",
       "      <td>0.599189</td>\n",
       "      <td>0.501551</td>\n",
       "      <td>0.789562</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-1</th>\n",
       "      <td>0.596895</td>\n",
       "      <td>0.491947</td>\n",
       "      <td>0.790368</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-1</th>\n",
       "      <td>0.613998</td>\n",
       "      <td>0.511419</td>\n",
       "      <td>0.784361</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-60-40-2/1-32-64-2/4-1</th>\n",
       "      <td>0.535205</td>\n",
       "      <td>0.491230</td>\n",
       "      <td>0.812034</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-60-40-5/1-32-64-5/10-2</th>\n",
       "      <td>0.542031</td>\n",
       "      <td>0.495481</td>\n",
       "      <td>0.809636</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-60-40-5/1-32-64-5/10-20-2</th>\n",
       "      <td>0.386088</td>\n",
       "      <td>0.402266</td>\n",
       "      <td>0.864404</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-60-40-10/1-32-64-10/20-40-2</th>\n",
       "      <td>0.379638</td>\n",
       "      <td>0.412707</td>\n",
       "      <td>0.866670</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-60-40-10/1-32-64-10/20-60-20-2</th>\n",
       "      <td>0.377850</td>\n",
       "      <td>0.404648</td>\n",
       "      <td>0.867298</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               MSE       MAE        R2  \\\n",
       "5-NN                                      0.587345  0.486148  0.793722   \n",
       "Decision tree                             0.490544  0.447684  0.827719   \n",
       "Random forest                             0.489989  0.448514  0.827914   \n",
       "SVM linear                                1.696579  0.788013  0.404154   \n",
       "SVM poly                                  1.741289  0.752971  0.388452   \n",
       "SVM rbf                                   1.618412  0.724068  0.431607   \n",
       "MLP: 17-5-1                               1.505071  0.867196  0.471413   \n",
       "MLP: 17-10-1                              1.554706  0.867515  0.453981   \n",
       "MLP: 17-20-1                              1.451219  0.828152  0.490326   \n",
       "MLP: 17-25-1                              1.472163  0.836597  0.482970   \n",
       "MLP: 17-40-1                              1.444209  0.820480  0.492788   \n",
       "MLP: 17-60-1                              1.411537  0.821209  0.504262   \n",
       "MLP: 17-10-5-1                            1.400415  0.823216  0.508168   \n",
       "MLP: 17-20-10-1                           1.345054  0.802008  0.527611   \n",
       "MLP: 17-40-20-1                           1.263771  0.772361  0.556158   \n",
       "MLP: 17-40-10-1                           1.388075  0.811131  0.512502   \n",
       "MLP: 17-60-40-1                           1.009602  0.684272  0.645424   \n",
       "MLP: 17-60-20-1                           1.124673  0.718425  0.605010   \n",
       "MLP: 17-80-50-1                           1.027500  0.670468  0.639138   \n",
       "MLP, small-median: 7-60-40-1              1.431023  0.786463  0.497419   \n",
       "MLP, small-mean: 7-60-40-1                1.403210  0.783605  0.507187   \n",
       "MLP, small-min: 7-60-40-1                 1.534875  0.822353  0.460945   \n",
       "MLP, small-max: 7-60-40-1                 1.253040  0.759482  0.559927   \n",
       "MLP, small-q25: 7-60-40-1                 1.458630  0.796491  0.487723   \n",
       "MLP, small-q75: 7-60-40-1                 1.399672  0.788665  0.508429   \n",
       "MLP, custom: 7-60-40-1                    1.133965  0.721711  0.601747   \n",
       "HGNN: 1-16-32-1                           0.611047  0.506354  0.785398   \n",
       "HGNN: 1-32-16-1                           0.660738  0.533360  0.767946   \n",
       "HGNN: 1-16-32-16-1                        0.599189  0.501551  0.789562   \n",
       "HGNN: 1-32-64-1                           0.596895  0.491947  0.790368   \n",
       "HGNN: 1-4-16-1                            0.613998  0.511419  0.784361   \n",
       "combi: 17-60-40-2/1-32-64-2/4-1           0.535205  0.491230  0.812034   \n",
       "combi: 17-60-40-5/1-32-64-5/10-2          0.542031  0.495481  0.809636   \n",
       "combi: 17-60-40-5/1-32-64-5/10-20-2       0.386088  0.402266  0.864404   \n",
       "combi: 17-60-40-10/1-32-64-10/20-40-2     0.379638  0.412707  0.866670   \n",
       "combi: 17-60-40-10/1-32-64-10/20-60-20-2  0.377850  0.404648  0.867298   \n",
       "\n",
       "                                               MSE       MAE        R2  \n",
       "5-NN                                      0.640365  0.480216   0.79731  \n",
       "Decision tree                             0.591385  0.455429  0.812813  \n",
       "Random forest                             0.573214  0.453536  0.818565  \n",
       "SVM linear                                1.859457  0.828425  0.411439  \n",
       "SVM poly                                  1.829105  0.784481  0.421047  \n",
       "SVM rbf                                   1.792327  0.772814  0.432687  \n",
       "MLP: 17-5-1                                      -         -         -  \n",
       "MLP: 17-10-1                                     -         -         -  \n",
       "MLP: 17-20-1                                     -         -         -  \n",
       "MLP: 17-25-1                                     -         -         -  \n",
       "MLP: 17-40-1                                     -         -         -  \n",
       "MLP: 17-60-1                                     -         -         -  \n",
       "MLP: 17-10-5-1                                   -         -         -  \n",
       "MLP: 17-20-10-1                                  -         -         -  \n",
       "MLP: 17-40-20-1                                  -         -         -  \n",
       "MLP: 17-40-10-1                                  -         -         -  \n",
       "MLP: 17-60-40-1                                  -         -         -  \n",
       "MLP: 17-60-20-1                                  -         -         -  \n",
       "MLP: 17-80-50-1                                  -         -         -  \n",
       "MLP, small-median: 7-60-40-1                     -         -         -  \n",
       "MLP, small-mean: 7-60-40-1                       -         -         -  \n",
       "MLP, small-min: 7-60-40-1                        -         -         -  \n",
       "MLP, small-max: 7-60-40-1                        -         -         -  \n",
       "MLP, small-q25: 7-60-40-1                        -         -         -  \n",
       "MLP, small-q75: 7-60-40-1                        -         -         -  \n",
       "MLP, custom: 7-60-40-1                           -         -         -  \n",
       "HGNN: 1-16-32-1                                  -         -         -  \n",
       "HGNN: 1-32-16-1                                  -         -         -  \n",
       "HGNN: 1-16-32-16-1                               -         -         -  \n",
       "HGNN: 1-32-64-1                                  -         -         -  \n",
       "HGNN: 1-4-16-1                                   -         -         -  \n",
       "combi: 17-60-40-2/1-32-64-2/4-1                  -         -         -  \n",
       "combi: 17-60-40-5/1-32-64-5/10-2                 -         -         -  \n",
       "combi: 17-60-40-5/1-32-64-5/10-20-2              -         -         -  \n",
       "combi: 17-60-40-10/1-32-64-10/20-40-2            -         -         -  \n",
       "combi: 17-60-40-10/1-32-64-10/20-60-20-2         -         -         -  "
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "36176ba7-a233-45d7-ad1b-7eee16ac3334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2526/2575078847.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  table_time_diff = table_time_diff.applymap(round_if_number)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-NN</th>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>0.6404</td>\n",
       "      <td>0.4802</td>\n",
       "      <td>0.7973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.4905</td>\n",
       "      <td>0.4477</td>\n",
       "      <td>0.8277</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.4554</td>\n",
       "      <td>0.8128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4485</td>\n",
       "      <td>0.8279</td>\n",
       "      <td>0.5732</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.8186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM linear</th>\n",
       "      <td>1.6966</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>0.4042</td>\n",
       "      <td>1.8595</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.4114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM poly</th>\n",
       "      <td>1.7413</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.3885</td>\n",
       "      <td>1.8291</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM rbf</th>\n",
       "      <td>1.6184</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>0.4316</td>\n",
       "      <td>1.7923</td>\n",
       "      <td>0.7728</td>\n",
       "      <td>0.4327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-5-1</th>\n",
       "      <td>1.5051</td>\n",
       "      <td>0.8672</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-1</th>\n",
       "      <td>1.5547</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-1</th>\n",
       "      <td>1.4512</td>\n",
       "      <td>0.8282</td>\n",
       "      <td>0.4903</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-25-1</th>\n",
       "      <td>1.4722</td>\n",
       "      <td>0.8366</td>\n",
       "      <td>0.4830</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-1</th>\n",
       "      <td>1.4442</td>\n",
       "      <td>0.8205</td>\n",
       "      <td>0.4928</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-1</th>\n",
       "      <td>1.4115</td>\n",
       "      <td>0.8212</td>\n",
       "      <td>0.5043</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-10-5-1</th>\n",
       "      <td>1.4004</td>\n",
       "      <td>0.8232</td>\n",
       "      <td>0.5082</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-20-10-1</th>\n",
       "      <td>1.3451</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.5276</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-20-1</th>\n",
       "      <td>1.2638</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>0.5562</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-40-10-1</th>\n",
       "      <td>1.3881</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-40-1</th>\n",
       "      <td>1.0096</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.6454</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-60-20-1</th>\n",
       "      <td>1.1247</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP: 17-80-50-1</th>\n",
       "      <td>1.0275</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.6391</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-median: 7-60-40-1</th>\n",
       "      <td>1.4310</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-mean: 7-60-40-1</th>\n",
       "      <td>1.4032</td>\n",
       "      <td>0.7836</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-min: 7-60-40-1</th>\n",
       "      <td>1.5349</td>\n",
       "      <td>0.8224</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-max: 7-60-40-1</th>\n",
       "      <td>1.2530</td>\n",
       "      <td>0.7595</td>\n",
       "      <td>0.5599</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q25: 7-60-40-1</th>\n",
       "      <td>1.4586</td>\n",
       "      <td>0.7965</td>\n",
       "      <td>0.4877</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, small-q75: 7-60-40-1</th>\n",
       "      <td>1.3997</td>\n",
       "      <td>0.7887</td>\n",
       "      <td>0.5084</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP, custom: 7-60-40-1</th>\n",
       "      <td>1.1340</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>0.6017</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-1</th>\n",
       "      <td>0.6110</td>\n",
       "      <td>0.5064</td>\n",
       "      <td>0.7854</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-16-1</th>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>0.7679</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-16-32-16-1</th>\n",
       "      <td>0.5992</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-32-64-1</th>\n",
       "      <td>0.5969</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>0.7904</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGNN: 1-4-16-1</th>\n",
       "      <td>0.6140</td>\n",
       "      <td>0.5114</td>\n",
       "      <td>0.7844</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-60-40-2/1-32-64-2/4-1</th>\n",
       "      <td>0.5352</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.8120</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-60-40-5/1-32-64-5/10-2</th>\n",
       "      <td>0.5420</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-60-40-5/1-32-64-5/10-20-2</th>\n",
       "      <td>0.3861</td>\n",
       "      <td>0.4023</td>\n",
       "      <td>0.8644</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-60-40-10/1-32-64-10/20-40-2</th>\n",
       "      <td>0.3796</td>\n",
       "      <td>0.4127</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combi: 17-60-40-10/1-32-64-10/20-60-20-2</th>\n",
       "      <td>0.3778</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             MSE     MAE      R2     MSE  \\\n",
       "5-NN                                      0.5873  0.4861  0.7937  0.6404   \n",
       "Decision tree                             0.4905  0.4477  0.8277  0.5914   \n",
       "Random forest                             0.4900  0.4485  0.8279  0.5732   \n",
       "SVM linear                                1.6966  0.7880  0.4042  1.8595   \n",
       "SVM poly                                  1.7413  0.7530  0.3885  1.8291   \n",
       "SVM rbf                                   1.6184  0.7241  0.4316  1.7923   \n",
       "MLP: 17-5-1                               1.5051  0.8672  0.4714       -   \n",
       "MLP: 17-10-1                              1.5547  0.8675  0.4540       -   \n",
       "MLP: 17-20-1                              1.4512  0.8282  0.4903       -   \n",
       "MLP: 17-25-1                              1.4722  0.8366  0.4830       -   \n",
       "MLP: 17-40-1                              1.4442  0.8205  0.4928       -   \n",
       "MLP: 17-60-1                              1.4115  0.8212  0.5043       -   \n",
       "MLP: 17-10-5-1                            1.4004  0.8232  0.5082       -   \n",
       "MLP: 17-20-10-1                           1.3451  0.8020  0.5276       -   \n",
       "MLP: 17-40-20-1                           1.2638  0.7724  0.5562       -   \n",
       "MLP: 17-40-10-1                           1.3881  0.8111  0.5125       -   \n",
       "MLP: 17-60-40-1                           1.0096  0.6843  0.6454       -   \n",
       "MLP: 17-60-20-1                           1.1247  0.7184  0.6050       -   \n",
       "MLP: 17-80-50-1                           1.0275  0.6705  0.6391       -   \n",
       "MLP, small-median: 7-60-40-1              1.4310  0.7865  0.4974       -   \n",
       "MLP, small-mean: 7-60-40-1                1.4032  0.7836  0.5072       -   \n",
       "MLP, small-min: 7-60-40-1                 1.5349  0.8224  0.4609       -   \n",
       "MLP, small-max: 7-60-40-1                 1.2530  0.7595  0.5599       -   \n",
       "MLP, small-q25: 7-60-40-1                 1.4586  0.7965  0.4877       -   \n",
       "MLP, small-q75: 7-60-40-1                 1.3997  0.7887  0.5084       -   \n",
       "MLP, custom: 7-60-40-1                    1.1340  0.7217  0.6017       -   \n",
       "HGNN: 1-16-32-1                           0.6110  0.5064  0.7854       -   \n",
       "HGNN: 1-32-16-1                           0.6607  0.5334  0.7679       -   \n",
       "HGNN: 1-16-32-16-1                        0.5992  0.5016  0.7896       -   \n",
       "HGNN: 1-32-64-1                           0.5969  0.4919  0.7904       -   \n",
       "HGNN: 1-4-16-1                            0.6140  0.5114  0.7844       -   \n",
       "combi: 17-60-40-2/1-32-64-2/4-1           0.5352  0.4912  0.8120       -   \n",
       "combi: 17-60-40-5/1-32-64-5/10-2          0.5420  0.4955  0.8096       -   \n",
       "combi: 17-60-40-5/1-32-64-5/10-20-2       0.3861  0.4023  0.8644       -   \n",
       "combi: 17-60-40-10/1-32-64-10/20-40-2     0.3796  0.4127  0.8667       -   \n",
       "combi: 17-60-40-10/1-32-64-10/20-60-20-2  0.3778  0.4046  0.8673       -   \n",
       "\n",
       "                                             MAE      R2  \n",
       "5-NN                                      0.4802  0.7973  \n",
       "Decision tree                             0.4554  0.8128  \n",
       "Random forest                             0.4535  0.8186  \n",
       "SVM linear                                0.8284  0.4114  \n",
       "SVM poly                                  0.7845   0.421  \n",
       "SVM rbf                                   0.7728  0.4327  \n",
       "MLP: 17-5-1                                    -       -  \n",
       "MLP: 17-10-1                                   -       -  \n",
       "MLP: 17-20-1                                   -       -  \n",
       "MLP: 17-25-1                                   -       -  \n",
       "MLP: 17-40-1                                   -       -  \n",
       "MLP: 17-60-1                                   -       -  \n",
       "MLP: 17-10-5-1                                 -       -  \n",
       "MLP: 17-20-10-1                                -       -  \n",
       "MLP: 17-40-20-1                                -       -  \n",
       "MLP: 17-40-10-1                                -       -  \n",
       "MLP: 17-60-40-1                                -       -  \n",
       "MLP: 17-60-20-1                                -       -  \n",
       "MLP: 17-80-50-1                                -       -  \n",
       "MLP, small-median: 7-60-40-1                   -       -  \n",
       "MLP, small-mean: 7-60-40-1                     -       -  \n",
       "MLP, small-min: 7-60-40-1                      -       -  \n",
       "MLP, small-max: 7-60-40-1                      -       -  \n",
       "MLP, small-q25: 7-60-40-1                      -       -  \n",
       "MLP, small-q75: 7-60-40-1                      -       -  \n",
       "MLP, custom: 7-60-40-1                         -       -  \n",
       "HGNN: 1-16-32-1                                -       -  \n",
       "HGNN: 1-32-16-1                                -       -  \n",
       "HGNN: 1-16-32-16-1                             -       -  \n",
       "HGNN: 1-32-64-1                                -       -  \n",
       "HGNN: 1-4-16-1                                 -       -  \n",
       "combi: 17-60-40-2/1-32-64-2/4-1                -       -  \n",
       "combi: 17-60-40-5/1-32-64-5/10-2               -       -  \n",
       "combi: 17-60-40-5/1-32-64-5/10-20-2            -       -  \n",
       "combi: 17-60-40-10/1-32-64-10/20-40-2          -       -  \n",
       "combi: 17-60-40-10/1-32-64-10/20-60-20-2       -       -  "
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def round_if_number(x):\n",
    "    try:\n",
    "        return round(float(x), 4)\n",
    "    except ValueError:\n",
    "        return x\n",
    "\n",
    "table_time_diff = table_time_diff.applymap(round_if_number)\n",
    "table_time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "4c2de776-ad0e-42ad-a1e0-22ff8160b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_time_diff.to_csv('results/table_time_diff_DDB_rounded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399dc07e",
   "metadata": {},
   "source": [
    "## Maximum achievable scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887f7283",
   "metadata": {},
   "source": [
    "Train on the train set and validate on the train set again to see how good the classifier can be having the whole information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "02cd9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2_classes_max_ach = pd.DataFrame(columns=['acc', 'rec'])\n",
    "table_3_classes_max_ach = pd.DataFrame(columns=['acc', 'rec-mic', 'rec_mac'])\n",
    "table_time_diff_max_ach = pd.DataFrame(columns=['MSE', 'MAE', 'R2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647f257e",
   "metadata": {},
   "source": [
    "### Maximum achievable score basic ML models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7379eae7",
   "metadata": {},
   "source": [
    "#### 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "403c858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1085  153]\n",
      " [ 169  881]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.859266</td>\n",
       "      <td>0.839048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec\n",
       "Decision tree  0.859266  0.839048"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_dec_tree = clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y1_train, y1_pred_dec_tree)\n",
    "recall = recall_score(y1_train, y1_pred_dec_tree)\n",
    "conf_matrix = confusion_matrix(y1_train, y1_pred_dec_tree)\n",
    "print(conf_matrix)\n",
    "\n",
    "table_2_classes_max_ach.loc[\"Decision tree\"] = [accuracy, recall]\n",
    "table_2_classes_max_ach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "bfb25b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1066  172]\n",
      " [ 150  900]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.859266</td>\n",
       "      <td>0.839048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.859266</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc       rec\n",
       "Decision tree  0.859266  0.839048\n",
       "Random forest  0.859266  0.857143"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_rand_forest = clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y1_train, y1_pred_rand_forest)\n",
    "recall = recall_score(y1_train, y1_pred_rand_forest)\n",
    "conf_matrix = confusion_matrix(y1_train, y1_pred_rand_forest)\n",
    "print(conf_matrix)\n",
    "\n",
    "table_2_classes_max_ach.loc[\"Random forest\"] = [accuracy, recall]\n",
    "table_2_classes_max_ach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8429821",
   "metadata": {},
   "source": [
    "#### 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "83b58a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 281  132   24]\n",
      " [  39 1088   76]\n",
      " [   7   97  544]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.795644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acc   rec-mic   rec_mac\n",
       "Decision tree 0.5  0.836101  0.836101  0.795644"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_dec_tree = clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y1_equal_05_train, y1_equal_05_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_05_train, y1_equal_05_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_train, y1_equal_05_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_train, y1_equal_05_pred_dec_tree)\n",
    "print(conf_matrix)\n",
    "\n",
    "table_3_classes_max_ach.loc[\"Decision tree 0.5\"] = [accuracy, recall_micro, recall_macro]\n",
    "table_3_classes_max_ach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "934c3680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[741  58  85]\n",
      " [170 353  67]\n",
      " [ 53  58 703]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.795644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.766726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acc   rec-mic   rec_mac\n",
       "Decision tree 0.5  0.836101  0.836101  0.795644\n",
       "Decision tree 0.1  0.785402  0.785402  0.766726"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_dec_tree = clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y1_equal_01_train, y1_equal_01_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_01_train, y1_equal_01_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_train, y1_equal_01_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_train, y1_equal_01_pred_dec_tree)\n",
    "print(conf_matrix)\n",
    "\n",
    "table_3_classes_max_ach.loc[\"Decision tree 0.1\"] = [accuracy, recall_micro, recall_macro]\n",
    "table_3_classes_max_ach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "271ea5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[892  39 104]\n",
      " [116 195  48]\n",
      " [ 93  36 765]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.795644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.766726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.753572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac\n",
       "Decision tree 0.5   0.836101  0.836101  0.795644\n",
       "Decision tree 0.1   0.785402  0.785402  0.766726\n",
       "Decision tree 0.05  0.809441  0.809441  0.753572"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_dec_tree = clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y1_equal_005_train, y1_equal_005_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_005_train, y1_equal_005_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_train, y1_equal_005_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_train, y1_equal_005_pred_dec_tree)\n",
    "print(conf_matrix)\n",
    "\n",
    "table_3_classes_max_ach.loc[\"Decision tree 0.05\"] = [accuracy, recall_micro, recall_macro]\n",
    "table_3_classes_max_ach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "42cf1467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1072    1  132]\n",
      " [  41    6   22]\n",
      " [ 160    1  853]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.795644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.766726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.753572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.605935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac\n",
       "Decision tree 0.5   0.836101  0.836101  0.795644\n",
       "Decision tree 0.1   0.785402  0.785402  0.766726\n",
       "Decision tree 0.05  0.809441  0.809441  0.753572\n",
       "Decision tree 0.01  0.843969  0.843969  0.605935"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_dec_tree = clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y1_equal_001_train, y1_equal_001_pred_dec_tree)\n",
    "recall_micro = recall_score(y1_equal_001_train, y1_equal_001_pred_dec_tree, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_train, y1_equal_001_pred_dec_tree, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_train, y1_equal_001_pred_dec_tree)\n",
    "print(conf_matrix)\n",
    "\n",
    "table_3_classes_max_ach.loc[\"Decision tree 0.01\"] = [accuracy, recall_micro, recall_macro]\n",
    "table_3_classes_max_ach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "a121490e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 261  150   26]\n",
      " [  19 1099   85]\n",
      " [   6   89  553]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.795644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.766726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.753572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.605935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.788066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac\n",
       "Decision tree 0.5   0.836101  0.836101  0.795644\n",
       "Decision tree 0.1   0.785402  0.785402  0.766726\n",
       "Decision tree 0.05  0.809441  0.809441  0.753572\n",
       "Decision tree 0.01  0.843969  0.843969  0.605935\n",
       "Random forest 0.5   0.836101  0.836101  0.788066"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_rand_forest = clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y1_equal_05_train, y1_equal_05_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_05_train, y1_equal_05_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_05_train, y1_equal_05_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_05_train, y1_equal_05_pred_rand_forest)\n",
    "print(conf_matrix)\n",
    "\n",
    "table_3_classes_max_ach.loc[\"Random forest 0.5\"] = [accuracy, recall_micro, recall_macro]\n",
    "table_3_classes_max_ach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "181ed9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[719  79  86]\n",
      " [148 374  68]\n",
      " [ 52  58 704]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.795644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.766726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.753572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.605935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.788066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.770704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac\n",
       "Decision tree 0.5   0.836101  0.836101  0.795644\n",
       "Decision tree 0.1   0.785402  0.785402  0.766726\n",
       "Decision tree 0.05  0.809441  0.809441  0.753572\n",
       "Decision tree 0.01  0.843969  0.843969  0.605935\n",
       "Random forest 0.5   0.836101  0.836101  0.788066\n",
       "Random forest 0.1   0.785402  0.785402  0.770704"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_rand_forest = clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y1_equal_01_train, y1_equal_01_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_01_train, y1_equal_01_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_01_train, y1_equal_01_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_01_train, y1_equal_01_pred_rand_forest)\n",
    "print(conf_matrix)\n",
    "\n",
    "table_3_classes_max_ach.loc[\"Random forest 0.1\"] = [accuracy, recall_micro, recall_macro]\n",
    "table_3_classes_max_ach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "a37a1bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[873  52 110]\n",
      " [ 99 205  55]\n",
      " [ 88  32 774]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.795644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.766726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.753572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.605935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.788066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.770704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.760094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac\n",
       "Decision tree 0.5   0.836101  0.836101  0.795644\n",
       "Decision tree 0.1   0.785402  0.785402  0.766726\n",
       "Decision tree 0.05  0.809441  0.809441  0.753572\n",
       "Decision tree 0.01  0.843969  0.843969  0.605935\n",
       "Random forest 0.5   0.836101  0.836101  0.788066\n",
       "Random forest 0.1   0.785402  0.785402  0.770704\n",
       "Random forest 0.05  0.809441  0.809441  0.760094"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_rand_forest = clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y1_equal_005_train, y1_equal_005_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_005_train, y1_equal_005_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_005_train, y1_equal_005_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_005_train, y1_equal_005_pred_rand_forest)\n",
    "print(conf_matrix)\n",
    "\n",
    "table_3_classes_max_ach.loc[\"Random forest 0.05\"] = [accuracy, recall_micro, recall_macro]\n",
    "table_3_classes_max_ach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "bf55f9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1051    1  153]\n",
      " [  38    6   25]\n",
      " [ 139    1  874]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>rec-mic</th>\n",
       "      <th>rec_mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.795644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.1</th>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.766726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.05</th>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.753572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree 0.01</th>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.605935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.5</th>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.836101</td>\n",
       "      <td>0.788066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.1</th>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.785402</td>\n",
       "      <td>0.770704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.05</th>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.760094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest 0.01</th>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.843969</td>\n",
       "      <td>0.607030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc   rec-mic   rec_mac\n",
       "Decision tree 0.5   0.836101  0.836101  0.795644\n",
       "Decision tree 0.1   0.785402  0.785402  0.766726\n",
       "Decision tree 0.05  0.809441  0.809441  0.753572\n",
       "Decision tree 0.01  0.843969  0.843969  0.605935\n",
       "Random forest 0.5   0.836101  0.836101  0.788066\n",
       "Random forest 0.1   0.785402  0.785402  0.770704\n",
       "Random forest 0.05  0.809441  0.809441  0.760094\n",
       "Random forest 0.01  0.843969  0.843969  0.607030"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_rand_forest = clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y1_equal_001_train, y1_equal_001_pred_rand_forest)\n",
    "recall_micro = recall_score(y1_equal_001_train, y1_equal_001_pred_rand_forest, average='micro')\n",
    "recall_macro = recall_score(y1_equal_001_train, y1_equal_001_pred_rand_forest, average='macro')\n",
    "conf_matrix = confusion_matrix(y1_equal_001_train, y1_equal_001_pred_rand_forest)\n",
    "print(conf_matrix)\n",
    "\n",
    "table_3_classes_max_ach.loc[\"Random forest 0.01\"] = [accuracy, recall_micro, recall_macro]\n",
    "table_3_classes_max_ach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee7d66",
   "metadata": {},
   "source": [
    "#### Time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "1733c46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.457891</td>\n",
       "      <td>0.395721</td>\n",
       "      <td>0.856827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2\n",
       "Decision tree  0.457891  0.395721  0.856827"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(random_state = 20)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_dec_tree = model.predict(X_train)\n",
    "\n",
    "mse = mean_squared_error(y1_diff_log_train, y1_pred_dec_tree)\n",
    "mae = mean_absolute_error(y1_diff_log_train, y1_pred_dec_tree)\n",
    "r2 = r2_score(y1_diff_log_train, y1_pred_dec_tree)\n",
    "\n",
    "table_time_diff_max_ach.loc[\"Decision tree\"] = [mse, mae, r2]\n",
    "table_time_diff_max_ach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "2b0ac326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.457891</td>\n",
       "      <td>0.395721</td>\n",
       "      <td>0.856827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.459172</td>\n",
       "      <td>0.397169</td>\n",
       "      <td>0.856426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSE       MAE        R2\n",
       "Decision tree  0.457891  0.395721  0.856827\n",
       "Random forest  0.459172  0.397169  0.856426"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=20)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_rand_forest = model.predict(X_train)\n",
    "\n",
    "mse = mean_squared_error(y1_diff_log_train, y1_pred_rand_forest)\n",
    "mae = mean_absolute_error(y1_diff_log_train, y1_pred_rand_forest)\n",
    "r2 = r2_score(y1_diff_log_train, y1_pred_rand_forest)\n",
    "\n",
    "table_time_diff_max_ach.loc[\"Random forest\"] = [mse, mae, r2]\n",
    "table_time_diff_max_ach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43911344-0e24-4cfe-86a9-407a4aaeb60b",
   "metadata": {},
   "source": [
    "## Inspection of the misclassifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ee668-6715-46aa-882e-d2d59f39908f",
   "metadata": {},
   "source": [
    "### Decision tree with two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "93ae7c14-4eea-44d5-844a-7b0961bd94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_train)\n",
    "y1_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "2da286a0-e64d-4fb2-8b19-9528b4161b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8321678321678322"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_pred_dec_tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "94120459-0794-43db-aeac-41101c8a6e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137,  19],\n",
       "       [ 29, 101]])"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y1_val, y1_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "fe18bff1-355c-4897-9652-a70e1be81636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450    1\n",
      "2732    1\n",
      "868     1\n",
      "1472    1\n",
      "336     0\n",
      "1730    0\n",
      "1421    1\n",
      "1231    1\n",
      "2425    1\n",
      "520     1\n",
      "1072    1\n",
      "719     0\n",
      "2424    1\n",
      "1417    1\n",
      "119     0\n",
      "1239    0\n",
      "1262    0\n",
      "1825    1\n",
      "1179    0\n",
      "1379    1\n",
      "2243    1\n",
      "137     0\n",
      "1268    0\n",
      "1367    0\n",
      "744     1\n",
      "750     1\n",
      "112     0\n",
      "184     1\n",
      "2748    1\n",
      "285     0\n",
      "177     1\n",
      "2895    0\n",
      "1455    1\n",
      "1442    1\n",
      "620     0\n",
      "1175    0\n",
      "1210    0\n",
      "353     1\n",
      "1983    1\n",
      "2043    1\n",
      "872     1\n",
      "651     1\n",
      "1937    1\n",
      "333     0\n",
      "1209    0\n",
      "402     1\n",
      "94      0\n",
      "1669    1\n",
      "Name: orig/rewr(mean), dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0])"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_not_equal = np.where(y1_val != y1_pred_dec_tree)[0]\n",
    "print(y1_val.iloc[indices_not_equal])\n",
    "y1_pred_dec_tree[indices_not_equal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "f5711bfd-38da-40de-ae87-a6e81e03caad",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py:891\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    890\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m--> 891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexers/utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[615], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m indices_not_equal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y1_val \u001b[38;5;241m!=\u001b[39m y1_pred_dec_tree)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m misclass \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43my1_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_not_equal\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m misclass\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue label\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39marray(y1_val\u001b[38;5;241m.\u001b[39miloc[indices_not_equal]))\n\u001b[1;32m      4\u001b[0m misclass\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred label\u001b[39m\u001b[38;5;124m'\u001b[39m, y1_pred_dec_tree[indices_not_equal])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py:1743\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1747\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py:1717\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[0;32m-> 1717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "indices_not_equal = np.where(y1_val != y1_pred_dec_tree)[0]\n",
    "misclass = df.iloc[y1_val.iloc[indices_not_equal].index]\n",
    "misclass.insert(0, 'true label', np.array(y1_val.iloc[indices_not_equal]))\n",
    "misclass.insert(0, 'pred label', y1_pred_dec_tree[indices_not_equal])\n",
    "misclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f38a0-6cb8-4e95-a80e-46fc22e35fc3",
   "metadata": {},
   "source": [
    "Cases where we would predict rewriting even if the original is faster should be avoided. This is only the case for 1056 and 904, where the differences of the running times are minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d895913-0a46-4caf-a78b-fe89e5eeaf53",
   "metadata": {},
   "source": [
    "### Decision tree with three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abed74e-ac6b-4a41-a324-149f0b7b9771",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0facc7-c81a-4f00-91f7-034e10c81e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_05_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66090a8-bd3a-46cc-8262-79c906dd95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_05_train)\n",
    "y1_equal_05_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae633a3-4e63-4503-b192-38792bfabc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y1_equal_05_val, y1_equal_05_pred_dec_tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e7b0a-840c-404b-9205-ee418365048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y1_equal_05_val, y1_equal_05_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2c296-c3b3-4534-a839-87f516813f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_not_equal = np.where(y1_equal_05_val != y1_equal_05_pred_dec_tree)[0]\n",
    "misclass = df.iloc[y1_equal_05_val.iloc[indices_not_equal].index]\n",
    "misclass.insert(0, 'true label', np.array(y1_equal_05_val.iloc[indices_not_equal]))\n",
    "misclass.insert(0, 'pred label', y1_equal_05_pred_dec_tree[indices_not_equal])\n",
    "misclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544b450-ac73-44f6-960d-4e5ad88405cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a739497-e34a-4cdc-98ec-f31bbc440bb5",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479e16e-2741-43f8-ba53-f21752c474b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_01_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb5ddb-9c5e-4041-b563-f37b9f5b81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_01_train)\n",
    "y1_equal_01_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26faef13-e78a-42b4-a4ed-35316641b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y1_equal_01_val, y1_equal_01_pred_dec_tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faab2ad-c0ef-40bd-9d14-8900a96a1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y1_equal_01_val, y1_equal_01_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507cbf1-4aed-4acf-9f27-f799bff8d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_not_equal = np.where(y1_equal_01_val != y1_equal_01_pred_dec_tree)[0]\n",
    "misclass = df.iloc[y1_equal_01_val.iloc[indices_not_equal].index]\n",
    "misclass.insert(0, 'true label', np.array(y1_equal_01_val.iloc[indices_not_equal]))\n",
    "misclass.insert(0, 'pred label', y1_equal_01_pred_dec_tree[indices_not_equal])\n",
    "misclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7d174-09a0-46e6-90f3-f3f6d68ffcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57656e6e-9776-4f56-b5a8-ec453a30f515",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef4c99-cb59-46d2-a780-5fc9aaae1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_005_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735e727-7173-4b83-b34f-27a7fe666574",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_005_train)\n",
    "y1_equal_005_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5838464-80c6-4629-810c-153dbda57a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y1_equal_005_val, y1_equal_005_pred_dec_tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf3f77-c1e7-4272-bbf1-ff77e6d6e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y1_equal_005_val, y1_equal_005_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0d5a6-7693-47d0-ab2c-2fc177aac755",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_not_equal = np.where(y1_equal_005_val != y1_equal_005_pred_dec_tree)[0]\n",
    "misclass = df.iloc[y1_equal_005_val.iloc[indices_not_equal].index]\n",
    "misclass.insert(0, 'true label', np.array(y1_equal_005_val.iloc[indices_not_equal]))\n",
    "misclass.insert(0, 'pred label', y1_equal_005_pred_dec_tree[indices_not_equal])\n",
    "misclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c09d2-6e50-4fdd-9a04-107c5d727546",
   "metadata": {},
   "source": [
    "Here -1 = orig, 0 = equal and 1 = rewr. We do not want to predict 1 and true = -1. This is never the case.\n",
    "Since we would also assign equal as orig later, we do not want predict = 0 and true = -1. This is the case for two times, but both in the same order of magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d8b8a4-e1b7-483d-b777-a7e0d28d5523",
   "metadata": {},
   "source": [
    "##### equal cut off: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac920d86-da96-4a21-9bd7-86a85e2c54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_equal_001_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7fc01-ee7f-42d6-bf68-ce67e68f78b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 20)\n",
    "clf.fit(X_train, y1_equal_001_train)\n",
    "y1_equal_001_pred_dec_tree = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b283504-1200-4509-b389-55195e05b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y1_equal_001_val, y1_equal_001_pred_dec_tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675ddfd-9376-438d-a846-aa4501198dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y1_equal_001_val, y1_equal_001_pred_dec_tree)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e5c13-9f68-44d2-bf5c-17dc5e126563",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_not_equal = np.where(y1_equal_001_val != y1_equal_001_pred_dec_tree)[0]\n",
    "misclass = df.iloc[y1_equal_001_val.iloc[indices_not_equal].index]\n",
    "misclass.insert(0, 'true label', np.array(y1_equal_001_val.iloc[indices_not_equal]))\n",
    "misclass.insert(0, 'pred label', y1_equal_001_pred_dec_tree[indices_not_equal])\n",
    "misclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b5064-707c-497e-83ef-d81dd9b01434",
   "metadata": {},
   "source": [
    "### Decision tree with time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c42601-693f-4279-9a94-c22fba79439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(random_state = 20)\n",
    "model.fit(X_train, y1_diff_log_train)\n",
    "y1_pred_dec_tree = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638fe407-ff3a-46d1-82c5-bc0cf9a92e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y1_diff_log_val, y1_pred_dec_tree)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3b53e-c526-4b7c-b8ad-b21f1370c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_decision = (y1_pred_dec_tree < 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c801a-8946-42b0-942a-559b0909106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y1_val, y1_decision)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cbfba4-561d-4c6d-8a64-77c5968002d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y1_val, y1_decision)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148c3bc-e003-4479-960c-2b04dc8b0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_not_equal = np.where(y1_val != y1_decision)[0]\n",
    "misclass = df.iloc[y1_val.iloc[indices_not_equal].index]\n",
    "misclass.insert(0, 'true label', np.array(y1_val.iloc[indices_not_equal]))\n",
    "misclass.insert(0, 'pred label', y1_decision[indices_not_equal])\n",
    "misclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6631ac77-52ee-4f06-8124-e8ac1e2f3177",
   "metadata": {},
   "source": [
    "Cases where we would predict rewriting even if the original is faster should be avoided. This is only the case for 1268, 944, 1056 and 904, where the differences of the running times are minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fecc98-d8f1-4927-a904-760b554f5bb4",
   "metadata": {},
   "source": [
    "## Statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0241f383-002b-4d5b-9d04-07272933f3ca",
   "metadata": {},
   "source": [
    "We are testing the difference between the maximum, mean, median and standard deviation of the runtimes with the original version and the decision version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec3910-72e8-4eac-a21f-dbd8ea765fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9045a06-f5ce-49bf-b41c-485ec4a38279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
